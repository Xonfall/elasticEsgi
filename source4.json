{"index": {"_id": 1}}
{"title":"Elastic Cloud and Meltdown","seo_title":"","url":"\/blog\/elastic-cloud-and-meltdown","author":{"name":"Elastic Engineering"},"date":"January 08, 2018","category":"Engineering","locales":"","content":" Elastic is aware of the and we are addressing them for Elastic Cloud. We know that you entrust your data to our cloud service, and we take the confidentiality of all data very seriously. At this time, we are not aware of any exploit on our cloud service that utilized the Meltdown or Spectre vulnerabilities. Impact Assessment The Meltdown or Spectre vulnerabilities apply when untrusted code can execute on a system. At the host infrastructure level, we know that both our infrastructure providers (AWS and GCP) have patched their systems, and are no longer vulnerable. At the Elastic Cloud service level, Elastic Cloud allows you to upload some artifacts, such as plug-ins, dictionaries, and scripts. These uploads provide a potential vector of attack that could exploit Meltdown. Old Elasticsearch clusters on version 1.x are more vulnerable. Except uploads from you, Elastic Cloud does not allow for untrusted code execution. Based on our assessment, we believe the impact of Meltdown and Spectre to Elastic Cloud to be small. We have focused our efforts on mitigation and control while we carry out our regular process for operating system patches in an accelerated fashion. Mitigation We disabled non-sandboxed scripting for all Elasticsearch 1.x clusters as a primary, customer-visible mitigation. We have also disabled self-service uploads of custom bundles from you until we have fully completed our patching. Behind the scenes, we\u2019ve further increased our observability of system-level calls and isolated clusters running version 1.x of Elasticsearch on their own hosts. Patching and Customer Impact We are using an accelerated version of our regular maintenance procedure to perform OS-level updates while maintaining service availability for user clusters. Your clusters will not experience downtime from this operating system patching. There is considerable speculation on the internet about the performance impact of the patches to address Meltdown. We have begun Elasticsearch-specific testing to establish the impact for our common benchmarking scenarios and will publish a blog post with this information as soon as we have it. Further Assistance As always, our support team is available to answer questions you have regarding Meltdown, Spectre, and our handling of them. Please use your standard support channel to ask those questions. \n"}
{"index": {"_id": 2}}
{"title":"Brewing in Beats: Password Keystore","seo_title":"","url":"\/blog\/brewing-in-beats-password-keystore","author":{"name":"Monica Sarbu"},"date":"January 05, 2018","category":"Brewing in Beats","locales":"","content":" Did you know that is already available? Try it and let us know what you think. If you are curious to see the Beats\u00a0in action, we just published the . This update includes the changes over the last two weeks. Password keystoreWe have merged the which allow users to define sensitive information into an obfuscated data store on disk instead of having them defined in plaintext in the yaml configuration.# create new keystore to disk .\/metricbeat keystore create # add a new key to the store. .\/metricbeat keystore add elasticsearch_password # remove a key from the store .\/metricbeat keystore remove elasticsearch_password # list the configured keys without the sensitive information .\/metricbeat keystore list You can then reference the keys from the keystore using the same syntax that we use for the environment variables: password: \"${elasticserarch_password}\" In the current implementation, the passwords are not encrypted into the keystore, only obfuscated. This new feature is planned to be released with the 6.2 release. Structured logging in libbeatThis refactors the logging of libbeat and adds support for structured logging. The new logging implementation is based on , which is one of the most efficient structured logging libraries for Golang. To switch to the JSON format, simply add to the configuration file. Another enhancement is that the Beats can also . By setting , all logs will be written to the Application log. The source name will be the name of the Beat. Besides this, there are no changes to the user facing logging configuration. The non-JSON logger output has some format differences, but, in general, it will have a more consistent format across outputs. These changes are only in the master branch at the moment, but we will likely include it in 6.2. Metricbeat: Read HAProxy metrics over HTTPThanks to , the HAProxy module can in addition to the TCP socket. This means HTTP authentication is also supported when reading the stats. The improvement will be available in the 6.2 release. Other changes:Repository: elastic\/beatsAffecting all BeatsChanges in master: MetricbeatChanges in 6.1: PacketbeatChanges in master: AuditbeatChanges in master: TestingChanges in master: Changes in 6.1: Changes in 6.0: InfrastructureChanges in master: DocumentationChanges in 6.1: \n"}
{"index": {"_id": 3}}
{"title":"Logstash Lines: Update for January 2, 2018","seo_title":"","url":"\/blog\/logstash-lines-2018-01-02","author":{"name":"Andrew Cholakian"},"date":"January 02, 2018","category":"The Logstash Lines","locales":"","content":" We're back from the holidays with some great new features!In 6.0 we released the Logstash Pipeline Viewer. To get to this view, users would first have to go through the Pipelines view. This view listed the user's pipelines as cards with each card listing out the pipeline's versions.We are targeting 6.2 for a\u00a0redesigned tPipelines view to not only serve as a navigational tool to the Pipeline Viewer but also to provide users with a summary view of their pipelines' health.Many thanks to several Elasticians who volunteered their time to help usability test designs for the new Pipelines view.With \u00a0users will be able to specify the pipeline ID from the CLI from 6.2.0 onward with the new --pipeline.id option. This is useful for those not using the pipelines.yml file.\u00a0More consistent handling of IP addr lookups (Targetting LS 7.0) in TCP input as of\u00a0Better handling of empty source fields in geoip plugin as of\u00a0We have a tool that can generate a list of LS deps + their licenses for Legal compliance reasons. \n"}
{"index": {"_id": 4}}
{"title":"This Year in Elasticsearch and Apache Lucene - 2017","seo_title":"","url":"\/blog\/this-year-in-elasticsearch-and-apache-lucene-2017","author":{"name":"Adrien Grand"},"date":"January 01, 2018","category":"Engineering","locales":"","content":" As the Earth's rotation\u00a0reaches the point where\u00a0we\u00a0close out another Gregorian calendar year, we wanted to share one last week\u00a0in Lucene.Lucene is the core component that Elasticsearch is built on, we've seen some users that may have\u00a0not even\u00a0known about Lucene without Elasticsearch,\u00a0and there are\u00a0\u00a0\u00a0\u00a0that mention that Lucene bugs were\u00a0found via Elasticsearch. The work we do on both projects\u00a0is a\u00a0commitment that we take great pride in.Here is a non-exhaustive list, in no particular order, of improvements that we made to Lucene over the course of 2017 that we hope you find interesting.And, as a bit of history, here is\u00a0Shay Banon's , way back in 2006.We're really\u00a0looking forward to growing this list of Elastic contributors in 2018. \n"}
{"index": {"_id": 5}}
{"title":"Kibana: This week in Kibana for December 26, 2017","seo_title":"","url":"\/blog\/keeping-up-with-kibana-2017-12-26","author":{"name":"Jim Goodwin"},"date":"December 26, 2017","category":"Kurrently in Kibana","locales":"","content":" Welcome to\u00a0This is a weekly series of posts on new developments\u00a0in the Kibana project and any related learning resources and events. Let's talk breaking changes. Wondering how we migrated to be compatible with 6.0? Tyler walks through how the team navigated the removal of mapping types. \u2014 elastic (@elastic) Hi all, Well, this is the last post in this series for 2017, and it has been an incredibly productive year for Kibana. Thank you for all of the enhancement requests, PRs, error reports, AMA questions, and forum posts, they help us to make Kibana better for everyone.\u00a0I won't reiterate all of the changes from 2017, but if you haven't upgraded Kibana in a while you should really read these release posts below, there is a lot of value there and we have a packed road map for 2018.That's all for this week, have a great end of 2017, and a happy new year!Cheers, Jim \n"}
{"index": {"_id": 6}}
{"title":"The Elastic Advent Calendar 2017, Week 4","seo_title":"","url":"\/blog\/elastic-advent-calendar-2017-week-four","author":{"name":"Aaron Aldrich"},"date":"December 26, 2017","category":"Engineering","locales":"","content":" As we mentioned in our , the Engineering team here at Elastic wanted to celebrate the end of the 2017 Calendar via our own tech-advent series. We took a lot of inspiration from both the (fully in Japanese) and (in English) and we\u2019d like to thank them for providing the awesome quality we have aspired to maintain. We have summarised weeks , and in previous blog posts, and this post covers the last and final (all be it short) week and also provides a summary of all the topics that were posted in the series. Here\u2019s all 25 topics: Dec 1: by Mark Walkom Dec 2: by Jun Ohtani Dec 3: by Tyler Hannan Dec 4: by David Pilato Dec 5: by Tal Levy Dec 6: by Jongmin Kim Dec 7: by Christopher Wurm Dec 8: by Medcl Zeng Dec 9: by Jordan Sissel Dec 10 by Philipp Krenn Dec 11: by Thiago Souza Dec 12: by Atonio Bonuccelli Dec 13: by Aaron Aldrich Dec 14: by Jun Ohtani Dec 15: by Abdon Pijpelink Dec 16: by David Pilato Dec 17: by Mat Schaffer Dec 18: by Jongmin Kim Dec 19: by Tyler Langlois Dec 20: by Medcl Zeng Dec 21: by Sherry Ger Dec 22: by Thiago Souza Dec 23: by Bhavya Mandya Dec 24: by Philipp Krenn Dec 25: by Mark Walkom Thank You! We will be keeping all the of the topics available on the so you can refer back to them at any time. And, as these are Discuss topics, you can also continue the conversation with the authors! Thanks for following on through this series, we hope it\u2019s provided some useful inspiration for your use of the Elastic Stack. If you\u2019d like us to repeat this, or if you have ideas for next year, please let us know via or feel free to create a topic in our with your comments. We hope 2017 has been a great year and we look forward to 2018 being even better! \n"}
{"index": {"_id": 7}}
{"title":"Solving the Small but Important Issues with Fix-It Fridays","seo_title":"","url":"\/blog\/solving-the-small-but-important-issues-with-fix-it-fridays","author":{"name":"Daniel Cecil"},"date":"December 22, 2017","category":"Culture","locales":"","content":" Question: How many engineers does it take to change a light bulb? Answer: The light bulb works fine on the system in my office... OK. It isn\u2019t a great joke. But it\u2019s the perfect setup for discussing an important topic here at Elastic: How do busy engineers, often working on large and gnarly projects, handle the small issues \u2014 like changing a metaphorical light bulb \u2014 that inevitably pop up from time to time? The answer: Fix-It Friday. The Elasticsearch code is housed in a public repository and accessible to anyone. When a user finds bugs, spots missing features, or wants to make a specific request, they can flag it using the issues tab by simply submitting a new issue. The process is open and transparent \u2014 just the way we like it. Each day, someone on the Elasticsearch team is assigned to a role called support dev help. In this role, the engineer has the dual duty of aiding the Elastic support team while looking for fresh issues in the Elasticsearch repository. When a new issue arises, the engineer will add a label to help the team prioritize when to tackle it, and how much effort it might take to solve it. However, not all issues have a simple diagnosis, nor an easy fix. \u201cIf there\u2019s enough information, but it\u2019s not clear that the issue is something we really want to handle due to policy, or maybe the person handling the ticket doesn\u2019t have enough knowledge in the issue area to make a decision on it, then we can mark the ticket \u2018discuss\u2019 and it goes into the queue for Fix-It Friday,\u201d said Colin Goodheart-Smithe, Elasticsearch Software Engineer. \u00a0 Elasticsearch Team Lead Clint Gormley created the Fix-It Friday initiative a little over three years ago as a time when these small issues were given to engineers to solve. That ambitious concept didn\u2019t last very long. The team quickly learned that small issues often turned out to be big ones in disguise. (Think: the filament in the light bulb looks dead, but in reality the electricity is out.) So, the scope of Fix-It Friday evolved into a get together for discussing user requests and finding solutions. Since the Elastic team is distributed, the meetup also became a weekly opportunity to get off Slack and email and get focused on a team video call. \u201cIt\u2019s a good time,\u201d said Gormley, \u201cgetting a group with such a wide range of expertise in one virtual room \u2014 it\u2019s amazing.\u201d About 10 issues are discussed during a typical one hour Fix-It Friday session. Issues are later fixed and implemented or de-escalated. When asked whether there was a particular issue from a Fix-It Friday meeting that jumped out at him, or that he thought was quirky or fun, Gormley laughed. \u201cWe\u2019ve only been through 12,000 issues or something \u2026.\u201d But one seemingly small bug hiding something larger did spring to mind. Users reported heavy queries submitted to Elasticsearch never timing out, and Gormley recalled queries which ran for hours. \u201cUsually, our queries run milliseconds, so if one runs for an hour, you know you have a problem,\u201d he explained. In these situations users, thinking nothing is happening, run the query again. So, instead of one running for an hour, they actually have two \u2014 or more. This isn\u2019t exactly an issue that could break anything, but it had the potential to slow results and reduce resources. The issue was marked for discussion at a Fix-It Friday session. After a lengthy debate, Elastic engineers considered adding a default timeout, meaning in one hour\u2019s time, the query got canceled. It seemed like a good idea at first. But with several eyeballs on the issue, another perspective developed. Data is stored in indexes mapped out to shards, which are situated on different machines. When you run a query, it reaches out to all the shards, gathering the results and providing those results to the user. But what happens if one of the shards is missing due to a dying node on the shard, or when it gets disconnected from the network, causing the heavy query to fail? Should Elasticsearch show an exception? Or show only the results from the available shards? Users performing a simple search might be happy with getting results only from available shards. But users performing analytics would want to know that they\u2019re receiving partial results. For the timeout option, Elastic engineers decided that a silent timeout (when you do not get a notification that the query stopped running) was out of the question. They also considered throwing an exception so that the user knew something was wrong with the query. But what of other circumstances, such as a missing shard, that can create partial results? Should that throw a hard exception too? In the end, they decided to add a global and per-request setting to toggle this behavior. The timeout discussion turned out to be too large a decision for one engineer to make on their own. \u201cFrom a user perspective it\u2019s important that we actually look at these things,\u201d said Gormley. \u201cOur users are very involved. If they\u2019ve taken the time to write a decent issue, we owe it to them to respond appropriately.\u201d This is where the value of Fix-It Friday really comes into play \u2014 it\u2019s a broadening of the collective Elastic mind. For engineers, Fix-It Friday is a chance to break from the day-to-day and think about new issues in different ways, providing an opportunity to meditate on an problem that may not be their particular focus but is part of the larger product. In the end, Fix-It Friday isn\u2019t about simply fixing bugs, or fielding requests \u2014 it\u2019s about widening the scope of what Elastic can do. \u201cIt's about making decisions,\u201d said Elasticsearch Software Engineer Adrien Grand. \u201cIt\u2019s about which direction we want to take.\u201d \u201cYou see people asking us to add features that work on small datasets but won\u2019t scale,\u201d said Gormley. \u201cIf we make something as a small-scale solution, inevitably someone will want to use it on the big scale and it will fail. That kind of stuff is important for new devs to know so that they can make these decisions later on. There\u2019s an ethos to how we develop: guiding principles of what to add, and what not to add.\u201d However, Gormley added, nothing is set in stone. \u201cThat willingness to change minds is an important part of the Elastic culture.\u201d \u201cAs usual in open source,\u201d added Adrien Grand, \u201cno is temporary, but yes is forever.\u201d \n"}
{"index": {"_id": 8}}
{"title":"iPrice Group & the largest e-commerce catalog in Southeast Asia \u2013 powered by Elasticsearch","seo_title":"","url":"\/blog\/iprice-group-and-the-largest-ecommerce-catalog-in-southeast-asia-powered-by-elasticsearch","author":{"name":"Heinrich Wendel"},"date":"December 22, 2017","category":"User Stories","locales":"","content":" E-commerce is a very young and fragmented space in Southeast Asia (SEA). Unlike the United States, where Amazon is well established as the no. 1 player in online shopping, there are tens of thousands of entrepreneurs fighting for the favor of local shoppers with no clear leader in sight. Moreover, customers in our seven countries that constitute SEA, namely , , , , , and , have their individual preferences and unique tastes in accordance to their local culture.\u00a0 Here at iPrice, we set out with the mission to build SEA\u2019s one-stop-shopping destination, aggregating the product catalogs of all these merchants into a single shopping experience for the end user. They wouldn\u2019t have to visit each merchant one-by-one to find the products they are searching for: instead, iPrice categorizes the products and presents them to shoppers in a well-organized and visually-appealing fashion. The idea of product discovery was born, with the goal to make e-commerce more accessible and credible to the . Targeting 250 million SKUs to a population of almost 600 million peopleAt the beginning we had to ask ourselves the all too well-known question, \u201cWhat technology platform to base iPrice on?\u201d While a traditional SQL approach would have secured us easy access to developer talent, we were concerned about scalability. The two most popular e-commerce stores in SEA were\u00a0launched just less than five years ago, but we knew that the region was about to experience its internet moment in a similar way to how China did a few years earlier. We were looking for a solution that was simple to set up with a small start-up team while we had little traffic and only a couple of million products, but scaled easily whenever the internet-burst would happen. From a functional perspective, e-commerce is all about search. Shoppers are trying to find one or two items they want to buy out of a catalog of hundreds of thousands of items. We are not a simple store but an aggregator of all stores\u2014meaning we would have to deal with a scale that is one order of magnitude higher, carrying\u00a0hundreds of millions of items. Our eyes naturally fell on Elasticsearch,\u00a0a Lucene-based solution which was already renowned for its full-text search capabilities and had already gathered a decent reputation. Still undecided if we should stage Elasticsearch with a SQL-based primary data store, we thought through the customer purchasing journey through online portals. We found that customers only want to see the most recent information, meaning if they click on a product and it turns out to be out-of-stock on the merchant\u2019s site, they can\u2019t buy it and we lose a potential lead.\u00a0 As such, we had to make sure that our product catalog is always up-to-date, while avoiding any additional replication or synchronization of the data which would potentially take a couple of hours.\u00a0 While product data is the core of what we deal with, we also have to store the navigation structure of our portals, supplemental content that provides shoppers with contextual information about products they are interested in, and\u00a0last but not least, data about the shoppers\u2019 behavior on the site. Again, the question was whether to add a secondary SQL database or not, but the nature of this kind of data is also not very relational and Elasticsearch was already renowned for holding\u00a0large amounts of log information. We settled on implementing our own CMS on top of Elasticsearch as our primary data store, going completely NoSQL in our approach, and this has benefited us in the long run. Importing >630 GB every 24 hours into a cluster with 320 GB of memoryThe following diagram illustrates our architecture in a nutshell. At the end of every day, our partners provide us with their latest product catalog in the form of CSV or XML files. After midnight, when it is unlikely that there are any updates to their inventory and the load on Elasticsearch\u00a0is minimal, we start the import process. It is timed very accurately, to ensure most late night shoppers in SEA have gone to bed and the countries with different time-zones, like Indonesia, have also crossed the ending of the day. Within two and a half years, our product catalog has grown to 250 million products, and with that, it is quite natural that every day a couple of the feeds error out or provide invalid data. To catch these, we use the powerful aggregation capabilities of Elasticsearch to create reports showing how the new catalog differs from the old one. First thing in the morning,\u00a0our Ops team looks at the report, and decides which parts of the new catalog are good to go out to our site.During this phase, our navigation structure is dynamically updated based on the new product catalog and written into another index\u2014the content index. This pre-calculation makes sure that heavy aggregations won\u2019t slow down the site during customer visits, an\u00a0important learning that we will expound in detail later. At the same time the log data is analyzed and each product gets a new popularity value assigned. This value is used in the frontend for sorting the items, making sure that we show the most relevant ones to our users. Singapore and Hong Kong are relatively small in terms of their population with a couple of millions, whereas Indonesia\u2019s hundreds of islands account more than 260 million people. Also, their status of development couldn\u2019t be more different, while Singapore is amongst the world\u2019s most modern cities, Indonesia\u2019s capital is known for the world\u2019s worst traffic. We serve a totally different product catalog in each country and had to specifically cater to SEA\u2019s various demographic of online shoppers as well as their different consumer behavior, which affects our frontend performance. We decided to duplicate our index structure for each country, keep light content indices in dedicated cluster, and run each of heavy indices with products on its own cluster. This guarantees that only the required dataset for the individual country has to be loaded into memory for queries, but balances out the load across all nodes in the most efficient way. What we have learned while building this architectureImplementation of the first couple versions of our application have been quite minimal. At the same time, the amount of uncompressed data didn't exceed the limit of a few gigabytes. At that time, imports only took a few hours each night and were finished at the beginning of the day. Over time, the amount of data being imported increased more than 10-fold, which influenced the speed of the imports. The time it took was up to 10 hours, and we had to begin exploring possible ways to further optimize the process. First implementation of our infrastructure was quite simple. We used PAAS such as Qbox and Amazon\u2019s Elasticsearch. This was justified as long as the dataset was within tens of gigabytes. It served us well in quickly setting up an Elasticsearch cluster and scaling it with our growing traffic. It has its limitations though, for example we were not able to tweak cluster settings like queue sizes, thread pools limits, or shard allocation.\u00a0 Migrating to EC2 self-hosted nodes allowed us to optimize our database to mostly query heavy operations during the day, while running a quick nightly import of our product catalog. At the same time, Elastic was developing new versions at a rapid speed, introducing a lot of performance optimizations, and such setup allows us upgrade as soon as a stable version is released. Moving further, while performing a set of benchmark tests, we decided to go with multi-cluster setup: running each node as a separate cluster. Scaling up the number of nodes in the clusters did not lead to linear performance increase. Import speed with the one node cluster is ~14,000 documents per second, adding second node to the cluster gives ~20,000 documents per second, a 50% improve approximately. At the same time, such setup allowed us to separate heavy indices with product catalog on a country level. Furthermore, we clearly understood that Elastic Block Storage volumes are not inferior in performance to directly attached instance storage, with its relatively limited size. Provision data volumes with size ~3.3 TB allowed us to get maximum IOPS performance that AWS provides for one general purpose SSD volume. Average disk utilization, during ingesting and heavy aggregations, was below 70%.\u00a0 It was worth mentioning that our major goal was ingest performance and search. In order to keep our infrastructure fault tolerant, we have developed certain backup and restore policies as well as introduced a caching layer on the frontend. Next, we started using bulk requests instead of singular index query and set the refresh interval to -1 during import. It reduced overhead of HTTP packages and improved indexing significantly. The exact bulk sizing depends on the average document size and we ran a few tests with different configurations to find the best performing configuration in our case. The basic idea was to measure and optimize the number of documents that are inserted in one bulk and the . We made measurements with bulk sizes in the range of 100\u201325,000 documents and number of threads ranging from 10-1,100.\u00a0 In our particular case, with average document size between ~3-5 KB and one m4.4xlarge node per cluster each having 16 cores, the optimal configuration is 70 simultaneously running threads with bulk size equal to 7,000 documents. This might sound very big\u2014it\u2019s about 75 MB per request\u2014but since both our clusters and backend are located in the same AWS datacenter, the network bandwidth was not an issue. If you set the number of simultaneously running threads and bulk size too high though, the cluster nodes are unable to process data in its queue and requests will be rejected. Import time could be decreased by a factor of five this way. Import application runs on c4.8 large sized instance with 36 CPU cores and 60 GB of memory. Our use case involves post processing of data after it has been imported. Roughly speaking, we have to update, remove or insert documents, applying a set of rules and index it with supplemental content. Here we benefited from\u00a0 that can be used together with bulk API. Since documents in Elasticsearch are immutable, the update API follows a \"retrieve-change-reindex\" process. With partial update, we can specify only the fields of the document that should be updated. Merging process happens within each shard, avoiding unnecessary data transfer. The equivalent of bulk for getting data is the , which makes sure that data is held in memory and doesn\u2019t have to be requeried while retrieving it in multiple chunks. Again, only the required fields should be retrieved using . All this helped us to solve issues with slow post-processing of the imported data. Since we are serving seven different countries, with an import running on a nightly basis, we create one new index per country in every cluster. Using one index per day makes sure that only the current version has to be held in memory by Elasticsearch and does not affect query performance. In order to release the freshest data set in each country, every day we use aliases which give us the flexibility to allow us to: We don't have to update anything on our frontend to use the new index name, take care of all of this. Over time, as our website offers more functionality, our queries and aggregations became heavier and the response time of some queries has increased dramatically as well as the node\u2019s CPU usage. On one hand, deep investigation showed that we did not use filter cache efficiently, on the other hand some queries were just not well optimized. In order to improve them, we split queries that retrieved actual hits from aggregations. when a dynamic query that retrieves actual documents (hits) does not get cached. We still issue both together using the to avoid additional trips between our frontend and the database. You can quickly overlook that you have to manually enable the for each of your indexes. Keep in mind that the cache key is the complete json query, so if you change a small part, let\u2019s say only the indenting, it will have to re-run the complete query again. We then got rid of exclude or include statements in aggregations. Filtering data in query helps to aggregate less data, which has a severe impact on performance. Next, we noticed that running aggregation on analyzed data field slows down response time significantly due to an explosion of possible terms. As an example, we used the path hierarchy analyzer for some document's fields. With more and more documents, the time aggregation queries on analyzed data field took increased up to 800 ms. Obviously, performance of certain pages went down. In order to address this, we defined raw fields in addition to the analyzed fields and run aggregation on them if possible. When timed, the duration required for aggregation was around 30-40 ms. Future improvements and optimizations on the way to 1 billion productsSo far, we have only scratched the surface of Elasticsearch\u2019s capabilities and we have plenty of ideas to further exploit its full potential. Here is short excerpt of the projects we have on our backlog to give you an idea of the possibilities with Elasticsearch: Based on our experience, we are confident to say that Elasticsearch is the technology of choice to implement in these scenarios. There are always stumbling blocks along the road and we are planning to share our experience about implementing these scenarios in subsequent blog posts, so that you don\u2019t have to stumble over them yourself. Stay tuned. About the Authors is the co-founder & CTO of iPrice Group Sdn Bhd. After working for Microsoft for four years, Heinrich left his position as a Product Manager for Visual Studio in Seattle and moved to Malaysia in 2014 to in initiate iPrice. With an affinity to bridge user experience and technology, he aims to make iPrice a leader in Southeast Asia's young e-commerce ecosystem. Combining NLT and a data-driven approach with visual discovery, iPrice strives to provide customers the most relevant products and coupons amongst the plethora of products on the internet is the lead DevOps Engineer at iPrice Group Sdn Bhd. He has been a part of\u00a0iPrice since its inception in 2014. Anton is passionate about system architecture, overcoming challenges, and has an extremely strong affinity for automation and system software development \u00a0iPrice Group is a meta-search website where consumers can easily compare prices, specs and discover products with hundreds of local and regional merchants. iPrice\u2019s meta-search platform is available in six other countries across Southeast Asia namely in: Singapore, Malaysia, Indonesia, Philippines, Thailand, Vietnam and Hong Kong. Currently, iPrice compares and catalogues more than 200 million products and receives more than five million monthly visits across the region. iPrice currently operates three business lines: price comparison for electronics and health & beauty: product discovery for fashion and home & living: and coupons across all verticals. \n"}
{"index": {"_id": 9}}
{"title":"Elastic Advent Calendar 2017, Week 3","seo_title":"","url":"\/blog\/elastic-advent-calendar-2017-week-three","author":{"name":"Mark Walkom"},"date":"December 22, 2017","category":"Engineering","locales":"","content":" Week three of the leads us towards the last of the series. If you\u2019re just joining us, this calendar is how we\u2019re celebrating the end of the year \u2014 by sharing a daily Elastic Stack tip in our community . You can catch up on the first two weeks by heading . French, Korean and English feature this week, and we have topics ranging from Elastic Cloud Enterprise, through to building your own crawler that indexes pages to Elasticsearch and a fantastic post on monitoring Kubernetes using the Elastic Stack. As usual you can follow along live by checking out or subscribing to the , or watch for the daily tweeting on . Here\u2019s a sample of what we\u2019ve posted from our third week: Dec 15: by Abdon Pijpelink Dec 16: [[FR][Elasticsearch] Tests de performance pour votre plugin Elasticsearch]]() by David Pilato Dec 17: by Mat Schaffer Dec 18: by Jongmin Kim Dec 19: by Tyler Langlois Dec 20: by Medcl Zeng Dec 21: by Sherry Ger ! If you\u2019re looking for other great pieces of reading, we recommend checking out our inspiration calendars \u2014 the (fully in Japanese) and (in English). And don\u2019t be afraid to leave some feedback on the posts \u2014 we\u2019d love to hear your thoughts! \n"}
{"index": {"_id": 10}}
{"title":"Kibana's Road to 6.0 and the Removal of Mapping Types","seo_title":"","url":"\/blog\/kibana-6-removal-of-mapping-types","author":{"name":"Tyler Smalley"},"date":"December 20, 2017","category":"Engineering","locales":"","content":" When Elasticsearch in 6.0.0, it was a major breaking change that affected any application that uses indices with multiple types. Kibana is one such application, relying on multiple types to store objects like visualizations, dashboards, index patterns, and more. How did we successfully migrate Kibana to be compatible with Elasticsearch 6? We share this strategy with you below, and hope that it gives you ideas for how to convert your multi-type indices to single-type. First, deciding what the new mapping was going to look like. There are a few common alternatives to mapping types: We chose adding a custom type field and nesting the data under the name of the type. This allowed us to have fields with the same name under different types, which was previously a limitation. Here is a visual of what this Elasticsearch document transformation looks like: Once we had the mapping, the next step was migrating the data. When creating the new index, we need to ensure is , otherwise we will not be able to fall-back to the single type. Additionally, 5.6 has an option which mimics the behavior in 6.0. After creating the new index with the desired mapping, we reindexed the data into the new format. To do this, we leverage the reindex API to transform the documents, setting the type field and nesting the previous data under the name of the type. Since IDs are only unique within a type, we also prefix the ID with the type. Using an alias, we can swap out the index in a single atomic action without downtime. Details of this full migration process can be found in our . Kibana 5.6 is considered a compatibility release, allowing users to perform a rolling upgrade to 6.0 without downtime. This means Kibana 5.6 needs to seamlessly handle both single and multiple mapping types. To allow for this, we introduced a which has become the preferred way of programmatically interacting with Kibana data. This allows for a consistent interface, regardless of the underlying Elasticsearch document structure. In 5.6, we still default to using multiple types, but fall back to a single type when we identify the data has been migrated. Here are a few examples of how we built a fallback system. Create When creating a document we will receive a if the type does not exist. We receive this error after the data has been migrated, allowing us to re-try with the single-type format. POST \/.kibana\/doc\/index-pattern:abc123\/_create { \"type\":\"index-pattern\", \"index-pattern\":{ \"title\":\"Test pattern\" } } GetInstead of making two requests, we can perform a single search to capture the document. Here we use a boolean query containing both of the formats. POST \/.kibana\/_search { \"query\":{ \"bool\":{ \"should\":[{ \"bool\":{ \"must\":[{ \"term\":{ \"_id\":\"abc123\" } }, { \"term\":{ \"_type\":\"index-pattern\" } }] } }, { \"bool\":{ \"must\":[{ \"term\":{ \"_id\":\"index-pattern:abc123\" } }, { \"term\":{ \"type\":\"index-pattern\" } }] } }] } } } DeleteWhen deleting a document, we use , providing the same query used for fetching a document. UpdateWhen using the _update API, we receive a if the document is missing. We receive this after the data has been migrated, allowing us to re-try with the single-type format. POST \/.kibana\/doc\/index-pattern:abc123\/_update { \"index-pattern\":{ \"title\":\"My new title\" } } These changes allowed us to migrate the Kibana index at any time during a 5.6 installation. In X-Pack, we have made this process even easier for users through our . If you have indices created in 2.x, you must reindex them before upgrading to Elasticsearch 6.0. In addition, the internal Kibana and X-Pack indices must be reindexed to upgrade them to the format required in 6.0. The Reindex Helper identifies these indices and provides a button to perform the reindex. Have a special use case or strategy for how to migrate your multiple type indices to single type? Share it with us! You can also ask us for advice on our . \n"}
{"index": {"_id": 11}}
{"title":"Applications for Django Girls San Francisco Workshop Now Open","seo_title":"","url":"\/blog\/applications-for-django-girls-san-francisco-workshop-now-open","author":{"name":"Michelle Carroll"},"date":"December 20, 2017","category":"Culture","locales":"","content":" We\u2019re excited to be hosting a Django Girls workshop in San Francisco on Sunday, February 25! . If you\u2019re not familiar with the organization, Django Girls is on a mission to inspire a love of programming for newcomers, and especially for underrepresented folks in tech (like women). The organization enables local teams of volunteers to set up one-day workshops, with an emphasis on achieving small successes in a supportive environment. It\u2019s an organization and a mission we\u2019re passionate about \u2014 democratizing technology, keeping things fun, and having fantastic documentation to boot. We strongly believe in the value of Django Girls. We are not only hosting this event, but we have sponsored 18 other events all over the world. This is our second year hosting a workshop around Elastic{ON}, and it\u2019s been an amazing experience for everyone involved. (Want an additional perspective? .) As part of a distributed company, is a rare opportunity to bring many employees together in one place and work together on passion projects \u2014 like being coaches for the workshop. We\u2019re also super-jazzed to be hosted by in their awesome space. While most of the folks who are using the Elastic Stack have some experience programming, we know that\u2019s not universal \u2014 and folks who are in dev, ops, QA, analyst, or other programming-heavy roles often get asked for recommendations on learning how to code. Help us spread this education by getting the word out on this free workshop. Share this blog post or the , and don\u2019t forget that applications close January 30! And finally, we recommend checking out the to see what workshops are coming up (and when they\u2019re looking for coaches or applicants) and to get a sense of what it takes to organize one in your local region. Django Girls. Dream. Create. Code. We hope to see you there! \n"}
{"index": {"_id": 12}}
{"title":"Smarter Machine Learning Job Placement in Elasticsearch","seo_title":"Smarter Machine Learning Job Placement in Elasticsearch","url":"\/blog\/smarter-machine-learning-job-placement-in-elasticsearch","author":{"name":"David Roberts"},"date":"December 19, 2017","category":"Engineering","locales":"","content":" Ever since we , ML jobs have been automatically distributed and managed across the Elasticsearch cluster. To recap, you specify which nodes you\u2019re happy for ML jobs to run on by configuring the and settings to on these nodes. Then, when you the cluster runs the job\u2019s associated analytics process on one of those nodes, and the job will continue to run there until it\u2019s closed or the node is stopped. Prior to version 6.1 this node allocation was done in a very simple way: a newly opened job was always allocated to the node running the fewest jobs subject to a couple of : Different ML job configurations and data characteristics can require different resources. For example, a single metric job generally uses very little resource, whilst a multi-metric job analysing 10,000 metrics will require more memory and CPU. But no account was taken of the expected or actual resource usage of each job when allocating jobs to nodes, which could lead to: To mitigate these problems, starting in version 6.1 ML will allocate jobs based on estimated resource usage. Each ML job runs in a separate process, outside of the Elasticsearch JVM. In 6.1 we have added a new , , to control the percentage of memory on a machine running Elasticsearch that may be used by these processes associated with ML jobs. This is a dynamic cluster setting, so the same number will apply to all nodes in the cluster, and it can be changed without restarting nodes. By default the native processes associated with ML jobs are allowed to use 30% of memory on the machine. ML will never allocate a job to a node where it would cause any of these constraints to be violated: For nodes where none of the hard constraints would be violated, we will continue to allocate jobs to the least loaded ML nodes. However, instead of number of jobs being the definition of load it is now estimated job memory. Job memory is estimated in one of two ways: The first method is preferred, but cannot be used very early in the lifecycle of a job. The estimate of job memory use is based on actual model size when the following conditions are met: Once jobs are \u201cestablished\u201d according to these criteria, we should be able to make pretty good decisions about whether opening a new job is viable. However, if many jobs are created and opened around the same time then we will tend to be restricted by the configured in the . Before version 6.1 our default was 4GB, and this was excessive in many cases. Therefore, in version 6.1 we have cut the default to 1GB. If you are creating advanced jobs that you expect to have high memory requirements we\u2019d encourage you to explicitly set this limit to a higher value when creating the job. And there should be less scope to hog resources if you accidentally create a job that would use a lot of memory if it were allowed to run unconstrained. Similarly, if you\u2019re creating jobs that you expect to have very low memory requirements, we\u2019d encourage you to set in the to a much lower value than the default. We\u2019ve done this in the job creation wizards in Kibana: single metric jobs created using the wizard now have their set to 10MB, and multi-metric job created by the UI wizard have it set to 10MB plus 32KB per distinct value of the split field. Because of the smarter limiting of ML jobs based on memory requirements, in version 6.1 we\u2019ve increased the default value for from 10 to 20. Of course, if you have large jobs or little RAM then the memory limit will kick in and you won\u2019t be able to open 20 jobs per node. But if you have many small jobs then you\u2019ll no longer be artificially restricted. If you\u2019ve previously customized the value of then you may wish to revisit your setting taking account of the new functionality. During rolling upgrades to version 6.1 ML jobs might be running in mixed version clusters where some nodes are running version 6.1 and others pre-6.1. In such clusters some nodes will know enough to apply the new allocation logic and some won\u2019t. Additionally, it is theoretically possible for the node stats API to fail to determine the amount of RAM a machine has. Rather than try to do anything clever in these scenarios, the following simple rule will apply: if any ML node in the cluster is unable to participate properly in the memory-based node allocation process then the pre-6.1 count based allocation will be applied to all ML node allocation decisions. For people running clusters on supported operating systems where all nodes have been upgraded to version 6.1 this should not be a problem. . \n"}
{"index": {"_id": 13}}
{"title":"Kibana 6.1.1 released","seo_title":"","url":"\/blog\/kibana-6-1-1-released","author":{"name":"Court Ewing"},"date":"December 19, 2017","category":"Releases","locales":"","content":" Today, we released Kibana 6.1.1 with a fix for a high severity security vulnerability in the Time Series Visual Builder. All administrators of Kibana 6.1.0 are urged to upgrade Kibana immediately. Versions prior to 6.1.0 are not affected. If you had any Kibana 6.1.0 instances on , we\u2019ve automatically upgraded them, so no further action is required. For folks that cannot upgrade from 6.1.0 at this time, you can disable time series visual builder entirely by specifying in kibana.yml and restarting Kibana. Note, this will require a full \u201coptimize\u201d run, which can take a few minutes. Math aggregations and remote code execution In Kibana 6.1.0, we released a new feature for \u201cmath aggregations\u201d in the Time Series Visual Builder which allowed users to apply mathematical operations to their TSVB results. Unfortunately, this new feature has a vulnerability that could allow an attacker to execute arbitrary code on the Kibana server. We\u2019ve in 6.1.1. Removing a feature is never something we take lightly, especially in a patch release, but the issue is severe and there isn\u2019t a reliable way to permanently fix it. We do want to have this sort of math capability in Kibana at some point, but we need to take a more holistic view on its security before releasing it again. There are a couple of other bug fixes in this release as well, so check out the for all the details. If you\u2019re not using , head on over to our page to get the release now. \n"}
{"index": {"_id": 14}}
{"title":"Logstash Lines: Update for December 19, 2017","seo_title":"","url":"\/blog\/logstash-lines-2017-12-19","author":{"name":"Andrew Cholakian"},"date":"December 19, 2017","category":"The Logstash Lines","locales":"","content":" Hello Logstashers! We're glad to present you all the past couple week's news in convenient digest form! This past week has been mostly about fixes. We have some big picture things we're working on, but nothing in enough shape to share yet. \n"}
{"index": {"_id": 15}}
{"title":"Default Password Removal in Elasticsearch and X-Pack 6.0","seo_title":"Default Password Removal in X-Pack 6.0","url":"\/blog\/default-password-removal-elasticsearch-and-x-pack-6-0","author":{"name":"Jay Modi"},"date":"December 18, 2017","category":"Engineering","locales":"","content":" The Elasticsearch team takes pride in making software that is easy to get started with, which allows developers to make progress on their projects at a faster pace. The team wanted the same experience for X-Pack security features and out of this desire, the addition of built-in user accounts was born. X-Pack ships with a built in administrator account and accounts for Kibana and Logstash system users. In 5.x, these accounts have a default password of \u2018changeme', which\u00a0was chosen with the hopes that users would heed the advice embedded in the password and, well, change the password. Hope is not good enough when it comes to securing applications: relying on hope means we assume our users know about these accounts and the default password and also know why these need to be changed. As a company, relying on hope is like rolling the dice for becoming the next major piece of software featured in the news cycle as the culprit responsible for a bad data leak. In order to provide better security, we made\u00a0for 6.0 that removed the default password altogether. The removal of the default password has the effect of adding a single step to the getting started process for Elasticsearch and we felt that this tradeoff was the right one to make when it came to shipping software that is secure. Getting this process down to a single step was not easy: there were a lot of ideas and a lot of back-and-forth discussions on how we accomplish this. The solution makes use of an auto-generated seed value on each node. This seed value serves as the initial password for the elastic user. The seed value alone could have been a fine solution but it has its own issues: the most important being that we have a different password for the elastic user on each node. In terms of usability, the seed value as the elastic password would complicate the getting started experience as it would require additional manual steps to configure passwords for other users such as the `kibana` user. More work was needed to make getting started a nice experience. Moving beyond the seed value, a new tool, \u2018\u2019, has been added to make the initial password setting as easy as possible. The tool has both an interactive mode where the user can provide their own passwords and an automated mode that sets the passwords to a random value, which is then sent to standard out. Let\u2019s take a look at how easy it is to get started with X-Pack: \n"}
{"index": {"_id": 16}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2017-12-18","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2017-12-18","author":{"name":"Clinton Gormley"},"date":"December 18, 2017","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. automatically optimises away the need to track versions of in-memory buffered documents while indexing if all documents in the ram buffer are guaranteed to have no duplicates and are documents using auto-generated IDs. This reduces the GC overhead drastically in high-throughput scenarios (up to 50%) and offers a depending on the workload. This change will come in 6.2. Elasticsearch 6.2.0 will be the first release of Elasticsearch to officially support JDK 9. Elasticsearch 6.2.0 will run out-of-the-box on both JDK 8 and JDK 9. We as of the JDK, but Elasticsearch will move forward with the JDK ecosystem. When , releases of Elasticsearch will stop supporting JDK 9: we intend to support JDK 10 but there is no guarantee of that at this time. Support for JDK 8 will continue until end-of-life in of the JDK. A new () has been added to master and is planned to be backported to 6.2. The ranking evaluation API can be used to evaluate the quality of ranked search results over a set of typical search queries. Users can supply a set of typical queries together with a list or manually rated documents, and the API will perform the queries and calculate common information retrieval metrics like mean reciprocal rank, precision or discounted cumulative gain on it. The API is currently marked as experimental and will probably change a bit in the foreseeable future. More details about the current state can be found in the . Ranking via the API is a very manual process at the moment, so we only expect to see traction around this feature once we have a UI to make interaction much more point-and-click. Brainstorming in progress with the Kibana team. Changes in 5.6: Changes in 6.0: Changes in 6.1: Changes in 6.2: Changes in 7.0: Apache Lucene There is an ongoing to release Lucene 7.2.0, which is going well so far. and . \n"}
{"index": {"_id": 17}}
{"title":"Keeping up with Kibana: This week in Kibana for December 18, 2017","seo_title":"","url":"\/blog\/keeping-up-with-kibana-2017-12-18","author":{"name":"Jim Goodwin"},"date":"December 18, 2017","category":"Kurrently in Kibana","locales":"","content":" Welcome to\u00a0This is a weekly series of posts on new developments\u00a0in the Kibana project and any related learning resources and events. 6.1 has a new homepage with even more dashboard customization options and input controls. \u2014 elastic (@elastic) Hi all, The big event last week was shipping the 6.1 release of Kibana, you can see a link to the blog post in the tweet above.Work on integrating into Kibana continues and it hopefully will be available for use in the 6.2 release. One of the important parts of EUI is its\u00a0documentation, including a new set of guidelines for writing content for Kibana. You can see some of the work in progress here: I'd also like to point out some recent Webinars featuring members of the Kibana team:With some significant changes to the visualize API, using existing Kibana visualizations in your own plugins has become much easier. Join Alex Francoeur, Thomas Neirynck, and Peter Pisljar for a live demonstration to learn how to develop visualizations in Kibana. Version 6.0 introduces many new features and improvements across all components of the Elastic Stack. In this webinar, Archana Sriram, Mike Baamonde, and George Kobar will walk you through the considerations, best practices, and caveats for upgrading your Elastic Stack to 6.0. That's all for this week. Cheers, Jim \n"}
{"index": {"_id": 18}}
{"title":"Brewing in Beats: Monitor RAID status with Metricbeat","seo_title":"","url":"\/blog\/brewing-in-beats-monitor-raid-status-with-metricbeat","author":{"name":"Monica Sarbu"},"date":"December 14, 2017","category":"Brewing in Beats","locales":"","content":" Did you know that is already available? Try it and let us know what you think. If you are curious to see the Beats\u00a0in action, we just published the . Metricbeat: RAID metricsetAdded upon request from our own Cloud team, this polls and records software RAID specific metrics. The metricset is part of the system module and is planned to be released in 6.2. New community Beat: TracebeatCreated by , this sends traceroute pings and indexes the results into Elasticsearch. Other changesRepository: elastic\/beatsAffecting all BeatsChanges in master: Changes in 6.1: Changes in 6.0: MetricbeatChanges in master: Changes in 6.1: Changes in 6.0: PacketbeatChanges in master: FilebeatChanges in master: WinlogbeatChanges in master: Changes in 6.1: Changes in 6.0: ProcessorsChanges in master: Machine learning jobsChanges in master: TestingChanges in master: Changes in 6.1: Changes in 6.0: InfrastructureChanges in master: Changes in 6.1: Changes in 6.0: PackagingChanges in master: DocumentationChanges in 5.3: Changes in master: Changes in 5.6: Changes in 6.1: Changes in 6.0: Repository: elastic\/gosigarChanges in master: \n"}
{"index": {"_id": 19}}
{"title":"Elastic Advent Calendar 2017, Week 2","seo_title":"","url":"\/blog\/elastic-advent-calendar-2017-week-two","author":{"name":"Michelle Carroll"},"date":"December 14, 2017","category":"","locales":"","content":" Week two of the has been a busy one! If you\u2019re just joining us, this calendar is how we\u2019re celebrating the end of the year \u2014 by sharing a daily Elastic Stack tip in our community . You can catch up on the first week by heading . In this batch, we\u2019ve got posts in Chinese, English, German, Portuguese, Italian, and Japanese, and covered everything from text analysis to migrating data with the reindex API to analyzing your hockey game and cryptocurrencies with the Elastic Stack. You can follow along live by checking out or subscribing to the , or watch for the daily tweeting on . Here\u2019s a sample of what we\u2019ve posted from our second week Dec 8: by Medcl Zeng Dec 9: by Jordan Sissel Dec 10 by Philipp Krenn Dec 11: by Thiago Souza Dec 12: by Atonio Bonuccelli Dec 13: by Aaron Aldrich Dec 14: by Jun Ohtani ! If you\u2019re looking for other great pieces of reading, we recommend checking out our inspiration calendars \u2014 the Elastic Stack calendar on Qiita (fully in Japanese) and SysAdvent (in English). And don\u2019t be afraid to leave some feedback on the posts \u2014 we\u2019d love to hear your thoughts! \n"}
{"index": {"_id": 20}}
{"title":"How to Build a Site Search UI","seo_title":"","url":"\/blog\/how-to-build-a-site-search-ui","author":{"name":"Sam Reid"},"date":"December 14, 2017","category":"Engineering","locales":"","content":" .w3-btn,.w3-button{border:none: display:inline-block: outline:0: padding:12px 20px: vertical-align:middle: overflow:hidden: text-decoration:none: color:inherit: background-color:inherit: text-align:center: cursor:pointer: white-space:nowrap} .w3-btn:hover{box-shadow:0 8px 16px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19)} .w3-btn,.w3-button{-webkit-touch-callout:none: -webkit-user-select:none: -khtml-user-select:none: -moz-user-select:none: -ms-user-select:none: user-select:none} .w3-disabled,.w3-btn:disabled,.w3-button:disabled{cursor:not-allowed: opacity:0.3}.w3-disabled *,:disabled *{pointer-events:none} .w3-btn.w3-disabled:hover,.w3-btn:disabled:hover{box-shadow:none} .w3-black,.w3-hover-black:hover{color:#fff!important: background-color:#00BFB3!important} Note: The original extended post is available on the . Search nirvana: A powerful backend + well-designed UIDepending on the purpose and scale of your website, search can be a critical feature that enables your users to quickly find the information they need. Elasticsearch makes it significantly easier to architect a search engine that delivers relevant results, but building your search backend is only part of the work of implementing a search experience. Without an intuitive search interface, your users may not get the full value of your search engine. What we\u2019ve learned as search providersAt (an Elastic Company), we provide search as a service to completely handle the backend of your search engine, and\u00a0we also help you to build well-designed search UIs. Swiftype is built on the Elastic Stack which has enabled us to support over 10,000 production search engines and serve over 5 billion queries a month. It\u2019s safe to say that we\u2019ve learned a thing or two about search over the years as we\u2019ve helped small and large companies like Lyft, AT&T, Twilio, Asana, and Samsung provide top-notch search experiences. If you\u2019d like to learn more about Swiftype\u2019s architecture and use of the Elastic Stack, . In our experience helping these organizations and many others with search, we\u2019ve been able to see what works well when it comes to search UIs and apply those learnings to both our out-of-the-box search interface\u00a0as well as our jQuery libraries that we support for creating fully custom UIs. While building a great search interface can take some effort, we\u2019ve consistently seen companies reap the rewards of implementing well-designed search UIs which include revenue growth and better user engagement. Implementing your search UISwiftype can help you to get a jump start on building your next search experience, including the UI (or ). In 3 steps, you can have a functioning search UI implemented. \u2014 Index your data into Swiftype \u2014 Tune your search results \u2014 Implement your search bar \n"}
{"index": {"_id": 21}}
{"title":"Machine Learning 6.1.0 Released","seo_title":"","url":"\/blog\/machine-learning-6-1-0-released","author":{"name":"Steve Dodson"},"date":"December 14, 2017","category":"Releases","locales":"","content":" On Demand Forecasting Smarter Node Allocation for ML Jobs Automatic Job Creation for Known Data Types Data Visualizer This tool summarizes the key features in the data, such as cardinality of fields, sparsity and counts of key values. Moving forward we will extend this view to help you create more effective analysis configurations for time series ML jobs: Population Analysis Job Wizard Job GroupsOverall Buckets GET _xpack\/ml\/anomaly_detectors\/job-1,job-2,job-3\/results\/overall_buckets { \"overall_score\": 75, \"start\": \"1403532000000\", \"top_n\": 2 } { \"count\": 1, \"overall_buckets\": [ { \"timestamp\" : 1403532000000, \"bucket_span\" : 3600, \"overall_score\" : 75.0, \"jobs\" : [ { \"job_id\" : \"job-1\", \"max_anomaly_score\" : 80.0 }, { \"job_id\" : \"job-2\", \"max_anomaly_score\" : 70.0 }, { \"job_id\" : \"job-3\", \"max_anomaly_score\" : 14.0 } ], \"is_interim\" : false, \"result_type\" : \"overall_bucket\" } ] } \n"}
{"index": {"_id": 22}}
{"title":"You know, for visualizing your Logstash pipelines","seo_title":"","url":"\/blog\/logstash-pipeline-viewer-6-0","author":{"name":"Andrew Cholakian"},"date":"December 13, 2017","category":"Engineering","locales":"","content":" Logstash\u2019s strength is its flexibility. With its minimalist syntax and rich set of plugins, users have been able to conjure up all kinds of Logstash pipelines \u2014 from to . As you create increasingly sophisticated pipelines, you may have discovered that understanding these pipelines becomes harder. You might want to see the overall shape of your pipeline, understand where branches in data flow might be, and how the various parts of your pipeline perform under actual production conditions. To help you answer some of these questions, we have introduced the Logstash Pipeline Viewer UI. Concepts and Terminology Before we talk some more about the Pipeline Viewer, it\u2019s necessary to understand some associated concepts and terminology first. Every Logstash pipeline has an . If you define your pipelines using the or command-line options, your pipelines will have their ID set to \u201cmain\u201d. If you define your pipelines or , you will be able to set your own pipeline IDs to something more descriptive like, say, \u201cApache Access Logs Processing\u201d. For every (uniquely ID\u2019d) pipeline, there can be multiple of that pipeline. What differentiates one version of a pipeline from another version of that pipeline are its contents. For instance, say you created a pipeline with ID = \u201cp1\u201d containing one input, one filter, and one output plugin. At this point, only one version of \u201cp1\u201d exists. At some point in the future, say you modified \u201cp1\u201d so it contained the same plugins as before but also included an additional filter plugin. Now \u201cp1\u201d would have two versions in existence - the original one and the changed one. Since the version of a pipeline is based on its contents, Logstash will automatically calculate a version for you. It will look something like this: . This version currently only shows up in the Monitoring UI in Kibana (where the Pipeline Viewer feature lives), and even there it often shows up in a shortened form for ease of readability. The Tour Great! Now that you understand pipeline IDs and versions, let\u2019s dive into the Pipeline Viewer UI itself. We assume that you have one or more Logstash pipelines currently running and to Elasticsearch. Navigate to the Monitoring tab in Kibana and scroll down to the Logstash section. You might notice that there is a new item in this section called \u201cPipelines\u201d. Clicking here shows you all pipelines across your Logstash deployment that have been running during the time window set by the Kibana Time Picker (top right of screen). For each pipeline the list of its versions that existed during the Kibana Time Picker time window are shown. Clicking on a pipeline\u2019s version takes you to the Pipeline Viewer, the centerpiece of this blog post. It shows a rendering of that specific version of the pipeline. The pipeline is visualized as a directed acyclic graph, with vertices and edges. Vertices in the graph can represent one of three elements in a Logstash pipeline: plugins, if conditions, or the queue in Logstash that exists between the input and filter stages of a pipeline. Edges represent paths that events can take as they travel through the pipeline. Plugin vertices show the ID of the plugin (if one is specified by the pipeline creator via the property), the plugin\u2019s throughput (in events per second), and the latency (in milliseconds) introduced by the plugin as it processes events passing through it. If condition vertices show the condition being tested. They have two types of edges emanating from them: \u201ctrue\u201d or \u201cT\u201d edges, representing the path an event would take if the condition is met, and \u201cfalse\u201d or \u201cF\u201d edges, representing the path an event would take if the condition is not met. Today we do not show metrics for if condition vertices or the queue vertex but this is something we plan to add in the future. Applications Now that you know your way around the Pipeline Viewer, here are some of its practical applications. As mentioned at the start of this blog post, you can use the Pipeline Viewer to get a bird\u2019s eye view of your pipelines. This is especially helpful for more sophisticated pipelines. From this view you can also zoom in closer and inspect specific plugins. This will help you identify performance bottlenecks so you can work towards alleviating them. Finally, as the Pipeline Viewer visualizes a specific version of a pipeline at a given time, you can make changes to the pipeline and compare the effects of these changes with the version prior. Limitations and Future Plans The Pipeline Viewer uses a force-directed graph layout algorithm to optimally lay out the vertices and edges representing the pipeline. For clarity, the algorithm tries to prevent overlap of vertices and minimize overlap of edges. It tries to solve for these constraints in a reasonable amount of time, a few seconds. Turns out that such an algorithmic layout problem is a tough one to solve! So the algorithm comes up with a \u201cbest effort\u201d solution. What this means for you, the user, is that depending on the complexity of your pipeline, you may see layouts ranging from obvious to downright messy. We are continually tweaking this algorithm and even considering alternatives to make layouts more readable and therefore useful for users in the future. In addition to better layouts, you can also expect to see metrics for the queue and if conditions in the future. We also plan to add a detail panel for each vertex. This panel will let you see the vertex\u2019s complete configuration as well as charts visualizing the vertex\u2019s performance metrics over time. We hope you are as excited about the Pipeline Viewer as we are. Please play with it (requires an X-Pack Basic license, which is free) and so we can continue to make the right improvements to it. And watch this space for an \u201cunder the covers\u201d look at the Pipeline Viewer UI, in which we\u2019ll talk about the engineering aspects of how it\u2019s built, the challenges we faced building it, and some of the options we\u2019ve explored over the course of its evolution. \n"}
{"index": {"_id": 23}}
{"title":"Elasticsearch 6.1.0 released","seo_title":"Elasticsearch 6.1.0 released","url":"\/blog\/elasticsearch-6-1-0-released","author":{"name":"Clinton Gormley"},"date":"December 13, 2017","category":"Releases","locales":"","content":" Today we are pleased to announce the release of , based on . This is the latest stable release, and is already available for deployment on , our Elasticsearch-as-a-service platform. Latest stable release in 6.x: You can read about all the changes in the release notes linked above, but there are a few changes which are worth highlighting: \n"}
{"index": {"_id": 24}}
{"title":"Logstash 6.1.0 Released","seo_title":"","url":"\/blog\/logstash-6-1-0-released","author":{"name":"Andrew Cholakian"},"date":"December 13, 2017","category":"Releases","locales":"","content":" Logstash 6.1.0 has launched! We've got some great new features to talk about! Read about it here, or just head straight over\u00a0to our \u00a0and give it a shot! However, you may want to take a minute to read about \u00a0and \u00a0first. Read on for what's new in Logstash 6.1.0. We\u2019re proud to announce a great new way to extend Logstash functionality in 6.1.0. Complex modification of events in Logstash is now much easier due to our new feature, file based Ruby scripting via the Logstash Ruby filter. While the Ruby filter already lets you use custom ruby code to modify events, that code must live inside the Logstash configuration file itself, which doesn\u2019t work well for longer pieces of code, and is hard to debug. Additionally, there\u2019s never been a good way to reuse or test that code. File based Ruby scripts can take arguments, letting you reuse code within your Logstash configs easily. This new feature lets you write Ruby code in an external file, with tests inline in that same file, and reuse that anywhere you\u2019d like. Another nice feature here is that we can generate accurate line numbers in stack traces for exceptions in file based Ruby scripts, making them much easier to debug. The full details for configuring this are available in the . For a short example see below: To configure the ruby filter with a file use: filter { ruby { # Cancel 90% of events path => \"\/etc\/logstash\/drop_percentage.rb\" script_params => { \"percentage\" => 0.9 } } } The file 'drop_percentage.rb' would look like: def register(params) @should_reject = params[\"reject\"] end def filter(event) return [] if event.get(\"message\") == @should_reject event.set(\"field_test\", rand(10)) extra_processing(event) [event] end def extra_processing(event) # .. end test \"non rejected events\" do parameters do { \"reject\" => \"hello\" } end in_event { { \"message\" => \"not hello\" } } expect(\"events to flow through\") do |events| events.size == 1 end expect(\"events to mutate\") do |events| events.first.get(\"field_test\").kind_of?(Numeric) end endLogstash 6.1.0 brings some exciting new changes to the Logstash internals. We\u2019ve been working on a full rewrite of the internal execution engine in Logstash. This rewrite moves the core execution logic from JRuby to Java\/JVM Bytecode. With this approach we\u2019ll be able to pave the way to more performance improvements in the future, as well as the ability to write optimized Logstash plugins in any JVM language.This feature is currently disabled by default, and users should note that it is experimental and not yet ready for production. To enable this feature, you\u2019ll need to use the '--experimental-java-execution'\u00a0flag. We encourage users to try this flag out in test and staging environments and report any bugs found. Our hope is to make this the default execution method sometime in the 6.x timeframe. \n"}
{"index": {"_id": 25}}
{"title":"Beats 6.1.0 released","seo_title":"","url":"\/blog\/beats-6-1-0-released","author":{"name":"Monica Sarbu"},"date":"December 13, 2017","category":"Releases","locales":"","content":" We\u2019re pleased to announce the Beats 6.1.0 release. This is the latest stable version and it comes with lots of new modules and an exciting Autodiscovery feature. Docker AutodiscoveryBeats 6.1 brings in the first phase of autodiscovery support. Autodiscovery allows the user to configure providers, that watch for system changes and emit events to a common bus. Based on these events, the Autodiscovery system detects situations when there is something new that we can monitor and instantiates new Beats modules for it. In general, Autodiscovery allows the Beats to react and adapt to changes in the ever more dynamic infrastructures. The first provider watches for Docker events. It supports config mapping from container metadata to config templates, so new modules are created when a container starts. metricbeat.autodiscover: providers: - type: docker templates: - condition: equals.docker.container.image: redis config: - module: redis metricsets: [\"info\", \"keyspace\"] hosts: \"${data.host}:${data.port}\" The above is an example configuration that instantiates the Metricbeat Redis module every time a new redis container (defined by having the redis image) is started. Note that the connection information (host\/ports) is filled in by the autodiscovery support via a template. Future releases will add more Autodiscovery providers, for example for Kubernetes events and package managers. New Metricbeat and Filebeat modulesEach Beats release adds a few new Metricbeat and Filebeat modules, but 6.1 really sets the bar higher. Many of these modules are contributed by our users (Thank You!). Let\u2019s go through the list: TLS support in PacketbeatPacketbeat 6.1 adds , which is one of the most anticipated Packetbeat features. It doesn\u2019t mean decrypting traffic, but it parses the initial handshake and extracts data like ciphers supported by the client and the server, the client and server certificate chains, the subject alternative name (SAN), validity dates, raw certificates, and so on. This data is super valuable for debugging TLS issues and also for intrusion detection and auditing. The implementation also comes with support for the extension to TLS, which allows Packetbeat to detect, for example, whether HTTP\/2 or HTTP\/1 are used as an application protocol on top of the TLS connection. Docker JSON-file prospector in FilebeatFilebeat 6.1 comes with an (experimental) Docker prospector that implements the default . Filebeat could already read Docker logs via the log prospector with JSON decoding enabled, but this new prospector makes things easier for the user. It abstracts the format, so there is no need to manually configure JSON decoding. Here is an example config, which captures the logs from a single container specified by its ID: prospectors: - type: docker containers.ids: - c3ec7a0bd9640151a768663b7e78c115d5b1a7f87fba572666bacd8065893d41 It also parses the timestamp from the JSON file, something that wasn\u2019t previously possible with Filebeat alone (it required Logstash or Ingest Node). This new prospector works great with the Docker Autodiscovery provider. New Auditbeat dashboards Auditbeat 6.1 comes with several in the default configuration file, which makes it easier to get started with. To match the use cases, we also have three new dashboards: FeedbackIf you want to make use of the new features added in Beats 6.1.0, please , install it, and let us know what you think on Twitter () or in our . \n"}
{"index": {"_id": 26}}
{"title":"Kibana 6.1.0 is released","seo_title":"","url":"\/blog\/kibana-6-1-0-released","author":{"name":"Jim Goodwin"},"date":"December 13, 2017","category":"Releases","locales":"","content":" You may be thinking \"But wait, you just released 6.0?\"... I know, right! But 6.1.0 has been percolating for months and now it is here. New in this release we have: \u00a0 You can now create input control visualization components which when placed on a Dashboard allow users to select particular values from a terms aggregation from a multi-select drop down control or select a range from a min\/max aggregation using a range slider control. This will make it easy to guide users to important filtering values for the dashboard and make it simple for them to apply filters and explore the information on the dashboard.Kibana has a homepage! Finally clicking on the Kibana logo in the upper left will do something useful! And finally new users will get some great pointers as to what to do with Kibana when they launch it for the first time! Please watch this space, there is a lot more coming...Beginning with X-Pack monitoring 6.1, the Monitoring UI will automatically use to load data from remote clusters defined using the Elasticsearch connection's remote cluster list . That means if you only define elasticsearch.url in your kibana.yml, and configure your dedicated monitoring clusters as remote clusters of it, then the Monitoring UI will detect and show all clusters! We also took the time to optimize the experience so that it routes requests to specific monitoring clusters whenever possible. This provides multiple advantages over the existing behavior:Using Cross Cluster Search is now the preferred way to talk to a dedicated monitoring cluster because of these benefits and simplifications. We hope that it helps you to both improve your Elastic Stack monitoring and simplify it at the same time.Newly introduced visualizations can now be part of labs-mode. Visualizations in labs-mode introduce new more cutting-edge functionality and can be subject to change across minor releases. Labs-mode can be turned off in the advanced settings. Labs-visualization will then no longer be available to the user. The Time Series Visual Builder is not part of labs-mode, it continues to be an experimental feature. The input controls are the first to be flagged as a lab visualization.Pie charts now support data labels making it easy to understand the values being presented without having to look back and forth to a legend.We have improved the use of Region Maps for deployment in environments without internet access. Similar to the Coordinate Map visualization, the Region map can now use a WMS-service as a base-layer. Admins can now also setup Kibana to opt-out of connection to the Elastic Maps Service. Users can now opt-out of having the visualization display warnings.Reporting now has the ability to render Dashboards in a WYSIWYG manner to PDF preserving the locations and sizes of panels on the dashboard.There are now additional options for customizing the content on Dashboards.\u00a0We've added\u00a0a new option to \"use margins\" to add separation between Dashboard panels. We've also added the capability to customize the panel titles or hide them altogether.\u00a0The Management application now supports managing the license for your cluster including seeing your current license level and expiration information, links out to obtain a Basic or a paid license\u00a0and support for uploading and installing a new license. We've also made sure that you'll be able to log into Kibana to use this tool\u00a0even if your license has expired.Some settings are sensitive, and relying on filesystem permissions to protect their values is not sufficient. For this use case, Kibana provides a keystore, and the kibana-keystore tool to manage the settings in the keystore.\u00a0[More information here:\u00a0] Please , try it out, and let us know what you think on Twitter () or in our . You can report any problems on the . \n"}
{"index": {"_id": 27}}
{"title":"Elastic Stack 6.1.0 Released","seo_title":"","url":"\/blog\/elastic-stack-6-1-0-released","author":{"name":"Tyler Hannan"},"date":"December 13, 2017","category":"Releases","locales":"ja-jp","content":" 6.1.0 is here. Fresh on the heels of the 6.0.0 GA release, we are pleased to introduce you to the capabilities of 6.1.0. You should download it now or use it on (your favourite hosted Elasticsearch and Kibana provider. The line between products and features is often a blurry one. And we feel that pain \u2013 or experience that delight \u2013 as keenly as many. When there are so many features to highlight in a release, where do you even start? Either you craft the next great novel or you choose to provide links to details. Happy reading and\u2026more importantly\u2026happy searching, analyzing, and visualizing. Let\u2019s start with some features that are, without question, worth mentioning: APM After announcing that we joined forces with Opbeat, and an alpha (in the 6.0 timeframe), we are super pleased to share that Elastic APM is now in beta. This includes not only all of the goodness we have described in the past, but also features a brand new UI. It is available in X-Pack Basic (free!) and you can read more information in the . Machine Learning Unsupervised, Automated, Expedited\u2026adjectives abound when describing machine learning solutions. But, as our team has said, Elastic Machine Learning \u2018catches what you might miss, all by itself.\u2019 In 6.1.0 this expanded to include a series of substantive new features including On Demand Forecasting (based on the past, what values would you expect in the future), smarter allocation for efficiently assigning jobs to ML nodes, and automatic job creation for known data types. The fun doesn\u2019t stop there, and all the features are described in the post. Elasticsearch The summary, or aggregation, of features is in the . Kibana Visualize the future of interacting with your data in the because there is MUCH more than can be listed here. Logstash Grok the details in the . Beats If you want all the details, \u2018Go\u2019 read the . Get It Now! \n"}
{"index": {"_id": 28}}
{"title":"Custom Region Maps in Kibana 6.0","seo_title":"","url":"\/blog\/custom-region-maps-in-kibana-6-0","author":{"name":"Mark Walkom"},"date":"December 12, 2017","category":"Engineering","locales":"","content":" Grab Your Cartometers In Kibana 5.5 we added the ability to define your own , which are also also known as choropleth maps. This allows users to define custom geo-boundaries as , then overlay them on the Elastic Map Service to display aggregations for custom geographical areas natively in Kibana. This is a simple yet very powerful method for providing localised insights from your datasets. We've touched on this previously in a , but let's dig into this some more and run through a practical example of how to deploy it step by step in the Elastic Stack! If you'd like to replicate this blog post as you read it, the code for doing so is all . Ready, Set\u2026. Before we start, let's define a few words that we will use throughout this post that you may be unfamiliar with, or have heard elsewhere in different contexts: Sourcing Your Map has a number of high quality maps and for this post we'll be using the Australian State file. If you download the file, extract it and take a look in it, you will find a repetitive structure, with the geoshapes we need and other fields that we will use later. There are a number of other sources out there that build and provide geojson files for you to download and use, your favourite search engine can help locate them for you. Ultimately, if you can't find what you want on the internet then you can build your own geojson files. That's outside the scope of this blog post, but luckily exploratory.io themselves have an excellent blog post on how to do that right ! Configuring Your Source Now that we have our geojson file, we need to let Kibana know how to read it and map the geoshapes it holds onto the tiles that the Elastic Map Service provides. kibana.yml Using the extracted aus_state.geojson from the \"Australia States\" archive, we need to configure some custom settings in your kibana.yml file. Open the yaml file in your favourite editor and add this on the end: # Custom Region Maps regionmap: layers: - name: \"Australian States\" url: \"http:\/\/localhost:8000\/aus_state.geojson\" attribution: \"https:\/\/exploratory.io\/maps\" fields: - name: \"STATE_NAME\" - description: \"State Name\" These settings are explained in of the documentation, but let's break it down here: The fields.name we define above is extremely important. It tells Kibana how to take the documents in Elasticsearch and then figure out which shapes in the geojson file it needs to place that document for the aggregation results to be displayed. We will run through this in detail and step by step, so don't worry if that's a bit confusing for right now. Serving Up The Geojson File The last step we need to do here is to serve the geojson file from a web server, as was defined in url. For this post we kept it simple and used this awesome little tool from npm, , and ran this command via our shell from the same directory that the aus_state.geojson lives in: http-server --cors=Access-Control-Allow-Origin -p 8000 You can test this by opening from your browser, and you should see the contents of the geojson file. There are also dedicated products to serve your geo-data, like that would be better suited for ongoing, production level deployments. We'd definitely recommend investigating them as more permanent solutions. Deploying Your Configuration It's all been pretty text heavy so far, especially for what is ultimately a visualisation. So let's take a look at what this all translates to in the Kibana UI. The Aggregation Settings As with most things in Kibana, we need to build an aggregation to show our data on our custom geoshapes. For this example dataset we will change the default Count Aggregation, under Metrics, to a Max and select the Population field to run the agg on. Then we Bucket the data using a Terms Aggregation on the Name field. Here's what we mean: Note - these are shown side-by-side to save room on this\u00a0page. In Kibana they are displayed as a single vertical column on the left of the browser window. The Map Settings Now we have to tell Kibana to use the regionmap settings as we defined in the kibana.yml. Under the Options tab we need to change the default Vector map to point to the one we configured, this is where the name field from above is used, so select Australian States. After that we select the Join field, which you have probably already guessed, will show the fields.description value of State Name. Then we hit the Apply changes button and\u2026. The Outcome Let's break and explain something we briefly touched on earlier, remember when we talked about the inner-join? Well, at this point Kibana has: However! Most importantly to all this is what happens between steps 2 and 3, where we run this inner join we keep referring to. Let's break that down as it's super important to understand if you want to start building these maps for your own datasets. Joint Pain In our aus_state.geojson file we have a number of geoshapes that represent the boundaries of the Australian States (and Territories). Each of those has a STATE_NAME field with, funnily enough, the name of the state\/territory in it. For any custom regionmap to display the data correctly, we need a field in each document we've indexed into Elasticsearch to have one of the same values as is in the specified join field from the geojson file. Therefore, if we have these values in the geojson file: grep STATE_NAME aus_state.geojson \"STATE_NAME\": \"New South Wales\", \"STATE_NAME\": \"Victoria\", \"STATE_NAME\": \"Queensland\", \"STATE_NAME\": \"South Australia\", \"STATE_NAME\": \"Western Australia\", \"STATE_NAME\": \"Tasmania\", \"STATE_NAME\": \"Northern Territory\", \"STATE_NAME\": \"Australian Capital Territory\", \"STATE_NAME\": \"Other Territories\", And if we create a document in Elasticsearch like so: PUT aussiestates\/doc\/nsw { \"Name\": \"New South Wales\", \"Population\": 7757800 } We then create a terms aggregation on the `Name` field (i.e. step 2). Kibana takes the value of the `Name` field and look in the geojson file against the field we defined in `fields.name`, which is `STATE_NAME`. Given it finds an exact match, it adds the max value in the `Population` field to the `New South Wales` bucket (i.e. step 3). Then it takes the custom geoshape and transposes it onto the tilemap service with the results of the aggregation. Then it repeats this over and over until all the documents have been processed and we have the final results being displayed (step 4). And what does that all translate to? Glorious, sunburnt Australia! Some places more than others\u00a0: ) Troubleshooting space-not-tabs.yml One general point we will start with is that the configuration file for Kibana is yaml formatted. That means that spaces are super important for nested definitions like the one we use here. If you run into problems then it's always good to check your indentation is correct and uses spaces and not tabs. There's Nothing On My Map! If you've still gotten this far but your maps are still blank, remember that the values in the geojson file and the Elasticsearch document need to be the same. Not just similar, exactly the same. If you aren't already adjusting your mappings, make sure you do and set the field that contains the value to a to ensure it doesn't get split and\/or lower-cased like a field would. Ultimately you need make sure your processing pipeline normalises the field values to the geojson file values. From 6.1 there will be\u00a0improvements on how we handle failed joins. We will allow users to turn off warnings for failed joins, so when some terms aren't present in the geojson source, the dashboard won't be overloaded with error warnings. CORS Mate! CORS stands for Cross-Origin Resource Sharing and is an important feature of the browser's security model. CORS configurations define how a browser decides what content any given web-application has access to, based on the domain (or origin) of where that web application is hosted. The default behavior is simple: Browsers do NOT allow Javascript to load or post any content cross-origin. If this were so the browser would make data-theft very easy! \u00a0After all, as administrators, we generally do not want a web-application to retrieve (possibly malicious) code or post (possibly private) content from or to another domain we do not control. Our users certainly would not want this! For example, javascript-code from the Kibana application hosted on the cannot execute a request to fetch files hosted on , as they are on two different domains. To work around this, servers can advertise which other domains they \"trust\". This is a server's CORS configuration. As an example, the admins of accounting.example.org can configure the CORS-headers of their server so it will accept requests from the engineer.example.org domain. The browser's behavior would then look something like this: When users visit Kibana running on the on engineering.example.org domain, the browser will first sent a preliminary 'test'-request to accounting.example.org. When the server on accounting.example.org responds that it accepts requests from websites hosted on the engineering.example.org domain, the browser will then send the \"real\" request for the data to accounting.example.org. So why did we decide to require users to setup CORS? After all, why can't the Kibana server serve the geojson file so we can avoid this whole CORS business? The reason for this is that geodata comes from many different sources, and a lot of organisations already have an established stack for geo-data deployed, products like Geoserver or ArcGIS server. It is very common that these dedicated services would be running on a different domain from where Kibana will be hosted. And That's It! One last thing that we will note is that the Region map provides a zoom level of 10 by default. To increase the zoom levels, install X-Pack alongside Kibana and Elasticsearch and then register for for all 18 levels! We hope this has been useful and given you some great ideas on how to use custom maps with \u00a0the flexibility built natively into the Elastic Stack. Imagine extending this to show voting levels based on your state\/district\/electoral areas, or grades for schools based on their coverage area, or even showing It's now even easier if you have the data. Feel free to head on over to if you have any further questions, or if you just want to share your awesome custom Region map successes, and thanks for reading. \n"}
{"index": {"_id": 29}}
{"title":"Elastic APM enters Beta with new UI","seo_title":"","url":"\/blog\/elastic-apm-beta-released","author":{"name":"Rasmus Makwarth"},"date":"December 12, 2017","category":"Releases","locales":"","content":" We're excited to share that Elastic APM is now in beta! In 6.0, we released the alpha, which included the open source APM Server and agents. With this release, we're now also providing you with a dedicated Kibana UI to easily visualize and debug performance bottlenecks and errors in your code. We want to help developers spend less time in the develop-test-deploy loop, and be able to ship code changes with confidence. To accomplish that, we've designed an UI that is designed specifically for the developers that wrote the code. The UI is available for free via X-Pack with a Basic license, and you get it out of the box with the 6.1 release. Here's a preview of the UI in action: Zero UI configuration Once you install the Elastic APM agent library in your application, the application will automatically appear in the UI. Installing agents is as easy as installing the Elastic APM agent for your programming language and copy\/pasting a few lines of configuration. The agent will automatically instrument your application and send performance data through to the APM Server. The APM Server will process and index the data into Elasticsearch. Visualize application bottlenecks APM monitors transactions and errors in your application. A transaction can be a request to your server or a batch job or a custom transaction type. Out of the box, you'll get response times, requests per minute, status codes per endpoint, plus the ability to dive into a specific request sample and get a complete waterfall view of what your application is spending its time on - like database queries, cache calls, external requests, etc. This lets you easily compare and debug fast responses to slow responses. For each incoming request and each application error you also get access to contextual information, like request header, user information, system values or custom data that you can manually attach to the request. Having access to application-level insights with just a few clicks will drastically decrease spent on debugging 500s, slow response times and crashes. Correlate APM with other data sources using dashboards If you're already using the Elastic Stack for logging and server-level metrics, you can easily import the prepacked APM dashboards that comes with the APM Server. This will enable you to easily grab APM specific visualizations and use those to correlate APM data with other data sources. To get the dashboards, run the following command in the APM Server 6.1 directory Get started today The UI is now available as part of Kibana and activated via X-Pack with a Basic license. It's free - and you can . If you have questions or feedback, please drop us a note in the . \n"}
{"index": {"_id": 30}}
{"title":"Logstash Lines: Update for December 12, 2017","seo_title":"","url":"\/blog\/logstash-lines-2017-12-07","author":{"name":"Andrew Cholakian"},"date":"December 12, 2017","category":"The Logstash Lines","locales":"","content":" Hello Logstashers! We're glad to present you all the past couple week's news in convenient digest form!We've now for resetting logging settings changed via the Logstash web API back to their defaults.\u00a0We've added some much improvements fixes for Logstash's log4j logging. We will cap log files at 100MB per file, and gzip files as they're rolled over automatically. We're targeting 6.2 with this change.\u00a0The Logstash HTTP input previously exhibited poor behavior when the queue was blocked. If a client connected and timed out, LS would not release the connection, but rather, block indefinitely, causing the client to potentially time out. The HTTP protocol doesn\u2019t deal well with long running requests. This plugin will now either return a 429 (busy) error when Logstash is backlogged, or it will time out the request.If a 429 error is encountered clients should sleep, backing off exponentially with some random jitter, then retry their request.This plugin will block if the Logstash queue is blocked and there are available HTTP input threads. This will cause most HTTP clients to time out. Sent events will still be processed in this case. This behavior is not optimal and will be changed in a future release. In the future, this plugin will always return a 429 if the queue is busy, and will not time out in the event of a busy queue.While doing this work, we discovered that the HTTP input had some synchronization bottlenecks which were unnecessary. Users might see a nice perf boost on multicore systems.One of the big changes in 6.0 is our work on a new execution backend as well as a new IR for our compiler. We've seen a number of small discrepancies pop up in the 6.x series that we've been ironing out with both the new IR (used by all users) and the new execution engine (will be optional with 6.1). We've done this work in a . \n"}
{"index": {"_id": 31}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2017-12-11","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2017-12-11","author":{"name":"Clinton Gormley"},"date":"December 11, 2017","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. A new dynamic cluster setting in 7.0 tracks the number of buckets created in an aggregation and fails the request if this number reaches the limit. The default for 7.0 is set to 10000, this means that any request that tries to return more than this number will fail. The number of buckets is checked in the coordinating node and also in each shard when we build the response. This setting should help to reject bad requests that were not caught by the circuit breaker but could push memory use over the limit. This setting will also be present in 6.2 but it will be disabled by default. Requests in this version that hit the default limit (10,000) will log a deprecation in order to prepare users for the migration to 7.0. X-Pack security will now filter the mappings fields returned by get index, get mappings, get field mappings and field capabilities APIs. This means that fields that a user cannot access due to field-level security will no longer be returned from these APIs. Since 5.0, it has been possible to remove index or cluster settings by setting them to . This should have worked for wildcard settings too (eg ) but a bug prevented that from working correctly. Finally, unknown settings from 2.x indices\/cluster were moved to the namespace, but it was impossible to delete settings from indices as this was rewritten to . Both of these issues have been . The jvm.options file syntax has changed in 6.2 in order to support a breaking change in command line arguments in Java 9. Each option now needs to be preceded by a . Apache Lucene We are fixing \u00a0before building the first release candidate. We should hopefully have a release in the coming weeks. was merged, allowing for great speedups when only the top matches are needed. This optimization requires scorers to expose a maximum score that they may contribute and currently only works well with BM25, but we are working on to work well with this optimization and . We are also looking into how we could , or maybe even the per-norm per-term maximum term frequencies in order to , which would in-turm make the optimization more efficient. It turns out the same API could be used to , when the term term frequency of the most frequent term is not high enough to produce a competitive score. At index time, documents are first buffered in an in-memory\u00a0. Seeing it as a single buffer is a bit of a simplification though: there is actually a set of index buffers. This helps with concurrency since different threads can write to different index buffers concurrently. When refreshing, each index buffer writes a segment.In order to make multi-tenancy easy, Elasticsearch adds an abstraction layer on top of\u00a0Lucene\u00a0called\u00a0\u00a0which tries to make sure that each shard can use as much memory as possible for these buffers at index-time, because it makes indexing faster, while also ensuring that the total amount of memory that is spent on the index buffers across shards does not exceed . The issue is that when this shared limit is reached, Elasticsearch tells\u00a0Lucene\u00a0to do a refresh, which writes _all_ per-thread buffers to disk. This new feature is a way to tell\u00a0Lucene\u00a0to release some of the memory it spends on indexing, only flushing one of the largest per-thread buffers. This means we will write larger index buffers on average, which should make indexing more efficient. \n"}
{"index": {"_id": 32}}
{"title":"Keeping up with Kibana: This week in Kibana for December 11, 2017","seo_title":"","url":"\/blog\/keeping-up-with-kibana-2017-12-11","author":{"name":"Jim Goodwin"},"date":"December 11, 2017","category":"Kurrently in Kibana","locales":"","content":" Welcome to\u00a0This is a weekly series of posts on new developments\u00a0in the Kibana project and any related learning resources and events. We\u2019re proud to present 6.0 with accessibility improvements, one-click CSV exports, tighter access control with Dashboard Only Mode, and more. Learn more: \u2014 elastic (@elastic) Hi all,\u00a0This blog is going to be a different style going forward, instead of being mostly a change log, I'm going to try to highlight some important topics in Kibana development each week. So, here we go... A while ago we decided to move towards React as our rendering technology and\u00a0away from Angular. We've also been developing a new UI design for Kibana which we refer to as K7 (who knows what the 7 means...) and if you follow along in github.com there has been a frenzy of activity around it. This includes the creation of a set of reusable React components that we call EUI (\u00a0) and a complete redesign of our CSS structure.\u00a0 In order to reach our goals we're going to start using EUI in Kibana and migrating our UIs to it during the 6.x series of releases. We've got a skin that closely mimics the 6.x design using the EUI components. This will allow us to continue feature development and keep back-porting sane. This week we'll be merging EUI into Kibana and upgrading to React 16, and then cleaning up any rendering issues that come up. Our plan is to have things stable quickly.\u00a0 You can read more at \"EUIfying Kibana\"\u00a0. Earlier this year at \u00a0( at 1h28m ) a prototype of a new application in Kibana called Canvas. Canvas is a truly innovative presentation tool that integrates live data and analysis from Elasticsearch into info-graphic-like presentations. This week we have a technology preview of Canvas that you can \u00a0as well as a Canvas blog so that you can follow along with all the updates.That's all for this week.Cheers,Jim \n"}
{"index": {"_id": 33}}
{"title":"Welcome to the Elastic Advent Calendar! Looking back on Week One","seo_title":"","url":"\/blog\/elastic-advent-calendar-2017-week-one","author":{"name":"Aaron Aldrich"},"date":"December 07, 2017","category":"Engineering","locales":"","content":" This year, the Elastic Engineering team wanted to do something special to celebrate the end of the 2017 Calendar year. Drawing heavy inspiration from the (fully in Japanese) and (in English), we\u2019ve decided to join the tech-advent tradition. From the 1st through 25th of December the team is publishing a series of Elastic Stack tips each day at 00:00 UTC. And\u200a\u2014as we are a distributed organization with community members from all corners of the globe\u2014\u200ayou\u2019ll be seeing these threads in a variety of our native languages. Just this week we have contributions in English, Japanese, French, and Korean! If you want to be actively notified of new topics, subscribe to the ! We\u2019ll also be posting weekly summary blog posts (like this one) if you prefer to follow along here, and we encourage you to join in the conversation either way: topics are open for feedback and questions and we\u2019d love to hear from you. Here\u2019s what we\u2019ve posted from our first week It\u2019s a great collection of content packed into some mighty small space, and we\u2019d love to hear your feedback on the posts. Happy reading! \n"}
{"index": {"_id": 34}}
{"title":"Brewing in Beats: Recursive file watching on macOS with Auditbeat","seo_title":"","url":"\/blog\/brewing-in-beats-recursive-file-watching-on-macos-with-auditbeat","author":{"name":"Monica Sarbu"},"date":"December 07, 2017","category":"Brewing in Beats","locales":"","content":" Did you know that is already available? Try it and let us know what you think. If you are curious to see the Beats 6.0 in action, we just published the . This update covers the last two weeks Auditbeat: recursive file watching on macOSAuditbeat now supports . This functionality is based on the \u00a0library. One drawback of FSEvents is that in the case of multiple events on the same file, they have coalesced in a single notification. The PR orders the set of actions in a single event to be meaningful depending if the file existed in the beat database and if it doesn\u2019t exist anymore at the moment of processing the event. Packetbeat: add_kubernetes_metadataAfter Filebeat and Metricbeat, Packetbeat is the next in line to get Kubernetes support. The `add_kubernetes_metada` processor is now with the pods and enhance the events with Kubernetes metadata. This feature was merged into master and is scheduled to be released in 6.2. Packetbeat: Several TLS support enhancementsPacketbeat now includes a for the TLS data. It can also report the , which is defined as the time spent between first packet and completion of the handshake. Finally, it can now calculate for the client TLS sessions. The JA3 fingerprints are efficient for detecting malware or unauthorized applications. These features are merged into master and are scheduled to be released with 6.2. Filebeat: use the local timezone in the system moduleAn issue that we had in Filebeat modules was that the Ingest Node pipelines assume the incoming logs have timestamps in UTC. In 6.1, Elasticsearch is getting the ability to parse timestamp in the timezone specified by . We now , so the local timezone can be correctly used when decoding the timestamp. This feature will be present in 6.1 but disabled by default. Filebeat and Metricbeat modules for Logstash monitoringThe Filebeat module for Logstash was in time for 6.1. The Metricbeat module got a with basic event stats, also in time for 6.1. Other changes:Repository: elastic\/beatsAffecting all BeatsChanges in master: Changes in 6.1: Changes in 6.0: MetricbeatChanges in master: Changes in 5.6: Changes in 6.1: Changes in 6.0: PacketbeatChanges in master: FilebeatChanges in master: HeartbeatChanges in master: ProcessorsChanges in master: TestingChanges in master: Changes in 6.1: Changes in 6.0: InfrastructureChanges in master: Changes in 6.1: PackagingChanges in master: Changes in 6.0: DocumentationChanges in master: Changes in 6.1: Changes in 6.0: Repository: elastic\/gosigarChanges in master: \n"}
{"index": {"_id": 35}}
{"title":"Canvas Technology Preview","seo_title":"","url":"\/blog\/canvas-tech-preview","author":{"name":"Rashid Khan"},"date":"December 06, 2017","category":"Engineering","locales":"","content":" Hey. You there. Want a sneak peek at a product in progress? We showed off an early prototype of Canvas at Elastic{ON} 17 earlier this year and since then we\u2019ve been hacking on translating the concepts from that prototype into something we can share with you. Let\u2019s be clear: This is still early stuff. But we\u2019re having enough fun with it in the lab that we want to share fun with you. Well, probably you anyway.Is this preview for me? Have you ever taken something apart with no intention of putting it back together, just to see how it works? Can you make a half passable drink in the absence of a half passable liquor cabinet? Would you ride your bike down a road just because you\u2019ve never ridden a bike down that road before? Do you do\u00a0things just to prove to yourself that you can? If you answered yes, or no, to any or all, of these questions, then Canvas might be for you. These rough cuts of Canvas are for those with a bit of curiosity, some imagination and a whole lot of crazy. One more question: Do you run everything and anything in production? If so, Canvas isn\u2019t for you. Canvas is marching forward rapidly, so we recommend that you try it out in an environment that won\u2019t anger the masses should a hiccup occur. Ok, what is it? Hold on, we\u2019re getting ahead of ourselves. There\u2019s a section on that later. In short, Canvas is a composable, extendable, creative space for live data.\u00a0 The \u00a0goal of Canvas is to be flexible, and allow you to tweak all bits and pieces required\u00a0to get to the result you desire. Canvas presents you with a blank page to which you can add a selection of elements. These elements can be connected to data and configured with a simple UI. Within the sidebar you can play with palettes, fonts, background, borders and more. When there\u2019s a style you have to have, but there isn\u2019t a button, Canvas gives you the option of using raw CSS. Canvas today can\u2019t do everything (though we\u2019re working on that!) but its capabilities go much deeper than what you see on the surface. Sometimes\u00a0you need to manipulate the style, or even the data, in a way that no graphical interface can easily express. The Canvas interface is intentionally compact because many of the most interesting and powerful features of Canvas are contained within a small window at the bottom of the screen. Hidden behind a button that says is the nerve center of Canvas.\u00a0 The interfaces you touch in Canvas, are in fact manipulating the Canvas expression in this text box. The expression describes everything Canvas needs to do to create your element. When you change something in the sidebar, for example a color palette, Canvas updates that expression in the right place.\u00a0 Not only can Canvas update the expression, but you can too and Canvas will do its best to create an interface to whatever you type. For example if you add or\u00a0change the palette in the expression, the sidebar will update to reflect the expression\u00a0in turn. There isn\u2019t an interface to every function and argument, but we\u2019re steadily adding new ones. Canvas expressions are simple, but like any sufficiently powerful concept, there is a learning curve. At its heart it is a pipe based syntax, and the output of one function flows\u00a0into the next: Here we\u2019re using the function to search for the string \u201cerror\u201d and retrieve the \"@timestamp\" and \"bytes\" fields for the most recent 100 document. Then we\u2019re using the function to assign those fields to dimensions, and finally piping into to put the points on a simple chart. This is, of course, a very simple example, all of these functions have arguments we aren't using. Canvas has dozens of functions and many more capabilities including table transforms, type casting and sub-expressions. The best way to learn right now is to open the code screen and play with the sidebar to see how it manipulates the expression. If you really want to dig deep see the . What doesn\u2019t it do? (aka: What\u2019s coming?) See, I told you there was a section for this. Let\u2019s get this out of the way. Elasticsearch aggregations: It doesn\u2019t do those yet. While we could build a function to perform aggregations it wouldn\u2019t change anything else about how Canvas works, so we figured we\u2019d rather share Canvas with you sooner. Plus, we\u2019re working to ensure that Canvas supports as soon as it\u2019s ready. What it does support is working with, and charting, raw Elasticsearch documents, which is something we haven\u2019t historically done in Kibana. That means you can do scatter style plots of low density data sets.\u00a0 We\u2019re also working to integrate Canvas with X-Pack Reporting so you can email PDFs and print out hard copies of Canvas work pads. We have a proof of concept, we just need to get everything tied in, look for it soon! There\u2019s a million other little features we\u2019re working on, and a few big ones we\u2019re still exploring, so you can expect to see many changes to Canvas in the near future. What a time to be alive.\u00a0 How do I learn more? We\u2019ve put together a series of short videos and articles highlighting how Canvas works. Like Canvas itself these are in an ever changing state of forward progress so we\u2019ve broken them off into a micro-site just for Canvas over at .\u00a0 How do I install it?\u00a0 Pop over to \u00a0for installation instructions. Canvas installs like any other Kibana plugin, but there\u2019s a couple things you should know. Plus that site always has install instruction for the latest and greatest Canvas build. How do I give you feedback? In the lower right hand corner of the application you\u2019ll find a \u201cGive Feedback\u201d button. We\u2019d love to hear about how you\u2019re using Canvas, what you\u2019re making and what you\u2019d like to be able to do. If you don\u2019t need a response and just want to let us know about something, submit feedback there. Otherwise, if you have a question, join us in the\u00a0\u00a0of\u00a0 \n"}
{"index": {"_id": 36}}
{"title":"Developing new Kibana visualizations","seo_title":"Creating new Kibana visualizations and embedding them into your own plugin","url":"\/blog\/developing-new-kibana-visualizations","author":{"name":"Peter Pi\u0161ljar"},"date":"December 06, 2017","category":"Engineering","locales":"","content":" Creating new visualization typesIn 6.0 we made some significant changes to the visualize API and how visualizations are implemented. We also which should provide basic description of the interface. This tutorial should help you get started quickly. Let us discuss some terms firstWe will build a visualization similar to Kibana's built-in Metric visualization, except we will try to keep it simple without any advanced options. When you start with creating new metric visualization in Kibana you are presented with a screen looking something like this: On the left side we have the default editor and on the right side there is the actual visualization. If you look at the side editor you notice it consists of few parts, which are numbered in the image above. Bootstrapping the pluginNew visualizations are just Kibana plugins with the right . We won't go over all the details. Instead, let's start with creating a folder inside Kibana's plugins directory. We will use a super smart name of 'test_vis'. { \"name\": \"test_vis\", \"version\": \"kibana\" } export default function (kibana) { return new kibana.Plugin({ uiExports: { visTypes: [ 'plugins\/test_vis\/test_vis' ] } }): } Visualization definitionThe file referenced in above file will define a new visualization type and register it. As it is there are multiple factories depending on the rendering technology you are using. You could even extend it with your own. But in this tutorial we will use the , which is the one we recommend to use. Base visualization type does not make any assumptions about the rendering technology. Let's look at our example . First we import our styles and option template (we will talk about it later) as well as our visualization controller, which will take care of rendering the visualization. import '.\/test_vis.less': import optionsTemplate from '.\/options_template.html': import { VisController } from '.\/vis_controller': import { CATEGORY } from 'ui\/vis\/vis_category': import { VisFactoryProvider } from 'ui\/vis\/vis_factory': import { VisTypesRegistryProvider } from 'ui\/registry\/vis_types': import { VisSchemasProvider } from 'ui\/vis\/editors\/default\/schemas': function TestVisProvider(Private) { const VisFactory = Private(VisFactoryProvider): const Schemas = Private(VisSchemasProvider): } The method of the accepts the definition object. Take a look at the documentation to get a better idea of what these properties do. The important parts are that we define the name for our visualization, the controller class which will take care of rendering, the default configuration of the visualization itself and the configuration for the editor. return VisFactory.createBaseVisualization({ name: 'test_vis', title: 'Test Vis', icon: 'fa fa-gear', description: 'test vuis', category: CATEGORY.OTHER, visualization: VisController, visConfig: { defaults: { \/\/ add default parameters fontSize: '30' }, }, We will be using the default Kibana editor in this tutorial. This is the side editor you see in many Kibana visualizations. We need to provide the , which should be the angular template for the options tab. We also need to provide definition, which tells which aggregations can be configured. In the below example our schema definition contains a single object of group metrics. The minimum is set to one (so users will have to configure at least one metric), some aggregations are excluded from the list and the default configuration is provided. editorConfig: { optionsTemplate: optionsTemplate, schemas: new Schemas([ { group: 'metrics', name: 'metric', title: 'Metric', min: 1, aggFilter: ['!derivative', '!geo_centroid'], defaults: [ { type: 'count', schema: 'metric' } ] } ]), } }): } At the end we need to register our provider function with the . \/\/ register the provider with the visTypes registry VisTypesRegistryProvider.register(TestVisProvider): Visualization OptionsIn the visualization definition we set the default options for the visualization. In this case, . We could provide more configuration options there and nest them as we like. We also need to provide the UI for changing them. The property on the allows us to provide an angular template to do just that. We could also provide . Our looks something like this. Note how we reference the parameter with the variable.
Font Size - {{ vis.params.fontSize }}pt<\/label> <\/div> But what if we need more control over it ? Instead of providing HTML we could also provide an angular directive: import '.\/options_directive': \u2026 optionsTemplate: '<\/myvis_options_directive>' ... Visualization ControllerThe last missing part is the visualization controller. This is the actual code that will render the visualization to the screen. We need to create a class with and functions. The constructor will get the DOM element to which visualization should be rendered and the object. It should prepare everything it can before the data is available. class VisController { constructor(el, vis) { this.vis = vis: this.el = el: this.container = document.createElement('div'): this.container.className = 'myvis-container-div': this.el.appendChild(this.container): } The function needs to clean up. Here we just remove all the DOM. we should also remove any hanging listeners or pending timers. destroy() { this.el.innerHTML = '': } The render method will receive the data object along with status object. It will be called every time a change happens which requires an update of visualization like changing time range, filters, query, uiState, aggregation, container size or visualization configuration. Here we re-render whole visualization every time, but this is not the most optimal behaviour. Your code could inspect the object to find out what exactly triggered the render call (was it a change in time range for example?) and update accordingly to that. For example a change in container size should probably not require to redraw the whole thing. render(visData, status) { this.container.innerHTML = '': return new Promise(resolve => {. resolve('when done rendering'): }): } }: export { VisController }: Now we need to provide our visualization implementation. First, we\u2019ll extract the data. Note how we can\u2019t rely on to be present, but we should always check if it is and use to correctly format the value in such case. As we didn\u2019t provide a to our visualization it will use the default response handler, which returns data in tabular format. const table = visData.tables[0]: const metrics = []: table.columns.forEach((column, i) => { const value = table.rows[0][i]: metrics.push({ title: column.title, value: value, formattedValue: column.aggConfig ? column.aggConfig.fieldFormatter('text')(value) : value, aggConfig: column.aggConfig }): }): And at last we add the elements to the DOM: metrics.forEach(metric => { const metricDiv = document.createElement('div'): metricDiv.className = 'myvis-metric-div': metricDiv.innerHTML = `${metric.title}:<\/b> ${metric.formattedValue}`: this.container.appendChild(metricDiv): }): Using parametersIn our visualization definition we defined the parameter. We can access it inside the visualization thru : metrics.forEach(metric => { const metricDiv = document.createElement('div'): metricDiv.className = 'myvis-metric-div': metricDiv.innerHTML = `${metric.title}:<\/b> ${metric.formattedValue}`: metricDiv.setAttribute('style', `font-size: ${this.vis.params.fontSize}pt`): this.container.appendChild(metricDiv): }): Adding bucket configurationMany kibana visualizations allow you to define a bucket aggregation to then show you a metric for every bucket. For example, this is especially useful with date histograms where each date could be one bucket. To add bucket support to our aggregation we first need to tell the editor that we support buckets: editorConfig: { optionsTemplate: optionsTemplate, schemas: new Schemas([ { group: 'metrics', name: 'metric', title: 'Metric', min: 1, aggFilter: ['!derivative', '!geo_centroid'], defaults: [ { type: 'count', schema: 'metric' } ] }, { group: 'buckets', name: 'segment', title: 'Bucket Split', min: 0, max: 1, aggFilter: ['!geohash_grid', '!filter'] } ]), } }): } And we need to handle them in our visualization controller's render method: const table = visData.tables[0]: const metrics = []: let bucketAgg: table.columns.forEach((column, i) => { \/\/ we have multiple rows \u2026 first column is a bucket agg if (table.rows.length > 1 && i == 0) { bucketAgg = column.aggConfig: return: } table.rows.forEach(row => { const value = row[i]: metrics.push({ title: bucketAgg ? `${row[0]} ${column.title}` : column.title, value: row[i], formattedValue: column.aggConfig ? column.aggConfig.fieldFormatter('text')(value) : value, bucketValue: bucketAgg ? row[0] : null, aggConfig: column.aggConfig }): }): }): Adding eventsWhat about handling click events? Easy! We can add a click handler to our DOM elements: metrics.forEach(metric => { const metricDiv = document.createElement('div'): metricDiv.className = 'myvis-metric-div': metricDiv.innerHTML = `${metric.title}:<\/b> ${metric.formattedValue}`: metricDiv.setAttribute('style', `font-size: ${this.vis.params.fontSize}pt`): metricDiv.addEventListener('click', () => { if (!bucketAgg) return: const filter = bucketAgg.createFilter(metric.bucketValue): this.vis.API.queryFilter.addFilters(filter): }): this.container.appendChild(metricDiv): }): When the click event fires, we create a filter for the selected value. We then add this filter to the filter-bar using the method. Using kibana visualizations in your pluginIn 6.0 using existing kibana visualizations in your own plugins has become much easier. We also around it. So let\u2019s create a new plugin. There is already a community resource available on , so we are not going in depth on that. Let\u2019s quickly review the steps. file will create a new plugin object and define the for the plugin. In we will define our app. If we want to be able to use existing Kibana visualizations we need to tell Kibana which modules we will use. Also we need to inject some variables from Kibana. Here is the example file for my plugin: export default function (kibana) { return new kibana.Plugin({ uiExports: { app: { title: 'Test Visualize', description: 'This is a sample plugin', main: 'plugins\/test_visualize_app\/test_vis_app', uses: [ 'visTypes', 'visResponseHandlers', 'visRequestHandlers', 'visEditorTypes', 'savedObjectTypes', 'spyModes', 'fieldFormats', ], injectVars: (server) => { return server.plugins.kibana.injectVars(server): } } } }): } Here is a minimal example of : require('ui\/autoload\/all'): require('ui\/routes').enable(): require('ui\/chrome'): import '.\/test_vis_app.less': import '.\/test_vis_app_controller.js': const app = require('ui\/modules').get('apps\/test_app', []): require('ui\/routes').when('\/', { template: require('.\/test_vis_app.html'), reloadOnSearch: false, }): We will come back to the template HTML file, the .less file for the styles and the controller file later. Embedding saved visualizations in your pluginOur first application will be really simple. It will have a select control with all the saved visualizations on top and it will render the selected visualization in the main area.Getting a list of saved visualizationsLet's create the . This will define a simple angular controller holds the main logic of our application. First we need to load the which will help us get the list of saved visualizations as well as embedding those visualizations to our DOM. To load saved visualizations we will use method, which will return a list of all saved visualizations. Each object in the list will contain: import { getVisualizeLoader } from 'ui\/visualize\/loader': const app = require('ui\/modules').get('apps\/kibana_sample_plugin', []): app.controller('TestVisApp', function ($scope) { $scope.visualizationList = null: $scope.selectedVisualization = null: let visualizeLoader = null: getVisualizeLoader().then(loader => { visualizeLoader = loader: loader.getVisualizationList().then(list => { $scope.visualizationList = list: }): }) }): We also need to add a template file to show our dropdown and prepare a placeholder where we will render visualizations. This is the file we referenced in the above. Note how we set to use the controller we just defined.
, , } Using the our prior work, we just need to put it together into our wrapper template and index it into Elasticsearch. Since this watch doesn\u2019t have any conditions, it will just fire and send an email every five minutes with the information.\u00a0 PUT _watcher\/watch\/my_simple_watch { \"trigger\" : { \"schedule\" : { \"interval\" : \"5m\" } }, \"input\" : { \"simple\" : { \"my_field\" : \"red\" } }, \"actions\" : { \"my_action\" : { \"email\" : { \"to\" : \"my_alert_mailbox@mydomain.com\", \"subject\" : \"Hello From Your Elasticsearch Cluster\", \"body\" : \"This is the simple watch. The value of my_field is: {{ ctx.payload.my_field }} \" } } } } In this watch, we will include all of the sections and index a sample document to test the condition we set, mainly looking for documents with the value of \u201cred\u201d in \u201cmy_field\u201d. PUT _watcher\/watch\/my_conditional_watch { \"trigger\" : { \"schedule\" : { \"interval\" : \"5m\" } }, \"input\" : { \"search\" : { \"request\" : { \"search_type\" : \"query_and_fetch\", \"indices\" : [ \"my_monitored_index\" ], \"body\" : { \"query\" : { \"range\" : { \"my_date\" : { \"gte\" : \"now-10m\" } } } } } } }, \"condition\" : { \"compare\" : { \"ctx.payload.hits.hits.0._source.my_field\" : { \"eq\" : \"red\" } } }, \"actions\" : { \"my_action\" : { \"email\" : { \"to\" : \"your_alert_mailbox@yourdomain.com\", \"subject\" : \"Hello From Your Elasticsearch Cluster\", \"body\" : \"This is the conditional watch. The value of my_field is: {{ ctx.payload.hits.hits.0._source.my_field }} \" } } } } To test this watch, we\u2019ll just need to index a simple document into Elasticsearch that has the value we\u2019re looking for but first, let\u2019s define the mapping for our index so that we can set the data type for the my_date field and allow us to do date math on it. PUT \/my_monitored_index { \"mappings\": { \"mytype\": { \"properties\": { \"my_field\" : { \"type\" : \"string\" }, \"my_date\": { \"type\": \"date\", \"format\": \"yyyy-MM-dd HH:mm:ss\" } } } } } Now we index a simple document. Try different tests such as changing the color value in my_field or setting the my_date field to a time outside the 10 minute window that we\u2019ve configured in the watch. PUT \/my_monitored_index\/mytype\/1 { \"my_field\" : \"red\", \"my_date\" : \"2016-09-14 23:00:00\" } You should receive an email alert when the condition is met. In fact, you may already be tired of receiving these alerts and you want to get rid of them. \u00a0 You can do this easily by using the API as in the example below: DELETE _watcher\/watch\/my_simple_watch You can force execution of a watch by using the endpoint: POST _watcher\/watch\/my_simple_watch\/_execute Watcher is a powerful and highly configurable component of the Elastic Stack. These examples are meant to demystify the steps needed to configure a watch. From here, you can use different options to catch a variety of conditions from different sources and send them to multiple targets. For example, you can tell Watcher \u201cHey, I want you to check the log data coming in from my firewall every minute and see if within the last 5 minutes there were over 10 failed login attempts, if there was, send an email to our security group with the users list and notify the security chat room in Slack\u201dFor detailed information about Watcher: For further information about the Watcher REST API: Using the Watcher context: Visualizing Watcher History in Kibana: \n"}
{"index": {"_id": 482}}
{"title":"You get a report! You get a report!","seo_title":"You get a report! You get a report!","url":"\/blog\/you_get_a_report_you_get_a_report","author":{"name":"Pius Fung"},"date":"October 03, 2016","category":"Engineering","locales":"","content":" Everybody gets a report! \n"}
{"index": {"_id": 483}}
{"title":"Elasticsearch as a column store","seo_title":"Elasticsearch as a column store","url":"\/blog\/elasticsearch-as-a-column-store","author":{"name":"Adrien Grand"},"date":"September 29, 2016","category":"Engineering","locales":"","content":" If you have no idea what questions you will want to ask your data when you start ingesting it, columnar storage is probably a good option for you: it helps in two areas that are often close to the heart of users who deal with large amounts of data: You might have noticed the quotes around in the above paragraph. The reason is that however fast a linear scan is, it is still a linear scan and performs in linear time with the amount of queried data. Elasticsearch takes a different approach that consists in indexing all fields by default and only exposing queries that can leverage these indices so that identifying the matching documents does not need to visit all the data. Well, almost only, there is query that might run a linear scan in order to identify matching documents, the . The purpose of this query is to not require you to reindex for once-in-a-while questions that you had not thought you would need to ask your data when you indexed it, such as finding all documents whose value for field X is less than the value of field Y. But other than this one, all queries make use of some form of index in order to quickly identify matching documents. While Elasticsearch does not use a column-oriented view of the data for searching, it still needs one for workloads that work best with columnar data such as sorting and aggregations. In the next sections, we will do a quick survey of the history of columnar data in Lucene and Elasticsearch. First, there was fielddataLucene was originally designed as a search library, allowing users to get the most relevant documents for a particular query. But soon users wanted to do more: they wanted to be able to sort by arbitrary fields, aggregate information about all matching documents, etc. To cover these needs, Lucene added a feature called , which would \"uninvert\" the inverted index in order to build a column-oriented view of the data in memory. The initial release of Elasticsearch back in 2010 used the same mechanism with what it called , which was similar to , but with more flexible caching management. Then doc valuesThe growing use of was embarassing: it required an amount of memory that was linear with the amount of indexed data, and made reopening the index slower since entries had to be reloaded on all new segments, some of which being potentially very large due to merging. So on the one hand you had an efficient inverted index structure that allowed to find matching documents, but most collectors then had to rely on this inefficient memory-intensive data-structure in order to compute interesting things about the data. This is what lead Lucene to introduce in Lucene 4.0, which was released in the end of 2012. Just like , doc values provide a column-oriented view of the data, except that they are computed at index time and stored in the index. Their memory footprint is very low and getting doc values ready to use on a new segment is a matter of opening a file. The fact that doc values are computed at index time also gives more opportunities for compression. The longer it takes to uninvert fielddata, the longer users have to wait before changes to the index becomes visible, which is undesirable. On the other hand doc values are either computed asynchronously at merge or on small datasets at flush time, so it is fine to spend more time doing interesting compression. Here is a non exhaustive list of some compressions techniques that doc values use that fielddata doesn't: Elasticsearch integrationDoc values became available in Elasticsearch in version (February 2014) as an opt-in. However at that time, the performance did not quite match that of fielddata yet: Elasticsearch was hiding doc values behind its existing fielddata API, introducing overhead, and it took Lucene some time before introducing a and a that helped performance significantly. Both these concerns got fixed in , which was the first release to have matching performance of fielddata and doc values. We then enabled doc values by default in Elasticsearch 2.0 and the next major release of Elasticsearch (5.0) will not support fielddata anymore, leaving doc values as the only option for having a columnar representation of the data. Specifics of Elasticsearch's column storeDoes it make Elasticsearch a good general-purpose replacement for column-stores? No. As usual, it is better to . But the Elasticsearch column store has one key characteristic that makes it interesting: values are indexed by the doc id of the document that they belong to. What does it mean? Doc ids are transient identifiers of documents that live in a segment. A Lucene index is made of several components: an inverted index, a , a column store (doc values), a document store (stored fields) and term vectors, and these components can communicate thanks to these doc ids. For instance, the inverted index is able to return an iterator over matching doc ids, and these doc ids can then be used to look up the value of a field thanks to doc values: this is how aggregations work. This makes Elasticsearch particularly good at running analytics on small subsets of an index, since you will only pay the price for documents that match the query. This is how user interfaces to Elasticsearch like Kibana make it easy to slice and dice the data, by recursively filtering subsets that seem to have some interesting properties and running analytics on them. Moreover, Lucene is geared towards making search operations fast. Thus doc values do not store the raw bytes for each document in case of a string field. Instead it writes separately a terms dictionary containing all unique values in sorted order and writes the indexes of string values in the column store. This helps since small integers make better keys than strings and allow to run eg. terms aggregations more efficiently by keying on the term index rather than the term bytes and using an array rather than a hash table as a data structure for storing per-term counts.What's next?Given that doc values need to be indexed by the doc id of the document they belong to, the current approach that Lucene takes is to reserve a fixed amount of space per document. While this makes doc values lookups very efficient, this has the undesired side-effect of not being space-efficient for sparse fields, since documents that do not have a value would still require the same amount of storage as documents that have values. This is why Elasticsearch works best when all documents in an index have a very similar set of fields. However, there are ongoing developments that are exploring rather than a random-access API so that these sparse cases could be handled more efficiently and that compression could be more efficient using techniques like . \n"}
{"index": {"_id": 484}}
{"title":"Reporting 2.4.2 Released","seo_title":"Reporting 2.4.2 Released","url":"\/blog\/reporting-2.4.2-released","author":{"name":"Joe Fleming"},"date":"September 28, 2016","category":"Releases","locales":"","content":" Today we are releasing Reporting version 2.4.2, a patch release that brings one important change to the interface. From the beginning, users with access to Reporting have always been able to download and view reports that were created by any other user, but we didn\u2019t make this clear in the way we presented completed reports in the interface. To avoid confusion about permissions and access, we now show and make available all reports from all users of Reporting. Changelog: \n"}
{"index": {"_id": 485}}
{"title":"Elasticsearch 2.4.1 released","seo_title":"Elasticsearch 2.4.0 released","url":"\/blog\/elasticsearch-2-4-1-released","author":{"name":"Clinton Gormley"},"date":"September 28, 2016","category":"Releases","locales":"","content":" Today we are pleased to announce the bugfix release of based on . This is the latest stable release and is already available for deployment on , our Elasticsearch-as-a-service platform. All users are advised to upgrade, especially Windows users and X-Pack users.Latest stable release:Full details of the changes in this release are available in the release notes listed above, but this release contains four important bug fixes which are worth mentioning: \n"}
{"index": {"_id": 486}}
{"title":"Do you grok Grok?","seo_title":"Do you grok Grok?","url":"\/blog\/do-you-grok-grok","author":{"name":"Jo\u00e3o Duarte"},"date":"September 28, 2016","category":"Engineering","locales":"","content":" One the most common tasks when parsing log data is to decompose raw lines of text into a set of structured fields which other tools can manipulate. If you\u2019re using the Elastic Stack, you can leverage Elasticsearch\u2019s aggregations and Kibana\u2019s visualizations to answer both business and operational questions from the information extracted in the logs, like ip addresses, timestamps, and domain specific data. For Logstash, this deconstruction job is carried by , a filter plugin that helps you describe the structure of your log formats. There are which abstract concepts such as , and . In order to match a line with the format: with the grok library, it\u2019s only necessary to compose a handful of patterns to come up with: Which will create the structure: Easy right? Yes! Great! Are we done here? No! Because.. \u201cI\u2019m using grok and it\u2019s super slow!!\u201d That is a very common remark! Performance is a topic that is often brought up from the community as, often enough, users or customers will create a grok expression that will greatly reduce the number of events per second being processed by the logstash pipeline. As mentioned before, grok patterns are regular expressions, and therefore this plugin\u2019s performance is severely impacted by the behaviour of the regular expression engine. In the following chapters, we\u2019ll provide some guidelines on do\u2019s and don\u2019ts when creating grok expressions to match your log lines. Measure, measure, measure In order to validate decisions and experiments during grok expression design, we need a way to quickly measure performance between two or more expressions. For this, I created a small jruby script that uses the logstash-filter-grok plugin directly, bypassing the logstash pipeline. You can fetch . We\u2019ll be using it to collect performance numbers to validate (or destroy!) our assumptions. Beware of the performance impact when grok fails to match Although it is very important to know how fast your grok pattern matches a log entry, it is also essential to understand what happens when it doesn\u2019t. Successful matches can perform very differently than unsuccessful ones. When grok fails to match an event, it will add a tag to the event. By default, this tag is . Logstash allows you then to route those events somewhere where they can be counted and reviewed. For example, you can write all the failed matches to a file: If you find that there are multiple pattern match failures, you can benchmark those lines and find out their impact on the pipeline throughput. We\u2019ll now use a grok expression that is meant to parse apache log lines and study its behaviour. First, we start with an example log entry: And use the following grok pattern to match it: Now, we\u2019ll compare the matching speed of a successful match against three other log entries which don\u2019t conform to the format, either at the start, the middle, or at the end of the line: These log lines were benchmarked using the script described at the start, and the result is presented below: We can see that, for this grok expression, depending on the location of the mismatch, . This helps explain user reports on grok maximizing CPU usage when lines don\u2019t match, like . What can we do about it? Fail Faster, Set Anchors So now that we understand that match failures are dangerous to your pipeline\u2019s performance, we need to fix them. In regular expression design, the best thing you can do to aid the regex engine is to reduce the amount of guessing it needs to do. This is why greedy patterns are generally avoided, but we\u2019ll come back to that in a bit, as there\u2019s a much simpler change that alters how your patterns are matched. Let\u2019s come back to our lovely apache log line\u2026 \u2026which is parsed by the grok pattern below: There\u2019s a performance problem hiding in plain sight which exists due the natural expectations from the user of the grok plugin: the assumption that the grok expression we wrote will only match our log line from start to finish. In reality, what grok is being told is to \u201cfind this sequence of elements within a line of text\u201d. Wait, what? That\u2019s right, \u201cwithin a line of text\u201d. This means that a line such as\u2026 \u2026will still match the grok pattern! The good news is that the fix is simple, we just need to add a couple of ! Anchors allow you to pin the regular expression to a certain position of the string. By adding the start and end of line anchors ( and ) to our grok expression, we make sure that we\u2019ll only match those patterns against the whole string from start to finish, and nothing else. This is very important in the case of failure to match. If the anchors aren\u2019t in place and the regex engine can\u2019t match a line, it will start trying to find the pattern within substrings of the initial string, hence the performance degradation we saw above. So, to see the performance impact, we benchmarked the previous expression against a new one, now with anchors: Here are the results: It\u2019s a pretty dramatic change in behavior for the non matching scenarios! Not only we removed huge performance drops in the middle and end scenarios, but also made the initial match failure detection around 10 times faster. Sweet. Beware of matching the same thing twice You might be tempted to say: \u201cwell, all my lines are correctly formatted so we don\u2019t have failed matched\u201d, but this might not be the case. Over time, we\u2019ve seen a very common pattern of grok usage, especially when lines from multiple applications come through a single gateway like syslog which adds a common header to all messages. Let\u2019s take an example: imagine that we have three applications which log using a \u201ccommon_header: payload\u201d format: A common grok setup for this would be to match the three formats in one grok: Now notice that even if your applications log correctly, grok will still sequentially try to match the incoming log line against the three expressions, breaking at the first match. This means that it\u2019s still important to ensure we skip to the right one as fast as possible, since you\u2019ll always have one failed match for Application 2 and two failed matches for Application 3. The first tactic we often see is to tier the grok matching: first match the header, overwrite the message field, then match only the bodies: This alone provides an interesting performance boost, matching lines 2.5x faster than the initial approach. But what if we add our fellow anchors? Interesting! Adding anchors makes both architectures perform equally well! In fact, because of the greatly increased failed match performance, our initial single grok design performs slightly better since there is one less match being executed. Ok, so how can I know things aren\u2019t going well? We\u2019ve already come to the conclusion that monitoring the existence of \u201c_grokparsefaiure\u201d events is essential, but there is more that you can do: Since version 3.2.0 of the grok plugin, there\u2019s a couple of settings that help you understand when an event is taking a long time to match (or fail to). Using it\u2019s possible to set an upper bound time limit to the execution of the grok match. If this limit is reached, the match is interrupted and the event is tagged by default with . Using the same conditional strategy we presented before, you can redirect those events to a file or a different index in elasticsearch for later analysis. Another really cool thing that we will be introducing in Logstash 5.0 in the context of metrics is the ability to extract data on the pipeline performance and, most importantly, per plugin statistics. While logstash is running, you can query its API endpoint and see how much cumulative time logstash is spending on a plugin: With this information, you can see if grok\u2019s \u201cduration_in_millis\u201d is growing rapidly or not and if the number of failures is increasing, which could serve as a warning flag that some pattern is not well designed or consuming more time than expected. Conclusion Hopefully this blog post will help you understand how grok is behaving and how to improve its throughput. To sum up our conclusions: \n"}
{"index": {"_id": 487}}
{"title":"A New Way To Ingest - Part 1","seo_title":"A New Way To Ingest - Part 1","url":"\/blog\/new-way-to-ingest-part-1","author":{"name":"Christoph Wurm"},"date":"September 27, 2016","category":"Engineering","locales":"","content":" With , it is time we took a closer look at how to use one of the new features, Ingest Nodes. \n"}
{"index": {"_id": 488}}
{"title":"Introducing beta releases of Elasticsearch and Kibana Docker images!","seo_title":"Introducing beta releases of Elasticsearch and Kibana Docker images","url":"\/blog\/releasing-beta-version-of-elastic-docker-images","author":{"name":"Dimitrios Liappis"},"date":"September 23, 2016","category":"Engineering","locales":"","content":" Introducing Docker images for Elasticsearch and Kibana Beta releases of the Elasticsearch and Kibana Docker images are here! They track the latest versions of Elasticsearch and Kibana 5.0 and are pre-installed with our awesome ! The images are hosted on Elastic\u2019s own Docker Registry. Instructions can be found on the and GitHub pages, but let\u2019s see how easy it is to launch an Elasticsearch + Kibana stack with them. First, ensure that: Download an example definition to help us bring up Elasticsearch and Kibana, then issue: : the above command assumes that you don\u2019t have Elasticsearch and Kibana listening on the . Feel free to adjust the ports in the . You will see logs from Kibana and Elasticsearch racing on your screen. To access Kibana, visit and you will be greeted by the Kibana 5.0 login page! Since is pre-installed, you can use the default credentials, (login: , password: ) but you are to change those via the Management menu in Kibana. Now let\u2019s add some data. Using curl we will create an index called containing data for two users: Back to the Kibana UI, let\u2019s configure an index pattern for the data. Enter for the index name and untick , as shown below: Click \u201ccreate\u201d and now you can view the inserted data in the Kibana Discover page: Terminating your containers is as simple as : this will not destroy the Elasticsearch data volume so if you again your data will still be present. To terminate the containers the data volume use instead. The images are in beta, and we . However there are a number of best practices that we have compiled . We welcome issues and PRs. Stay tuned for the full-release version! Example docker-compose.yml: \n"}
{"index": {"_id": 489}}
{"title":"Elastic Stack Release - 5.0.0-beta1","seo_title":"","url":"\/blog\/elastic-stack-release-5-0-0-beta1","author":{"name":"Tyler Hannan"},"date":"September 22, 2016","category":"Releases","locales":"","content":" We\u2019ve reached a milestone in the 5.0.0 release. Today, we are pleased to announce that the first public beta is available for download. At Elastic, a beta indicates that the products have reached feature freeze and the final effort is in squashing any unexpected bugs or regressions. It should look, and feel, very similar to the final GA release. Of course, it is software, so we reserve the right to change our mind and implement\/change things that make the world better for you. Before you get too excited, keep in mind that this is still a beta, so don\u2019t put it into production. If you open a bug report, today, you too can become an . And now, without further ado, some highlights from beta1. ElasticsearchFor more detailed information, and many other features, peruse the Elasticsearch . From 2.3.x to 5.0. The magical journey. The undiscovered country. The next frontier. Other coined phrases. As a reminder, we\u2019ve also released the , which runs on your existing 2.3 cluster. \u00a0Use this site plugin to prep for your migration. KibanaTo quote the , \u201cKibana is where the party is\u201d. Logstash Did we say we <3 logs? The Elastic Stack is great for log management and analysis, and thousands of users use Logstash and the rest of the stack to crunch application logs of all kinds. Logstash as a software is no exception \u2014 we emit internal logs which can be used by operators to troubleshoot issues. In this release, we've significantly improved the debugging capability of Logstash by revamping its internal logging framework. Oh, and new, shiny APIs. Check out the deets in this . BeatsWe collect data from the edge. We document all the updates are in a single Beats . ES-HadoopES-Hadoop v 5.0.0-beta1 has also been released today. Peruse all the information in the . Get it Now!Happy testing. Your feedback is instrumental in making 5.0 successful. And, don't forget that X-Pack is here and continually being updated with each pre-release. \n"}
{"index": {"_id": 490}}
{"title":"Elasticsearch 5.0.0-beta1 released","seo_title":"Elasticsearch 5.0.0-beta1 released","url":"\/blog\/elasticsearch-5-0-0-beta1-released","author":{"name":"Clinton Gormley"},"date":"September 22, 2016","category":"Releases","locales":"","content":" Today we are excited to announce the release of based on . This is the sixth in a series of pre-5.0.0 releases designed to let you test out your application with the features and changes coming in 5.0.0, and to give us feedback about any problems that you encounter.Open a bug report today and become an . This is a beta release and is intended for . Indices created in this version .Over 300 enhancements and bug fixes have been added since 5.0.0-alpha5 (all of which you can read about in the release notes linked above), but there are three changes in this release that deserve special mention below: huge improvements to indexing performance, switching fields to Lucene\u2019s LatLonPoint, and making Painless the new default scripting language. \n"}
{"index": {"_id": 491}}
{"title":"Elasticsearch for Apache Hadoop 5.0.0-beta1","seo_title":"","url":"\/blog\/es-hadoop-5-0-0-beta1","author":{"name":"James Baiera"},"date":"September 22, 2016","category":"Releases","locales":"","content":" \u200bI am excited to announce the release of Elasticsearch for Apache Hadoop (aka ES-Hadoop) built against Elasticsearch 5.0.0-beta1. : This is an beta release and is intended for purposes only. Beta releases are normally more stable than Alpha releases, but crazy things can still happen when running this code. Indices created with this version . For the sake of your own sanity, we do not advise using this version in production. Think of the hamsters. What\u2019s new? Spark 1.3-1.6 Streaming Support Spark is pretty fast, but sometimes you need your data even faster. We loved hearing that some of you were using ES-Hadoop with Spark Streaming, but we also felt the same heartache about the limitations that you were running into. We decided to do something about it. ES-Hadoop now natively supports consuming DStreams from Spark Streaming 1.3-1.6! We\u2019ve included some fixes for the most commonly reported Spark Streaming issue of running out of connection resources during small processing windows. May your TIMED_WAIT\u2019s be few, and your Spark Streaming Jobs live long and prosper. Ingest Node We heard about this cool new feature called the that was available in the alpha releases and coming out in Elasticsearch v5.0.0. We thought \u201cOh man, we ingest stuff, this node ingests stuff. We need to schedule a brunch with it immediately to trade gossip.\u201d Starting in ES-Hadoop 5.0.0-beta1 you can now specify an ingest pipeline to send your data to, as well as target only ingest nodes to cut down on unnecessary traffic. We\u2019re still waiting to hear back from you about brunch, Ingest Node. Call us! Fast Acting Bug Repellant Computers are hard. We thank our lucky stars every day that our friends in the community are so helpful when it comes to reporting issues. When you open up your copy of ES-Hadoop, you\u2019ll find a fresh batch of bug fixes already applied. These bugs range from issues with overwriting data with SparkSQL, memory leaks in the network code, false warnings about version compatibility, and a bunch more. You can check out all those fixes (and their gritty details) . Cheers to the bug hunters! Feedback Anticipation is one of those cool things in life, but we understand that sometimes waiting is a real bummer. That\u2019s one of the reasons why we work so hard to make these early access releases for you all. It\u2019s like getting to open your birthday presents a few weeks in advance! You\u2019re happy, we\u2019re happy, and if anything ends up being broken, we have some time to get it fixed before the big special day. So, please, try this at home! You can ES-Hadoop 5.0.0-beta1, try it out, find out how it breaks, and let us know what you did on , , or in the . We are forever indebted to our early adopters, so much so that we created the ! Now that\u2019s the sound of sweet, sweet gratitude! \n"}
{"index": {"_id": 492}}
{"title":"Kibana 5.0.0-beta1 released","seo_title":"Kibana 5.0.0-beta1 released","url":"\/blog\/kibana-5-0-0-beta1","author":{"name":"Court Ewing"},"date":"September 22, 2016","category":"Releases","locales":"","content":" We are pleased to announce the immediate availability of Kibana 5.0.0-beta1. I\u2019m not ashamed to admit it - the Kibana team really knows how to beta. Those Elasticsearch nerds might have a monopoly on consistency, and those squares working on Beats might get their stuff installed on thousands of servers before you\u2019ve finished reading this post, but Kibana is where the party is. We\u2019re shipping so many features in this release, it\u2019s taken me three drafts of this blog post to try to whittle it down to highlights. And that doesn\u2019t even include the dozens of bug fixes that are baked right in. . You won\u2019t be disappointed. Hopefully we\u2019re preaching to the choir at this point, but become an by opening a valid bug report and we\u2019ll send you free stuff. : This is beta software that will only work with . Please test it, but do not use it in production. Upgrading 5.0.0-beta1 to any other version is not supported. Time series data with Timelion Timelion is a plugin no more. It\u2019s now a fully supported, first-class citizen of Kibana core. Analyze your time series data with style, or at least with a custom DSL that let\u2019s you do some really cool stuff. And don\u2019t forget to embed those bad boys in your dashboards. Set scripting language for scripted fields You can now select which Elasticsearch scripting language you\u2019d like to use in scripted fields in Kibana. It\u2019s so easy, it\u2019s painless. Sorry\u2026 that pun was bad. But seriously, you can and should use the new . Set position of visualization legends Because you deserve better than being hamstrung by right-aligned legends. Release the creative beast within and make your dashboards stand out with the new and improved, slightly-more-options-than-before legend positioning feature. Share exactly what you\u2019re looking at, or share a link directly to the saved object We\u2019ve revamped the Sharing UI so you can easily select between a URL to what you\u2019re seeing on the screen right now versus a link to the underlying saved object that will remain up to date over time. No more sending people links to stale data, unless that\u2019s the kind of thing you\u2019re in to. X-Pack Reporting You\u2019ve seen it for Kibana 4.6, and now you can get it in X-Pack 5.0. Go ahead and generate PDF reports of your visualizations and dashboards to your heart\u2019s content. Saved workspaces in X-Pack Graph Building awesome graphs takes time, effort, and sometimes a little bit of luck. Don\u2019t let that all go to waste - save your workspace and come back to it later. Stop URL length errors once and for all This one sits squarely in the gray area between feature and bug fix, but the underlying issue is pretty gnarly, so we might as well shout to the heavens about it. If you have non-trivial dashboards on Internet Explorer, then you probably have hit the URL length limit and have experienced the bottomless sadness that is Kibana falling apart before your eyes. Fix this once and for all by enabling the setting in Advanced Settings under Management. Note that when this setting is enabled, you must use the sharing UI when you want to link someone to something you\u2019re looking at rather than grabbing the URL directly from your browser. It\u2019s a trade off we want to get rid of, but for now we wanted to get this fix out to anyone that\u2019s being plagued by URL length limits in their browser. The highlights of the non-highlights Like I said before, there\u2019s just too darn much to highlight effectively in a single blog post. Here are some of the other features that don\u2019t get the full section treatment: All the bugs We fixed dozens of bugs in 5.0.0-beta1. You read that right\u2026 dozens with a \u201cd\u201d. Though I guess that makes sense since you can\u2019t spell \u201cdozens\u201d any other way. Wrap up Download the beta1 release and help us track down any last bugs. Issues can be filed on , feedback is appreciated on our , and feel free to reach out to us on or as well. \n"}
{"index": {"_id": 493}}
{"title":"Logstash 5.0.0-beta1 released","seo_title":"","url":"\/blog\/logstash-5-0-0-beta1-released","author":{"name":"Suyog Rao"},"date":"September 22, 2016","category":"Releases","locales":"","content":" We are pleased to announce that Logstash 5.0.0-beta1 has been released today. You can review the changes or jump directly to.Note: This is a beta release. Please do not use this in your production environment.Logstash's LogsDid we say we <3 logs? The Elastic Stack is great for log management and analysis, and thousands of users use Logstash and the rest of the stack to crunch application logs of all kinds.Logstash as a software is no exception \u2014 we emit internal logs that can be used by operators to troubleshoot issues. In this release, we've significantly improved the debugging capability of Logstash using its own logs. We've migrated to use the, and for our users, this means tons of new functionality:PUT \/_node\/logging { \"logger.logstash.outputs.elasticsearch\" : \"DEBUG\" }Monitoring EnhancementsWe've received good feedback about the new from our pre-releases. In this release, we've incorporated most of the feedback we received:Breaking Change: New Elasticsearch TemplateThe index template for 5.0 has been changed to reflect Elasticsearch's. Most importantly, the subfield for string multi-fields has changed from .raw to .keyword to match ES's default behavior. The impact of this change to various user groups are detailed below:FeedbackAs we approach the 5.0 release, we welcome and appreciate all your feedback. You can open issues on our, or start a conversation on our. Also, we would love for you to be a part of our! \n"}
{"index": {"_id": 494}}
{"title":"Beats 5.0.0-beta1 released","seo_title":"","url":"\/blog\/beats-5-0-0-beta1-released","author":{"name":"Monica Sarbu"},"date":"September 22, 2016","category":"Releases","locales":"","content":" Beats 5.0.0-beta1 releasedWe are totally stoked to announce the 5.0.0-beta1 release, another major milestone on our road to Beats 5.0. IMPORTANT: This is a beta release and it is intended for testing purposes only. More modules in Metricbeat is a new addition to the Beats lineup for the 5.0 release. It\u2019s a lightweight shipper that periodically interrogates external services, and sends their metrics to Elasticsearch. Metricbeat is replacing Topbeat in the 5.0 release, and it incorporates all the metrics provided by Topbeat plus many more.\u00a0 In this release, PostgreSQL and HAProxy are added to the list of supported . The module exports statistics about each PostgreSQL database, the background writer process activity, and each PostgreSQL process. Thanks to a community contribution by, Metricbeat is able to collect statistics from , an open source TCP\/HTTP load balancer. To enable gathering the statistics from HAProxy, you must enable the stats socket via TCP. For more details please check the . Get visibility into your containersMetricbeat is able to collect control group metrics from the Linux kernel. Control groups, which are commonly referred to as cgroups, is a mechanism for allocating resources - such as cpu time, memory, or block I\/O time - to a process or set of processes. Cgroup metrics are especially useful for collecting detailed metrics from processes running inside containers because each container is assigned to a cgroup. The benefit of collecting container metrics directly from cgroups is that it works with any container tool (e.g. Docker, rkt, runC, LXC, systemd). Metricbeat reads directly from the cgroup pseudo filesystem provided by the Linux kernel, so it has no dependency on the APIs provided by the container tools. For more details about how to enable cgroups functionality in Metricbeat, please check the . Please note that cgroups is experimental in 5.0.0-beta1, and it\u2019s disabled by default. Easily import Kibana dashboardsStarting with the 5.0.0-beta1 release, each Beat package comes with an app, called import_dashboards, which replaces the bash\/powershell scripts to import the Kibana dashboards. The reason behind this change is to make it easier for us to maintain a single Golang application instead of two scripts, and for the user to easily import any Kibana dashboards by running a single command. To keep the Beat package light, starting with the 5.0.0-beta1 release, we are releasing the sample Kibana dashboards for all the Elastic Beats in a separate common package, instead of including the dashboards in each Beat package. The import_dashboards app accepts a URL to any local or online zip archive that contains the Kibana dashboards. If no URL is provided, by default the app imports the Elastic Beat dashboards of the same version as the Beat package. .\/scripts\/import_dashboards Share your own Beats dashboardsYou can now make use of any Kibana dashboards created by the community, by passing the URL to a zip archive that contains the dashboards, visualizations, and searches. .\/scripts\/import_dashboards -url https:\/\/github.com\/monicasarbu\/metricbeat-dashboards\/archive\/1.1.zip Do you have some awesome Kibana dashboards to share with the community? , upload the archive to your GitHub repository, and share it with the community by creating a topic in the . Improvements to the Kafka outputIn 5.0.0-beta1 the Kafka output received many more enhancements since first introducing Kafka support for 5.0.0-alpha releases. The Kafka Go client library by Shopify has been upgraded to version 1.10.0, adding support for Kafka 0.10. In addition to 0.10 support, \u00a0SASL\/plain authentication support has been added, so you can configure the username and password used to connect to Kafka.\u00a0 The beta1 release enables users to configure the topic selection and event partitioning strategy. You can choose between `random` event distribution, `round robin` event distribution, or `hash`-ing, where a hash-value is computed either from the event key or a composed hash value based on configurable event fields. Check the for more configuration details. \u00a0 Monitor Cassandra traffic with PacketbeatStarting with the 5.0.0-beta1 release, you can monitor the network traffic exchanged between your applications and Cassandra. A sample for Cassandra is available, and you can import it together with the other Packetbeat dashboards by using the `scripts\/import_dashboards` or `scripts\/import_dashboards.exe` script from the Packetbeat package. Rename TLS config options to SSLThis is done as part of a larger effort to align the security settings across all the Elastic products. Changing TLS to SSL in all output types breaks the compatibility with the older versions. To make it easier for the users to upgrade their configuration file, we provide a python migration script, which you can find in the \u201cscripts\u201d folder of the Beat package. Become a PioneerA big Thank You to everyone that has tried the alpha releases and or . We\u2019d like to also remind you that if you post a valid, non-duplicate bug report during the alpha\/beta period against any of the Elastic stack projects, you are entitled to a . \n"}
{"index": {"_id": 495}}
{"title":"50% More Storage, Same Price. Elastic Cloud (Hosted Elasticsearch) Gets Even Better","seo_title":"","url":"\/blog\/50-percent-more-disk-same-price-elastic-cloud-hosted-elasticsearch-gets-even-better","author":{"name":"Tyler Hannan"},"date":"September 21, 2016","category":"News","locales":"","content":" In our last post, titled , we shared that we have been able to extend a 15% discount. Basically\u2026 Phenomenal, cosmic cloudy powers.Itty, bitty annual price. In that post, we mentioned a few infrastructure updates that we were rolling out. They have now been deployed to the entire Elastic Cloud fleet and it is important to understand the impact. 50% More Storage, Same Price. The Elastic Cloud service operates on a fixed ratio of Memory to Storage. When we first launched, it was fixed at 1:8. We subsequently upgraded to 1:16 and, today, only a few months later, we are pleased to announce that we have increased the Memory to Storage ratio to 1:24. You now get 24GB of storage for every 1GB of RAM. Most importantly, we\u2019ve done this without increasing the price. The flexibility of managing the fleet of deployed cloud clusters means we are able to monitor usage, cost, sizing and settle on a ratio that provides the highest value and widest applicability for all use-cases. Were you concerned, in the past, that your log data was too voluminous for using Elastic Cloud? Now you have 50% more storage. New Region But wait, there\u2019s more\u2026As discussed in the last post, our approach to adding regions to Elastic Cloud is fairly straightforward. Your feedback guides our roadmap. US West (Oregon) was a frequently requested region. For some very compelling reasons: A ratio of 1:24 and the decreased cost of a new region means with Elastic Cloud is cheaper than it has ever been. \n"}
{"index": {"_id": 496}}
{"title":"Brewing in Beats: Dashboards for containerized processes","seo_title":"","url":"\/blog\/brewing-in-beats-dashboards-containerized-processes","author":{"name":"Tudor Golubenco"},"date":"September 21, 2016","category":"Brewing in Beats","locales":"","content":" Welcome to Brewing in Beats! With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources. Filebeat: -once flag to exit after finishing current work When the flag is used, Filebeat starts all configured harvesters and prospectors and runs each prospector until the harvesters are closed. It is recommended to use the flag in combination with so harvester directly close when the end of the file is reached. This could be used for measuring the Filebeat performance or for loading a fixed set of files. Kibana dashboards for containerized processes Since recently, Metricbeat can report cgroup data for any running process (see this for details), and now we\u2019ve also added for this data. Added \/net\/ and \/ns\/ support to procfs library Andrew to the procfs Golang library, which does proc file system parsing and which we plan to use in Metricbeat. Updated to Go 1.7.1 Our compiler images used in packaging, docker files used in tests, and our CI tools configurations were all (from 1.7). Filebeat: fix concurrent harvesters In case newly started harvesters did not persist their first state before the next scan started, it could have happened that multiple harvesters were started for the same file. This could have been caused by a large number of files or the output blocking. There are more details in the . Release 1.3.1 We\u2019ve released the\u00a0, which includes a\u00a0\u00a0in Filebeat, discovered and fixed by\u00a0, a contributor. \n"}
{"index": {"_id": 497}}
{"title":"Painless: A New Scripting Language","seo_title":"","url":"\/blog\/painless-a-new-scripting-language","author":{"name":"Jack Conradson"},"date":"September 20, 2016","category":"Engineering","locales":"","content":" A little over a year ago, I received a phone call one evening about an opportunity to come build an embedded programming language into Elasticsearch. \u00a0Initially, I thought the idea was a crazy one. \u00a0Why build a brand new language when there are already so many to choose from? \u00a0But, as it turns out, it is very difficult to properly secure a language that can be executed remotely without that feature being thought of during the initial design phase. \u00a0 So, with that in mind, I\u2019m pleased to introduce Painless, a new scripting language in Elasticsearch 5.0, designed from the ground up to be both secure and performant. Painless is a dynamic scripting language with syntax similar to Groovy. \u00a0Painless scripts are composed of optionally some number of static methods and a required single main section of code. \u00a0Some highlights of Painless include the following: Painless can be used anywhere in Elasticsearch where scripts can normally be run by specifying the 'lang'\u00a0parameter as 'painless'.\u00a0 Painless will also become the default language in Elasticsearch 5.0. \u00a0. On a final note, I would like to thank both Robert Muir and Uwe Schindler for their significant contributions related the dynamic side of Painless, and also to Nik Everett for his significant contribution of regular expressions. \u00a0Uwe even had several methods related to array length added directly to Java to eek out the best dynamic performance possible. \n"}
{"index": {"_id": 498}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-09-19","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-09-19","author":{"name":"Michael McCandless"},"date":"September 19, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Building an AR navigation system for visually impaired users with ElasticSearch \u2014 Erik Schlegel (@erikschlegel1) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole Elastic ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 499}}
{"title":"Instant Aggregations: Rewriting Queries for Fun and Profit","seo_title":"Instant Aggregations: Rewriting Queries for fun and profit","url":"\/blog\/instant-aggregations-rewriting-queries-for-fun-and-profit","author":{"name":"Colin Goodheart-Smithe"},"date":"September 19, 2016","category":"Engineering","locales":"","content":" In 1.4.0 Elasticsearch gained a shard level \u2018Request Cache\u2019 which caches the result of the query phase on each shard keyed on the search request itself. Until 5.0 this feature was disabled by default since it wasn\u2019t as useful as it could be for most of the computationally heavy use cases. The cache was intended to make searches faster, especially for aggregations. One problem was that ordering in JSON is not deterministic so although two requests may be logically the same, when rendered to JSON strings they may not be equal. The other main problem is that these computationally heavy use cases tend to use time windows relative to the current time so subsequent requests will tend to have slightly different time ranges. Enabling it would likely be a waste memory for most of the users \u00a0since they would rarely ever get a cache hit. So why would we add such a feature? Here at Elastics, we try to follow the rule of \u201cprogress over perfection\u201d. Even if we can\u2019t utilize it\u2019s full potential we get a step closer to our goals. Now after 2 years of engineering effort and representation, we can finally take full advantage of it. From 5.0 the request cache will be enabled by default for all requests with `size:0`. The request cache is most useful for analytics use cases and generally analytics use cases use search requests with `size: 0`. So how did the changes made since 1.4.0 enable us to better use this feature? The search request cache gives massive improvements in search performance when running the same search multiple times on a static index. However, search requests are rarely exactly the same, especially in the time series use case. Lets look at some of the characteristics of typical search for time-series use cases: The above are common characteristics of search requests for a lot of time series use cases including common patterns of usage for Kibana. A lot of Kibana dashboards contain quite a few visualisations a lot of which are complex and can take a number of seconds for the dashboard request to be executed by Elasticsearch. Because search requests are rarely the same, the search request cache can\u2019t be used effectively to improve search performance for these use cases. Or can it? How can we make the search request cache work when the time range is always moving? Let\u2019s solve this by considering an example. Imagine we have the details for every residential house sale in the UK since 1995 (luckily this information is conveniently ). We can index this into 21 yearly indices (e.g. house-prices-1995, house-prices-1996, \u2026, house-prices-2016). For the purposes of this explanation let\u2019s make each index only have 1 shard (though the same idea can easily be extended to multiple shard indices without modification) Now we can run queries against the indices by using requests like this: ``` GET house-prices-*\/_search { \"query\": { \"range\": { \"date\": { \"gte\": \"2013-09-01\", \"lt\": \"2016-03-01\" } } } } ``` The figure below shows three of these such queries overlaid on the yearly indices. These queries are typical for dashboard style use cases in that they differ only by small amounts (imagine a refreshing dashboard) A couple of things stand out from this diagram: So the only indices which affect the matching documents between the three queries are house-prices-2013 and house-prices-2016. If we could rewrite the queries on each shard based on the range of values present in that index we could make the queries able to actually utilize the request cache. Below is the diagram with the same three queries rewritten to make them more cachable in the search request cache: You can see that in the diagram above, the first query is rewritten and run as a `match_none` query on the `house-prices-2012` indexes shard and a `match_all` query on the `house-prices-2014` and `house-prices-2015` indices shards. This means that when the second and third query is run it can use the cached results of the search on the `house-prices-2012`, `house-prices-2014` and `house-prices-2015` indices shards instead of actually running a search on those shards. So for the second and third queries we only need to actually search the shards on the `house-prices-2013` and `house-prices-2016` indices. Also, even for the first query, running a `match_none` query instead of a range query will be faster since it will not need to try to lookup the date range in the index. So how does this work in practice? This feature not only relies on the search request cache mentioned at the beginning of this post, but it is also heavily based on the query refactoring that we described in a recent . The reason for this is that in order to add the rewrite logic described above we need objects that represent the query and the search request that we can actually rewrite. When the search request is received by the shard, we rewrite the entire request including `query` and `post_filter` QueryBuilder objects. Each type of query has it\u2019s own implementation of QueryBuilder which will rewrite according to it\u2019s own rules. Compound queries, queries that themselves contain queries (such as `bool` and `constant_score`) will call rewrite on the queries they wrap. Most leaf queries, queries that do not contain other queries, currently do not contain any rewrite logic so just return themselves (to indicate they did not change). The range query however, will check the minimum and maximum value of the field (we will call this the field range) and compare this to the range it contains. There are three cases that we care about when evaluating the rewrite for the range: Now that the search request has been rewritten we can check the cache with the rewritten version and either retrieve the cached result or execute the search and add the result to the cache, keyed on the rewritten search request. This has a nice side effect since the rewritten queries are \u201cnormalized\u201d search requests that are semantically equivalent but differ in the order of keys in the json will now also produce cache hits. Why not use `match_all` ? In the case that the query range contains the entire field range you might think we could rewrite the `range` query as a `match_all` query. We can\u2019t do this because we can\u2019t assume that all documents have a value for the field. If we rewrite to a `match_all` query we would incorrectly match documents that have no value for the field. For this reason we instead rewrite the range to an unbounded range query (effectively [* TO *]) which still means the query is much more useful to the search request cache. Is this all worth the trouble? To answer this question we\u2019ll go back to our yearly house price indices. This dataset contains 21 yearly indices containing 21,304,688 residential UK house sales from 1995 to 2016. I ran this fairly unscientific test on my Macbook Pro. Each index has a single shard. I created a Kibana dashboard showing 14 different visualisations relevant to the data mixing simple and complex visualisations. The top of the dashboard looks like the following: With the request cache disabled, requests to elasticsearch for the dashboard to refresh takes 12s-14s. When the request cache is enabled this drops to ~100ms. The same request is now 100x faster! But this is on completely static data so what happens when we are indexing data? To test this I deleted the data from 2010 to 2016 and loaded it in date order whilst refreshing the dashboard: Now the request to Elasticsearch for the dashboard refresh takes 60-200ms. So the query is still at least 50x faster than our original un-cached query! The refresh time varies depending on how much data is present in the changing index since the search on the latest index does not hit the cache. This is because as new data is indexed, the cache on the shards of the latest index is constantly being invalidated. The Instant Aggregations feature enables much better caching of search requests by rewriting the query based on the data present on the shard. As of 5.0.0 the query is only rewritten for date range queries, but with this infrastructure in place it opens the door to the potential of rewriting other types of query to improve the request cache utilization. We even have the potential to rewrite aggregations to make them more cacheable! We have shown in this post that the potential performance improvements when we use this technique can be huge, so watch this space for more improvements in the future. \n"}
{"index": {"_id": 500}}
{"title":"Welcome Prelert to the Elastic Team","seo_title":"Welcome Prelert to the Elastic Team","url":"\/blog\/welcome-prelert-to-the-elastic-team","author":{"name":"Shay Banon"},"date":"September 15, 2016","category":"News","locales":"","content":" I am happy to announce that Prelert and Elastic are joining forces. Ever since we started Elastic, our goal has been to allow users to easily find relevant data or insights within large amounts of data. Search is a wonderful way to do it, and the ability to slice, dice, and aggregate the data in an unconstrained way allowed users to feel they are in control of the data, compared to the other way around. But we can take it a step forward, and with Prelert, we just did. Prelert has developed an unsupervised machine learning engine\u00a0that can plow through large amounts of data and automatically find those insights our users today have been proactively finding using search. We view the Prelert technology as a generic engine that can apply to many different use cases, which maps very nicely with what we are trying to do with the Elastic Stack. It has been proven to be extremely successful within specific use cases. Finding anomalies within transactions \/ operational metrics, detecting uncharacteristic user behavior, finding a population of attacking IP addresses, and much more. Let me stop here and let Steve Dodson, Prelert CTO and Founder, share his thoughts: At Prelert we work on developing machine learning technologies that allow users to understand the behavior of their data. Joining Elastic gives us a fantastic opportunity to bring this technology to a large range of users and data, and will allow us to execute on the vision we set out for Prelert over 7 years ago. The journey to this point initially started when I was offered the opportunity to help diagnose an application issue on a large trading platform in an investment bank. Sporadically, traders were becoming disconnected from the trading platform and the goal was to proactively preempt this issue and diagnose the root cause. The problem was that the data was overwhelming, with 100s of log files from 100s of servers, and 10,000s of performance metrics from the applications and systems. Simply searching through the logs or metrics didn\u2019t yield sufficient insight into the problem, and it started to become clear that hidden in this data was the behavior of the system, and if we could model the normal behavior of the system we could isolate the unusual activity. Based on this premise we built out a prototype that statistically modelled the behaviour of the system via the logs and metrics allowing the customer to identify, diagnose and resolve the issue. (First Prelert UI showing anomalies and root cause!) The great thing was that at the same time we were developing this technology, users with large IT systems were moving from legacy monitoring solutions, to solutions that could collect and centralize storage of all their logs, performance metrics and data. Elasticsearch is a great example of this, and showed how this new generation of search technologies could be used by customers to give significant insight into their data. Also, the questions users were asking from this data were becoming broader, and instead of relying on silo\u2019ed tools, users were using these platforms to answer IT Operations, Security, Business and other questions. Layering Prelert on top of these technologies was the natural next step, as users were asking questions that required statistical and machine learning analysis of the data. Another really exciting discovery was that customers then started using Prelert to answer questions such as \u201cwhich bus routes are congested?\u201d, \u201cis the temperature across my environment normal?\u201d, \u201chas there been a change in the number of retail transactions?\u201d along with traditional IT Operations questions. This showed that our technology was not only robust to diverse use cases, but had the opportunity to be broadly applicable across diverse time series data. (Current Prelert UI in Kibana) However, a challenge we kept running into was that customers wanted our analytics more and more tightly integrated into the data platform. The really exciting part is that Elastic shared our vision of extending these platforms beyond search using machine learning, and so joining Elastic is the natural next chapter for Prelert, and it\u2019s a privilege to be working with Steven, Shay and team. Thanks Steve :). Let me cover the near-term future when it comes to the products. Prelert has already worked on a wonderful integration with Elasticsearch and Kibana. It is used in 2 products, the API Engine, and the Integration for Elastic Stack. Now that we joined forces, we think we can improve this to be a much more integrated product, where Prelert becomes a feature of our stack. Think Prelert node(s). Within this context, we are going to put a Beta label on the existing 2 products, and work towards the more native integration towards a GA. Prelert also developed a Splunk App, and we are announcing today the End of Life for the app. In the short term, nothing changes for Prelert customers but this announcement starts the timing for the maintenance period of this app. Importantly, the app will still be supported and all existing customer commitments will be upheld. We hope that any existing Splunk customers who are interested in using the Elastic Stack will find significant improvements in the user experience with our native Prelert and Elastic Stack integration. We will obviously be there for the existing customers to help migrate and transition to use Elastic products.We are very excited about this, and we think this will prove to be a valuable addition to the Elastic user base, and a great, fully integrated, and improved product for Prelert\u2019s customers. Oh, and if you want to see Prelert in action and hear more about our developments, come join us at one of our stops in the US, EMEA, or in Asia Pacific. \n"}
{"index": {"_id": 501}}
{"title":"The Great Query Refactoring: Thou shalt only parse once","seo_title":"The Great Query Refactoring: Thou shalt only parse once","url":"\/blog\/the-great-query-refactoring-thou-shalt-only-parse-once","author":{"name":"Luca Cavanna"},"date":"September 14, 2016","category":"Engineering","locales":"","content":" . When writing software, adding cool new features is of course always great fun. But sometimes it\u2019s also important to work on internal changes in the code base that enable those shiny new additions in the future. For example, there were for Elasticsearch floating around that were essentially blocked by the lack of having a good intermediate representation for search requests arriving through the REST layer, which prevented early query optimizations and delayed parsing to the shard level. For the upcoming release of Elasticsearch 5.0 we embarked on a large refactoring to change the way search requests work internally. In this blog post we want to highlight some of the changes and challenges that came along with the refactoring of queries and the search request, how it helped us improve our testing and how it enables great new features like \"Instant Aggregations\", that will be highlighted in a following blog post.How search requests were sent across the cluster prior to the RefactoringWhen you send a search request to a node in the cluster, the node receiving the request coordinates the search request from then on. The coordinating node identifies what shards the search request needs to be executed on, and forwards it to the nodes that hold those shards via the internal node-to-node . Each shard returns a set of documents, whose ids will be sent back to the coordinating node that is responsible for reducing the matching documents obtained to the top matching ones that need to be returned to the client. Once those documents are identified, they are fetched as part of the fetch phase and finally returned.Before Elasticsearch 5.0, each node received the original search request, parsed the query and used other information available from the shard (like mappings) to actually create the Lucene query that was then executed as part of the query phase. The body of the search request is not parsed on the coordinating node but rather serialized via the transport layer untouched, as an opaque byte array which holds nothing more than its json representation. This was historically done to avoid having to write serialization code for every single query and every single section of a search request, as elasticsearch uses its own binary serialization protocol. We eventually came to the conclusion that this was the wrong trade-off. So what's the problem with this?While simply forwarding incoming requests on the coordinating node as described above is simple and fast (at least on the coordinating node), there are some drawbacks: All these drawbacks arise because before 5.0 there is no intermediate representation of a query within elasticsearch, only the raw JSON request and the final Lucene query. The latter can only be created on the shards, because Lucene queries are not serializable and often depend on context information only available on the shard. By the way, this is actually true not only for the \"query\" part of the search request, but for many other things like aggregations, suggestions etc.. that can be part of a search request. So, wouldn't it be nice to be able to parse queries to an intermediate representation once and early? That way we would be able to eventually rewrite them, and optimize their execution, for example by shortcutting them to queries that are less expensive.What we didFor the queries we achieved this by splitting the query parsing into two phases: As a result of the split, the code is better organized as parsing is decoupled from lucene query generation. Having a serializable intermediate format for queries meant that we had to write serialization code for all of the queries and search sections supported in elasticsearch. Also, every query implements `equals()` and `hashCode()`, so that they can be compared with each other for easier caching and to aid their testing.Once we moved parsing to the coordinating node, we could also move some validation to earlier stages of a search request and throw one single error earlier. Validation applies to malformed queries in terms of invalid json, queries that are missing some of their required values, or queries with invalid values provided.In order to make all those changes in a safe way that doesn\u2019t break existing behavior, we wrote extensive unit tests. For each query, we added to verify that it can be properly parsed and serialized, added tests that the resulting lucene query is the expected one and also test explicitly that all of the required values are checked and validated correctly. In order to do so, we created a which provides the code necessary for test setup and has some abstract methods that only need to be filled in for each individual query. This base class is shipped as part of our test framework helping downstream developers of custom queries with testing.Most of our query parsing code had low unit test coverage before the refactoring. For example, the `org.elasticsearch.index.query` package that contains all the QueryBuilder and QueryParser classes had only 47% test coverage (actually, with randomized testing we cover more over time, these numbers refer to the coverage in one CI run) before the refactoring, going to above 77% coverage after the refactoring branch was merged.How we did itThis query refactoring was really a that needed a proper feature branch. Initially we thought it could be enough to only refactor the query part of the search request, but in the end we went for refactoring almost all parts of the search request. The branch stayed alive for several months and we took care of merging master in daily (or at least twice a week). In some cases we found bugs that we fixed upstream rather than on the branch, to get them out with regular releases as soon as possible.As a team working on the feature branch, we decided to essentially replicate the development model of how we work on Elasticsearch master: instead of trying to plow through all changes needed and having an enormous bulk review at the very end, each change was submitted and reviewed as a small, manageable pull request against the branch. Having a closely knit team dedicated to this work, we could agree early on the goals of the changes, coding and architectural standards. This later made finding a reviewer familiar with those goals easy and made review cycles faster.Given the amount of code that this refactoring touched, the challenging part was to keep the branch healthy while the task was in progress. We had to sit down and come up with some incremental steps to run tests while the refactoring was still in progress. It was all a matter of introducing the new functionality gradually, while leaving the old infrastructure \u00a0alive until there was a complete replacement for it. Initially we introduced the two phase parsing but it all still happened on the data nodes rather than on the coordinating node. When all queries were migrated, we were able to move parsing to the coordinating node and start working on the remaining sections of the search request (e.g. rescore, suggestions, highlighting and so on).Lessons learntAfter several months of wading through code that was originally written by multiple authors and at very different times through the evolution of the code base, we learned a couple of things: ConclusionAll in all, the improvements made with this large refactoring become obvious when we need to go back to the old 2.x branch now and then to backport something from the current main development line. Not only has the parsing infrastructure become much more efficient, but introducing the intermediate query representation and decoupling parsing from query creation has lead to much cleaner code and the new test infrastructure makes debugging of parsing-related problems and writing new test much easier. But the most important thing is, that we are now able to analyze, rewrite and optimize search request on the coordinating node much more easily. Features like \u201cinstant aggregations\u201d that were long talked about, but never tackled because of the months of work required, suddenly became possible to implement quickly. In an upcoming blog post we will shed some more light on what this feature is and how it works. \n"}
{"index": {"_id": 502}}
{"title":"Brewing in Beats: HAProxy module in Metricbeat","seo_title":"","url":"\/blog\/brewing-in-beats-haproxy-module-metricbeat","author":{"name":"Tudor Golubenco"},"date":"September 14, 2016","category":"Brewing in Beats","locales":"","content":" Welcome to Brewing in Beats! With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources. Metricbeat: new HAProxy module Thanks to a community contribution by , Metricbeat got an \ud83c\udf89 Filebeat: The return of the Symlinks Filebeat used to somehow unintentionally follow symlinks when opening files. So we deprecated them in 1.3 and were planning to remove the support for symlinks in 5.0. However, we\u2019ve got some pretty strong pushback from Kubernetes users (K8s uses symlinks to), so we\u2019ve listened and . However, the symlink support is off by default and marked as experimental at this point. Filebeat: close_removed and clean_removed are now on by default This will keep the registry file from growing to quickly. For background: in 1.x the registry file was a map using the filename as a key. In 5.x the registry file is a list. A side effect of this change is that the registry file grows even if the same file names are reused (think of the usual syslog file names). By making , we\u2019re making sure the registry file stays small. Metricbeat: Improvements to the MySQL module A community contribution by adds several to the MySQL module in Metricbeat. Store the version in the Elasticsearch templates We now of the Elasticsearch templates we provide. This can help with troubleshooting and perhaps we could use it in the future to provide automatic mappings upgrades. import_dashboards: automatically select the right Beat Now that the import_dashboard scripts were rewritten in Go and download the beats-dashboards package when executed, we wanted to make sure that it does the \u201cright thing\u201d when called without any arguments. So we now the at build time to have a different `-beat` argument depending on the package. Packetbeat: Improve handling of HTTP messages larger than 10MB Old implementation dropped messages larger than 10MB (hard coded), to protect against memory DoS. However, in some cases the transaction was still recorded, but the parsing of the headers was incomplete. makes the support for large messages explicit, by adding a mode to the parser that \"sees\" the segments without storing them. \n"}
{"index": {"_id": 503}}
{"title":"Monitoring Container Resource Usage with Metricbeat","seo_title":"","url":"\/blog\/monitoring_container_resource_usage_with_metricbeat","author":{"name":"Andrew Kroh"},"date":"September 14, 2016","category":"Engineering","locales":"","content":" - Monitoring Container Resource Usage with Metricbeat === is a new addition to the Beats lineup for the 5.0 release. It is a lightweight shipper for host and service metrics. Metricbeat is replacing Topbeat in the 5.0 release, and it incorporates all of the metrics provided by Topbeat plus many more. One of the capabilities of Metricbeat is the ability to collect control group metrics from the Linux kernel. Control groups, which are more commonly referred to as cgroups, are for allocating resources (i.e. cpu, memory) to a process or set of processes and metering resource usage. This feature is brand new and will be released in Metricbeat 5.0.0-beta1. The feature itself is still evolving and for that reason it is marked as experimental. As we receive feedback there may be enhancements to the metrics it reports. How do I enable cgroup metrics in Metricbeat? To enable the cgroup metrics you must add as part of the system module definition within your Metricbeat configuration file. metricbeat.modules: - module: system metricsets: [process] cgroups: true If you are planning to deploy Metricbeat in a container there are some additional configuration items to be aware of. The full details are in the Metricbeat documentation, see the section titled . But in short, you need to mount both the host machine\u2019s proc filesystem and the cgroup filesystem inside of the container. Here\u2019s an example using Docker (you will need to provide your own container image). sudo docker run \\ --volume=\/proc:\/hostfs\/proc:ro \\ --volume=\/sys\/fs\/cgroup:\/hostfs\/sys\/fs\/cgroup:ro \\ my\/metricbeat:latest -system.hostfs=\/hostfs How are cgroups related to container monitoring? Each container is assigned to a cgroup which allows for limiting and metering resource usage of the process running in the container. We can use this fact to collect detailed metrics from processes running inside containers. The benefit of collecting container metrics directly from cgroups is that it works with any container tool (e.g. Docker, rkt, runC, LXC, systemd). Metricbeat reads directly from the cgroup pseudo filesystem provided by the Linux kernel, so it has no dependency on the APIs provided by container tools (which are subject to change between releases). As with any design decision, there is a tradeoff for not using the container tool APIs. Metadata that is only known to the container tool (e.g. names and labels) cannot be read by Metricbeat. We will be addressing this limitation in the future. What kind of metrics can cgroups provide? Control groups provide a wealth of information about resource usage. Metricbeat reports both the limits assigned to the cgroup (if any) and the statistics captured by the cgroup. You can view a here. These are the areas that Metricbeat focuses on: For a detailed look at the metrics reported by Metricbeat, have a look at the . Metricbeat sends all of this data as part of the system process metricset. This means that Metricbeat is providing a process centric view versus a container centric view. Metricbeat examines each process and includes the cgroup metrics if the process is a member of a (non-root) cgroup. If you are running one process per container then a process centric view of the data is equivalent to a container centric view. But if you run multiple processes per container then there will be some duplication of the cgroup metrics among the processes running in the same container. Generally the container ID is used as the name of the cgroup. Metricbeat stores the cgroup name in the field. This value can be used to associate the data to a specific container. If you have any Metricbeat related questions or feature requests, please connect with the Beats engineering team on . \n"}
{"index": {"_id": 504}}
{"title":"The tale of caching and why it matters\u2026","seo_title":"The tale of caching and why it matters\u2026","url":"\/blog\/the-tale-of-caching-and-why-it-matters","author":{"name":"Simon Willnauer"},"date":"September 13, 2016","category":"Engineering","locales":"","content":" It\u2019s early 2013 and an unusually sunny day in Amsterdam and a group of people are meeting around table soccer and ping pong tables for what we call a company all-hands. Just recently Rashid Khan, one of the big characters behind Kibana, joined Elastic and we are still just a handful of engineers. I\u2019m hacking around trying to get checksums to work for recovery, listening to a conversation between Shay and Rashid. It\u2019s Kibana\u2019s initial dashboard slowness that causes this intense conversation. Even though Kibana fires up almost identical searches each time you open the home page, elasticsearch has to recompute everything from scratch. Someone might ask, no caching eh? True! A closer look under the hood shows that searches are almost the same, but are subject to this annoying property of time: it never stands still. If you have used Kibana yourself you might have realized that a default filter is always based on the current time (NOW) going backwards for a defined time range. In other words you never fire the same query more than once a millisecond. Then the discussion got serious: Rashid and Shay started talking about caching and adding REST level primitives to control the cache key. Time to stop working on checksums: I gotta get involved! If you try to solve one of the hardest problems in computer science and the discussion is heading towards allowing the user to control it, you are either a really brave engineer or all other options would require you to be a hell of a brave engineer! The discussion continued for a while and ideas basically went through the roof. \u00a0You might have experienced this in your day to day job before. Luckily, we had so many other problems to solve at that time that we just dropped the ball on it for a while. Fast forward: it\u2019s October 1st and my calendar says \u201cThe Dudes are in Berlin\u201d meaning that Shay and a bunch of other team leads were coming into town for some planning sessions. That\u2019s usually an intensive time in a distributed company like Elastic since we don\u2019t meet in person more than twice per year. After 3 days of discussions, brainstorming and arguing Shay and I went out for Schnitzel to this awesome Austrian place near my house. Honestly, neither Shay nor I were really up for any more discussions but suddenly the caching thing came up again. I don\u2019t blame anybody: I\u2019m not sure who opened that particular can of worms. Anyway, this time we came up with a plan! Admittedly, not low hanging fruit, but something that could actually work well, is fully transparent, easy to test and can be disabled if it\u2019s not working. You noticed that escape hatch, did you? Caching is hard but let me explain what we had in mind. Bear with me, I\u2019m going to take a big swing: Elasticsearch is based on Apache Lucene\u2122 which works based on point-in-time view of an index. Such a snapshot is basically a set of write once index segments, each holding a subset of the indexed documents. The software construct we use to represent such a snapshot is what we call a \u201ctop-level\u201d indexreader. We know that, unless the top-level reader changes, queries are idempotent or in other words, cacheable. In Elasticsearch there is exactly one Lucene index per shard, so we can simplify things to use one top-level reader per shard. Now, if we can identify the outer bounds of an index for any date field we could also make much better decisions if for instance all or even no documents at all would match a certain filter and therefore could rewrite the query to \u00a0or match-no-docs respectively. If we could manage to do that then we could put queries that appear to be un-cachable into the we added basically just before that Schnitzel brainstorming session. The request cache utilizes Lucene\u2019s top-level reader as well as the search request\u2019s binary representation (the plain unmodified JSON, YAML or CBOR bytes) as a combined cache key. This allowed us to minimize the space requirement at the same time as minimizing the number of objects to represent a cache entry. Back to the idea, the main driver of it was a in Lucene that allows us to fetch the upper and lower bounds of a field from a top-level reader. With this information we could do anything you could possibly imagine with a query that has time properties. You can imagine when two engineers get excited over Schnitzel and caching is involved it ain\u2019t gonna end well. With all that excitement I went and asked to give the idea a shot. Mike pulled off a quite quickly. As usual after all that excitement we had to face reality, but the basic idea worked, YAY! Well, reality was that the prototype worked but it was far from anything that could go into production any time soon. We had to realize that to effectively modify queries in a generic and safe way (both are good properties to have if you want to use something as a cache key) we need an intermediate representation for our entire request constructs. At this point we had no way to parse the request, modify it and write it back out into a byte representation that can be used as a cache key. This was kind of a downer for all of us since we had to face the fact that each of these ~70 queries, aggregations, suggest, highlight, sort, etc. classes had to be refactored in order read, normalize, modify and write back its values. What could possibly go wrong. Is this worth the trouble?After that prototype and the reality check that our code wasn\u2019t ready we needed to talk about the exciting possibilities again. When you look at your code and you realize you have to basically invest 6 month worth of engineering time to make the first step towards a new feature you think twice about whether it\u2019s worth it. That said, with the immense growth of time-based data and how the data is structured on a macro level it became obvious why it would make sense to invest in solutions that are done the right way. A typical installation of logging data might have daily indices spanning period of a week or a month. Searches typically span all indices in that time range but, except for the current daily index, all other indices are static: they don\u2019t receive any changes anymore and therefore they maintain the same point-in-time snapshot. This means we\u2019d get 100% cache hits if queries included the entire day for each shard. In other words we could reduce the search workload for these machines dramatically and kibana dashboards would appear instantly. Well, these were convincing arguments, so now it was time to get things started. In March 2015 we started prototyping how we could represent queries and write them back out. Nobody knew that it would take another 12 months for all the needed parts to come together and yet another 6 months for this feature to be released in an alpha release. I won\u2019t tell the rest of the story because I want to leave that to the hard working folks who implemented all these changes. So, stay tuned for the upcoming articles in this series. \n"}
{"index": {"_id": 505}}
{"title":"Announcing Annual Discounts for Elastic Cloud Standard","seo_title":"","url":"\/blog\/announcing-annual-discounts-for-elastic-cloud-standard","author":{"name":"Tyler Hannan"},"date":"September 12, 2016","category":"News","locales":"","content":" The current forecast?Cloudy with a 15% annual discount. If you haven\u2019t perused our , you may be unaware that we sell hosted Elasticsearch in 3 ways. These subscription levels are Standard, Gold, and Platinum. They are distinguished by features and different SLAs for support. For the purpose of this post, I want to focus exclusively on Cloud Standard, our most affordable feature-packed offering. Starting Simple, Starting Small, Full AccessAs the creators of Elasticsearch, our support team is backed by the engineers who wrote the code. And, for critical use cases, this is an incredibly important requirement. However, we know that the business of hosted products differs slightly. The ability to start small and expand on demand is an assumption for any \u201chosted\u201d or \u201cSaaS\u201d or \u201cother cloudy term\u201d offering. With that in mind, we believe Cloud Standard is a fantastic starting point for those looking for a hosted Elasticsearch solution.Does your cluster require less than 64 GB of RAM in total? All Platinum X-Pack Products & Features (including Field & Document-level security and Graph) are available for no additional cost. And, starting last week, annual subscriptions of Cloud Standard enjoy a 15% discount on the total cost. The math is simple. Design the cluster you desire in the , then apply the discount and calculate the annualized cost. You can get the details, and sign the contract, by . But why a discount for annual customers? Put simply, we believe that Elastic Cloud is the best hosted Elasticsearch service around. And, for those of you who desire an ongoing relationship, we want to recognize your commitment with a discount. Don\u2019t dismay. The hourly pricing isn\u2019t going away.\u00a0But it doesn\u2019t stop there. Infrastructure Matters. Here Are Some Updates to Ours. Is there a manager or business user in your life who just wants to see a report -- either periodically or at a scheduled interval -- in their email? Reporting matters, so much so that we wrote an entire about it. What we didn\u2019t share in that post is that the reporting release required rethinking Kibana instance sizing (Yeah, Elastic Cloud comes with Kibana) and ensuring that the asynchronous report process would not negatively impact the experience of usage of Elasticsearch and visualization and discovery in Kibana. Report away in Cloud. You want \u2018em? \u00a0You got \u2018em. Our approach to expanding available regions has been simple. Let you, the user, tell us what is the priority. There has been enough feedback on a specific region, that we will be adding the ability to launch Elastic Cloud clusters in soon. Getting the latest release, on the day of release, simply isn\u2019t enough. We\u2019re starting to expose milestone releases on Cloud as well, so you can kick the tires of the cutting edge. This requires a substantial amount of tooling and work with our build process and will be first realized with the release of 5.0 RC1 for public consumption on Elastic Cloud. (Still not familiar with 5.0 or the ? You should be.) \u00a0The goal is to be \u00a0able to expose nightlies. (Do you test nightlies or use updated, non-release software in your environment? Soon you can in Cloud.) Seeing is Believing. Coding is Understanding.We have long said that the best way to understand the Elastic Stack is to use it. The same is true for Elastic Cloud.\u00a0 It is simple, really simple.It is powerful, absurdly powerful.It is -- now -- cheaper, 15% cheaper. \n"}
{"index": {"_id": 506}}
{"title":"Logstash Lines: Monitoring API, Logging Enhancements, S3 Output changes","seo_title":"","url":"\/blog\/logstash-lines-2016-09-12","author":{"name":"Suyog Rao"},"date":"September 12, 2016","category":"The Logstash Lines","locales":"","content":" Welcome back to The Logstash Lines! In these weekly posts, we'll share the latest happenings in the world of Logstash and its ecosystem. PUT _node\/settings {\"logger.logstash.output.elasticsearch\" : \"error\"} GET _node\/logging?pretty { .... \"loggers\" : { \"logstash.registry\" : \"WARN\", \"logstash.instrument.periodicpoller.os\" : \"WARN\", \"logstash.instrument.collector\" : \"WARN\", \"logstash.runner\" : \"WARN\", \"logstash.inputs.stdin\" : \"WARN\", \"logstash.outputs.stdout\" : \"WARN\" ... } } This project is nicely. Last week we got all the core unit tests to pass with the in-memory queue infrastructure. Integration tests are yet to be added which will use the real file-backed queue. Plan is to merge this feature branch to master in 2 weeks, following a code review.PH is working on adding tons of improvements to this output to make it easier to maintain\/test. We're also adding popular such as \u2014 using event based data to determine the target S3 bucket\/location. Like Also, updating to AWS ruby client v2 should fix many bugs and knock off some enhancements like multi-threaded uploader. Suffice to say, this plugin needed some love. \n"}
{"index": {"_id": 507}}
{"title":"Elastic Support: An Investment That Keeps Paying Off at Symantec","seo_title":"Symantec's Elasticsearch Support Story","url":"\/blog\/elasticsearch-support-an-investment-that-keeps-paying-off-at-symantec","author":{"name":"Lauren Johnson"},"date":"September 08, 2016","category":"User Stories","locales":"","content":" Even with 18 years of search experience and a PhD in computer science, this senior Symantec engineer finds value in Elastic\u2019s dedicated support and training. ***** ***** After we decided to migrate to Elasticsearch, I needed to learn more about it because I hadn't used it before. I could learn a lot of stuff on my own, but I signed up for a training session and gained more knowledge quickly. \u00a0 Then we signed up for a . I started with some small tickets and then they got more interesting as time went on. I knew Greg only through the support ticket system at first, and we had a good rapport there. Then we met at Elastic{ON}, which helped further develop our relationship. The initial questions and tickets were pretty much about standing up clusters and all the little gotchas that you encounter when you're trying to get everything up, running, and tuned to the point where you\u2019re getting acceptable performance. You\u2019re not getting crashes or the standard newbie kinds of things that happen when you're picking your way through the landscape for the first time. It\u2019s a teaching process, so as Geena and Symantec became more comfortable with things in the early tickets, they could move on to more connected, complex scenarios, and now they\u2019re using the product in new and interesting ways where we can help. And because we have engineers who are extremely deep and know the internals of the products, support saves Symantec time and effort. You don't go down a path where you say, \u201cThis looks fine now,\u201d but in another two or three years, you think, \u201cOh, wow, I wish I hadn\u2019t done that.\u201d We help you find those things way in advance. You can\u2019t underestimate the value of something like that. As Greg said, it\u2019s an educational process. I started at Symantec two years ago, and at this point I\u2019m considered the Elasticsearch expert in this 10,000-employee company. I did three , I went to , and I filed a lot of tickets. That really got me here \u2014 plus the , but the documentation only tells you what you can do. When you\u2019re trying to figure out what you want to do for your use case, it\u2019s helpful to have Elastic support. I've used Lucene directly for years, so I don't file tickets about data modeling or analyzers, but about the distributed system. For example, we had a system where we were doing event logging from security events, so all the machines out there from our customers were sending us events like \u201cAntivirus definitions were updated\u201d or \u201cThere was a failed phishing attack.\u201d We have a daily index that we can search and aggregate on that data. We noticed that some of our queries that searched more than 14 days worth of events were really slow. Not only were they slow, but we were getting search rejections because the queue was filling up. So I put in a ticket for that. I asked, \u201cWhy is the queue filling up? It\u2019s only 14 days.\u201d Greg writes back and explains that it depends on how many shards you search, so if you have five shards in 14 days, that multiplies out to 70 shards. And if you search 90 days of shards, it\u2019s pretty much hopeless. What happens is that when you do a search, it creates an item on the thread queue for each shard that you search. Then it really adds up. Coming to understand this was really important for getting our application to work with many users searching at the same time. Geena and her team are fairly adept, so they don\u2019t necessarily need a lot of guidance on the things that are mapped out explicitly. What they generally come to me for are explanations of how things work. Like, how does the number of shards that you have impact your actual search, especially when you have this many indexes? Or, when you get a rejection, what\u2019s the process going on behind the scenes in the actual execution queues? How are those things queued up, and why do you get a rejection versus the next one going through? Things like that. It\u2019s a more consultative relationship. It\u2019s a conversation, and at the end, the results of the conversation tend to present the solution. The educational part makes it worthwhile, like learning not just the number of shards to use but why. I can do that for a lot of use cases now, we can make good decisions, and some shard counts are going to be different for different use cases. The Elastic ecosystem keeps expanding with new features and products. Now that I consult for so many Norton Engineering product groups, I need to learn quickly. Having a dedicated support engineer is having a mentor that helps me grow. This gives me confidence in my technical knowledge when speaking with my engineering colleagues at Symantec. The best thing I can say is that even though I have a PhD in computer science and I've been doing search applications since 1998, I still get a lot of value out of Greg's support. Even after two years, I'm just running into more interesting challenges, and it keeps paying off.\u00a0 \n"}
{"index": {"_id": 508}}
{"title":"Strings are dead, long live strings!","seo_title":"Elasticsearch replaces string type with two new types text and keyword.","url":"\/blog\/strings-are-dead-long-live-strings","author":{"name":"Adrien Grand"},"date":"September 07, 2016","category":"Engineering","locales":"","content":" Text vs. keywordWith the release of Elasticsearch 5.0 coming closer, it is time to introduce one of the release highlights of this upcoming release: the removal of the type. The background for this change is that we think the type is confusing: Elasticsearch has two very different ways to search strings. You can either search whole values, that we often refer to as keyword search, or individual tokens, that we usually refer to as full-text search. If you are familiar with Elasticsearch, you know the former strings should be mapped as a string while the latter should be mapped as an string. But the fact that the same field type is used for these two very different use-cases is causing problems since some options only make sense for one of the use case. For instance, makes little sense for a string and it is not obvious whether applies to the whole value or to individual tokens in the case of an string (in case you wonder: it does apply to the value, limits on individual tokens can be applied with the token filter). To avoid these issues, the field has split into two new types: , which should be used for full-text search, and , which should be used for keyword search. New defaultsAt the same time we did this split, we decided to change the default dynamic mappings for string fields. When getting started with Elasticsearch, a common frustration is that you have to reindex in order to be able to aggregate on whole field values. For instance imagine you are indexing documents with a field. Aggregating on this field would give different counts for and instead of having a single count for which is usually the expected behaviour. Unfortunately, fixing this problem requires to reindex the field in order for the index to have the correct structure to answer this question. To make things better, Elasticsearch decided to borrow an idea that initially stemmed from Logstash: strings will now be mapped both as and by default. For instance, if you index the following simple document: { \"foo\": \"bar\" } Then the following dynamic mappings will be created: { \"foo\": { \"type\" \"text\", \"fields\": { \"keyword\": { \"type\": \"keyword\", \"ignore_above\": 256 } } } } As a consequence, it will both be possible to perform full-text search on foo, and keyword search and aggregations using the field. Disabling this feature is easy: all you need to do is to either map string fields explicitly or to use a dynamic template that matches all string fields. For instance the below dynamic template can be used to restore the same dynamic mappings that were used in Elasticsearch 2.x: { \"match_mapping_type\": \"string\", \"mapping\": { \"type\": \"text\" } } How to migrateIn most cases, the migration should be pretty straightforward. Fields that used to be mapped as an string { \"foo\": { \"type\" \"string\", \"index\": \"analyzed\" } } Now need to be mapped as a field: { \"foo\": { \"type\" \"text\", \"index\": true } } And fields that used to be mapped as a string { \"foo\": { \"type\" \"string\", \"index\": \"not_analyzed\" } } Now need to be mapped as a field: { \"foo\": { \"type\" \"keyword\", \"index\": true } } As you can see, now that fields have split into and , we do not need to have 3 states for the property (, and ), which only existed because of string fields. We can use a simple boolean in order to tell Elasticsearch whether searching the field should be possible. Backward compatibilityBecause major upgrades usually have their own challenges, we did our best not require you to upgrade all mappings at the same time as you upgrade your cluster to Elasticsearch 5.0. First, the field will keep working on existing 2.x indices. And when it comes to new indices, Elasticsearch has some logic that will make it automatically convert string mappings to an equivalent or mapping. This is especially useful if you have index templates that add mappings with string fields: these templates will keep working with Elasticsearch 5.x. That said, you should still look into upgrading them since we plan on removing this backward compatibility layer when we release Elasticsearch 6.0. \n"}
{"index": {"_id": 509}}
{"title":"New features in Curator 4.1","seo_title":"New features in Curator 4.1","url":"\/blog\/new-features-in-curator-4-1","author":{"name":"Aaron Mildenstein"},"date":"September 07, 2016","category":"Releases","locales":"","content":" I am very pleased to announce the release of ! \u00a0There are some new features I\u2019m excited to tell you about. \n"}
{"index": {"_id": 510}}
{"title":"Dockbeat: A new addition to the Beats Community","seo_title":"Dockerbeat: A new addition to the Beats Community","url":"\/blog\/dockbeat-a-new-addition-to-the-beats-community","author":{"name":"Erwann Cloarec"},"date":"September 07, 2016","category":"User Stories","locales":"fr-fr","content":" : The previously published article has now been modified to reflect the name change from DockerBeat to Dockbeat.Dockbeat is an open source project created by , based on the Beats platform. Ingensi is a business unit of located in France. Our main goal is to create big data solutions offering powerful decision-making tools to unveil the value in the customer\u00a0data. For that, we employ our technological expertise in Hadoop, Elasticsearch, and Docker. At Ingensi, we use the Elastic Stack as the basis of our log management solution. We also use Elasticsearch as a search engine in our application as we need fast responding searches. Docker Big Data platform: Ingensi meets DockerFor resource optimization reasons, when we receive a cluster deployment request from our customers, we deploy it in a shared big data infrastructure based on . In 2015, we had our first shared big data infrastructure deployed and we naturally used the Elastic Stack to monitor the entire platform: hosts, network, users, etc. However, our processing workflow did not allow us to monitor Docker containers. That\u2019s when comes into play! The Beats platform allows you to build lightweight data shippers for different types of data that you can search and analyze in Elasticsearch, and visualize in Kibana. From there, we had the idea to create our own beat to collect Docker statistics. Hello, Dockbeat!Since the release of Docker 1.5., a new functionality was added to Docker's API: Docker stats. This endpoint returns a live stream of a running container's resource usage statistics, such as CPU, memory, network, disk IO, etc. Therefore, we've decided to collect all these metrics in order to capitalize on the use of our existing Docker infrastructure. Based on the Beats platform, we started to develop our own Beat: Dockbeat. How does Dockbeat work?Dockbeat is used for Docker monitoring. It is responsible for collecting the containers' statistics and send them to Logstash or directly to Elasticsearch. As it is very lightweight, Dockbeat\u2019s impct on the server is very low. The collected\u00a0data can then be visualized in\u00a0a\u00a0Kibana\u00a0dashboard. Today, we are able to view in real time all the containers running on our servers, their consumption, and thus, quickly identify any anomalies. This new beat exports five types of documents corresponding to the different metric sets collected : Great! How can I use Dockbeat?Simple:\u00a0Dockbeat is hosted on . You first need to clone and build the project (see\u00a0)\u00a0or simply\u00a0 you need. In a basic Docker installation, Dockbeat should work out of the box with its default configuration. If you have your own settings, check the configuration file dockbeat.yml. In this file you can configure:\u00a0 There is no specific configuration\u00a0to be edited, unless you need to enable the TLS docker daemon. Finally, you can launch your beat by running the following command : .\/dockbeat -c etc\/dockbeat.yml Dockbeat todayDockbeat grew up and became operational. Today, we are happy to announce the It's an open source project and we love to receive contributions from the community. You can contribute to\u00a0Dockbeat in many ways:\u00a0 So, feel free to contact us for further information or contributions, we will be happy to hear from you. The Team is a Big Data Engineer , Docker passionate, Elastic fan and Hadoop professional, Dockbeat co-creator. is a Software Engineer . Interested in Big Data and OpenSource technologies, Docker & Elastic enthusiast, Dockbeat co-creator. is an Engineering Student in final year. Curious and ambitious, she\u00a0loves to discover new intelligent technologies. Elastic fan. She's the blog post author\u00a0and a\u00a0Dockbeat contributor. \n"}
{"index": {"_id": 511}}
{"title":"Kibana 4.6.1 and Reporting 2.4.1 released","seo_title":"Kibana 4.6.1 and Reporting 2.4.1 released","url":"\/blog\/kibana-4-6-1","author":{"name":"Court Ewing"},"date":"September 06, 2016","category":"Releases","locales":"","content":" Today we\u2019re releasing Kibana version 4.6.1, which includes a fix for a regression that we introduced in last week\u2019s release, and Reporting version 2.4.1, which includes a high severity security fix. We recommend that users upgrade as soon as possible. Users of Elastic Cloud will get these updates automatically. Upgrading To upgrade Kibana, follow the instructions in the . If you had previously installed Kibana 4.6.0 with apt or yum, you should be able to upgrade Kibana through your package manager instead. To upgrade Reporting, uninstall the current version and reinstall version 2.4.1: The Changes The that was fixed in 4.6.1 would cause a fatal error whenever an aggregation would order by Term. Reporting 2.4.1 includes a fix for a CSRF vulnerability () that could allow an attacker to generate superfluous reports whenever an authenticated Kibana user navigates to a specially-crafted page. Conclusion You can grab Kibana from the page. If you have any questions, please don\u2019t hesitate to reach out to us on our , , or . \n"}
{"index": {"_id": 512}}
{"title":"Brewing in Beats: New community Beat for RETS","seo_title":"","url":"\/blog\/brewing-in-beats-new-community-beat-for-rets","author":{"name":"Monica Sarbu"},"date":"September 05, 2016","category":"Brewing in Beats","locales":"","content":" New community Beat: Retsbeat We\u2019re the Packetbeat functionality that maps IP address to host names using Elasticsearch or Redis as a backend. While this can be useful functionality, the current implementation is limited (only works with the Elasticsearch and Redis outputs) and it's done in the wrong place (outputs). We do hope to have a better implementation before or soon after removing the current one. \n"}
{"index": {"_id": 513}}
{"title":"Release Bonanza! Elasticsearch, Graph, Shield, Watcher, Marvel, Reporting, Logstash 2.4, Beats 1.3, and Kibana 4.6 are Now Available!","seo_title":"","url":"\/blog\/release-bonanza-elasticsearch-graph-shield-watcher-marvel-reporting-logstash-2-4-beats-1-3-and-kibana-4-6-are-now-available","author":{"name":"Tyler Hannan"},"date":"August 31, 2016","category":"Releases","locales":"ja-jp","content":" The returns! The train rolls on! Other release related sayings! \n"}
{"index": {"_id": 514}}
{"title":"Kibana 4.6.0 released","seo_title":"Kibana 4.6.0 released","url":"\/blog\/kibana-4-6-0-released","author":{"name":"Matt Bargar"},"date":"August 31, 2016","category":"Releases","locales":"","content":" The newest version of Kibana is here and it\u2019s got something for everyone. Linux packages have seen major improvements and Kibana 4.6.0 adds support for the much anticipated Reporting plugin. As usual, this release of Kibana supports the latest and greatest version of Elasticsearch (2.4.0) allowing you to upgrade your Elastic Stack with ease. Read on for more details about what\u2019s new or dive right in by grabbing the now. \n"}
{"index": {"_id": 515}}
{"title":"Elasticsearch 2.4.0 released","seo_title":"Elasticsearch 2.4.0 released","url":"\/blog\/elasticsearch-2-4-0-released","author":{"name":"Clinton Gormley"},"date":"August 31, 2016","category":"Releases","locales":"","content":" Today we are pleased to announce the release of based on . This is the latest stable release and is already available for deployment on , our Elasticsearch-as-a-service platform. Latest stable release: Full details of the changes in this release are available in the release notes listed above, but this release contains two important changes which are worth mentioning: \n"}
{"index": {"_id": 516}}
{"title":"Logstash 2.4.0 released","seo_title":"","url":"\/blog\/logstash-2-4-0-released","author":{"name":"Suyog Rao"},"date":"August 31, 2016","category":"Releases","locales":"","content":" We are pleased to announce that Logstash 2.4 has been released. Please see the for a detailed change report and you can binaries on our products page. New Plugin API Compatibility While 2.4 does not have many headlining features, it's an important release that brings in key internal API changes. These changes make 2.4 compatible with plugins developed for. In other words, Logstash 2.4 will be able to install most\u00a0plugins that use the 5.0 API. As maintainers, this API backport eases efforts which mean we don't have to maintain 2 separate code branches for each plugin. We have a\u00a0of plugins. The Logstash 2.4 release enables\u00a0new plugin features that are not available in the remaining 2.x series. We've recently updated a bunch of plugins to add new functionality. A popular enhancement request has been to bring in new features in Kafka's 0.9.x and 0.10.x releases like . In 2.4, we don\u2019t package Kafka input\/output plugin versions that support newer Kafka versions (see the ). This is because most config options for these plugins have been changed which makes it not compatible, and we don't intend to break configurations in point releases. If you still want to get all the goodness of the latest Kafka versions in 2.4, fear not. You can simply install the plugin on top of 2.4, like so: bin\/logstash-plugin install \u2014version 5.0.4 logstash-input-kafka This is just an example. Like Kafka, there are many plugins which have been updated. They'll be packaged in our upcoming 5.0 release, but if you can't wait, you can always install them on top of 2.4. Please review the changelog for individual plugins before upgrading to them. has been reimplemented using Netty, an asynchronous IO framework for Java. This rewrite for performance brings it in line with Logstash Forwarder + LS combination. In some test cases, it is faster. Go on, migrate all your LSF instances to the Filebeat goodness. I've heard Filebeat 5.0 is packed with features, so you don't want to miss out on that. As part of the Beats refactor we now\u00a0only supports private keys in the format, you can use to convert them, newer version of OpenSSL will already create the key in the right format.\u00a0Oh and a note for our subscription customers \u2014 LSF will reach EOL on Nov 7, 2016.\u00a0 Back in the day, Logstash used to emit its logs in JSON format. Because of endless encoding issues and crashes in the logger, we had to roll it back. We've worked through most of these issues, so we're bringing structured logging back. You can tell LS to switch to JSON logging by using the CLI flag. Be aware that logging in JSON is verbose and may fill up disk even faster than before! Kibana. Beats. And now Logstash has it too! We're talking about the plugin generator tool that makes it easier to bootstrap new plugins for Logstash. Previously we've recommended developers to clone\/fork the, but now you can simply do: bin\/logstash-plugin generate --type input --name xkcd --path ~\/ws\/elastic\/plugins This subcommand bootstraps a new plugin logstash-input-xkcd with the right directory structure and all the required files (templates) for you to start developing this plugin right away. So, go on, create that input to stream those fine comic strips to Kibana! We are super excited for this release of Logstash and look forward to your feedback. You can reach us at our, open issues in your or twitter(). Happy 'stashing! \n"}
{"index": {"_id": 517}}
{"title":"Reporting 2.4.0 released","seo_title":"Reporting 2.4.0 Released","url":"\/blog\/reporting-2-4-0-released","author":{"name":"Joe Fleming"},"date":"August 31, 2016","category":"Releases","locales":"","content":" Reporting is a new product in our commercial lineup that allows you to easily generate PDFs of your Kibana searches, visualizations, and dashboards. It\u2019s great for getting a snapshot of your data and sharing it with anyone. If you attended or watched recordings from Elastic{ON} 2016, or if you\u2019ve been following our latest alpha releases, you know that we\u2019re shipping Reporting in 5.0. But we just couldn\u2019t wait to get it in your hands, so we decided to make it available even sooner, as a plugin for Kibana 4.6. Reporting has been a long time coming, and we\u2019re excited to make it available today, ahead of schedule. Using Reporting The Reporting plugin adds a new interface right inside Kibana that allows you to create a report based on what you have open. You can also use it with Watcher to trigger reports in response to an event, or simply have reports emailed on a set schedule - it\u2019s up to you. In fact, reports can be automated using any tool that can make an HTTP request. Reporting also includes a page under in Kibana that allows you to download (or re-download) generated reports. Scaling Reporting Reporting works in the background, in an asynchronous manner, using Elasticsearch as the source of truth. Kibana instances pointing at the same Elasticsearch cluster all work on the jobs together, allowing you to distribute your reporting jobs across multiple machines. If reporting jobs aren\u2019t being worked through fast enough, spin up another Kibana instance and double your reporting power. You can even start up extra instances based on demand, and shut them back down when you don\u2019t need them. One Last Thing The is a great place to go to begin using this feature and sharing reports. We\u2019re also excited to announce that Reporting is immediately available to all users of . All it takes is an upgrade to 2.4.0 and you\u2019re ready to generate reports. Want to learn more? to see the new feature in action. \n"}
{"index": {"_id": 518}}
{"title":"Elasticsearch, the server","seo_title":"Elasticsearch, the server","url":"\/blog\/elasticsearch-the-server","author":{"name":"Clinton Gormley"},"date":"August 30, 2016","category":"Engineering","locales":"ja-jp","content":" Back in early 2010, when the first version of Elasticsearch was released, the future (we were reliably informed) was orange. Or was it black? Or green? Nobody really knew. Nobody knew how the NoSQL space would envolve, nor how Elasticsearch would end up being used. Back then, we tried to have a horse in every race. You could talk to Elasticsearch with JSON, YAML, SMILE, CBOR, Thrift, and Memcached protocol. You could specify settings using JSON, YAML, Java properties, and environment variables. We logged to Log4J and SLF4J. There were three ways to configure mappings. And templates. And analyzers. Elasticsearch could run standalone or embedded. Your HTTP web servers could join the Elasticsearch cluster as real nodes. Plugins could override pretty much any part of Elasticsearch, replacing integral parts of the core. One of the things that made Elasticsearch so popular was its flexibility and its familiarity. It was easy to get started, and easy to integrate Elasticsearch into your application, no matter how unusual the design. Six years later, Elasticsearch has evolved into a powerful search and analytics engine. It has been downloaded by millions of people and is a core technology depended upon by hundreds of thousands of users and companies. Flexibility and leniency are no longer as\u00a0important as: Flexibility comes at a price: complexity. With so many alternatives it is impossible to test them all and to be sure that they actually work. Complexity interferes with the goals listed above. We can\u2019t have it all, so we have\u00a0to narrow our focus to be able\u00a0to deliver a solution that can be relied on. \n"}
{"index": {"_id": 519}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-08-29","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-08-29","author":{"name":"Michael McCandless"},"date":"August 29, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top News Had an awesome time presenting zero-downtime re-indexing of - slide deck: \u2014 Mahdi Ben Hamida (@mahdouch) Elasticsearch Core Changes in 2.x: Changes in master: Ongoing changes: Apache Lucene Watch This Space , where we'll share more news on the whole Elastic ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 520}}
{"title":"Brewing in Beats: Configurable Kafka partitioning strategies","seo_title":"","url":"\/blog\/brewing-in-beats-configurable-kafka-partitioning-strategies","author":{"name":"Tudor Golubenco"},"date":"August 29, 2016","category":"Brewing in Beats","locales":"","content":" Welcome to Brewing in Beats! With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources. Kafka output: configurable partitioning strategies The Kafka output in libbeat now several strategies for selecting the Kafka partition: hash, round robin, random. The hash partitioner works on a key configured via the string formatter (i.e. can be a field or a combination of fields). Long running Filebeat tests To detect potential issues with long running filebeat instances, a was created. Metricbeat is used to monitor Filebeat and report the open file handlers from the operating system to Elasticsearch. Log total internal metrics values on shutdown The Beats now on shutdown at INFO level. This completes the of reducing the log verbosity on INFO\/WARN while still providing the needed information for troubleshooting. Docs on Metricbeat container support Besides improving the documentation on cgroups, includes a on how to run Metricbeat in a container to monitor the other containers and the services they run. Packetbeat: IPv6 support for matching processes When running on the same host as the monitored application, Packetbeat can correlate the network traffic with the process that created the traffic based on data in the proc file system. This , coming from a\u00a0community contribution by , makes this work also when IPv6 addresses are involved. Packetbeat: display IP addresses when listing the devices Via another , this time by , the flag from Packetbeat now also lists the IP addresses. This makes it easier to figure out which device is which on Windows. Sample dashboards import\/export improvements We\u2019ve got for the scripts that we use to save, package, and load the sample dashboards. Fix panic on empty host array was affecting the libbeat Logstash output, in the master version only. \n"}
{"index": {"_id": 521}}
{"title":"Serverless Elasticsearch Curator on AWS Lambda","seo_title":"Serverless Elasticsearch Curator on AWS Lambda","url":"\/blog\/serverless-elasticsearch-curator-on-aws-lambda","author":{"name":"Toby McLaughlin"},"date":"August 26, 2016","category":"Engineering","locales":"","content":" In this post, we demonstrate how Elastic's Infrastructure team runs \u00a0as a serverless application on . We share the rationale, the tools, and of course, the code. Servers, Services, and ServerlessAs the team responsible for managing Elastic's internal systems, we want to build great systems without increasing the burden of system management. If we deploy a server instance to manage our existing infrastructure, we are creating overhead, which ultimately makes us less effective. To keep our overhead low and our effectiveness high, we often eschew \u00a0for \u00a0and more recently, \u00a0computing. Elastic Cloud We use Elasticsearch to store and analyse all sorts of things. We keep system metrics from , logging from Puppet, even a running history of our GitHub issues to track our performance as a service team.We use \u00a0for our Elasticsearch clusters. The Cloud service gives us Elasticsearch, without expanding our server footprint, and thus our management overhead. Serverless We also run a selection of tasks as \"serverless\" processes on Lambda. This article focuses on our serverless approach to running Curator. With all the time-series and log data we collect, we certainly have a need for Curator, but it would be a shame to run servers just to host it. LambkinGetting a function into Lambda in a repeatable, automated way is a reasonably complex task. We use our open-source tool to\u00a0reduce that complexity.\u00a0Lambkin creates skeleton functions on demand\u00a0and helps us publish, run, and schedule Lambda functions. The ProcedureHere, we will step through a process for setting up a serverless Elasticsearch Curator system identical to the one we use internally. The example is implemented in Python, the language used for both Curator and Lambkin. To follow along, you'll need a Python environment with the \"\u00a0command\u00a0available. Deep knowledge of Python is not required, however. The solution provided will run as-is, and is configurable for your environment by editing a simple YAML file. Let's go:Install Lambkin and virtualenvsudo pip install lambkin virtualenv Configure AWS credentials and default regionIf you don't already have your\u00a0AWS account configured, a simple way to do it is:sudo pip install awscli aws configureMore detail is available in the .Create a new skeleton Lambda function lambkin create serverless-curator cd serverless-curator In the new directory, you'll find some skeleton files. These files make up a valid, ready-to-run Lambda function in Python, and a context for managing any dependencies it might have. Create the Python functionThe primary file is\u00a0. It contains the body of our Python function. Feel free to examine it if you're interested. The function doesn't do much yet, but it's already possible to publish and run it on Lambda:lambkin publish --description='Just a test.' lambkin run You should then see some output from Lambda, ending with a JSON object returned by the sample function. Like this: {\"from\": \"Python\", \"hello\": \"World\"} Replace the skeleton function It's time to replace the example function with something more useful. Full source code for a working Curator function is provided in . The function makes use of a YAML configuration file where you can declare index patterns across multiple Elasticsearch clusters. Be sure to create the file . A \u00a0is also provided in the Gist. Install Python requirementsOur new function requires some library packages from the , so we need to ensure they will be available in Lambda. Edit the \u00a0file, changing its contents to: certifi==2016.8.8 elasticsearch-curator==4.0.6 PyYAML==3.11 Then install the packages: lambkin build The function's requirements are now installed. Lambkin uses \u00a0to ensure that each function\u00a0gets its own isolated dependencies. Publish and try the new versionWe'll also update the description, and set a long timeout in case we will be processing a lot of indices: lambkin publish --description='Elasticsearch Curator' --timeout=300 lambkin run The function will return (in JSON format), a dictionary showing which indices were deleted (if any). Schedule the function If you're happy with the results, Lambkin can arrange to have the function run on a regular schedule: lambkin schedule --rate '1 hour' At this point, you have a reliable, regularly scheduled Curator job running in a serverless environment. Now would be a great time to check your new function into version control. When you want to change the configuration, perhaps to accommodate new indices, just edit the YAML config, and do a \"\". Wrap UpIf you'd like to remove the\u00a0function from Lambda, try these commands:lambkin list-published lambkin unpublish --helpIf you'd like to explore Lambkin further, try \"\u00a0or come and join the conversation on . \n"}
{"index": {"_id": 522}}
{"title":"An Arduino-Based Home Weather Station on the Elastic Stack","seo_title":"An Arduino-Based Home Weather Station Built with Arduino, Elasticsearch, and Kibana","url":"\/blog\/arduino-based-home-weather-station-on-the-elastic-stack","author":{"name":"Issac Kelly"},"date":"August 25, 2016","category":"User Stories","locales":"","content":" I\u2019m far from a meteorologist. I\u2019m a hacker with a garage\/office that I spend way too much time in. I have a bias toward things that feel like data. A friend told me that I was maybe being a bit of a garage troll: I am tucked away from the sun and warmth. I decided that I needed to figure out if she was right. This was a perfect opportunity to dive into the Internet of Playful Things: Arduino for my weather measurements, Elasticsearch for storage, and Kibana for viewing and analysis. With off-the-shelf parts, open source libraries and a Saturday afternoon available, I got to work. I choose the ESP8266 more and more often lately. It\u2019s a microcontroller with WiFi capabilities that can be used by itself or with most other platforms. Folks have built compatibility layers for Node.js, Python, and Arduino with it. It has become a very popular device because of its price and capabilities. For only a couple bucks, you can add WiFi to any hobby hardware project. For about sixteen dollars, you can get a battery-powered Arduino and node\/lua-compatible development board. For this project I chose a board from . Elasticsearch and Kibana provide a very tidy combination for storing and visualizing the sensor data coming out of my hardware. Prebuilt modules from Adafruit make creating your own wireless weather station simple. Things you\u2019ll need Electronics Tools Nice to have Computer For Elasticsearch and Kibana, you can setup an instance on or you\u2019ll need to share a network with your devices and use a local instance of both. Hardware Build I recommend using a breadboard for most prototypes and temporary projects. The first step is to solder the header pins onto the board. Adafruit ships most of its modules without the pins soldered on. If you haven\u2019t soldered before, there are lots of really good guides to getting started. SparkFun has . If you\u2019re getting really into it you should dig into the . A note on soldering and tools: Most guides on how to solder are written by people who do it a lot. Like most other hobbies and professions, using good tools will make the job easier. It\u2019s also expensive. All you really need to get started is an iron, solder, and something to cut and strip wires with. Get better tools as you need them. My , yours might too. You might also have a which may be able to assist with tools, equipment, and techniques. My first toolset, which got me through about 10 years of experimenting. This sensor board uses SPI to communicate with the microcontroller. The ESP8266 has SPI support, so we hook up Data (SDA) and Clock (SCL) lines to the SDA and SCL lines of each board for communication. We also hook up the 3v and Ground (GND) lines to power sensor board. That\u2019s it! 4 wires is all we need. Arduino Software If you haven\u2019t already, download and install the Arduino IDE and ESP8266 Board Package. . You\u2019ll also need to install the libraries below. if you need help installing Arduino Libraries. Having WiFi makes it very easy to publish directly to Elasticsearch via the HTTP interface. The only real challenge was getting the Arduino code to generate an Elasticsearch compatible timestamp. I think that we\u2019ve got a clever and straight-forward solution, by combining the arduino `mils()` function with an NTP generated unix timestamp. Change the SSID and password in the sketch below and you should be ready to start. Configuring Elasticsearch Before we start sending data we\u2019re going to prime Elasticsearch to index the documents we\u2019re sending. Make sure to check the Elasticsearch URL (my `response = requests.put` line) to match your Elasticsearch endpoint. I\u2019m using Python and the requests library, but you can use whatever tool you\u2019re familiar with. import requests import json data = { \"mappings\": { \"reading\": { \"properties\": { \"temperature\": {\"type\": \"float\"}, \"pressure\": {\"type\": \"float\"}, \"timestamp\": {\"type\": \"date\"}, }, } } } response = requests.put('http:\/\/localhost:9200\/weather', data=json.dumps(data)) try: assert response.status_code is 200 except AssertionError: raise AssertionError(\"Your mapping was not created\", response) # You could use this snippet to delete your old data if you have an error. #response = requests.delete('http:\/\/localhost:9200\/weather') #try: # assert response.status_code is 200 #except AssertionError: # raise AssertionError(\"Your mapping was not deleted\", response) Sending Data Modify the as mentioned above, and upload it to your device. It should start sending data to your Elasticsearch instance. You can verify in the Serial Monitor under `Tools -> Serial Monitor`. Make sure that the baud rate is set to 115200. Configuring Kibana Open your Kibana instance, click \u201cSettings\u201d and add a new pattern. If you type \u201cweather\u201d into the index pattern, it should autofill the timestamp. Mine looks like this: Once you create a new index, you can click `Visualize` to start making graphs. Here\u2019s one I created. Start with the settings I have in the screenshot and then experiment to find what you like. Arduino Code Listing \/* * Simple HTTP get webclient test *\/ #include #include #include #include #include #include Adafruit_BMP085_Unified bmp = Adafruit_BMP085_Unified(10085): static const char ntpServerName[] = \"us.pool.ntp.org\": \/\/ Setup your wifi SSID and password here. const char* ssid = \"CanIGetAWiFi\": const char* password = \"n0youCan7\": const int timeZone = 0: \/\/ UTC \/\/ Variables needed for NTP \/\/ Elasticsearch needs us to generate timestamps for the data in order to make date histograms in Kibana. WiFiUDP Udp: unsigned int localPort = 8888: \/\/ local port to listen for UDP packets time_t getNtpTime(): void printDigits(int digits): void sendNTPpacket(IPAddress &address): \/\/ This is the IP address, or DNS name of my Elasticsearch instance. const char* host = \"192.168.1.215\": const int port = 9200: int motion: \/\/ Variables float temperature: String timestamp: time_t start_time: uint32_t t_ms: uint32_t start_mills: String run_mills: int milis_chars: void setup() { Serial.begin(115200): delay(100): \/\/ We start by connecting to a WiFi network Serial.println(): Serial.print(\"Connecting to \"): Serial.println(ssid): WiFi.begin(ssid, password): while (WiFi.status() != WL_CONNECTED) { delay(500): Serial.print(\".\"): } Serial.println(\"\"): Serial.println(\"WiFi connected\"): Serial.println(\"IP address: \"): Serial.println(WiFi.localIP()): Serial.println(\"Setting up NTP\"): Udp.begin(localPort): Serial.print(\"Local port: \"): Serial.println(Udp.localPort()): Serial.println(\"waiting for sync\"): setSyncProvider(getNtpTime): setSyncInterval(300): start_time = now(): Serial.println(\"Pressure Sensor Test\"): Serial.println(\"\"): \/* Initialise the sensor *\/ if(!bmp.begin()) { \/* There was a problem detecting the BMP085 ... check your connections *\/ Serial.print(\"Ooops, no BMP180 detected ... Check your wiring!\"): while(1): } } void loop() { \/\/ Measure pressure & temperature from BMP sensor \/\/ Modified from https:\/\/learn.adafruit.com\/bmp085\/using-the-bmp085-api-v2 sensors_event_t event: bmp.getEvent(&event): float pressure = event.pressure: float temperature: bmp.getTemperature(&temperature): \/\/ Use WiFiClient class to create TCP connections, connect to the Elasticsearch instance. WiFiClient client: if (!client.connect(host, port)) { Serial.println(\"connection failed\"): return: } run_mills = String(millis()): milis_chars = run_mills.length(): \/\/ To generate a millisecond unix timestamp, we first get the second timestamp, and add to it, the last three characters of the arduino\/relative millisecond timestamp timestamp = String(now()) + run_mills.charAt(milis_chars-3) + run_mills.charAt(milis_chars-2) + run_mills.charAt(milis_chars-1): \/\/ With such a simple document, we're just going to use a string to generate the JSON to send to Elasticsearch String data = \"{pressure: \"+String(pressure)+\", temperature: \"+String(temperature)+\", timestamp: \"+ timestamp +\"}\": \/\/ We can inspect the data being sent over the Serial line, in the Arduino IDE. Serial.println(data): \/\/ We now create a URI for the request \/\/ This is the index of the Elasticsearch document we're creating String url = \"\/weather\/reading\": \/\/ client.print(String(\"POST \") + url + \" HTTP\/1.1\\r\\n\" + \/\/ If you're using Shield, you'll need to generate an authentication header \"Content-Length: \" + data.length() + \"\\r\\n\" + \"\\r\\n\" + data): \/\/ We need this delay in here to give the WiFi Time delay(50): \/\/ Read all the lines of the reply from server and print them to Serial while(client.available()){ String line = client.readStringUntil('\\r'): Serial.print(line): } Serial.println(): } \/* Copied from https:\/\/github.com\/PaulStoffregen\/Time\/blob\/master\/examples\/TimeNTP_ESP8266WiFi\/TimeNTP_ESP8266WiFi.ino#L99 *\/ \/*-------- NTP code ----------*\/ const int NTP_PACKET_SIZE = 48: \/\/ NTP time is in the first 48 bytes of message byte packetBuffer[NTP_PACKET_SIZE]: \/\/buffer to hold incoming & outgoing packets time_t getNtpTime() { IPAddress ntpServerIP: \/\/ NTP server's ip address while (Udp.parsePacket() > 0) : \/\/ discard any previously received packets Serial.println(\"Transmit NTP Request\"): \/\/ get a random server from the pool WiFi.hostByName(ntpServerName, ntpServerIP): Serial.print(ntpServerName): Serial.print(\": \"): Serial.println(ntpServerIP): sendNTPpacket(ntpServerIP): uint32_t beginWait = millis(): while (millis() - beginWait < 1500) { int size = Udp.parsePacket(): if (size >= NTP_PACKET_SIZE) { Serial.println(\"Receive NTP Response\"): Udp.read(packetBuffer, NTP_PACKET_SIZE): \/\/ read packet into the buffer unsigned long secsSince1900: \/\/ convert four bytes starting at location 40 to a long integer secsSince1900 = (unsigned long)packetBuffer[40] << 24: secsSince1900 |= (unsigned long)packetBuffer[41] << 16: secsSince1900 |= (unsigned long)packetBuffer[42] << 8: secsSince1900 |= (unsigned long)packetBuffer[43]: return secsSince1900 - 2208988800UL + timeZone * SECS_PER_HOUR: } } Serial.println(\"No NTP Response :-(\"): return 0: \/\/ return 0 if unable to get the time } \/\/ send an NTP request to the time server at the given address void sendNTPpacket(IPAddress &address) { \/\/ set all bytes in the buffer to 0 memset(packetBuffer, 0, NTP_PACKET_SIZE): \/\/ Initialize values needed to form NTP request \/\/ (see URL above for details on the packets) packetBuffer[0] = 0b11100011: \/\/ LI, Version, Mode packetBuffer[1] = 0: \/\/ Stratum, or type of clock packetBuffer[2] = 6: \/\/ Polling Interval packetBuffer[3] = 0xEC: \/\/ Peer Clock Precision \/\/ 8 bytes of zero for Root Delay & Root Dispersion packetBuffer[12] = 49: packetBuffer[13] = 0x4E: packetBuffer[14] = 49: packetBuffer[15] = 52: \/\/ all NTP fields have been given values, now \/\/ you can send a packet requesting a timestamp: Udp.beginPacket(address, 123): \/\/NTP requests are to port 123 Udp.write(packetBuffer, NTP_PACKET_SIZE): Udp.endPacket(): } It turned out that the temperature alone wasn\u2019t enough to dissuade my friend that I\u2019ve been spending too much time inside the house. That being said, setting up this experiment couldn\u2019t have been easier and I\u2019m really looking forward to using WiFi-enabled microcontrollers to send readings to Elasticsearch for further experiments. I also got this sweet live gif of myself with a hair dryer and a popsicle on this temperature sensor, so there\u2019s that. is an Engineer and Designer in Oakland, CA. \n"}
{"index": {"_id": 523}}
{"title":"Monitoring the Search Queries","seo_title":"Monitoring the Search Queries","url":"\/blog\/monitoring-the-search-queries","author":{"name":"Jaleh Dastmalchi-Round"},"date":"August 24, 2016","category":"Engineering","locales":"","content":" Ever wonder how your users are using your Elasticsearch cluster? Have you felt the need to investigate the queries sent to the Elasticsearch cluster by your users? Using Packetbeat you can keep an eye on what comes and goes and avoid those nasty surprises your users may throw at your cluster. You can use Elastic plugins to monitor your own Elastic Stack, with the addition of the road to great monitoring started and is continuing to improve in the future generation as part of the bundle. Long term, this will best provide insight into cluster performance, even behind SSL. Elastic recommends that you make use of these components first and foremost, and that you do have a dedicated Elasticsearch cluster running on at least one node, for this purpose.\u00a0This monitoring cluster is a great place to also store additional query detail: so if you don't already have a monitoring cluster this gives you another great reason to set it up as it is imperative that you send the query data to a separate cluster. Please note this blog focuses on monitoring search traffic over HTTP only: current versions of Packetbeat do not support inspecting encrypted payloads What\u2019s a monitoring cluster?A monitoring cluster is a cluster dedicated for storing and analyzing the monitoring data from your production Elasticsearch cluster. Keeping your monitoring data on a separate cluster is highly recommended: if things do go wrong in production, you want insight to this data and you want them somewhere you can access them (outside the \u201cfire zone\u201d). This separation becomes essential if you are planning to monitor search queries via Packetbeat. If you have Marvel but this is you wish to set up a monitoring cluster this is a good starting point. Make sure to give your monitoring cluster a face by installing a dedicated Kibana instance for monitoring. Picture itGetting ready for the data You\u2019ll need this for to filter the traffic to specific portions of the traffic you are interested (i.e., only search queries). I created config file called sniff_search.conf with below content: it includes extracting query_body and the index that has been searched into their own fields. You can go as crazy as you wish here with extracting bits that are useful to you. input { beats { port> 5044 } } filter { if \"search\" in [request]{ grok { match => { \"request\" => \".*\\n\\{(?.*)\"} } grok { match => { \"path\" => \"\\\/(?.*)\\\/_search\"} } if [index] { } else { mutate { add_field => { \"index\" => \"All\" } } } mutate { update => { \"query_body\" => \"{%{query_body}\" } } } } output { if \"search\" in [request] and \"ignore_unmapped\" not in [query_body]{ elasticsearch { hosts => \"10.255.4.165:9200\" } } } On Linux: .\/bin\/logstash -f sniff_search.conf Start sniffing # Select the network interfaces to sniff the data. You can use the \"any\" # keyword to sniff on all connected interfaces. interfaces: device: any http: # Configure the ports where to listen for HTTP traffic. You can disable # the HTTP protocol by commenting out the list of ports. ports: [9200] send_request: true include_body_for: [\"application\/json\", \"x-www-form-urlencoded\"] #elasticsearch: # Array of hosts to connect to. # Scheme and port can be left out and will be set to the default (http and 9200) # In case you specify and additional path, the scheme is required: http:\/\/localhost:9200\/path # IPv6 addresses should always be defined as: https:\/\/[2001:db8::1]:9200 #hosts: [\"Localhost:9200\"] ### Logstash as output logstash: # The Logstash hosts hosts: [\"10.255.4.166:5044\"] On Linux: sudo .\/packetbeat -e -c packetbeat.yml -d \"publish\" This is an example of what a document will look like: { \"bytes_in\" => 537, \"client_ip\" => \"10.255.5.101\", \"client_port\" => 52213, \"client_proc\" => \"\", \"client_server\" => \"\", \"ip\" => \"10.255.4.167\", \"port\" => 9200, \"path\" => \"\/logstash-*\/_search\", \"beat\" => { \"hostname\" => \"ip-10-255-4-167.eu-west-1.compute.internal\", \"name\" => \"ip-10-255-4-167.eu-west-1.compute.internal\" }, \"proc\" => \"\", \"server\" => \"\", \"method\" => \"POST\", \"type\" => \"http\", \"status\" => \"OK\", \"params\" => \"%7B+%22query%22%3A+%7B%0A%22match%22%3A+%7B%0A+++%22clientip%22%3A+%22105.235.130.196%22%0A%7D%0A%7D%7D%0A=\", \"http\" => { \"code\" => 200, \"content_length\" => 7587, \"phrase\" => \"OK\" }, \"bytes_out\" => 7675, \"request\" => \"POST \/logstash-*\/_search HTTP\/1.1\\r\\nHost: 10.255.4.167:9200\\r\\nConnection: keep-alive\\r\\nContent-Length: 62\\r\\nAccept: application\/json, text\/javascript, *\/*: q=0.01\\r\\nOrigin: chrome-extension:\/\/lhjgkmllcaadmopgmanpapmpjgmfcfig\\r\\nUser-Agent: Mozilla\/5.0 (Windows NT 6.0: WOW64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/49.0.2623.112 Safari\/537.36\\r\\nContent-Type: application\/x-www-form-urlencoded: charset=UTF-8\\r\\nAccept-Encoding: gzip, deflate\\r\\nAccept-Language: en-US,en: q=0.8\\r\\n\\r\\n{ \\\"query\\\": {\\n\\\"match\\\": {\\n \\\"clientip\\\": \\\"105.235.130.196\\\"\\n}\\n}}\\n\", \"@timestamp\" => \"2016-08-05T14:35:36.740Z\", \"query\" => \"POST \/logstash-*\/_search\", \"count\" => 1, \"direction\" => \"in\", \"responsetime\" => 28, \"@version\" => \"1\", \"host\" => \"ip-10-255-4-167.eu-west-1.compute.internal\", \"tags\" => [ [0] \"beats_input_raw_event\" ], \"query_body\" => \"{ \\\"query\\\": {\\n\\\"match\\\": {\\n \\\"clientip\\\": \\\"105.235.130.196\\\"\\n}\\n}}\\n\", \"index\" => \"logstash-*\" } From the data you see the IP and the port of the client connected to Elasticsearch \"client_ip\": \"10.255.5.101\" , \"client_port\": 56433. The IP of the node and port \u00a0\u00a0\"ip\": \"10.255.4.167\", \"port\": 9200,, you can also see the query sent to Elasticsearch \"query\": \"POST \/logstash-*\/_search\",... You can visualize this data in Kibana. Connect to Kibana you installed in step 2 and configure an index pattern of Logstash-* You can find an example of visualization you can create below: Above dashboard is just one example you might find useful, if interested you can download it . You can easily import the visualizations and the dashboard via Kibana through Settings > Objects tab. When\/why monitor search queriesMaintaining a healthy cluster needs insight into how it\u2019s used and the search queries your users run. Whether you provide direct search access to the cluster to your users or have an application layer in between, usage patterns can be helpful in planning for your data and resources. Once you have the data inside your monitoring cluster you can answer questions like these and many more: Answering these questions helps better planning and outage prevention. [1] [2] \n"}
{"index": {"_id": 524}}
{"title":"Benchmarking REST client and transport client","seo_title":"Benchmarking REST client and transport client","url":"\/blog\/benchmarking-rest-client-transport-client","author":{"name":"Daniel Mitterdorfer"},"date":"August 23, 2016","category":"Engineering","locales":"","content":" With the release of Elasticsearch 5.0, we will add a . It offers a lot of advantages compared to the transport client, especially looser coupling of your application to Elasticsearch: You just need the Elasticsearch Java REST client JAR and its dependencies on your application\u2019s classpath which is much more lightweight. Also the REST API is much more stable than the transport client interface which needs to match exactly with your Elasticsearch version. At Elastic we care a lot about performance and we also want to ensure that the new Java REST client is fast enough. So we compared the performance of the transport client against the Java REST client. All benchmarks use only a single client thread because we are mainly interested in what a single client can achieve. The main purpose of a multi-threaded benchmark would be to demonstrate the scalability (or lack thereof due to contention effects) and might be another interesting area we can look at. For this benchmark we chose two typical operations: bulk indexing and search. As we want to benchmark the client, not the server, we use a \u201cnoop\u201d Elasticsearch plugin that we have implemented specifically for benchmarking. It does nothing except accepting requests and sending corresponding responses. By using this plugin, we ensure that Elasticsearch does the minimal work that is needed to serve a request and put as much pressure as possible on the client. We look at two key performance characteristics of both client implementations: We also measure latency at defined throughput levels. This means that we are not hitting Elasticsearch as hard as we can but the benchmark driver attempts to reach a specific throughput, called \u201ctarget throughput\u201d. The reason is that we want to measure whether and how latency changes under varying load. In addition to target throughput, we also look at the actually achieved throughput. We have published all in the Elasticsearch repository so you can try the benchmark by yourself. For the bulk index benchmark you also need the from . Benchmark Setup Client: Elasticsearch (server): Both machines are connected via a direct 1GBit Ethernet connection. Bulk Index benchmark Command line parameters: where is either or and varies as stated above. Search benchmark Command line parameters: where is either or and vary as stated above. Results Bulk Indexing Below we can see the achieved throughput for both client implementations with the \u201cgeonames\u201d data set in documents per seconds: The HTTP client has between 4% and 7% smaller bulk indexing throughput than the transport client. Remember that these are lab conditions: We do not process requests in Elasticsearch to stress the clients as much as possible. To get a more realistic picture, we also did a test with complete request processing in Elasticsearch and there the achieved throughput was nearly identical: This shows that a lot of factors influence performance. So, as always with performance topics, it is best to measure yourself. Create a test environment, take a set of representative data and benchmark the two client implementations against each other to get a feeling for the performance characteristics in your case. Search What would a search engine be good for if you couldn\u2019t search? So we have also analyzed the performance of search requests in this benchmark. To explain the results, we need to take a short detour and talk a little bit about what operating a search engine has in common with operating checkouts in a supermarket. Typically, a search engine should be able to provide search results as quickly as possible. For its operation, it is important to run the search engine at a sustainable throughput rate but not at peak load. To understand the reason for that, consider a checkout in a supermarket: When there are not much customers in the supermarket, you just need one cash register. The cashier can process each customer individually without a waiting line building up. As more or and more customers enter the supermarket, customers will queue up at the checkout and their wait time will increase. At a certain point the shop manager may want to open a second checkout in order to keep waiting lines shorter and customers happy. Exactly the same happens when you operate a search engine (or any request-response driven system for that matter): At low throughput rates, latency will stay low but as throughput increases, queueing effects begin to dominate and latency will increase. To keep your customers happy, you don\u2019t want to operate your system at maximum throughput but rather at a sustainable throughput where latency is still acceptable. This is such an important topic that there is a whole branch in mathematics dedicated to such questions, called . The issue above is formalized by : The long-term average number of customers in a stable system L is equal to the long-term average effective arrival rate, \u03bb, multiplied by the (Palm\u2011)average time a customer spends in the system, W: or expressed algebraically: L = \u03bbW. As Little\u2019s law talks about averages, we\u2019ll also look at the average latency. For the Java REST client and the transport client it looks as follows: We can see that in this scenario, a sustained throughput rate for the REST client is around 1,200 operations per second and for the transport client it is around 1,700 operations per second. In general, you should care more about tail latencies to get a better understanding what response times your customers can experience. Tail latencies exhibit roughly similar characteristics until the 99 percentile: For each client, we have chosen the trial run with the worst 99.99 percentile at a throughput rate of 1,200 operations per second, which we consider sustainable for both clients in this setting. As for the bulk indexing benchmark, remember that these are lab conditions: We do not process requests in Elasticsearch to stress the clients as much as possible. Similar to the bulk indexing benchmark, we also ran real search requests against a Elasticsearch node: Again, you can see very similar behavior for the real-life case for both clients. If you are interested in the details, you can also look at the of both benchmarks. Summary The Elasticsearch Java REST client that is coming with Elasticsearch 5.0 provides looser coupling of your application to Elasticsearch. It also has less dependencies making your application more lightweight. In our benchmarks, the Java REST client already has promising performance characteristics for real-life use cases although it doesn\u2019t yet match that of the transport client under lab conditions. We will still continue to improve performance of the Java REST client so stay tuned. The new Java REST client is already a great alternative to the transport client for a lot of scenarios. You can even start playing around with the Java REST client right now, by downloading . \n"}
{"index": {"_id": 525}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-08-22","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-08-22","author":{"name":"Michael McCandless"},"date":"August 22, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top News \u201cLess Code, More Nodes, More Features\u201c Application Scaling with Elasticsearch @ StockTwits | Elastic - \u2014 Kraut Kl\u00edck (@QIMP3G) Elasticsearch Core Changes in 2.x: Changes in master: Ongoing: Apache Lucene Watch This Space , where we'll share more news on the whole Elastic ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 526}}
{"title":"Brewing in Beat: New Beats dashboards management","seo_title":"","url":"\/blog\/brewing-beats-new-beats-dashboards-management","author":{"name":"Monica Sarbu"},"date":"August 22, 2016","category":"Brewing in Beats","locales":"","content":" New community beat: Springbeat In addition to\u00a0, Valentin Crettaz created to collect different data from Spring Boot applications running with the actuator module. For now, it supports only health and metrics data. Please give it a try and let us know what do you think. Packetbeat: Add Cassandra support With this , Medcl adds support for Cassandra in Packetbeat, so you can now monitor the network traffic exchanged between your applications and Cassandra, and visualize it with Kibana. The PR comes with a sample Kibana dashboard for Cassandra traffic that you can use as a starting point for your dashboards. Easily import\/export the Beats dashboards We were providing two scripts for importing the Kibana dashboards for a single Beat in Elasticsearch, one in bash and one in powershell in order to have support for Unix and Windows systems. Maintaining two scripts became complex with the time, and we decided to the script in Golang that can be compiled for all Go supported platforms. \u00a0The script is called , and it will be part of the Beat package. With this change, we are trying to make it easier for the community to share their own custom Kibana dashboards. If you created some awesome Kibana dashboards, just create a zip archive that has a certain , and share it with us. Starting with the next release, we will provide the sample Kibana dashboards for all the Elastic Beats in a separate common package, instead of including the dashboards in each Beat package. To import the Kibana dashboards and the index pattern for a single Beat, together with the dependencies, visualizations, searches, you just need to run: .\/scripts\/import_dashboards -beat Metricbeat This will download the right version of the Metricbeat dashboards, and import them for you to your local Elasticsearch node. You can also specify a different Elasticsearch URL in `-es URL`, or an username\/password (-user USER -pass PASSWORD) to connect to Elasticsearch. By default, this uses the default index pattern,\u00a0 in this case, but you can specify a different index pattern in the . Please check the for more details. You can also use the script to import any custom Kibana dashboards of an Elastic Beat or a community Beat: .\/scripts\/import_dashboards -url https:\/\/github.com\/elastic\/my-dashboards\/archive\/v5.0.0.zip Where the represents the zip archive with the Kibana dashboards of a Beat or multiple Beats. Metricbeat: Monitor Filebeat with Metricbeat Add \u00a0in Metricbeat to monitor Filebeat. It exports statistics like the number of renamed, open or truncated files per harvester or per prospector. Completed Postgresql module in Metricbeat Added metricsets for per-database statistics and for the background writer, finalizing the new in Metricbeat. Switch to Go 1.7 We have the Golang version to 1.7, so all the Beats version 5.0 and 1.3 will run with Go 1.7. This is needed for supporting OS X Sierra and should also bring some performance improvements. Upgrading required us to update also the OS X cross compiler. Packaging Makefile refactoring This moves part of the Makefile from the packer to the main Beats Makefile. The result is that the community Beats no longer have to provide a custom Makefile for packaging, simplifying the Beat generator and making it easier for the community authors to package their Beats. Vendor libbeat in community Beats The Beat generator now of the generated Beat. This encourages the practice of dependency vendoring (which we do for the official Beats) and makes it easier to cross-compile and package the Beats. Metricbeat: Introduce experimental flag for cgroups Mark experimental the cgroups support in the system module of Metricbeat. In this regard a new configuration option was added to enable\/disable gathering data from cgroups for each process. By default it\u2019s set to false to not send any cgroups information. # EXPERIMENTAL: cgroups can be enabled for the process metricset. #cgroups: false Document the configuration file format We now have a that walks the user through the various features and conventions used by our configuration files. Document how to throttle the output bandwidth We\u2019ve also added a that explains how to use Linux tool to cap the bandwidth used by the Beats to Logstash\/Elasticsearch communication. Because the Beats outputs are handling well the network backpressure, an OS level solution like this one is effective. \n"}
{"index": {"_id": 527}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-08-16","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-08-16","author":{"name":"Michael McCandless"},"date":"August 16, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top News Powering Transactions Search with Elastic \u2013 Learnings from the Field \u2014 PayPal Developer (@paypaldev) Elasticsearch Core Changes in 2.x: Changes in master: Ongoing: Apache Lucene Watch This Space , where we'll share more news on the whole Elastic ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 528}}
{"title":"Just Enough Redis for Logstash","seo_title":"","url":"\/blog\/just_enough_redis_for_logstash","author":{"name":"Aaron Mildenstein"},"date":"August 16, 2016","category":"Engineering","locales":"de-de,fr-fr,ja-jp,ko-kr","content":" Message queues are used in Logstash deployments to a surge in events which may lead to slowdown in Elasticsearch or other downstream components. Redis is one of the technologies in use as a message queue. Due to its speed, ease of use, and low resource requirements it is also one of the most popular ways as well.That\u00a0is probably why it has been around for a very, very long time\u2014since Logstash version 1.0.4, released more than five years ago!With all of the recent changes to improve the Logstash pipeline\u2014as well as improvements to the Redis plugin itself\u2014you may not be getting all the performance the Logstash Redis input plugin is capable of delivering.Logstash attempts to detect the number of cores in your system and set the number of pipeline workers to match. But pipeline workers only matter for filter and output plugins. \u00a0It has no effect on input plugins. If you haven\u2019t set `threads` in the Redis input plugin, you are only ingesting a fraction of what you could.The test setup included the most recent stable version of Logstash (2.3.4) with Redis 3.0.7\u00a0running on the same machine, which is a 2015 MacBook Pro, for reference. The Logstash configuration used isinput { redis { host => \"127.0.0.1\" data_type => \"list\" key => \"redis_test\" # batch_count => 1 # threads => 1 } } output { stdout { codec => dots } }Run this with This test setup is only designed to test for maximum throughput. Actual performance numbers will vary widely depending on what other plugins are used.By iterating through a few options for only the \u00a0setting, and using all other settings at their defaults, we see results like these:Let\u2019s run the same tests again, but with , and add \u00a0to our Logstash command line to take full advantage of that increase:As you can see, increasing the default \u00a0(which is 125), to 250 results in a decrease in performance.It\u2019s been common in the past for users to use a larger \u00a0when working with Redis. \u00a0This is no longer best practices, and will actually reduce performance. \u00a0This is primarily due to changes in the Logstash pipeline architecture. Even an increase of \u00a0to 250 results in a drop of performance from 89.5K\/sec down to 72.5K\/sec when . The sweet spot for \u00a0is right around 125, which is the default \u00a0(there\u2019s a reason for that!).Diving deeperRecent changes to the Redis input include turning on batch mode by default and using a to execute the batch retrieval commands on the Redis server. Lua scripts also act as a transaction so we can take a batch and shorten the queue in one step. This forces other Redis connections to wait. Note, your Logstash Redis output plugin in the upstream Logstash config is one such connection.Also, you should be aware that the manner in which events are added to Redis by the upstream Logstash can affect the performance of the downstream Logstash instance. For example, while preparing the results of the tests, we found that querying the list size with \u00a0in too often would affect the measurement. Try to understand these factors in your upstream Logstash instance:You might want to look at using bigger sizes e.g. 500 on the upstream Redis output - this will buffer the events before calling Redis and doing this may give the downstream Redis input threads time to jump in to pull from Redis. However, if the event generation rate is high then this may not be as helpful - 50K\/sec in batches of 500 means a batch buffer fills in 10 milliseconds.We have seen that the performance of the Lua script suffers proportionately with larger batch sizes. This means that larger batch sizes on the Redis input will affect the performance of both of the Logstash instances on either side of Redis.Generally, the goal of tuning the Redis input plugin config and the pipeline batch size and worker threads is to make sure that the input is able to keep pace with the filter\/output stage. You should know what the average throughput of your filter\/output stage is with the defaults. If, for example, your filter\/output stage throughput is 35K\/sec then there is little need to change the redis input worker count to 8 when one or two workers can fetch sufficient events per second.One more source of variation is JSON encoding (1), decoding (2) and encoding (3) - yes, three times, 1 in the upstream Redis output, 2 in the downstream Redis input and 3 in the elasticsearch output. Events with big string values do take some time to decode so make sure your testing is using data sets that represent the size and distribution of size as close to your production data as you can make it.Scaling throughput using multiple Logstash instance and one Redis serverMany users seek to improve throughput by starting up multiple Logstash instances on different hardware all pointing to the same Redis server and list.This does work and can work well, but you are advised to apply the same tuning tips to each instance. There is probably not much point in having multiple Redis inputs defined in any one config unless they are connecting to different Redis servers or a different list. Simply tune the threads of the one Redis input. Clearly, having, say, 3 Logstash instances pointing at the same Redis server will create some degree of Redis client connection contention - meaning that you should probably tune one instance and then retune all three when running together.ConclusionIn the not too distant future, we will be enhancing the Redis input with a JRuby wrapper around the popular and speedy Jedis Java library. \u00a0This will bring the added bonus of Redis Cluster mode!In the meanwhile, to give your Redis input performance a boost, try increasing the number of threads used. And be sure to measure and tune accordingly if you use something other than the default , or have multiple instances of Logstash pointing to a single Redis server.If you have a question about Redis and Logstash, feel free to open a discussion topic on our . You can also find us on IRC (#logstash), and on .Happy Logstashing! \n"}
{"index": {"_id": 529}}
{"title":"Behind the Elastic Stack: Working with USAA","seo_title":"Behind the Elastic Stack: Working with USAA","url":"\/blog\/behind-the-elastic-stack-working-with-usaa","author":{"name":"Greg Nieman"},"date":"August 16, 2016","category":"User Stories","locales":"","content":" One of the upsides of\u00a0working in a support capacity for a new and growing software stack is the opportunity to watch a customer installation go from the \u201cgreen field\u201d stage to become an integral part of their organization. \u00a0 At Elastic, each client is assigned a set of dedicated support engineers to assure the continuity of experience that comes from day-to-day familiarity with their installation and use case.\u00a0USAA\u2019s Cyber Threat Operations Center was one of my first accounts when I joined Elastic, and I was privileged to watch that transition their first year of deployment. \u201cAs they become more comfortable with the products and start attempting harder, bigger, more ambitious things, we\u2019re there to advise them along the way.\u201dAt the beginning, there were a variety of \u201cHow do I do this?\u201d and \u201cWhy isn\u2019t this working?\u201d types of questions that are common as an organization goes\u00a0through the first stages of learning and deployment. As they learned how to address common initial production issues that are part and parcel of large deployments\u00a0and how to design proactively to address them\u00a0long term, these gradually segued into more complex and difficult items\u00a0\u2013 topics such as\u00a0\u201cWhere did my heap go all of a sudden?\u201d, starting a discussion on how quickly can consume available memory, and how to use in your mappings to alleviate it. And now, a little over a year later they\u2019ve managed to make Elasticsearch an integral part of their threat management strategy \u2013 analyzing 2-4 billion security and server events per day originating from over two dozen feeds. They\u2019ve also become evangelists, . It\u2019s a tangible implementation of how someone can utilize the entire Elastic Stack to add a significant business value. \u201cYou want someone who is actively participatory in their solution, because not only does the problem get fixed, but they gain valuable skills and expertise.\u201dNeelsen Cyrus, the primary architect visionary for this system, is my primary point contact. He and all the other USAA personnel have always been curious, flexible, and engaged during all our interactions, and helping them achieve \u2013 and possibly even surpass \u2013 their initial goals has been more than gratifying. Meeting Neelsen at was one of the high points of the conference for me, and we look to continue building on an already significant achievement in the coming year (I also found out he is our customer with the most rocking tattoos . . . although we\u2019re still waiting for the Elastic cluster logo to show up at some point!). We took a few minutes to share what it\u2019s been like working together so far in the below video \u2013 I hope you enjoy it. \n"}
{"index": {"_id": 530}}
{"title":"Brewing in Beats: Export cgroup metrics on Linux","seo_title":"","url":"\/blog\/brewing-in-beats-export-cgroup-metrics-linux","author":{"name":"Monica Sarbu"},"date":"August 14, 2016","category":"Brewing in Beats","locales":"","content":" Metricbeat Reports cgroup Metrics on Linux, which is short for control group, is a mechanism for allocating resources - such as cpu time, memory, or block I\/O time - to a group of processes. Cgroup metrics are especially useful for collecting metrics from containerized processes because normally each container is assigned to its own cgroup. This allows Metricbeat to collect detailed cpu, memory, and disk metrics from processes and even attribute those processes to a specific container ID. When processes are assigned to a specific cgroup, Metricbeat will report the stats and configured limits of the cgroup. The is reported in the system process metricset. Metricbeat is capable of collecting data from the cpu, , , and subsystems. Here\u2019s the . Metricbeat: New Postgresql moduleWe\u2019ve merged the first version of the Metricbeat , for now having only a basic Metricset with data about each PostgreSQL process. this week. Metricbeat: Add file descriptor usage the number of file descriptors for each process is now exported\u00a0in Metricbeat under . This information is available on Linux and FreeBSD. Packetbeat: Refactor HTTP exported fieldsPreviously Content-Type and\u00a0Content-Length were exported only for the HTTP response. The exported fields were called\u00a0 and . With this Content-Type and Content-Length are also exported\u00a0for the HTTP request. To make it easier to understand, the request and the response details are grouped under and , so the following breaking changes are made: Packetbeat: Export http bodyWith this , the body of the HTTP request and HTTP response are exported. You can configure what type of HTTP attachments to export by configuring\u00a0the include_body_for option. For example to include the json attachments of the HTTP transactions, you need to configure the following: include_body_for: application\/json and the json attachment for the HTTP request is exported in and the attachment for the\u00a0response is exported in . Filebeat: Avoid exporting fields as pointersThe event exported by the Beats shouldn\u2019t contain fields of type pointers, only basic types. This fixes the type of the message field exported by Filebeat, and exports it as string instead of pointer to string. Packetbeat: Fix mappings for Packetbeat flowsFix mappings of the source statistics and destination statistics for Packetbeat flows as they were marked as not_analyzed strings instead of longs. Metricbeat: Fix action from MetricSet filtersThe drop_event filter was causing the MetricSet data to be nil, but the event was still being sent. This causes the event to actually be dropped. Libbeat: Accept array of strings in processor\u2019s condition the contains condition used in processors to accept an\u00a0array of strings, so you check if an exported\u00a0field\u00a0contains a certain string. processors: - drop_event: when: contains: tags: \"service-1\" Docs: Restructure the FAQ pageIn the current version, the questions available under the FAQ page of each Beat were splitted one per page, which\u00a0made it a bit difficult to search for your problem, especially with the growing number of the questions available for a single Beat. This organize the FAQ in a single page, where you can use the browser shortcuts to\u00a0easily search\u00a0for keywords. is what\u00a0the FAQ page for Packetbeat looks like. Metricbeat: Change type to dateThe start time of the process was exported as string (eg. \u201c12:03\u201d), which\u00a0made it difficult to filter by time. The type of the is changed to date in this . Metricbeat: Replace nanos with nsThe fields in nanoseconds that are exported by Metricbeat under nanos, are replaced with ns. This way becomes . This breaks the compatibility with Metricbeat 5.0.0-alpha4. Libbeat: Fix Elasticsearch error parsingFix regression in the Elasticsearch bulk-request error parsing. This resolves when ingest node processors do not accept the document provided. Libbeat: Update kafka clientThis updates the kafka client library adding kafka 0.10 support. It also exposes some new kafka configuration settings. Setting the protocol version to 0.10 in beats config will report the event timestamp to kafka (requires kafka 0.10 running). Look for config files relative to path.configThis makes a change into how the CLI flags are handled. If the files specified by is not absolute, but or are used, the configuration files . This also solves a we have in 5.0.0-alpha5. \n"}
{"index": {"_id": 531}}
{"title":"Indexing IPv6 addresses in Elasticsearch","seo_title":"Support for IPv6 in Elasticsearch","url":"\/blog\/indexing-ipv6-addresses-in-elasticsearch","author":{"name":"Adrien Grand"},"date":"August 11, 2016","category":"Engineering","locales":"","content":" Starting with Elasticsearch 5.0, the field will support indexing IPv6 addresses. Why only now?The ability to index IPv6 addresses has been . The reason why we have been pushing back so far is that we had no way to index IPv6 addresses efficiently. Our two options were basically to either index them as sortable strings, or to index them with multiple levels of precision like we did for 32-bits and 64-bits numerics. The issue with indexing as a sortable string is that you get terrible range performance: this typically requires visiting every single matching value, so querying a large IPv6 subnet would have been very slow. Then it would be tempting to index IPv6 addresses with multiple levels of precision, but this raises another issue: the more levels of precision, the fewer terms you need to visit at index time and the faster the range queries. However, these additional terms also have a cost in terms of index size and indexing speed. With only 32 or 64 bits of data, we managed to find trade-offs that provided good search performance with a reasonable indexing slow down and increase of the index size. But the trade-off is more complicated with 128 bits of data as you either get terrible indexing performance or terrible search performance. What changed?Lucene 6 introduced a new index structure called . In particular, up to 128 bits by configuring a number of dimensions equal to 1. Conceptually, it is not that different from how Lucene indexed numerics with multiple level of precision, in the sense that it is putting together data that are likely to match the same ranges. Except that points compute these ranges dynamically based on the data that is being indexed, rather than obeying to a static scheme. This is a huge difference since it means we do not index ranges that will not be useful at search time, which is exactly what was adding bloat to the index and making indexing slow in previous versions. How does it work?IPv6 addresses will be supported on all indexes that are created after the upgrade to 5.x, there will be no way to add IPv6 addresses to indexes that were created on Elasticsearch 2.x without reindexing. Internally, all IP addresses are now represented as a 128-bits IPv6 address. If you index an IPv4 address, it will be automatically translated to an at index time, and then converted back to an IPv4 address when returning sort values or aggregations. For instance, IPv4 address would internally be indexed as . You might be worried that indexes will be larger in the case that you only need to index IPv4 addresses since they only need 32 bits of data while they are indexed as IPv6 addresses that need 128 bits of data. However IPv4-mapped IPv6 addresses all start with the same 12 bytes, which is something that makes compression easy. And since the new data-structure that we use for indexing numerics is more space-efficient that the one we were using previously, you could actually expect disk usage reduction. \n"}
{"index": {"_id": 532}}
{"title":"Application Scaling with Elasticsearch @ StockTwits","seo_title":"Application Scaling with Elasticsearch @ StockTwits","url":"\/blog\/application-scaling-with-elasticsearch-at-stocktwits","author":{"name":"Eric Alford"},"date":"August 10, 2016","category":"User Stories","locales":"","content":" In this article, I want to share with you how at StockTwits we overhauled our message sharing system that took us from frequent downtime and general slowness to lightning fast requests and very happy users \u2013 all while allowing us to continue to scale in the future as traffic increases.Our Use Case: Mo Cashtags, Mo Problems is the largest social network dedicated to the finance community, with 1.5 million monthly active visitors. One of our primary features is the ability to view chronological streams of message posts based on specific filters. More specifically, we need the ability to query our collection of posts and get only posts that have a \u201ccashtag\u201d mentioned in them ($AAPL, $GOOG, etc). We also need the ability to query for posts from users that a specific user is following. This needs to be done quickly and at scale, regardless of how much our traffic grows. The initial architecture for this use case involved heavy database queries on MySQL\u00a0and a lot of complex caching with Redis. Imagine you are a user and every stream you want to look at is an individual set in Redis. If you have 100,000 followers, that means every time you post a message, that message would have to get inserted in 100,000 individual sets in Redis so your followers can see your posts. This worked in the beginning, but was no longer scalable as our user base continued to grow. As we added more streams, the complexity snowballed: more code, more maintenance, more points of failure. We were recently forced to rethink how our entire system was architected and realized that it is a perfect use case to implement Elasticsearch. The Solution: Two Indexes, One QueryImagine we have 2 indexes. One called \u201cmessages,\u201d which has a body and user_id field on it, and another called \u201cfriendships,\u201d which has a following field that is an array of user id\u2019s that a particular user is following. Message: body: The text of the message user_id: id of the user who shared the message Friendships: following: Array of user ids of which the user is following Since each document in Elasticsearch has an value, we can assign each message document the id value we have in our MySQL database for easier reference in the future. Each friendship document is better suited by using the user_id value from our database as the value for the document. This is pretty straight forward, but how do you query these indexes to get a stream of messages that a single user is following? Let\u2019s say is logged in. His user_id is 123 and he is requesting his stream of messages from the users he follows. All we have to do is query the messages index with a get request to the url http:\/\/yourhost:9200\/messages\/message\/_search with the JSON query attached: { \"query\": { \"bool\": { \"filter\": [{ \"terms\": { \"user_id\": { \"index\": \"friendships\", \"type\": \"friendship\", \"path\": \"following\", \"id\": 123 }, } }] } }, \"size\": 15, \"sort\": [{ \"id\": { \"order\": \"desc\" }}] } Let\u2019s take a deeper look at how this query works. We are asking our messages index to give us a filtered set of messages in which the user_id field must be equal to any ids that user 123 is following, similar to an IN query in SQL. It knows the set of following user ids for user 123 because we have specifically told it to route through the friendships index and use the following field for the set of following user ids. The size field is used to limit the result set Elasticsearch gives back and the sort field says we want to sort in descending order. This is pretty straightforward when looking at it from the outside but there is some Elasticsearch is doing under the hood of this. Before Elasticsearch 2.0, it was up to the developer to provide caching logic for these queries. For example, if we wanted to cache the following ids that this query uses, we used to\u00a0have to provide a field with the name of the key and expire that cache manually when the list changed. The problem with this was there was a point at which we would be over-caching and taking a performance hit, thinking our efforts would net a performance gain. Since there is no easy way for the developer to know the point at which they are over-caching, Elasticsearch has taken that burden off of the developer and into their own hands by making sure that only reused filters are cached. This is why it\u2019s important to stay up-to-date on the Elasticsearch versions and utilize\u00a0\u00a0as efficiency upgrades are happening rapidly. As you can see, the query DSL is powerful, and most filter queries will be much more trivial than this one. It\u2019s mostly a matter of structuring the query and setting up the indexes accordingly. Make it Faster: Enter AliasesThe above approach works well for us but we noticed our queries were getting slower as our index grew, regardless of how many nodes we scaled out to. Even though this wasn\u2019t causing any problems, at 80,000 posts per day and growing we knew eventually it would. In addition, we later found out that this approach has a major capacity issue as it is never a good idea to let one index grow indefinitely. The solution was to break up the message index into monthly chunks and use the alias approach for querying a set of indexes. For example, we alias the most recent three indexes as \u201cmessages_last_3_months\u201d and then query on that alias to get a result set from the last three months. It is important to note that the more indexes you query at once, the more shards have to be queried, increasing the overall search load for that query. This may or may not have implications depending on your data and traffic size, but it needs to be monitored closely. In our case, we were able to keep the amount of indexes being queried concurrently to a minimum, and didn\u2019t prove to be an issue. [ This will improved in Elasticsearch 5.0! Read more .] Partitioning the message index did come with a bit of work as we had to lay out the logic for when we need to query on one, three, six, or all indexes,\u00a0but the net gain was tremendous, which is submillisecond queries. Given our total indexed documents of about 51 million and 60GB in size, it blew us away when we first witnessed this kind of performance in production at the scale we are at. We have 5 nodes with each node running on a machine that has 16 cores, 64GB of memory and 160GB of disk. Our CPU usage usually hovers around 4-8%, so 16 cores is a bit overkill here. A seven day overview from Marvel is shown below. You\u2019ll notice we don\u2019t get high traffic during the weekends. As you can see from a sample of our server data, we are running stable and healthy. Our indication that we may need to scale is when our JVM usage starts hitting at or above 75%, which looks like might be soon as our growth continues. Summary: Less Code, More Nodes, More Features Aside from our query performance gain, the most notable gain here is the amount of code we were able to scrap. Our architecture\u2019s complexity is highly simplified from our previous design and the learning curve of this design is less steep. The time it takes between a user posting a message and being able to see it in any stream is the time it takes to get indexed plus the time it takes to search, which as we can see from our cluster statistics, is negligible. When it comes time to scale again, we simply add another node to our cluster. To top it off, we\u2019ve now set ourselves up for full-text search. With a simple query to our Elasticsearch set up, our application has outstanding full-text search capabilities. Not only have we solved our main scaling issue, but we have also added additional features to our application that Elasticsearch provides, such as fast filter queries, custom aggregations, , and . \n"}
{"index": {"_id": 533}}
{"title":"Beats 5.0.0-alpha5 released","seo_title":"","url":"\/blog\/beats-5-0-0-alpha5-released","author":{"name":"Tudor Golubenco"},"date":"August 09, 2016","category":"Releases","locales":"","content":" We\u2019re happy to announce the fifth alpha release of the Beats 5.0 series. As we slowly approach the GA release, we're polishing the Beats with lots of small improvements and fixes. \u00a0You can find all the details in the release notes below, or read the rest of the blog post for the highlights. IMPORTANT: This is an alpha release and is intended for testing purposes only. Please do not deploy in production. Yada yada. Automatically load the right Elasticsearch template Elasticsearch 5.0 comes with several , but it is still able to use the old 2.x templates for backwards compatibility. This is good news because it means that you can use Beats 1.x with either Elasticsearch 2.x or 5.x. However, because we want the Beats 5.x to use the new mapping features, but also be able to work with Elasticsearch 2.x, we added a feature that can query the Elasticsearch version and automatically load the best template for you. This way, you have complete freedom in planning your rolling upgrades. More filtering flexibility Beats 5.0.0-alpha5 introduces simple processors (previously called \"generic filters\") that allow you to flexibly choose which events or fields to drop based on simple conditions. Starting with alpha5, these conditions can also be combined with logical operators (AND\/OR\/NOT) so they don\u2019t have to be so simple anymore. You can then express conditions like \u201cdrop all logs about 200 and 404 responses, except if the response time is larger than 100 milliseconds\u201d. Filebeat registry file cleanup + more options Filebeat stores its state about the files it reads in a registry file on disk. This way, it can avoid shipping the same log lines after a restart. With the 5.0.0-alpha5 release, we introduce new configuration options that allow you to configure when to remove entries from this registry file. This means you can make sure that the registry file doesn\u2019t grow forever. On the same note, other Filebeat configuration settings were renamed for consistency and we now have a short explaining what each Filebeat component does. Override settings from the CLI via the -E flag Do you like how Elasticsearch allows you to set any configuration setting from the command line by using the flag (yes, it used to be , but was renamed in 5.0 to avoid confusion with the JVM flags)? Well, the same is now possible for all Beats. For example, you can quickly enable the console output by adding . More configuration flexibility On the same theme with the flag, you can now specify multiple configuration files by repeating the flag. Settings in subsequent config files override those that precede them. You can use this, for example, for setting defaults in a base configuration file, and overwrite settings via local configs. We have also standardized on using as a way to disable most things in the configuration file. For example, if you want to disable a Packetbeat protocol without commenting out 10 lines of config, add . Want to disable an output? The same does the trick. New defaults for the logging verbosity We did some rethinking of the Beats logging strategy. Part of this, we\u2019ve switched the default log level from ERROR to INFO and reduced the verbosity of most warnings and info messages. To compensate, we added a set of internal metrics which also get logged to the INFO level every 30 seconds. This means you get good visibility into what is happening inside the Beats without getting huge files during periods of high traffic. Become a Pioneer A big Thank You to everyone who has tried the previous alpha releases and or . We\u2019d like to also remind you that if you post a valid, non-duplicate bug report during the alpha\/beta period against any of the Elastic stack projects, you are entitled to a . \n"}
{"index": {"_id": 534}}
{"title":"Brewing in Beats: Configurable index patterns","seo_title":"","url":"\/blog\/brewing-in-beats-configurable-index-patterns","author":{"name":"Tudor Golubenco"},"date":"August 09, 2016","category":"Brewing in Beats","locales":"","content":" Welcome to Brewing in Beats! With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources. New community beat: Burrowbeat is a new Beat that can be used to monitor consumer lags in Kafka queues. It is based on the project. Configurable index patternsThe Beats now offer . They used to enforce daily indices of the form , which is still the default. But it\u2019s now possible to do weekly or hourly indices using a syntax similar to Logstash, or something like to work with the new from Elasticsearch, or even to automatically split the data into separate indices based on any field from the events. Use scaled floats for percentagesAfter adding support for half floats a few weeks back, Adrien and added scaled floats to Elasticsearch \ud83c\udf89. Scaled floats are stored as longs behind the scenes, which makes them benefit of the compression scheme used for integers in Lucene. This makes them a great fit for the way we store percentages in Beats: a number between 0 and 1 that gets formatted as a percentage by Kibana. This switches our percentages to use scaled_float. We had quite a few of those, so we can expect a significant improvement in the storage footprint. Automatically generate Kibana index patternsThe sample Beats dashboards contain the Kibana index patterns, which allow us to define custom formatting for some of our fields (think of percentages). Providing the index pattern also saves the user a step while getting started. We used to create these index patterns by exporting them from Kibana, in a mostly manual process. To improve on this, Monica created a script to from our files, which are the primary source data for everything that the Beats export. Lookup functionalityThe allows attaching arbitrary metadata to events by calling external scripts. The scripts are called with parameters that can be taken from the original event, and the results cached for that parameters. This can be used, for example, to attach extra metadata to every file read by Filebeat by calling the Kubernetes APIs. The same could be used to add custom metadata to every process monitored by Metricbeat. Since the results are cached, the external script is called only once per file\/process. into an experimental branch called , which we plan to merge into master after we add several security checks around calling external scripts. Filebeat: shorter close_inactive defaultThe option sets after what time interval Filebeat closes the open files that don\u2019t receive updates. The old default used to be 1h, which could mean that we keep a lot of open files in the case of quickly rotating files. This PR changes the default to 5m. If a file receives updates after it was closed, it is picked up again by Filebeat, so the lower default doesn\u2019t mean any risk of data loss. \n"}
{"index": {"_id": 535}}
{"title":"Elastic Stack Release - 5.0.0-alpha5","seo_title":"Elastic Stack Release - 5.0.0-alpha5","url":"\/blog\/elastic-stack-release-5-0-0-alpha-5","author":{"name":"Shay Banon"},"date":"August 09, 2016","category":"Releases","locales":"ja-jp","content":" So many alphas. So many new things we want the community to explore, utilize, abuse, and...hopefully...find compelling. The release train continues. (*choo choo*) It\u2019s here! \u00a0Say \u201cHeya\u201d to alpha 5. Or, say \u201c\u201d if you would prefer... Before you get too excited, keep in mind that this is still an alpha, so don\u2019t put it into production. And, since it is an alpha, it is not available on . But, because Elastic Cloud is the official hosted Elasticsearch and Kibana offering on AWS, you'll be able to deploy releases on the day of 5.0 GA. (We wouldn't want you to wait for all this goodness!)\u00a0 If you open a bug report, today, you too can become an . And now, without further ado, some highlights from alpha 5. ElasticsearchFor more detailed information, and many other features, peruse the Elasticsearch . From 2.3.x to 5.0. The magical journey. The undiscovered country. The next frontier. Other coined phrases. As a reminder, we\u2019ve also released the , which runs on your existing 2.3 cluster. \u00a0Use this site plugin to prep for your migration. KibanaWe\u2019re heads down and laying the groundwork for beta1 throughout Kibana, but we couldn\u2019t help but squeeze a few key updates into this release. Logstash \u201cGo faster\u201d, you said. \u201cOk!\u201d, we replied. Speed and a few more additions feature highly in this release. BeatsWe may collect data from the edge, but all the updates are in a single Beats . ES-HadoopES-Hadoop v 5.0.0-alpha5 has also been released today. Peruse all the information in the . Get it Now!Happy testing. Your feedback is instrumental in making 5.0 successful. And, don't forget that X-Pack is here and continually being udpated with each Alpha release. \n"}
{"index": {"_id": 536}}
{"title":"Elasticsearch for Apache Hadoop 5.0.0-alpha5","seo_title":"","url":"\/blog\/es-hadoop-5-0-0-alpha5","author":{"name":"James Baiera"},"date":"August 09, 2016","category":"Releases","locales":"","content":" \u200bI am excited to announce the release of Elasticsearch for Apache Hadoop (aka ES-Hadoop) built against Elasticsearch 5.0.0-alpha5. : This is an alpha release and is intended for purposes only. Crazy things might happen when running this code and indices created with this version . For the sake of your own sanity, we do not advise using this version in production. What\u2019s new? Spark 2.0 !!! It\u2019s here! It\u2019s here! It\u2019s finally here! It\u2019s exciting enough to warrant three exclamation points in the header! This version has added preliminary support for Spark 2.0! Give it a try and let us know what needs improving! Every sentence in this section has an exclamation point at the end of it! Hurray! (Hadoop\/Spark) + Slice API = More Parallel A substantial change has been added to support the use of Elasticsearch\u2019s new Scroll Slicing functionality. Now you can state the maximum number of documents you wish to see per input task and the framework will attempt to sub-divide input splits to increase your computing parallelism. Isn\u2019t sharing beautiful? Squashing Bugs Have sub-fields in your mapping named \u201cproperties\u201d? Fixed. Don\u2019t like DataFrames saving null values? Fixed. Tired of not seeing why your bulk indexing requests don\u2019t report why they failed? Double fixed. Take a look at in this release! Feedback Now you might be wondering, \u201cWhy would I want to try an Alpha Release? Aren\u2019t these things normally riddled with bugs?\u201d Well, yeah, sometimes. We\u2019re tracking a few things that we already know we\u2019ve broken (like ), but we\u2019re only human. Thats why we need the help from all of you awesome early adopters! So, please, try this at home! You can ES-Hadoop 5.0.0-alpha5, try it out, find out how it breaks, and let us know what you did on , , or in the . A crisp high five is waiting for all who participate! Not a huge fan of high fives? There\u2019s always the instead! \n"}
{"index": {"_id": 537}}
{"title":"Elasticsearch 5.0.0-alpha5 released","seo_title":"Elasticsearch 5.0.0-alpha5 released","url":"\/blog\/elasticsearch-5-0-0-alpha5-released","author":{"name":"Clinton Gormley"},"date":"August 08, 2016","category":"Releases","locales":"","content":" Today we are excited to announce the release of based on . This is the fifth in a series of pre-5.0.0 releases designed to let you test out your application with the features and changes coming in 5.0.0, and to give us feedback about any problems that you encounter. Open a bug report today and become an . This is an alpha release and is intended for . Indices created in this version . Development of Elasticsearch 5.0.0 is nearing completion. This release contains more bug fixes and enhancements than it does new features (all of which you can read about in the release notes linked above), but there are a few gems worth mentioning. Also take a look at the release announcements for , , , and to read about features like: Known networking bug in 5.0.0-alpha5We have discovered is a major bug in the new Netty4 implementation in this release which affects any REST requests greater than 1024 bytes in size, and which will generate an exception similar to the following:This is due to incorrect handling of the HTTP header, and it can be worked around in one of three ways: \n"}
{"index": {"_id": 538}}
{"title":"Logstash Lines: Grok timeout option, SSL for TCP output and more","seo_title":"","url":"\/blog\/logstash-lines-2016-08-08","author":{"name":"Suyog Rao"},"date":"August 08, 2016","category":"The Logstash Lines","locales":"","content":" Welcome back to The Logstash Lines! In these weekly posts, we'll share the latest happenings in the world of Logstash and its ecosystem.LS has used a home-grown library called Cabin to do all its structured logging. As we write more Java components in core and in plugins, we've had to our logging framework across the board to Log4j. Also, log4j brings in nice features like log rotation, per-component based logging... With this feature, we will also be able to control setting log levels dynamically via an API. Tal recently demoed a of this, and we're putting finishing touches.Logstash's plugin documentation gets generated from the asciidoc embedded in the code itself. Recently we've been running into many issues with plugin generation tool, which was written a while ago. PH has been to make it more robust while adding much-needed enhancements like versioned docs, generating directly from Github repo, easy html preview, dealing with dependencies etc. \n"}
{"index": {"_id": 539}}
{"title":"Elasticsearch: Verifying Data Integrity with External Data Stores","seo_title":"","url":"\/blog\/elasticsearch-verifying-data-integrity-with-external-data-stores","author":{"name":"Chris Earle"},"date":"August 08, 2016","category":"Engineering","locales":"de-de,fr-fr,ja-jp,ko-kr","content":" Elasticsearch is sometimes used alongside other databases. In those scenarios, it's often hard to implement solutions surrounding due to the lack of transaction support across all systems in play. Depending on your use case, it may or may not be necessary to verify the data exists in both data stores, where one serves as the so-called \"source of truth\" for the other. As Support Engineers at Elastic, we frequently see requests that ask things like the best way to structure your data for verification as well as simply how to do verification efficiently. This blog post will walk through a few examples that we have seen and helped to create, ranging from simple to advanced, that verify Elasticsearch contains the necessary data from a database like PostgreSQL. Modeling Data for VerificationThe way that your data is stored, both in and out of Elasticsearch, can make a big difference in the difficulty of verification. The first thing that you need to decide is how much needs to be verified: That decision has ramifications on the amount of effort required to perform verification. Evolution of Verifying ExistenceFortunately this is not a deep, philosophical question. Instead, it's simply the question: \"do all of the documents exist in Elasticsearch?\" Elasticsearch offers a lot of ways to verify existence, as long as you fully understand what is happening. Remember that , but it can get documents directly in real time. This means that, right after indexing a document, it may not be visible to searches, but it will be available to any direct get request. One By OneFor small scale deployments, the simplest approach is to perform requests against individual documents, then confirm that the HTTP response code is not 404 (page \u2014 or document in this case \u2014 not found). HEAD \/my_index\/my_type\/my_id1 An example response would be just headers for success: HTTP\/1.1 200 OK Content-Type: text\/plain: charset=UTF-8 Content-Length: 0 And for non-existence, it looks practically the same, minus the response code: HTTP\/1.1 404 Not Found Content-Type: text\/plain: charset=UTF-8 Content-Length: 0 This requires that you perform requests against an index expected to have documents. As you might expect, that does not scale very well. Batch ProcessingThe next thing that you might choose to do is to perform these in batch requests using Multi GET API: . GET \/my_index\/my_type\/_mget { \"ids\": [ \"my_id1\", \"my_id2\" ] } Another equivalent approach to this is to simply search for the IDs and return the expected number. GET \/my_index\/_refresh GET \/my_index\/my_type\/_search { \"size\": 2, \"query\": { \"ids\": { \"values\": [ \"my_id1\", \"my_id2\" ] } } } First, the endpoint is invoked to ensure that everything indexed is searchable. This removes the \"near real time search\" aspect of searching. Under normal searching conditions, you should not be doing that, but it makes total sense here! Presumably your verification processing happens all at once, so calling at the start of a job is sufficient for the rest of it as long as you're not checking for new data that comes in after the process starts. That offers a superior request handling, but it does not avoid the background work, which remains unchanged, and it means that each document is going to be returned as well, which means added overhead. Search, Then BatchFrom batch processing, people generally branch off to try to beat the problem by subdividing it. First, they will often perform a search to determine what is missing and only then begin digging for the missing document: GET \/my_index\/_refresh GET \/my_index\/my_type\/_search { \"size\": 0, \"query\": { \"ids\": { \"values\": [ \"my_id1\", \"my_id2\" ] } } } If you check the response's value, then it should match the number that you expect. In this simple example, it should be . If it's not 2, then you need to switch gears and either: There Must Be A Better WayThe long-winded or two-step processing can be a bit messy at scale, and it really implies that you're asking an expensive question, but also that you're perhaps asking the wrong question. What if you flipped the query or question on its head and, instead of effectively querying for \"find everything that exists\", you asked \"what is missing?\" It is hard to query for \"what is not here\" and, in fact, it's downright impossible because the data does not exist. However, we can use aggregations to answer the question you can structure data conveniently. Most verification use cases come from an SQL world, where integer-based keys are extremely common for primary keys and foreign keys. Even if you do not use those numeric IDs as your Elasticsearch , you should be indexing those as integer-based values with (on by default in ES 2.x and later). For example: POST \/my_index\/my_type\/my_id1 { \"id\": 1, \u2026 } The name of the field is irrelevant, but do note that it's not , which is a reserved metadata field in Elasticsearch. Once you start indexing that value, then finding data becomes very simple with histograms: GET \/my_index\/my_type\/_search { \"size\": 0, \"aggs\": { \"find_missing_ids\": { \"histogram\": { \"field\": \"id\", \"interval\": 1, \"min_doc_count\": 0 }, \"aggs\": { \"remove_existing_bucket_selector\": { \"bucket_selector\": { \"buckets_path\": { \"count\": \"_count\" }, \"script\": { \"inline\": \"count == 0\", \"lang\": \"expression\" } } } } } } } This does two things: By removing what exists, we're left with what does not exist which might look something like this: { \"took\": 4, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"failed\": 0 }, \"hits\": { \"total\": 5, \"max_score\": 0, \"hits\": [] }, \"aggregations\": { \"find_missing_ids\": { \"buckets\": [ { \"key\": 4, \"doc_count\": 0 } ] } } } From a tiny index with 5 documents, known thanks to , this shows that you are missing the document whose is 4. That's all there is to it: if you can create a histogram from the unique key of the document, then you can create one that only shows missing data. You cannot do this with strings, which means things like and UUIDs (e.g., a GUID) cannot use this approach with aggregations! It comes back to structuring your data for this type of check. Mind The GapFor those not very familiar with sequential identifiers, it is not uncommon for systems (e.g., SQL databases) to prefetch batches of identifiers. Within those batches, it's possible for some values to get skipped for many reasons, such as a failed transaction or even for simpler reasons like the record being deleted explicitly afterward. In such cases, you need to be aware that those will appear as missing documents according to the histogram. To avoid them, as the client, you can tell Elasticsearch to explicitly ignore those values by adding a secondary bucket selector that eliminates those s explicitly, or ignore them on the client side. Verifying Entire DocumentsThe verification of entire documents is a different beast from simple existence checking. In this scenario, entire documents need to be verified to ensure that the data contained is the expected data. From the Elasticsearch standpoint, it's actually easier, but the work on your side is more difficult. Scrolling Through DataThe simplest way to perform this check is to scroll through it. Fortunately, this does not mean piping all of your data into an HTML table and using your mouse wheel to double check everything. No, it means using the (, used below,\u00a0is described in that link). Like every search API, it also works on the same near real time principles noted above. GET \/my_index\/my_type\/_search?scroll=1m { \"sort\": [ \"_doc\" ] } The scroll time is the amount of time that you, as client software, need to process that batch before requesting the next batch. Make sure that it's long enough to be able to loop through the subsequent response and read through the linked documentation above! By scrolling through the data, you can go document-by-document and verify all of the data is correct per your requirements. Taking Control of VersioningElasticsearch supports , which is another way to say versioning. You can take complete control of versioning by supplying your own version number. If you do this, then you can possibly side-step full document verification by verifying version numbers. To enable version numbers in search responses, you must specify the version flag: GET \/my_index\/my_type\/_search { \"version\": true } Side-Stepping VerificationIt is possible that you can side-step verification altogether, if you can trust that the data was only provided by a trusted user and any ingestion failures were properly handled (e.g., if Elasticsearch was down when document 15123 should have been indexed, then something still needs to add it). In that scenario, then verification can become redundant. in 5.0 and in earlier releases can provide the security aspect to give trusted users access and block untrusted users, but it is up to you to properly handle ingestion failure because it completely depends on what is doing the ingestion. FinYou have done it! You made it through my long blog post. I hope that you enjoyed reading about data verification and how structuring your data can lead to dramatically simplified approaches to doing it. Thinking about this kind of approach, you can start to see how other problems can be solved by thinking about the query or data differently, alongside rich features like aggregations or X-Pack Security. We are constantly looking for creative ways to solve interesting problems, and this is no exception. As always, we encourage our users to discuss these issues on our , and open GitHub issues for any issues that you may come across and we are also available on ( for me) and to help you out! \n"}
{"index": {"_id": 540}}
{"title":"Searching numb3rs in 5.0","seo_title":"","url":"\/blog\/searching-numb3rs-in-5.0","author":{"name":"Adrien Grand"},"date":"August 04, 2016","category":"Engineering","locales":"","content":" Lucene 6.0 introduced new exciting feature called . While the name of the feature puts a lot of emphasis on the fact that it supports multiple dimensions, this feature behaves more than decently in the case of a single dimension and actually better than the that was used in previous versions of Lucene. This caused us to refactor number-based fields (, , , , , , and ) to use this new data-structure for indexing numbers. How does it work? The current data-structure that underlies dimensional points is called a , which in the case of a single dimension is a simple binary search tree that stores blocks of values on the leaves rather than individual values. Lucene currently defaults to having between 512 and 1024 values on the leaves. This is quite similar to the b-trees that are used in most regular databases in order to index data. In the case of Lucene, the fact that files are write-once makes the writing easy since we can build a perfectly balanced tree and then not worry about rebalancing since the tree will never be modified. Merging is easy too since you can get a sorted iterator over the values that are stored in a segment, then merge these iterators into a sorted iterator on the fly and build the tree of the merged segment from this sorted iterator. Comparison with the old number implementation While Mike already reported that than the old implementation, things got even better with recent optimizations in Lucene 6.1 and the upcoming 6.2: So I re-ran the same benchmark as in the to get a more up-to-date comparison in the case of a single dimension. google.charts.load('current', { packages: ['corechart', 'bar'] }): google.charts.setOnLoadCallback(draw1DQueryTime): function draw1DQueryTime() { var data = google.visualization.arrayToDataTable([ ['Approach', 'Query time (msec)', { role: 'style' }], ['Points', 25.0, '#e62739'], ['Numeric Field', 39.3, '#9068be'], ]): var options = { title: 'Query time (msec)', chartArea: { width: '50%' }, hAxis: { minValue: 0 }, vAxis: { }, legend: { position: \"none\" }, }: var chart = new google.visualization.BarChart(document.getElementById('query_time_1d_div')): chart.draw(data, options): } google.charts.setOnLoadCallback(draw1DIndexTime): function draw1DIndexTime() { var data = google.visualization.arrayToDataTable([ ['Approach', 'Index time (sec)', { role: 'style' }], ['Points', 62.3, '#e62739'], ['Numeric Field', 217, '#9068be'], ]): var options = { title: 'Index time (msec)', chartArea: { width: '50%' }, hAxis: { title: 'Index time (msec)', minValue: 0 }, vAxis: { }, legend: { position: \"none\" }, }: var chart = new google.visualization.BarChart(document.getElementById('index_time_1d_div')): chart.draw(data, options): } google.charts.setOnLoadCallback(draw1DIndexSize): function draw1DIndexSize() { var data = google.visualization.arrayToDataTable([ ['Approach', 'Index size (MB)', { role: 'style' }], ['Points', 251, '#e62739'], ['Numeric Field', 744, '#9068be'], ]): var options = { title: 'Index size (MB)', chartArea: { width: '50%' }, hAxis: { title: 'Index size (MB)', minValue: 0 }, vAxis: { }, legend: { position: \"none\" }, }: var chart = new google.visualization.BarChart(document.getElementById('index_size_1d_div')): chart.draw(data, options): } google.charts.setOnLoadCallback(draw1DSearchHeap): function draw1DSearchHeap() { var data = google.visualization.arrayToDataTable([ ['Approach', 'Search time heap (MB)', { role: 'style' }], ['Points', 2.12, '#e62739'], ['Numeric Field', 14.4, '#9068be'], ]): var options = { title: 'Search time heap (MB)', chartArea: { width: '50%' }, hAxis: { title: 'Search time heap (MB)', minValue: 0 }, vAxis: { }, legend: { position: \"none\" }, }: var chart = new google.visualization.BarChart(document.getElementById('search_heap_1d_div')): chart.draw(data, options): } For this particular data and set of queries, points proved 36% faster at query time, 71% faster at index time and used 66% less disk and 85% less memory. Numbers may differ based on the data and queries, but we are confident that points will perform much better on average than the current implementation, especially in the case of very high-cardinality fields. New number types Beats is pushing the limits of Elasticsearch when it comes to numbers. For time series use-cases in general, users want to be able to index as fast as possible using as little disk space as possible. While integer types are easy to compress based on the number of bits that they actually use (for instance if all integers are between 2 and 200, they can be encoded on one byte), the same is not true for floating-point data. In particular, the fact that they cannot represent decimals accurately makes them use all available bits in order to be as close as possible to the value that needs to be represented. This makes compression hard since values in a given segment rarely have a pattern that can be leveraged for compression. But do you actually need the accuracy of a float or a double for your data, or would you happily trade some precision for reduced disk usage and faster queries? For those to whom this sounds like a logical trade-off, we introduced two new field types called and . work the same way as floats and doubles, except that they use fewer bits for the mantissa and the exponent, allowing them to be stored on 16 bits in total, rather than 32 in the case of floats and 64 in the case of doubles. However beware that this storage reduction comes at a cost: they only have 3.3 significant decimal digits and the maximum value is . We suspect the new field will be even more useful in practice: it takes a scaling factor and for every value, it internally stores the long that is closest to the product of the value and the scaling factor. For instance, with a scaling factor of 100, would internally be indexed as and all queries and aggregations would behave as if the value was actually . This helps because even though values are decimal, they are internally encoded as integers, which Lucene can compress more efficiently. Conclusion Number support improved greatly in the upcoming 5.0 release. Feel free to give a try to the if you want to check out these improvements on your data. \n"}
{"index": {"_id": 541}}
{"title":"Kibana 4.5.4 and 4.1.11 Released","seo_title":"Kibana 4.5.4 and 4.1.11 Released","url":"\/blog\/kibana-4-5-4-and-4-1-11","author":{"name":"Court Ewing"},"date":"August 03, 2016","category":"Releases","locales":"","content":" Today we\u2019re releasing Kibana versions 4.5.4 and 4.1.11, which include two security fixes, an increase in the maximum zoom capabilities for tile maps, and some other bug fixes. Since these are security releases, we recommend that users upgrade as soon as possible. You can grab the latest versions from the page. 4.5.4 4.1.11 Conclusion As always, head over to our page to get the latest versions. If you have any questions, please don\u2019t hesitate to reach out to us on our , , or . \n"}
{"index": {"_id": 542}}
{"title":"Elasticsearch 2.3.5 released","seo_title":"Elasticsearch 2.3.5 released","url":"\/blog\/elasticsearch-2-3-5-released","author":{"name":"Clinton Gormley"},"date":"August 03, 2016","category":"Releases","locales":"","content":" Today we are pleased to announce the release of based on . This release contains only bug fixes for Marvel, Watcher, and Shield\u2009\u2014\u2009there are no changes to core Elasticsearch. It is already available for deployment on , our Elasticsearch-as-a-service platform.Latest stable release:Full details of the changes in this release are available in the release notes listed above, but the most important change is that Shield again works correctly with Tribe Nodes. \n"}
{"index": {"_id": 543}}
{"title":"The Art of a Pull Request","seo_title":"","url":"\/blog\/art-of-pull-request","author":{"name":"Nicol\u00e1s Bevacqua"},"date":"August 03, 2016","category":"Engineering","locales":"","content":" The Art of a Pull Request \n"}
{"index": {"_id": 544}}
{"title":"Elasticsearch for Apache Hadoop 2.3.4 released","seo_title":"","url":"\/blog\/es-hadoop-2-3-4-released","author":{"name":"James Baiera"},"date":"August 03, 2016","category":"Releases","locales":"","content":" I am pleased to announce the release of Elasticsearch for Apache Hadoop (aka ES-Hadoop) . ES-Hadoop 2.3.4 is primarily a bug-fix release, including some new configuration validation steps, smarter parsing of index mappings, and support for the latest and greatest Elasticsearch version . Feedback Looking forward to hearing your feedback on this ! Drop us a line on , Twitter (), , or the . \n"}
{"index": {"_id": 545}}
{"title":"Logstash Lines: Beats Input Performance and other fixes","seo_title":"","url":"\/blog\/logstash-lines-2016-08-02","author":{"name":"Suyog Rao"},"date":"August 02, 2016","category":"The Logstash Lines","locales":"","content":" Welcome back to The Logstash Lines! In these weekly posts, we'll share the latest happenings in the world of Logstash and its ecosystem. In preparation for persistence feature landing in 5.x, we added to the 5.0 pipeline. We now have a separate read (consumer) client and write (producer) client that deals with queue operations. We also encapsulated all the event batch management to a separate class. A couple of us were involved in a user's throughput issue with Redis input for LS 2.3.4. User was migrating from 1.4.x and had experienced a slowdown. We'll convert all the good info in this issue to a blog. We are still input's performance. The current rewrite in Java has given us a 50% increase in throughput performance, but our preliminary tests had shown ~100% increase! Anyhow, the good news is that the current beats input + filebeat combo is much faster than the LSF + lumberjack input combo, which was our original goal for this project. We are shipping this change in 5.0.0-alpha5 and will backport it to 2.4. \n"}
{"index": {"_id": 546}}
{"title":"Brewing in Beats: Configure the Ingest Node Pipeline","seo_title":"","url":"\/blog\/configure-pipeline-ingest-node","author":{"name":"Monica Sarbu"},"date":"August 02, 2016","category":"Brewing in Beats","locales":"","content":" New community Beat: Cassandrabeat Filebeat: Unmarshal JSON inputs to integer by default The standard library in Golang unmarshals the integer values of the json object into floats instead of integers. This leaded to some unexpected behaviour when using the conditions from processors as you couldn\u2019t easily compare a status code from the JSON object as it was translated to float64. The overwrites the Unmarshal behaviour and it tries to convert the numbers from the json objects to integers first, and if it fails then it converts them to floats. This way, unmarshals as int64 and as float64. Metricbeat: Enhance load metrics A new Metricset called is exported by Metricbeat instead of exporting the load statistics inside the CPU statistics. With this \u00a0 becomes , becomes and becomes . In addition, the load values divided by the number of cores are exported under . Filebeat: Fix state remove and sending empty logs When a very low is set, then it could happen that a state of a finished harvester was overwritten by the prospector and the state is never set to Finished. This is now in that the prospector only sends a state when the state is set to Finished. In addition, there is a to not send empty log lines. Community Beats: Create pure Go binaries in packaging by default The makes the Beat generator assume the Beat is pure Go (doesn\u2019t have C dependencies). This simplifies the packaging process and produces fully static binaries by default. It\u2019s still possible to create packages for the Beats that require Cgo, but you need to adjust the Makefile. Use the as an example of the possible features. Add support for cgroup in gosigar The gives you the ability to ask gosigar for cgroup stats by PID. It returns metrics and limits from the , , , and subsystems. This is part of a larger effort to build a solution on top of Beats to monitor containers. \n"}
{"index": {"_id": 547}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-08-01","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-08-01","author":{"name":"Michael McCandless"},"date":"August 01, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top News \u2014 Christoph Wurm (@ChristophWurm) Elasticsearch Core Changes in 2.x: Changes in master: Ongoing changes: Apache Lucene Watch This Space , where we'll share more news on the whole Elastic ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 548}}
{"title":"Earthquake data with the Elastic Stack","seo_title":"","url":"\/blog\/earthquake-data-with-the-elastic-stack","author":{"name":"Kosho Owa (JP)"},"date":"August 01, 2016","category":"Engineering","locales":"","content":" INTROThe Elastic Stack is fantastic for analysing time based data, most of which we currently see coming from operational requirements around things like system load, memory or disk use, network flows, application error rates and so on. However, the awesome thing about the stack is that it isn't tied to time based data consisting of logs or metrics. Here we'll take a look at earthquake data from the Northern California Earthquake Data Center, via the , this data set includes naturally occurring quakes, as well as man-made ones from nuclear blasts and quarry explosions. You may not be shaking in your boots with excitement yet, but we'll show a few neat tricks around leveraging custom maps, visualisations and other tips to increase usability for your users and to give things a bit of extra shine. FIRST STEPSTo get this dataset into Elasticsearch we built a very simple Logstash configuration with the CSV, mutate and date filters. We've also created mappings for the fields in the data and converted that into a template. If you want to play along at home, then head over to and either clone it or download the files, then follow the instructions to get the data loaded. The dashboards are all provided, but we'll dig into the bits that make this an interesting use case throughout this post, so don't go anywhere! VISUALISING WITH YOUR EYEBALLS When you open the main Earthquake dashboard (as seen above), you can see we've broken down the data into different groupings, which are also separate dashboards themselves. These are based on Hot Areas around the world, Catalogues, or archives, and finally, by a few specific Quarries and Nuclear Blasts. This is a basic visualisation that's a handy way for introducing your data to your users. Rather than letting them click around and figuring out what the data is all about, you can help frame their discovery process by creating dashboards that link to specific subsets of your data. It's also a great way to introduce concepts such as filters and the ability to build multiple dashboards with different visualisations for different audiences, but all based on the one dataset. One tip we also really like in markdown boxes like this, is having a simple \"return to home\" or \"reset time frame\" link that can help if someone gets lost or makes changes they didn't want. This helps with time based data, as you can have a link to the dashboard with the last 5\/10\/100 minutes\/months\/years without them having to jump into the timepicker. We've called our reset link Go back to the world map. and it's at the bottom of markdown box. Moving on, and next to that we have a heat map of all the events, which has been populated thanks to the inclusion of latitude and longitude in the dataset, that was then converted to a single field and then mapped to a using the Elasticsearch template. Note that this is a standard Kibana heatmap, we'll touch on some custom maps goodness later. Then we have a few high level metrics, a histogram of all the magnitudes for the given time period, a breakdown of quake type (natural or man made) and then (ie the network operator code for the detectors) of each of these. Finally we have a bar chart showing a date histogram of all the events for each month, with a count of each magnitude, and below that a Timelion plot showing the average depth of the quakes, broken down per-week as dots, with a moving average of those depths over the past 3 months as a line graph. Let's look at all of this in more detail. SECOND STEPSNow we will open up the dashboard, you can do that by clicking Japan under the Hot Areas links, or finding the dashboard using the Load Saved Dashboard button on the top right of the toolbar. The first thing we notice is that a saved filter has been applied, the little green box labelled \"Japan Territorial Water\". Interestingly. this is actually a query that isn't currently exposed natively in Kibana, luckily for us, Kibana does allow us to specify custom queries to pass to Elasticsearch and then have applied in our dashboard. If you mouse over the box and click the Edit button, the one that looks like a pencil and is the furthest icon on the right of the filter, you can see how this has been set up as a filter, with the points being an area that contains Japan's territorial waters. As we are only looking at data points within the general Japan region, as defined by our polygon, the other visualisations also change the values that they report. This is one of the great features of Kibana as it automatically puts all of the data we are looking at in the same point of reference. If you compare the average depth of quakes in Japan to all events worldwide from the previous dashboard, it is nearly 300% more than the average and the quakes that strike the region are also usually a magnitude 4. People sometimes think Kibana visualizations are static, but most of them are capable of running queries and aggregations dynamically on the dashboard. Let's zoom to around 2010 to the end of 2011. What is also obvious here is a spike in quakes from December 2010 through to July 2011, as we know this is when the T\u014dhoku earthquake and tsunami occurred. Moving onto the Timelion visualisation, the average depth of the quakes around this time are also very consistent and relatively shallow, which was why the event was so devastating. The last few visualisations, which are also from Timelion, show a number of interesting statistics that are taken dynamically from the World Bank API. This is another neat feature that Timelion has and you can read more on it here. By mousing over the any of the Timelion graphs we can see a horizontal line showing the current time period we are over, this line is carried over to all other Timelion visualisations on the dashboard, which lets us quickly draw correlations between the data. After the financial crisis happened in 2008, the GDP grown of Japan was in the recovery but the trial was broken and the direct investment finally became minus in 2011. Opposite to the situation, Japanese Yen was strong at that time. DOWN AND DIRTY WITH MAPSThose with sharp eyes may have noticed that the graphs in the Earthquake - Japan dashboard are different to the main Earthquake dashboard. Here we have leveraged the ability for Kibana to import WMS compliant maps from other sources and taken something from . We have used this map server as when we display the heatmap on top of the supplied bathymetric chart, you can very easily find out the connection between the earthquakes and oceanic trenches. The dashboard can be used not only for showing statistics and exploring the data, but also recording the event happened in the past. In the \"Catalogues\" section of the dashboard, we have put some historical tragedies caused by earthquakes. Click on under the \"Catalogues\". According to , \"The 1989 Loma Prieta earthquake occurred in Northern California on October 17 at 5:04 p.m. local time. The shock was centered in The Forest of Nisene Marks State Park approximately 10 mi (16 km) northeast of Santa Cruz on a section of the San Andreas Fault System and was named for the nearby Loma Prieta Peak in the Santa Cruz Mountains.\" Let's locate where it happens. We know the maximal magnitude of the earthquake is about 7 so type into the query area of Kibana. Now a blue dot appears on the center of the map which is the epicenter of the biggest earthquake. We sometimes find something unexpected while exploring public datasets. When we were looking at man made quakes, typically quarries and blasts, in Nevada states, we found some hot spots on the north west of Las Vegas where could be considered as nuclear bomb testing sites. Those were quite often from the 60's to the 80's. We also found two blue dots in Henderson city which shouldn't be nuclear explosions. According to the timeline, those blasts happened on May 4th 1988. As We searched \"henderson explosion may 4 1988\" on Google, it seems those are the evidences of . Two of those explosions are huge as equal to magnitude 3 earthquakes. OUTROHopefully we have given you a few good tips for getting the most from Kibana. Whether it's as simple as adding a markdown box with some intro text and links to other dashboards to help guide your users, integrating Timelion visualisations showing correlation of data from external sources against the data in Elasticsearch, or getting really advanced and importing your own maps. As a reminder, you can find the dataset, Logstash configs, Elasticsearch mappings and Kibana dashboards at this\u00a0 - so please check it out, see how the methods we have talked about in the blog post were applied, and leverage it to make something awesome of your own. The really cool part about all of what we have looked at here: If you're someone like the United States Geological Survey (USGS), you can ingest tweets in real time to detect when earthquakes have hit regions that may not have adequate detection systems, and then build insightful dashboards to visual that data! To see more of how that works for them, watch their fantastic talk from Elastic{ON} 2015 . If you have further questions or comments about any of this, please head over to our , or hit us up on Twitter via @elastic \n"}
{"index": {"_id": 549}}
{"title":"Getting Started with Elasticsearch and SSL & Native Authentication","seo_title":"Getting Started with Elasticsearch and SSL & Native Authentication","url":"\/blog\/getting-started-with-elasticsearch-ssl-native-authentication","author":{"name":"Jason Bryan"},"date":"July 28, 2016","category":"Engineering","locales":"","content":" When planning to stand up a new Elasticsearch cluster, it is important to make considerations for implementing authentication and SSL\/TLS with Shield as early as possible. Getting this going in the planning and testing phases will help ensure a smoother transition to production with security in place. In this article, we walk through setting up Shield's native authentication and SSL\/TLS with a wildcard certificate. Native authentication is by far the simplest way to manage users and it will be the default in X-Pack for Elasticsearch 5.x.\u00a0 There are many ways to setup SSL\/TLS, and in this post we will go through one of them that I find simple and easy to use for all my development environments. Prior to proceeding, be sure you have a certificate authority (CA) in place. A private (self-signed) or public CA can be used. Getting Started1. 2. Install the License and Shield plugins bin\/plugin install elasticsearch\/license\/latest bin\/plugin install elasticsearch\/shield\/latest 3. Configure for Shield's file and native authentication. stores users and passwords in file stored locally on each cluster node. With , users are managed with a REST API and centrally stored in the cluster. In Elasticsearch 2.3.x, file-based authentication must be configured prior to using native authentication to gain access to the cluster. This step will not be required in 5.x. shield: authc: realms: file1: type: file order: 0 native1: type: native order: 1 4. Create an admin user with the command that will be used for file-based authentication. bin\/shield\/esusers useradd admin -p as@m25 -r admin 5. Test authentication to the cluster using a REST client. I like curl, but any REST client will do. curl -s 'http:\/\/node1.kle.moc:9200' -u admin:as@m25 { \"name\" : \"roger\", \"cluster_name\" : \"kermy\", \"version\" : { \"number\" : \"2.3.4\", \"build_hash\" : \"e455fd0c13dceca8dbbdbb1665d068ae55dabe3f\", \"build_timestamp\" : \"2016-06-30T11:24:31Z\", \"build_snapshot\" : false, \"lucene_version\" : \"5.5.0\" }, \"tagline\" : \"You Know, for Search\" } Native AuthenticationUse the Shield REST API to configure and manage users for native authentication. To setup the first native admin user, use the file-based credentials. curl -u admin:as@m25 'http:\/\/node1.kle.moc:9200\/_shield\/user\/esadmin' -XPOST -d ' { \"password\": \"as@m25\", \"roles\": [ \"admin\" ], \"full_name\": \"Search Admin\", \"email\": \"searchadmin@kle.moc\" }' Confirm the native user was setup successfully with a REST call. curl 'http:\/\/node1.kle.moc:9200' -u esadmin:as@m25 { \"name\" : \"roger\", \"cluster_name\" : \"kermy\", \"version\" : { \"number\" : \"2.3.4\", \"build_hash\" : \"e455fd0c13dceca8dbbdbb1665d068ae55dabe3f\", \"build_timestamp\" : \"2016-06-30T11:24:31Z\", \"build_snapshot\" : false, \"lucene_version\" : \"5.5.0\" }, \"tagline\" : \"You Know, for Search\" } Configuring SSL\/TLSCreate the Java KeystoreIn this example, a wildcard certificate will be used as it provides ease of administration across a large Elasticsearch cluster. Wildcards permit a single certificate to be used for every node in the cluster. While this is a convenient way to manage cluster certificates, be sure to take into consideration the risk factors associated with using wildcards. It is assumed an issuing certificate authority (CA) is already in place. See the article for help setting up your own CA that can be used with Shield. 1. Create a new Java Keystore by importing the CA certificate that will issue the wildcard certificate. Note: the Java Keystore can be created on any host or workstation with Java installed using the command. keytool -importcert -keystore shield.jks -file ca.cert.pem -trustcacerts -storepass s3cret -alias ca_cert 2. Create a private key in the Java Keystore. keytool -storepass s3cret -genkey -alias es-shield -keystore shield.jks -keyalg RSA -keysize 2048 -validity 3650 -dname \"cn=*.kle.moc\" 3. Create a certificate signing request (CSR) using for requesting a certificate from the issuing CA. keytool -storepass s3cret -certreq -alias es-shield -keystore shield.jks -keyalg RSA -keysize 2048 -validity 3650 -dname \"cn=*.kle.moc\" > kermy-shield.csr 4. Once the CA has signed the CSR and returned the certificate in PEM format, import it into the Java Keystore. Be sure the alias lines up with the one used in steps 2 and 3. keytool -storepass s3cret -importcert -keystore shield.jks -alias es-shield -file kermy-shield.pem Certificate reply was installed in keystore Configure Elasticsearch1. Copy to the Elasticsearch configuration directory . 2. Configure elasticsearch.yml for SSL\/TLS shield: http.ssl: true ssl: keystore.path: shield\/shield.jks keystore.password: s3cret My full cluster.name: kermy node.name: roger network.host: _ens160:ipv4_ http.port: 9200 transport.tcp.port: 9300 shield: http.ssl: true ssl: keystore.path: shield\/shield.jks keystore.password: s3cret authc: realms: file1: type: file order: 0 native1: type: native order: 1 And the final curl test with SSL\/TLS and native authentication curl 'https:\/\/node1.kle.moc:9200\/' -sku esadmin:as@m25 -v * Trying 192.168.5.50... * Connected to node1.kle.moc (192.168.5.50) port 9201 (#0) * TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA * Server certificate: *.kle.moc * Server certificate: Unicorn Ltd CA * Server auth using Basic with user 'esadmin' > GET \/ HTTP\/1.1> Host: node1.kle.moc:9200 > Authorization: Basic ZXNhZG1pbjphc0BtMjU= > User-Agent: curl\/7.43.0 > Accept: *\/* > < HTTP\/1.1 200 OK < Content-Type: application\/json: charset=UTF-8 < Content-Length: 306 < { \"name\" : \"roger\", \"cluster_name\" : \"kermy\", \"version\" : { \"number\" : \"2.3.4\", \"build_hash\" : \"e455fd0c13dceca8dbbdbb1665d068ae55dabe3f\", \"build_timestamp\" : \"2016-06-30T11:24:31Z\", \"build_snapshot\" : false, \"lucene_version\" : \"5.5.0\" }, \"tagline\" : \"You Know, for Search\" } * Connection #0 to host node1.kle.moc left intact Enabling SSL\/TLS and authentication should be at the forefront of every service running in your infrastructure, including Elasticsearch. Once this configuration is in place, it can be modeled for further production use when adding new nodes or creating more clusters.\u00a0 We want to help you ensure that your Elasticsearch cluster is safe and secure. and we welcome your feedback via the or file a support ticket. \n"}
{"index": {"_id": 550}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-07-26","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-07-26","author":{"name":"Michael McCandless"},"date":"July 26, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top News Wrote a post about combining RestClient with templates for creating and executing queries: \u2014 Jettro Coenradie (@jettroCoenradie) Elasticsearch Core Apache Lucene Watch This Space , where we'll share more news on the whole Elastic ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 551}}
{"title":"A History of Logstash Output Workers","seo_title":"","url":"\/blog\/a-history-of-logstash-output-workers","author":{"name":"Andrew Cholakian"},"date":"July 25, 2016","category":"Engineering","locales":"","content":" SummaryA Brief OverviewThis blog post is meant to clarify the output worker changes in Logstash 2.2+, and to discuss how we\u2019ll be improving output workers in the future. Logstash 2.2 introduced the\u00a0\u00a0which provided a sizable performance improvement. It has created some confusion however. Prior to 2.2 there was a notion of Filter Workers (FWs) and Output Workers (OWs). Filter workers executed everything in the\u00a0\u00a0portion of the config, and each plugin in the\u00a0\u00a0portion could use a user definable number of OW threads. In 2.2 these were both replaced with one concept of Pipeline Workers (PWs). Confusingly, you can still set OWs, and they still do something very important. Let\u2019s compare and contrast.\u00a0The animation below contrasts the threading model between 2.1 and 2.2.To put it a bit more formally:The upshot of this change is that in 2.2+\u00a0, which now controls the pipeline worker setting, controls how many concurrent threads can exist for the filter and output stage combined (PWs). The output worker setting controls how many of those threads can simultaneously work on that output. The takeaways here are:Output workers should never be set to a number > the number of pipeline workers, since that is the maximum number that can be simultaneously used. You may need more PWs than cores on your system since multiple PWs can be blocked on I\/O in a single OW object. Increasing the number of OWs often provides a tangible benefit but be careful. For some outputs adding more can either slow them down or cause them to break in subtle ways.A more in-depth exploration of the history and the evolution of pipeline architecture is available in this video by Logstash creator Jordan Sissel. We encourage you to watch this! Why Autoscaling Output Workers in Logstash 2.2 was a MistakeThe NG pipeline was released in 2.2 a few months after 2.0 went out. In Logstash 2.0 we had switched the default protocol for the Elasticsearch output to HTTP. One concern here was that while the plugin was nearly identical in performance \/ resource utilization to the old default of the Elasticsearch Transport protocol it needed more OWs to reach parity. There was a concern that users upgrading from 1.x to 2.x might feel this slowdown due to the defaults and not tune OW settings. We thought it would also be generally good to, by default, set the number of OWs for every plugin to be equal to the number of PWs. We code reviewed each output we maintain for concurrency issues and set the required options on ones that didn\u2019t support > 1 OW, which meant that the pipeline would leave these at a single OW. This turned out to have some...err\u2026 adverse effects.The main problem with this approach is that doing post-hoc code reviews for concurrency is hard. We have a truly massive amount of plugins which made the task even harder. We started getting bug reports in the 2.2.x series related to plugins we\u2019d missed that may have been threadsafe in terms of data structures, but not in terms of logic.We made the decision that it was premature to assume that all outputs would behave well in a concurrent environment and to let those bugs shake out in a minor release, so, we reverted it, setting the default back to one OW. So, users who saw speed gains in 2.2.x might have seen speed losses in 2.3.x out of the box. Improving performance is a top priority for us, but correctness of outputs is of even greater importance. Luckily we can achieve both with the new model we\u2019re incorporating into the upcoming Logstash 2.4 and 5.0 series.All this being said, if you\u2019re having performance problems please read the new\u00a0. Its an easy to follow set of diagnostic and remedial procedures for managing Logstash performance.The FutureThe future is in just\u00a0. We call these \u2018shared\u2019 outputs. Outputs that can\u2019t be parallelized will be the default, and will only support a single instance with synchronized access. The latest version of the ES output (currently only available in 5.x alphas, but most likely coming to ES 2.4.x) is the first shared Logstash output. These outputs manage all their own concurrency internally as a single shared object. The new ES output will run in parallel for as many PWs as you have with no additional configuration. There are some concurrency controls but these must be custom defined by the plugin in a way that makes sense for its own IO. For instance, on the Elasticsearch output plugin the maximum # of connections will be tunable (it defaulted to a very high number by default, at 100), but aside from that there aren\u2019t any.In the future we hope to refactor as many Logstash output plugins as possible to use the new\u00a0\u00a0option, per\u00a0\u00a0and use finer grain locking than what the OW system provided. We\u2019ll provide an update when this is done. In the meanwhile, we encourage our users to discuss these issues on our , and open GitHub issues. We are also available on and to help you out! \n"}
{"index": {"_id": 552}}
{"title":"Brewing in Beats: How Filebeat works","seo_title":"","url":"\/blog\/brewing-in-beats-how-filebeat-works","author":{"name":"Tudor Golubenco"},"date":"July 25, 2016","category":"Brewing in Beats","locales":"","content":" Welcome to Brewing in Beats! With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources. In progress: add cgroup information to gosigarAs part of a larger effort to make container monitoring easy with the Beats, (the library we use in Metricbeat) is getting support for the data from . This gives us not only the CPU and memory usage of each container, but also the configured limits for each. This is a feature requested, for example, by our Cloud team to properly report on the cpu usage as a percentage of the configured limit. Metricbeat: Conversion helpers refactoringThe effort started last week to make most of the parsing and conversion work in Metricbeat declarative was this week. The bulk of the work involved in writing and maintaining a Metricbeat module lies in renaming and converting the metrics, so we hope that doing this declaratively will be an important productivity win. The Metricbeat was also . How Filebeat works documentationGetting confused about what a Prospector or what a Harvester is? Don\u2019t know the difference between and ? We have a explaining the high level Filebeat concepts and docs to explain all the relevant configuration options. Path variables available in the configuration fileIt is now possible to refer to (e.g. path.home, path.data, path.config) in the configuration file. The benefit is that it is a bit more clear to write than just the equivalent . Format string support in libbeatIn several planned features (the lookup feature, , dynamic ) it is useful to be able to format strings based on event fields. This adds supports in libbeat for using a format similar to the one used by Logstash. E.g. `pipeline: %{[fields.type]}`. Metricbeat: add PGID to process dataComing from a , this adds the process group id information to the per process docs. Quickly switch Packetbeat protocols on\/off in configWe have standardized on using as a way to disable most things in the configuration file. For example, if you want to disable a Packetbeat protocol without commenting out 10 lines of config, add . Want to disable an output? Add . Filebeat cleanupsThe effort () of cleaning up the Filebeat code continued last week with this doing lots of small improvements. Potential Filebeat file descriptor leak fixedA potential FD leak was and . The file descriptors would have gotten garbage collected eventually, but it\u2019s better to close them as soon as they are not needed anymore. Kibana Dashboard for the Metricbeat network statsThis adds a new sample dashboard that can be used with the networking stats collected by the Metricbeat system module. \n"}
{"index": {"_id": 553}}
{"title":"Security and Alerting for Elasticsearch: A Vandis Story (Part 2)","seo_title":"Security for Elasticsearch in a logging use case at Vandis.","url":"\/blog\/security-and-alerting-for-elasticsearch-a-vandis-story-part-2","author":{"name":"Haley Eshagh"},"date":"July 25, 2016","category":"User Stories","locales":"","content":" It\u2019s just another day when Shield, Watcher, Marvel, and Beats help Vandis identify and resolve problems before their customers know anything\u2019s amiss.\u00a0 \u00a0 : Watcher is instrumental to us in terms of notifying us when things are going awry inside of a customer network. When we picked up Elasticsearch, we also picked up PagerDuty, and Watcher is tightly integrated with it. Each one of our customers has a service with PagerDuty and each one of those services has on-call, tier-one engineers, and tier-two and tier-three escalation engineers. Any time there's an event, we get notified, days, nights, weekends, and really that's because and Elasticsearch are doing their jobs.: I think we're at 1.2 billion documents right now, and that\u2019s not even 30 days\u2019 worth of data. We have one customer who has a network operations center (NOC). They have a voice monitoring solution and because of how fast Elasticsearch is parsing the logs and alerting, we actually were on the phone with them before the NOC even called to say that they were down. That has been deeply instrumental to us. : is its own cluster running in our data center, watching our clusters to make sure that life continues smoothly. was a requirement for us. As we build out our deployment, it's a requirement for me to have role-based access control so that my sales team can go in and look at something and not expose data to customers or people who shouldn\u2019t have access. Whereas the engineering team needs to have full access to all the data.For example, a proof-of-concept customer the other day called to say, \"We have a problem. We don't know what the problem is.\" We built a Kibana dashboard for them that focused on the threat and almost immediately, they knew that they had a machine within their facility that had been compromised and was infecting other hosts. We were able to turn that around for them in about five to ten minutes. They responded with, \"Wow, we knew about the value, but now we really see the value.\" : Oh, absolutely. I was actually having this debate with someone on a bus on the way to , going from the hotel to the venue. He was telling me that they had support previously, and ended up not renewing. I replied, \"You might want to look at that again. It's a whole different world.\" That got us talking about how he's gone and built his own software stack to pretty much do exactly what Watcher and Shield do. He was lamenting about how many cycles he's spending on that and I said, \"That\u2019s another reason you might want to look at a subscription. You don't have to support or maintain any of that. That's actually done for you. It's part of the deal.\"It's awesome. Shield was probably the driving force to get my management to sign off on a subscription. Then, almost immediately after the engagement began and Jason was sleeves rolled up, deep in it with us, they turn around and were like, \"Oh, there's actually a lot more value to this.\" : I\u2019ll leave you with one cool story. This is actually one of my favorite Elastic stories.All of my engineers were out at a conference. We were running very thin. We had a customer who called and said, \"We have this crazy issue. We can't figure it out. We have our firewall vendor involved. We have our load-balancer vendor involved. We have our virtualization platform vendor involved.\" He went through the full list of vendors. He said, \"Everyone is just pointing fingers at each other. No one is telling me anything.\"I happened to have the most recent versions of Elasticsearch and running on my laptop. I went into the office, threw Packetbeat on their network and let it sit there for an hour. We sat and drank some coffee, talked about our kids, what we're doing on the weekend. Meanwhile, in the background, I have Kibana up and it's just running the dashboards.The customer came back and asked, \"So, any idea what we got going on here?\" We look over at the dashboards, and see they have 75% DNS failure. Their DNS servers had just gone off the reservation. Within an hour, we had root cause and solution.The customer asked, \"What was that?\"We replied, \"Oh, that was Elastic.\"Talk about winning a victory for our team. \n"}
{"index": {"_id": 554}}
{"title":"Cloud Enterprise - The Architecture","seo_title":"Elastic Cloud Enterprise - The Architecture","url":"\/blog\/cloud-enterprise-the-architecture","author":{"name":"Igor Kupczy\u0144ski"},"date":"July 21, 2016","category":"Engineering","locales":"","content":" In today's blog\u00a0post we would like to give you an overview of and its architecture. IntroductionWe'll start by describing what Elastic Cloud Enterprise is and how it differs from our current Software-as-a-Service offering \u2014 . Elastic offers a hosted version of the Elastic Stack named Elastic Cloud. It allows you to run Elasticsearch and Kibana in the cloud. No need to set up the infrastructure or work out the management details. Provisioning and scaling clusters is just a few clicks away. Behind the scene the clusters are hosted on AWS. We've had a lot of great traction with this offering to date \u2014 companies of various sizes and profiles love the ease of use, security, and having the latest version of Elasticsearch in a monitored and managed cloud environment. Using a public cloud is a bit trickier for large enterprises. Either because enterprises deal with regulated or sensitive data that cannot leave internal networks: or because of the investments they have already made in existing on premises infrastructure. Yet, the rapid adoption of the Elastic Stack within different lines of business within these enterprises leads to proliferation of separate clusters managed by different teams. And consequently to a zoo of versions, configurations, and usage patterns. Centralizing the management of these clusters can not only enforce uniform versioning, data governance, backup, and user management policies but also reduce the total cost by increasing the hardware utilization. As we can see, an enterprise with a large number of Elasticsearch installations can hugely benefit from a centralized cloud-like approach, such as the one that is present in Elastic Cloud. We happen to have the right solution to address the challenge \u2014 we have decided to package our SaaS platform and to make it available as a product. Enter Elastic Cloud Enterprise. ArchitectureElastic Cloud Enterprise shares most of its codebase with our Elastic Cloud SaaS offering. The key tenets of the architecture are: Let us discuss the points in more detail. ServicesWe have avoided the monolithic approach from day one. The service-oriented architecture has various benefits. It allows us to scale the platform easily. It supports the notion of different services having different reliability and performance requirements as each service can be scaled separately. The services have well-defined behavior accessible via an API. This eases the operational management and allows us to change and improve one service without affecting all the other services. Each service is deployed independently in its own Docker container. This, combined with fine-grained permissions to read and write application state, makes the whole installation more secure. Even if a service is compromised, the damage is contained to a single container plus part of the application state. For example, in our cloud service we assume that any Elasticsearch cluster node can be compromised at any time due to a yet undiscovered vulnerability. Even if attackers can compromise a cluster node they cannot break out of their containers and the host that hosts this container. They can write no application state and they can read only the part of the state that is related to their own cluster. The above diagram depicts the core services and the connections between them. ProxyProxy is the first component that a user's request hits. It maps a cluster id passed in the request url to the container to the actual cluster nodes. The association of cluster id to a container is stored in ZooKeeper, but the proxy caches it. That means that even in the rare event of ZooKeeper downtime the platform can still service the requests to existing clusters. The Proxy is intelligent \u2014 if you have a highly available cluster, so that your nodes are spread across two or three availability zones, and if one of the zones goes down then the proxy will not route any requests there. It keeps track of the state and availability of the zones. It helps with no-downtime scaling and upgrades. Before we perform an upgrade a snapshot is taken. Then new nodes with new configuration or new quota are spun up. The data is migrated to the new nodes using standard Elasticsearch features. Finally, when the migration is complete the proxy switches the traffic to the new nodes and disconnects the old ones. AllocatorAllocators let you scale the Cloud Enterprise installation. They run on all the machines that we want to host the Elasticsearch and Kibana nodes on. Containers with Elasticsearch cluster nodes are then run on the machines managed by allocators. An allocator advertises the resources of the underlying machine in ZooKeeper. It controls the lifecycle of cluster nodes \u2014 it creates new containers and starts Elasticsearch nodes in these containers when asked: it makes sure to restart a node in case it becomes unresponsive: finally it kills a node if it's no longer needed. We use Docker containers to guarantee shares of resources for the underlying clusters. This allows us to mitigate the noisy neighbor effect where one busy cluster can overwhelm the entire host. ConstructorAn allocator is an agent \u2014 it manages the container and Elasticsearch nodes, but it only responds to explicit requests. Basically, it needs a service to direct and tell it what to do. The constructor provides such a service. The constructor monitors new requests from admin console (see below), calculates what needs to be changed and writes it to ZooKeeper nodes which are monitored by the allocators. Its job is also to assign cluster nodes to proper allocators. The constructor is location aware, meaning that it understands the topology of the allocators within a region. If you select a cluster plan with high-availability it will place cluster nodes within different availability zones to ensure that the cluster can survive downtime of the whole zone. Additionally, it maximizes the utilization of underlying allocators to make sure that we don't need to spin up extra hardware for new clusters. Cloud UIProvides the UI and API to manage and monitor the clusters. It consists of both the administrative part \u2014 which can be used to monitor the overall health of the platform and managed clusters, and the end user's part, which users can use to provision and configure their clusters. ContainerizationAll of the services are deployed as Docker containers. This simplifies the operational effort plus makes it easy to provision a similar environment for development and staging. Each cluster node is also run within a Docker container \u2014 to make sure that all of the nodes have access to a guaranteed share of the host resources. Containerization is great for security \u2014 we assume that any cluster can be compromised and give its container no access to the platform. The same is true for the services \u2014 each one can only read and\/or write these parts of the system state that are relevant to it. Even if some services are compromised the attacker won't get hold of the keys to the rest of them and will not compromise the whole platform. StunnelsWe want the Docker containers to communicate securely with one another. Usually the way to provide secure communication is to use. Not all the services or components that we use offer a native support for TLS. to the rescue. We use it to tunnel all the traffic between the containers and hence to make sure that it is not possible to eavesdrop the conversation even when someone else has access to the underlying cloud or network infrastructure. ZooKeeper is a distributed, strongly consistent data store. It offers a file system-like structure, where each node is both a folder (it can have sub items) and a file (it holds data). These nodes are called znodes to differentiate them from the physical nodes that ZooKeeper runs on. ZooKeeper is designed to remain consistent even in the event of network partitions \u2014 a write operation is rejected unless it can be confirmed by a majority of ZooKeeper servers. The writes are linear. It is possible to set watches on znodes so ZooKeeper can serve as an event bus \u2014 one service can notify another by writing to an observed znode. Znodes can have associated Access Control Lists (ACLs). We use this feature to give a fine-grained access to the system state for the various services. For example, the constructor can write cluster plans, but the allocators can only read them. ZooKeeper is central to our solution as it is the source of truth \u2014 it stores the state of the Elastic Cloud Enterprise installation and the state of all of the clusters running on that installation. It is also the event bus coordinating all the other services. No assumptions about the underlying infrastructureBecause all the services are containerized we can support a wide range of configurations. Elastic Cloud Enterprise can be deployed on public or private clouds or even on bare metal hardware. Our only prerequisites are to use Linux (RHEL, CentOS or Ubuntu) with a recent kernel that can run Docker. The installation script needs either internet connectivity to access the Elastic Docker registry or access to an internal Docker registry with cached images of our services. We rely on the Docker daemon and we deliver the services as Docker images, but we do not rely on any specific container orchestration solution. Not taking an opinionated view on the underlying infrastructure allows Elastic Cloud Enterprise to work with a wide range of deployment strategies. SummaryAt this point we've released two private alphas. We are getting great feedback about the technology. If you want to take part in the testing please fill in . We hope to release the next version shortly. Elastic Stack is becoming increasingly popular. It is being used for new and innovative use cases, which results in a proliferation of clusters. This poses new challenges for enterprises where centralizing the management and creating internal centers of excellence may provide great benefits. With Elastic Cloud we have a battle-tested technology that makes it not only possible, but also easy to manage thousands of clusters. With Elastic Cloud Enterprise we bring this technology and experience to your own data center or internal cloud. \n"}
{"index": {"_id": 555}}
{"title":"How JJ Food Service Uses the Elastic Stack for Log Analytics and Search","seo_title":"How the UK's JJ Food Service Uses the Elastic Stack for Log Analytics and Search","url":"\/blog\/how-jj-food-service-uses-the-elastic-stack-for-log-analytics-and-search","author":{"name":"Erdem Ekici"},"date":"July 21, 2016","category":"User Stories","locales":"","content":" Ltd is a B2B food services company founded in 1988. We provide services to about 60,000 individual accounts, with eight branches across the UK supplying all food industry sectors, from restaurants, pubs and hotels to schools, universities and local authorities. The business offers a wide range of fresh, chilled, ambient and frozen products, a selection of high-quality own-label lines, and packaging and cleaning materials, all competitively priced.\u00a0 OverviewAt JJ Food Service Ltd we use Elastic products in a number of ways, firstly we use the Elastic Stack - , , and - \u00a0to power our logging system. Secondly we use Elasticsearch in a more conventional way, for product search. Our web application is modelled in a fairly unconventional way: in the front end we use , Web Components talk to JSON APIs via vanilla Ajax and WebSocket requests. We maintain a high level of security on our front facing servers, these just act as brokers between the client and middleware which is running with the support of . This layer does all the heavy lifting. Our backend data comes from , an enterprise ERP system for which we are a reference implementation. This is an eagle\u2019s eye view of our web application. Detecting Errors Made EasyIt is important to know what state a system is in from minute to minute. Knowing when errors occur and how they fit into the context of our system has helped us to react swiftly to issues, change our approach and make our system more resilient, for example are customers getting their passwords wrong? By aggregating and analyzing our logs with the Elastic Stack, it gives us clarity. Not only that but it also helps us to resolve customer issues, track journeys simply by search. An interesting detail to how we use the Elastic Stack is that we do not write logs to files, instead we directly pipe log events into a Redis Pub\/Sub, Logstash then consumes the Pub\/Sub events directly and feeds them to Elasticsearch. It is faster, better and we love it! There will be more developments on that front in the future. For example we are really excited about and and how it could further improve our system visibility.\u00a0 Creating a Better Search Experience for CustomersLastly product search. We have separated Elasticsearch instances for this and we developed the infrastructure to feed Elasticsearch from the latest products that emerge from our AX ERP system. This is done at least once a day, we use the excellent NodeJS client for this, making bulk inserts and general management of Elasticsearch easy. Our search on our website is exposed as a Microservice, via Seneca. What this gives us is a really nice decoupling of Elasticsearch and our server and its logic. We can insert our own logic backed by a reliable client such as elasticsearch.js Node client. Service Oriented Architecture done right. \u00a0Elasticsearch allowed us to model our Microservices with great flexibility, allowing us to create phased searches that will take into account both exact product matches, store filtering (as our products can be branch specific) and fuzziness. \u00a0All of this helps us return the right products to our customers. For example we have greatly decreased the number of zero results that we used to have, by applying fuzziness intelligently, regular expression searches and mutli-field term searches in a layered way will usually return something relevant, it\u2019s a great improvement. Again our work is never done and we will continue to explore the Elastic Stack and its capabilities into the future. , is taking the lead on our cutting edge frontend web development. , a recent addition to our team who was instrumental in testing our Elasticsearch implementation. , is a Senior Engineer at JJ Food Service with 20 years of experience in web development. His passion has always been for high performance, concurrent, real time systems. He has worked across a broad variety of ecosystems and is mainly found working in Node JS these days. \n"}
{"index": {"_id": 556}}
{"title":"Spinning up a cluster with Elastic's Azure Marketplace template","seo_title":"","url":"\/blog\/spinning-up-a-cluster-with-elastics-azure-marketplace-template","author":{"name":"Russ Cam"},"date":"July 20, 2016","category":"Engineering","locales":"","content":" Last week saw us push out\u00a0, delivering more features and choices than ever to configure an Elasticsearch cluster deployment within Azure,\u00a0in a way to suit a multitude of needs.\u00a0We want\u00a0to take this opportunity to highlight some of the options available within our\u00a0offering to demonstrate just how easy it is to get up and running.\u00a0 For those unfamiliar with ARM templates, there are essentially two components to them: a UI definition template that defines a step-by-step wizard for gathering all of the inputs required for a deployment and emitting a set of key\/value pairs as output, and a deployment template that takes a set of key\/value pairs as input and defines all of the resources to create and configure within Azure. It is possible to use the deployment template independently of the UI definition template, for example, with , but the beauty of the UI definition is that not only is it integrated into the Azure portal, it can also take advantage of querying existing resources within an Azure subscription to aid in filling out each step with valid values. Before we dive into the nitty gritty, we\u2019d like to take a moment to pay homage to the from which Elastic\u2019s was forked: The quickstart templates are a collection of community-contributed templates for provisioning a multitude of different resources and applications on Azure, and Elastic has been happy to contribute features back to the template to continually improve it. Getting startedWhen you want to use the Elastic Stack with existing services running on Azure, it can make sense to also deploy the components to Azure as well, not only to have everything managed from a single dashboard, but also to mitigate egress costs associated with moving data out of Azure data centers. Finding the template on the Azure Marketplace to start a deployment is a simple affair: simply choose + New and search for Elasticsearch to find the \u201cElasticsearch and Kibana\u201d template published by Elastic (that\u2019s us!). The template is a Bring-Your-Own-License (BYOL) model: that is, the template deploys with a 30-day trial license of our commercial X-Pack offering, giving you access to all of the goodness that come with it, including monitoring, security, alerting and graph capabilities. Then, once the trial license expires, you can install your own license to continue using the critical commercial enhancements, or simply uninstall them (although we always recommend having some form of access control on a publicly available cluster!). Deploy into an existing Virtual NetworkSince the initial launch of the template back in December 2015, one of the features most requested has been to allow deployment of a cluster into an existing virtual network and, with the latest template version, we\u2019re pleased to announce this request is now a reality. Whilst configuring the Elasticsearch version and name of the cluster, one can also specify whether to set up a new virtual network in the resource group into which all resources will be created or alternatively, use an existing virtual network within the same subscription and location as the current resource group being created. This is particularly useful in situations where you may already have resources deployed in another resource group, for example, a farm of servers running your website, and wish to make a cluster available on the same network, possibly same subnet, for those web servers to make requests to. Previous incarnations of the template always set up a new virtual network as part of the deployment, deploying master nodes into one subnet and data and client nodes into another subnet. Now, all nodes are deployed into one subnet. One to 50\u00a0data nodes (and more!)The portal UI provides the choice to configure anywhere from one to 50 data nodes, , defaulting to three data nodes with three dedicated master nodes. Depending on your use case, it is possible to forgo dedicated master nodes and opt instead for master eligible data nodes and in doing so, it\u2019s recommended to have at least three data nodes so that the template can , which in this case will be each data node. Similar to choosing the number of data nodes, up to 20\u00a0 can also be configured for deployment, forwarding cluster-level requests to the master node and data-related requests to the appropriate data nodes. For clusters larger than 100 nodes, client nodes are mandatory to scaling due to a limitation with the internal load balancer only being able to be attached to one availability set for the backend pool. The number of data and client nodes are limited in the UI definition to up to 50 and 20, respectively, although in using the deployment template directly it is possible to deploy even bigger clusters: for clusters with more than 100 nodes,\u00a0 in a round robin fashion, to overcome the maximum capacity of a single availability set within Azure. The Hostname prefix input within the template serves to differentiate one cluster from another when deploying into the same subnet: since virtual machines are dynamically assigned IP addresses within the template, uses hostnames as the list of hosts within the configuration of each node, and Azure networking resources do not prevent a device from being attached to a network with the same hostname as an already connected device, it is crucial to set this to avoid nodes from joining the wrong cluster. Hostnames are also used as the node names within the cluster.Premium Locally Redundant StorageFor scenarios where performance is paramount, there is the choice of deploying a cluster onto virtual machines that support , shared virtual machine disks that offer much greater IOPS than Standard Storage, utilizing solid state drives (SSDs) over Hard disk drives (HDDs). For Standard storage disks on standard tier virtual machines,. Premium Storage disks on the other hand can . With greater performance comes greater cost, so the template allows the choice of the right \u201chorses\u201d (boxes) for the right \u201ccourses\u201d (scenarios), allowing different virtual machine sizes for different node roles within the cluster.\u00a0\u00a0For dedicated master nodes that do not store data per se but do need to persist cluster state, the OS disk of each machine is used, which is persisted in Azure Blob storage.Outside inIn addition to deploying an Elasticsearch cluster, the template can also deploy an instance of Kibana to a separate virtual machine, allowing visualizations and dashboards to be built upon the data in the cluster.Kibana connects to the cluster through an internal load balancer, the internal IP address of which is configured as the default url when installing : no more digging around in the portal to ascertain the right IP address to input to make requests to the cluster!Finally, an external load balancer can be configured in addition to an internal load balancer for scenarios\u00a0where\u00a0external access to the cluster is required.Protected with ShieldThis brings us to an important point: the trial license for X-Pack provides security for the cluster in the form of , with a blade step\u00a0dedicated to configuring passwords for admin, read-only and Kibana roles. Right now, you need to configure Transport Layer Security yourself for the cluster if you require it, such as when using or an external load balancer, as the template does not ship with it by default: this is something that we would very much like to add in a future version, to turn things up to 11. Azure provides , a resource that is able to load balance at the application level and perform SSL termination, providing an immediate solution, albeit with a little configuration.\u00a0 Making cluster changesAs previously mentioned, the ARM template simply facilitates spinning up a cluster on Azure infrastructure and does not prevent access to individual machines within the cluster when needed, for example, when needing to access logs, install plugins or change configuration. Since the Kibana machine is set up with a public IP address, it is also possible to use it as a jumpbox to gain access to any node in the cluster and for cases where Kibana is not required, a separate jumpbox machine can be configured to serve this purpose. Accessing the jumpbox can be achieved using , using the username and password\/ssh credentials specified in the Basic Settings stepssh Once a connection has been established to the jumpbox, any machine can then be connected to within the cluster using ssh with the same credentials as before and the internal IP address of the target machine. On an Elasticsearch node SummaryThat was a quick whirlwind tour of our ARM template and we hope that it has been useful in demonstrating capabilities and how easy it is to get up and running on Azure. Stay tuned for further improvements and features in the future by . \n"}
{"index": {"_id": 557}}
{"title":"Logstash Lines: Persistent Queue progress, more monitoring API fixes","seo_title":"","url":"\/blog\/logstash-lines-2016-07-19","author":{"name":"Suyog Rao"},"date":"July 19, 2016","category":"The Logstash Lines","locales":"","content":" Welcome back to The Logstash Lines! In these weekly posts, we'll share the latest happenings in the world of Logstash and its ecosystem.Nice progress again this week. On Friday, we were\u00a0able to plug the various components (producer, disk-backed store, consumers), write test data to disk, successfully read it on the other side and acknowledge it. We now have a meta to track progress, and have a\u00a0 in Logstash GH repo.Updated all the plugins to use a relaxed version constraint. This allows plugins written for LS 5.0 to be used\u00a0in the upcoming\u00a02.4 release, so we don't have to maintain 2 separate branches.Work in progress to add support for specifying a as parameters to these APIs. Just like Elasticsearch. For example, will filter and show only jvm and process information. Other to make sure these APIs are implemented as per the specs, and are consistent with ES APIs.More this week surfaced a couple of issues. Tal found and fixed a memory leak when using the compression feature. He also changed the assembly process which packages Java, JRuby and its dependencies (jar libs) to use Gradle instead of jar_dependencies. We released a beta version of this plugin, which can be installed viabin\/logstash-plugins install --version 3.1.0.beta1 logstash-input-beatsAdded regex patterns in topics, so you can subscribe to multiple ones. Thanks to Anup Chatterjee () for this contribution. Added extra Kafka based metadata (size, partition, etc) for EventsAaron Mildenstein\u00a0has been on a speaking marathon this week! He presented a 3 hour crash course on the Elastic stack at the . His other talks were on writing custom LS plugins, managing and performance tuning ES + LS! I'm sure his swag bag was full as well :) \n"}
{"index": {"_id": 558}}
{"title":"Running site plugins with Elasticsearch 5.0","seo_title":"Running site plugins with Elasticsearch 5.0","url":"\/blog\/running-site-plugins-with-elasticsearch-5-0","author":{"name":"Clinton Gormley"},"date":"July 19, 2016","category":"Engineering","locales":"de-de,fr-fr,ja-jp,ko-kr","content":" Way back in Elasticsearch 0.17, Elasticsearch gained the ability to serve static web pages, and were born. Site plugins allowed users to write Javascript applications which provide graphical user interfaces to Elasticsearch.This spawned a flurry of development by Elasticsearch users producing plugins for monitoring Elasticsearch stats, for index management, segment merging visualisations, analyser debugging, clustering, and more.The two most popular site plugins today are and , both of which combine monitoring with index management.All good so far. Now for the bad news\u2026 Site plugins are not supported in Elasticsearch 5.0Why are we removing this popular feature from Elasticsearch? Elasticsearch is not designed to be a web server. Serving static files was just a hack that was easy to add on top of the HTTP REST interface that Elasticsearch does provide. What\u2019s the harm in serving static files? Well, it turns out that just serving static files can be harmful. ever discovered in Elasticsearch had to do with site plugins. That\u2019s significant, especially for a non-essential feature. In contrast, two of the other vulnerabilities were due to dynamic scripting, and we wrote a to solve that problem! Elasticsearch now runs under the Java Security Manager. We have locked down the privileges that Elasticsearch core requires to run to the bare minimum. We are moving functionality out of core and into modules to further restrict privilege escalation and file access to the smallest chunk of code possible. We do all of this with the aim of restricting the exploit possibilities open to any hacker who finds a zero day vulnerability. Running a web server for a non-essential feature is not consistent with this goal. On top of that, hosting web applications on Elasticsearch encourages the bad practice of exposing Elasticsearch to the Internet, while it should be running in an isolated, more secure network. Running site plugins with Elasticsearch 5.0While many popular site plugins like , (soon to be replaced by ), and already include instructions for running outside of Elasticsearch, it\u2019s easy to do on your own as well. A site plugin consists of static HTML, Javascript, CSS, and image files, which can be served by the web server of your choice, even (for local use) Python\u2019s SimpleHTTPServer: cd my_plugin\/ python -m SimpleHTTPServer 8000 Because site plugins make requests directly to Elasticsearch from the user\u2019s browser, a little configuration is required to instruct Elasticsearch to allow . For example, you could add the following to the config file: http.cors.enabled: true http.cors.allow-origin: \/https?:\\\/\\\/localhost(:[0-9]+)?\/ The setting should be a regular expression that matches the address of the web server hosting the site plugin. You can read more about the CORS settings in the . If your Elasticsearch server is using the Security feature in (the replacement for Shield in 5.0), then you will also need to add the following settings: http.cors.allow-credentials: true http.cors.allow-headers: X-Requested-With,X-Auth-Token,Content-Type, Content-Length, Authorization Beyond site pluginsIf you are a plugin author and would like to move beyond the restrictions of writing an application with static web files then consider developing a instead. Kibana comes with a web server and plugins can include server-side functionality. For instance, all calls to Elasticsearch could be made directly from Kibana\u2019s backend server instead of from the user\u2019s browser. There is even a to help you get started with your own plugin, and a describing the process. As always, helpful Kibana devs are and to help with any questions. \n"}
{"index": {"_id": 559}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-07-18","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-07-18","author":{"name":"Michael McCandless"},"date":"July 18, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top News I just published \u201cHow we reindexed 36 billions documents in 5 days within the same Elasticsearch cluster\u201d \u2014 Fred de Villamil \u270c\ufe0e (@fdevillamil) Elasticsearch Core Changes in 2.x: Changes in master: Ongoing: Apache Lucene Watch This Space , where we'll share more news on the whole Elastic ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 560}}
{"title":"Kibana 4.5.3 and 4.1.10 released to fix tile map visualizations","seo_title":"Kibana 4.5.3 and 4.1.10 Released","url":"\/blog\/kibana-4-5-3-and-4-1-10","author":{"name":"Court Ewing"},"date":"July 15, 2016","category":"Releases","locales":"de-de,fr-fr,ja-jp,ko-kr","content":" Today we\u2019re shipping Kibana versions 4.5.3 and 4.1.10, which use Elastic\u2019s new tile service by default. The tile map settings are also now configurable, so users can use other leaflet-compatible tile services. These releases are available right now on the page. Elastic Tile Service The Elastic Tile Service is brand new, is the default tile service for Kibana, and requires no configuration to use. That said, it does currently have two key limitations that we want to be upfront about. First, the current service only supports zooming up to level 8. With this zoom level, users will be able to see major cities and lakes spread across small countries and US states. We\u2019d love to provide additional zoom levels, but we need to evaluate usage first as each additional zoom level adds considerable bandwidth and scaling requirements for the service. If we do increase the zoom levels in the service, users will be able to take advantage of the additional zoom capabilities with only a configuration change. Second, the current tiles are less detailed than the old tiles. Again, this is something we\u2019d like to improve upon, and if we do, users will get the updated tiles without having to upgrade Kibana. It is also worth mentioning that the Elastic Tile Service is not meant to be a general tile server solution outside of Elastic applications (see ). Custom tile map services If robust map details and zoom capabilities are more your jam, then you can configure Kibana to use other tile service providers instead: For 4.5.3: For 4.1.10: How we got here Since the beginning of time, Kibana has used MapQuest as its tile service provider for map visualizations. MapQuest\u2019s tile service is excellent, and their permissive usage requirements meant that most Kibana users could have beautiful map visualizations without any cost or configuration. On June 15th, MapQuest that they\u2019d be discontinuing the direct tile access API that Kibana was leveraging. On Monday, July 11th, the service was discontinued, and maps in Kibana broke. This was a huge blunder on our part, and it resulted in broken maps across the entire Kibana ecosystem. We sincerely apologize to all of our users, and we promise to do better. We have just begun our internal postmortem process, and that will yield more concrete steps to prevent something like this from happening in the future. For now, moving entirely away from default third party services while also making the provider configurable in the event of any future service outage are our immediate steps. Wrapping up These releases are immediately available on our page. If you have any questions about these changes, please do not hesitate to reach out to us on our , , or . \n"}
{"index": {"_id": 561}}
{"title":"Build your own Beat","seo_title":"","url":"\/blog\/build-your-own-beat","author":{"name":"Jongmin Kim (KR)"},"date":"July 14, 2016","category":"","locales":"de-de,fr-fr,ko-kr,zh-chs","content":" Beats is the platform for building lightweight, open source\u00a0data shippers that send all kinds of data to Elasticsearch for being later analyzed. We have Packetbeat for monitoring the network traffic exchanged between your servers, Filebeat for getting the logs from your servers and the newly released Metricbeat that periodically fetches metrics from external systems.\u00a0If you need to collect other custom data,\u00a0you can easily build your own Beat based on the libbeat framework. \u00a0There are already 25+ made by the\u00a0community. We provide the Beat Generator package that helps you create your own Beat. In this blog post, you will see how to create your own Beat by using the\u00a0Beat Generator. The Beat that we create today for practice is . lsbeat indexes informations of files and directories, similar with the Unix command . This article is based on Unix,\u00a0so if you are Windows or other OS user, follow the instructions\u00a0which fits with your OS. Step 1 - Setup your Golang Environment Beats are written in Golang. To create and develop a Beat, Golang must be installed on your machine. Follow the guide here to . Currently Beats require at least Golang 1.6. Make sure you\u00a0properly setup your variable. Let's see the code that we will use for Lsbeat. This is a simple Golang program that receives a directory as a command line argument and lists all files and subdirectories under this directory. package main import ( \"fmt\" \"io\/ioutil\" \"os\" ) func main() { \/\/apply run path \".\" without argument. if len(os.Args) == 1 { listDir(\".\") } else { listDir(os.Args[1]) } } func listDir(dirFile string) { files, _ := ioutil.ReadDir(dirFile) for _, f := range files { t := f.ModTime() fmt.Println(f.Name(), dirFile+\"\/\"+f.Name(), f.IsDir(), t, f.Size()) if f.IsDir() { listDir(dirFile + \"\/\" + f.Name()) } } } We will reuse the code of the function. Step 2 - Generate To generate our own beat we use the . First you must install . Check out the installation guide . After having installed cookiecutter, we must decide on a name for the Beat. The name must be one word all lowercase. In this example we are using . To create the Beat skeleton, you should get the\u00a0Beats generator package,\u00a0available in the repository. Once you installed , you can download the Beats generator package using command. Once you run the command, all source files will be downloaded under the path. $ go get github.com\/elastic\/beats To work on a stable branch, check out the specific branch. $ cd $GOPATH\/src\/github.com\/elastic\/beats $ git checkout 5.1 Now create and move to your own repository under , and run cookiecutter with the Beat Generator path. $ cd $GOPATH\/src\/github.com\/{user} $ cookiecutter $GOPATH\/src\/github.com\/elastic\/beats\/generate\/beat Cookiecutter will ask you several questions. For your project_name enter lsbeat, for github_name\u00a0- your github id. The next two questions with beat and beat_path should already be automatically set correctly. For the last one your can insert your Firstname Lastname. project_name [Examplebeat]: lsbeat github_name [your-github-name]: {username} beat [lsbeat]: beat_path [github.com\/{github id}]: full_name [Firstname Lastname]: {Full Name} This should now have created a directory lsbeat inside our folder with several files. Let\u2019s change to this directory and list up files automatically created. $ cd lsbeat $ tree . \u251c\u2500\u2500 CONTRIBUTING.md \u251c\u2500\u2500 LICENSE \u251c\u2500\u2500 Makefile \u251c\u2500\u2500 README.md \u251c\u2500\u2500 beater \u2502 \u2514\u2500\u2500 lsbeat.go \u251c\u2500\u2500 config \u2502 \u251c\u2500\u2500 config.go \u2502 \u2514\u2500\u2500 config_test.go \u251c\u2500\u2500 dev-tools \u2502 \u2514\u2500\u2500 packer \u2502 \u251c\u2500\u2500 Makefile \u2502 \u251c\u2500\u2500 beats \u2502 \u2502 \u2514\u2500\u2500 lsbeat.yml \u2502 \u2514\u2500\u2500 version.yml \u251c\u2500\u2500 docs \u2502 \u2514\u2500\u2500 index.asciidoc \u251c\u2500\u2500 etc \u2502 \u251c\u2500\u2500 beat.yml \u2502 \u2514\u2500\u2500 fields.yml \u251c\u2500\u2500 glide.yaml \u251c\u2500\u2500 lsbeat.template.json \u251c\u2500\u2500 main.go \u251c\u2500\u2500 main_test.go \u2514\u2500\u2500 tests \u2514\u2500\u2500 system \u251c\u2500\u2500 config \u2502 \u2514\u2500\u2500 lsbeat.yml.j2 \u251c\u2500\u2500 lsbeat.py \u251c\u2500\u2500 requirements.txt \u2514\u2500\u2500 test_base.py We now have a raw template of the Beat but still need to fetch the dependencies and setup the git repository. First you need to fetch the dependencies, which in our case is only libbeat, and\u00a0create\u00a0the basic config and template files. We will have a closer look at the template and config files later. $ make setup After you have your own Beat, start sharing with the community by uploading it to a GitHub repository. To push lsbeat in the GitHub\u00a0repository, run the following commands: $ git remote add origin git@github.com:{username}\/lsbeat.git $ git push -u origin master Now we have a complete Beat and pushed the first version to Github. Let\u2019s build and run our Beat and then dig deeper into the code. Step 3\u00a0- Configure Once you run the commands above, it will create the and files automatically. All basic configurations are already written in these files. lsbeat.yml: lsbeat: # Defines how often an event is sent to the output period: 1s is a parameter that is included by the generator in all Beats. It represents that Lsbeat iterates the process every 1 second. Let's change this from 1 to 10 sec and add new parameter which represents the path of top directory program will scan. We can add these parameters in under the etc\/ directory.\u00a0 lsbeat: # Defines how often an event is sent to the output period: 10s path: \".\" Once we added new parameters, we run command to apply changes to the configuration file. We can see that the new parameters we set in are available now in . $ make update $ cat lsbeat.yml ################### Lsbeat Configuration Example ######################### ############################# Lsbeat ###################################### lsbeat: # Defines how often an event is sent to the output period: 10s path: \".\" ############################################################################### After updating the configuration files, you should edit , so you can add the parameter. package config import \"time\" type Config struct { Period time.Duration `config:\"period\"` Path string `config:\"path\"` } var DefaultConfig = Config{ Period: 10 * time.Second, Path: \".\", } Let\u2019s use the default configuration options to 10 sec for period and current directory (.) for the default directory. Step 4\u00a0- Add code Each Beat needs to implement the Beater interface, by defining the and functions. A more detailed guide about the Beater interface is available\u00a0. To do that, you just need to define a structure named which defines the Lsbeat object that should implement the Beater interface. Let\u2019s add which we will use for saving the last timestamp data. type Lsbeat struct { done chan struct{} config config.Config client publisher.Client lastIndexTime time.Time } In addition, each Beat needs to implement the New() function that receives the Beat configuration and returns the Beat object of type Lsbeat. func New(b *beat.Beat, cfg *common.Config) (beat.Beater, error) { config := config.DefaultConfig if err := cfg.Unpack(&config): err != nil { return nil, fmt.Errorf(\"Error reading config file: %v\", err) } ls := &Lsbeat{ done: make(chan struct{}), config: config, } return ls, nil } In the case of Lsbeat, we want to extend the default function to export information about the files and subdirectories available in a directory. Before we modify the function, lets add function on the bottom of lsbeat.go file first, which collect files and directories informations. \u00a0It generates events that include: It will index all files and directories for the first time, but after first routine it will check if file or directory is created or modified after first routine, to index only newer files and directories. Timestamp of last routine will be saved in variable. func (bt *Lsbeat) listDir(dirFile string, beatname string) { files, _ := ioutil.ReadDir(dirFile) for _, f := range files { t := f.ModTime() path := filepath.Join(dirFile, f.Name()) if t.After(bt.lastIndexTime) { event := common.MapStr{ \"@timestamp\": common.Time(time.Now()), \"type\": beatname, \"modtime\": common.Time(t), \"filename\": f.Name(), \"path\": path, \"directory\": f.IsDir(), \"filesize\": f.Size(), } bt.client.PublishEvent(event) } if f.IsDir() { bt.listDir(path, beatname) } } } And don't forget to add package at import libraries. import ( \"fmt\" \"io\/ioutil\" \"time\" ) Now, let\u2019s see the function that calls function and saves timestamp in variable. func (bt *Lsbeat) Run(b *beat.Beat) error { logp.Info(\"lsbeat is running! Hit CTRL-C to stop it.\") bt.client = b.Publisher.Connect() ticker := time.NewTicker(bt.config.Period) for { now := time.Now() bt.listDir(bt.config.Path, b.Name) \/\/ call listDir bt.lastIndexTime = now \/\/ mark Timestamp logp.Info(\"Event sent\") select { case <-bt.done: return nil case <-ticker.C: } } } The Stop() function is supposed to break the run loop and it is the same with the generated one: func (bt *Lsbeat) Stop() { bt.client.Close() close(bt.done) } We are almost done with coding. We have to add new fields on mapping. Add the fields information in the file. - key: lsbeat title: LS Beat description: fields: - name: counter type: integer required: true description: > PLEASE UPDATE DOCUMENTATION #new fiels added lsbeat - name: modtime type: date - name: filename type: text - name: path - name: directory type: boolean - name: filesize type: long And apply new updates. $ make update field will be analyzed with nGram tokenizer. Let's add an custom analyzer on lsbeat.template.json file, under \"settings\". { \"mappings\": { ... }, \"order\": 0, \"settings\": { \"index.refresh_interval\": \"5s\", \"analysis\": { \"analyzer\": { \"ls_ngram_analyzer\": { \"tokenizer\": \"ls_ngram_tokenizer\" } }, \"tokenizer\": { \"ls_ngram_tokenizer\": { \"type\": \"ngram\", \"min_gram\": \"2\", \"token_chars\": [ \"letter\", \"digit\" ] } } } }, \"template\": \"lsbeat-*\" } Step 5\u00a0- Build and run Now we can build and run. Just run the\u00a0make command and it will compile the\u00a0code\u00a0and will build the\u00a0 ( on windows) runnable binary file. $ make Modify file to set root directory for listing the files. In our case, we will set which is . Make sure you put full path of directory. lsbeat: # Defines how often an event is sent to the output period: 10s path: \"\/Users\/ec2-user\/go\" And also make sure your Elasticsearch and Kibana is running. Let's run Lsbeat and see what is happening. $ .\/lsbeat You can use _cat api to check if index is created and datas are indexed properly. we can see lsbeat-2016.06.03 index and can see count of documents. Let's query Lsbeat with filename field, which analyzed with nGram tokenizer. Queried with lsbe keyword.\u00a0 It works! Congratulation, you just built\u00a0your own beat. \n"}
{"index": {"_id": 562}}
{"title":"From POC to Prod with Elasticsearch: A Vandis Story (Part 1)","seo_title":"From POC to Production with Elasticsearch: A Vandis Story","url":"\/blog\/from-poc-to-prod-with-elasticsearch-a-vandis-story-part-1","author":{"name":"Haley Eshagh"},"date":"July 14, 2016","category":"User Stories","locales":"","content":" Eight days. That\u2019s how much time Vandis\u2019 Director of Engineering had to go from proof-of-concept to production. There was a job to do \u2014 and he wasn\u2019t alone. It's definitely a new support experience for me. The Elastic support model has done a lot in terms of helping me manage my cycles. It's not a I-have-to-call-in-and-speak-to-someone-new-every-time model: I can call Jason or send him an email with any questions because he knows my system so well. Similarly, Jason also will call us just to say, \"Hey, I was thinking about something. You should look at this as your next option.\" It's been a truly pleasant experience. I jokingly tell my CEO that he's got half an employee he doesn't know about. I like to take a proactive approach to my responses to Ryan and his team. I think responses should be applicable directly to their environment and not just a broad stroke like, \"Here are some things people do.\" I like to provide examples that apply specifically to the Vandis environment, that they can take and use in production.Ryan and his team are ideal customers because we're always discussing things. They trust us, we trust them, and we just have this mutual relationship that carries on through all of our support interactions.I've been supporting open source software for seventeen years. I've managed product development in my past. Every Elastic support engineer is high caliber. We don't sit here and take inbound tier-one support calls. I know Ryan, I know the Vandis use case, I know the environment. I feel like I'm a branch of his team. That's how we do things and that's my mentality when I approach Vandis.To give you a little bit of history, our proof-of-concept cluster has been running since late September. We got funding and had a go-live date within my company for January 1. On December 23, we signed the contract, while I was at my in-laws for Christmas. December 26, 27, 28, 29, 30, Jason worked very closely with me in terms of moving on our proof-of-concept environment into a full-production environment. When a new cluster spun up and started to move data, I was working in my in-laws\u2019 basement and my wife is sleeping next to me in bed, and I just stood up and yelled, \"Yes!\"I woke her up. She asked, \"What? What?\"I said, \"Nothing. The nerdiest thing just happened, don't worry about it.\"I could not have done it without Jason and the support team that I had, especially with the tight turnaround. My hat\u2019s off to everyone at Elastic. It has been an absolute pleasure to work with them. With any of the teams I have one-click access to our engineers, and that translates to one- or maybe two-click access for Ryan and Vandis. Elastic support is part of the Elastic engineering team. We all have the same goal. We want our customers to be successful. There's a lot of comfort in that. Before I had support, I was a lurker on IRC. Yes, all those guys and ladies do a great job of being available there and answering questions. They take a lot of pride in the platform, but at the end of the day, we're all busy and they might not have the time to be there.Having the ability to just shoot a question to Jason that's like, \"I'm going to throw this way out there. You mind just looking it up?\" And having him come back and say, \"Hey man, listen, I talked to the guy who actually wrote the code and it can do that. They want to know your use case a little more and walk through that.\"When I got back from , I told my boss that one of the great things about attending is that I feel like I'm not waiting for a product to develop for the features I want to see. I have more of a direct line within the company to talk about what's important to me. It might not always get done, but I know that I have someone on the inside who's waving my flag and saying, \"Listen, this is what my customer is asking for.\u201d And I know that voice is being heard, instead of me putting it up on a blog or a listserv somewhere saying, \"I'd really love to see Elastic do this.\"So absolutely, 100%, it's a lot of weight off my shoulders. \n"}
{"index": {"_id": 563}}
{"title":"Using Beats with Amazon AWS","seo_title":"Using Beats with Amazon AWS","url":"\/blog\/using-beats-with-elasticsearch-on-aws","author":{"name":"Dara Gies"},"date":"July 13, 2016","category":"Engineering","locales":"","content":" Ever-increasing quantities and varieties of data are being created and captured. Application, system and user behavior logs, network packets, sensor metrics... you name it. The availability of these data drives a diverse and vast set of use cases ranging from intrusion detection to user behavior analysis, network monitoring, machine monitoring, and remote sensor monitoring, just to name a few. are open source, purpose-built, lightweight, and efficient agents that acquire and feed data natively to Elasticsearch. Optionally, Beats can feed data to Logstash for further refinement before being forwarded to Elasticsearch. As part of the Elastic Stack, Beats is a architecture, enabling the capture and transmission of measurements and other data from remote sources to Elasticsearch for analysis, aggregation, and search. Anywhere there is change, such as production and consumption, growth and demise, acceleration and deceleration, data has significance. GPS-driven tractors capture soil depths, soil fertility, and ground temperatures, all of which influence agricultural strategy. Ocean buoys record wave amplitudes that may help to warn of impending catastrophes or inform of welcome beach conditions. Automobiles capture thousands of metrics ranging from tire pressure to average speed to fuel consumption that facilitate an understanding of a vehicle's abilities and failures, as well as the owner's driving behaviors. Network sensors capture machine communication messages that help with understanding usage patterns that drive security and infrastructure policies. In the previous article we configured a three-node Elasticsearch cluster on AWS EC2. It was fairly straightforward and didn't take much time or effort. We will expand on the example and configure Beats to feed the Elasticsearch cluster running on AWS EC2 instances. This will demonstrate how simple it is to configure a centralized machine resource monitoring solution. First, we'll provide an overview of Beats, review available Beats and the environments in which they run - Part I. Then we'll do a step-by-step example installing, configuring, and verifying Beats output - Part II. Part I - Beats Overview are purpose-built lightweight data shippers, or agents, that run on remote machines and feed Elasticsearch instances. Beats make it easy to get data into Elasticsearch. Beats are available on a number of operating systems such as Debian, Redhat, Linux and Mac. There are several available including Filebeat, Metricbeat, Packetbeat, Winlogbeat and Topbeat. Each Beat has a specific purpose or multiple purposes that are logically related, allowing each Beat to focus on its specific task and do it well. tails logs and can ship data to Logstash for further refinement, or directly to Elasticsearch for analysis and search. Filebeat can be installed on any machine that has applications that generate log data, such as a database or application server. (Alpha) captures operating system metrics as services such as Apache web server and Redis. Metricbeat does everything Topbeat does and much more in that it captures operating system metrics such as per-process CPU, memory, and storage use as well as common application messages, such as web servers. Metricbeat will replace Topbeat, so you might consider using Metricbeat for development. captures web, database, and other network protocols, enabling Kibana real-time analytics. Packetbeat is extensible, enabling the addition of new protocols, metrics and analytics. captures Windows event log system, application and security data, enabling monitoring of Windows machines. captures per-process memory, CPU and disk usage statistics. Topbeat can be installed across a set of machines and indexed into a central Elasticsearch cluster, enabling centralized machine resource monitoring. Topbeat is being replaced by Metricbeat, currently in Alpha, and the change is discussed in this . If you have metric data not addressed by available Beats, there's also , a framework for developing new Beats. The is growing and developers are contributing everything from pingbeat, for capturing ping roundtrips, to redisbeat, for Redis monitoring, and to hsbeat, for capturing Java HotSpot VM performance counters.Part II - Configuring BeatsIn this example we will install and on a development machine, in this case a Macbook Pro, and feed an Elasticsearch cluster running on AWS. Beats can be installed on any machine running a supported operating system that has network connectivity with the Elasticsearch cluster. Configure Topbeat to a directory on the machine that will be running the Beats. Download and extract the Topbeat archive using your preferred method, for example: curl -L -O https:\/\/download.elastic.co\/beats\/topbeat\/topbeat-...<\/a>tar xzvf topbeat-1.2.3-darwin.tgz This will create a folder named that contains , and . Locate and open in your preferred editor. There is a property that tells Topbeat where Elasticsearch is located. Locate the hosts parameter and update it to refer to the AWS public hostname, for example: Next, find the property, which defines the index template that defines the field mappings required by Topbeat. Topbeat will load the index template file to Elasticsearch. Uncomment the template property along with the name and path properties that immediately follow. Then, run Topbeat with the command: sudo .\/topbeat -e -c topbeat.yml To verify documents are being indexed, we'll use curl to make a search request: curl -XGET 'http:\/\/ec2-50-17-114-78.compute-1.amazonaws.com:9200\/topbeat-2016.07.07\/_search?pretty' The curl request has several components. The first is the AWS EC2 public hostname \"ec2-50-17-114-78.compute-1.amazonaws.com\". This should be changed to your EC2 instance's public hostname. The second component \"topbeat-2016.07.06\" is the index. Lastly, is the search request \"_search\" with an optional \"pretty\" argument to format the JSON response. If you want to dive deeper into Topbeat, a comprehensive is available and it covers topics such as and . Configure Packetbeat to a directory on the machine that will be running the Beats. Download and extract the Packetbeat archive using your preferred method, for example: curl -L -Ohttps:\/\/download.elastic.co\/beats\/packetbeat\/packe...<\/a>tar xzvf packetbeat-1.2.3-darwin.tgz This will create a folder named that contains three files: , , and . Locate and open in your preferred editor. There is a property that tells Packetbeat where Elasticsearch is located. Locate the hosts parameter and update it to refer to the AWS public hostname, for example: Next, find the property, which defines the index template that defines the field mappings required by Topbeat. Topbeat will load the index template file to Elasticsearch. Uncomment the template property along with the name and path properties that immediately follow. sudo .\/packetbeat -e -c packetbeat.yml To verify documents are being indexed, we'll use curl to make a search request: curl -XGET 'http:\/\/ec2-50-17-114-78.compute-1.amazonaws.com:9200\/packetbeat-2016.07.07\/_search?pretty' If you want to dive deeper into Packetbeat, a comprehensive is available and it covers topics such as and . Part III - Summary Installing, configuring and running Beats is very easy. Beats address a broad set of use cases. They eliminate the challenge of acquiring data and feeding Elasticsearch.\u00a0Beats can feed any network accessible Elasticsearch cluster, whether it resides on Amazon AWS EC2, Microsoft Azure, dedicated iron and even .In the next installment of the AWS blog series, we'll cover installing Kibana on AWS EC2 and visualize the Beats indexed in this example. \n"}
{"index": {"_id": 564}}
{"title":"Brewing in Beats: Set configuration options from the CLI","seo_title":"","url":"\/blog\/brewing-in-beats-set-configuration-options-CLI","author":{"name":"Tudor Golubenco"},"date":"July 12, 2016","category":"Brewing in Beats","locales":"","content":" Welcome to Brewing in Beats! With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources. New community Beat: SaltbeatSalt is an open source automation framework, similar to Ansible for example. is a forwarder for messages from the salt master event bus to Logstash and Elasticsearch. Set configuration options via the CLIThe Beats are , similar to the Elaticsearch -E option, that allows overwriting configuration options from the command line. For example, you can now quickly enable the console output by adding . Combine processor conditions with and\/or\/notThe Beats processors (a.k.a generic filters), which are new in 5.0, now support . This means you can express complex conditions for filtering out the interesting events. For example, to drop all events that have codes 200 or 404 on a given URL: drop_event.when: and: - equals.request_url: \u201c\/test\u201d - or: - equals.http.code: 404 - equals.http.code: 200 Logging verbosity cleanup + more internal metricsWe started with a (thanks Lee) that highlighted how sometimes we fail to provide the operator with important information and started doing a to rethink what we log and with what verbosity level. Part of this, we the numbers of WARN and INFO messages that we produce, so we can switch the default log level . To compensate, we replaced the most verbose warnings\/infos with . These internal metrics are dumped periodically in logs and will provide data for the future central monitoring system. Environment variable expansion based on go-ucfgThe previous implementation for environment variable expansion in our configuration files was done via textual replacement before parsing. This was easy and elegant to implement, but could lead issues when the sequence shows up accidentally (e.g. in a password field). By to our new , we can be more selective on where we accept variable expansions. This also comes with a breaking change: we used to replace unresolved variables with an empty string, the shell way. Now unresolved variables result in a configuration error, which should help catching configuration bugs earlier. Specify multiple configuration filesAnother improvement that we owe to go-ucfg is that you can now specify multiple configuration files by . You can use this, for example, for setting defaults in a base configuration file, and overwrite settings via local configs. Filebeat fix for very quick file rotationIn case a file was renamed after the state was read but before the file was opened by the harvester it could happen that the wrong file was opened. This lead to the issue, that the wrong file was read including reporting the wrong state for a file. In general this was rather unlikely to happen, but can happen when scan_frequency is very low and number of files rotated is very high. \n"}
{"index": {"_id": 565}}
{"title":"And the big one said \"Rollover\"\u2009\u2014\u2009Managing Elasticsearch time-based indices efficiently","seo_title":"And the big one said \"Rollover\"\u2009\u2014\u2009Managing Elasticsearch time-based indices efficiently","url":"\/blog\/managing-time-based-indices-efficiently","author":{"name":"Clinton Gormley"},"date":"July 12, 2016","category":"Engineering","locales":"","content":" Anybody who uses Elasticsearch for indexing time-based data such as log events is accustomed to the index-per-day pattern: use an index name derived from the timestamp of the logging event rounded to the nearest day, and new indices pop into existence as soon as they are required. The definition of the new index can be controlled ahead of time using . This is an easy pattern to understand and implement, but it glosses over some of the complexities of index management such as the following: In this blog post I\u2019m going to introduce the new , and the APIs which support it, which is a simpler, more efficient way of managing time-based indices. \n"}
{"index": {"_id": 566}}
{"title":"Logstash Lines: Persistent Queues, 2.3.4 Release, Pipeline Error Handling","seo_title":"","url":"\/blog\/logstash-lines-2016-07-11","author":{"name":"Suyog Rao"},"date":"July 12, 2016","category":"The Logstash Lines","locales":"","content":" Welcome back to The Logstash Lines! In these weekly posts, we'll share the latest happenings in the world of Logstash and its ecosystem., which an important security issues in Elasticsearch Output.Persistence QueuesGood progress on Persistence Queues feature this week. Implementation is in full swing now. We added the first end-to-end tests that integrate all the building blocks classes \u2014 low level PageIO, in-memory checkpointing etc with the Queue interface. We've also introduced a Queue client class that handles batch of Events as its taken out of the queue by the consumer, manages its acks.Improved pipeline error handling (5.0)Added a configurable flag (pipleine.continue_on_error ) in Logstash to continue processing when there is an error in the filter stage. Sometimes there is a badly written Ruby filter, or a particular data or bug in plugin which triggers an error. For some users the right thing to do here is to crash Logstash so an operator is forced to diagnose and fix the issue. For others, they generally just want it to log an error and keep on running. One long term solution is to have a dead letter queue so bad events can be moved from the main pipeline. In the meanwhile, having this continue option will help some users.Performance Tuning Guide (2.x)We are putting together a performance tuning guide for Logstash 2.x. Until 5.0 GA we will not have any monitoring APIs, so debugging performance issues in 2.x can be hard. Especially since we changed the pipeline work unit (-w) to include both filters and outputs (in 2.2) we've had confusions about how to tune Logstash. In addition, to help with this, we are crafting a blog post to explain in detail the pipeline evolution from pre 2.0 to 2.3 timeframe.Prepping for a 2.4 ReleaseLS 2.4 will be released with ES 2.4 and the rest of the stack. We did some ground work on 2.4 so that plugins developed in 5.x can be installed on top of 2.4. Dependency management in LS plugins is hard. And this involved some back and forth discussion before settling on a solution. Now all plugins will be mass updated to reflect the new version constraints.Others: \n"}
{"index": {"_id": 567}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-07-11","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-07-11","author":{"name":"Michael McCandless"},"date":"July 11, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top News Just wrote a new blogpost about the new java RestClient. The post shows how to use the client. \u2014 Jettro Coenradie (@jettroCoenradie) Elasticsearch Core Apache Lucene Watch This Space , where we'll share more news on the whole Elastic ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 568}}
{"title":"Elasticsearch 2.3.4 released","seo_title":"Elasticsearch 2.3.4 released","url":"\/blog\/elasticsearch-2-3-4-released","author":{"name":"Clinton Gormley"},"date":"July 07, 2016","category":"Releases","locales":"","content":" Today we are pleased to announce the bug fix release of based on . All users of 2.x are advised to upgrade. This release is already available on , our Elasticsearch-as-a-service platform. Latest stable release: Full details of the changes in this release are available in the release notes listed above, but some of the more important changes are mentioned below: \n"}
{"index": {"_id": 569}}
{"title":"Kibana 4.5.2 and 4.1.9 Released","seo_title":"Kibana 4.5.2 and 4.1.9 Released","url":"\/blog\/kibana-4-5-2-and-4-1-9","author":{"name":"Court Ewing"},"date":"July 07, 2016","category":"Releases","locales":"","content":" Today, we\u2019re releasing Kibana versions 4.5.2 and 4.1.9, which have bumped the bundled version of node.js to address a low severity buffer overflow upstream. As with any security fix, we recommend that users upgrade as soon as possible. You can grab the latest versions from the page. \n"}
{"index": {"_id": 570}}
{"title":"Elasticsearch for Apache Hadoop 2.3.3 released","seo_title":"","url":"\/blog\/es-hadoop-2-3-3-released","author":{"name":"James Baiera"},"date":"July 07, 2016","category":"Releases","locales":"","content":" I am pleased to announce the release of Elasticsearch for Apache Hadoop (aka ES-Hadoop) . ES-Hadoop 2.3.3 is primarily a bug-fix release, including extended support for interpreting boolean values from Elasticsearch, backporting support for mixed value maps in Pig, and support for the latest and greatest Elasticsearch version . Feedback Looking forward to hearing your feedback on this ! Drop us a line on , Twitter (), , or the . \n"}
{"index": {"_id": 571}}
{"title":"Logstash 2.3.4 released","seo_title":"","url":"\/blog\/logstash-2-3-4-released","author":{"name":"Suyog Rao"},"date":"July 07, 2016","category":"Releases","locales":"","content":" We are pleased to announce 2.3.4, a\u00a0bug fix release for Logstash. This release fixes an important\u00a0security vulnerability with Elasticsearch Output, so we advice our users to read the note below\u00a0and upgrade to 2.3.4. You can get this release on our page, and the changelog is .Prior to version 2.3.4, Elasticsearch Output plugin would log to file HTTP authorization headers which could contain sensitive information. Users who secure communication from Logstash to Elasticsearch via Basic Auth\u00a0using or other systems are advised to upgrade to this version. We have created Elastic Security Advisory\u00a0ESA-2016-02 for this vulnerability and updated our with details.\u00a0 \n"}
{"index": {"_id": 572}}
{"title":"Betting on Elasticsearch for Enterprise-wide Search with BA Insight","seo_title":"Betting on Elasticsearch for Enterprise-wide Search with BA Insight","url":"\/blog\/betting-on-elasticsearch-for-enterprise-wide-search-with-ba-insight","author":{"name":"Jeff Fried"},"date":"July 06, 2016","category":"User Stories","locales":"","content":" Combining Elasticsearch with SharePointElasticsearch developers may not be too familiar with, but it\u2019s ubiquitous. More than 200,000 organizations use SharePoint today, often as their UI of choice for employee-facing applications, because it is easy for administrators and end users to tailor. BA Insight has been working in the SharePoint ecosystem for 10 years, and has a very tight relationship with Microsoft, so it\u2019s home base for us. When we started working with Elasticsearch we focused first on making a great solution for enterprise search with Elasticsearch as the underlying search engine and SharePoint as the UI. This screenshot is an example of a typical application, designed for investment managers at financial services companies. We\u2019re told by these users that it has become the first thing people check at the beginning of the day, and something they use constantly throughout the day. We\u2019ve set up specific search screens for these financial analysts that encapsulates areas of interest and includes search tabs and embedded Kibana visualizations to drill down into fund performance. It includes: Elasticsearch vs. SharePoint\u2019s built-in searchWe\u2019ve traditionally worked with the search engine included with SharePoint, and still do a lot with it. However, there are several things that we do now that we couldn\u2019t do before we started using Elasticsearch. Most notably: What does the future look like?This is an exciting time. Elastic is growing incredibly fast as a company, and SharePoint is also in a huge resurgence with lots of new releases, so we are sort of holding on to a rocket ship with each hand. I\u2019m particularly excited about: We have also got some cool applications, and interesting case studies in the pipeline. And of course in the near term, we are excited about helping customers adopt and succeed with our products, and with Elasticsearch. (@jefffried) is a longstanding search nerd and CTO of BA Insight. \n"}
{"index": {"_id": 573}}
{"title":"Brewing in Beats: Introduce processors","seo_title":"Brewing in Beats: Introduce processors","url":"\/blog\/brewing-in-beats-introduce-processors","author":{"name":"Monica Sarbu"},"date":"July 04, 2016","category":"Brewing in Beats","locales":"","content":" Welcome to ! With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources. Metricbeat: Use half floatsElasticsearch added support for half floats in the 5.0.0-alpha4 release. The Beats make use of the for the percentage values (a float value between 0 and 1) and for the other float values that are expected to be small. Filebeat: Add more configuration options to help with files managementThere are couple of added in Filebeat to deal with corner cases: Topbeat 1.x: Fix high values of CPU usageThere is a bug in the Topbeat 1.2.x series that reports high values of the CPU usage on Windows. The will be available in the next release of Topbeat 1.x and is already fixed in the 5.0 alphas. libbeat: Rename filters with processorsThe configuration option helps you reduce the fields from the exported event. To align with the naming in the Ingest Node and Logstash, we are the configuration option to . In addition, we are planning to extend its functionality and use it to enhance the event with additional fields. This change breaks the compatibility with the previous version of the Beats. All Beats: Update the definition of the condition in processorWhile renaming with and extending its functionality, we decided to use the keyword to introduce the condition associated to the processor in order to differentiate its borders from the action associated with the processor. processors: - include_fields: equals: proc.pid: 3455 fields: [\"proc.cpu\", \"proc.mem\"] processors: - include_fields: when: equals: proc.pid: 3455 fields: [\"proc.cpu\", \"proc.mem\"] Metricbeat: the system module now compiles on FreeBSDThe system module of Metricbeat is using the library to gather system statistics like the CPU and memory usage, disk usage, file system usage. Thanks to , the gosigar library has support for FreeBSD. \n"}
{"index": {"_id": 574}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-07-04","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-07-04","author":{"name":"Michael McCandless"},"date":"July 04, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsI love the new \"How To... Tune for indexing speed \/ search speed \/ disk usage\" section in the docs \u2014 Clinton Gormley (@clintongormley) Elasticsearch Core Apache LuceneThe Apache Lucene update will be back next week.Watch This Space, where we'll share more news on the whole Elastic ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 575}}
{"title":"Finding You the Best Hotel at LateRooms.com with Elasticsearch","seo_title":"Finding You The Best Hotel at LateRooms.com With Elasticsearch","url":"\/blog\/finding-you-the-best-hotel-at-laterooms-com-with-elasticsearch","author":{"name":"Andy Lowry"},"date":"July 04, 2016","category":"User Stories","locales":"","content":" At we use Elasticsearch to solve a number of problems. We regularly talk about how we use it for logging, but we don't talk often about how we use it for search. If you visit LateRooms.com the search bar is very prominent on the site, it's our main interface for our customers to find the hotel they want. So it's important we get it right. When you type into the search bar, the autocomplete feature kicks in which is powered by Elasticsearch. Furthermore the search function itself is also powered by Elasticsearch. To quote one of our developers, when asked why we use Elasticsearch: \u201cwe spiked it, it met our requirementswe tried it further, it never failed us,we adopted it\u201d AutocompleteLast year we completed a project to rewrite our existing autocomplete feature. Our existing system was slow and the results were not great. We chose to use the Elasticsearch Completion Suggester feature, as we were convinced this would give us the performance we needed. This allowed us to load our destination data and all our hotels into a single index. Each document in the index has a suggest field which we use to match the input text, display text which is what you see in the drop down, and some metadata about the entry. This is our schema: { \"mappings\": { \"destination\": { \"properties\": { \"name\": { \"type\": \"string\" }, \"suggest\": { \"max_input_length\": 50, \"payloads\": true, \"analyzer\": \"standard\", \"preserve_position_increments\": true, \"type\": \"completion\", \"preserve_separators\": true } } } } } Matching is done on the suggest field. Indexing is done on every permutation on the first 5 words of the search text. We needed to do this to allow matches where the words are out of order, so \u201cManchester City Centre\u201d and \u201cCity Centre Manchester\u201d would both match the same results. We also apply stop words for words that are common to hotel names and destinations. This solution resulted in an index of approximately 1GB in size, We have a single cluster for all search and autocomplete with 3 machines all with 24 cores and 80GB RAM. With this, we are getting response times averaging around 15ms. SearchWe have a Search API which powers the data on our Search Results pages on the website, our apps and a few other internal tools. Our existing implementation is based around SQL Server and this has served us well for many years, but we needed something more flexible and better targeted to our problems. So we chose to move most parts of our implementation to Elasticsearch. It is a work in progress and currently we have a hybrid of the 2 systems, however we are focussing on moving the functionality to Elasticsearch where it gives us the most value. Destination SearchWe have 2 main indexes, one for destinations and the other one for hotels. The hotels index includes relatively simple information about the hotel including name, address, facilities and its geo location. Here is the schema for hotel: { \"settings\": { \"analysis\": { \"analyzer\": { \"stopwords_analyzer\": { \"type\": \"standard\", \"stopwords\": [ \"hotel\", \"the\", \"and\", \"in\", \"hotels\" ] } } } }, \"mappings\": { \"hotel\": { \"properties\": { \"id\": { \"type\": \"long\" }, \"name\": { \"type\": \"string\" }, \"typeId\": { \"type\": \"long\" }, \"location\": { \"type\": \"geo_shape\" }, \"address\": { \"type\": \"string\" }, \"brand\": { \"type\": \"string\" }, \"postcode\": { \"type\": \"string\" } } } } } Destinations are places such as cities, towns, counties, points of interest, train stations, airports - basically anywhere someone might be looking for a hotel. Each destination includes a name, a geoshape and some metadata. Here is the schema for destinations - (without the metadata for brevity) { \"mappings\": { \"geoShape\": { \"properties\": { \"name\": { \"type\": \"string\" }, \"location\": { \"type\": \"geo_shape\" }, \"destinationId\": { \"type\": \"integer\" } } } } } We have 1.7 million destinations in our index, most of which are UK postcodes. Some are indexed as a circle, and others by a polygon, depending on which type works best for each destination. Sourcing the polygons is one of our biggest challenges. Freely available data sources such as OpenStreetMaps and Ordnance Survey have an incredible level of detail we don\u2019t need for our searches. In order to minimise index size and indexing time we reduce the polygon before indexing it. Furthermore we have the issue of accuracy. Most of this data is too accurate for us. While official boundaries and borders are great for administrations they aren\u2019t great for finding hotels, and we often need polygons that extend well beyond the official borders. Our home city of Manchester is a great example, the red line show the boundary of Manchester, purple dots are inside Manchester, red ones outside: This map shows the official boundaries of Manchester and the neighbouring city of Salford. As you can see many of the hotels near the city centre of Manchester are actually in Salford. If a user is searching for Manchester hotels they expect to see those hotels listed even though they are not technically in Manchester. This turns out to be a very common situation. We could address this with a team of cartographers and a lot of effort but this would be very expensive. So we resolve this issue by having multiple shapes for each destination and A\/B testing them until we find one which works best for our customers. Our running A\/B experiments are also stored in Elasticsearch. When we want to test a new shape we add it to our experiments index, including the information about what proportion of users are included in the experiment. For example: { \"id\": 2, \"destinationId\": 20000060, \"active\": true, \"pots\": [ { \"percentage\": 45, \"action\": \"UseLegacy\", \"variantName\" : \"UseLegacyPot\" }, { \"percentage\": 45, \"action\": \"UseGeoShape\", \"variantName\" : \"UseGeoShapePot\" }, { \"percentage\": 10, \"action\": \"Control\", \"variantName\" : \"ControlPot\" } ], \"shape\": { \"location\": { \"type\": \"polygon\", \"coordinates\": [[[-2.2309112548828125,53.51663422436193], [-2.3476409912109375,53.489271160998356], [-2.264556884765625,53.45371365685254], [-2.1498870849609375,53.44062753992289], [-2.1320343017578125,53.49744108888947], [-2.21649169921875,53.50846799494849], [-2.2309112548828125,53.51663422436193]]] } } } Map search Text SearchText search is a little more complicated. We first try to find an appropriate destination by matching its name against the supplied text. Then if we find one we use the geoshape to query the hotel index. If there is no matching destination, we try to find a hotel directly by matching against the name and the address. This allows customers to find hotels by place and by name using the same search box. Filtering, Sorting and AggregatingYou might notice none of our indexes have information about facilities, room types or prices in our schema. Currently filtering and aggregating are done through our legacy system, and sorting is done by a very highly customised sorting system based on our hotel recommendations. However, filtering and aggregating are some things that we very much want to move to Elasticsearch, as this should speed up our searches, by reducing the number of documents Elasticsearch has to fetch, and also the number of external service we need to interact with. The Benefits of using ElasticsearchUsing Elasticsearch has allowed us to build features that we would not have been able to build on our own. Features such as geo polygon searches, and a great autocomplete. It\u2019s clustering also allows us to have high performance without worrying about data integrity and load balancing. But the largest benefit comes from us being able to concentrate on our own strengths with our hotel recommendation engine, without having to implement the other search features that Elasticsearch already gives us. The FutureNow that we have the data we need in Elasticsearch we see a lot of other features we can develop. Features such as guaranteeing results even when hotels are full, allowing users to draw their own search areas and suggesting popular areas for major cities. All these new features and improvements mean we give a better experience to our users, helping them to find the right hotel for their trip. is a Development Team Lead at LateRooms.com. He has been writing software professionally for more than 15 years, in industries such as Defence, Scientific Instrument control and Travel. Andy is a regular blogger on many areas of software development and is also organizer of Elastic Manchester User Group. \n"}
{"index": {"_id": 576}}
{"title":"Elasticsearch for Apache Hadoop 5.0.0-alpha4","seo_title":"","url":"\/blog\/es-hadoop-5-0-0-alpha4","author":{"name":"James Baiera"},"date":"June 30, 2016","category":"Releases","locales":"","content":" \u200bI am excited to announce the release of Elasticsearch for Apache Hadoop (aka ES-Hadoop) built against Elasticsearch 5.0.0-alpha4. : This is an alpha release and is intended for purposes only. Indices created in this version . For the sake of your own sanity, we do not advise using this version in production. What\u2019s new? Pig - Mixed Value Maps Maps in Pig with mixed value types are now supported by the connector. No longer will these collection types be processed as an empty map during indexing time. Spark - Auto Create Index Fixed In some cases, Spark integration was all too eager to help you index your data, even when asked to automatically create new indices. After a quick intervention, it\u2019s happy to notify you when the index doesn\u2019t exist. Objects Used in Update Script Parameters Internal request rendering was improved so that the connector would no longer incorrectly treat objects in an update\u2019s parameter list as flat JSON strings. Documentation A handful of documentation improvement contributions have been accepted. Relatedly, we\u2019ve given our personal spell checkers a stern talking to. Feedback Please try this at home! You can ES-Hadoop 5.0.0-alpha4, try it out, find out how it breaks, and let us know what you did on , , or in the . A crisp high five is waiting for all who participate! Not a huge fan of high fives? There\u2019s always the instead! \n"}
{"index": {"_id": 577}}
{"title":"Elasticsearch 5.0.0-alpha4 released","seo_title":"Elasticsearch 5.0.0-alpha4 released","url":"\/blog\/elasticsearch-5-0-0-alpha4-released","author":{"name":"Clinton Gormley"},"date":"June 30, 2016","category":"Releases","locales":"","content":" Today we are excited to announce the release of based on . This is the fourth in a series of pre-5.0.0 releases designed to let you test out\u00a0your application with the features and changes coming in 5.0.0, and to give us feedback about any problems that you encounter. Open a bug report today and become an . This is an alpha release and is intended for . Indices created in this version . Elasticsearch 5.0.0-alpha4 delivers some exciting new features which we talk about below. In addition, there are many small changes which you can read about in the release notes above. Also take a look at the release announcements for , , and to read about features like: \n"}
{"index": {"_id": 578}}
{"title":"Beats 5.0.0-alpha4 released","seo_title":"","url":"\/blog\/beats-5-0-0-alpha4-released","author":{"name":"Monica Sarbu"},"date":"June 30, 2016","category":"Releases","locales":"","content":" Today we are excited to announce the fourth alpha release of the Beats 5.0.0 series. This is an alpha release and is intended for testing purposes only. Please do not deploy in production. Monitor MongoDB with MetricbeatYou are now able to monitor your with Metricbeat. It gives you information about the uptime (ms) of the service, the number of active connections, the number of unused connections, the number of transactions written to the journal, the total size of the heap space (bytes), the number of page faults, the number of inserts, updates, deletes, the RAM size (MB), and . At the moment, Metricbeat has support for monitoring Apache, MySQL, Nginx, Redis, System statistics, Zookeeper, and MongoDB. If you are interested in monitoring another service, please open a in GitHub or contribute to the open source community by . Support for gzip compression in Elasticsearch outputYou can now configure the Beats to the payload when using the Elasticsearch bulk API. The compression level is configurable in the Elasticsearch output section and must be in the range of 1 (best speed) to 9 (best compression). By default the gzip support is off (compression level is set to zero), so you need to explicitly opt in. Ignore Symlinks log filesIn the previous versions, Filebeat had support for symlinks to log files, but it often happened that the same log file was read twice. Now Filebeat is completely Remove topology_expire optionPrior to 5.0, you could configure the topology_expire option in Packetbeat to automatically expire the topology entries from Elasticsearch. Starting with Elasticsearch 5.0, the _ttl index option is removed, so the topology_expire option no longer works. We have the option in 5.0, and the user is responsible for any required cleanup. Kibana Dashboards for Apache Metricbeat ModuleThanks to , Metricbeat comes with a predefined for the Apache Module. Known issue and workaroundThere is a in the 5.0.0-alpha4 release of Kibana which affects the loading process of our sample dashboards. It only affects brand new installations of Kibana 5.0.0-alpha4 that don\u2019t yet have any indices defined. If you are upgrading you can skip this. When following the Beats , after , you will get an error when trying to set the index pattern as the default: If this happens, you can either manually overwrite the index pattern and then run the loading script again, or paste the following in the Kibana Console to force setting the default index (replacing `packetbeat-*` with the name of the Beat you are using): POST .kibana\/config\/5.0.0-alpha4\/_update { \"doc\": { \"defaultIndex\": \"packetbeat-*\" } } Become a PioneerA big \"Thank you!\" to everyone who has tried the previous alpha releases and or . We\u2019d like to also remind you that if you post a valid, non-duplicate bug report during the alpha\/beta period against any of the Elastic stack projects, you are entitled to a . \n"}
{"index": {"_id": 579}}
{"title":"Elastic Stack Release - 5.0.0-alpha4","seo_title":"Elastic Stack Release - 5.0.0-alpha4","url":"\/blog\/elastic-stack-release-5-0-0-alpha-4","author":{"name":"Shay Banon"},"date":"June 30, 2016","category":"Releases","locales":"ja-jp","content":" Game of Thrones season 6 is wrapped, the Pound has\u00a0lost a few ounces,\u00a0and\u00a0Messi is talking about retirement. It\u2019s been quite\u00a0a week. But we have something to cheer you up.\u00a0Say hello to Elastic Stack 5.0 alpha 4.\u00a0As a reminder, we've also released the to help prepare you for migration from 2.3.x to 5.0. to make the transition to 5.0 more enjoyable.Kibana Head out to the \u00a0for\u00a0details on the awesomeness. But, here's the quick rundown.\u00a0LogstashFor more detailed information on the latest and greatest, head over to the Logstash\u00a0.BeatsYou can find more beaty\u00a0details about these changes in the . ES-HadoopAnd last, but certainly not the least. ES-Hadoop version\u00a05.0.0-alpha4\u00a0has also been released . \n"}
{"index": {"_id": 580}}
{"title":"Getting Started with Shield Document Level Security in Elasticsearch","seo_title":"Getting Started with Shield\u2019s Document Level Security in Elasticsearch","url":"\/blog\/getting-started-with-shield-document-level-security-in-elasticsearch","author":{"name":"Marcelo Rodriguez"},"date":"June 30, 2016","category":"Engineering","locales":"","content":" Elastic Shield is capable of filtering documents using query criteria. In this blog post I'll demonstrate how to use this feature by using a simple, two document data set in Elasticsearch where documents will be filtered for the user according to the value of a field and displayed in a simple Kibana visualization. \u00a0Users and roles will be created with the Users and Roles API. The Scenario There are three users: a sales manager and two account representatives. Documents are indexed using a code for one of two regions, EAST and WEST. \u00a0Each account representative needs read access to documents in their region and the manager will need access to both regions. \u00a0All users will be using the same Kibana visualizations to view the counts of their documents. In Kibana, users will be allowed to create\/modify visualizations and dashboards to view their documents. For the the initial steps, you will need to log in using an account with sufficient privileges to create \u00a0indices, roles and users. \u00a0The following REST API examples can be used directly in Kibana through the Sense plugin. Elasticsearch and Shield STEP 1: Configure Authentication Realm In this example, I'll be using the Native realm to create users so the native realm needs to be configured in Elasticsearch for Shield. Shield configuration example: #-----SHIELD CONFIG------- shield: authc: realms: native: type: native order: 0 STEP 2: Index Sample Data First, we will index two simple documents into one index. PUT myindex\/mytype\/1 { \"name\" : \"ABC Company\", \"region\" : \"EAST\" } PUT myindex\/mytype\/2 { \"name\" : \"DEF Company\", \"region\" : \"WEST\" } GET myindex\/mytype\/_search STEP 3: Create Roles Next, create the roles that will be used to allow users of each region to access their documents. We are specifying two indices: and . \u00a0The . index is set up with the \"all\" privilege so that our users can log in, change settings and create visualizations. The index is set up with the \"read\" privilege and we use a query to specify the documents that the users belonging to the role will be able to see. POST \/_shield\/role\/myroleEAST { \"indices\": [ { \"names\": [ \".kibana*\"], \"privileges\": [\"all\"] }, { \"names\": [ \"myindex*\" ], \"privileges\": [ \"read\", \"view_index_metadata\" ], \"query\": \"{\\\"match\\\": {\\\"region\\\": \\\"EAST\\\"}}\" } ] } POST \/_shield\/role\/myroleWEST { \"indices\": [ { \"names\": [ \".kibana*\"], \"privileges\": [\"all\"] }, { \"names\": [ \"myindex*\" ], \"privileges\": [\"read\", \"view_index_metadata\" ], \"query\": \"{\\\"match\\\": {\\\"region\\\": \\\"WEST\\\"}}\" } ] } GET \/_shield\/role STEP 4: Create Users Now we are ready to create the three users. One user will be assigned the role that allows access to documents marked with the EAST region, another user to the WEST region and the last account will include both roles. POST \/_shield\/user\/myuserEAST { \"password\" : \"mypassword\", \"roles\" : [ \"myroleEAST\" ] } POST \/_shield\/user\/myuserWEST { \"password\" : \"mypassword\", \"roles\" : [ \"myroleWEST\" ] } POST \/_shield\/user\/myuserManager { \"password\" : \"mypassword\", \"roles\" : [ \"myroleEAST\",\"myroleWEST\" ] } GET \/_shield\/user Kibana In this section, we will configure Kibana to read our new index, , then create a visualization. You will need to log into Kibana with an admin role user to configure the initial dashboard. STEP 1: Set Index Pattern in Kibana STEP 2: Create Visualization in Kibana STEP 3: Test Users The tests below demonstrate how the query clause defined in the role restricts the data for the users. \u00a0If there are several visualizations in a dashboard on the same data, the window into the data will also be applied. Repeat the test with the user and you should see only the WEST bar. Repeat the test with the and you should see both EAST and WEST bars. Summary This article provided a base starting point to demonstrate how Shield can be configured with Elasticsearch to restrict Kibana visualization data. Although we used very basic and minimal configurations, the procedures can be customized in several ways to achieve security goals in your architecture and allow for more complex configurations. Shield installation and configuration Sense installation and configuration Native user authentication Configuring role based access control Setting up field and document level security \n"}
{"index": {"_id": 581}}
{"title":"Kibana 5.0.0-alpha4 released","seo_title":"Kibana 5.0.0-alpha4 released","url":"\/blog\/kibana-5-0-0-alpha4","author":{"name":"Court Ewing"},"date":"June 30, 2016","category":"Releases","locales":"","content":" The moment is finally here, and after only 26 days and a bunch of internal delays that we don\u2019t like to talk about, we are stoked to release Kibana 5.0.0-alpha4, or the Alpha to End All Alphas. Folks, if alphas were ears, features would be coming out of this one. And this ball of wax is only one away (ok, two clicks). As usual, become an by opening a bug report today and earn yourself some free stuff. : This is alpha software that will only work with . Please test it, but do not use it in production. Indices created in this version will not be compatible with Elasticsearch 5.0.0 GA. Upgrading 5.0.0-alpha4 to any other version is not supported. Import data from a CSV You read that right. For the first time ever, you can import CSV data into your Elasticsearch cluster via Kibana. Via the new \u201cUpload CSV\u201d tool under the also-new \u201cManagement\u201d application, you can simply drag and drop a CSV of your choosing and we\u2019ll let you review a sample of the results, tweak the mappings, name an index pattern, and Kibana does the rest. Monitor your Kibana instance with X-Pack In addition to the new and improved Elasticsearch monitoring capabilities, you now get Kibana monitoring with your free basic license of X-Pack. Keep track of requests, response times, memory usage, and more. Disable visualization buckets, and drag to sort as well Have you ever been in the situation where you meticulously set up a range aggregation on a sub-bucket in Kibana but want to temporarily remove it? Or how about move it to the top of a list of other buckets? Well, in our ongoing effort to single-handedly stop global warming, we decided to embrace micro-optimizations for energy usage by lowering the amount of clicks necessary. Or maybe we just got fed up with the tedium of rebuilding our range aggregations all the time. In any case, you can now sort buckets by dragging and dropping or disable them entirely rather than removing them. Settings is gone. Long live Management! This isn\u2019t really a new feature in its own right - the new Management app still has the old capabilities of the Settings app, but it\u2019s structured to enable a ton of features that we\u2019re planning in the near and long term. Management is your window into the Elastic stack. This is where you\u2019ll go to set up Kibana, configure users and roles in X-Pack security, and even add or manage data in your Elastic stack. Bugs n\u2019 stuff In addition to screenshot-worthy features, we\u2019ve also added a bunch of other improvements and bug fixes, including these highlights: What\u2019s next? Beta, baby! For real this time. We still have a bunch of features we want to get into 5.0.0, and we\u2019re simultaneously focusing more and more on the spit and polish that we all demand of a stable release. For now, download the alpha4 release and help us track down those remaining issues. Bugs can be filed on , and feedback is always appreciated on our . As always, feel free to reach out to us on or as well. \n"}
{"index": {"_id": 582}}
{"title":"Logstash 5.0.0-alpha4 released","seo_title":"","url":"\/blog\/logstash-5-0-0-alpha4-released","author":{"name":"Suyog Rao"},"date":"June 30, 2016","category":"Releases","locales":"","content":" We are pleased to announce that Logstash 5.0.0-alpha4 has been released today. You can review the changes , or jump directly to . Moar Metrics, Moar VisibilityBuilding on the systems level monitoring APIs that were exposed in previous alphas, we have now added per-plugin metrics. The question you've always wanted to ask Logstash: where are events spending the most time? In alpha4, every filter and output plugin has been enhanced to expose wall-clock time spent by events flowing through it. It doesn't stop with timing info \u2014 plugins like Grok, Date and GeoIP filters now expose number of failures, successes, cache stats and more. So, yes, debugging your four page Logstash configuration just got a lot easier! curl localhost:9600\/_node\/stats\/pipelines?pretty { \"plugins\":{ \"filters\":[ { \"id\":\"grok_8b1226e2-e714-444c-9774-0135833457d3\", \"name\":\"grok\", \"events\":{ \"in\":122, \"duration_in_millis\":75, \"out\":122 } \"failures\": 3 \"matches\" : 1, \"patterns_per_field\" : { \"message\" : 1 } } ], \"output\":[ { \"id\":\"elasticsearch_713f61e2-6d7a-436c-9159-b3a953b18451\", \"name\":\"elasticsearch\", \"events\":{ \"in\":122, \"duration_in_millis\":175, \"out\":122 } } ] } } Elasticsearch Output Kafka 0.10 SupportVersion 0.10 of Apache Kafka was with many enhancements like rack awareness, better handling for protocol versions and timestamp in messages. Logstash input and output has been updated to work with 0.10. Others FeedbackWe welcome and appreciate all your feedback as we iterate through our pre-releases for 5.0.0! You can open issues on our , or start a conversation on our . Also, do you know about our ?\u00a0 \n"}
{"index": {"_id": 583}}
{"title":"An Elastic Stack Primer","seo_title":"An Elastic Stack Primer - log, stream, and visualize data","url":"\/blog\/elastic-stack-primer","author":{"name":"Nicol\u00e1s Bevacqua"},"date":"June 29, 2016","category":"Engineering","locales":"","content":" This article describes my adventures while getting initiated into the Elastic Stack. We'll be building upon the index I've set up for search in an earlier post. We'll upgrade our stack to , incorporate and , so we can : and we'll also hone and troubleshoot our understanding of the Elastic Stack along the way. Getting started with the can feel a bit overwhelming. You need to set up , Kibana, and before you even can get to the fun parts \u2013 maybe even before you fully understand how the three synergize providing you with formidable and formerly untapped insights into your platform. I have been running Pony Foo since late 2012, and, , these kinds of user tracking systems are far from ideal when it comes to troubleshooting. In the years since I launched the blog I tried a couple of instrumentation tools that would provide me with reporting and metrics from the Node.js application for my blog, but these solutions would require me to, well... the Node apps by patching them with a snippet of code that would then communicate with a third party service. Visiting that service I could learn more about the current state of my production application. For a variety of reasons, I ended up ditching every one of these solutions not long after giving them a shot. Not long ago I wrote about , and since I'm already working on the Kibana analytics dashboard team I figured it wouldn't hurt to learn more about so that I could go full circle and finally have a look at some server metrics my way. It helps stream events pulled out of files, HTTP requests, tweets, event logs, or . After processing events, Logstash can output them via Elasticsearch, disk files, email, HTTP requests, or . The above graph shows how Logstash can provide tremendous value through a relatively simple interface where we define inputs and outputs. You could easily use it to pull a Twitter firehose of political keywords about a presidential campaign into Elasticsearch for further analysis. Or to anticipate breaking news on Twitter as they occur. Or maybe you have more worldly concerns, like streaming log events from and into for increased visibility through a Kibana dashboard. That's what we're going to do in this article. Installing the Elastic StackI had used for . This represented a problem when it came to using the Elastic Stack, because I wanted to use the latest version of Kibana As mentioned in the earlier article, we'll have to download and install Java 8 to get Elasticsearch up and running properly. Below is the piece of code we used to install Java 8. Keep in mind this code was tested on a Debian Jessie environment, but it should mostly work in Ubuntu or similar systems. Next, we'll install the entire pre-release Elastic Stack , for lasticsearch, ogstash and ibana. The following piece of code pulls all three packages from and installs them. After installing all three, we should turn on their services so that they run at startup. This is particularly desirable in production systems. Debian Jessie relies on for services, so that's what we'll use to enable these services. You want to reduce your \"hands on\" production experience as much as possible. Automation is king, etc. Otherwise, why go through the trouble? Lastly, we start all of the services and log their current status. We pause for ten seconds after booting Elasticsearch in order to give it time to start listening for connections, so that Logstash doesn't run into any trouble. Great, now we'll need to tweak our server. It's important to note that we'll be expecting the file to have a specific format that Logstash understands, so that we can consume it and split it into discrete fields. To configure with the pattern we'll call metrics, add this to the section of your file. log_format metrics '$http_host ' '$proxy_protocol_addr [$time_local] ' '\"$request\" $status $body_bytes_sent ' '\"$http_referer\" \"$http_user_agent\" ' '$request_time ' '$upstream_response_time': Next, in the section of your for the site you want to be parsing logs for, just tell to use the logging format we've defined earlier. access_log \/var\/log\/nginx\/ponyfoo.com.access.log metrics: After exposing the Kibana web app on my server and pointing a DNS entry for to my load balancer, I was good to go. From to Elasticsearch via LogstashLogstash relies on inputs, filters applied on those inputs, and outputs. We configure all of this in a config file that we can then feed logstash using the command. Getting Logstash to read access logs is easy. You specify an event type that's later going to be used when indexing events into Elasticsearch, and the path to the file where your logs are recorded. Logstash takes care of tailing the file and streaming those logs to whatever outputs you indicate. input { file { type => \"nginx_access\" path => \"\/var\/log\/nginx\/ponyfoo.com.access.log\" } } When it comes to configuring Logstash to pipe its output into Elasticsearch, the configuration . output { elasticsearch {} } An important aspect of using Logstash is using filters to determine the fields and field types you'll use when indexing log events into Elasticsearch. The following snippet of code tells Logstash to look for patterns in , and to match the field to the grok pattern, which is defined in a patterns file that lives in the provided directory. filter { grok { patterns_dir => \"\/opt\/logstash\/patterns\" match => { \"message\" => \"%{NGINX_ACCESS}\" } } } The contents of the file containing the grok patterns are outlined below, and they should be placed in a file in , as specified in the directive above. Logstash comes with and the general way of consuming a pattern is where some patterns such as also take a type argument, such as , in the piece of code below. NGINX_USERNAME [a-zA-Z\\.\\@\\-\\+_%]+ NGINX_USER %{NGINX_USERNAME} NGINX_ACCESS %{IPORHOST:http_host} %{IPORHOST:client_ip} \\[%{HTTPDATE:timestamp}\\] \\\"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP\/%{NUMBER:http_version:float})?|%{DATA:raw_request})\\\" %{NUMBER:status:int} (?:%{NUMBER:bytes:int}|-) %{QS:referrer} %{QS:agent} %{NUMBER:request_time:float} %{NUMBER:upstream_time:float} NGINX_ACCESS %{IPORHOST:http_host} %{IPORHOST:client_ip} \\[%{HTTPDATE:timestamp}\\] \\\"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP\/%{NUMBER:http_version:float})?|%{DATA:raw_request})\\\" %{NUMBER:status:int} (?:%{NUMBER:bytes:int}|-) %{QS:referrer} %{QS:agent} %{NUMBER:request_time:float} Each match in the pattern above means a field will be created for that bit of output, with its corresponding name and type as indicated in the pattern file. Going back to the section of our file, we'll also want a filter that parses the field into a proper date. a filter so that the field gets the geolocation treatment. filter { grok { patterns_dir => \"\/opt\/logstash\/patterns\" match => { \"message\" => \"%{NGINX_ACCESS}\" } } date { match => [ \"timestamp\" , \"dd\/MMM\/YYYY:HH:mm:ss Z\" ] } geoip { source => \"client_ip\" } } You can run to test the configuration file and ensure your pattern works. There's also a website where you can . If you're running Logstash as a service, or intend to, you'll need to place the file in My preference when configuring globally-installed tools such as Logstash is to keep configuration files in a centralized location and then create symbolic links in the places where the tool is looking for those files. In the case of Logstash there's two types of files we'll be using: patterns and Logstash configuration files. I'll be keeping them in and creating links to the places where Logstash looks for each of these kinds of files. By the way, I had an issue where logs wouldn't be piped into Elasticsearch, and Logstash would fail silently, . It turned out to be a file permissions issue, one that was easily fixed by ensuring that the user had execute permissions on every directory from to . You can verify that by executing the following command, which interpolates all the way through to the directory. You'll get output such as this: getfacl: Removing leading '\/' from absolute path names # file: var\/log\/nginx # owner: www-data # group: adm user::rwx group::r-x other::--- You'll note that in this case, user of group wouldn't have execute rights on . This can be easily fixed with the following command, but it gave me quite the headache until I stumbled upon this particular oddity. sudo chmod o+x \/var\/log\/nginx I didn't just want to stream logs to Elasticsearch, I also wanted application level logs to be here. Let's do this! Throwing Logs into the MixTo add Node logs into the mix, we don't need to change the section of our Logstash file. It has all we needed. We do need to change the and sections. First, we'll add another to the section. This should point to the file where your Node.js app is streaming its logs into. In my case that file was , which is where the service running my app redirected its output. input { file { type => \"node_app\" path => \"\/var\/log\/ponyfoo-production.log\" } } Now, the log is a bit different. Sometimes, there are multi-line log entries. That happens when I log a stack trace. That's easily fixed by adding to my input processor, where each log entry must start with a pattern-matching string, or otherwise is merged into the current log entry. Effectively, this means that lines that don't start with a timestamp will be treated as part of the last event, until a new line that matches a timestamp comes along, creating a new entry. input { file { type => \"node_app\" path => \"\/var\/log\/ponyfoo-production.log\" codec => multiline { patterns_dir => \"\/opt\/logstash\/patterns\" pattern => \"^%{NODE_TIME} \" what => \"previous\" negate => true } } } My Node.js logs are quite compact, containing a date and time, a marker and the logged message. 8 Jun 21:53:27 - info: Database connection to {db:ponyfoo-cluster} established. 08 Jun 21:53:27 - info: Worker 756 executing app@1.0.37 08 Jun 21:53:40 - info: elasticsearch: Adding connection to http:\/\/localhost:9200\/ 08 Jun 21:53:40 - info: cluster listening on port 3000. 08 Jun 21:56:07 - info: Database connection to {db:ponyfoo-cluster} established. 08 Jun 21:56:07 - info: Worker 913 executing app@1.0.37 08 Jun 21:56:07 - info: elasticsearch: Adding connection to http:\/\/localhost:9200\/ 08 Jun 21:56:08 - info: Database connection to {db:ponyfoo-cluster} established. 08 Jun 21:56:08 - info: Worker 914 executing app@1.0.37 08 Jun 21:56:08 - info: elasticsearch: Adding connection to http:\/\/localhost:9200\/ 08 Jun 21:56:08 - info: app listening on ip-10-0-69-59:3000 08 Jun 21:56:09 - info: app listening on ip-10-0-69-59:3000 As a result, my Node.js patterns file is much simpler. The was exacted into its own pattern for convenience. NODE_TIME %{MONTHDAY} %{MONTH} %{TIME} NODE_APP %{NODE_TIME:timestamp} - %{LOGLEVEL:level}: %{GREEDYDATA:description} In order for the section to play nice with two different input files under different formats, we'll have to update it using conditionals. The following piece of code is the same section we had earlier, wrapped in an that checks whether we are dealing with an event of type . filter { if [type] == \"nginx_access\" { grok { patterns_dir => \"\/opt\/logstash\/patterns\" match => { \"message\" => \"%{NGINX_ACCESS}\" } } date { match => [ \"timestamp\" , \"dd\/MMM\/YYYY:HH:mm:ss Z\" ] } geoip { source => \"client_ip\" } } } For events, we'll do something quite similar, except there's no geolocation going on, and our main pattern is named instead of . Also, make sure that the filter matches the new document type, . filter { if [type] == \"node_app\" { grok { patterns_dir => \"\/opt\/logstash\/patterns\" match => { \"message\" => \"%{NODE_APP}\" } } date { match => [ \"timestamp\" , \"dd MMM HH:mm:ss\" ] } } } Purrrfect! If you restart , \u2013 either using the service or by executing the command again \u2013 it should start streaming logs into Elasticsearch, from both and , as soon as the Logstash service comes online. How do we interact with those logs in a friendly manner then? While it's okay for search to be mostly accessible through the web interface of the blog, it'd be pretty pointless to go through all of this trouble just to dump the logs into a table again on the web front-end. That's where comes in, Getting Started with KibanaHaving already installed the Elastic Stack, and after having set up Logstash to channel our logs into Elasticsearch, we're now ready to fire up Kibana and gain some insights into all our data. The default port Kibana listens on is . I use as a reverse proxy in front of Kibana. You can use to forward requests to the back-end Kibana app. Here's the full entry for I use for . server { listen 8080 proxy_protocol: server_name analytics.ponyfoo.com: set_real_ip_from 172.31.0.0\/20: real_ip_header proxy_protocol: access_log \/var\/log\/nginx\/analytics.ponyfoo.com.access.log metrics: location \/ { proxy_pass http:\/\/127.0.0.1:5601: proxy_redirect off: proxy_http_version 1.1: proxy_set_header Host $http_host: proxy_set_header Upgrade $http_upgrade: proxy_set_header Connection $connection_upgrade: proxy_set_header X-Real-IP $remote_addr: proxy_cache one: proxy_cache_key nx$request_uri$scheme: } } Now you should be able to visit your Kibana dashboard at either or your designated port and hostname. The first time you load Kibana, you will be greeted with a message about configuring a default index pattern. Kibana suggests we try the index pattern. Logstash defaults to storing events on indices named according to the day the event is stored on, such as , and so on. The in the pattern acts as a wildcard so that every index starting with will match. Once we've set up the index pattern, we might want to visit the tab. Here, we'll be able to pull up Elasticsearch records as data rows, as well as a simple time-based chart displaying the amount of events registered over time. You can use the Elasticsearch query DSL to perform any queries and you can also apply filters on top of that query. Data tables are nowhere near the most exciting kind of thing you can do in Kibana, though. Let's take a look at a few different charts I've set up, and while we're at it I'll explain the terminology used by the Kibana interface as well as a few statistics terms in layman's language. Articles have been written before that describe in detail , but I'll favor Let's head to the tab for our first visualization. Charting Status Codes and Request VolumeCreate a pie chart and select for the index pattern. You'll note that the default pie chart visualization is a whole pie containing every matching document and displaying the total count. Fair enough. Add a bucket with a aggregation and choose the field That sentence was overcharged with technical terms. Let's break it down. We are splitting the pie into several slices, using the Terms aggregation type to indicate that we want to identify distinct terms in the field, such as , , , and grouping documents by that aggregation. We'll end up with an slice for documents with a status code of , another slice for documents with a status code, and so on. Generally speaking, a healthy application should be returning mostly and responses. This chart makes it easy to visualize whether that's the case. You can further specialize the graph by adding a sub-bucket, aggregating again using Terms, this time by the field. That way, you'll not only get a general ratio of status codes, but you'll also gain insight into which requests are the most popular, as well as which ones are the most problematic, all in one chart. In the screenshot found below, you can see that the route is getting even more traffic than the home page. Maybe a little bit of caching is in order, since the RSS feeds don't change all that often. In the same light, earlier on these pie charts helped me identify and fix a bunch of requests for icons and images that were yielding errors. That's something that would've been harder to spot by looking at the dense and raw nginx logs, but it's really easy to take action based on visualizations that help us work with the data. Save the pie chart using the link on the top bar and give it a name such as \"Response Stats\". Plotting Responses Over Time, By Status CodeGo back to the Visualize tab and create a new line chart. You'll see that we only get a single dot graphed, because there's no axis by default. Let's add an , using a of . This is a fancy way of saying we want to group our data points into 30 minute long buckets. All events within a 30-minute window are grouped into a single bucket displaying the Count . A makes it possible to render a large dataset into a line chart without having to render several thousands of individual data points. The Date Histogram aggregation allows you to define the time lapse you want to use to group events, or you can use the default value of 30 minutes, as with the example below. While it's useful to render requests over time, particularly when it comes to determining whether our server is functioning properly under load, experiencing a sudden surge of requests, or not responding to a single request, it's even more useful to understand the underlying sub-segments of data. What are the status codes for each of those responses over time? Was the spike that we saw in the earlier chart the product of errors or just a spike in traffic? Add a aggregation by Terms using the field. After hitting Enter , we'll note that the chart is now divided into several different lines, each line representing all responses that ended with a given status code. Now it'll be much easier to spot error spikes and discern them from spikes in traffic. Save this chart as , and let's create something else. Charting Geographic DataIt's really easy to chart geographic data into a map using Kibana, provided that you've set up the filter in Logstash as indicated earlier, so that the IP addresses found in nginx logs are transformed into geolocation data that can be charted into a map. Given that, it's just a matter of going to the Kibana Visualize tab, creating a Tile Map, and adding a Geo Coordinates bucket using the field computed by Logstash. Save the map as . Stitching It All TogetherNow that we've created three different visualizations, where we have a rough overview of status codes and the hottest endpoints, time-based plots of each of the status codes, and a map showing where requests are coming from, it'd be nice to put all of that in a single dashboard. Visit the tab in Kibana, pick from the top-bar navigation and add all of our saved charts. After some rearranging of the charts, you'll get a dashboard like the one below. You can save this one as well, naming it something like . Whenever you want to get a glimpse into your operations now you can simply visit the Overview dashboard and you'll be able to collect insights from it. I've also included an \"average response time\" over time chart in my dashboard, which wasn't discussed earlier. You can plot that on a line chart with a axis of a with minute or second resolution, and an axis using an aggregation of . \u00a0to your data and Kibana instanceOther X-Pack features include cluster health monitoring, alerting on changes in your data, reporting, and graph exploration. I've set it up myself for my blog, and I must say that X-Pack is pretty awesome. Check out\u00a0\u00a0to learn more about setting it up. In this article, I've decided against providing a more detailed description of the installation process and features in X-Pack. If you want to give it a shot, we offer\u00a0\u00a0where you can take all of these extra awesome features for a ride. This post originally \u00a0and the author built\u00a0upon the Elasticsearch index set up for search in . \n"}
{"index": {"_id": 584}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-06-27","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-06-27","author":{"name":"Michael McCandless"},"date":"June 27, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top News \u201cHow Airbnb manages to monitor customer issues at scale\u201d by \u2014 Joe McCann (@joemccann) Elasticsearch Core Apache Lucene Watch This Space , where we'll share more news on the whole Elastic ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 585}}
{"title":"Logstash Lines: More Monitoring Info, Beats Input Improvements","seo_title":"","url":"\/blog\/logstash-lines-2016-06-27","author":{"name":"Suyog Rao"},"date":"June 27, 2016","category":"The Logstash Lines","locales":"","content":" Welcome back to The Logstash Lines! In these weekly posts, we'll share the latest happenings in the world of Logstash and its ecosystem. Moar Metrics, Moar Visibility (5.0)For key filters like Grok, Date and GeoIP, we added per-plugin metrics like number of matches, failures, cache stats, and some more. This, coupled with execution timings we added recently, should make it easier to debug these popular filters. \"name\": \"grok\" \"failures\": 3 \"matches\" : 1, \"patterns_per_field\" : { \"message\" : 1 }, Persistent QueuesThis week saw good progress in this area! Colin and Guy pushed initial commits for the low level data structures and classes that implement ack-able file based queues. Follow the for updates. Beats Input ImprovementBeats input is being rewritten in Java, using the Netty library. This week we are doing and end-to-end testing. Curator v4Big day for Curator! Aaron a new version with tons of enhancements. The headlining feature is adding support for snapshot restore, and a new yaml based config file to manage execution. Others: \/tmp\/logstash-5.0.0 % time bin\/logstash --version logstash 5.0.0 27.79s user 1.34s system 270% cpu 10.773 total .... \/tmp\/logstash-5.0.0 % time bin\/logstash --version logstash 5.0.0 0.01s user 0.02s system 101% cpu 0.029 total \n"}
{"index": {"_id": 586}}
{"title":"Elasticsearch Percolator Continues to Evolve","seo_title":"Elasticsearch Percolator Continues to Evolve","url":"\/blog\/elasticsearch-percolator-continues-to-evolve","author":{"name":"Martijn van Groningen"},"date":"June 27, 2016","category":"Engineering","locales":"","content":" In 5.0 the percolator is much more flexible and has many improvements. For example, to be able to skip evaluating most queries. All of this is part of since Elasticsearch , which made the percolator scale with the number of shards and nodes in your cluster. However the underlying mechanism of the percolator hasn\u2019t been changed since this feature was back in version . If you didn\u2019t make use of query metadata tagging the execution time of the percolator was always linear to the amount of percolator queries, because all percolator queries had to be evaluated all the time. The main purpose of this refactoring was to address this, so that in many cases not all percolator queries have to be evaluated when percolating a document. The slowest part of percolating is verifying if a percolator query actually matches with the document being percolated. When percolating, the document being percolated gets indexed into temporary in-memory index. Prior to 5.0, all percolator queries need to be executed on this in-memory index in order to verify whether the query matches. So the idea is that the less queries that need to be verified by the in-memory index the faster the percolator executes. Percolator field mapper It is no longer required to index percolator queries in the special type under the field. Any field and type (in any index) can contain percolator queries. Instead before indexing percolator queries, you must configure the in the type you\u2019re going to index percolator queries into. So let\u2019s take a look at how this looks now: We created an index with the name , which has two mappings. The first mapping , is for the percolator query documents, in this case the query must be defined inside the field. The second mapping is for a document being percolated. We need to define this mapping upfront, otherwise the queries that are going to be indexed wouldn\u2019t be analyzed correctly and the process used to skip evaluating percolator queries relies on this analysis. After this we can just index the following document, which holds a query: Besides storing the actual query, the field mapper extracts all terms from the query and indexes them separately into an auxiliary indexed field that is part of field. In the above example the following terms will get extracted and indexed: and . During percolation all the terms from the document to be percolated are extracted. A query is built from these terms, so that the percolator can query this auxiliary field to find candidate percolator queries that may match with the document being percolated. Potentially many percolator queries that don\u2019t match with this query are never evaluated by the in-memory index and thus reducing the time it takes to execute the entire percolate request. It is safe to ignore these percolator queries, because if the queries\u2019 terms don\u2019t appear in the document being percolated then these queries will never match anyway. This is a big win. The query can\u2019t extract terms from all queries and if that happens these percolator queries get marked and will always be evaluated upon percolating. Most term based queries (like , , , and most span queries) and compound queries (like , and queries) are supported. If you\u2019re wondering how you can figure out which queries the field mapper was able to extract the terms for, you can just execute a query as described . Also the percolator will no longer load the percolator queries as Lucene queries into memory as they are instead read from disk. Pre 5.0 if you had thousands of percolator queries they\u2019d take up megabytes of precious JVM heap space, putting pressure on jvm garbage collecting and if not being careful lead to an infamous jvm out of memory error. Back then loading the percolator queries into memory made sense because all the percolator queries were evaluated all the time so we made executing each one as fast as possible. Now with pre-selecting, only percolator queries that are likely to match. We decided to trade speed for stability, removing the caching to free up memory. The speed loss is more than paid for by skipping most queries in most cases. Also updates made to the percolator query are no longer visible in real time by default. This is because Elasticsearch relies on a query to select percolator queries to execute and that search index is updated by the refresh cycle. If you want changes to a percolator query to be visible in real time, you need to run a refresh as part of the index, delete, or update request. Alternatively you can also use option that is available on all write APIs. Indices holding types created before upgrading to Elasticsearch 5.0 will continue to work. However because these types don\u2019t have the new field mapper, the percolator will need to evaluate all the queries all the time. So it is strongly recommended that the percolator queries in these indices are reindexed into a new index. We will drop support for the type in the next major version of Elasticsearch. Percolate query Another big change is that the percolate and multi percolate APIs have been superseded by the search and multi search APIs with the . First let\u2019s look at percolating a document in Elasticsearch 2.x and before via percolate API: The percolate API would then respond with a response like this: Percolating a document via the search API in Elasticsearch 5.0 and onwards: The search API would then respond with the following response: As you can see the percolate API response is very minimalistic compared to the search API response. The percolate API basically just returns ids, whereas the the search API returns the source of the percolator and score. Aside from returning more information, the move to the search API and its infrastructure was huge. Just by 7 requested features (pagination support, returning and others) were immediately implemented, while at the same time exposing the same functionality the percolate APIs did. Also because the percolator is now a query, it has become much more flexible. You\u2019re free to use the in any other query. For example in a clause of query or just define multiple queries inside of a query. For example percolate two documents at the same time via a query with two queries in its should clauses: In the above case this would return percolate queries that match with either documents or both. Scoring in percolator has also changed completely. In Elasticsearch 2.x and before the percolator API didn\u2019t return a score unless a query was specified. The query was meant to query on the percolator query\u2019s metadata and therefore the score didn\u2019t tell anything about how well the percolator query matches with the document being percolated. The score that the query emits for each percolator query is now based on the score the in-memory Lucene index computes. Note that if your application is using the percolate or mpercolate APIs, that you can still use these APIs after you\u2019ve upgraded to . However these APIs have been deprecated and will not exist from Elasticsearch . This will give the opportunity to first upgrade to Elasticsearch and then migrate to the query either via the search or msearch APIs. Behind the scene the percolate and mpercolate APIs will transform the percolate request into a search request and redirect that to the search API or msearch API. Improving the percolator doesn\u2019t stop. Especially the field mapper will continue to get improvements, so that at search time the query will need to fallback to the in-memory index for match verification less often. We would love for you to try out the latest in order to test drive the improved percolator. Happy percolating! \n"}
{"index": {"_id": 587}}
{"title":"Curator 4.0 Release","seo_title":"","url":"\/blog\/curator_v4_release","author":{"name":"Aaron Mildenstein"},"date":"June 24, 2016","category":"Releases","locales":"","content":" I am very pleased to announce the release of\u00a0! So much has changed since version 3. This is a major change in how Curator works. I\u2019ve listened to a lot of feedback, and incorporated many suggestions. I think you\u2019ll find the results compelling. Before we go on, you need to know about the breaking changes from the previous version. Breaking changes Version Support Due to the sweeping nature of the changes, this is the first version of Curator which is not fully reverse compatible with older versions of Elasticsearch. Curator 4 only supports Elasticsearch versions 2.x and the 5.0 pre-releases. It is anticipated that Curator 4 will continue to support Elasticsearch 5.0 releases, though a special Curator 5 may be released which will take advantage of new features set to be released in Elasticsearch 5. API The API is completely different. If you were using the 3.x API, you will perhaps want to stick with that until you\u2019ve tested the new API out. The documentation for the new API is still at\u00a0 Command line The command line structure is completely different. The new command line only has these few flags: Date Math Dates are all converted to epoch time. Conversions no longer try to pad a full time unit. Either an age is older or younger than the reference epoch time, or it isn\u2019t. More on these changes in a bit! How is it different? Curator 3 and each of its predecessors were designed to be run from cron, so that periodic maintenance could be performed easily. All of the other features added to Curator since the very beginning (which was\u00a0\u00a0index deletion) have been bolted on, resulting in a very complex command-line structure. This was still navigable, but not what I would have called ideal. One of the most requested features was snapshot restore. A look at the configuration flags revealed that 9+ additional flags would have been required to accommodate only most of the options available.\u00a0 Another frequent request was atomic add and remove alias actions. I puzzled over how to do that with the command-line structure for a long time and realized that it would have resulted in huge, complicated and hard to read command lines. It was time to rethink Curator configuration.\u00a0\u00a0The solution? Configuration files. Configure all the things! One of the design decisions for Curator 4 was to use YAML configuration files\u2013two of them, to be precise:\u00a0\u00a0(and logging options), and\u00a0. Having a default client configuration allows for multiple, different action configuration files to not need to repeat the client information in each of them. If you store the client configuration file as\u00a0, then you won\u2019t even have to reference it at the command-line! The action file allows for\u00a0\u00a0and\u00a0 Filter Stacking If you used Curator before version 4, then you know that Curator had a limited number of ways you could combine filters before performing the desired action. Generally, that was limited to regular expression filtering combined with age-based filtering. With Curator 4, you can combine multiple filters together\u2013as many as you like\u2013to restrict which indices to act on. How might this help you?\u00a0 Let\u2019s say you want to delete Logstash named indices in excess of 30G of total space consumed. This might represent 30 days worth of data with your normal logging. What if some event caused a torrent of log lines to be produced? You might accidentally delete weeks worth of logs. With filter stacking, you could first filter by pattern, to only count Logstash indices. The next filter would be disk space, 30G worth, sorting by age. The third filter, however, is the magic one: Only delete indices older than 30 days. The total stack would mean, \u201cdelete Logstash indices in excess of 30G of storage, but only if they\u2019re also older than 30 days.\u201d Neat, eh?\u00a0This is what the action file might look like: actions: 1: action: delete_indices description: >- Delete indices. Find which to delete by first limiting the list to logstash- prefixed indices. Next filter by space, to those indices in excess of 20g of usage. Then further filter those to prevent deletion of anything less than 30 days old. options: continue_if_exception: False disable_action: False filters: - filtertype: pattern kind: prefix value: logstash- - filtertype: space disk_space: 20 use_age: True source: creation_date - filtertype: age source: creation_date direction: older unit: days unit_count: 30 Command Chaining Command chaining means that you don\u2019t have to execute a different Curator command for each action you want to perform. You can use the YAML action file to have multiple commands, one after the other, in the same file. It is a configurable option to have execution halt if an action fails with an exception, or continue even if there is an exception. New Actions There are some new tools in the Curator stable: One that should almost be considered new since it\u2019s so improved over previous versions is\u00a0, which now supports simultaneous, atomic add & remove. Optimize has been renamed to\u00a0, in accordance with Elastic\u2019s API changes. New Filters Well, mostly just\u00a0\u00a0filters. Filter by space allows you to also filter by age, so that instead of filtering exclusively by space, that you can also filter by age as an extra step in the space filter (not as a stacked filter). Why might this be important? So you delete the oldest indices first, of course!\u00a0\u00a0Speaking of deleting the oldest indices first, filtering by age now offers 3 different ways to determine index age:\u00a0\u00a0*\u00a0name\u00a0(which is what all previous versions of Curator used) requires a time or date as part of the index name\u00a0*\u00a0creation_date\u00a0derives the age from the time that Elasticsearch created the index, as stored in the index metadata\u00a0*\u00a0field_stats\u00a0calculates the age from the greatest and least values in a specified field. For Curator 4, since this is age calculations, the field type must be mapped as a date. Age Calculation Also, with regards to age, Curator now converts the name-derived timestamps to epoch time for comparisons, since \u00a0and\u00a0\u00a0are already in epoch time. This is important, as it means that comparisons do not follow the conventions used in Curator 3. If a timestamp is older than a date, it\u2019s older. If it\u2019s younger, it\u2019s younger. Curator no longer tries to calculate and compensate for a full unit count. Test with the\u00a0\u00a0flag before using this to ensure you don\u2019t delete something you want kept.\u00a0Also, since all time calculations are relative to epoch time, and are therefore in seconds, time units have been revamped as multiples of seconds: if unit == 'seconds': multiplier = 1 elif unit == 'minutes': multiplier = 60 elif unit == 'hours': multiplier = 3600 elif unit == 'days': multiplier = 3600*24 elif unit == 'weeks': multiplier = 3600*24*7 elif unit == 'months': multiplier = 3600*24*30 elif unit == 'years': multiplier = 3600*24*365 This means you can use seconds, minutes, hours, days, weeks, months, or even years as valid units. Just remember that Curator 4 doesn\u2019t care that February only has 28 days. If you use months, it is counting 30 days worth of seconds. Installing and Upgrading Installing The instructions for installing Curator 4 are at\u00a0.\u00a0 Upgrading If using pip, it\u2019s as simple as\u00a0 If using\u00a0\u00a0or\u00a0\u00a0packages, I highly recommend you uninstall any older versions (include the 4.0 pre-releases), and then follow the installation procedure for 4.0. What else is new? There\u2019s too much for me to describe in a single blog post. I\u2019ll continue to write about the new changes in Curator 4 over the coming days. In the meantime, please read the\u00a0\u00a0and the\u00a0\u00a0for more information. Happy Curating! \n"}
{"index": {"_id": 588}}
{"title":"Running Elasticsearch on AWS","seo_title":"Instructions for Running Elasticsearch on Amazon Web Services (AWS)","url":"\/blog\/running-elasticsearch-on-aws","author":{"name":"Kosho Owa (JP)"},"date":"June 22, 2016","category":"Engineering","locales":"de-de,fr-fr,ko-kr","content":" : Elastic Cloud ( can now be added directly\u00a0your AWS bill through the . If you are looking for hosted & managed Elasticsearch, you can for 14-days at no cost. For deploying and managing yourself on AWS EC2, this is the right article for you:Part I - Provisioning EC2 InstancesWe often talk to customers running Elasticsearch clusters on Amazon Web Services (AWS). AWS is a convenient way to provision and scale machine resources in response to changing business requirements. Elasticsearch takes advantage of EC2's on-demand machine architecture enabling the addition and removal of EC2 instances and corresponding Elasticsearch nodes as capacity and performance requirements change. In this article we will show you how to deploy on Amazon EC2. In this example we will configure a three node Elasticsearch cluster. Step 1: Choose an Amazon Machine Image (AMI)Elasticsearch runs on various operating systems such as CentOS, Redhat, Ubuntu, and Amazon Linux. We suggest using the latest Amazon\u00a0Linux AMI \u2014 \"Amazon Linux AMI 2016.03.0 (HVM), SSD Volume Type\". Step 2: Choose an Instance TypeA reasonable starting instance type is m3.2xlarge which provides 8 vCPUs, 30 GiB of memory, 2 x 80 GB SSD drives and comes with High Network Performance. Solid State Drives are preferred as indexing is IO intensive and High Network Performance is essential for cluster performance and reliability. M3.2xlarge is a baseline recommendation. To determine whether it is an appropriate choice, you should to determine whether it meets performance and scaling requirements. Click the \"Next: Configure Instance Details\" button. Step 3: Configure Instance DetailsEach Elasticsearch node will run on its own dedicated EC2 instance, so set the number of instances to 3. Note that any AWS accounts that have been created after December 4, 2013 only support EC2-VPC, so the \"Network\" option for picking \"Launch into EC2-Classic\" won't be available for those users and should not be enabled anyway. Selecting \"Enable termination protection\" is a good idea as it prevents accidental deletion of nodes and their data. Leave the default values for remaining fields and click the \"Next: Add Storage\" button. Step 4: Add StorageLet's leave the storage Size at 8 GiB. If you happen to know your index storage requirements at this time, you can adjust the storage now. Leave the Volume Type set to General Purpose SSD. Click the \"Next: Tag Instance\" button. Step 5: Tag InstanceIn this field, provide a key and value pair, for example \"name\" and \"esonaws\", to make it easy to recall the ec2 instances. Click the \"Next: Configure Security Group\" button. Step 6: Configure Security GroupThis configuration panel allows you to configure a set of firewall rules for accessing your instance. By default, Elasticsearch exposes TCP port 9200 for REST API access and TCP port 9300 for internal cluster communication. Consider adding rules to allow connecting to TCP port 9200 from desired subnets, typically private subnets, and TCP port 9300 from the subnets where Elasticsearch nodes live. If you plan to change the default port settings in elasticsearch.yml, configure rules for those ports rather than TCP ports 9200 and 9300. Also, add a rule to allow SSH connections on port 22, so you can connect to the instance in the later steps. Click The \"Review and Launch\" button. Step 7: Review Instance LaunchNote any warnings and review the Instance Launch settings and click the \"Launch\" button when ready. At this point you will be prompted to provide a key pair or create a new key pair. This is necessary to enable SSH access to the EC2 instance. If you need help setting up a key pair the article provides an overview and instructions for creating new new key pairs. Start up the EC2 instances and take note of the assigned private IP addresses which we will use in a following step. Part II - Installing ElasticsearchRPMLog into each EC2 instance via SSH. $ ssh -v -i \/pathto\/[certfilename].pem ec2-user@[ec2hostname] Then install the Elasticsearch RPM package on each EC2 instance as instructed below. $ sudo rpm -i https:\/\/download.elastic.co\/elasticsearch\/release\/org\/elasticsearch\/distribution\/rpm\/elasticsearch\/2.3.3\/elasticsearch-2.3.3.rpm Other versions of Elasticsearch are available . Refer to if you prefer installing with yum. Register Elasticsearch as a system service. $ sudo chkconfig --add elasticsearch Install PluginsYou need to install\u00a0AWS cloud plugin on each EC2 instance in the cluster. $ cd \/usr\/share\/elasticsearch\/ $ sudo bin\/plugin install cloud-aws If there are any additional plugins you need, such as Marvel, for monitoring, or ICU, for additional language support, now is a good time to install them. Configure ElasticsearchThe maximum JVM heap size should be based upon the machine's memory. Open \"\/etc\/sysconfig\/elasticsearch\" on each EC2 instance with your favorite editor and set the \"ES_HEAP_SIZE\" and \"MAX_LOCKED_MEMORY\" parameters. The following configuration will fit a m3.2xlarge instance. The \"ES_HEAP_SIZE\" is recommended to be half of the memory but not more than 32GB. ES_HEAP_SIZE=15g MAX_LOCKED_MEMORY=unlimited Open \"\/etc\/elasticsearch\/elasticsearch.yml\" on every machine and edit the following settings. cluster.name:esonaws bootstrap.mlockall: true discovery.zen.ping.unicast.hosts: [_ip_address_,\u2026] network.host: [_ip_address_] \"\" is a list of EC2 instance private IP addresses. All the master-eligible nodes must be listed. In a small cluster all nodes can be configured as both master nodes and data nodes. is the EC2 instance private\u00a0IP address\u00a0of\u00a0this host that is shared with the\u00a0other nodes in the cluster.The IP address is not required for a single node cluster. \"_site_\" and \"_local_\" represent the private address and the local loopback address \"127.0.0.1\" and allow access to those from remote. Starting Up and VerificationIf you are setting up multiple Elasticsearch nodes, they must all be the same version, same plugins and equivalent configurations. Start up Elasticsearch on each EC2 instance. $ sudo service elasticsearch start Once started, let's verify the Elasticsearch cluster by using curl to request the cluster state. $ curl localhost:9200\/_cluster\/health?pretty If successful, the \"status\" will be \"green\" (or \"yellow\" for a single node). The \"number_of_nodes\" should be the same number of nodes started. Depending on your index settings,\u00a0you will need a minimum of two nodes for the cluster \"status\" to turn \"green\". A minimum of 3 nodes is recommended to avoid leader election conflicts.\u00a0If \"status\" isn't \"green\" you can also check the Security Group configuration or check logs under \"\/var\/log\/elasticsearch\" for errors. { \u201ccluster_name\u201d : \u201cesonaws\u201d, \u201cstatus\u201d : \u201cgreen\u201d, \u201ctimed_out\u201d : false, \u201cnumber_of_nodes\u201d : 3, \u201cnumber_of_data_nodes\u201d : 3, \u201cactive_primary_shards\u201d : 8, \u201cactive_shards\u201d : 16, \u201crelocating_shards\u201d : 0, \u201cinitializing_shards\u201d : 0, \u201cunassigned_shards\u201d : 0, \u201cdelayed_unassigned_shards\u201d : 0, \u201cnumber_of_pending_tasks\u201d : 0, \u201cnumber_of_in_flight_fetch\u201d : 0, \u201ctask_max_waiting_in_queue_millis\u201d : 0, \u201cactive_shards_percent_as_number\u201d : 100.0 } Your Elasticsearch cluster is ready! SummaryDeploying an Elasticsearch cluster on Amazon EC2 is relatively easy, but it does require a number of configuration steps, familiarity with SSH, key pair management, and also assumes that you will be managing the machines. If you prefer the ease-of-use of a managed service, , Elastic's official hosted Elasticsearch and Kibana offering on AWS, is a great choice. You can spin up a cluster in just a few clicks. also comes with Security, Kibana, supported Plugins, on-demand cluster scaling, automatic version backup and more. The is free and doesn't require a credit card. Here's a link to a\u00a0short video that describes in a little more detail. \n"}
{"index": {"_id": 589}}
{"title":"Just Enough Kafka For The Elastic Stack, Part 2","seo_title":"Just Enough Kafka For The Elastic Stack, Part 2","url":"\/blog\/just-enough-kafka-for-the-elastic-stack-part2","author":{"name":"Suyog Rao"},"date":"June 22, 2016","category":"Engineering","locales":"de-de,fr-fr,ja-jp,ko-kr","content":" Welcome to part 2 of our multi-part and Elastic Stack post. In our , we introduced use cases of Kafka for the Elastic Stack and shared knowledge about designing your system for time based and user based data flow. In this post, we'll focus on the operation aspects: tips for running Kafka and\u00a0Logstash in production to ingest massive amounts of data. Before we dive deep, a reminder that we are mostly talking about Kafka 0.8, and Logstash 2.x which is the current stable version. There are newer versions of Kafka \u2014 0.9 and recently, 0.10, but the core concepts discussed here can be applied to any Kafka versions. Without further ado, let\u2019s start by discussing the different systems at play here: Kafka has a dependency on (ZK) \u2014 brokers need it to form a cluster, topic configuration is stored in ZK nodes, etc. Plus, in version 2.x of Logstash, the input offsets are stored in ZK as they get acknowledged. Newer versions of Kafka have decoupled the clients \u2014 consumers and producers \u2014 from having to communicate with ZooKeeper. In Kafka 0.9 and 0.10, offsets are stored in topics by default instead of in ZK. Either way, you still need ZooKeeper to run Kafka brokers. Our general advice is to run 3 ZK instances to achieve a quorum configuration, and all of them on separate hardware. For more information on operationalizing ZK, refer to in Kafka docs. From our experience, ZK itself does not need much hand-holding once set up. You just have to make sure the instances are up and are monitored. Number of Kafka brokers you need typically depends on data retention and replication strategy. The more brokers you add, more data you can store in Kafka. In terms of resources, Kafka is typically IO bound. Performance will be limited by disk speed and file system cache \u2014 good SSD drives and file system cache can easily allow millions of messages\/sec to be supported per second. You can use to monitor these information. How many Logstash instances do you need to process the data in Kafka? It is really hard to magically place a number for this, because frankly, it depends on a lot of variables. Questions like: how many filters do you have? How expensive are your filters, needs to be answered. Remember, it is really easy to end up with a complex Grok pattern with multiple conditionals to process your data! What is your volume of data you expect? What are all your outputs? As you see, there's a lot of information we need to gather before providing a number. Often times, it is the outputs (external systems) where you have to focus your capacity planning, not Logstash itself! That being said, you can easily scale Logstash and Elasticsearch horizontally. Therefore, our advice is to start small, and continue to add nodes or new LS instances as your data needs grow. In particular, for data in Kafka that Logstash consumes, you can group multiple instances into consumer groups. Each group shares the load and instances will handle data exclusively, i.e. messages will be consumed only once by one client in the group. This design lends very cleanly to our original proposition \u2014 start small and scale iteratively. Using topics, you can design your workflow such that data which needs more complex transformations, or data that needs to be stored in a slower output is isolated from other fast-moving data. Remember, in Logstash, a single slow output can block all other outputs which are configured to run after it. As we've mentioned before, Elasticsearch is truly elastic in that you can scale up easily. Capacity planning for Elasticsearch is an entire blog\u00a0post by itself, and beyond the scope of this article. We recommend you read the following posts which cover the concepts of\u00a0scaling and sizing Elasticsearch --\u00a0, , and .\u00a0 \u00a0 If your Kafka instance is running out of disk space, chances are that your retention time for Kafka logs is too high. In Kafka, you can configure data retention based on 2 criteria: age and size, using and broker settings respectively. If either one of these criteria is met, Kafka broker will start deleting messages starting from the oldest, regardless of whether Logstash has consumed it. It is tempting to design data recovery and retention for Elasticsearch by using Kafka's retention tools. From our experience, it is best to use a tool like to manage Elasticsearch's time-based indexes, in addition to configuring a snapshot strategy for restoring indexes on any catastrophic failures. Most often, data in Kafka is raw, unfiltered content, and has multiple destinations, so it is good to not have it tightly coupled to one downstream component. From Kafka\u2019s documentation: Kafka input keeps track of offset information using ZooKeeper. As Logstash pulls messages from the topic and processes it, it periodically commits to ZK. This process is called check-pointing or committing. By default, Logstash check-points to ZK every minute. You can control this frequency by using the setting. Be aware that longer times for this setting could lead to data loss in case Logstash is forcefully stopped, or the process crashes. On the other hand, small time value means increase writes per client, which could overwhelm the ZK cluster. If you restart Logstash, it will first read the offset information stored in ZK and start fetching messages from the previous commit point. Kafka is designed to follow semantics \u2014 messages are guaranteed to be not lost, but may be redelivered. This means there could be scenarios where Logstash crashes, while the offset is still in memory, and not committed. This cause messages to be re-delivered, or in other words, duplicated. If this is a concern in your use\u00a0case, you can workaround the potential duplication by generating\/using unique IDs in a field for your messages. Whether you write your own code to create these IDs, or use the filter in Logstash, you will have to do this prior to the messages entering Kafka. On the \"shipper\"\u00a0side of Logstash, you can map this event ID to option in the Elasticsearch output plugin. This means Elasticsearch will overwrite the indexed document which has the same ID, which is generally preferred over producing multiple documents with same content! This is also useful if you ever have to replay content, should you lose data downstream. You can use a different consumer group to replay data at its own pace. input { kafka { zk_connect => \"kafka:2181\" group_id => \"logstash\" topic_id => \"apache_logs\" consumer_threads => 16 } } .... output { elasticsearch { document_id => \"%{my_uuid}\" } } Where is an existing field in the Event. One of the important things to monitor when using Kafka is how many messages are backed up and waiting to\u00a0be consumed by Logstash. There are plenty of tools to monitor this information: below are some options: CLI tool bundled with KafkaSimple, command line tool to check offsets. You can run it on a cronjob periodically and alert using your favorite alerting software. \/usr\/bin\/kafka-consumer-offset-checker --group logstash --topic apache_logs --zookeeper localhost:2181 Sample response: Group Topic Pid Offset logSize Lag Owner logstash apache_logs 0 145833 300000 154167 none logstash apache_logs 1 145720 300000 154280 none logstash apache_logs 2 145799 300000 154201 none logstash apache_logs 3 146267 300000 153733 none The Lag column tells you how many messages you are lagging by. Kafka can be easily monitored via JMX with . To attach JMX to monitor Logstash, you can set these extra Java options before starting Logstash: export LS_JAVA_OPTS=\" -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.port=3000 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false\" If you are running on AWS, don't forget to use the external hostname or IP of the server. -Djava.rmi.server.hostname=ec2-107-X-X-X.compute-1.amazonaws.com Why yes, you can monitor Kafka\u00a0by using the Elastic Stack itself. Obviously, its our favorite option! For this specific case, we use the purpose built \u00a0called Kafkabeat which is written by our very own This Beatgathers offset and other topic\u00a0information and stores it in\u00a0Elasticsearch. You can then analyze consumer lag using Kibana. Coupled with that captures system level stats like disk throughput, CPU and memory, we have a powerful solution to monitor Kafka. So now you have all the data in one place\u00a0to\u00a0convince your boss to replace those old crufty spinning disks with brand new SSDs! Oh, and in 5.0.0, it gets even better. All this critical information -- application and system level monitoring -- gets rolled into one Beat,\u00a0called .\u00a0Savvy?\u00a0 Ok, back to Kafkabeat for now. Here's how you get\u00a0started with it: This will collect offset information from all Kafka topics for this broker and index into Elasticsearch with the following document structure\"@timestamp\": \"2016-06-22T01:00:43.033Z\", \"beat\": { \"hostname\": \"Suyogs-MBP-2\", \"name\": \"Suyogs-MBP-2\" }, \"type\": \"consumer\", \"partition\": 0, \"topic\": \"apache_logs_test\", \"group\": \"logstash\", \"offset\": 3245 \"lag\": 60235 } Once the data is in Elasticsearch, it is straightforward to visualize it with Kibana.\u00a0I've used the hot-off-the-press\u00a0\u00a0to create a dashboard to\u00a0graph\u00a0consumer field over timestamp. Kafka Manager This isan open source to manage Kafka\u00a0in its entirety. You can create topics, track metrics, manage offsets and more. Be aware that this tool takes a while to compile and build, but if you need an end-to-end management solution for Kafka\u00a0you can give this a try! Once you start the Kafka Manager tool, follow instructions to create a new cluster to monitor\u00a0by pointing it to your ZK instance.\u00a0 In this post, we provided tips to operationalize Kafka and Logstash so you can ingest data from multiple sources into Elasticsearch. There's more to come! Last year, Kafka released version, and recently which is packed with new features like inbuilt security, new consumer implementation, data quotas and more. We've updated Logstash input and output so you can use these features with Logstash! In the next post, we'll cover the new features in Kafka, and in particular, end-to-end security using Kafka and the Elastic Stack. 'till next time! \n"}
{"index": {"_id": 590}}
{"title":"Finding a Scalable Data Model for Search @ bol.com","seo_title":"","url":"\/blog\/finding-a-scalable-data-model-for-search-at-bol-com","author":{"name":"Maarten Roosendaal"},"date":"June 22, 2016","category":"User Stories","locales":"","content":" started in 1999 and has grown from an online bookstore to an online superstore with a wide variety of products, including books, segways, shoes, saunas, swimming pools, and much more. Since 2010, Bol.com has also opted to become a platform for other sellers to (re)sell their products and\/or sell the same products bol.com offers but with different conditions. Right now we have over 11 million products available, 6.2 million active customers, and about 230,000 active sellers a month. What's the problem? Like any e-commerce site, we want to help our customers find what they are looking for and part of that comes in the form of a search engine. Currently we use Endeca for site search and we have a 'flat' document model for products, which means that we join data relevant for search for each product in one flat document and for each product we select the offer (which contains information like price, availability, seller) from a set of offers we think is most relevant based on some rules. This means and are part of the product document and we can only use one offer: Functionally this limits the customers. Let's say I have a product with an offer from bol.com for 20 Euros and an offer from Seller A for 18 Euros and our offer selection says bol.com has the . The price-facet is based on the 'best buy' price so if a customer selects a price between 15-19 Euros the product will disappear because it does not apply to the filter. This is bad for our customers because there actually is a relevant offer, and it\u2019s also bad for sellers because their offer isn't shown. We want the customer to be in more control. One of the major things we need to solve is that we need a scalable way to model all offers for each product. Other challenges We've been working with and the Elastic Stack for a while and recently also for an application for our professional sellers. Elasticsearch seems to be very scalable and flexible so we wanted to see if Elasticsearch could solve our modelling challenge and whether it comes close to the performance we get out of our current search engine. To give an indication, we had about 2,400 requests a second on our search engine during the holiday season, and expect a lot more this year. Another crucial challenge is the number of updates due to the amount of products, offers, and sellers \u2014 about 500K offer updates (price or availability changes) and 200K content updates a day (and mostly during office hours). Sometimes we have peaks of 1.5 million product updates and 20 million offer updates a day. On average this will increase in the coming years because we are growing, with more products, more sellers, more offers, and more updates and inserts. So choosing the model is not just about IF we can model product offers correctly, it's also thinking about how we can set up Elasticsearch in such a way that it can handle all those updates in near real-time while processing the number of requests. For this article we'll stick mostly to modelling and performance from a request perspective. Challenge recap So to recap our challenges: I'll get back to 'complex query requirements' in a moment but in general we have come up with a principle which states 'although we value performance at index time, we value performance at query time more'. We used this principle in the decision process. Elasticsearch and data modelling Elasticsearch has a few modelling options for our case: Approach Option 3\u00a0is the situation we have now so we skipped that one, option 2\u00a0was also quickly discarded because you lose the relation between the data of an offer if you have more than one offer. That left us with three models (1, 4\u00a0and 5). But how can you test which one is best? We first started by actually creating representative indices for all these options to test against. We used a Node.js script for creating random data: Product Offer We also want to test with different index sizes so we flushed the test data out to disk in three flavors - each flavor keeping its own bulk size of 100K - 1M, 10M and 100M products. We ended up with nine indices to test with, for each model we had three flavors. Now that we've got the indices, let's talk about the queries. Complex query requirements For our test we came up with four use cases that we want to test, each one with increasing complexity but still a representative query that customers perform each day. Below is an overview of the first three use cases. Use case A is a regular query where we need to display the cheapest offer and aggregate of some offer attributes. For use case B we \u2018selected\u2019 the deliverycode with value \u20180\u2019 which means that we need to filter use case A and select the correct cheapest offer and aggregate on the correct offers. Use case C is ordering the selection on cheapest offer first. Here we need to display the cheapest offer and again aggregate on the correct offers. Use Cases: Use case D is special case and can best be explained with the following example What you see here is the \u2018rollup\u2019 functionality, which means that we want to display closely related products (we call them product families, products are the same except on 1 or 2 attributes) as 1 result. Here you can see the Apple iPad, all black but with different GB sizes. This results in the following requirements for the fourth use case: The complexity here is doing the aggregation on the set of products within the family\/rollup and selecting the best offer to display. Now we\u2019ve defined our use cases, let\u2019s start testing. Testing Again we used a Node.js script to query and good old Excel to generate some graphs. The Node.js script used an array of terms, they have an overlap with the test data but a percentage results in 0 results, just like on our website. You could also specify how many queries to execute (we used 1,000 and 10,000) and it wrote out the response times to file. During the first run the response times were terrible, what was wrong? Well, rookie mistake, we only provided Elasticsearch with 1 GB of HEAP_SPACE, so after we set that to 32 GB (yes I know, more than 30 is an overkill but for testing it was fine) thinks were looking much better. So after setting that straight the result of our tests can be seen in the graphs below, the left side is average time in ms for all requests during the run, on the bottom the 4 different use cases. Some remarks about the graphs and outcome: The downside of nested documents is the update behaviour, if only one offer changed for a doc with five offers, the whole document needs to be reindexed. But remember our principle? It's not a big issue if the data is behind for, let's say, 15-20 minutes. Not to say it's not a challenge... Conclusions Based on the outcome of the test we draw the following conclusions: Based on the outcome, we decided to move forward and we are now in the process of building part of the search and browse of our webshop on Elasticsearch. is an IT Architect at bol.com and his main focus is on scalable search and SEO solutions. He has a background in Java\/J2EE and previously worked for Sogyo and Capgemini. When not spending time with family or working, you can find him either in the gym, watching NBA\/NCAA basketball, or at a movie theater. \n"}
{"index": {"_id": 591}}
{"title":"Jobrapido: Powering the Search for Employment","seo_title":"","url":"\/blog\/jobrapido-powering-the-search-for-employment","author":{"name":"Antonio Bonuccelli"},"date":"June 21, 2016","category":"User Stories","locales":"","content":" Searching for a job in general can quickly become a full-time job, we all know.... Allowing others to find their dream vacancy in 58 different countries with a state-of-the-art search solution that scales and is able to understand up to 18 different languages is a different matter, and the team at Jobrapido knows it very well. 58 countries. 20 million monthly job listings. 60 million registered users.Headquartered in Milan, Jobrapido allows millions of people to quickly find relevant results when searching for a job. Elasticsearch is powering its searches \u2014 providing great search throughputs and delivering contextualised relevant results in the blink of an eye. Since the end of 2014, Jobrapido has migrated its global infrastructure to rely on Elasticsearch to handle 20,000+ requests per second for its 60 million globally distributed registered\u00a0users. They make use of a wide range of features, including custom language analyzers, stopwords, and stemming for all the major languages, as well as percolations and aggregations to improve search results \u2014 helping users find jobs that are tailored to their history and preferences, and providing a seamless search experience overall. \"They're one of those customers that have a strong interest and passion for the product. I'm lucky to have them.\"Supporting Jobrapido and its awesome search team, led by Salvatore Vadacca, is one of my tasks and surely it's always been a pleasant one. Their use case is one of the most feature rich and advanced for free text search that I have had the chance to directly support. I am impressed and inspired by the passion and dedication of the Jobrapido search team, always striving for perfection and actively exploring new ways to make your life better when you're on a quest for a job. At Elastic{ON}, Salvatore and I got a chance to talk about what it's been like working together for the past year and a half. We recorded it in this video: There's still quite some time ahead, but I can already say that I look forward to seeing Salvatore and company again next year at Elastic{ON}, our epic yearly user conference in San Francisco\u00a0( to receive Elastic{ON} updates!). That's where we had the chance to meet, know each other better and also have beers and play some table football. : -) \n"}
{"index": {"_id": 592}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-06-20","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-06-20","author":{"name":"Michael McCandless"},"date":"June 20, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top News Sat on this draft for a week, and well, it's Friday. Yolo. ElasticSearch at petabyte scale on AWS: \u2014 Jamie Alquiza (@jamiealquiza) Elasticsearch Core Apache Lucene Watch This Space , where we'll share more news on the whole Elastic ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 593}}
{"title":"Where are my documents?
Refreshing news...","seo_title":"","url":"\/blog\/refreshing_news","author":{"name":"Nik Everett"},"date":"June 17, 2016","category":"Engineering","locales":"","content":" When you send Elasticsearch a request that modifies or creates documents and it replies with or it has synced the changes to disk on all active shards . That means that the changes will survive catastrophic system shutdown but it doesn't mean that the changes are available for search. The process that makes changes available for search is called a \"refresh\" and it is the topic of this post. Refreshes are performed periodically ( ), when the is full, and on demand (). On demand refreshing is rarely used outside of testing because it creates small index segments which are inefficient to create and search and must later be merged into larger segments. Waiting for the indexing buffer to be full is unpredictable so we can't rely on it either. That means that we mostly think of the index as being refreshed every , which defaults to 1 second. The problem Refreshing every second is fine if you are indexing something like logs where you expect to be some amount of time behind real time, but if you are indexing blog posts or comments or calendars then it can be a bit difficult. For anything where a user might expect to make a change and immediately be able to search for that change (blog, forum, scheduling app) your application needs some way to that the change is visible for search. This is doubly true for applications that want to use search for something interesting after the user's change (think scheduling or aggregations). In those cases you have a few options all of which have interesting tradeoffs: Wait for the refresh You could just wait for the refresh interval to pass. This has the advantage of being something you can do totally asynchronously. The disadvantage is that you have to wait for the whole one second and even then it is not guaranteed. Refresh isn't instant. Usually it is pretty quick but some refreshes will be slower than others so you can't really predict it. For applications where you can tolerate not knowing for sure if something is available for search then this is totally the right choice. But this blog post really isn't about those applications. So, for the sake of this blog post, we're going to assume this option isn't good enough for you. Force a refresh with You could force an immediate refresh. This has the advantage of being pretty quick. Like I said a few paragraphs up, it has the disadvantage of creating small segments that are inefficient to create, search, and merge. For plenty of use cases this inefficiency is worth the speed. Don't be afraid to force a refresh if it makes sense for your use case. For example, say you are loading something into Elasticsearch and plan to analyze the results. This search index is just for you so you know when you are done loading documents. At that point you shouldn't hesitate to refresh the index. Waiting isn't going to help. I should mention that adding to an index, update, delete, or bulk request is subtly different than performing a API call. Refresh API calls will refresh all the shards on the index. will only refresh the shards that have been modified. So for index, update, and delete requests that is just the shard to which the document was routed. For bulk requests that is all shards to which any document was routed. might also be a bad choice because it affects other indexing in the same index. Say you have a bulk loading process that works quite well. But now you want to start inserting a few documents into the same index interactively. If you do it with then, suddenly, you've started refreshing documents outside of whatever refresh interval you were using for the bulk load. If you do that frequently enough that'll change the search and index performance of the bulk loading process. Wait for the refresh with \u00a0 Elasticsearch 5.0 brings a hybrid approach between the two options. Adding to index, update, delete, or bulk request will cause the request to wait until its changes have been made visible for search before returning to the user. This has the advantage of being correct without creating inefficient segments. It has the disadvantage of having to wait for the refresh. You don't have to wait for as long as the \"wait for the refresh\" option because Elasticsearch signals you as soon as the document is ready for search. So if the change comes half way through the refresh interval you only have to wait for half of the time. Unlike , won't affect concurrent indexing on the same index. It has no effect on segment size because it doesn't force a refresh immediately. If you must know when the refresh happens, you can wait for the refresh, and you plan to upgrade to 5.0\u00a0 , then this is the right choice! Even if you are super excited to upgrade to 5.0-alpha4 to get this feature keep in mind that Elasticsearch's alphas and betas are for testing purposes only because they aren't compatible with the GA release. We are still finalizing the wire level communications and on disk layout so 5.0' alphas and betas aren't guaranteed to upgrade to properly to 5.0.0, either with rolling restarts or a full cluster restart. Please test this feature to see if it fits for you but don't upgrade production clusters to alphas or betas. Back to the feature, there is a limit to the number of API calls that can be waiting on any one shard: which defaults to . If a request with comes in while all the slots are full then Elasticsearch will refresh the shard and reply to the request immediately. What does do if you set the to , disabling periodic refreshes, you may ask? Well the answer is that will honor whatever refresh interval you configure. The request will only return when you fill the indexing buffer, force an explicit refresh, or try to wait on more than requests in the same shard. is just about the maximum number of time that will have to wait for the changes to become visible. If you use , raising the refresh interval will make indexing feel slower and slower to your users. And lowering it will make indexing feel faster and faster. So it might be tempting to lower the refresh interval. Doing so will make less and less efficient segments. Making the refresh interval the same as the write rate is as inefficient as using on every request. Pick the refresh strategy that makes sense for you Ultimately there is no silver bullet for refreshes. Elasticsearch's is a useful because it coalesces several changes into one big change to the search index, making a more efficient index. You either wait for the refresh interval, potentially slowing down your users, or you force an immediate refresh and pay the price at search and merge time. gives you a tool to make waiting for the refresh interval interactive so you can make whatever tradeoffs make sense for you. \n"}
{"index": {"_id": 594}}
{"title":"Logstash 2.3.3 Released","seo_title":"","url":"\/blog\/logstash-2-3-3-released","author":{"name":"Suyog Rao"},"date":"June 17, 2016","category":"Releases","locales":"","content":" Bugs Fixed \n"}
{"index": {"_id": 595}}
{"title":"Brewing in Beats: Logstashbeat, Nginxupstreambeat, Lambdabeat","seo_title":"","url":"\/blog\/weekly-beats-logstashbeat-nginxupstreambeat-lambdabeat","author":{"name":"Tudor Golubenco"},"date":"June 15, 2016","category":"Brewing in Beats","locales":"","content":" Welcome to Weekly Beats! With this series, we're keeping you up to date with all that's new in\u00a0, from the details of work in progress pull requests to releases and learning resources. New Community Beat: Logstashbeat Logstash now has a monitoring API, so it can be monitored with Beats :-). has created a new community Beat called that gathers stats (events, jvm and process) from a running Logstash instance and ship them to Elasticsearch. New Community Beat: Nginxupstreambeat Nginxustreambeat is a Beat used for Nginx upstream server status monitoring. The Nginx , by the same , \u00a0reads the statistics periodically and indexes them in Elasticsearch. This is very useful when using Nginx as a reverse proxy to load-balance among multiple upstream servers. New Community Beat: Lambdabeat , one of our Elastic colleagues, created\u00a0\u00a0to collect various\u00a0AWS Lambda metrics and index them in\u00a0Elasticsearch. Lambdabeat fetches data from the\u00a0Cloudwatch API, so you don't need to\u00a0deploy it\u00a0anywhere in particular, but it does require valid AWS credentials. New Generators, now in the main Beats repository The Beat generator proved to be extremely useful in quickly bootstrapping new Beats and keeping them up-to-date with our changes. As we\u2019re adding different types of generators, like the one that generates a , or one for generating a Beat that , we figured it makes more sense to in a single place. This place is inside the main Filebeat: symlinks are no longer followed Following symlinks to log files in Filebeat was asking for trouble, for example it could happen that the same file was read twice. We will be with the next alpha release. Symlinks are now completely ignored from now on. Fixed backoff logic in outputs Coming from a community contributor, this fixes a bug in the backoff retry code in libbeat. Metricbeat: automatically document events Every Metricbeat module so far comes with Dockerized tests to verify it against a real instance of the monitored system. We now take and automatically generate samples of the events by running the integration tests. MongoDB Metricbeat module A for Metricbeat is currently in progress. \n"}
{"index": {"_id": 596}}
{"title":"Apache ZooKeeper Backup, a Treatise","seo_title":"","url":"\/blog\/zookeeper-backup-a-treatise","author":{"name":"Jordan Zimmerman"},"date":"June 15, 2016","category":"Engineering","locales":"","content":" Introduction is an open source distributed coordination service originally developed at Yahoo and now at Apache. It is the core coordination service that we use here at . Critical data is stored in ZooKeeper and having a reliable backup system for it is vital. However, backing up and restoring a ZooKeeper cluster can be very tricky to do correctly. Data types A ZooKeeper database contains two broad categories of data: persistent and ephemeral. Persistent data is generally the same type of data stored in traditional datastores (RDBMSes, etc.). It is data that is accessed via traditional CRUD activity. Ephemeral data, however, is unique to ZooKeeper and is usually associated with state machine semantics. The presence of the ephemeral data implies a specific state. Consistency ZooKeeper in production is deployed on multiple processes (typically 3 or 5) each of which maintains its own database. ZooKeeper\u2019s consistency guarantee is that processes will receive writes. The important implication of this is that, at any given point in time, it must be assumed that one or more of the individual ZooKeeper databases are in a different consistent state than the others. Data Implications Regardless of whether the data is persistent or ephemeral, data stored in ZooKeeper can be: Note: this is different than traditional datastores where data is nearly always source of truth. Sessions ZooKeeper clients maintain a session with the server. The server implements this session as a special type of transaction that is stored in its database. Ephemeral nodes are tied to sessions and expire when sessions expire. ZooKeeper sessions are durable and fault tolerant. They are managed by the internal ZooKeeper leader instance. Distributed State Machine The transient and stateful data in ZooKeeper extends to data structures held in client processes to form a distributed state machine composed of ZooKeeper servers, client applications, etc. For example, five clients might be involved in a leader election meaning they all have created ephemeral nodes in ZooKeeper and the leader is executing some action. Thus, there are ephemeral nodes in ZooKeeper and objects in client memory that form a single state machine. Backup\/Restore Implications With source of truth datastores backups usually are done by periodic copying of a transaction log or some similar type of on-disk representation of the data. These datastores have built-in mechanisms to help\/support backup and restore. In the best cases, restores can be achieved with no transaction losses. In the worst cases, only the most recent transactions are lost. ZooKeeper creates a new class of backup\/restore issues due to its use for transient and stateful data. Further, it has no built in support for backup and restore. As stated above, at any point in time transient or stateful data combine with client data structures to create a distributed state machine. Thus, . Back In Time An improperly restored ZooKeeper . Imagine the following scenario: This is just one example. Copious other scenarios can be contemplated. Recommendations Backup of ZooKeeper by copying its transaction and snapshot logs is a reasonable method. It must be understood that data loss will occur for writes that happened past the time of last log copy. These logs should be restored without filtering. All ephemeral node transactions should appear to be deleted nodes from the logs before the ensemble is restored. This can be accomplished by removing all session transactions from the logs. Dealing with transient persistent nodes is more difficult as it\u2019s not possible to automatically identify these nodes. They could be identified by known path prefixes or some other method. Or, hopefully, there are no cases and this can be ignored. Filtering of ZooKeeper\u2019s transaction log is very easily done. There are existing classes in the ZooKeeper library that can be used for this (e.g. ). Alternatively, if possible, all clients should be closed prior to restoring an ensemble from a backup. This would have a similar effect of ending all sessions and implying deletion of all ephemeral nodes. \n"}
{"index": {"_id": 597}}
{"title":"Behind the Elastic Stack: Working with eBay","seo_title":"Behind the Elastic Stack: Working with eBay","url":"\/blog\/behind-the-elastic-stack-working-with-ebay","author":{"name":"Joshua Rich"},"date":"June 14, 2016","category":"User Stories","locales":"","content":" \"I know that platform.\u00a0They're my customer. That's the way we work at Elastic.\"At Elastic, we like to build a relationship with our customers. We are assigned to a support contact as opposed to being in a rotation, so we often feel like an extension of the customer's team. We build relationships in that team just like at any workplace and the information exchange flows both ways. One of the first customers I started working with when I joined Elastic is eBay. I've built up a knowledge of their project and use\u00a0case just as Sudeep and the eBay team's knowledge of the Elastic Stack has increased. We're definitely past the general questions and issues \u2014 now we can focus on solving the fun problems! I have been involved with Sudeep and his team since they first became a support customer. However, although we've exchanged a ton of support tickets and many conference calls, it wasn't until our in February, some six months after I started working with Sudeep, that we were finally able to meet face-to-face. That was great to finally see each other, sit down, and just chat \u2013 talk shop and joke around a little. We also spent some time in front of the camera sharing what it's been like working together: The best part about working with eBay is working at scale. They have a huge amount of data and a massive range of projects using the Elastic Stack. It's a deployment of a size that not many people get to work with. It's great to be able to contribute to their success. At the end of the day, it's\u00a0really cool to think that I may have helped, even if\u00a0just in\u00a0a small way, to support something that millions of people all around the world are using. \"It feels less like working with colleagues and more like collaborating with friends on a project.\" Working at Elastic has been a fantastic experience. Everyone across the board is so committed to everything we do and supporting the wider community around our products. It feels much less like working with colleagues to meet some business goals and much more like just a bunch of friends coordinating together on a fun project. The depth and width of knowledge within the company is amazing, and it's an environment in which you can both constantly learn and definitely contribute back. Support is probably one of the most distributed teams within the company, so it's really important to us all that we have a sense of togetherness and team spirit. I think that is definitely the case and shines through strongly on those rare occasions where we are all standing in the same room. It's really great to be part of a passionate and fun team and it's always exciting to interact with our customers who continually surprise and inspire us with their use cases around . \n"}
{"index": {"_id": 598}}
{"title":"Uncoiling the Data in DNA: Elasticsearch as a BioInformatics Research Tool","seo_title":"Uncoiling the Data in DNA: Elasticsearch as a BioInformatics Research Tool","url":"\/blog\/uncoiling-data-in-dna-elasticsearch-as-a-bioinformatics-research-tool","author":{"name":"MyGene.info Development Team"},"date":"June 09, 2016","category":"User Stories","locales":"","content":" Awash in a sea of gene and variant informationThe availability of genetic and genomic information has exploded in the last decade following decreasing costs in sequencing technology: however, much of this information exists scattered over many different resources. For example, different resources on the same gene often have different identifiers, formats, and information. The fragmented data landscape makes creating and maintaining bioinformatics pipelines challenging, frustrating, and time consuming.As part of (Associate Professor) computational biology research group at the , our team is interested in solving big data challenges like the aforementioned fragmented gene\/variant data landscape.\u00a0 (Associate Professor) spearheaded the endeavor to create easy-to-use gene and genetic variant annotation services so that researchers can spend more time making new discoveries and less time on dealing with the fragmented data landscape. By using our free* service, users can obtain up-to-date gene and variant information in a consistent format (JSON), from any of the two endpoints used for each service.Building the solution with ElasticsearchMyGene.info was the first of the two annotation services we built. In building our services, we knew there were several issues we needed to consider:Given these constraints, we employed Elasticsearch in our Indexing Engine. Our previous experience with CouchDB for a different resource, enabled us to smoothly transition into using Elasticsearch and we were\u00a0early adopters of Elasticsearch (circa v0.5.x). Even at the earlier stages of development, Elasticsearch has been a valuable tool in our arsenal, and we had no doubt it would be able to suit our needs.Applying our success in building MyGene.info into a highly scalable service, we followed by building MyVariant.info to address the even more fragmented data landscape of genetic variant information. MyVariant.info currently has more than 334 million unique gene variants from over 14 databases.By using Elasticsearch in our services, users would be able to search for one or thousands of gene or variant-specific JSON object(s) using flexible query terms and return just the information of interest to them. If they were only interested in variant annotations from dbSNP or gene annotations from worms, they would be able to specify those filters in their search. Most importantly, users could get their results quickly. According to our recent paper released in , MyGene.info can handle traffic from >5000 concurrent users for approximately 10,000 requests per minute: and over 95 % of actual user requests take less than 30 ms to process. MyGene.info receives requests from over 4000 unique IP addresses on a monthly basis, while MyVariant.info caters to roughly 1,500 unique IP\u2019s each month.Tracking our success with KibanaWe already had , a well-used, user-friendly resource, which originally utilized CouchDB (v1). As we migrated the service over to utilize MyGene.info, we wanted a way to distinguish the MyGene.info traffic coming from BioGPS.org from our various clients (python, R, etc). We utilized Kibana to help visualize the different sources and volumes of traffic for MyGene.info and MyVariant.info. Both MyGene.info and MyVariant.info consist of two endpoints each, and Kibana was an easy way for us to inspect the usage of our service endpoints.Scaling towards other BioThingsMyGene.info currently has 10 shards spread across two web nodes, three master nodes, and three data nodes. Scaling up from 13 million genes to cover 334 million variants, MyVariant.info is made up of 20 shards spread across three web nodes, three master nodes, and five data nodes. We use load balancers to handle the queries coming into our web nodes to ensure fast and stable processing. Given the lessons learned on scaling when we developed MyVariant.info following MyGene.info, we expect to be able to readily extend coverage to other research areas with excess data fragmentation. Gene annotation and Variant annotation data are only two examples of \u201cBioThings\u201d with fragmented data sources, and we hope to expand our service to be of greater use to the research community.For more details about the MyGene.info and MyVariant.info services, please see the research paper published in . \n"}
{"index": {"_id": 599}}
{"title":"Elastic <3 for the Adopt-a-Character Program and the Unicode Consortium :-)","seo_title":"Elasticsearch Loves the Unicode Adopt-a-Character Program","url":"\/blog\/elastic-love-for-the-adopt-a-character-program-and-the-unicode-consortium","author":{"name":"Robert Muir"},"date":"June 07, 2016","category":"Culture","locales":"","content":" The is a non-profit corporation founded in 1991. Its goals include standardizing and supporting the languages of the world and allowing people to use any language on their computers and smartphones. This work is essential for the software we build at Elastic. Unicode does more than just list out all the characters. They describe how to parse text, how to sort in different languages, and so much more to support all human languages. The Unicode Consortium's raises money to support a variety of important missions. Conserving the world's living languages is a huge task, and includes working with language experts, technologists, and cultural leaders, all in order to support minority languages on computers. According to Unicode, close to 98 percent of our world's living languages are digitally disadvantaged. This means that operating systems, web browsers and mobile applications don't support them. So the Adopt-a-Character donations help Unicode \u2014 a neutral organization\u00a0interested in language conservation and technological standardization \u2014 to drive the work to correct this. They plan to focus use of the funds on adding characters for both modern and historic disadvantaged languages, and to support internationalization for those languages ( and ). When Elastic Founder and CTO found out about the adoption program, he had a cool idea: why not allow every engineer at Elastic (as well as other teammates within the company) to choose and adopt a character? Besides supporting a good cause, it tells us a bit about every engineer on our team! Here's what we chose: td {vertical-align:top: }figcaption {font-size:10px: text-align:left: line-height:130%: } Soon to be added: The Elastic \u00a0Team will be\u00a0adopting the owl\u00a0(U+1F989) from Unicode 9.0\u00a0at\u00a0bronze level.\u00a0As seen in the , the owl is one of a set of\u00a0brand-new emojis coming soon to a screen near you!\u00a0The Unicode Consortium is\u00a0close to allowing adoption of Unicode 9.0 characters with their website update in the coming weeks. Check back and you can\u00a0be first to adopt one of the awesome new emojis! In case you're wondering, adopting wasn't required and all adoption fees were eligible for reimbursement by Elastic. And here's an example of the cool certificates that a Bronze-level sponsor may choose to receive: Elastic commends the Unicode Consortium for all the work it is doing, and we encourage everyone reading this to visit the site and its , and make a donation to sponsor your favorite character today! \n"}
{"index": {"_id": 600}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-06-06","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-06-06","author":{"name":"Michael McCandless"},"date":"June 06, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsSupporting customers is encoded into our DNA. explains how \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole Elastic ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 601}}
{"title":"Setting Up Elasticsearch for a Blog","seo_title":"Setting Up Elasticsearch for a Blog","url":"\/blog\/setting-up-elasticsearch-for-a-blog","author":{"name":"Nicol\u00e1s Bevacqua"},"date":"June 06, 2016","category":"Engineering","locales":"","content":" I've been experimenting with \u00a0\u2014\u00a0and working at the company behind it for a while\u00a0\u2014\u00a0so it only made sense to incorporate it as 's search provider. This article describes in detail the steps I took in setting up Elasticsearch as the search provider for Pony Foo. I start by explaining what Elasticsearch is, how you can set it up to make useful searches through the Node.js API client, and how to deploy the solution onto a Debian or Ubuntu environment. A while back I started working at Elastic\u00a0\u2014\u00a0the , a search engine & realtime analytics service powered by Lucene indexes. It's an and I'm super happy here\u00a0\u2014\u00a0 \ud83d\ude09 \ud83c\udf89 Thrilled to announce I've started working at !\u26f9 Working on Kibana (ES graphs)\ud83d\udc4c Great fun\/team! Hiring!\ud83c\udfa2 \u2014 Nicol\u00e1s Bevacqua () Possible use cases for Elasticsearch range from indexing , analyzing in real-time, , all the way to and back to providing search for a lowly blog like Pony Foo. We also build , a dashboard that sits in front of Elasticsearch and lets you perform and graph the most complex queries you can possibly imagine. Many use Kibana across those cool service status flat screens in hip offices across San Francisco. But enough about me and the cool things you can do with Elastic's products. Let's start by talking about Elasticsearch in more meaningful, technical terms. What is Elasticsearch, even? \ud83d\udd0e is a REST HTTP service that wraps around , a Java-based indexing and search technology that also features spellchecking, hit highlighting and advanced analysis\/tokenization capabilities. On top of what Lucene already provides, Elasticsearch adds an HTTP interface, meaning you don't need to build your application using Java anymore: and is distributed by default, meaning you won't have any trouble scaling your operations to thousands of queries per second. Elasticsearch is great for setting up blog search because you could basically dump all your content into an index and have them deal with user's queries, with very little effort or configuration. Here's how I did it. Initial SetupI'm on a Mac, so \u2014 \u2014 I just installed using . brew install elasticsearch If you're not on a Mac, just go to the download page and , unzip it, run it in a shell, and you're good to go. Once you have the executable, you can run it on your terminal. Make sure to leave the process running while you're working with it. elasticsearch Querying the index is a matter of using , which is a great diagnostics tool to have a handle on: a web browser, by querying ( ): the , which provides a simple interface into the Elasticsearch REST service, or the , which is similar to Sense. There are client libraries that consume the HTTP REST API available to several different languages. In our case, we'll use the Node.js client: . npm install --save elasticsearch The API client is quite pleasant to work with, they provide both Promise-based and callback-based API through the same methods. First off, we'll create a client. This will be used to talk to the REST service for our Elasticsearch instance. Creating an Elasticsearch IndexWe'll start by importing the package and instantiating a REST client configured to print all logging statements. import elasticsearch from 'elasticsearch': const client = new elasticsearch.Client({ host: 'http:\/\/localhost:9200', log: 'debug' }): Now that we have a we can start interacting with our Elasticsearch instance. We'll need an index where we can store our data. You can think of as the rough equivalent of a database instance. A huge difference, though, is that at once\u00a0\u2014\u00a0 I'll create an index named . Since returns a , we can on it for our code to stay easy to follow. If you need to brush up on \/ you may want to read \"\" and the as well. await client.indices.create({ index: 'ponyfoo' }): That's all the setup that is . Creating an Elasticsearch Mappingin addition to creating an index, you can create . Type mappings aid Elasticsearch's querying capabilities for your documents\u00a0\u2014\u00a0avoiding issues when you are storing dates using their timestamps, . If you don't create an explicit mapping for a type, Elasticsearch will and create a dynamic mapping. A timestamp is often represented in JSON as a , but Elasticsearch will be unable to detect the field as a date field, preventing date filters and facets such as the histogram facet from working properly. \u2014\u00a0 Let's create a mapping for the type , which is the document type we'll use when storing blog articles in our Elasticsearch index. Note how even though the property will be stored as an array, Elasticsearch takes care of that internally and we only need to specify that each tag is of type string. The property will be a , as hinted by the mapping, and everything else is stored as strings. await client.indices.putMapping({ index: 'ponyfoo', type: 'article', body: { properties: { created: { type: 'date' }, title: { type: 'string' }, slug: { type: 'string' }, teaser: { type: 'string' }, introduction: { type: 'string' }, body: { type: 'string' }, tags: { type: 'string' } } } }): The remainder of our initial setup involves two steps\u00a0\u2014\u00a0both of them involving keeping the Elasticsearch index up to date, so that querying it yields meaningful results. Keeping Elasticsearch Up-to-DateThese steps vary slightly depending on the storage engine you're using for blog articles. For Pony Foo, I'm using MongoDB and the driver. The following piece of code will trigger a post-save hook whenever an article is saved\u00a0 mongoose.model('Article').schema.post('save', updateIndex): The method is largely independent of the storage engine: our goal is to update the Elasticsearch index with the updated document. We'll be using the method for an article of equal to the we had in our MongoDB database, although that's entirely up to you\u00a0\u2014\u00a0I chose to reuse the MongoDB, as I found it most convenient. The provided should match the type mapping we created earlier, and as you can see I'm just forwarding part of my MongoDB document to the Elasticsearch index. Given that we are using the flag, a new document will be inserted if no document with the provided exists, and otherwise the existing id document will be modified with the updated fields, again in a single HTTP request to the index. I could have done , but I prefer where I explicitly name the fields that I want to copy over to the Elasticsearch index, which explains the function. const id = article._id.toString(): await client.update({ index: 'ponyfoo', type: 'article', id, body: { doc: toIndex(article), doc_as_upsert: true } }): function toIndex (article) { return { created: article.created, title: article.title, slug: article.slug, teaser: article.teaser, introduction: article.introduction, body: article.body, tags: article.tags }: } Whenever an article gets updated in our MongoDB database, the changes will be mirrored onto Elasticsearch. That's great for new articles or changes to existing articles, but what about articles that existed before I started using Elasticsearch? Those wouldn't be in the index unless I changed each of them and the post-save hook picks up the changes and forwards them to Elasticsearch. Wonders of the Bulk API, or Bootstrapping an Elasticsearch IndexTo bring your Elasticsearch index up to date with your blog articles, you will want to use the , which allows you to perform several operations against the Elasticsearch index in one fell swoop. The bulk API consumes operations from an array under the format. The question marks note that the data component of operations is optional. Such is the case of commands, which don't require any additional data beyond an object . Provided an array of pulled from MongoDB or elsewhere, the following piece of code reduces into command\/data pairs on a single array, and submits all of that to Elasticsearch as a single HTTP request through its bulk API. await client.bulk({ body: articles.reduce(toBulk, []) }): function toBulk (body, article) { body.push({ update: { _index: 'ponyfoo', _type: 'article', _id: article._id.toString() } }): body.push({ doc: toIndex(article), doc_as_upsert: true }): \/\/ toIndex from previous code block return body: } If JavaScript had we could do away with and , but we're not quite there yet. await client.bulk({ body: articles.flatMap(article => [{ update: { _index: 'ponyfoo', _type: 'article', _id: article._id.toString() } }, { doc: toIndex(article), doc_as_upsert: true }]) }): Great stuff! \ud83c\udf89 We're still missing the awesome parts \u2728, though! Querying the Elasticsearch IndexWhile utilizing the results of querying the Elasticsearch index is out of the scope of this article, you probably still want to know how to write a function that can query the engine you so carefully set up with your blog's amazing contents. A simple function looks like below. It returns a and it uses \/ . The resulting search hits are mapped through a function that only exposes the fields we want. Again, we take a whitelisting approach as favored earlier when we inserted documents into the index. Elasticsearch offers you can leverage to build complex queries. For now, we'll only use the to find articles whose match the provided . async function query (options) { const result = await client.search({ index: 'ponyfoo', type: 'article', body: { query: { match: { title: options.input } } } }): return result.hits.hits.map(searchHitToResult): } The function receives the raw search hits from the REST Elasticsearch API and maps them to simple objects that contain only the , , and fields. In addition, we'll include the field, Elasticsearch's way of telling us how confident we should be that the search hit reliably matches the human's query. Typically more than enough for dealing with search results. function searchHitToResult (hit) { return { _score: hit._score, _id: hit._id, title: hit._source.title, slug: hit._source.slug }: } You could always query the MongoDB database for to pull in more data, such as the contents of an article. Even in the case of a simple blog, you wouldn't consider a search solution sufficient if users could only find articles by matching their titles. You'd want to be able to filter by tags, and even though the article titles should be valued higher than their contents (), you'd still want users to be able to search articles by querying their contents directly. You probably also want to be able to specify date ranges, and then expect to see results only within the provided date range. What's more, you'd expect to be able to fit all of this in a single querying function. Building Complex Elasticsearch QueriesAs it turns out, we don't have to drastically modify our function to this end. Thanks to the rich querying DSL, our problem becomes finding out which types of queries we need to use, and figuring out how to stack the different parts of our query. To begin, we'll add the ability to query several fields, and not just the . To do that, we'll use the , adding , , to the title we were already querying about. async function query (options) { const result = await client.search({ index: 'ponyfoo', type: 'article', body: { query: { multi_match: { query: options.input, fields: ['title', 'teaser', 'introduction', 'content'] } } } }): return result.hits.hits.map(searchHitToResult): } Earlier, I brought up the fact that I want to rate the field higher. In the context of search, this is usually referred to as giving a term more \"weight\". To do this through the Elasticsearch DSL, we can use the field modifier to boost the field three times. { query: { multi_match: { query: options.input, fields: ['title^3', 'teaser', 'introduction', 'content'] } } } If we have additional filters to constrain a query, I've found that the most effective way to express that is using a , moving the options into a function and placing our existing query under a clause, within our query. Bool queries are a powerful querying DSL that allow for a recursive yet declarative and simple interface to defining complex queries. { query: { bool: { filter: filters(options), must: { multi_match: { query: options.input, fields: ['title^3', 'teaser', 'introduction', 'content'] } } } } } In the simplest case, the applied does nothing at all, leaving the original query unmodified. Here we return an empty object. function filters (options) { return {}: } When the user-provided object contains a date, we can use that to define a for our filter. For the we can specify fields and a condition. In this case we specify that the created field must be () the provided date. Since we moved this logic to a function, we don't clutter the original function with our () filter-building algorithm. We place our filters in a clause within a , so that we can filter on as many concerns as we have to. function filters (options) { const clauses = []: if (options.since) { clauses.unshift(since(options.since)): } return all(clauses): } function all (clauses) { return { bool: { must: clauses } }: } function since (date) { return { range: { created: { gte: date } } }: } When it comes to constraining a query to a set of user-provided tags, we can add a filter once again. Using the clause, we can provide an array of queries for the field, so that articles without one of the provided tags are filtered out. That's because we're specifying that the each user-provided against the field in the article. function filters (options) { const tags = Array.isArray(options.tags) ? options.tags : []: const clauses = tags.map(tagToFilter): if (options.since) { clauses.unshift(since(options.since)): } return all(clauses): } function all (clauses) { return { bool: { must: clauses } }: } function since (date) { return { range: { created: { gte: date } } }: } function tagToFilter (tag) { return { term: { tags: tag } }: } We could keep on piling condition clauses on top of our function, but the bottom line is that we can easily construct a query using the , and it's most likely going to be able to perform the query we want within a single request to the index. Finding Similar DocumentsThe API to find related documents is quite simple as well. Using the , we could specify the parameter to look for articles related to a user-provided document\u00a0\u2014\u00a0. We could reuse the function we just built, for extra customization. You could also specify that you want at most articles in the response, by using the property. { query: { bool: { filter: filters(options), must: { more_like_this: { like: { _id: options.article._id.toString() } } } } }, size: 6 } Using the query we can quickly set up those coveted \"related articles\" that spring up on some blogging engines but feel so very hard to get working properly in your homebrew blogging enterprise. The best part is that Elasticsearch took care of all the details for you. I've barely had to explain any search concepts at all in this blog post, and you came out with a powerful function that's easily augmented, as well as the of a search query for related articles\u00a0\u2014\u00a0 To round things out, I'll detail the steps I took in making sure that my deployments went smoothly with my recently added Elasticsearch toys. Rigging for Deployment \ud83d\ude80After figuring out the indexing and querying parts (), and setting up the existing parts of the blog so that search and related articles leverage the new Elasticsearch services I wrote for , came deploying to production. It took a bit of research to get the deployment right for Pony Foo's production environment. Interestingly, my biggest issue was figuring out how to install Java 8. The following chunk of code installs Java 8 in Debian Jessie and sets it as the default runtime. Note that we'll need the cookie in so that Oracle validates the download. echo \"install java\" JAVA_PACK=jdk-8u92-linux-x64.tar.gz JAVA_VERSION=jdk1.8.0_92 wget -nv --header \"Cookie: oraclelicense=accept-securebackup-cookie\" http:\/\/download.oracle.com\/otn-pub\/java\/jdk\/8u92-b14\/$JAVA_PACK sudo mkdir \/opt\/jdk sudo tar -zxf $JAVA_PACK -C \/opt\/jdk sudo update-alternatives --install \/usr\/bin\/java java \/opt\/jdk\/$JAVA_VERSION\/bin\/java 100 sudo update-alternatives --install \/usr\/bin\/javac javac \/opt\/jdk\/$JAVA_VERSION\/bin\/javac 100 Before coming to this piece of code, I tried using but nothing I did seemed to work. The package some suggest you should install was nowhere to be found, and the package isn't all that well supported by . After installing Java 8, we have to install Elasticsearch. This step involved copying and pasting Elastic's installation instructions, for the most part. echo \"install elasticsearch\" wget -qO - https:\/\/packages.elastic.co\/GPG-KEY-elasticsearch | sudo apt-key add - echo \"deb http:\/\/packages.elastic.co\/elasticsearch\/2.x\/debian stable main\" | sudo tee -a \/etc\/apt\/sources.list.d\/elasticsearch-2.x.list sudo apt-get update sudo apt-get -y install elasticsearch Next up came setting up that also relaunches itself across reboots. echo \"elasticsearch as a service\" sudo update-rc.d elasticsearch defaults 95 10 sudo \/bin\/systemctl daemon-reload sudo \/bin\/systemctl enable elasticsearch.service I deploy through a series of , ( \ud83c\udf40) building disk images along the way using Packer. For the most part, unless I'm setting up something like Elasticsearch, the deployment consists of installing the latest dependencies and updating the server to the latest version of the Node.js code base. More fundamental changes take longer, however, when I need to re-install parts of the system dependencies for example, but that doesn't occur as often. This leaves me with a decently automated deployment process while retaining tight control over the server infrastructure to use and friends as I see fit. When I'm ready to fire up the service, I just run the following. The last command prints useful diagnostic information that comes in handy while debugging your setup. echo \"firing up elasticsearch\" sudo service elasticsearch restart || sudo service elasticsearch start || (sudo cat \/var\/log\/elasticsearch\/error.log && exit 1) sudo service elasticsearch status That's about it. If the whole deployment process feels too daunting for you, Elastic offers . Although, at $45\/mo, it's mostly aimed at companies! If you're flying solo, you might just have to strap on your keyboards and start fiercely smashing those hot keys. There is one more step in my setup, which is that I hooked my application server up in such a way that the first search request creates the Elasticsearch index, type mapping, and bulk-inserts documents into the index. This could alternatively be done before the Node.js application starts listening for requests, but since it's not a crucial component of Pony Foo, that'll do for now! ConclusionsI had a ton of fun setting up Elasticsearch for my\u00a0blog. Even though I already had a homebrew search solution, it performed very poorly and the results weren't anywhere close to accurate. With Elasticsearch the search results are much more on point, and hopefully will be more useful to my readers. Similarly, related articles should be more relevant now as well! I can't wait to hook Elasticsearch up with and start feeding logs into my ES instance so that I can see some realtime HTTP request data\u00a0\u2014\u00a0\u00a0\u2014\u00a0 since I started blogging back in late 2012. I might do this next, when I have some free time. Afterwards, I might set up some sort of public dashboard displaying realtime metrics for Pony Foo servers. That should be fun! \n"}
{"index": {"_id": 602}}
{"title":"Elastic Support: Speaking Code and Human","seo_title":"Elastic Support: Speaking Code and Human","url":"\/blog\/elastic-support-speaking-code-and-human","author":{"name":"Marty Messer"},"date":"June 02, 2016","category":"Culture","locales":"","content":" I've worked in support for over twenty years \u2014 specifically in open source \u2014 and I can confidently say that support at Elastic is unlike anything else that exists out there. I mean, I don't know if you know, but typically, support sucks. And being in support sucks even more (just ask any support engineer you know). Why do I say this? Well, some software you buy doesn't always do what you were told it would. It's not as good as the packaging claims. This happens for a number of reasons: egos, cathedral building (when customer feedback doesn't make it back to engineering), marketing and sales being pressured to hit certain numbers no matter what it takes, etc. This gives customers certain expectations of how a product should perform, and when it doesn't work the way it's advertised \u2026 you know who has to absorb all that pain? Yeah, you know the answer. At Elastic, things are different. It starts with having empathy for our users. How can I explain it? I'll take you frame-by-frame it (bonus points if you get this reference). It starts with our very first support engineer. Do you know who that was? This guy named Shay Banon, Elastic co-founder and creator of Elasticsearch. Back in 2010 when Shay created Elasticsearch, he was the only person 'responsible' for supporting the developers who were using the software \u2014 answering questions on IRC and mailing lists (check out this exchange between Shay and Clinton Gormley, who joined Elastic two years later and ended up co-authoring ), reviewing and merging pull requests on GitHub \u2026 and, you know, continuing to build the software, too. NBD. That's open source, right? But just keep in mind that's our roots. That's where we came from. That's where we were born. And things evolved along the same path from there. Speaking Code and HumanAfter Elastic the company was founded, all the engineers we hired early on had to have the same skillset as Shay: a mix of being technically bad ass to continue building out our software, combined with the ability, desire, and skill to talk to people in order to support our customers. It was a fundamental part of their job. Fast forward to 2014, two years after Elastic the company was founded. That's when I came onboard to build a dedicated Customer Care team. Which has been really, well, incredible, and kind of f*cking awesome (can I say that? Well, I just did). Here's why. Our developers care. A lot.The people that created the open source projects that make up the \u2014 Elasticsearch, Kibana, Logstash, and Beats \u2014 all work here. Like Shay, these all started as passion projects they created and maintained \u2018on the side'. And again like Shay, they served as their sole support engineers before this whole Elastic company became a thing. They care deeply about user feedback and take it seriously. Hang out in our and . Follow them on Twitter and you'll see exchanges like this one with Logstash creator Jordan Sissel. you were busy so I didn\u2019t want to interrupt. But wanted to again say thanks for all your community work with \u2014 Chris (@tebriel) A lot of the developers we hire were avid users of the Elastic Stack before they got here\u2026 which is ultimately what brought them to Elastic. Many were contributors and active in the community, many were deploying our software in their companies or startups, and many had pre-existing relationships with our own developers. They're here because they not only have passion and love our software, but they want to continue to make it even better. The support team is fully integrated with the engineering teamBecause of what I already explained about our history \u2014 that supporting our users and making them successful is encoded into our DNA \u2014 the support team is part of the overall engineering organization. We are very closely aligned to product and development. We're constantly working together on Slack, and getting together virtually via video conference to learn about what everyone's working on. There is no disconnect. A screenshot from one of our virtual support team meetings. Loggy D. Wood and his family joined us. And Jeremy had his camera on ghost-mode apparently.Another fun fact: most of our support engineers didn't always work in support. A lot of them were developers or operators prior to joining Elastic. So yeah, they also have empathy. Take all of this goodness, and imagine how it translates into the product \u2026 I hope some of you can feel the love that goes into our work, and I hope that it shows in the fact that, in my humble opinion, our products are pretty good. We don't want our sales and marketing teams to have to stretch the truth to convert users to customers. So, because our products do what we say they do, our customers spend less time trying to make them do things they can't do but were told they could, and spend more time doing really cool sh*t \u2014 which means that the support engineers get to work on interesting and fun things with our customers. They're less like firefighters and more like remote consultants \u2014 some are even considered extensions of their customer's teams. Which makes their jobs much more enjoyable. And really, all of our engineers, whether they're dedicated support contacts or not, are interested in what our customers are doing and are helping them in one way or the other. The moral of the story is \u2026I guess it all boils down to the people we hire. They just give a sh*t. They're not drones. They are unique, they have a spark \u2026 they're special. They're family to me, and I think our customers feel the same way, too. See for yourself: Check out a few videos we shot at Elastic{ON} where folks from my team got to meet people they've been working with at eBay and Jobrapido in-person \u2014 some for the first time \u2014 and share what it's been like working together. These are unscripted, unrehearsed, literally shot in a trailer next to the catering tent in a small courtyard outside the conference venue. You can tell that these people are on a journey, together, and that they're really enjoying the ride.\u00a0 So, that's my spiel. But I thought it was worth writing down what we at Elastic care about when it comes to supporting our customers. I guess you can consider this my manifesto, of sorts.\u00a0 Messer. Out. \n"}
{"index": {"_id": 603}}
{"title":"Elastic{ON}16<\/sup> \u2014 One hundred days later","seo_title":"Elastic{ON}16<\/sup> \u2014 One hundred days later","url":"\/blog\/elasticon-16-one-hundred-days-later","author":{"name":"Martin Smith"},"date":"June 02, 2016","category":"User Stories","locales":"","content":" It\u2019s been almost exactly one hundred days since I gave a talk about the\u00a0 at in San Francisco, California. Since February, the new names and logos we saw for the first time have become commonplace, and many other changes announced at Elastic{ON} are faint memories. But since February, I\u2019ve also seen some really awesome new things come out \u2014 like \u2014 and major updates to projects like .As a conference attendee this year, I got a real sense that Elastic was picking up the pace on product development, and the release bonanzas have continued to show that commitment. has also supported my continuing efforts to maintain the Chef cookbook with updates for new versions, functional enhancements, Chef software updates, and packaging bug fixes. For the first time this year, I was also able to be part of the \u2018international attendance\u2019 at Elastic{ON}. I\u2019ve been living as a digital nomad and traveling with since February 1st, 2016. I traveled to San Francisco from Montevideo, Uruguay. I\u2019ve since lived a month each in Uruguay, Argentina, Bolivia, and Peru. At the conference, I met up with Chef cookbook collaborators who had traveled equally far\u00a0\u2014\u00a0 from Prague, from Austin, and from the Bay Area. I also had the pleasure of meeting some Elastic staff like and , both traveling to San Francisco from Europe. I learned that Elastic is actually a distributed company, which I very much respect as a digital nomad. Looking back on the trip, there was a spark of excitement in the air at the venue. It was a very different conference than the ones I\u2019m used to \u2014 a mixed focus of product and open source, all rolled into one. I gained a ton of practical knowledge, especially about the Beats architecture and the recent Kibana changes to support plugins like . In the talk I gave, I enjoyed explaining the challenges we faced in building automation around Elasticsearch, and inviting new contributors to join me: we even had some attend that I hadn\u2019t met in person before! Since that talk, I\u2019ve started to help maintain the popular Kibana and Logstash cookbooks in the Chef community as well. With the unification of things like plugin commands in the Elastic Stack, maintaining Chef automation across the products is starting to become easier too.If you weren\u2019t able to attend Elastic{ON}, be sure you about next year\u2019s conference. And if you get a chance, check out the videos () from this year. All talks are , and for free. I hope to see you next year at Elastic{ON}! Martin Smith is a DevOps Engineer at Rackspace Hosting, where he works with customers and colleagues on automation engineering and building IT infrastructure as code. With more than ten years of experience as a systems administrator and software developer, his interests also include load testing, performance tuning, and software testing in general. He strongly believes in open source and actively contributes to open source automation projects using Chef. When Martin isn\u2019t writing code or reviewing pull requests, he enjoys sharing his skills with others, volunteering in his local community, and mentoring minority college students in STEM fields. \n"}
{"index": {"_id": 604}}
{"title":"Tutorial: Getting Started with Elastic Cloud with a Sample Dataset","seo_title":"Elastic Cloud Tutorial: Getting Started with a sample dataset","url":"\/blog\/building-cloud-sandbox-with-sample-data-v2","author":{"name":"Chad Pryor"},"date":"June 01, 2016","category":"Engineering","locales":"","content":" Getting an Elasticsearch environment up and running has never been easier. With Elastic Cloud, you can launch your cluster and start ingesting data in literally minutes. See how in this . This step-by-step set of instructions will walk you through setting up an Elastic Cloud account, creating and securing a Elasticsearch cluster, importing data, and visualizing it in Kibana. So, let's get started. Log into Elastic Cloud\u00a0 Create your first\u00a0hosted\u00a0Elasticsearch cluster Secure your Cluster Next, let's configure cluster access and security. You can update your passwords or add additional users using the same process.\u00a0You may also use the new security API that is included in 2.3.1 by following the\u00a0.\u00a0 Enable Kibana Elasticsearch EndpointOnce you are logged into Kibana, you will first see the Discovery tab.\u00a0However, there is no data to visualize.\u00a0Next, we will work on ingesting data into Elasticsearch.\u00a0Let's gather some information so we can be successful.\u00a0 Import Data Now, let\u2019s get some data into our Elasticsearch cluster to see the Elastic Stack in action. If you don\u2019t have a sample dataset handy, use one from the various data samples in our\u00a0 I will be using the \u00a0and \u00a0(download your system version). To ingest the logs into our hosted Elasticsearch cluster, we will need to modify the elasticsearch output of the . 1. Download the repository, and change to the directory that contains the\u00a0\u00a0file. Be sure to replace hosts endpoint in the config\u00a0with your own cluster endpoint (copied in the previous step) 2. Modify username and password to the user account with write access configured Secure Elasticsearch section. I will be using user elasticsearch { hosts => \"https:\/\/e66e6e11692c749cc8e09f25e1af4efa.us-west-1.aws.found.io:9243\/\" user => \"sa_admin\" password => \"my_f@ncy_p@55w0rd\" index => \"apache_elastic_example\" template => \".\/apache_template.json\" template_name => \"apache_elastic_example\" template_overwrite => true } 3. Run the following command to index the data into Elasticsearch via\u00a0Logstash: cat ..\/apache_logs | \/bin\/logstash -f apache_logstash.conf 4. You can verify your data exists in Elasticsearch by going to , where is the Elasticsearch endpoint URL.\u00a0You should see the count as 10000. {\"count\":10000,\"_shards\":{\"total\":1,\"successful\":1,\"failed\":0}} 5. You can verify the health of your cluster by going to\u00a0.\u00a0You should see your index listed along with its\u00a0statistics: health status index pri rep docs.count docs.deleted store.size pri.store.size yellow open .kibana 1 1 2 0 19.1kb 19.1kb yellow open apache_elastic_example 1 1 10000 0 7.3mb 7.3mb Visualize DataNow let's access your Kibana instance and continue with the example\u00a0instructions to visualize our data. 2.\u00a0You can look at your data by selecting index on the Discovery tab. 3. Import the examples dashboard by clicking\u00a0on \u00a0>\u00a0\u00a0>\u00a0 and selecting the\u00a0\u00a0file.\u00a0You can view this dashboard by clicking on the view button (eye icon) or by going to the Dashboards tab and clicking the Load Saved Dashboard button. Now you have some sample Apache log data in Elasticsearch and you can begin to get some insight and more importantly value from your logs. You can continue exploring\u00a0with other sample datasets from the \u00a0 and the\u00a0 \u00a0or\u00a0start sending your own data by using Logstash or Beats. Here are some other useful links to help you on the journey of using the Elastic Stack on Cloud. Or, you can continue your Training with some official classes by some world class Education Engineers:\u00a0 \n"}
{"index": {"_id": 605}}
{"title":"Elasticsearch for Apache Hadoop 5.0.0-alpha3","seo_title":"","url":"\/blog\/es-hadoop-5-0-0-alpha3","author":{"name":"Costin Leau"},"date":"May 31, 2016","category":"Releases","locales":"","content":" \u200bI am excited to announce the release of Elasticsearch for Apache Hadoop (aka ES-Hadoop) built against Elasticsearch 5.0.0-alpha3. : This is an alpha release and is intended for purposes only. Indices created in this version . What\u2019s new? Upgrade to Storm 1.x Since ES-Hadoop 5.0.0-alpha3, the Storm support has been upgraded to 1.0.x. As this version is backwards compatible with Storm 0.9.x, support for these versions had to be dropped. (Do note that one can still use Storm 0.9.x with ES-Hadoop 2.x accordingly.) Changelog layout The release changelog is now aligned closer to that of Elasticsearch proper. Feedback Please [download] ES-Hadoop 5.0.0-alpha3, try it out and let us know what you think on , , or in the . \n"}
{"index": {"_id": 606}}
{"title":"Elasticsearch 5.0.0-alpha3 released","seo_title":"Elasticsearch 5.0.0-alpha3 released","url":"\/blog\/elasticsearch-5-0-0-alpha3-released","author":{"name":"Clinton Gormley"},"date":"May 31, 2016","category":"Releases","locales":"","content":" Today we are excited to announce the release of based on . This is the third in a series of pre-5.0.0 releases designed to let you test our your application with the features and changes coming in 5.0.0, and to give us feedback about any problems that you encounter.Open a bug report today and become an . This is an alpha release and is intended for . Indices created in this version . Upgrading 5.0.0-alpha3 to any other version is not supported.Elasticsearch 5.0.0-alpha3 is close to being feature complete, and builds on the work released in 5.0.0-alpha2. There are many small changes which you can read about in the release notes above, but some of the more interesting ones are mentioned below.Also take a look at the release announcements for and to read about features like: \n"}
{"index": {"_id": 607}}
{"title":"Logstash 5.0.0-alpha3 released","seo_title":"","url":"\/blog\/logstash-5-0-0-alpha3-released","author":{"name":"Suyog Rao"},"date":"May 31, 2016","category":"Releases","locales":"","content":" We are happy to announce the third pre-release (alpha3) in the 5.0.0 series! Please check the release notes for details, or jump directly to our if you can't wait to try it out! \u00a0This release is loaded with goodies that are highlighted below:Logstash release packages (Debian, RPM) has been given an overhaul in this release. Most importantly, this is a breaking change, so please read ahead! Previously, Logstash used directory to install the binaries, whereas Elasticsearch used , and . To make user experience consistent across our products \u2014 a theme you'll hear a lot in our 5.0.0 releases \u2014 we've to reflect Elasticsearch RPM and DEB layouts. Secondly, we added systemd and upstart support to run Logstash as a. Today, a lot of Linux distributions (Debian Jessie, Ubuntu 15.10+, and many of the SUSE derivatives) use systemd as the default service manager, and we received many requests from our users to support systemd. Oh, and all the JVM options have been extracted to a separate file, \u00e0 la Elasticsearch, so you can easily override or pass in new JVM options by modifying a single clean file, instead of digging through BASH scripts. Say hello to file. Yep, this is a new one-stop-place to configure all application-level settings for the Logstash process. With all the new features we've been adding, our list of CLI options kept growing! To stop cluttering the CLI, and to make bootstrap easier, we've introduced a new settings file which mirrors the CLI. Most of the have been renamed to adhere to the yml dot notation, so this is filed under as well. Short form options have remained the same. If you installed an RPM or DEB package, look for this file in , or otherwise in . Just to be clear, the pipeline configuration where you specify the input, filters and outputs is separate from the settings file. Remember we released a new feature called Java Event \u2014 a rewrite of Event handling in pure Java \u2014 in version 2.3? Say you were using the Ruby Filter: in some cases this change could have been backward incompatible because this filter allows users to manipulate the Event object directly using Ruby\u2019s hash paradigm. To mitigate this, we rolled back this feature when we released version 2.3.1. Now, in 5.0.0 \u2014 a major release \u2014 we've handled this correctly by introducing non-ambiguous APIs to interface with the Event object. This change mostly affects plugin developers who write and maintain custom plugins \u2014 all the default packaged plugins have been updated to use the new APIs. If you maintain a custom plugin, or plan to write a new one, this old style of accessing Events directly using the Ruby hash convention will not work anymore. Please use these if you need access to data inside of the Event object. Kibana. Beats. And now Logstash has it too! We're talking about a plugin generator tool that makes it easier to develop new plugins for Logstash. Previously we've recommended developers to clone\/fork the, but now you can simply do: bin\/logstash-plugin generate --type input --name xkcd --path ~\/ws\/elastic\/plugins This subcommand bootstraps a new plugin logstash-input-xkcd with the right directory structure and all the required files (templates) for you to start developing this plugin right away. So, go on, create that input to stream those fine comic strips to Kibana! Wait, you though we'd\u00a0just talk about and not drop a strip here?! We said this was a loaded release before.. \"process\" : { \"peak_open_file_descriptors\" : 48, \"max_file_descriptors\" : 10240, \"open_file_descriptors\" : 48, \"mem\" : { \"total_virtual_in_bytes\" : 5274738688 }, \"cpu\" : { \"total_in_millis\" : 20792844000, \"percent\" : 23 } } Please try and let us know what you think! You can even for Elastic{ON} '17 when you help test our pre-releases! Your feedback and contribution is really important as we continue to iterate on 5.0.0. You can create issues on our, find us on our, or hang out with us on IRC (#logstash). \n"}
{"index": {"_id": 608}}
{"title":"Beats 5.0.0-alpha3 released","seo_title":"","url":"\/blog\/beats-5-0-0-alpha3-released","author":{"name":"Monica Sarbu"},"date":"May 31, 2016","category":"Releases","locales":"","content":" We are over-the-moon excited to announce the 5.0.0-alpha3 release, a major milestone on our road to Beats 5.0. IMPORTANT: This is an alpha release and it is intended for testing purposes only. Bye bye Topbeat, hello Metricbeat We are proud to see that in just 6 months since we launched libbeat 1.0, there are already around created by the community. If you have a closer look at the community Beats, you notice that many of them are used to collect metrics from various services. For example, queries the MySQL server for metrics, queries Nginx for metrics, queries Apache for metrics, and so on. Our own works in a similar way: it periodically queries the various operating system APIs for system statistics like CPU usage, memory usage, per process statistics, and indexes them to Elasticsearch. We\u2019ve seen great adoption of Topbeat and have gotten constantly good feedback about it. Metricbeat is designed from the beginning to be modular so you can easily add new modules that collect data from external systems. For now Metricbeat includes the following modules: system, apache, mysql, nginx, redis, and zookeeper. We will keep extending this list during the alpha and beta phases of the 5.0 release. I would like to give special thanks to the community contributors (creator of Apachebeat), (Nginxbeat), and (Redisbeat) for converting their Beats to Metricbeat modules. In the default Metricbeat configuration, only the module is enabled, so running Metricbeat with the default configuration is equivalent with running Topbeat. It exports system statistics like CPU usage, memory, swap, per process statistics, per core statistics, and filesystem statistics. In addition, it also exports IO and network statistics, which were a popular feature request for Topbeat. This means that if you are currently using Topbeat, migrating to Metricbeat is easy. Here is the default Topbeat 1.x configuration: input: period: 10 procs: [\".*\"] stats: system: true process: true filesystem: true And here is the default Metricbeat configuration, exporting the same data: metricbeat.modules: - module: system metricsets: - cpu #- core #- diskio - filesystem #- fsstat - memory - process enabled: true period: 10s processes: ['.*'] So, if you are running the default Topbeat configuration, all you need to do is upgrade to Metricbeat and use its default configuration. You will get the same data, but in a slightly different format. Add conditions to filtering Filtering is a new feature added in 5.0.0-alpha2, and it\u2019s available to all the Beats through . With filtering, you can reduce the number of fields that are exported by defining a list of filter actions that are applied to each event before it\u2019s sent to the defined output. The filter actions are executed in the order that they are defined in the config file. Starting with alpha3, we introduce conditions to filter the exported fields only if the condition is fulfilled. We also add the operation to drop entire events. For example, if you are using Packetbeat to monitor your HTTP transactions, you can decide not to index the successful transactions in Elasticsearch by dropping all events that have the HTTP response 200 OK. The configuration file should include the following filters section: filters: - drop_event: equals: http.code: 200 Configuration files, how you like them The Beats use YAML for configuration and have a tradition of putting all the available options commented out in the configuration file together with a short description for each of them. This means that the configuration file also acts as a reference, so you almost don\u2019t have to read the manual (you still should, it contains useful guides and more details for some of the options). The downside of this is that as we add more options to the Beats (notably the Redis and Kafka outputs), the configuration files tend to become very large, which contradicts the lightweight nature of the Beats. With the alpha3 release, each Beat comes with two versions of the configuration file. A short one, the default, that contains only the most common options. It\u2019s beautifully simple. And a complete one (called, for example, ), containing all the non-deprecated options. It\u2019s wonderfully comprehensive. We recommend that you start with the short configuration and copy over settings from the full version as needed. These are not the only changes we did to the configuration files. We\u2019ve seen lots of users having trouble with the multiple indentation levels, so we reduced the number of levels by using dots in the field names. Also, YAML is just not strict enough when it comes to the accepted syntax, so we added lots of validators to catch errors early. Become a Pioneer A big Thank You to everyone that has tried the alpha1 and alpha2 releases and or . We\u2019d like to also remind you that if you post a valid, non-duplicate bug report during the alpha\/beta period against any of the Elastic stack projects, you are entitled to a . \n"}
{"index": {"_id": 609}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-05-31","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-05-31","author":{"name":"Michael McCandless"},"date":"May 31, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsUsing #Elasticsearch for #geohazards & working w' @esa to map ground deformation @terradue \u2014 elastic (@) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole Elastic ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 610}}
{"title":"Elastic Stack Release - 5.0.0-alpha3","seo_title":"Elastic Stack Release - 5.0.0-alpha3","url":"\/blog\/elastic-stack-release-5-0-0-alpha-3","author":{"name":"Shay Banon"},"date":"May 31, 2016","category":"Releases","locales":"ja-jp","content":" Alpha 1 has come and gone. Alpha 2 included a variety of new features. But, the release train continues.Or, the hits keep on coming.Perhaps, some other product release related catch-phrase. It's here! Say \"Heya\" to Alpha 3. Before you get too excited, keep in mind that this is still an Alpha, so don\u2019t put it into production. And, since it is an Alpha, it is not available on . But, because Elastic Cloud is the official hosted Elasticsearch and Kibana offering on AWS, you\u2019ll be able to deploy the 5.0 releases on Elastic Cloud the day of 5.0 GA.* (We wouldn\u2019t want you to wait for all this goodness!) If you open a bug report, today, you too can become an . And now, without further ado, some highlights from Alpha 3. Elasticsearch For more detailed information, and many other features, peruse the Elasticsearch . From 2.3.x to 5.0. The magical journey. The undiscovered country. The next frontier. Other coined phrases. As a reminder, we've also released the , which runs on your existing 2.3 cluster. \u00a0Use this site plugin to prep for your migration. Kibana For more detailed information, and all the PR links in one place, visualize the future in the Kibana . Logstash All the information, in one central location. Parse the . Beats Explore the edge, in the Beats . ES-Hadoop ES-Hadoop v 5.0.0-alpha3 has also been released today. Peruse all the information in the . \n"}
{"index": {"_id": 611}}
{"title":"Kibana 5.0.0-alpha3 released","seo_title":"Kibana 5.0.0-alpha3 released","url":"\/blog\/kibana-5-0-0-alpha3","author":{"name":"Court Ewing"},"date":"May 31, 2016","category":"Releases","locales":"","content":" This is a tale of triumph. Of intrigue and mystery, and an unwavering fortitude in the face of incredible odds. For in this tale, we release Kibana\u2019s third alpha in two months. They said this could never happen. They said we\u2019d never make it. Well, we made it. And you can get Kibana 5.0.0-alpha3 . This is alpha software that will only work with . Please test it, but do not use it in production. Indices created in this version will . Upgrading 5.0.0-alpha3 to any other version is not supported. With 30 pull requests in 28 days, we focused on making this the most stable pre-release yet. This is also an awesome release for the X-Pack UI, which includes two huge new features: X-Pack users and roles management Security UI, meet Users and Roles. Of course, you can still manage your users and roles via the X-Pack API, but why bother when you have that same power at your fingertips from within Kibana itself. X-Pack reports, now with history Reports now get queued and processed in the background, so you can generate a lot of reports without worrying about it having a negative impact on Kibana. The reports are then stored and appear in the UI, so you don\u2019t need to regenerate the same report over and over again. And Kibana core, of course What\u2019s next? Beta 1 is still on the horizon, but we want to get one more alpha out before then. You see, when we do launch beta 1, we want to shift our focus away from features and entirely toward stability and upgradability, but we don\u2019t yet feel like we\u2019ve jammed enough features into 5.0. Keep your eyes peeled for alpha4. In the meantime, grab alpha3 and help us find all of the bugs. Every. Last. One. We\u2019d love your feedback on our and any bug reports on . As always, feel free to reach out to us on or as well. \n"}
{"index": {"_id": 612}}
{"title":"Quick Start Guide - Configuring Elasticsearch with Shield and Active Directory","seo_title":"Quick Start Guide - Configuring Elasticsearch with Shield and Active Directory","url":"\/blog\/quick-start-guide-configuring-elasticsearch-with-shield-and-active-directory","author":{"name":"Marcelo Rodriguez"},"date":"May 31, 2016","category":"Engineering","locales":"","content":" When learning a new system, I always find it useful to have instructions on how to install and configure a feature with minimum steps in a cookbook style format. \u00a0It allows me to get up and running quickly without having to reference several pages with the multitude of optional settings. \u00a0From that point, I can take a look at the reference manuals and the more advanced options to configure the components according to my end architecture requirements. In this post, I\u2019ll go through installing and configuring Elastic Shield with Elasticsearch to use Windows Active Directory domain authentication for Elasticsearch Administrators. \u00a0 (Repeat steps below for every node in the cluster) 1. Download and install the public signing key: rpm --import https:\/\/packages.elastic.co\/GPG-KEY-elasticsearch 2. \u00a0Create the new yum repo file for Elasticsearch: vi \/etc\/yum.repos.d\/elasticsearch.repo 3. \u00a0Copy and paste the following entries in the new repo file: [elasticsearch-2.x] name=Elasticsearch repository for 2.x packages baseurl=https:\/\/packages.elastic.co\/elasticsearch\/2.x\/centos gpgcheck=1 gpgkey=https:\/\/packages.elastic.co\/GPG-KEY-elasticsearch enabled=1 1. \u00a0Create a user who will be the Elasticsearch administrative user in Active Directory Users and Computers (ADUC). See example below for user named Elasticsearch Administrator. 2. \u00a0Create an Active Directory security group for the Elasticsearch Admins. \u00a0This group will be used to hold our new user account. \u00a0 (Repeat steps below for every node in the cluster) 1. \u00a0Install the license plugin.\u00a0 *The license plugin is required to run commercial plugins from Elastic.\u00a0 \/usr\/share\/elasticsearch\/bin\/plugin install license 2. Install the Shield plugin. \/usr\/share\/elasticsearch\/bin\/plugin install shield 1. \u00a0Open the elasticsearch.yml file. vi \/etc\/elasticsearch\/elasticsearch.yml 2. \u00a0Add the following entries at the bottom of the file, replacing the sample domain entry with your specific domain: #-----SHIELD CONFIG------ shield: authc: realms: active_directory: type: active_directory order: 0 domain_name: mydomain.local url: ldap:\/\/mydomain.local:389 unmapped_groups_as_roles: false 3. \u00a0Repeat Steps 1 and 2 for all nodes in the cluster. 4. \u00a0Open the role_mapping.yml file. vi \/etc\/elasticsearch\/shield\/role_mapping.yml 5. \u00a0Add the following entry at the bottom of the file, replacing the sample DN location with the location noted above in Section B, Step 2. admin: - \"cn=ESAdmins, ou=Groups, ou=Elasticsearch, dc=mydomain, dc=local\"6. \u00a0Copy the role_mapping.yml file to all nodes in the cluster as in the examples below replacing sample node names with your node names: scp \/etc\/elasticsearch\/shield\/role_mapping.yml root@esnode2:\/etc\/elasticsearch\/shield\/ 7. Restart elasticsearch service on each node. service elasticsearch restart You can test by simply performing the following query replacing the sample node name with yours: curl -XGET \u2018esnode1:9200\u2019 -u esadmin Command and output should look something like this: [root@esnode1 ~]# curl -XGET 'esnode1:9200' -u esadmin Enter host password for user 'esadmin': { \"name\" : \"esnode1\", \"cluster_name\" : \"marscluster1\", \"version\" : { \"number\" : \"2.3.2\", \"build_hash\" : \"b9e4a6acad4008027e4038f6abed7f7dba346f94\", \"build_timestamp\" : \"2016-04-21T16:03:47Z\", \"build_snapshot\" : false, \"lucene_version\" : \"5.5.0\" }, \"tagline\" : \"You Know, for Search\" } There are many options and combinations that are possible. Once you are able to set up this basic Shield and Elasticsearch combination, you can find additional resources below to customize for your architecture requirements and needs. For additional information on: \u00a0Active Directory authentication options: Role-based access: Mapping groups to roles: Encrypting Active Directory communication with SSL\/TLS: Installing and managing Elastic licenses: Setting up Elasticsearch repositories: \n"}
{"index": {"_id": 613}}
{"title":"Brewing in Beats: Getting Metricbeat ready for release","seo_title":"","url":"\/blog\/brewing-in-beats-getting-metricbeat-ready-for-release","author":{"name":"Tudor Golubenco"},"date":"May 30, 2016","category":"Brewing in Beats","locales":"","content":" Welcome to Brewing in Beats! With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources. New community Beat: CloudTrailBeat An interesting new Beat was created by . relies on a combination of SNS, SQS and S3 to create a processing 'pipeline' to process new log events quickly and efficiently. The Beat polls the SQS queue for notification of when a new CloudTrail log file is available for download in S3. Each log file is then downloaded, processed and sent to the configured receiver (logstash, elasticsearch, etc). Metricbeat: export CPU usage fields as percentages With , the system module in Metricbeat exports all CPU usage fields (user, system, idle, etc.) as percentages from the total CPU time. This makes it easier to make sense of the values. The old \u201cticks\u201d units are also available, but disabled by default. Metricbeat: export network IO stats This new provides network IO metrics collected from the operating system. An event is generated for each network interface. This metricset is available on Darwin (aka OSX), Windows, Linux, and FreeBSD. Filebeat new registry file format The previous format for the registry file was a dictionary with the file paths as keys. This had the potential to lead to overwrite and conflicts on file rotation. As the file path is also stored inside the state object this information was duplicated. Now which makes the format more flexible and brings it close to the format used by Logstash. The migration from the old format happens automatically on the first run. Lumberjack code extracted in a library We now have a library that implements both the client and the server side of the Lumberjack protocol, which we use between Beats and Logstash. The unit tests for logstash output now use , simplifying test code quite a bit. Custom incomplete lumberjack server has been removed from output plugin. The above referenced PR also does the first steps towards replacing the default JSON encoding with custom code that does JSON encoding without reflection and with fewer allocations. Generator for Metricbeat modules\/metricsets Adding a MetricSet requires creating several files with a predefined file structure for automation. To simplify the task of creating a MetricSet and make sure the correct structure is used, this task is now . Normalizing Metricbeat fields We\u2019ve continued to normalize the fields exported by Metricbeat to use a common format. This week the and the field names were refactored. Configuration files improvements Continuing the theme from the last weeks, the configuration files were improved to the \u201cfull\u201d versions. Our system tests were to use a similar structure for configuration as the files that we ship. Also, to use the same style in configuration samples. Packetbeat NFS fixes and refactoringCommunity contributor has done a great job improving the NFS module in packetbeat with fixes and refactorings to make the code cleaner. \n"}
{"index": {"_id": 614}}
{"title":"Lost in Translation: Boolean Operations and Filters in the Bool Query","seo_title":"Boolean Operations and Filters in the Bool Query in Elasticsearch","url":"\/blog\/lost-in-translation-boolean-operations-and-filters-in-the-bool-query","author":{"name":"Tyler Fontaine"},"date":"May 31, 2016","category":"Engineering","locales":"","content":" With on the horizon, a number of query types deprecated in 2.x will be removed. Many of those are replaced by functionality of the bool query, so here\u2019s a quick guide on how to move away from : , , queries: and a general look into how to parse boolean logic with the bool query.For the examples used in this article, let's assume this scenario: A school surveyed its students on their preferences for fruit snacks. Now you're putting together an application so administrators can view this data. Because of the many grades, categories, and other features of the data, you may find you have some arbitrarily complex boolean logic to deal with.Matching Boolean Operations with the Bool Query FieldsLet's get to the heart of these boolean operations and how they'd look without the and, or, not queries. In the bool query, we have the following fields: is analogous to the boolean , is analogous to the boolean , and is roughly equivalent to the boolean . Note that isn't exactly like a boolean , but we can use it to that effect. And we\u2019ll take a look at later on.Boolean AND and NOT are easy, so let's look at those two first. If you want documents where preference_1 = Apples AND preference_2 = Bananas the bool query looks like this:{ \"query\" : { \"bool\" : { \"must\": [{ \"match\": { \"preference_1\": \"Apples\" } }, { \"match\": { \"preference_2\": \"Bananas\" } }] } } }If you want documents where preference_1 != Apples:{ \"query\" : { \"bool\" : { \"must_not\": { \"match\": { \"preference_1\": \"Apples\" } } } } }But what about OR? That's where the parameter comes in. If you want the set of documents where preference_1 = Apples OR preference_1 = Raspberries:{ \"query\" : { \"bool\" : { \"should\": [{ \"match\": { \"preference_1\": \"Apples\" } }, { \"match\": { \"preference_1\": \"Raspberries\" } }] } } }So these, then, can all be combined into much more complex boolean logic, because we can easily nest bool queries. So let's look at this boolean logic: So in this case, you are searching for documents that match this set of rules, so documents where preference_1 is Apples and term 2 is either Bananas or Cherries, OR preference_1 is grapefruit, regardless of what term 2 equals.That logic translates into a query that looks like this:{ \"query\": { \"bool\": { \"should\": [{ \"bool\": { \"must\": [{ \"match\": { \"preference_1\": \"Apples\" } }, { \"match\": { \"preference_2\": \"Bananas\" } }] } }, { \"bool\": { \"must\": [{ \"match\": { \"preference_1\": \"Apples\" } }, { \"match\": { \"preference_2\": \"Cherries\" } }] } }, { \"match\": { \"preference_1\": \"Grapefruit\" } }] } } }To break this down a bit further:Note that the whole of this query is wrapped in a which satisfies the three OR clauses, and each individual piece is its own nested bool query.So the piece is{ \"bool\": { \"must\": [{ \"match\": { \"preference_1\": \"Apples\" } }, { \"match\": { \"preference_2\": \"Bananas\" } }] } }And because this is all wrapped in a should, the next in the chain would be an ORSo the piece would be another bool:{ \"bool\": { \"must\": [{ \"match\": { \"preference_1\": \"Apples\" } }, { \"match\": { \"preference_2\": \"Cherries\" } }] } }And then finally the single term:{ \"match\": { \"preference_1\": \"Grapefruits\" }The query can be arbitrarily complex, to fit your particular boolean requirement. Each piece can be broken down and turned into its elementary boolean expressions, then chained together as shown above, to make sure you're retrieving the right documents. It\u2019s also worth noting here that you can set to a value you choose. This is the prime difference of the function from the boolean . By default , defaults to 1, but if you would like for more than one should clause to match for a document to be returned, you can increase this value.Filtered QueriesBecause filtered queries have also been deprecated in 2.x, the new method is the field in the bool query. So let's take our boolean logic from before: . Let\u2019s say an administrator is focusing on grade 2, so they want to see only the results for that grade. It would just be a matter of adding a to the bool to get only those documents. If you are filtering documents, keep in mind that the relevance score for the returned results is only affected by the query, not by the filter, so it\u2019s possible that your relevance scoring may not be what you expect, since it\u2019s the query that sets the score, not the filter.Here\u2019s what the filter looks like:\"filter\" : { \"term\": { \"grade\": \"2\" } }So the whole query looks like this:{ \"query\": { \"bool\": { \"should\": [{ \"bool\": { \"must\": [{ \"match\": { \"preference_1\": \"Apples\" } }, { \"match\": { \"preference_2\": \"Bananas\" } }] } }, { \"bool\": { \"must\": [{ \"match\": { \"preference_1\": \"Apples\" } }, { \"match\": { \"preference_2\": \"Cherries\" } }] } }, { \"match\": { \"preference_1\": \"Grapefruit\" } }], \"filter\" : { \"term\": { \"grade\": \"2\" } } } } }As you can see, the bool query is quite versatile, but sometimes parsing out the complex boolean operations into the bool query syntax can be a challenge. Hopefully, this has given you a better idea of how each of the bool query fields map to traditional boolean operators, and how you can chain those together for complex boolean logic for better search results.Also, this hopefully has given you some ideas as you work to remove filtered and and, or, not queries using the bool query to make sure you are ready for 5.0 when it is released. As ever, please make sure you review all and thoroughly test against your specific use case prior to upgrading. \n"}
{"index": {"_id": 615}}
{"title":"Elastic Earth Science for Global Monitoring","seo_title":"Elastic Earth science for global monitoring","url":"\/blog\/elastic-earth-science-for-global-monitoring","author":{"name":"Emmanuel Mathot"},"date":"May 27, 2016","category":"User Stories","locales":"","content":" Our living planet is continuously monitored by a growing number of Earth observation satellites that produce terabytes of data daily. Europe is taking a lead role in the mission and is stimulating the use of this large amount of public and private satellite data. At we are developing platforms and applications for researchers and practitioners in Earth Science to help them extract information from these massive amounts of data. We are also bringing the community together with the European Space Agency to serve all the major research institutes in Europe, and aid international cooperation abroad. Hereafter, we share a look at a specific domain, the , for which Terradue developed a query engine powered by Elasticsearch aimed at selecting the best satellite acquisitions for the application, a technique for mapping ground deformation using radar images of the Earth's surface. In a few words, InSAR (Interferometric Synthetic Aperture Radar) consists in comparing phase information from images taken at different times, by the radar instrument on board of a satellite. This technique can measure the smallest terrestrial displacements down to a centimeter! Not clear enough? \u00a9 DLR\/EOC The above image is a 3D view of an area near the boundary of the Indian and Eurasian tectonic plates over Nepal. The colored zone corresponds to displacement of the Earth ground after the 7.8 magnitude earthquake that struck Nepal on 25 April 2015. To obtain this result, SAR experts compared two satellite images using a complex processing technique that depends on one crucial step - data selection. One image was taken just after the earthquake (post-event) and one before the earthquake (pre-event). The latter one was not selected randomly among the large archive of satellite acquisitions, but must be chosen based on analysing and minimizing the \u201cbaseline\u201d between the two acquisitions.\u00a0Because a satellite flies an orbital pattern the sensor is at a different position every time it images the same area. This is how SAR imagery is collected from slightly different viewing angles. \n"}
{"index": {"_id": 616}}
{"title":"Brewing in Beats: Conditional Filtering","seo_title":"","url":"\/blog\/brewing-in-beats-conditional-filtering","author":{"name":"Tudor Golubenco"},"date":"May 26, 2016","category":"Brewing in Beats","locales":"","content":" Welcome to Brewing in Beats! With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources. Last week we have released Beats 1.2.3 containing a few important . Besides that, we have worked on a set of improvements that we plan to release with 5.0.0-alpha3: Conditionals for generic filtering It is now to use conditionals when filtering out fields and events in libbeat. This makes it really easy to remove unneeded data even before sending it over the network. Here is an example filter that drops the HTTP header fields if the code is 200 and the status is OK: - drop_fields: fields: [\"http.request_headers\", \"http.response_headers\"] equals: http.code: 200 status: OK Metricbeat gets an Nginx module KS Chan, the person behind , has contributed an to Metricbeat. Metricbeat progress As anticipated last week, the work has started to normalize the metric names so that users get an uniform experience regardless of the system they monitor. For example, here is the and here is the one . Other Metricbeat improvements include: Configuration refactoring The work on reorganizing the options in our configuration files is almost . We now distribute two versions of the configuration files: the default one which contains only the most common options and a \u201cfull\u201d one, that contains all non-deprecated options with longer comments. The full versions can be almost used as a reference and it is easy to copy and paste between them. Another configuration related improvement is that all now accept the same specifiers (e.g 10s, 1ms). This change was done in a backwards compatible way. Static builds We now produce for Filebeat and Winlogbeat (which don't use CGo) by using simple cross compilation, without Cgo enabled. The advantage of the statically linked binaries is that they tend to be more portable. The Beats that use CGo continue to be dynamically linked against libc and not much else. Package names We have updated our to be consistent with the other Elastic stack projects. Filebeat to Logstash performanceThe work on figuring out why the Filebeat to Logstash communication is slower than expected is now resumed. The current intention is to rewrite the beats input plugin in Logstash to use Netty. It\u2019s really early, but there are some very promising results already. \n"}
{"index": {"_id": 617}}
{"title":"Monitoring Windows Logons with Winlogbeat","seo_title":"","url":"\/blog\/monitoring-windows-logons-with-winlogbeat","author":{"name":"Andrew Kroh"},"date":"May 26, 2016","category":"Engineering","locales":"","content":" Windows event logs can provide invaluable insight into your Windows based infrastructure. The Windows operating system has many event log channels, each dedicated to a specific category of events. In this blog post we are going to look at how to visualize logon and logon failure events from the Security event log. Winlogbeat is our lightweight shipper for Windows event logs. It installs and runs as a Windows service and ships event log data to Elasticsearch or Logstash. We will install Winlogbeat 5.0 on all machines in our example domain. Winlogbeat 5.0 has a that enables it to ship the raw data that was used in logging the event. Having these raw event data fields makes filtering and aggregating much easier than in earlier versions of Winlogbeat. Setup Below is the configuration file being used with Winlogbeat to ship data directly to Elasticsearch. For more information on how to install Winlogbeat please see the . winlogbeat.event_logs: - name: Security ignore_older: 168h output.elasticsearch: hosts: [\"elasticsearch.elastic.local:9200\"] template.name: \"winlogbeat\" template.path: \"winlogbeat.template.json\" template.overwrite: false On domain controllers I am adding an additional line to the configuration file as shown below. This will tag all events from the domain controllers with \u201cdc\u201d. The tag will we be used for filtering. tags: [\u201cdc\u201d] Monitoring for Successful Logons The reason for monitoring successful logons is to look for compromised user credentials. The number of successful logons can be a major indicator that compromised credentials are being used for system crawling or other malicious activity. An event with event ID is logged by Windows for every successful logon regardless of the (local, network, remote desktop, etc.). If we simply created a data table visualization in Kibana showing all events with event ID 4624 we would be overwhelmed with noise and it would not be easy to spot abnormal user logon patterns. So there are several filtering steps we are going to apply to remove the noise. Each of the filters is described below. The data table visualization shown above was created using this list of filters. The data table uses aggregations to count the total number of logons per user, the number of unique computers the user logged on to, and the number of unique source IPs that were used in those logons (if the user was remote). The table can be used to spot accounts that are potentially compromised. If an account has been used to logon to an abnormally high number of computers within your organization, it would warrant further investigation to see if the account is being used to crawl the network. Monitoring Logon Failures Monitoring failed logons can be useful for a number of purposes. From a security perspective, the obvious use cases are to detect unauthorized access attempts and brute-force credential attacks. From an infrastructure management perspective, failed logon attempts can be used to detect problems. For example, if a service account starts generating failures then it may indicate a configuration issue. Windows uses event ID when logging failed logon attempts. To visualize the failed logons we are going to use an area chart and simply filter for . To show the different types of logons being used we split the area based on the field. An example is is shown above. If anomalies are spotted in the chart, the user can select a more specific time period or logon type and use the Discover tab to view more details. Visualizing the Origin of Remote Logons (requires Logstash) If you allow Remote Desktop connections from the Internet it can be useful to plot the origins of those connections of a map. Both successful and failed logons report the IP address of the client in the field. By using a GeoIP filter to enrich the event with the location associated with the source IP address, we can visualize the events on a map in Kibana. This type of visualization can be used to quickly spot anomalies. For example, if you have no employees in South America and suddenly you have successful logons originating from that continent, then it\u2019s time to further investigate the incident. Setup This setup is a bit more advanced because it requires using either Logstash or an pipeline to enrich the event with the location associated with the IP address. Below are the configurations I used to enrich the events using Logstash. This is the Winlogbeat configuration file. The output was changed from Elasticsearch to Logstash. winlogbeat.event_logs: - name: Security ignore_older: 168h output.logstash: hosts: [\"logstash.elastic.local:9200\"] This is the Logstash configuration. It accepts data from the Winlogbeat instances on port 5044. It enriches the events with location information using the the . And finally it outputs the events to Elasticsearch. input { beats { port => 5044 } } filter { geoip { source => \"[event_data][IpAddress]\" } } output { elasticsearch { hosts => \"logstash.elastic.local:9200\" manage_template => false index => \"%{[@metadata][beat]}-%{+YYYY.MM.dd}\" document_type => \"%{[@metadata][type]}\" } } And because we are indexing a new field in our events we need to enhance the Elasticserach index template used for the Winlogbeat data. Install this template to Elasticsearch before indexing events containing the geoip fields. PUT _template\/winlogbeat_1 { \"order\": 1, \"template\": \"winlogbeat-*\", \"mappings\": { \"_default_\": { \"properties\": { \"geoip\" : { \"dynamic\": true, \"properties\" : { \"ip\": { \"type\": \"ip\" }, \"location\" : { \"type\" : \"geo_point\" }, \"latitude\" : { \"type\" : \"float\" }, \"longitude\" : { \"type\" : \"float\" } } } } } } } Summary Logon (4624) and logon failure (4625) events are just two of the many events generated by Windows that can monitored, visualized, and alerted on by using the Elastic stack. There are many great resources available that explain the value that can be obtained by monitoring certain Windows event IDs. Check out from Microsoft or from the U.S. National Security Agency. The visualizations created here can be and imported directly into a Kibana. To import into Kibana click on Settings -> Objects -> Import, and then select the JSON file you downloaded. \n"}
{"index": {"_id": 618}}
{"title":"Using Elastic Graph + Kibana to Analyze Panama Papers","seo_title":"Using the Elastic Graph on Panama Papers Analysis","url":"\/blog\/using-elastic-graph-and-kibana-to-analyze-panama-papers","author":{"name":"Mark Harwood"},"date":"May 25, 2016","category":"Engineering","locales":"de-de,fr-fr,ja-jp,ko-kr","content":" The new Elastic Graph capabilities allow you to analyse connections in data. Whether it is chasing down the tangled web of offshore financial arrangements in the Panama Papers or a high-level overview of click behaviour on a busy ecommerce website, Graph technology helps bring these relationships into focus. The Graph capability is bundled as part of the commercial X-Pack plugins for the Elastic Stack and includes a Kibana app and a new Elasticsearch API. In this first Graph blog we'll take a brief look at what the combination of the Kibana app and the API can offer. Forensic analysis: Panama Papers from the offshore law firm Mossack Fonseca is one of the most explosive news stories of 2016. The records reveal that many politicians, members of royalty, the rich and their families are exploiting networks of shell companies established in secretive offshore tax regimes. Journalists and financial institutions are now intently focused on this data, but unravelling the connections can be both difficult and time consuming. The Kibana Graph app makes this process simple for anyone: Above we see the companies and individuals connected to Vladimir Putin's close friend, . \u00a0This picture was built up from a few simple steps: Selecting the datasource Initially we select \"panama\" from our list of indices and then select one or more fields whose values we want to show in the diagram. Each field can be given an icon and colour for the \"vertices\" that will appear in the diagram. Running a search Now we can run a regular free-text search to match documents containing the name of Putin's friend, \"Roldugin\". The terms found in the matching documents are shown as a network \u2014\u00a0each line representing one or more documents that connect a pair of terms.\u00a0 The journalists at the ICIJ who are curating the data have tried to give each real-world entity (person\/company\/address) a unique ID that is attached to every document that references them.\u00a0 Unfortunately people names and addresses can be awkward to match \u2014\u00a0the journalists correctly identified three documents that are connected to Person entity 12180773 but we can see that there are two other people with similar names, but they\u00a0have been assigned different identity codes. Equally there are two addresses that look similar but have been assigned different identity codes. In future blog posts, we will\u00a0talk about using the Graph API for automated entity resolution.\u00a0For now let's fix this manually with the grouping tool. Grouping vertices Using the advanced mode tools we can select, then click the group button to merge vertices. This gives us a cleaner picture. If we wanted, we could further group already grouped items e.g.\u00a0merging people with multiple identities into single vertices and then merging those into company vertices. \"Spidering out\" Now what if we wanted to see what else was connected with these entities? We can continue to explore the connections in the data using the \"+\" button on the toolbar to pull in other related entities. We can expand out the picture further by pressing \"+\" repeatedly and use selections to focus on expanding only certain areas of the graph. The undo and redo buttons are important parts of backing out of any uninteresting results. Additionally, delete and blacklist buttons allow control over which vertices are currently visible or can return. Snippets of example documents behind selected vertices can also be shown. If you'd like to explore the Panama Papers data yourself, grab a copy of , , and the then follow the index setup at Wisdom of crowds The Panama Papers are an example of a detailed \"forensic\" type investigation where each single document may represent a highly important connection. However, where the Elastic Graph technology can really shine is in its ability to summarise mass user behaviour such as the data found in click logs. Common phrases used to describe this form of analysis are mining \"collective intelligence\" or \"wisdom of crowds.\"\u00a0In these scenarios, each document by itself is not particularly interesting but the emergent patterns from many user behaviours are \u2014\u00a0they can be used to drive recommendations e.g. \"people who bought product X also tend to buy product Y.\"\u00a0In these scenarios we need to avoid the one-off documents that make spurious connections and equally avoid overly-obvious associations like people who bought product X also bought milk (most people buy milk). With this in mind the default settings that control graph exploration are tuned for identifying only the most significant associations. Let's look at a recommendation use case using the .\u00a0If we build a user-centric index, we have a single document per listener which contains an array of the music artists they like. Let's query this index for the people who like \"Chopin\" to see what else they like. The classical artists returned are obviously strongly related - clicking on a line between two vertices shows us just how many listeners share these interests. Nearly half of all Mendelssohn listeners also like Chopin. The Graph API has identified . This is an important distinction from other graph exploration technologies. Popular != Significant Let's see what happens if we open the settings tab and deliberately turn off the feature that looks for only significant connections. With the \"significant links\" checkbox unchecked let's re-run the query for Chopin listeners - the results are very different. Notice that the (globally) popular artists such as Radiohead and Coldplay have now crept into the results. Among the 5,721 Chopin fans, 1,843 of them like the Beatles. That's certainly a popular choice but what we call \"commonly common\" \u2014\u00a0like people who buy milk. When the switch for \"significant links\" is turned on we tune out noise and focus on signal \u2014\u00a0what we call the . For those from an information theory background, the TF-IDF algorithm that has powered search engines for years is based on these same principles. By reusing these relevance ranking techniques we can stay \"on topic\" when exploring connections in data. This is an important distinction from graph databases which have no concept of relevance ranking and are typically forced to employ a strategy of just deleting popular items (see the problem of \"supernodes\"). Summary Hopefully this blog has provided a quick taste of the two main usage modes for Graph: In future blog posts we'll look in more depth at specific use cases and get to grips with the Elasticsearch API used behind the scenes by the Kibana app. Stay tuned Graph fans... \n"}
{"index": {"_id": 619}}
{"title":"Logstash Lines: New Settings File, Release Packages Improvements","seo_title":"","url":"\/blog\/logstash-lines-2016-05-24","author":{"name":"Suyog Rao"},"date":"May 24, 2016","category":"Engineering","locales":"","content":" Welcome back to The Logstash Lines! In these weekly posts, we'll share the latest happenings in the world of Logstash and its ecosystem.Following projects are in progress: Monitoring: New System Stats Following up on monitoring APIs that got added in alpha1, we've enhanced to include detailed, process level information like file descriptors, cpu and memory stats. All this can be found in As part of exposing these stats, we've refactored this module for maintenance \u2014 removed boilerplate code, simplified classes to mirror API structure, etc. Plan is to merge this into alpha3 (). Release Packages This is a breaking change to make the\u00a0directory structure in LS release packages (RPM, DEB)\u00a0 to ES. As part of this work, we are also doing a much needed upgrade to our service scripts to be able to use systemd and upstart. Exploring Use Of Log4j To make improvements to logging framework used by Logstash, we are exploring a Log4j. This will allow us to do component based logging (think per-plugin), log rotation, dynamic log level setting etc. Tricky bit is to come up with a solution that works well with existing structured logging APIs used in JRuby and pure Java\u00a0(). Improve Beats Input Collaborating with the Beats team to improve performance of LS beats input. A POC of rewriting this input using an async Netty based approach has showed promising . Logstash Settings File Say hello to . This week we merged a feature to master and 5.0 which allows users to configure Logstash bootstrap settings using a yml file instead of doing it via CLI options. Please be aware that this is a breaking change in that most long form CLI options have been changed to mirror the yml dot notation. Using a settings file will un-clutter the already crowded CLI options and allow us to introduce more configurations for future features. Most importantly, we can now ship experimental features using feature flags. (). Others: \n"}
{"index": {"_id": 620}}
{"title":"Ingest Node: A Client's Perspective","seo_title":"Elastic Ingest Node: A Client's Perspective","url":"\/blog\/ingest-node-a-clients-perspective","author":{"name":"Greg Marzouka"},"date":"May 24, 2016","category":"Engineering","locales":"","content":" With the of Elasticsearch 5.0 comes a ton of new and awesome features, and if you've been paying attention then you know that one of the more prominent of these features is the new shiny .\u00a0Simply put, ingest aims to provide a lightweight solution for pre-processing and enriching documents within Elasticsearch itself before they are indexed. We aren't going to dive into the details of how ingest node works in this blog post (it is recommended that you \u00a0as a prerequisite), but instead we're going to showcase how to consume the ingest APIs from an Elasticsearch client. In these examples we're going to use , the official .NET client, but keep in mind that these concepts apply to any of the\u00a0.\u00a0So whether you're C# inclined or not, transferring this knowledge to the language of your choice should be trivial. Creating an ingestion pipelineIn Elasticsearch 5.0, all nodes are ingest nodes by default, so there's nothing to do in terms of setting up Elasticsearch.\u00a0Thus, the first step to enriching documents via an ingest node is to create an ingestion pipeline. Let's use the classic Tweet example (my apologies) and create a index in our Elasticsearch cluster with the following mapping: { \"tweets\": { \"mappings\": { \"tweet\": { \"properties\": { \"lang\": { \"type\": \"keyword\" }, \"message\": { \"type\": \"text\" }, \"retweets\": { \"type\": \"integer\", \"coerce\": false } } } } } } Here, contains the actual content of the tweet, represents the language code (, , etc...), and is the number of times the tweet has been re-tweeted. Now imagine we have the following C# type to model our documents: public class Tweet { public string Message { get: set: } public string Lang { get: set: } public string Retweets { get: set: } } Notice that is of type , and perhaps for some reason we cannot to change the type.\u00a0Well, since we set in our mapping of the field, if we try to index one of these documents, Elasticsearch is going to throw a parse exception since the incoming value will be a . So, what can we do?\u00a0Let's create a pipeline that converts our field to an before indexing it.\u00a0While we're at it, let's also uppercase our language codes since they are of type in our mapping and so case-sensitivity matters. Here's what this looks like using NEST: var client = new ElasticClient(): client.PutPipeline(\"tweet-pipeline\", p => p .Processors(ps => ps .Convert(c => c .Field(t => t.Retweets) .Type(ConvertProcessorType.Integer) ) .Uppercase(u => u .Field(t => t.Lang) ) ) ): So what we've done here is used the \u00a0to create a pipeline with the id \"tweet-pipeline\" that has two processors. A for converting from to , and an for, you guessed it, upper-casing the value of our field. Indexing documentsNow that we've created our pipeline, let's index some documents using the bulk API and enrich them through the pipeline. client.Bulk(b => b .Index(\"tweets\") .Pipeline(\"tweet-pipeline\") .Index(i => i .Document(new Tweet { Retweets = \"4\", Message = \"Hello, Twitter!\", Lang = \"en\" }) ) .Index(i => i .Document(new Tweet { Retweets = \"32\", Message = \"Bonjour, Twitter!\", Lang = \"fr\" }) ) .Index(i => i .Document(new Tweet { Retweets = \"\", Message = \"Hallo, Twitter !\", Lang = \"nl\" }) ) ): Business as usual, except notice we specified a pipeline.\u00a0This tells Elasticsearch we want to pre-process each document using the \"tweets-pipeline\" we created earlier before indexing. Here we specified the pipeline for all index commands, but we could specify a different pipeline for each individual index command if we had multiple pipelines. Handling errorsIf we inspect the response from our bulk request: { \"took\" : 33, \"ingest_took\" : 4, \"errors\" : true, \"items\" : [ { \"index\" : { \"_index\" : \"tweets\", \"_type\" : \"tweet\", \"_id\" : \"AVSl-cCKVD5bKRQTTXNo\", \"_version\" : 1, \"_shards\" : { \"total\" : 2, \"successful\" : 1, \"failed\" : 0 }, \"created\" : true, \"status\" : 201 } }, { \"index\" : { \"_index\" : \"tweets\", \"_type\" : \"tweet\", \"_id\" : \"AVSl-cCKVD5bKRQTTXNp\", \"_version\" : 1, \"_shards\" : { \"total\" : 2, \"successful\" : 1, \"failed\" : 0 }, \"created\" : true, \"status\" : 201 } }, { \"index\" : { \"_index\" : \"tweets\", \"_type\" : \"tweet\", \"_id\" : null, \"status\" : 400, \"error\" : { \"type\" : \"illegal_argument_exception\", \"reason\" : \"unable to convert [] to integer\", \"caused_by\" : { \"type\" : \"number_format_exception\", \"reason\" : \"For input string: \\\"\\\"\" } } } } ] } We'll notice that our last document failed.\u00a0Why? Well if we take a look at the document we tried to index we'll notice that the value was an empty string and our convert processor didn't know what to do with it. We can address this by telling our processor what to do when it encounters a failure.\u00a0Each processor has an property, which accepts more processors that it will execute when an error occurs. These nested processors themselves also have an property which you can further nest error handling, and so on and so forth.\u00a0Also, the pipeline itself has its' own which you can set as a \"catch all\" error handler for the entire pipeline. For our example, let's just update our processor and add a \u00a0to that will set to if it fails to convert the original value. client.PutPipeline(\"tweet-pipeline\", p => p .Processors(ps => ps .Uppercase(u => u .Field(twt => t.Lang) ) .Convert(c => c .Field(twt => twt.Retweets) .Type(ConvertProcessorType.Integer) .OnFailure(f => f .Set(s => s .Field(t => t.Retweets) .Value(0) ) ) ) ) ): If we index the document again (this time just using the index API), we'll get a back from Elasticsearch: client.Index(new Tweet { Retweets = \"\", Message = \"Hallo, Twitter !\", Lang = \"nl\" }, i => i .Index(\"tweets\") .Pipeline(\"tweet-pipeline\") ): Now let's take a look at the documents in our index: \"hits\": [ { \"_index\": \"tweets\", \"_type\": \"tweet\", \"_id\": \"AVSmDI7jVD5bKRQTTXin\", \"_score\": 1, \"_source\": { \"retweets\": 32, \"message\": \"Bonjour, Twitter!\", \"lang\": \"FR\" } }, { \"_index\": \"tweets\", \"_type\": \"tweet\", \"_id\": \"AVSmDJB6VD5bKRQTTXio\", \"_score\": 1, \"_source\": { \"retweets\": 0, \"message\": \"Hallo, Twitter !\", \"lang\": \"NL\" } }, { \"_index\": \"tweets\", \"_type\": \"tweet\", \"_id\": \"AVSmDI7jVD5bKRQTTXim\", \"_score\": 1, \"_source\": { \"retweets\": 4, \"message\": \"Hello, Twitter!\", \"lang\": \"EN\" } } ] All of our language codes are uppercase and retweets for our has been set to ! That is \u2014 in a nutshell \u2014\u00a0ingest node. Client considerationsDedicated ingest nodesSince Elasticsearch will automatically reroute ingest requests to ingest nodes, you don't have to specify or configure any routing information. However, if you're doing heavy ingestion and have dedicated ingest nodes, it makes sense to send index requests to these nodes directly, to avoid any extra hops in the cluster. The simplest way to achieve this with any Elasticsearch client is to create a dedicated \"indexing\" client instance, and use it for indexing requests: var pool = new StaticConnectionPool(new [] { new Uri(\"http:\/\/ingestnode1:9200\"), new Uri(\"http:\/\/ingestnode2:9200\"), new Uri(\"http:\/\/ingestnode3:9200\") }): var settings = new ConnectionSettings(pool): var indexingClient = new ElasticClient(settings): Increasing timeoutsWhen a pipeline is specified, there is an added overhead of document enrichment when indexing a document. For large bulk requests, you might need to increase the default indexing timeout () to avoid exceptions. Keep in mind, that the client may have its own request timeout \u2014\u00a0this should be increased as well, at least to the same value as the Elasticsearch timeout. client.Bulk(b => b .Index(\"tweets\") .Pipeline(\"tweet-pipeline\") .Timeout(\"5m\") \/\/ Increases the bulk timeout to 5 minutes .Index(\/*snip*\/) .Index(\/*snip*\/) .Index(\/*snip*\/) .RequestConfiguration(rc => rc .RequestTimeout(TimeSpan.FromMinutes(5)) \/\/ Increases the request timeout to 5 minutes ) ): ConclusionIn this post I've covered the basics of the new ingest node feature coming in Elasticsearch 5.0 and how to consume the ingest APIs from an Elasticsearch language client. I've only scratched the surface though, so I highly recommend and watching the talk from Elastic{ON}16. NEST supports the ingest node APIs since the release and will work against any Elasticsearch 5.0.0 alpha release. Try it out and what you think! \n"}
{"index": {"_id": 621}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-05-23","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-05-23","author":{"name":"Michael McCandless"},"date":"May 23, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsUnwittingly using deprecated features in #elasticsearch? Maybe not for much longer \u2014 Chris Earle (@) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole Elastic ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 622}}
{"title":"From Splunk to Elastic in 4 weeks \u2013 Challenge Accepted!","seo_title":"From Splunk to Elastic in 4 weeks \u2013 Challenge Accepted!","url":"\/blog\/from-splunk-to-elastic-in-4-weeks-challenge-accepted","author":{"name":"Kevin Moore"},"date":"May 23, 2016","category":"User Stories","locales":"","content":" Like a lot of companies, invested heavily in log aggregation and analysis, which\u00a0quickly became an absolutely critical tool, both from an operational perspective and\u00a0also for the development teams.\u00a0And Splunk became the go-to place to find answers to many questions relating to performance and what was going on in the systems. Paddy Power sees double digit growth year on year and not surprisingly we rather\u00a0quickly hit our daily license limits in what we were indexing in Splunk. We got a temporary increase while a budget request was submitted for a license increase. That request was rejected so I was set a challenge to build an alternative to Splunk that not only provides the functionality we were so used to, but do it for a fraction of the cost \u2013 thankfully the fraction was not specified! And to have\u00a0production logs in this new system within six\u00a0weeks, which was more like four\u00a0weeks as it was just before Christmas. My team had previously looked into other log analysis platforms and had built and evaluated the various different tools. We had concluded that the only product that would meet our needs was the Elastic Stack. This meant we could use our limited time in building a solution to start with the straight away, and not need another POC phase. We knew we could set up an Elastic Stack ourselves, but we also knew this would not be fit for Paddy Power's purpose and wouldn\u2019t have a chance of scaling, so we needed help from the experts. I decided to go directly to the source and contacted Elastic. We had a few calls to discuss what we wanted as a solution and signed on the dotted line for a 10-node cluster. The goal was to scale this as we migrated more and more to the Elastic Stack. We also took an eight-day consultancy package with the aim of having our cluster production ready by the end of it. I had one full-time employee\u00a0dedicated to work with the Elastic consultant and an extra person available to help out when needed. Even though we ran into some challenges in the build phase, at the end of those eight\u00a0days, we were indexing production logs for the specified application in parallel in both the Elastic Stack and Splunk. We confirmed that searches were returning the same results in both stacks and replicated the dashboards the users were so fond of. The build can only be described as manic. We helped Elastic re-write Puppet modules, found bugs in the latest Filebeat and were running on pretty much Betas of every stack. But it was a hugely entertaining and rewarding two weeks. Due to the tight timelines, we didn\u2019t have time to procure dedicated hardware so we plonked the entire stack on virtual machines. We knew there would be performance issues with this but we ended up seeing massive lag during our peak times. We engaged with Elastic as running on virtual machines was not the only contributing factor. We identified performance bottlenecks in our implementation of Logstash and other various components in the Elastic Stack. I have never been so impressed with Elastic support as I was when we had calls with the original authors of Filebeat, Logstash, and other Elastic Stack components. We had new agents custom written and these improvements were merged back to the master branch so hopefully people reading this are enjoying those improvements and bug fixes!Due to the migration, the second phase of the project was dedicated to hardware and migrating other applications into the Elastic Stack, but since our merger with Betfair, we are about to look into the Elastic Stack as a solution for the entire combined organisation! I can\u2019t give a higher compliment than that! , Systems Engineering Manager in PaddyPower Betfair. I have been with Paddy Power for 5 years and started as a Senior Linux Admin. My team is responsible for the almost 8000 *nix systems that run the Paddy Power website, mobile apps as well as internal apps and tools. We help the business deliver stable, reliable and scalable features at pace and are responsible for a plethora of the usual tools and applications you would expect to find in an engineering\/DevOps team. \n"}
{"index": {"_id": 623}}
{"title":"Elasticsearch for Apache Hadoop 2.3.2 released","seo_title":"","url":"\/blog\/es-hadoop-2-3-2-released","author":{"name":"Costin Leau"},"date":"May 18, 2016","category":"Releases","locales":"","content":" I am pleased to announce the release of Elasticsearch for Apache Hadoop (aka ES-Hadoop) . ES-Hadoop 2.3.2 is a bug-fix release, addressing handling on Hive, introducing a couple of options for Kerberos configurations for repository hdfs plugin and also upgrading the Elasticsearch dependency to . Feedback Looking forward to hearing your feedback on these ! You can find us on , Twitter () or the . works too. \n"}
{"index": {"_id": 624}}
{"title":"Count with us: Beats 1.2.3 released","seo_title":"","url":"\/blog\/beats-1-2-3-released","author":{"name":"Tudor Golubenco"},"date":"May 18, 2016","category":"Releases","locales":"","content":" We\u2019re happy to announce that the 1.2.3 bug fix release is now available for all the Elastic Beats: Filebeat, Packetbeat, Topbeat and Winlogbeat. You can download the new versions from the usual . You can find the full release notes . Fix Filebeat sending duplicate logs of rotated files on restart This fixes an where Filebeat didn\u2019t record the file offset on shutdown of rotated files. This could cause resending of already shipped files on restart. Note that while the bug is fixed with the 1.2.3 release, the duplicates can still happen one time only on the upgrade from 1.2.2. Fix Topbeat high CPU usage on Windows Before this release, Topbeat could cause on Windows when using a custom regular expression pattern to filter processes. The root cause was that the caching that we were using for command lines (getting the command line is fairly expensive on Windows) wasn\u2019t working when most of the processes were filtered out. Fix Winlogbeat panic on large events Messages larger than 32K could cause Winlogbeat to crash on Windows XP or Windows 2003. There are more details in this . Easy as 1, 2, 3Many thanks to our dear community members who tested the Beats, reported and helped with the troubleshooting of the above issues. If you find any issues with the new release or there are features that you miss, please interact with us on Discuss or GitHub. \n"}
{"index": {"_id": 625}}
{"title":"Elasticsearch 2.3.3 released","seo_title":"Elasticsearch 2.3.3 released","url":"\/blog\/elasticsearch-2-3-3-released","author":{"name":"Clinton Gormley"},"date":"May 18, 2016","category":"Releases","locales":"","content":" Today we are pleased to announce the bug fix release of based on . All users of 2.3.x are advised to upgrade. This release is already available on , our Elasticsearch-as-a-service platform.Latest stable release:Full details of the changes in this release are available in the release notes listed above, but some of the more important changes are mentioned below: \n"}
{"index": {"_id": 626}}
{"title":"Kibana 4.5.1 and 4.1.7 Released","seo_title":"Kibana 4.5.1 and 4.1.7 Released","url":"\/blog\/kibana-4-5-1-and-4-1-7","author":{"name":"Court Ewing"},"date":"May 18, 2016","category":"Releases","locales":"","content":" Today, we\u2019re releasing Kibana patch versions 4.5.1 and 4.1.7 that include an updated version of Node.js with a fix for a high severity vulnerability in OpenSSL (). We recommend any users that have configured Kibana to use TLS\/SSL to upgrade as soon as possible. You can grab the latest versions from the page. \n"}
{"index": {"_id": 627}}
{"title":"Elastic, Yale, and the Quest to Cure Cancer","seo_title":"Elastic, Yale, and the Quest to Cure Cancer","url":"\/blog\/elastic-yale-and-the-quest-to-cure-cancer","author":{"name":"Daniel Palay"},"date":"May 18, 2016","category":"User Stories","locales":"","content":" The date was December 4, 2014, and we had just launched the Call for Papers for our first ever Elastic{ON}. I didn't really know what to expect and then boom, an email hits my inbox from Dr. Wade Schulz of the Yale Department of Laboratory Medicine: Hold up \u2014 did I just read that our software was being used to help to find causes and treatments for cancer?! This realization was and continues to be one of my proudest moments working for Elastic. (Now I couldn't sleep because I needed to know these answers.)So we invited Wade to join us at Elastic{ON}. His pinpoint exact DNA variants that led to higher cancer risk or treatment possibilities was the perfect fit for the conference. The standing-room only crowd got a great mix of technical, biological, and medical knowledge and I walked away wanting more.Luckily Elastic{ON} was only the beginning of a beautiful friendship with Wade. Over the next several months we stayed in touch hoping to see how their Elastic Stack use case evolved and what their final research produced. Then, in November 2015, Wade invited me and Elastic videographer Ben Ferrer \u2014 my partner-in-storytelling-crime \u2014 to Yale New Haven Hospital. Wade gave us front-row seats to see firsthand how the Elastic Stack is helping power the next generation technology they are using to help find a cure for cancer. We had the camera rolling for nearly four hours, our attention and curiosity entranced by their work.As a science nerd, I spent the day geeking out about the machines we saw in action and the discoveries that I saw possible. But even more, as a human \u2014 and one who has lost a mother to cancer \u2014 I was humbled by the work being done and the hope that emanated from those halls. It's the kind of hope that our world needs right now: hope for treatments that give patients their lives back, that give parents more time with their kids, friends more time with their loved ones, and hope that once and for all, the power of human ingenuity will win, and cancer will most definitely lose.This is not the end of the journey (nor my friendship with Wade). But for now, I hope you enjoy the story (so far) of how the Elastic Stack is powering the search for cancer's cure\u2026 \n"}
{"index": {"_id": 628}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-05-17","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-05-17","author":{"name":"Michael McCandless"},"date":"May 17, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsVideo of my \"Ingest Node: (re)indexing and enriching documents within #elasticsearch\" talk given at #DevCon16 is up \u2014 Luca Cavanna (@) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole Elastic ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 629}}
{"title":"Brewing in Beats: disk IO status","seo_title":"","url":"\/blog\/brewing-in-beats-disk-io-status","author":{"name":"Monica Sarbu"},"date":"May 17, 2016","category":"Brewing in Beats","locales":"","content":" Welcome to Brewing in Beats! With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources. Last week we mostly worked on improving Metricbeat and reorganizing the configuration files of all our Beats.\u00a0Here are the most interesting pull requests that were merged in master: Monitor disk IO with Metricbeat Adding disk IO information was a very requested feature in Topbeat and is finally available in the system module of Metricbeat. Currently it works on Linux, Windows, and FreeBSD (amd64). Standardize the exported fields We decided to use the same format of the exported fields for all our Beats and the dot notation in Metricbeat `moduleName.metricSetName` (the dot is actually a sub-document) instead of `moduleName-metricSetName`. We are planning also to standardize the metric names and follow the rules: Refactor the configuration files The Beats are now following the format of the Elasticsearch yml configuration file in using the that makes the configuration file more robust as it doesn\u2019t rely so much on indentation. The change affects all the configuration files, but it doesn\u2019t break compatibility as the old way of writing is still accepted. The configuration files are containing all the options that can be configured, so they are bit too long. We decided to add a of the configuration file for each Beat. The short version would become the default configuration file and the long version would serve as a guide for more configuration options. Other Metricbeat improvements Proper shutdown in Filebeat Clean shutdown for all Beats is an important prerequisite for features like configuration reloading and running multiple beats in a single process. It is also important for our test suite. This \u00a0refactors the Filebeat code to make sure it shutdowns correctly. Deprecate GeoIP support One of the older Packetbeat features is that you can visualize the location of your clients on a map in Kibana based on the GeoIP information of the source IPs of the incoming HTTP requests. While this is a very appreciated feature, doing GeoIP lookups in Packetbeat is not needed, because you can better do it using Logstash or the Ingest Node in Elasticsearch (new in 5.0). So, we the GeoIP in 5.0. Switch to Perl like regular expressions We found some limitations in the current use of our regular expression engine () due to using the POSIX subset only, so we decided to closer in 5.0 to support same general regular expression syntax used by Perl, Python and other languages. \n"}
{"index": {"_id": 630}}
{"title":"Logstash Lines: Java Event updates, 5.0 features","seo_title":"Logstash Lines: Java Event updates, 5.0 features","url":"\/blog\/logstash-lines-2016-05-16","author":{"name":"Suyog Rao"},"date":"May 16, 2016","category":"The Logstash Lines","locales":"","content":" Welcome back to The Logstash Lines! In these weekly posts, we'll share the latest happenings in the world of Logstash and its ecosystem.JSON Logging is backBack in the day, Logstash used to emit its logs in JSON format. Because of endless encoding issues and crashes in logger framework, we had to roll it back. We've worked through most of these issues, so we're bringing structured logging back. For 5.0, you can tell LS to switch to JSON logging by using the CLI flag\u00a0().Java EventThe new have been merged to master. This seems trivial, but it required a delicate dance of making sure existing plugins used the old API while at the same time updating plugins to use the new, unpublished core code. Plus, we had to untangle the dependency requirements between plugins. Our main goal was to minimize failures in CI and not to unnecessarily publish gems while all this was happening. What followed was a plugins . 80+ plugins (bundled in LS core) were updated with the new setter\/getter APIs in about 3 days. Plugins tests are passing locally. We are now mass publishing these plugins so its compatible with 5.0.Next up, is phase 2, where we update the remaining non-packaged plugins and then we call this project doneRelease Packages ImprovementsWork is in progress to make improvements to our release artifacts. Firstly, we are changing the of rpm, deb packages to match Elasticsearch packages. This will provide a consistent user experience across our stack. Next, we'll be using and to LS service. They have more advanced features than , and make service scripts easier.\u00a0While we're at it, we're creating a separate JVM options file \u2014 to centralize all the JVM flags \u2014 just like ES did\u00a0().Persistence Investigating the use of for serializing\/deserializing Event objects into the disk backed queue.\u00a0Initial work on rewriting the mmap based queues (which was once written in JRuby) in Java using the new .Dynamic Config Reload BugA user reported symptoms of \u201cresource leak\u201d while using the dynamic config reloading feature. After much tricky debugging and chasing, turns out the problem was in usage of ivars in Logstash. The JRuby team explained internal details of how ivar is implemented and how it can grow \u2014 in our usage pattern \u2014 to ultimately cause a slowdown. Another good example of collaboration between JRuby team and us. Fix is in progress on our side and a new release (2.3.3) will be cut soon.RabbitMQ EnhancementsOthers \n"}
{"index": {"_id": 631}}
{"title":"How To Centralize Logs with Rsyslog, Logstash, and Elasticsearch on Ubuntu 14.04","seo_title":"How To Centralize Logs with Rsyslog, Logstash, and Elasticsearch on Ubuntu 14.04","url":"\/blog\/how-to-centralize-logs-with-rsyslog-logstash-and-elasticsearch-on-ubuntu-14-04","author":{"name":"Aaron Mildenstein"},"date":"May 16, 2016","category":"Engineering","locales":"","content":" IntroductionMaking sense of the millions of log lines your organization generates can be a daunting challenge. On one hand, these log lines provide a view into application performance, server performance metrics, and security. On the other hand, log management and analysis can be very time consuming, which may hinder adoption of these increasingly necessary services. Open-source software, such as , , and provide the tools to transmit, transform, and store your log data. In this tutorial, you will learn how to create a centralized rsyslog server to store log files from multiple systems and then use Logstash to send them to an Elasticsearch server. From there, you can decide how best to analyze the data. GoalsThis tutorial teaches you how to centralize logs generated or received by syslog, specifically the variant known as . Syslog, and syslog-based tools like rsyslog, collect important information from the kernel and many of the programs that run to keep UNIX-like servers running. As syslog is a standard, and not just a program, many software projects support sending data to syslog. By centralizing this data, you can more easily audit security, monitor application behavior, and keep track of other vital server information. From a centralized, or aggregating rsyslog server, you can then forward the data to Logstash, which can further parse and enrich your log data before sending it on to Elasticsearch. The final objectives of this tutorial are to: PrerequisitesIn the same data center, create the following servers with : You will also need a non-root user with sudo privileges for each of these servers. To maximize performance, Logstash will try to allocate 1 gigabyte of memory by default, so ensure the centralized server instance is sized accordingly. Step 1 \u2014 Determining Private IP AddressesIn this section, you will determine which private IP addresses are assigned to each server. This information will be needed through the tutorial. On each server, find its IP addresses with the command: sudo ifconfig -a The option is used to show all interfaces. The primary Ethernet interface is usually called . In this case, however, we want the IP from , the IP address. These private IP addresses are not routable over the Internet and are used to communicate in private LANs \u2014 in this case, between servers in the same data center over secondary interfaces. The output will look similar to: eth0 Link encap:Ethernet HWaddr 04:01:06:a7:6f:01 inet addr:123.456.78.90 Bcast:123.456.78.255 Mask:255.255.255.0 inet6 addr: fe80::601:6ff:fea7:6f01\/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:168 errors:0 dropped:0 overruns:0 frame:0 TX packets:137 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:18903 (18.9 KB) TX bytes:15024 (15.0 KB) eth1 Link encap:Ethernet HWaddr 04:01:06:a7:6f:02 inet addr:10.128.2.25 Bcast:10.128.255.255 Mask:255.255.0.0 inet6 addr: fe80::601:6ff:fea7:6f02\/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:6 errors:0 dropped:0 overruns:0 frame:0 TX packets:5 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:468 (468.0 B) TX bytes:398 (398.0 B) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1\/128 Scope:Host UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) The section to note here is and within that . In this case, the private network address is . This address is only accessible from other servers, within the same region, that have private networking enabled. Be sure to repeat this step for all 3 servers. Save these private IP addresses somewhere secure. They will be used throughout this tutorial. Step 2 \u2014 Setting the Bind Address for ElasticsearchWe will bind Elasticsearch to its private IP address. On the Elasticsearch server, edit the configuration file: sudo nano \/etc\/elasticsearch\/elasticsearch.yml Find the line that contains . If it is commented out, uncomment it by removing the character at the beginning of the line. Change the value to the private IP address for the Elasticsearch server so it looks like this: network.bind_host: private_ip_address Finally, restart Elasticsearch to enable the change. sudo service elasticsearch restart Step 3 \u2014 Configuring the Centralized Server to Receive DataIn this section, we will configure the to be the server able to receive data from other syslog servers on port 514. To configure the to receive data from other syslog servers, edit on the : sudo nano \/etc\/rsyslog.conf Find these lines already commented out in your : # provides UDP syslog reception #$ModLoad imudp #$UDPServerRun 514 # provides TCP syslog reception #$ModLoad imtcp #$InputTCPServerRun 514 The first lines of each section ( and ) load the and modules, respectively. The stands for nput odule , and stands for nput odule . These modules listen for incoming data from other syslog servers. The second lines of each section ( and ) indicate that rsyslog should start the respective UDP and TCP servers for these protocols listening on port 514 (which is the syslog default port). To enable these modules and servers, uncomment the lines so the file now contains: # provides UDP syslog reception $ModLoad imudp $UDPServerRun 514 # provides TCP syslog reception $ModLoad imtcp $InputTCPServerRun 514 Save and close the rsyslog configuration file. Restart rsyslog by running: sudo service rsyslog restart Your centralized rsyslog server is now configured to listen for messages from remote syslog (including rsyslog) instances. To validate your rsyslog configuration file, you can run the command. Step 4 \u2014 Configuring rsyslog to Send Data RemotelyIn this section, we will configure the to send log data to the we configured in the last step. In a default rsyslog setup on Ubuntu, you\u2019ll find two files in : On the , edit the default configuration file: sudo nano \/etc\/rsyslog.d\/50-default.conf Add the following line at the top of the file before the section, replacing \u00a0with the IP of your server: *.* @private_ip_of_ryslog_server:514 Save and exit the file. The first part of the line () means we want to send all messages. While it is outside the scope of this tutorial, you can configure rsyslog to send only certain messages. The remainder of the line explains how to send the data and where to send the data. In our case, the symbol before the IP address tells rsyslog to use UDP to send the messages. Change this to to use TCP. This is followed by the private IP address of with rsyslog and Logstash installed on it. The number after the colon is the port number to use. Restart rsyslog to enable the changes: sudo service rsyslog restart Congratulations! You are now sending your syslog messages to a centralized server! To validate your rsyslog configuration file, you can run the command. Step 5 \u2014 Formatting the Log Data to JSONElasticsearch requires that all documents it receives be in JSON format, and rsyslog provides a way to accomplish this by way of a template. In this step, we will configure our centralized rsyslog server to use a JSON template to format the log data before sending it to Logstash, which will then send it to Elasticsearch on a different server. Back on the server, create a new configuration file to format the messages into JSON format before sending to Logstash: sudo nano \/etc\/rsyslog.d\/01-json-template.conf Copy the following contents to the file exactly as shown: template(name=\"json-template\" type=\"list\") { constant(value=\"{\") constant(value=\"\\\"@timestamp\\\":\\\"\") property(name=\"timereported\" dateFormat=\"rfc3339\") constant(value=\"\\\",\\\"@version\\\":\\\"1\") constant(value=\"\\\",\\\"message\\\":\\\"\") property(name=\"msg\" format=\"json\") constant(value=\"\\\",\\\"sysloghost\\\":\\\"\") property(name=\"hostname\") constant(value=\"\\\",\\\"severity\\\":\\\"\") property(name=\"syslogseverity-text\") constant(value=\"\\\",\\\"facility\\\":\\\"\") property(name=\"syslogfacility-text\") constant(value=\"\\\",\\\"programname\\\":\\\"\") property(name=\"programname\") constant(value=\"\\\",\\\"procid\\\":\\\"\") property(name=\"procid\") constant(value=\"\\\"}\\n\") } Other than the first and the last, notice that the lines produced by this template have a comma at the beginning of them. This is to maintain the JSON structure help keep the file readable by lining everything up neatly. This template formats your messages in the way that Elasticsearch and Logstash expect to receive them. This is what they will look like: { \"@timestamp\" : \"2015-11-18T18:45:00Z\", \"@version\" : \"1\", \"message\" : \"Your syslog message here\", \"sysloghost\" : \"hostname.example.com\", \"severity\" : \"info\", \"facility\" : \"daemon\", \"programname\" : \"my_program\", \"procid\" : \"1234\" } The show the variables available from rsyslog if you would like to custom the log data. However, you must send it in JSON format to Logstash and then to Elasticsearch. The data being sent is not using this format yet. The next step shows out to configure the server to use this template file. Step 6 \u2014 Configuring the Centralized Server to Send to LogstashNow that we have the template file that defines the proper JSON format, let\u2019s configure the centralized rsyslog server to send the data to Logstash, which is on the same server for this tutorial. At startup, rsyslog will look through the files in and create its configuration from them. Let\u2019s add our own configuration file to extended the configuration. On the , create : sudo nano \/etc\/rsyslog.d\/60-output.conf Copy the following lines to this file: # This line sends all lines to defined IP address at port 10514, # using the \"json-template\" format template *.* @private_ip_logstash:10514: json-template The at the beginning means to process the remainder of the line for all log messages. The symbols means to use UDP (Use to instead use TCP). The IP address or hostname after the is where to forward the messages. In our case, we are using the private IP address for since the rsyslog centralized server and the Logstash server are installed on the same server. The port number is next. This tutorial uses port 10514. Note that the Logstash server must listen on the same port using the same protocol. The last part is our template file that shows how to format the data before passing it along. Do not restart rsyslog yet. First, we have to configure Logstash to receive the messages. Step 7 \u2014 Configure Logstash to Receive JSON MessagesIn this step you will install Logstash, configure it to receive JSON messages from rsyslog, and configure it to send the JSON messages on to Elasticsearch. Logstash requires Java 7 or later. Next, install the security key for the Logstash repository: wget -qO - https:\/\/packages.elastic.co\/GPG-KEY-elasticsearch | sudo apt-key add - Add the repository definition to your file: echo \"deb http:\/\/packages.elastic.co\/logstash\/2.3\/debian stable main\" | sudo tee -a \/etc\/apt\/sources.list Use the method described above to add the Logstash repository. Do not use as it will add a entry as well, but Elastic does not provide a source package. This will result in an error when you attempt to run . Update your package lists to include the Logstash repository: sudo apt-get update Finally, install Logstash: sudo apt-get install logstash Now that Logstash is installed, let\u2019s configure it to listen for messages from rsyslog. The default installation of Logstash looks for configuration files in . Edit the main configuration file: sudo nano \/etc\/logstash\/conf.d\/logstash.conf Then, add these lines to : # This input block will listen on port 10514 for logs to come in. # host should be an IP on the Logstash server. # codec => \"json\" indicates that we expect the lines we're receiving to be in JSON format # type => \"rsyslog\" is an optional identifier to help identify messaging streams in the pipeline. input { udp { host => \"logstash_private_ip\" port => 10514 codec => \"json\" type => \"rsyslog\" } } # This is an empty filter block. You can later add other filters here to further process # your log lines filter { } # This output block will send all events of type \"rsyslog\" to Elasticsearch at the configured # host and port into daily indices of the pattern, \"rsyslog-YYYY.MM.DD\" output { if [type] == \"rsyslog\" { elasticsearch { hosts => [ \"elasticsearch_private_ip:9200\" ] } } } The syslog protocol is UDP by definition, so this configuration mirrors that standard. In the input block, set the Logstash host address by replacing with the private IP address of , which also has Logstash installed on it. The input block configure Logstash to listen on port so it won\u2019t compete with syslog instances on the same machine. A port less than 1024 would require Logstash to be run as root, which is not a good security practice. Be sure to replace with the of your Elasticsearch server. The output block shows a simple configuration. Its object is to only allow matching events through. In this case, that is only events with a \u201ctype\u201d of \u201crsyslog\u201d. Test your Logstash configuration changes: sudo service logstash configtest It should display if there are no syntax errors. Otherwise, try and read the error output to see what\u2019s wrong with your Logstash configuration. When all these steps are completed, you can start your Logstash instance by running: sudo service logstash start Also restart rsyslog on the same server since it has a Logstash instance to forward to now: sudo service rsyslog restart To verify that Logstash is listening on port 10514: netstat -na | grep 10514 You should see something like this: udp6 0 0 10.128.33.68:10514 :::* You will see the private IP address of and the 10514 port number we are using to listen for rsyslog data. To troubleshoot Logstash, stop the service with and run it in the foreground with verbose messages: \/opt\/logstash\/bin\/logstash -f \/etc\/logstash\/conf.d\/logstash.conf --verbose It will contain usual information such as verifying with IP address and UDP port Logstash is using: Starting UDP listener {:address=>\"10.128.33.68:10514\", :level=>:info} Step 8 \u2014 Verifying Elasticsearch InputEarlier, we configured Elasticsearch to listen on its private IP address. It should now be receiving messages from Logstash. In this step, we will verify that Elasticsearch is receiving the log data. The and servers should be sending all their log data to Logstash, which is then passed along to Elasticsearch. Let\u2019s generate a security message to verify that Elasticsearch is indeed receiving these messages. On , execute the following command: sudo tail \/var\/log\/auth.log You will see the security log on the local system at the end of the output. It will look similar to: May 2 16:43:15 rsyslog-client sudo: sammy : TTY=pts\/0 : PWD=\/etc\/rsyslog.d : USER=root : COMMAND=\/usr\/bin\/tail \/var\/log\/auth.log May 2 16:43:15 rsyslog-client sudo: pam_unix(sudo:session): session opened for user root by sammy(uid=0) With a simple query, you can check Elasticsearch: Run the following command on the Elasticsearch server or any system that is allowed to access it. Replace with the private IP address of the Elasticsearch server. This IP address must also be the one you configured Elasticsearch to listen on earlier in this tutorial. curl -XGET 'http:\/\/elasticsearch_ip:9200\/_all\/_search?q=*&pretty' In the output you will see something similar to the following: { \"_index\" : \"logstash-2016.05.04\", \"_type\" : \"rsyslog\", \"_id\" : \"AVR8fpR-e6FP4Elp89Ww\", \"_score\" : 1.0, \"_source\":{\"@timestamp\":\"2016-05-04T15:59:10.000Z\",\"@version\":\"1\",\"message\":\" sammy : TTY=pts\/0 : PWD=\/home\/sammy : USER=root : COMMAND=\/usr\/bin\/tail \/var\/log\/auth.log\",\"sysloghost\":\"rsyslog-client\",\"severity\":\"notice\",\"facility\":\"authpriv\",\"programname\":\"sudo\",\"procid\":\"-\",\"type\":\"rsyslog\",\"host\":\"10.128.33.68\"} }, Notice that the name of the server that generated the rsyslog message is in the log (). With this simple verification step, your centralized rsyslog setup is complete and fully operational! ConclusionYour logs are in Elasticsearch now. What\u2019s next? Consider reading up on what can do to visualize the data you have in Elasticsearch, including line and bar graphs, pie charts, maps, and more. explains how to use Kibana web interface to search and visualize logs. Perhaps your data would be more valuable with further parsing and tokenization. If so, then learning more about will help you achieve that result. \n"}
{"index": {"_id": 632}}
{"title":"Using Elastic Graph to Analyze #Trump Data","seo_title":"Using Elastic Graph to Analyze #Trump Data","url":"\/blog\/using-elastic-graph-to-analyze-trump-data","author":{"name":"Jack Lawton"},"date":"May 12, 2016","category":"User Stories","locales":"","content":" In this blog, I will discuss how I've used , a new Elastic X-Pack plugin for\u00a0Elasticsearch and Kibana, to explore relationships in Twitter data based on Donald Trump's political campaign. Straight away Graph shows us popular hashtags associated with the Trump presidential campaign and links those which are frequently seen together. In contrast searching the hashtag \u201c#Cruz\u201d for the dataset gives a completely different impression. Using the advanced features of Graph, not only can we assess links between hashtags and other hashtags but also links between hashtags and other data fields. For my case, a good example of this is to categorise America by time-zone, splitting our sample into three groups we can see what hashtags are most commonly associated with each of these time-zones. The data fields provided by Logstash have a vast potential for gaining insight on topics that may be very difficult to understand otherwise, like I have studied hashtags here we can also look at the raw content of the tweets and common associated words, as well as the words Twitter users use to describe themselves! However, one place where the standard Logstash Twitter feed falls short is Twitter followers. What if I want to know what users are popular in a subject and who people who follow them also tend to follow? Fortunately, Logstash can read in pretty much any file, so it\u2019s pretty easy to use the Twitter API to bring down the data we\u2019re interested in and pass it to Logstash. Straight away, we can build up a graph showing common following trends, the thickness of the lines shows the strength of the links. Clearly Graph is a powerful tool for identifying key, associated and similar users quickly and easily. A subtle issue that can come about in graph analysis is results being dominated by repeated data from one source. For example, if one user tweets one hundred times more than another then their description will be weighted one hundred times stronger, such as when I search for the term \u201crepublican\u201d in user descriptions: Here at first glance the results seem good, but a couple of results seem a bit strange to see, are all Republicans cowgirls? I think it is more likely there is one Republican cowgirl who tweets very frequently. Fortunately, Graph has a solution to this issue, using the diversity field setting: one can limit the consideration given to content with the same value of a certain field. For our case it makes sense to limit this to one tweet per user ID. Repeating the analysis with this new setting gives a very different picture: Another one of the key advantages of the Graph algorithm is its ability to filter out popular \u201csuper-connected\u201d terms and identify only \u201csignificant links\u201d. This feature can be disabled if needed. For example, repeating the search for \u201crepublican\u201d without significant links, graph pulls back loads of connecting words, \u201cand\u201d, \u201cof\u201d, \u201cthe\u201d etc. these words do appear frequently with the world \u201crepublican\u201d, however they also appear frequently in descriptions without the word \u201crepublican\u201d and are hence not reflective of descriptions featuring the word. All the relationships displayed in the Kibana app are as a result of querying the Elasticsearch Graph API. The app allows you to view the raw JSON, making it easy to integrate Graph into a custom application.To get an even better idea of the power of Graph watch\u00a0\u00a0on the Elastic site, this video demonstrates the features of Graph as applied to other datasets such as Wikipedia and LastFM data. is a Technical Consultant at Aiimi, an Elastic partner specialising in information management consultancy. After studying Physics at Manchester, Jack is now exploring cutting edge data science technology to evolve Aiimi\u2019s services and meet rising demands. \n"}
{"index": {"_id": 633}}
{"title":"Just Enough Kafka for the Elastic Stack, Part 1","seo_title":"Just Enough Kafka for the Elastic Stack, Part 1","url":"\/blog\/just-enough-kafka-for-the-elastic-stack-part1","author":{"name":"Suyog Rao"},"date":"May 12, 2016","category":"Engineering","locales":"de-de,fr-fr,ja-jp,ko-kr","content":" The and\u00a0\u00a0share a tight-knit relationship in the log\/event processing realm. A number of companies use Kafka as a transport layer for storing and processing large volumes of data. In many deployments we've seen in the field, Kafka plays an important role of staging data before making its way into Elasticsearch for fast search and analytical capabilities. Through a series of blog posts, we'd like to shine more light on how to set up and manage Kafka when integrating with the Elastic Stack. Specifically, we'll\u00a0discuss our experiences operating Kafka and Logstash under high volume. For the purposes of these posts, we refer to Kafka's version. Some of the functionality has changed in Kafka's latest version, but 0.8.x is still very popular and widely used. The BasicsLet's get some basic concepts out of the way. From Kafka's : Kafka was created at LinkedIn to handle large volumes of event data. Like many other message brokers, it deals with publisher-consumer and queue semantics by grouping data into . As an application, you write to a topic and consume from a topic. An important distinction, or a shift in design with Kafka is that the complexity moves from producer to consumers, and it heavily uses the file system cache. These design decisions, coupled with it being distributed from scratch, makes it a winner in many high volume streaming use cases. Logstash integrates natively with Kafka using the . It provides both and plugins so you can read and write to Kafka from Logstash directly. The configuration to get started is pretty simple: kafka { zk_connect => \"hostname:port\" topic_id => \"apache_logs\" ... } Kafka has a dependency on , so if you are running Kafka, you'll need access to a ZooKeeper cluster. More on that later. When To Use Kafka With The Elastic Stack? Log data or event based data rarely have a consistent, predictable volume or flow rates. Consider a scenario where you upgraded an application on a Friday night (why you shouldn't upgrade on a Friday is for a different blog :) ). The app you deployed has a bad bug where information is logged excessively,\u00a0flooding\u00a0your logging infrastructure. This spike or a burst of data is fairly common in other multi-tenant use cases as well, for example, in the gaming and e-commerce industries. A message broker like Kafka is used in this scenario to protect Logstash and Elasticsearch from this surge. In this architecture, processing is typically split\u00a0into 2 separate stages \u2014 the and stages. The Logstash instance that receives data from different data sources is called a \u00a0as it doesn't do much processing. Its responsibility is to immediately persist data received to a Kafka topic, and hence,\u00a0its a producer. On the other side, a Logstash instance \u2014 a beefier one \u2014 will consume data, at its own throttled speed, while performing expensive transformations like Grok, DNS lookup and indexing into Elasticsearch. This instance is called the . While Logstash has traditionally been used as the Shipper, we strongly recommend using the suite of\u00a0 products available as\u00a0specialized shippers. Filebeat, for example, is a lightweight, resource friendly agent which can follow files and ship to Kafka via a Logstash receiver. At this time, Filebeat cannot write directly to Kafka, but starting with 5.0.0 (currently in ), you'll be able to configure Kafka as one of the outputs. This enhancement further simplifies the above architecture in use\u00a0cases that ingest data\u00a0using beats. Please try out this and other awesome new features in our , and let us know what you think! Word on the street is that\u00a0you can even win a to Elastic{ON} by helping us test these!\u00a0 Consider another scenario. You're planning to upgrade your multi-node Elasticsearch cluster from 1.7 to 2.3 which requires a full cluster restart. Or, a situation where Elasticsearch is down for a longer period of time than you expected. If you have a number of data sources streaming into Elasticsearch, and you can't afford to stop the original data sources, a message broker like Kafka could be of help here! If you use the Logstash shipper and indexer architecture with Kafka, you can continue to stream your data from edge nodes and hold them temporarily in Kafka. As and when Elasticsearch comes back up, Logstash will continue where it left off, and help you catch up to\u00a0the backlog of data. In fact, this bodes well with the Elastic nature of our software \u2014 you can temporarily increase your processing and indexing power by adding extra Logstash instances to consume from the same Kafka topic. You could additionally add extra nodes in Elasticsearch as well. Scaling horizontally without too much hand-holding is one of the core features of Elasticsearch. Once you are caught up, you can scale down to your original number of instances. Anti-pattern: When not to use Kafka with Elastic StackJust as it is good to know when to use Kafka, it is also good knowledge to know when not to use it. Everything has a cost \u2014 Kafka is yet another piece of software you need to tend to, in your production environment. This involves monitoring, reacting to alerts, upgrading and everything else that comes with running a software successfully in production. You are monitoring all your production software, aren't you? When it comes to centralized log management, there is often a blanket statement made that logs need to be shipped off your edge nodes as soon as possible. While this may be true for some use cases, ask yourself if this is really a requirement for you! If you can tolerate a relaxed search latency, you can completely skip the use of Kafka. Filebeat, which follows and ships file content from edge nodes, is resilient to log rotations. This means if your application is emitting more logs than Logstash\/Elasticsearch can ingest at real time, logs can be rotated \u2014 using\u00a0 or , for example \u2014 across files, but they will still be indexed. Of course, this brings in a separate requirement of having sufficient disk space to house these logs on your server machines. In other words, in this scenario,\u00a0your local filesystem will the temporary buffer. Design Considerations For Kafka And LogstashBelow we describe some design considerations while using Kafka with Logstash. Logstash input uses the high level Kafka consumer API and Logstash Output uses the new producer API. TopicsTopics are logical grouping of messages. They provide a way to isolate data from other consumers if necessary. Note, in 0.8 version of Kafka, there is no in-built security, so any consumer can access from any topic available on the broker. How many topics you need and how do you model your data, is, well, dependent on your data. Here are some strategies: In this case you would be creating a topic per user. Please remember that Kafka registers all partitions in ZooKeeper, so there is a cost of creating hundreds and thousands of topics. If your users are small in number \u2014 for example, departments \u2014 this strategy of partitioning per user works well. For logging and event driven data, you could also group multiple users in one topic based on attributes like data volume and expected search latency. Remember that more time events spend in the queue while not getting indexed into Elasticsearch, the longer are the latency for searching these. One solution is to create topics based on expected SLAs \u2014 \u201chigh\u201d, \u201cmedium\u201d and \u201clow\u201d topics.\u00a0Similarly based on data volume. Do you have a customer\/user who is known to produce bursty data? Give them a new topic. In a multi-tenant deployment, it's good practice to have a \u201cbursty\u201d topic, so when a user violates their data volume, or produces too much bursty data in the last X minutes\/hours, you can move them, at runtime, to this topic. This way you'll keep other topics clear of unnecessary traffic, thereby not slowing everybody down.\u00a0A good analogy here is an expressway \u2014 you mostly want the fast lane to be free flowing, so slower vehicles are expected to move to other lanes. Think of Kafka topics as lanes and events as cars!In general, separate topics per data source allows for isolation of sources. In Kafka, you can configure number of partitions per topic. This also means you can scale Logstash instances per topic. If you expect certain sources to grow to a higher volume in the future, you can always over-partition to future proof it. Topics can be on the fly when data is first published to a non-existent one, or can be manually pre-created. kafka-topics.sh --zookeeper zk_host:port --create --topic user1 --partitions 8 --replication-factor 1<\/span> PartitionsNow's a good time to talk about partitions! From Kafka's : In essence, the more partitions you have, the more throughput you get when consuming data. From the producer standpoint, Kafka provides you an option for controlling which data ends up in which partition. By default, when using Logstash, data is assigned to a partition in a round-robin fashion. By specifying the message_key in Logstash config, you can control how your data is assigned to a partition. In some cases it can be efficient to have fewer topic\/partitions to workaround the ZooKeeper limitation, but group multiple users under fixed partitions by using as . If key is specified, a partition will be chosen using a hash of the key. Another important property to be aware in Kafka is the order of messages. Kafka only guarantees message order within the same partition. So if messages from data source has no key, it gets sprayed across partitions, and Kafka will not guarantee ordering when consuming. Where data is immutable, and in particular, for logging use cases, this can be an acceptable property. If you need strong ordering, make sure that data is pinned to a single partition. Consumer Groups: Scalability And Fault ToleranceMultiple Kafka consumers which process data from similar topics form a designated by unique name in the cluster. Messages published to Kafka are distributed across instances in the group, but each message is handled by just one consumer in the group, i.e. there is no overlap. Logstash instances reading from Kafka form a consumer group with a default group ID called . You can spin up new Logstash instances at any time to scale read throughput for the subscribed topic. By default, the new Logstash instance started will join the consumer group. This process \u2014 when a new consumer joins a consumer group \u2014 triggers a in Kafka. we mentioned before that Logstash uses the high level Kafka consumer, so it delegates rebalancing logic to the Kafka library. This process automatically reassigns the partitions to current consumers based on metadata available in Zookeeper. Another reason to use multiple Logstash instances is to add fault tolerance. If one instance goes down, Kafka goes through rebalancing process and distributes assignments to existing Logstash instances. All this closely relates to setting in Logstash input. This setting controls the number of threads consuming from Kafka partitions. Ideally you should have as many threads as the number of partitions for a perfect balance \u2014 more threads than partitions means that some threads will not have anything do. Fewer threads than partition means some threads are consuming from more than one partition. Consider a scenario where topic that has 16 partitions. I could spin up one Logstash instance on an 8 core machine with this configuration: input { kafka { zk_connect => \"kafka:2181\" group_id => \"logstash\" topic_id => \"apache_logs\" consumer_threads => 16 } } Or we\u00a0could spin up 2 Logstash instances on 2 machines with set to 8 each. The latter deployment is a better choice \u2014 it fully utilizes the machine's CPU, but also adds fault tolerance in case of catastrophic failures. Usually, try to ensure that the number of partitions is a multiple of the number of Logstash threads\/instances. This ensures instances are balanced. Partitioning, similar to , means we can add more processing capacity (Logstash instances) later. Serialization FormatsKafka persists messages using byte arrays in its queue. So you can pretty much throw any format at Kafka, but in general its is recommended to use a serialization format which is compact and fast. Kafka has a way to deal with serialized message formats by specifying the in outputs, and in inputs. If you are a savvy Logstash user, you must surely be thinking about by now. It is both possible to leverage Logstash codecs as well as Kafka serializers to manage message representation into and out of Kafka topics. Other Logstash codecs that are relevant to the Kafka ecosystem are , , and . If you wish to write your own serializer\/deserializer you can do so in your favorite JVM language. Since these classes are not in Logstash's classpath, you must explicitly add the appropriate library into your java classpath export CLASSPATH=$CLASSPATH:\/path\/to\/kafkaserializers.jar: bin\/logstash -f .. Please note that decoding of messages in Logstash input is single threaded, so an expensive serialization format like json will decrease the overall performance of the pipeline. ConclusionIn this post, we've covered few basic concepts in Kafka and presented its use with the Elastic Stack. In the next post, we'll jump right into the operational aspects, and provide tips for running Kafka with Logstash. Meanwhile, if you have any questions, feel free to reach us on our or on ! Want more? Read of this series for operational and monitoring tips.\u00a0 \n"}
{"index": {"_id": 634}}
{"title":"Brewing in Beats: Metricbeat progress","seo_title":"","url":"\/blog\/brewing-in-beats-metricbeat-progress","author":{"name":"Tudor Golubenco"},"date":"May 11, 2016","category":"Brewing in Beats","locales":"","content":" Welcome to Brewing in Beats! With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources. Last week we released 5.0.0-alpha2, with several important . Apart from that, here is what we are busy with: Per process stats in Metricbeat We had a lot of back and forth on this , debating how we should best represent in Elasticsearch the metrics that are per \u201cdynamic entity\u201d. A good example of such entities are the processes in an operating system, but can also be mounted file systems or tables in an SQL database. After considering nested objects or creating dynamic fields, we went for the simpler solution of having individual objects for each entity. These objects are grouped in their own metricset. Metricbeat API refactoring In order to have a clean and stable API before adding more modules, Andrew did a lot of refactoring and documenting work on the . Configuration migration tool Between the 1.x and 5.0 there are a few configuration file changes that break compatibility. We now have a that should help with migrating existing configuration files to 5.0 format. The script doesn\u2019t do real YAML parsing, meaning that it won\u2019t work on any possible configuration file, but it should do the job in most cases. It also requires no dependencies besides python itself and preserves the comments. Zookeeper module in Metricbeat , created by Erik Redding, was into a Metricbeat module. It uses the Zookeeper command to get simple stats. Thanks Erik! Kafka output deadlock fix Due to a bug in the Go library we use for outputting to Kafka, a is possible in case infinite retries are used. In time for alpha2, a of were to this issue. We now avoid asking for infinite retries from the library and instead we simulate it in our code. Topbeat: fix high CPU usage on windows We had a couple of interesting that indicated that on Windows Topbeat uses more CPU when it is configured to monitor less processes. It turns out that the reason was failing to use the command line cache (getting the full command line is expensive on Windows) for the processes that were filtered out. The fixing PR the logic so that the command line is not read at all if the process is filtered out. Filebeat refactoring Heavy is in the Filebeat code, making the code more readable and easier to maintain. \u00a0Previously the file state was loaded from disk every time a new file was found. The state from the registry file once during startup and from the one the prospector internal in memory state is used. This is more efficient and prevents race conditions. It also makes the Registrar and the Harversters . This refactoring work is crucial for us to be able to stay on top of possible races due to all the file rotation and file systems variations. Normalize new line character after multiline In order for the regular expressions to work in a consistent way on multiline events, this makes sure is used as a line separator after multiline stitching. \n"}
{"index": {"_id": 635}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-05-09","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-05-09","author":{"name":"Michael McCandless"},"date":"May 09, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsDetecting Geo-Temporal anomalies with #Elasticsearch pipeline aggs Blog post: #gis \u2014 Dave Erickson (@) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole Elastic ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 636}}
{"title":"Where in the World is Elastic? - CodeMotion Amsterdam, DevOps Days Kiel and Oscon Austin","seo_title":"Where in the World is Elastic? - DevOpsDays Austin and PuppetCamp AU","url":"\/blog\/witwies-codemotion-amsterdam-devops-days-kiel-oscon-austin","author":{"name":"Megan Wieling"},"date":"May 09, 2016","category":"","locales":"","content":" Welcome to Find out which Elastic events and meetups are happening near you in the next two\u00a0weeks.Upcoming EventsMay 9-10: May 11-12: May 12-13: May 18-20: May 19-20:\u00a0May 14-15: May 16-19: May 18-20: May 12-14: Upcoming MeetupsMay 10:\u00a0May 11: May 12: May 17: May 18: May 10: May 11: May 17: May 19: May 15: May 15: May 18: That's it for this week. Stay tuned next week for more Elastic happenings.- The Elastic TeamP.S.\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}
{"index": {"_id": 637}}
{"title":"There are two hard problems in .NET, caching expressions and naming things","seo_title":"","url":"\/blog\/nest-2-3-1-released","author":{"name":"Martijn Laarman"},"date":"May 04, 2016","category":"Engineering","locales":"","content":" We recently released that contains an important fix for a memory leak NEST users are very likely to hit. We urge everyone on any version to upgrade to 2.3.1. If you are making the jump from , please jump straight to which will work against any release. The memory leak happened in the caching of s which are used throughout the NEST API to have strongly typed expressions to CLR type properties relating to fields in a document. For example, var response = client.Search(s => s .Query(q => q .Term(c => c .Field(p => p.Name) .Value(\"project description\") ) ) ) Here we have a reference to the \"name\" field in Elasticsearch using the Lambda expression, . Because of a bug in our 's implementation, the dictionary in which resolved expressions are cached would grow unbounded during the lifetime of the . We profile extensively and are halfway through adding profile results and their differences in our CI pipeline, but unfortunately this did not catch this leak in longer running applications. The low level client, , was not affected by this bug. Nearly three years ago through a GitHub issue reporting a regression, and today we've been served another. We would like to thank , , \u00a0and\u00a0 for raising and confirming the issue. If you have any questions, please don't hesitate to reach out to us either on or . We sincerely apologize for any inconvenience this may have caused! \n"}
{"index": {"_id": 638}}
{"title":"Elasticsearch for Apache Hadoop 5.0.0-alpha2 and 2.3.1 released","seo_title":"","url":"\/blog\/es-hadoop-5-0-0-alpha2-and-2-3-1-released","author":{"name":"Costin Leau"},"date":"May 03, 2016","category":"Releases","locales":"","content":" I am pleased to announce the release of Elasticsearch for Apache Hadoop (aka ES-Hadoop) and As mentioned in the version, 5.0.0 is software that will only work with . Please test it, but do use it in production. Now that we have that out of the way, let\u2019s see what these releases bring to the table. What\u2019s new? Version alignment ES-Hadoop 5.0.0-alpha2 joins the 5.0 Elastic release train and add support for Elasticsearch 5.0.0-alpha1 and alpha2 while maintaining support for Elasticsearch 1.x and 2.x. Attentive users might notice that there was no ES-Hadoop 5.0.0-alpha1 release and this was on purpose: to minimize confusion between products compatibility, ES-Hadoop is aligning itself with the global versioning of the Elastic stack. Removed support for \u2018old\u2019 library versions In ES-Hadoop 5.0.0-alpha2, the requirements for the various libraries have been raised to clean-up the code base and remove cruft. This includes (but is not limited to): Eliminate integration for Spark SQL 1.0-1.2 SparkSQL was released in Spark 1.0 through 1.2 as an component which became stable in Spark 1.3. In doing so however the Spark SQL API has changed significantly (moving away from to ). In ES-Hadoop 5.0.0-alpha2, support for Spark SQL 1.0-1.2 is being removed. The core\/ support for Spark 1.0 is still present however with the iminent release of Spark 2.0, it is likely the version requirement will be raised (probably to Spark 1.2 or 1.3). Remove HDFS plugin repository As the HDFS repository plugin is now part of Elasticsearch proper, it has been removed from the ES-Hadoop project. Users of Elasticsearch 2.x can still use it as part of ES-Hadoop 2.x. Note that the HDFS plugin in Elasticsearch 5.x is not just conveniently packaged but also better integrated (there is no need to disable the JVM for example - an option that is anyway not available anymore). Bump Hive compatibility to 1.0 Hive 1.0 has been released for quite a while and the majority of distros have already moved to it. As such, support for Hive 0.13 and Hive 0.14 (two releases that were plagued by snafus) has now been dropped cleaning up the code base. Keep compatibility with JVM 1.7 Currently ES-Hadoop 5.0.0-alpha2 can still be used on JVM 1.7. This means users using old Hadoop distros or using Scala 2.10 can upgrade to ES-Hadoop without concern. Note that Elasticsearch 5.0 itself does require JDK 1.8 however as ES-Hadoop is a client, there are no hard JVM dependencies between the two - decoupling FTW! What about 2.3.1? ES-Hadoop 2.3.1 accompanies the 5.0.0-alpha2 release, introducing a few but important enhancements: Rework field escaping A bug report in the Spark module triggered a review and subsequent rework of the way internally mapping fields are being passed on. No API have changed however, at least in Spark, users should be now able to use field names with rare characters (such as ). HDFS repository upgrade The HDFS repository plugin has been upgraded to Elasticsearch 2.3.2. Better error messages Some of the error messages at start-up have been improved to provide more guidance especially for new users. Feedback Looking forward to hearing your feedback on these ! You can find us on , Twitter () or the . works too. \n"}
{"index": {"_id": 639}}
{"title":"Beats 5.0.0-alpha2 released","seo_title":"","url":"\/blog\/beats-5-0-0-alpha2-released","author":{"name":"Tudor Golubenco"},"date":"May 03, 2016","category":"Releases","locales":"","content":" Around a month ago we released the of the next major release for the Elastic Stack. Today we\u2019re proceeding according to the plan and announce the 5.0.0-alpha2 release. It includes bug fixes and new features for the data collectors you know and love: Filebeat, Packetbeat, Topbeat, and Winlogbeat. What\u2019s new?Improved Redis outputThe Beats had a Redis output from the earliest days, but we neglected it for a while as we thought we will remove it to focus on the Logstash and Elasticsearch outputs. By popular demand we reverted that decision and, after introducing the new Kafka output in alpha1, we have now completely reworked the Redis output for alpha2. It now supports the guaranteed mode needed by Filebeat and Winlogbeat, meaning that events won\u2019t be lost in case of network unavailability. It also supports authentication, SOCKS5 proxies, and even . Redis itself doesn\u2019t natively support encryption, but you can make use of to secure the communication between the Beats and Redis. Kibana dashboards per BeatOur proved to be quite popular, so we worked on improving the experience around them. Part of this effort was to split them per Beat, so they are easier for us to maintain and more convenient for you to use. This means, for example, that if you only use Topbeat, you can load only the Topbeat dashboard along with all the required saved visualizations and searches. And since the dashboards are now per Beat, we include them in the , so they are there when you need them. New directory layoutWe also reorganized a bit where each Beat looks for and creates its files. This makes it easier to upgrade the Beats that store state and it makes it easier for us to create and maintain features like automatic template loading in a cross-platform way. \u00a0The new will be familiar to you if you know how the Elasticsearch paths are organized. Another notable change is that the Beats now log by default to rotating files instead of syslog. This makes the experience more consistent across the various platforms that we support. Bug fixes since Alpha1The change log also contains a few fixes for issues discovered since the 5.0.0-alpha1 release. These include bugs related to , to the automatic , and to using . Become a PioneerA big Thank You to everyone that has tried the alpha1 release and has or . We\u2019d like to also remind you that if you post a valid non-duplicate bug report during the alpha\/beta period against any of the Elastic stack projects, you are entitled to a . \n"}
{"index": {"_id": 640}}
{"title":"Elasticsearch 5.0.0-alpha2 released","seo_title":"Elasticsearch 5.0.0-alpha2 released","url":"\/blog\/elasticsearch-5-0-0-alpha2-released","author":{"name":"Clinton Gormley"},"date":"May 03, 2016","category":"Releases","locales":"","content":" Today we are excited to announce the release of based on . This is the second in a series of pre-5.0.0 releases designed to let you test our your application with the features and changes coming in 5.0.0, and to give us feedback about any problems that you encounter. Open a bug report today and become an . \u00a0This is an alpha release and is intended for\u00a0. Indices created in this version\u00a0. Upgrading 5.0.0-alpha2\u00a0to any other version is not supported. Elasticsearch 5.0.0-alpha2 is close to being feature complete, and builds on the work released in 5.0.0-alpha1. There are many small changes which you can read about in the release notes above, but some of the more interesting ones are mentioned below. Also take a look at the to read about features like: Migration HelperThe Elasticsearch Migration Helper is a site plugin designed to help you to prepare for your migration from Elasticsearch 2.3.x to Elasticsearch 5.0. It comes with three tools: Instructions for \u00a0on Elasticsearch 2.3.x. Lucene 6This release is based on Lucene 6.0.0 and uses the new for , , and fields. Besides faster indexing, faster range queries, and smaller indices, the use of point fields also means that fields support IPv4 and IPv6 out of the box. Percolate QueryWe sat back and had a long hard think about how we could improve the Percolator with requested features like highlighting, scoring, and pagination. What we realised was that percolation is just a special form of search and we could benefit from all the features of the search API by replacing the percolate API with the new . The query is just a new query that can be used along with the rest of the Query DSL. It queries the special , which replaces the document type. The old percolate API is now deprecated but will continue to work through Elasticsearch 5.x. Deleted Index TombstonesHave you ever restarted an old node and found that previously deleted indices popped back to life like annoying, hard-to-kill zombies? We now maintain tombstones for deleted indices in the cluster state to keep these zombies where they should be. The tombstone list is capped at 500 indices by default, which equates to about one season of The Walking Dead. Indexed Scripts\/Templates are now StoredPreviously, scripts and templates could be indexed into the special index and referenced by name in search and other requests. This complicated index recovery because the index had to be recovered before other indices. We have renamed these indexed scripts\/templates to scripts\/templates, and they are now stored in the cluster state instead of in an index. You will need to migrate any existing indexed scripts or templates that you have to the cluster state when moving to 5.0. Instructions for doing so are available . So long Environment Vars and thanks for all the fishIn previous versions, JVM configuration options could be scattered across multiple configuration files and environment variables. Now, all JVM options are centralized into a single that can be checked into your version control. Importantly, you can no longer use the environment variable but instead should . Safety MeasuresWe\u2019ve added more checks to Elasticsearch to keep your cluster running healthily. At we check to ensure that you have set the correctly, and that your node has access to enough . This last one is particularly important because Elasticsearch is switching to use for all Lucene files, instead of the \/ hybrid file system that was used before. There is also a new circuit breaker to limit the . This is to prevent users from overloading your cluster by sending too many large bulk or search requests at the same time, which can overload nodes and even cause them to run out of memory. ConclusionPlease , try it out, and let us know what you think on Twitter () or in our . You can report any problems on the . \n"}
{"index": {"_id": 641}}
{"title":"Elastic Stack Release - 5.0.0 alpha 2","seo_title":"Elastic Stack Release - 5.0.0 alpha 2","url":"\/blog\/elastic-stack-release-5-0-0-alpha-2","author":{"name":"Shay Banon"},"date":"May 03, 2016","category":"Releases","locales":"ja-jp","content":" In our post , we discussed the background of the release and the reason behind the Elastic Stack. So, this time, we will get right into the detail.\u00a0Before you get too excited, keep in mind that this is still an alpha so don\u2019t put it into production. And, since it is an alpha it is not available on . But, because Elastic Cloud is the official hosted Elasticsearch and Kibana offering on AWS -- the only hosted Elastic Stack offering with\u00a05.0 upon release will be Elastic Cloud. If you open a bug report, today, you too can become an . And now, without further ado, some highlights from alpha 2. ElasticsearchFor more detailed information, and quite a few other features, peruse the Elasticsearch . From 2.3.x to 5.0. The magical journey. The undiscovered country. The next frontier. Other coined phrases. In addition to alpha 2, we\u2019ve also released the , which runs on your existing 2.3 cluster. \u00a0Use this site plugin to prep for your migration. KibanaFor more detailed information, and all the PR links in one place, visualize the future in the Kibana . In the last release we mentioned that we hadn\u2019t lost our sense. In alpha 2, we officially found our Console. Make sense? No? It doesn\u2019t? Sense is now known as Console and it ships with Kibana. Logstash Download the Logstash packages from .BeatsThe Redis output in Beats just got a whole lot better, supporting the same level of guarantees as the other outputs, SOCKS5 proxies, and encryption. The downloadable Beats packages also got a new directory layout which is more consistent with the one used by Elasticsearch and they now also include sample Kibana dashboards. You can find more details about these changes in the . X-Pack ES-HadoopBut wait, there\u2019s more! ES-Hadoop v 5.0.0-alpha2 has also been released . \n"}
{"index": {"_id": 642}}
{"title":"Kibana 5.0.0-alpha2 released","seo_title":"Kibana 5.0.0-alpha2 released","url":"\/blog\/kibana-5-0-0-alpha2","author":{"name":"Court Ewing"},"date":"May 03, 2016","category":"Releases","locales":"","content":" Today marks a huge milestone in the history of Kibana, software development, and the world. Brace yourself. Be proud all ye who contribute here, for on this day in May 2016, we scraped some features together, fixed a bunch of bugs, and released Kibana 5.0.0-alpha2. Pick up your very own, generic copy of Kibana 5.0.0-alpha2 from the page. This is software that will only work with . Please test it, but do use it in production. Enough with the warnings, let\u2019s start breaking some new stuff. Features, you say? Sense is now Console, and it ships with every copy of Kibana Need I say more? Console is the same great Kibana application you\u2019ve come to rely on, only it now supports the ES 5.0 APIs and is free of any pesky maintenance burden for you or your swarm of devops minions. Oh, you never used Sense before? Well, feast your eyes on the easiest way on Gaia\u2019s green earth to query Elasticsearch: And there\u2019s more! Some features just aren\u2019t very screenshot friendly, but that doesn\u2019t mean we love them any less. We fixed some bugs as well: What\u2019s next? It\u2019s really quite hush hush, but if you promise not to tell anyone, I\u2019ll let you in on a little secret. Kibana 5.0.0-beta1 is coming. I know, right? I was as shocked as anyone when I heard. It won\u2019t be this week, and it won\u2019t be next week, but I have it from a reliable source that beta1 will be release during week sometime in the future. So what are you waiting for? Grab the release and give it a whirl. We\u2019d love to get your feedback on our , , or even , and please post any bugs you find directly to our . \n"}
{"index": {"_id": 643}}
{"title":"Brewing in Beats: Mysqlbeat and HWsensorsbeat from the community","seo_title":"","url":"\/blog\/brewing-in-beats-mysqlbeat-hwsensorbeat","author":{"name":"Monica Sarbu"},"date":"May 02, 2016","category":"Brewing in Beats","locales":"","content":" Welcome to Brewing in Beats! With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources. \n"}
{"index": {"_id": 644}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-05-02","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-05-02","author":{"name":"Michael McCandless"},"date":"May 02, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsWe \u201cunlocked\u201d some indexing performance in #elasticsearch Coming to 2.4.0 and 5.0.0! \u2014 Jason Tedor (@) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole Elastic ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 645}}
{"title":"Where in the World is Elastic? - DevOpsDays Austin and PuppetCamp AU","seo_title":"Where in the World is Elastic? - DevOpsDays Austin and PuppetCamp AU","url":"\/blog\/witwies-devopsdays-austin-puppetcamp-au","author":{"name":"Megan Wieling"},"date":"May 02, 2016","category":"","locales":"","content":" Welcome to Find out which Elastic events and meetups are happening near you in the next two\u00a0weeks.Upcoming EventsMay 9-10: May 11-12: May 12-13: May 2-3: May 14-15: May 12-14: May 3: Upcoming MeetupsMay 3: May 5: May 5: May 10:\u00a0May 11: May 12: May 3: May 3: May 4: May 4: May 4: May 10: May 11: May 7: May 15: May 15: That's it for this week. Stay tuned next week for more Elastic happenings.- The Elastic TeamP.S.\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}
{"index": {"_id": 646}}
{"title":"Logstash Lines: GeoIP filter enhancements","seo_title":"Logstash Lines: GeoIP filter enhancements","url":"\/blog\/logstash-lines-2016-05-02","author":{"name":"Suyog Rao"},"date":"May 02, 2016","category":"The Logstash Lines","locales":"","content":" Java EventLast week, we made to expose the new setter and getter APIs to the Event object. To propagate this change to all the 200+ plugins, we've taken a phased approach. First up, we've updated all the plugins that are used in the core unit tests with the new API, and tests are now passing. Next step, which will be this week, we move to those plugins (70+) which are packaged in Logstash artifacts. We have a to track that, and work will be split by the team. Once these plugin tests are passing, we can start publishing gems for all the updated plugins, and move on to non-packaged pluginsPlugin ManagerAdded option to command. This allows us to preserve gem options which are already specified in which would have been previously overwritten. This will also help with the unified build effort by avoiding the unnecessary publication of core plugins snapshots. When running any plugin related command you can use , which will give the user a bit more information about what bundler is doing.Acceptance TestingWork continues on building the framework for acceptance tests on multiple artifacts\/platforms using Vagrant. At this point, we've written plugin manager validation tests using the new framework. This week, we'll focus on deb\/rpm package tests and running these on Jenkins (thanks to our infra team).PluginsSupporting MaxMind's database has been a longstanding enhancement request! Over the past couple of weeks we've been working with our community members and on a to bring these changes to this filter. This plugin now directly uses the GeoIP2 Java API, adds support for IPv6 lookups and brings in all the goodness that is GeoIP2. Many thanks to Gary and Thomas! These changes will be packaged with 5.0.0-alpha2.This output now supports ingest pipelines while indexing docs. Very simply, you can:{ \"hosts\" => \"localhost\", \"pipeline\" => \"apache-logs\", ... }Others \n"}
{"index": {"_id": 647}}
{"title":"Kibana under the hood: object persistence","seo_title":"Kibana under the hood: object persistence","url":"\/blog\/kibana-under-the-hood-object-persistence","author":{"name":"Shaunak Kashyap"},"date":"April 29, 2016","category":"Engineering","locales":"","content":" Users of Kibana create saved searches, visualizations, dashboards, and other such objects. Kibana, of course, has to persist these objects somewhere so they can be loaded up next time users start it up. As Kibana connects to Elasticsearch for querying users\u2019 data anyway, it conveniently uses Elasticsearch to store its objects as well. This blog post explores some of these objects, how they are stored in Elasticsearch, and when they are created. The goal is for this information to serve as a useful tool not only for debugging but also for administrators who might want to deploy Kibana in an automated, repeatable fashion today. Please note, however, that these objects are internal data structures that may evolve over time. Future versions of Kibana may provide REST APIs to programmatically \u2014 and safely \u2014 manipulate these objects. The special index Kibana stores its objects as documents in the index in Elasticsearch. The name of this index can be changed via the configuration setting (starting with Kibana 4.2: prior to that this setting was named ). Let\u2019s start at the beginning When you start with a completely fresh install of Kibana there is, of course, no index in Elasticsearch yet. This index is created when you start the Kibana server. At this point the index contains two document types: Index patterns When a user loads up Kibana in their browser for the first time, they are required to create an index pattern. Of course, they can add more index patterns at a later time as well. Whenever users create a new index pattern, a document is created in the index, under the document type. Depending on the choices the user makes when creating the index pattern, this document will have the following fields: Also, when users create the very first index pattern, it becomes the default index pattern for Kibana to use as well. This bit of information \u2014 specifically the of the index pattern document \u2014 is recorded in the field of the type document introduced in the section above. Saved searches After creating an index pattern, users will typically start on the Discover page. Here they will explore the data in their index pattern by searching through it, focussing on certain fields in the results, etc. Sometimes users will want to save their search on the Discover page for later use. They might want to open it later on the Discover page or add it as a panel to a dashboard. When users save a search, a new document is created in the index under the search type. It contains the following fields: Saved visualizations When users create a new visualization via the Visualization page, a new document is created in the index under the visualization type. It contains the following fields: Saved dashboards When users create a new dashboard via the Dashboard page, a new document is created in the index under the (surprise, surprise!) dashboard type. It contains the following fields: This post covered persistence for the fundamental objects in Kibana. In a future post we\u2019ll cover more advanced objects and lifecycle operations. As always, if you have questions about Kibana feel free to ask them in our discussion forums at or chat live with the Kibana team and community in the #kibana channel on Freenode IRC. \n"}
{"index": {"_id": 648}}
{"title":"Structured logging with Filebeat","seo_title":"","url":"\/blog\/structured-logging-filebeat","author":{"name":"Tudor Golubenco"},"date":"April 28, 2016","category":"Engineering","locales":"","content":" The idea behind structured logging is simple: instead of having applications write logs that need to be parsed via regular expressions into JSON objects that you index into Elasticsearch, you make the application write JSON objects directly. To exemplify, let\u2019s say you are writing a Python web application, and you are using the standard library for logging. When a user signs in, you might use a logging statement that looks like this: logging.debug(\"User '{}' (id: {}) successfully logged in. Session id: {}\" .format(user[\"name\"], user[\"id\"], session_id)) And then when the user gets verified: logging.debug(\"User '{}' (id: {}) changed state to verified.\" .format(user[\"name\"], user[\"id\"])) This results in log lines like this: DEBUG:root:User 'arthur' (id: 42) successfully logged in. Session id: 91e5b9d DEBUG:root:User 'arthur' (id: 42) changed state to verified. This way of logging is popular ever since the good old printf. Back then, you would typically have a single server, and you would tail and grep the log files and everything was great. Times have changed, however, and today it is more likely that you have tens, hundreds, or thousands of servers \/ virtual machines \/ containers creating massive amounts of logs, so you centralize them in Elasticsearch and use its magical (that\u2019s just how it feels) search and aggregation features to navigate through them. This works best when the logs are pre-parsed in a structured object, so you can search and aggregate on individual fields. So before indexing, you would typically use Logstash\u2019s amazing Grok filter to parse the application logs into a JSON object, but this means that you have to write and maintain Grok patterns and spend CPU cycles to do the parsing. Now let\u2019s try the same example with structured logging. While usually not in the standard library, all major programming languages have libraries that make structured logging easy. James Turnbull created a list in this , which also goes into detail about how to do this for a Rails application. In Python, there\u2019s the library, which we will use here: log = log.bind(user='arthur', id=42, verified=False) log.msg('logged_in') log.msg('changed_state', verified=True) Which results in log lines like this: verified=False user='arthur' session_id='91e5b9d' id=42 event='logged_in' verified=True user='arthur' session_id='91e5b9d' id=42 event='changed_state' One thing to notice is that the code is less repetitive and it encourages the developer to include all the data rather than only what seems important while writing the code. Also note that in this format, the log lines are still reasonably easy to follow for a human during development. When moving to production, however, it makes more sense to use the JSON renderer: log = wrap_logger(PrintLogger(), processors=[JSONRenderer()]) This results in log lines like this: {\"verified\": false, \"user\": \"arthur\", \"session_id\": \"91e5b9d\", \"id\": 42, \"event\": \"logged_in\"} {\"verified\": true, \"user\": \"arthur\", \"session_id\": \"91e5b9d\", \"id\": 42, \"event\": \"changed_state\"} This is less readable to human eyes, but has the advantage that the data is already structured in the format that Elasticsearch likes. is an open source log shipper, written in Go, that can send log lines to Logstash and Elasticsearch. It offers \u201cat-least-once\u201d guarantees, so you never lose a log line, and it uses a back-pressure sensitive protocol, so it won\u2019t overload your pipeline. Basic filtering and multi-line correlation are also included. Starting with version 5.0 (currently in alpha, but you can give it a ), Filebeat is able to also natively decode JSON objects if they are stored one per line like in the above example. Here is a sample configuration file that configures Filebeat to pick up the files and send the JSON objects to Elasticsearch: filebeat.prospectors: - input_type: log paths: [\"test\/*\"] json.message_key: event json.keys_under_root: true fields: planet: Magrathea service: ${SERVICE_NAME} tags: [ \"i\", \"heart\", \"json\" ] output.elasticsearch: hosts: [\"192.168.99.100:9200\"] template.name: filebeat template.path: filebeat.template.json This is one of the JSON objects that gets indexed this way: { \"@timestamp\": \"2016-04-22T22:09:09.631Z\", \"beat\": { \"hostname\": \"DeepThought\", \"name\": \"DeepThought\" }, \"event\": \"logged_in\", \"fields\": { \"planet\": \"Magrathea\", \"service\": \"Answerer\" }, \"id\": 42, \"input_type\": \"log\", \"offset\": 0, \"session_id\": \"91e5b9d\", \"source\": \"test\/structured.log\", \"tags\": [ \"i\", \"heart\", \"json\" ], \"type\": \"log\", \"user\": \"arthur\", \"verified\": false } As you can see, Filebeat automatically adds a timestamp. Note that this is the time when the log line was read, which can be different from when the application wrote the log line. You can set up the structlog library to generate timestamps if you need better accuracy. Filebeat also automatically adds some metadata like the host name, and it makes it easy to add custom fields and tags via the configuration file. This means that the application doesn\u2019t have to worry about adding metadata from the environment. That\u2019s about all you need. Simple things should be simple :-) \n"}
{"index": {"_id": 649}}
{"title":"Beats 1.2.2 Released","seo_title":"","url":"\/blog\/beats-1-2-2-released","author":{"name":"Tudor Golubenco"},"date":"April 26, 2016","category":"Releases","locales":"","content":" We\u2019re happy to announce that the 1.2.2 bug fix release is now available for all the Elastic Beats: Filebeat, Packetbeat, Topbeat and Winlogbeat. You can download the new versions from the usual . Bug fixes affecting all Beats Bug fixes affecting Filebeat Many thanks to our dear community members who tested the Beats, reported and helped with the troubleshooting of the above issues. If you find any issues with the new release or there are features that you miss, please interact with us on or . \n"}
{"index": {"_id": 650}}
{"title":"Elasticsearch 2.3.2 released","seo_title":"Elasticsearch 2.3.2 released","url":"\/blog\/elasticsearch-2-3-2-released","author":{"name":"Clinton Gormley"},"date":"April 26, 2016","category":"Releases","locales":"","content":" Today we are pleased to announce the bug fix release of based on . Users who are affected by the issues mentioned in the release notes are advised to upgrade. This release is already available on , our Elasticsearch-as-a-service platform.Latest stable release:Full details of the changes in this release are available in the release notes listed above, but some of the more important changes are mentioned below: \n"}
{"index": {"_id": 651}}
{"title":"Logstash 2.3.2 Released","seo_title":"","url":"\/blog\/logstash-2-3-2-released","author":{"name":"Suyog Rao"},"date":"April 26, 2016","category":"Releases","locales":"","content":" Bugs Fixed In Logstash CoreBugs Fixed In Plugins \n"}
{"index": {"_id": 652}}
{"title":"Brewing in Beats: Tomcat JMX monitoring and DNSSEC monitoring","seo_title":"","url":"\/blog\/brewing-in-beats-tomcat-jmx-dnssec-monitoring","author":{"name":"Tudor Golubenco"},"date":"April 25, 2016","category":"Brewing in Beats","locales":"","content":" Welcome to Brewing in Beats! With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources. New community Beat: JmxProxyBeat Created by , who also wrote Apachebeat and Elasticbeat in the past, JmxProxyBeat gets JMX metrics from Tomcat via the JMX Proxy Servlet. Great companion for Metricbeat :-). DNSSEC support in Packetbeat DNS monitoring is already one of the most popular use cases for Packetbeat. Thanks to this , Packetbeat is now also able to understand EDNS and DNSSEC resource records. Clean shutdown procedure It used to be that you couldn\u2019t stop the Beats if the output queue was not empty (for example, because Elasticsearch\/Logstash was not available). After this fairly , the Beats can signal to the publisher that they want to shutdown and that the outputs can drop the output queue if needed. Dropping the inflight messages is fine, because for the Beats that offer at-least-once-guarantees (Filebeat & Winlogbeat), the registry makes sure they will be resent after the Beat restart. Besides solving the bug mention above, the clean shutdown semantics are one of the prerequisites for configuration reloading and running multiple Beats in a single binary. Metricbeat, meet generic filtering The new (since alpha1) libbeat functionality of generic filtering can now be used , making it possible to flexibly control which fields (metrics) are exported and which not. Metricbeat system module Metricbeat now borrows from Topbeat (every Beat is also a library!) the , so any host running it will report CPU\/mem\u00a0statistics. Topbeat and Packetbeat now work on OpenBSD We don\u2019t yet consider OpenBSD a supported platform for Beats, but thanks to the efforts of Jasper Lievisse Adriaanse, a , Topbeat and Packetbeat can now be compiled and executed on OpenBSD. Jasper went as far as fixing libpcap on OpenBSD and to us so we can test OpenBSD more regularly. Filebeat was already working on BSDs via simple cross-compilation, because it's pure Go. Load the Elasticsearch template on every connect One of the known issues with 5.0.0-alpha1 was that the Beats only attempted to load the Elasticsearch template once, meaning that if they were started before Elasticsearch the template was not loaded. With this , the template is loaded immediately after a successful connection is established. The error handling was also improved, so we can now make sure that we don\u2019t insert any documents before the template is loaded. Filebeat\u2019s JSON decoder can now parse @timestamp fields One of the bugs reported against alpha1 was that if a field was supplied as JSON field, Filebeat would crash. This is because our output plugins expect the field to have a particular type. Filebeat now that the timestamp and type (could also be affected by this) have the right types. Besides not crashing, a benefit of this is that the application can now provide its own timestamp\u00a0to overwrite the one added by Filebeat. Added path.logs option and log to files by default The Beats used to log to syslog by default. With the introduction of the , and to be more similar with the other products in the stack, it makes more sense to log to files by default. So this . The files are automatically rotated and old files are removed. When loading the default dashboards, you can now select the index name Thanks to another contribution by , you can now rename the index names before loading the dashboards in Elasticsearch. Other merges: \n"}
{"index": {"_id": 653}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-04-25","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-04-25","author":{"name":"Michael McCandless"},"date":"April 25, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsForbes: Amazing Big Data At NASA with Elasticsearch: Real Time Analytics 150 Million Miles From Earth \u2014 dbaldassano\u00a0(@) Elasticsearch Core Apache LuceneNews about Apache Lucene will be back next week.Watch This Space, where we'll share more news on the whole Elastic ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 654}}
{"title":"Where in the World is Elastic? - Elastic Meetups in Beijing, Portland, Dallas St. Louis and New York","seo_title":"\/blog\/witwies-qcon-devoxx-percona-aws","url":"\/blog\/witwies-elastic-meetups-beijing-portland-dallas-st-louis-new-york","author":{"name":"Megan Wieling"},"date":"April 25, 2016","category":"","locales":"","content":" Welcome to Find out which Elastic events and meetups are happening near you in the next two\u00a0weeks.Upcoming EventsMay 2-3: May 3: Upcoming MeetupsApril 25: April 25: April 27: April 28: April 28: April 29: May 3: May 5: May 5: April 26: April 26: May 3: May 3: May 4: May 4: May 4: April 30: May 7: April 26: That's it for this week. Stay tuned next week for more Elastic happenings.- The Elastic TeamP.S.\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}
{"index": {"_id": 655}}
{"title":"Logstash Lines: New Event API","seo_title":"","url":"\/blog\/logstash-lines-2016-04-25","author":{"name":"Suyog Rao"},"date":"April 25, 2016","category":"The Logstash Lines","locales":"","content":" Welcome back to The Logstash Lines! In these weekly posts, we'll share the latest happenings in the world of Logstash and its ecosystem.Event API This week, we spec'd out APIs for interacting with the Event class. Previously, there was no formal, documented API which meant that plugin developers and especially Ruby Filter users could use the internals (hash map) directly to modify data. Not a great idea! We defined setters and getters interfaces which will be used by all plugin developers. This breaking change affects almost plugins, and we need to review\/modify 200+ plugins, but this is the right thing to do in 5.0 and document properly. This will protect us against future implementation changes (e.g. plugging in Java Event implementation). See for new APIs -- we would love any feedback you have!\u00a0All core plugin tests are passing locally with these changes. Next up, we need to split the work to update all plugins with these new calls. Acceptance Tests Work continues on to add much needed acceptance tests. Progressing well on validating plugin manager workflow, CLI switches, testing release packages on CentOS and Debian flavors. Also, working with our infra team to add these to the new Jenkins CI server. Other Fixes\/In-Progress StuffUpcoming Releases Prepping for a 2.3.2 bug fix release this week and 5.0.0-alpha2 next week.\u00a0 \n"}
{"index": {"_id": 656}}
{"title":"Effective Elasticsearch Plugin Management with Docker","seo_title":"","url":"\/blog\/elasticsearch-docker-plugin-management","author":{"name":"Tyler Langlois"},"date":"April 25, 2016","category":"Engineering","locales":"","content":" If you're running Elasticsearch within Docker containers, there are some important operational considerations to bear in mind. This is especially true when managing stateful services and daemons - when persisting data outside of an ephemeral container becomes important.Using Elasticsearch plugins within containers is an example of this, both in terms of them in a repeatable, trackable manner and plugin configuration and data.In this post, we'll explore some of the options to achieve sane plugin management within the context of Docker and Elasticsearch.: In this guide we will reference the Elasticsearch image found on the Docker Hub. The development and production of this Docker image is not affiliated with Elastic, Inc.A Docker Persistence PrimerLike a file change in a version control system, changing the filesystem in a running container introduces differences in the running image. Steps need to be taken if data and changes need to persist permanently outside the scope of an impermanent container.Although one could leverage some more complex storage schemes to achieve container persistence, the basic Docker mechanism of is the most illustrative. This is achieved by, for example, keeping Elasticsearch indices long-term in by passing an option like to a command, which effectively stores your Elasticsearch data in the (not container's) directory.If the changes are more permanent, that is, they are expected to be there without changing over time, codifying changes in a may make more sense. Both approaches are useful in different cases.Managing Basic PluginsIn the following examples, I refer to \"basic\" plugins as those that do not require licenses or any other special components. Straightforward plugins like just need to place some files on the system to work.In a case like this, managing the presence of the plugin is simplest by just extending the image using a . For example, considering the following :FROM elasticsearch:2 RUN \/usr\/share\/elasticsearch\/bin\/plugin install --batch cloud-awsThis starts with the Elasticsearch image provided by maintainers at the Docker hub and runs a simple command. This image can then be built and referenced by a tag:$ docker build -t elasticsearch-aws .When run in the same directory as the , the image name is built and can now be referenced in future Docker commands when starting new containers with behavior inherited the original.More Complex PluginsSome plugins may require the presence of additional files (such as certificates when using ) for certain features. The aforementioned technique of building a custom image can handle the installation of these plugins, but managing configuration is a task better left to a different approach. This helps keep images generic for deployment re-use and maintains tighter control over secrets.: Some commercial plugins require the presence of a license. In the following examples, we simply rely on the temporary trial license present by default. When deploying in production, license management is performed through the Elasticsearch REST API, which stores the license in Elasticsearch's data path. As long as your data is persisted appropriately through a volume mount or otherwise, your license will be saved within your cluster.Example: ShieldAs outlined in the , installing the and plugins is a prerequisite, which we can achieve by using the previous strategy to build a derived image:FROM elasticsearch:2 RUN \/usr\/share\/elasticsearch\/bin\/plugin install --batch license RUN \/usr\/share\/elasticsearch\/bin\/plugin install --batch shieldThen build the image to use for future steps:$ docker build -t elasticsearch-shield .At this point, if we volume mount a config directory into the container, Shield will pick up our settings. As an example configuration, consider the following directory structure:$ tree config config \u251c\u2500\u2500 elasticsearch.yml \u251c\u2500\u2500 logging.yml \u251c\u2500\u2500 scripts \u2514\u2500\u2500 shield \u251c\u2500\u2500 roles.yml \u251c\u2500\u2500 users \u2514\u2500\u2500 users_roles 2 directories, 4 filesThe contains a default logging configuration. In , binding to the wildcard ensures we can reach the container:$ cat elasticsearch.yml network.host: 0.0.0.0For the Shield configuration, we have defined a single role, admin, along with a user called \"example\" with a password of \"password\" and added it to the admin role (you'll obviously want a more secure configuration than this!):$ cat shield\/roles.yml admin: cluster: all indices: '*': privileges: all $ cat shield\/users example:$2a$10$ppZqjFEXgVE3yT\/yQPsp4etGMdF4.RFCS9OOGwZGAp0l3lPh4\/ALC $ cat shield\/users_roles admin:example: In this example we are using a password hash generated using the Shield utility.We then start the container, passing in the volume for our configuration and exposing the REST port:$ docker run -d -p 9200:9200 -v \"$PWD\/config\":\/usr\/share\/elasticsearch\/config elasticsearch-shieldElasticsearch should deny unauthenticated requests and permit access to the credentials used earlier (in this example it is assumed that Docker is exposing ports on the localhost):$ curl -I -XGET -k https:\/\/localhost:9200\/_cluster\/health HTTP\/1.1 401 Unauthorized WWW-Authenticate: Basic realm=\"shield\" Content-Type: application\/json: charset=UTF-8 Content-Length: 389 $ curl -I -XGET -k -u example:password https:\/\/localhost:9200\/_cluster\/health HTTP\/1.1 200 OK Content-Type: application\/json: charset=UTF-8 Content-Length: 389Adding SSL\/TLSLike mounting Shield configuration files, SSL and TLS certificates can be similarly managed. Most of the steps outlined in the can be followed, bearing in mind that the directory is the path that we will be mounting into the container at runtime. The full extent of CA and certificate management is outside the scope of this tutorial, so we will assume here that you are using a correctly configured Java keystore file, referred to here as .Exposing the keystore file is simply a matter of including it within the configuration directory that is mounted into the container.$ tree config config \u251c\u2500\u2500 elasticsearch.yml \u251c\u2500\u2500 logging.yml \u251c\u2500\u2500 node01.jks \u251c\u2500\u2500 scripts \u2514\u2500\u2500 shield \u251c\u2500\u2500 roles.yml \u251c\u2500\u2500 users \u2514\u2500\u2500 users_roles $ file config\/node01.jks config\/node01.jks: Java KeyStoreFollowing the Shield user guide, we enable transport encryption:$ cat config\/elasticsearch.yml network.host: 0.0.0.0 shield.ssl.keystore.path: \/usr\/share\/elasticsearch\/config\/node01.jks shield.ssl.keystore.password: password shield.transport.ssl: true shield.http.ssl: true: In production, you may want tighter control over your keystore - in this example, we only locked the keystore with a generic password.With the keystore file in place and SSL enabled, we can start the node and issue requests over HTTPS (in this case, passing to curl to bypass a self-signed certificate):$ docker run -d -p 9200:9200 -v \"$PWD\/config\":\/usr\/share\/elasticsearch\/config elasticsearch-shield 87e51d000cc11d63fbedb8a61d58ab1723f4a598b13614272a3b9d7f36a7b223 $ curl -I -XGET -k -u example:password https:\/\/localhost:9200\/_cluster\/health HTTP\/1.1 200 OK Content-Type: text\/plain: charset=UTF-8 Content-Length: 0When it comes time to distribute keystore files across the cluster, they could potentially be managed by a or a similar approach.: Pay close attention to the appropriate options to pass to the option when generating certificates for your nodes that will run within Docker. DNS names and IP addresses should correctly reflect the hostname or IP address that nodes will use to communicate with one another.SummaryAlthough we've given a few concrete examples in this blog post, every deployment is different, and you should tailor your setup according to whatever promotes reliability, repeatability, and security in your environment. Generally speaking, following these guidelines should aid in a good plugin management scheme: \n"}
{"index": {"_id": 657}}
{"title":"Elastic Cloud Outage: Root Cause and Impact Analysis","seo_title":"","url":"\/blog\/elastic-cloud-outage-april-2016","author":{"name":"Alex Brasetvik"},"date":"April 21, 2016","category":"Engineering","locales":"","content":" Summary \n"}
{"index": {"_id": 658}}
{"title":"Announcing Rally: Our benchmarking tool for Elasticsearch","seo_title":"","url":"\/blog\/announcing-rally-benchmarking-for-elasticsearch","author":{"name":"Daniel Mitterdorfer"},"date":"April 19, 2016","category":"Engineering","locales":"de-de,fr-fr,ja-jp,ko-kr","content":" Today we\u2019re excited to announce the first public release of , the benchmarking tool we have been using internally in the Elasticsearch development team for a few months now. We want to share it with the community to help you reproduce performance numbers that we publish in your own environment and to help you write your own benchmarks without worrying about lots of tiny details. Rally\u2019s origins Rally originates from Python scripts that drive the and also . The benchmarking infrastructure is a great help to avoid boiling frog problems (a.k.a. slowly decreasing performance). We are constantly improving Elasticsearch in all areas and we also care deeply about performance. Wouldn\u2019t it be great if developers could run a benchmark by themselves to see the impact of their changes early during development instead of waiting until a feature is merged to the master branch? Developers are typically creative, so you can always write a quick and dirty script in the language of your choice, run it for your specific use case and forget about it. But how often do we really verify these numbers? So I tried the next best thing, which is to use the existing benchmark scripts locally, but the setup involved lots of manual steps. I\u2019ve decided to simplify installation and usage and . What can Rally do? Over the last months Rally gradually supported more and more features: We can attach so-called telemetry devices for detailed analysis of the benchmark candidate behavior. For example, Java flight recorder has already helped us to spot different problems. Here are a few examples of what you can do with Rally and the Java flight recorder telemetry device: Allocation Profiling Inspecting hot classes in Elasticsearch We have also added a JIT compiler telemetry device where we can inspect JIT compiler behavior, which allows us, for example, to analyze warm-up times during the benchmark. The graphics below shows the number of JIT compiler events during the benchmark: Evaluating the performance of such a complex system as Elasticsearch is also a very multi-dimensional problem. Whereas performance could improve in one scenario - say for searching log data - it could have a negative impact on full-text search. Therefore, we can define multiple benchmarks (called \u201ctracks\u201d in Rally). They are currently directly implemented in the Rally code base, but as the API is more stable, we want to , so it is easier to define your own ones. As Rally stores all metrics data in Elasticsearch, we can easily visualize data with Kibana, such as the distribution of CPU usage during a benchmark: In the beginning we add the benchmark data set to the index. After that we run search benchmarks. I bet you can clearly see the point in time where indexing is complete. We have also started to run the nightly benchmarks in parallel now and provide the results as . Roadmap There is still a lot of work to do: One major topic is to remove restrictions. We want to separate the benchmark definitions (called \u201ctracks\u201d) from Rally itself and also allow more flexibility in the steps that Rally performs during the benchmark. Currently we support only a very limited scenario: first all documents are bulk-indexed, then we run a track-dependent number of queries. By default, we run a benchmark based on data from but further tracks are available (just issue ). The second major topic is improving correctness of the measurements. We take correctness seriously and are already aware of a couple of topics that need improvement. One of the major issues that . This basically means that requests that take a long time to process prevent the benchmark driver to send further requests in the meantime, so we lose measurement samples. This means that the reported latency percentile distribution appears to be better than it actually is. Third: Rally is currently limited to single machine benchmarks, but and early prototypes are already promising. Running your first benchmark After all this talking, let\u2019s see how easy is it to run a benchmark on your own machine. Considering that and you have started Rally\u2019s metrics store, it is a three step process to get your first benchmark results: If you want to learn more about Rally, just head to , look at some or help us by . \n"}
{"index": {"_id": 659}}
{"title":"Datapalooza: How Jamplify is Rocking the Music Tour Industry with Elasticsearch","seo_title":"","url":"\/blog\/how-jamplify-is-rocking-the-music-tour-industry-with-elasticsearch","author":{"name":"Matt Roman"},"date":"April 19, 2016","category":"User Stories","locales":"","content":" collects and analyzes concert ticket sales data and provides venue and routing information for leading talent agencies, both large and boutique. For our clients, we are collecting and analyzing sales data for hundreds of touring artists as they perform in venues around the world. Data collection, visualization, and analysis around live event ticket sales have not advanced in parallel with other analytics tools in entertainment. With our and tools, Jamplify steps in not only by removing the time and headache of tracking down updated ticket sales data from venues, but also by turning otherwise stagnant sales data points into valuable, actionable insights for our clients. How we use ElasticsearchWe began using the Elastic Stack as a DevOps tool. It helped us get our log data in one place so that we could analyze problems with our servers and applications in context with each other. Once we had the Elastic Stack in place, we became accustomed to adding logging to diagnose what was happening with our application in production. It didn\u2019t take long to realize that we could use the Elastic Stack as an analytics platform to understand user behavior and feature viability on a deeper level. We were initially using Google Analytics for this purpose, but Elasticsearch provided much more flexibility and only required adding more logging.Eventually, we began using Elasticsearch to enhance our products as well. Previously, our clients collected and managed ticket sales data via emails and spreadsheets, but by using the Elasticsearch aggregation framework and D3 we were able to give our clients a new look at their sales data and provide them with actionable insights.Since dealing with Elasticsearch aggregation queries and results in your application can be a bit clumsy, we created a Node.js wrapper () which handles these tasks with a small DSL for retrieving relevant data from the results. This allowed us to simplify our application code and externalize parsing and processing as much as possible. Live IntelOur latest product release, Live Intel, heavily utilizes Elasticsearch\u2019s geographic search capabilities. Live Intel is a venue intelligence platform that helps booking agents route tours by providing them with a combination of geographic and term-based searching.Common challenges in tour routing include finding new venues that fit your artist profile and filling in open days during a tour. For instance, if there are two booked dates for a tour, one in New York on a Wednesday and another in Philadelphia on a Saturday, an agent would need to find potential shows and venues between these two cities and dates. To further complicate matters, live-event contracts often include radius clauses that prevent the artist from performing within a specified distance from the venue several months after the show date (music festivals have particularly onerous radius clauses that can span hundreds of miles and an entire year).Historically, agents would try to work with radius clauses by cross-checking venue\/promoter directories with Google Maps. This solution is limited, time-consuming, and cumbersome - an agent might spend an entire work day filing one or two available dates. \u00a0Live Intel quickly resolves this issue by using Elasticsearch to combine the map and the directory in a single application, while also ranking the search results based on performance metrics like the venues\u2019 ticket sales histories. Now they can reach out to every relevant venue within minutes and get to a booked show in an hour. By streamlining processes around both ticket sales data collection and tour routing, Jamplify helps agents do their jobs faster and better. \n"}
{"index": {"_id": 660}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-04-18","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-04-18","author":{"name":"Michael McCandless"},"date":"April 18, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top News 5.0 will use the new Lucene 6 points API to index numeric, date and ip fields\u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole Elastic\u00a0ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 661}}
{"title":"Brewing in Beats: Add data path support and enhance Redis output","seo_title":"","url":"\/blog\/weekly-beats-add-path-and-redis-output","author":{"name":"Monica Sarbu"},"date":"April 18, 2016","category":"Brewing in Beats","locales":"","content":" Highlights of the week:Enhance Redis output supportLast week we were on improving the Redis output by adding support for failover and loadbalancing if multiple Redis hosts are configured. In addition it adds support for TLS, SOCKS5 and backoff strategy in case Redis is unresponsive. \n"}
{"index": {"_id": 662}}
{"title":"Where in the World is Elastic? - QCon Beijing, Devoxx France, Percona Live & AWS Summit Chicago","seo_title":"\/blog\/witwies-qcon-devoxx-percona-aws","url":"\/blog\/witwies-qcon-devoxx-percona-aws","author":{"name":"Megan Wieling"},"date":"April 18, 2016","category":"","locales":"","content":" Welcome to Find out which Elastic events and meetups are happening near you in the next two\u00a0weeks.Upcoming EventsApril 18: April 19:\u00a0April 19: April 19:\u00a0April 23-24:\u00a0April 21-23:\u00a0Upcoming MeetupsApril 18: April 19:\u00a0April 19: April 19:\u00a0April 20:\u00a0April 20: April 25: April 25: April 27: April 28: April 28: April 29: April 19: April 19:\u00a0April 20:\u00a0April 20:\u00a0April 20:\u00a0April 21:\u00a0April 26: April 26: April 30: April 21:\u00a0April 26: April 21:\u00a0That's it for this week. Stay tuned next week for more Elastic happenings.- The Elastic TeamP.S.\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}
{"index": {"_id": 663}}
{"title":"Docker Networking","seo_title":"","url":"\/blog\/docker-networking","author":{"name":"Samir Bennacer"},"date":"April 15, 2016","category":"Engineering","locales":"","content":" In this\u00a0blog we\u2019ll talk about network considerations when using Docker with an Elasticsearch cluster.\u00a0Note: In this blog we will reference the Elasticsearch image found on the Docker Hub.The development and production of this Docker image is not affiliated with Elastic.You can create your own image by following our recommendation in the blog . There are different ways to setup networking in Docker and by default three\u00a0network types are presented. We can list all of them using the following command: $ docker network ls NETWORK ID NAME DRIVER d610d782daa0 bridge bridge 16a982d835f8 none null 7d80e0e91caf host host None NetworkIt completely disables networking, which is not useful when running an Elasticsearch cluster. Host Network If you use then the container will use the host network and this can be dangerous. It will allow you to change the host network from within the container and if you have an application running as root and it has a vulnerability, there is risk of unsolicited remote control of the host network via the the Docker container. In general we recommend against using it for security reasons, but it can be useful when you need to get the best network performance because it\u00a0is as fast as normal host networking. Bridge NetworkThe bridge network is the default network in Docker. We can check the details of the default\u00a0bridge network using the following command: $ docker network inspect bridge [ { \"Name\": \"bridge\", \"Id\": \"b38c312777a0f3890034c9b396669842947b80c9051d10a283c9d43937910578\", \"Scope\": \"local\", \"Driver\": \"bridge\", \"IPAM\": { \"Driver\": \"default\", \"Options\": null, \"Config\": [ { \"Subnet\": \"172.17.0.0\/16\" } ] }, \"Containers\": {}, \"Options\": { \"com.docker.network.bridge.default_bridge\": \"true\", \"com.docker.network.bridge.enable_icc\": \"true\", \"com.docker.network.bridge.enable_ip_masquerade\": \"true\", \"com.docker.network.bridge.host_binding_ipv4\": \"0.0.0.0\", \"com.docker.network.bridge.name\": \"docker0\", \"com.docker.network.driver.mtu\": \"1500\" } } ] The\u00a0bridge network name here is . When you add a container,\u00a0each of them will have\u00a0its own virtual Ethernet interface connected to the docker bridge\u00a0 and it will have an IP address allocated to the\u00a0virtual interface. This bridge will automatically forward packets between any other network interfaces that are attached to it and also allow containers to communicate with the host machine as well as with the containers on the same host. By default,\u00a0Docker containers can make connections to the outside world,\u00a0they connect via the interface but the outside world cannot connect to containers. External connectivity is provided by IP forwarding and rules. You can achieve that using the port mapping. When running Elasticsearch, you will need to ensure it\u00a0publishes to an IP address that is reachable from outside the container: this can be configured via the setting . For the discovery between the nodes you have to configure\u00a0Zen Discovery via the settings and . docker run -d -p 9200:9200 -p 9300:9300 elasticsearch:2 \\ elasticsearch \\ -Des.discovery.zen.ping.unicast.hosts=192.168.99.100,192.168.99.101 \\ -Des.discovery.zen.minimum_master_nodes=2 \\ -Des.network.publish_host=192.168.99.100 docker run -d -p 9200:9200 -p 9300:9300 elasticsearch:2 \\ elasticsearch \\ -Des.discovery.zen.ping.unicast.hosts=192.168.99.100,192.168.99.101 \\ -Des.discovery.zen.minimum_master_nodes=2 \\ -Des.network.publish_host=192.168.99.101 By default, a Docker container is configured to\u00a0use IPv4 only. It is possible to configure IPv4\/IPv6 by starting the Docker daemon with the flag. When creating a container it will get a link-local IP address. You can also assign a globally routable IPv6 addresses to your containers. Using routable IPv6 addresses allows you to realize communication between containers on different hosts. The following article provides a lot more information on this subject:\u00a0.Overlay NetworkIn recent versions of Docker they introduced a new type of network called overlay network which Docker recommends for multi-host networking. To use overlay networking you will need to setup a key-value store so that nodes can be discovered and added to the cluster: Docker currently supports only Consul, etcd, and ZooKeeper. \n"}
{"index": {"_id": 664}}
{"title":"Five-Star Videos and More: Top 10 Elastic{ON}16 Presentations","seo_title":"Five-Star Videos from Elastic{ON}16 Presentations","url":"\/blog\/five-star-videos-and-more-top-10-elasticon-16-presentations","author":{"name":"Jason Dickson"},"date":"April 13, 2016","category":"News","locales":"","content":" Elastic{ON} was a rad experience. This was my first time at our annual user conference. It was so much fun and an amazing opportunity for meeting other users, of our amazing dev team, and learning more about the Elastic Stack. For those of you who attended, I can't read all of your minds. So I can't say for sure that it was as much of an overwhelming and cool experience for you, but I did have a unique vantage point as one of the coordinators of the conference's . One thing that stood out in the mobile app comment feed again and again is that there were many great presentations happening across three stages, plus the Spotlight Theater, and the Birds of a Feather community chats in the lunch area.\u00a0It was often hard to choose which talk to attend. We have proudly shared videos of all of the great , and now want to provide you with a roundup of the\u00a0most popular talks. We had two criteria for selecting videos for this top 10 list: 1) top views on Elastic.co and 2) top-rated video (1 to 5 stars) by users from our mobile app. A handful even achieved the impressive average rating of 5 out of 5 \u2014 there are diamonds in the rough here! So we narrowed the list down to the following 10 vids. We hope you find a presentation or two that you haven't watched, or maybe didn't even realize existed. Without further delay, enjoy! 1) Logstash's creator Jordan Sissel and team lead Suyog Rao wowed the crowd when they presented \u201c,\u201d but this later talk \u2014 a technical deep dive with core developers Colin Surprenant and Andrew Cholakian \u2014 has been very popular on demand, earning a place on our list. 2) \u201cSpace\u2026 the final frontier.\u201d Oh wait, this isn't about that awesome Star Trek vs. Star Wars string wall at Elastic{ON}? My bad. This geo aggregations and visualizations talk is all about geo and Elasticsearch, and was given by core Elasticsearch developer Nick Knize, who self-describes himself as our \u201cspatial agent.\u201d 3) Probably the most anticipated and talked about new feature announced at Elastic{ON}, is now available for . Elastic's Mark Harwood and Steve Kearns revealed Graph's power to discover and explore the relevant connections in your data sets. 4) Another superstar among on-demand recordings! Elastic software engineer Spencer Alger and Director of Product Management Tanya Bragin discussed Kibana's extensibility, the goals of Kibana plugins, and resources like the plugin generator. 5) \"Here be math.\" The first talk on this list that was rated 5 stars out of 5 by you, attendees of Elastic{ON}! Elasticsearch software engineer Britta Weber spoke about BM25, the scoring algorithm of Apache Lucene 6 that will soon be the new default scoring algorithm in Elasticsearch. 6) This is another talk \u2014 featuring Elastic's Martijn van Groningen, Tal Levy, and Jim Unger \u2014 that attendees rated 5\/5 stars! 7) Also rated 5\/5 is this gem of a talk on choosing the best size and configuration of your cluster. Presented by Elastic solution architect Christian Dahlqvist and Elastic technical trainer Ryan Schneider, this features the answers to important questions that so many of you have about sizing your cluster. 8) The first talk on our list that took place in the smaller Spotlight Theater location at Elastic{ON} is all about securing Elasticsearch. Software engineer Igor Motov and security engineer Jay Modi discuss common pitfalls for securing data, document- and field-level security, and why will make integrated security across the Elastic Stack so grand. 9) You're not alone. That's the message that was sent loud and clear by Elastic's Chris Earle and Mark Walkom as they presented on the most interesting trials and tribulations our customers have shared with our . This talk was given five stars by in-app voting! 10) In one of the most popular talks from the first day of Elastic{ON}, Elastic's Clinton Gormley and Simon Willnauer walked the audience through the breaking news and big developments for Elasticsearch, including , the , and much more. We're very grateful that we were able to hang out with so many of our friends and colleagues at Elastic{ON} this year. If you haven't heard, we're doing it all again at Pier 48 next year. Hope to see all of you in San Francisco\u00a0at Elastic{ON}, March 7-9, 2017! \u00a0for notifications. \n"}
{"index": {"_id": 665}}
{"title":"Brewing in Beats: Manage dashboards per Beat","seo_title":"","url":"\/blog\/weekly-beats-manage-dashboards-per-beat","author":{"name":"Monica Sarbu"},"date":"April 11, 2016","category":"Brewing in Beats","locales":"","content":" Welcome to Brewing in Beats! With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources. Last week we released the long-expected Beats 5.0.0-alpha1 () and the patch release Beats 1.2.1 (). The highlights of the week are: Require braces in the environment variable expansion Version 1.2.0 introduced the possibility of using environment variables in the configuration file by replacing strings like or with the value of the environment variable. Together with this great feature, we also introduced a bug that replaces the environment variable when it\u2019s not wanted if the dollar sign shows up in passwords or in regular expressions. This restricts to replace the environment variable only when the form is encountered. Change exported fields for Packetbeat flowsThe re-organizes the exported fields for flows. The ip, ipv6, port, statistics and the associated location are grouped per and . In the case of flows, the is considered the one that sends the first SYN packet. Manage Kibana dashboards per Beat In the current version, the sample Kibana dashboards are available in a single for all the Beats together with a bash and powershell script to load them all in Kibana. In most of the cases, you don\u2019t need all the Kibana dashboards and only the ones for a single Beat. Last week we adjusted the bash and the powershell scripts to be able to import and export the Kibana dashboards together with visualizations, searches and index patterns to Kibana only for a single Beat. They will be available in elastic\/beats\/dev-tools with this Now it\u2019s easier to contribute with Kibana dashboards to the project. You can just create your own dashboard in Kibana for any Beat and export all the Beat dashboards together with visualizations, searches and index patterns by using the python script \u00a0Customize Discovery page for Packetbeat\u00a0Starting with 5.0.0-alpha1, Packetbeat exports two different types of data: transactions of various protocols and flows. Both are available in the index pattern, but with different values depending if it\u2019s a HTTP transaction or a flow. The creates two new searches to customize the transactions view and the flows view with the most important fields. They are already available in and you can start using them by following the . \u00a0Loading Elasticsearch template is now on by default With this , when the Beat starts the Elasticsearch template is loaded automatically by default, if it was not previously loaded. You can force to overwrite the template by enabling the option. This change is already available in 5.0.0-alpha1. If you want to learn more about this, please check the . \n"}
{"index": {"_id": 666}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-04-11","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-04-11","author":{"name":"Michael McCandless"},"date":"April 11, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsThe alpha-1 of the is here! If you\u2019re exploring it, you\u2019re an Elastic \u2014 & we\u2019ve got good news: Details: \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole Elastic\u00a0ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 667}}
{"title":"Where in the World is Elastic? - Elastic Los Angeles User Group Meetup","seo_title":"Where in the World is Elastic? - Elastic Los Angeles User Group Meetup","url":"\/blog\/witwies-elastic-los-angeles-user-group-meetup","author":{"name":"Megan Wieling"},"date":"April 11, 2016","category":"","locales":"","content":" Welcome to Find out which Elastic events and meetups are happening near you in the next two\u00a0weeks.Upcoming EventsApril 18: April 19:\u00a0April 20-22: April 19: April 19:\u00a0April 23-24:\u00a0April 21-23:\u00a0Upcoming MeetupsApril 13: April 14: April 18: April 19:\u00a0April 19: April 19:\u00a0April 20:\u00a0April 20: April 12:\u00a0April 12:\u00a0April 14: April 14: April 14: April 16:\u00a0April 19: April 19:\u00a0April 20:\u00a0April 20:\u00a0April 20:\u00a0April 21:\u00a0April 21:\u00a0April 21:\u00a0That's it for this week. Stay tuned next week for more Elastic happenings.- The Elastic TeamP.S.\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}
{"index": {"_id": 668}}
{"title":"Elasticsearch for Apache Hadoop 2.3.0 and 2.2.1 released","seo_title":"Elasticsearch for Apache Hadoop 2.3.0 and 2.2.1 released","url":"\/blog\/es-hadoop-2-3-0-and-2-2-1-released","author":{"name":"Costin Leau"},"date":"April 08, 2016","category":"Releases","locales":"","content":" Joining the release train this week, Elasticsearch for Apache Hadoop and are now out containing compatibility improvements and bug fixes. Users are recommend to upgrade as soon as possible to take advantage of these. As always, the artifacts are available at the and or . Important fixes HDFS repository compatibility with Elasticsearch 2.3.0 For those that missed it, Elasticsearch 5.0.0 alpha1 was a few days back and among its bundle of features, ships out of the box with the repository hdfs plugin. As such, pending any unforeseen events, ES-Hadoop 2.3 will be the last release cycle containing the HDFS plugin repository. Optimized network transfer for fixed routing When using a fixed or predefined routing, the connector optimizes the network request to hit only the target shards (whether it is for reads or writes). Improved indexing of Spark s The check for empty Spark s has been tweaked to avoid triggering loading of the content, especially important when using disk persistence or no caching. Better detection of shards overlap The algorithm for checking overlapping shards has been improved (thanks to a user ) to use significantly less memory and thus, increasing the limit of indices it can work on. Last 2.2. release Alongside 2.3, ES-Hadoop 2.2.1 is released as the last planned maintenance release in the 2.2.x line. It contains a series of backported bug-fixes for those with conservatory upgrade paths. However even if you are on ES 1.x, upgrading to ES-Hadoop 2.3 is highly recommended. Feedback Looking forward to hearing your feedback on ! You can find us on , Twitter () or the . works too. \n"}
{"index": {"_id": 669}}
{"title":"How to make a Dockerfile for Elasticsearch","seo_title":"","url":"\/blog\/how-to-make-a-dockerfile-for-elasticsearch","author":{"name":"Henrik Nordvik"},"date":"April 08, 2016","category":"Engineering","locales":"","content":" How to make a Dockerfile for ElasticsearchDocker containers gives you a way to ship and run applications with their environment in an isolated and repeatable way. While there are a myriad of Docker images out there , creating your own Dockerfile allows you to customize it, for instance by installing plugins, changing the base image, strip out what you don't need, etc. Dockerfiles also act as a way to document how an application gets installed and deployed. In this introductory post we will go through how to create a Dockerfile from scratch for running Elasticsearch, and discuss a few things that you need to consider when creating your own. Building the imageA Dockerfile is a recipe with steps describing how to build your Docker image. You start from a base image, which gives you the basics needed for\u00a0running applications, then run steps on top of that, which results in a new image. If you want you can also use the resulting image as a base image for another image. The simplest Dockerfile you can create is something like this: FROM ubuntu:14.04 Put this in a file called\u00a0.\u00a0You can now build it by running: docker build -t my-es-image . The image has been built and can be run with: docker run --rm -it my-es-image \/bin\/bash While this created an image that is not very useful, we have now learned how to build and test an image. Now let\u2019s create a more useful one. Since Elasticsearch requires Java to run, let\u2019s install it first. FROM ubuntu:14.04 ENV DEBIAN_FRONTEND=noninteractive RUN apt-get install -y --no-install-recommends software-properties-common && add-apt-repository -y ppa:webupd8team\/java && \\ apt-get update && \\ (echo oracle-java8-installer shared\/accepted-oracle-license-v1-1 select true | sudo \/usr\/bin\/debconf-set-selections) && \\ apt-get install --no-install-recommends -y oracle-java8-installer && \\ rm -rf \/var\/cache\/oracle-jdk8-installer && \\ echo \"networkaddress.cache.ttl=60\" >> \/usr\/lib\/jvm\/java-8-oracle\/jre\/lib\/security\/java.security && \\ apt-get clean && rm -rf \/var\/lib\/apt\/lists\/* ENV JAVA_HOME \/usr\/lib\/jvm\/java-8-oracle This one installs Oracle JDK 8. If you build and run it with the\u00a0\u00a0command above then you can test that is works by running . At this point we\u2019re ready to install Elasticsearch. Let\u2019s use the apt package. RUN groupadd -g 1000 elasticsearch && useradd elasticsearch -u 1000 -g 1000 RUN apt-key adv --keyserver pgp.mit.edu --recv-keys 46095ACC8548582C1A2699A9D27D666CD88E42B4 && \\ add-apt-repository -y \"deb http:\/\/packages.elastic.co\/elasticsearch\/2.x\/debian stable main\" --keyserver https:\/\/pgp.mit.edu\/ && \\ apt-get update && \\ apt-get install -y --no-install-recommends elasticsearch WORKDIR \/usr\/share\/elasticsearch RUN set -ex && for path in data logs config config\/scripts: do \\ mkdir -p \"$path\": \\ chown -R elasticsearch:elasticsearch \"$path\": \\ done Before we run it, we should add an elasticsearch.yml file. Create a file named\u00a0 in the same directory as the Dockerfile, with this content: cluster.name: \"docker-cluster\" network.host: 0.0.0.0 Also, to get logging to work with docker we should add a simple\u00a0 file: rootLogger: INFO,console appender: console: type: console layout: type: consolePattern conversionPattern: \"[%d{ISO8601}][%-5p][%-25c] %m%n\" Note: When running with logging to stdout\/stderr Docker stores the log in a json file, and it is recommended to specify a max size for the log file to rotate, and a max number of files to keep. E.g.\u00a0 To add these files to the container we add the following to the Dockerfile: COPY logging.yml \/usr\/share\/elasticsearch\/config\/ COPY elasticsearch.yml \/usr\/share\/elasticsearch\/config\/ This will bake the files into the image when running\u00a0. \u00a0What\u2019s left now is to actually make the container run Elasticsearch at startup. USER elasticsearch ENV PATH=$PATH:\/usr\/share\/elasticsearch\/bin CMD [\"elasticsearch\"] EXPOSE 9200 9300 To run this, first build it as before, and then run with\u00a0. This opens port 9200 from the container to the host and runs CMD. You should now see the Elasticsearch instance starting. Note that currently this Elasticsearch instance does not persist the data between runs, since it is ephemeral and we didn\u2019t specify any data volumes. Persistent storage volumesStoring data persistently in Docker requires the use of volumes. Volumes are a bit tricky because of the way it works with permissions. By default volumes are using bind-mount, which means that a file belonging to a user with ID 1000 inside the container will be owned by user 1000 on the host, which may or may not be the same actual user.\u00a0Docker are working on a way of fixing this, and it has been\u00a0partially implemented, but we need \u201cphase 2\u201d of user namespaces to solve this fully. In the meantime, we need some workaround for storing the data. One way to get around it is to hard code the User ID and make sure that it is the same on all machines running that container.\u00a0If we only care that the data is persisted between restarts, another way is to let the container create the volume so the permissions are correct for the container, since we don\u2019t need to access the container contents from the host machine. Let\u2019s do the latter approach\u00a0that with a feature called \u201cnamed volumes\u201d. Create a named volume: docker volume create --name esdata You can mount that volume using the\u00a0\u00a0option: docker run --rm -ti -p 9200:9200 -v esdata:\/usr\/share\/elasticsearch\/data my-es-image Even if you restart your Elasticsearch container now it should preserve all data. Note: This requires at least version 1.10 of Docker Memory and heap sizeBy default memory for a container is unbounded. If you want to limit for the max memory the container uses you can specify e.g.\u00a0 with . You should also set the heap size for Elasticsearch. The normal recommendation with allocating half of the memory to the heap also applies. For example: docker run --rm -ti -p 9200:9200 -v esdata:\/usr\/share\/elasticsearch\/data --memory=\"4g\" -e ES_HEAP_SIZE=2g my-es-image ConclusionWe have created a basic docker image which runs Elasticsearch and stores\u00a0the data persistently. It is basic, but it's a starting point. Next steps could be to and , which we will look at in follow-up blog posts. \n"}
{"index": {"_id": 670}}
{"title":"Beats 1.2.1 released","seo_title":"","url":"\/blog\/beats-1-2-1-released","author":{"name":"Monica Sarbu"},"date":"April 07, 2016","category":"Releases","locales":"","content":" Today we are pleased to announce the bug fix release of Beats 1.2.1. Change the behaviour of environment variables expansion Version 1.2.0 introduced the possibility of using . This is a great feature because it allows you to inject settings via environment variables, but the way it was initially implemented was a bit too simplistic. The way it worked was that before parsing the configuration file, the code simply replaced strings like or with the value of the environment variable. However, we didn't account for the usage of as a literal in configurations files.\u00a0For example, if a dollar sign shows up in a password or in a regular expression, it will get removed together with the word next to it. This can break existing configuration files. In Beats 1.2.1 we restrict to one form and replace only with the value of the environment variable. We started our own to improve the environment variables expansion so\u00a0that it works only on selected options. Add username to Topbeat We were planning to add support for reporting the user name of a process in Beats 1.2.0, but we discovered in the late stages of QA that it doesn\u2019t actually work, so we removed it from the release notes. It is now fully working in Beats 1.2.1. Other fixes coming with Beats 1.2.1 Send us feedback!A big Thank You to everyone who contributed code, reported issues, created a new Beat or just tried the Beats. Start your experience with\u00a0 and let us know what you think on ,\u00a0,\u00a0or open an issue on . \n"}
{"index": {"_id": 671}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-04-05","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-04-05","author":{"name":"Michael McCandless"},"date":"April 07, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top News release w\/ 6, ingest node, & more! Details:\u00a0\u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole Elastic\u00a0ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 672}}
{"title":"Explore the Elastic Stack 5.0 with the Elastic Pioneer Program","seo_title":"","url":"\/blog\/elastic-pioneer-program","author":{"name":"Michelle Carroll"},"date":"April 07, 2016","category":"News","locales":"","content":" This week, we released the alpha 1 of the . You can test the new goodness in the Elastic Stack 5.0 today, by . This pre-release period is incredibly important. As much as we test the software before release, there are users with environments we haven\u2019t conceived of, and folks using the Elastic Stack in ways we\u2019ve never seen. We want to know the limits of our stack, and do everything we can to improve it before general release. We\u2019re launching the Elastic Pioneer Program to encourage folks to try the latest version. What is the Elastic Pioneer Program?We\u2019re very excited about these upcoming Elastic Stack Version 5.0 releases, but we want to make sure they\u2019re perfect (or as perfect as software gets) before they ship more broadly. Everyone who reports a legitimate bug on the pre-release of the software will be recognized for the wider release, and receive a special Elastic gift package as our thank you. If you find something particularly tricky, you could also earn a free ticket to , coming up next March 7 \u2013 9 in San Francisco. How to participateTo join the program, just try out the pre-release of any (preferably, every) part of the Elastic Stack, and open issues as you find them in the appropriate repo (, , , ) or forum\u00a0().\u00a0When you open an issue, mention that you found the bug in 5.0.0-alpha1\/2\/beta1, and we\u2019ll add a \u201cPioneer Program\u201d label. While we appreciate the information, duplicate issues won\u2019t enter you into the program.: This is an alpha release and is intended for purposes only. There is no guarantee that any of the 5.0.0-alpha1 versions will be compatible with other pre-releases, or the 5.0.0 GA. We strongly recommend that you keep this far, far away from production. We hope you\u2019ll join us in trying the pre-release versions of the Elastic Stack 5.0! , or . \n"}
{"index": {"_id": 673}}
{"title":"USAA, Security Analytics, and a Journey to the Elastic Stack","seo_title":"USAA, Security Analytics and the Elastic Stack","url":"\/blog\/usaa-security-analytics-journey-to-the-elastic-stack","author":{"name":"Jason Dickson"},"date":"April 07, 2016","category":"User Stories","locales":"","content":" Is your company getting the most out of its SIEM and log management solutions? Allow us to share a story with a happy ending. It's about a company that needed the best way to analyze their ever-growing data, in order to protect personal information and other sensitive files. The analysts now enjoy faster, easier data management, while predicting and averting cyber threats all along the way \u2026 all while USAA saves money. USAA is a financial institution serving the U.S. military community, and Neelsen \"Nelly\" Cyrus has been a part of that institution for almost two decades. As a senior security analyst in the company's Cyber Threat Operations Center (CTOC), his primary focus is infrastructure support. At in San Francisco, we were honored to host Nelly and five other attendees from the USAA CTOC.USAA's 93-year history stretches back to a group of U.S. Army officers who saw a need for auto insurance when other insurers had classified military officers as \"high risk.\" Today, employs over 26,000 people, boasts a multi-billion dollar annual net income, and has been consistently named one of the over the past 11 years by . At Elastic{ON}, Nelly presented on USAA's transition to the Elastic Stack from a security information and event management (SIEM) solution \u2014 a transition that saved the company money and improved productivity among the company's security analysts. The presentation included a recipe for \"hunting\" \u2014 the practice of information security analysts proactively seeking out malicious activity and vulnerabilities before harm is done. Hunters have to think like attackers and block off routes before they can be exploited. As the volume of these attacks is ever-increasing, analysts like Nelly and the team at USAA CTOC rely on technology like the Elastic Stack for effective logging and constant monitoring for malicious activity. USAA traditionally invested in large enterprise solutions. Advocating the Elastic Stack, an open source product, up the chain of command for use at the size and scale needed by the CTOC team was challenging. However, the available from Elastic's world-class engineers made all the difference. \"We know that they're there, and they've proven it time and time again,\" Nelly said. One manager assured Nelly that he made the right move. The cost was easily justifiable based on seeing analyst productivity improvements.In production, USAA's Elastic Stack deployment has grown to seven clusters, grouped by feed type \u2014 feeds change often but include \"almost all of the major security appliances,\" Unix and Windows server events, etc. \u2014 after they broke up their single, monolithic cluster (and upgraded ) about two months before Elastic{ON}16. They send 24 feeds into Elasticsearch, with between 2 billion and 4 billion security events daily and an average of about 52,700 events per second. They have 53.11 billion documents in their store. About moving to the multi-cluster setup, Nelly noted that they cut the time it takes to create a snapshot of their data from 20+ hours to 10 hours, with the snapshots executed in parallel. It's important for all companies to back up data, but keenly important for those in financial and military spaces like USAA. The great thing about Elasticsearch's snapshot API is that after the first backup process, subsequent snapshots save the delta change between the existing snapshots and new data. Transmitting far less data means snapshots takes less valuable time away from CTOC personnel.Bottom line: USAA's old SIEM and old log management solution weren't giving them the same bang for the buck that the Elastic Stack does today. Elastic quickly became an integral part of USAA's cyber threat prevention process, and the speed and scale of Elastic helps these analysts ask questions (and find answers) that they couldn't ask before\u00a0\u2014 and if this interests you, definitely watch the recording and hear all about Nelly's eight steps for hunting success.And if you want to check out\u00a0more Elastic{ON} security analytics presentations, we suggest with FireEye, by Cisco's Talos, from last year's Elastic{ON} Tour \u2014 Los Angeles, and with Decision Lab at Elastic{ON} Tour \u2014 Washington, D.C. Nelly is also active in the San Antonio DevOps\u00a0Meetup. If you are in the San Antonio, Texas, area , attend to learn\u00a0about the USAA use case and more. \n"}
{"index": {"_id": 674}}
{"title":"Logstash 2.3.1 and 2.2.4 Released","seo_title":"Logstash 2.3.1 and 2.2.4 Released","url":"\/blog\/logstash-2.3.1-and-2.2.4-released","author":{"name":"Andrew Cholakian"},"date":"April 07, 2016","category":"Releases","locales":"","content":" Hot on the heels of 2.3.0 and 2.2.3, we\u2019ve released Logstash 2.3.1 and Logstash 2.2.4 which contain important compatibility and security updates. We highly recommend that all users upgrade to either version immediately.\u00a0You can read the detailed release notes , or jump directly to our if you can't wait to test drive this release! Additionally, we've released an update to the 2.2.x series, with a bunch of important bugs packaged in 2.2.4. You can read the changelog for 2.2.4\u00a0.Regression in Regex handling in JRubyThe upgraded version of JRuby we included in 2.3.0 contained an important fix for Windows users, but introduced a dangerous thread safety bug for regular expressions used within Logstash. Environment Variable Support Now Deactivated By DefaultWe are very excited to have introduced support for environment variables in configuration files in Logstash 2.3.0! However, we didn\u2019t anticipate that some existing configs would be incompatible with this change. The environment variable support we added treats or characters as part of our new variable syntax. This creates problems for people using the characters for other purposes, such as in password values. As such, we have disabled environment variable interpolation by default in 2.3.1 to make the upgrade path easier. You can enable it in 2.3.1 with the flag on the CLI. In addition, we have removed support for environment variables completely. Only the syntax will be supported going forward as it minimizes the potential for conflicts. This change was completed in Fixed Broken ConditionalsLogstash 2.3.0 includes our new dynamic reloading feature. A change to the pipeline internals required by this feature caused conditionals (anywhere an was used in a config) to not work correctly. This was fixed in . Logstash versions prior to 2.3.0 were not affected by this bug. Reverting the new Java Event In Logstash 2.3.1The new pure Java implementation of the Event class Logstash 2.3.1 is lightning fast, but unfortunately not as compatible as we\u2019d have liked for a minor release. In particular, it could cause problems with some custom Ruby filter scripts and custom plugins from the community. We take our commitment to compatibility, and versioning semantics, seriously. Though we have reverted to the prior Ruby Event implementation, the Java version remains the correct technical direction and we will most likely be reintroducing it in Logstash 5.0 if not sooner. If any breaking changes need to be made, we will ensure these changes are communicated as clearly and broadly as possible. Passwords Printed in Log Files under Some ConditionsIt was discovered that, in Logstash 2.1.0+, log messages generated by a stalled pipeline during shutdown will print plaintext contents of password fields. While investigating this issue we also discovered that debug logging has included this data for quite some time. Our latest releases fix both leaks. You will want to scrub old log files if this is of particular concern to you. This was fixed in issue Fixed Config Test Flag in Logstash 2.3.0The Logstash 2.3.0 release inadvertently broke the option, this has been fixed in Logstash 2.3.1. This was fixed in issue Other IssuesThe accounting of issues fixed in the Logstash 2.3.1 \/ 2.2.4 release is tracked on issue . FeedbackWe are super excited for this release of Logstash and look forward to your feedback. You can reach us at our , open issues in our , or tweet at us . Happy 'stashing! \n"}
{"index": {"_id": 675}}
{"title":"Video: Describe Elasticsearch in 3 Words","seo_title":"Describe Elasticsearch in Three Words","url":"\/blog\/elasticsearch-in-3","author":{"name":"Scott Fingerhut"},"date":"April 06, 2016","category":"Culture","locales":"","content":" During our annual conference in San Francisco, our roving reporter captured some great insights from attendees. If you didn't catch \"\", check that one out. We filmed that at the Elastic{ON} party where alcohol may have played some role.\u00a0 This time, on the conference floor, we asked attendees to describe Elasticsearch in just three words.\u00a0There were certainly plenty that told us Elasticsearch was fast and scaled. But you'll have to watch the video to see some of the other ones. \n"}
{"index": {"_id": 676}}
{"title":"Beats 5.0.0-alpha1 released","seo_title":"","url":"\/blog\/beats-5-0-0-alpha1-released","author":{"name":"Tudor Golubenco"},"date":"April 05, 2016","category":"Releases","locales":"","content":" At almost precisely a year after the Packetbeat team has joined Elastic, we\u2019re excited to reveal the first alpha release of the Filebeat, Packetbeat, Topbeat, and Winlogbeat next major versions. One version to rule them allYou might be wondering why we\u2019re jumping from version 1.2 directly to 5.0. To make our software suddenly more stable and to one-up our competition, of course. In seriousness, all the projects in the Elastic stack are doing releases in sync and will use the same version numbers from now on. As Kibana is currently at 4.5, we\u2019re all going with 5.0 as the next major. This is to avoid the support matrix from hell, for example now you need to know that Beats 1.2 were tested against Elasticsearch 2.3, Logstash 2.3 and Kibana 4.5. \u00a0Starting with 5.0, you\u2019ll know that if Beats and Elasticsearch have the same version number, they were released at the same time and we have tested them together. It simplifies communication all around. New FeaturesBeats 5.0-alpha1 comes packed with new features and you can expect more of them to land in during the alpha and beta phases. Here are some of the highlights from Alpha 1: Custom fields and generic filteringYou now have more freedom over how the documents created by the Beats look like. On one hand, you can now add custom fields and tags per Beat and module. On the other hand, you can use the newly introduced to remove the fields that you don\u2019t want. These features are implemented at the libbeat level, meaning that all automatically benefit from them as soon as they upgrade. JSON support in FilebeatFilebeat can now natively objects from log lines. This is useful for structured logging, where the logging library writes the metadata directly formatted as JSON. This can also be used as a convenient way of collecting logs from Docker hosts, because Docker uses JSON to wrap the log lines from the application. Integration with Ingest NodeThe new functionality, released with Elasticsearch 5.0.0-alpha1, is big news because it gives users processing capabilities similar with Logstash directly in Elasticsearch! This makes it really easy to get started with the Elastic stack. For simple logging usecases, for example, you only need Filebeat and Elasticsearch. All Beats can work with the Ingest Node, simply set the in the Elasticsearch output configuration. Packetbeat IP\/TCP flowsSo far Packetbeat was focused on the application layer protocols, giving you visibility into the business transactions as seen in the network. Packetbeat now also reports statistics like packet count and byte count about IP and TCP flows, regardless of the upper layer protocols. This opens Packetbeat to a new set of use cases, giving insights into how the traffic is flowing through the network. Kafka outputWe listened to your feedback and we\u2019ve added Kafka output support in Beats, at the same time removing the deprecation mark for the Redis output. This means that if you are passing all messages through a Kafka queue anyway, you won\u2019t need a Logstash instance to convert between Beats and Kafka. Winlogbeat improvementsWinlogbeat now extracts all the fields from Windows event log records including the EventData and UserData fields and includes them in the documents it indexes. In addition, now it is possible to select events by event ID, level, and provider. Winlogbeat efficiently implements this event selection by using a query with Windows APIs so that only the requested events are returned. Don\u2019t fear the alphaGetting your feedback early is key for us to make the necessary adjustments in time for the 5.0 GA release, so please test early and often.\u00a0You can find us on discuss for question and discussion and on Github for issues and enhancement requests. \n"}
{"index": {"_id": 677}}
{"title":"Elastic Stack Release - 5.0.0 alpha 1","seo_title":"Elastic Stack Release - 5.0.0 alpha 1","url":"\/blog\/elastic-stack-release-5-0-0-alpha-1","author":{"name":"Shay Banon"},"date":"April 05, 2016","category":"News","locales":"ja-jp","content":" At Elastic{ON} we announced the Elastic Stack. Before diving into detail about the 5.0\u00a0alpha release, let us review why this release is so important. When we say \u201c,\u201d we are making a powerful statement about how we develop our products and how our community and customers will consume those products. The Elastic Stack is more than just a name. It is an investment in building, testing, and releasing all products together. Recognizing this, we incremented the version number to . This is not just about our release cycles. It is a commitment to make it easier for developers to add new functionality not just to a single product, but to the entire Stack. Which brings us to the notion of \u201cpacks.\u201d Packs are bundled extensions for the whole Elastic Stack - and they\u2019re key in making your life easier. Say heya to the X-Pack. Naming things is the greatest challenge in computer science: perhaps only surpassed by exactly-once delivery, guaranteed messages of order, and exactly-once delivery. Marvel, Shield, and Watcher will be product names no longer. (Quick, can you tell us which product performed which feature?) Rather, all commercial capabilities are combined into X-Pack, which includes security, alerting, monitoring, Graph, and reporting features. This ensures a consistent experience during installation and usage. In addition, features (like security) will apply to the entirety of the Stack. In addition, we will soon be announcing the Elastic Pioneer Program to recognize community participation. The feedback garnered during the 2.0 release was invaluable. Help us make 5.0 the most scrutinized release ever. Happy and testing! Keep in mind, it is an alpha so don\u2019t put it into production. Given that this is an alpha release, it is not available on . We expect a release candidate version of 5.0.0 in the coming months which we\u2019ll make available on Elastic Cloud, the best hosted Elastic Stack. Let\u2019s explore a few of the alpha details at a high-level. Elasticsearch For more detailed information, and quite a few other features, peruse the . Kibana For more detailed information, view the . As a note: \u00a0No, we haven\u2019t lost our senses. \u00a0But 5.0.0 alpha 1 has temporarily lost its Sense. Sense will remain open source and will be built into Kibana, directly, as \u201cConsole\u201d. But it is not yet available in this release. Logstash For more detailed information, grok the . Beats For more detailed information, a lightweight (at the edge). X-Pack X-Pack is a single extension for Elasticsearch and Kibana that brings together the functionality of Shield, Watcher, Marvel, Graph, and adds new Reporting capabilities. All of the products now install together, have the sleek new Kibana 5 design, and it\u2019s easier than ever to ! Among the new features and improvements, Reporting is a highlight: \n"}
{"index": {"_id": 678}}
{"title":"Elasticsearch 5.0.0-alpha1 released","seo_title":"Elasticsearch 5.0.0-alpha1 released","url":"\/blog\/elasticsearch-5-0-0-alpha1-released","author":{"name":"Clinton Gormley"},"date":"April 05, 2016","category":"Releases","locales":"","content":" Today we are excited to announce the release of based on . This is the first in a series of pre-5.0.0 releases designed to let you test out\u00a0your application with the features and changes coming in 5.0.0, and to give us feedback about any problems that you encounter. \u00a0This is an alpha release and is intended for\u00a0. Indices created in this version\u00a0. Upgrading 5.0.0-alpha1\u00a0to any other version is not supported. Elasticsearch 5.0.0-alpha1 is jam packed with awesome new features, with more to be added before we release 5.0.0 GA. \n"}
{"index": {"_id": 679}}
{"title":"Kibana 5.0.0-alpha1 released","seo_title":"Kibana 5.0.0-alpha1 released","url":"\/blog\/kibana-5-0-0-alpha1","author":{"name":"Court Ewing"},"date":"April 05, 2016","category":"Releases","locales":"","content":" Kibana 5 is the best thing since sliced bread. There, I\u2019ve said it. You know what? It\u2019s better than sliced bread. Kibana 5 is going to dethrone bread as the universal standard of goodness. And you can take a bite out of this bad boy right now: today we\u2019re sharing with the world the first alpha release of Kibana 5. If you\u2019re already salivating, pick up the Kibana 5.0.0-alpha1 from the page. This is software that will only work with . Please test it, but do use it in production. So what\u2019s new in Kibana 5? A new design That\u2019s right, we redesigned it. Where Kibana 4 was dreary, Kibana 5 is bright and colorful. Where Kibana 4 wasted countless pixels on unnecessary navigation and chrome, Kibana 5 lets the borders fall away and brings a new focus on your data. Where Kibana\u2026 ah forget it. Just see for yourself: First-class applications Since the plugin system was launched in 4.2, people have been building entire applications on top of Kibana. In Sense and Timelion, we created two such applications ourselves, but even they have been relegated to a tiny \u201capp switcher\u201d that is mostly hidden away in the toolbar. In Kibana 5, all applications are first-class citizens. Applications added by any plugin will appear in the main navigation alongside the Kibana favorites: discover, visualize, and dashboard. Packs, and a new plugin installer I\u2019m sure you all loved installing every single plugin by hand as well as always remembering the exact plugin version that was compatible with your current version of Kibana. And off the top of your head, I bet you can recite exactly which organization name we arbitrarily chose to use for any given plugin of our own. But despite those \u201ccharms\u201d of the existing plugin installer, we decided to make it a bit easier this time around anyway. In Kibana 5, one or more plugins can be bundled and installed as a single pack. Want to install a third party pack? Just give it a url: Or how about one of our own - perhaps timelion\u2019s your cup of tea: Want security, monitoring, reporting, and graph? Grab them all as a single pack: What is it not? Great question, me! Kibana 5 is not a rewrite from the ground up. We ripped that band-aid off long ago, and while necessary at the time, a massive overhaul of the entire application is no longer required to take a huge step forward like we have in Kibana 5. This alpha release is also not production ready. There are a bunch of known issues, and there are no doubt many more that we haven\u2019t discovered yet. There will be tons of commits coming into 5.0 over the next few weeks and months, and we\u2019ll probably break a few new things as well. This release isn\u2019t even feature-complete. We have a ton of features that we\u2019re still working on that we want to get into 5.0. Sense, for example. We\u2019re bringing that whole plugin into Kibana core, but that work isn\u2019t finished yet, so alpha1 is Senseless. What\u2019s next? Well, alpha2 of course! We\u2019re already working on it, and it\u2019s going to be even better than this. When Kibana 5.0 stable ships, these Kibana pre-releases will have bogarted the whole goodness leaderboard, and there will be no bread in sight. Too far with that analogy, eh? Anyway, we hope that you\u2019ll download this alpha and try it out. We\u2019d love to get your feedback on our , , or even , and please post any bugs you find directly to our . \n"}
{"index": {"_id": 680}}
{"title":"Logstash 5.0.0-alpha1 released","seo_title":"","url":"\/blog\/logstash-5-0-0-alpha1-released","author":{"name":"Pier-Hugues Pellerin"},"date":"April 05, 2016","category":"Releases","locales":"","content":" We are excited to announce the availability of the first pre-release version for Logstash 5.0.0. Wait, what? 5.0.0? Yep, the next major version will be 5.0.0. In case you missed our during Elastic{ON} 2016, we've decided to align all the components of the Elastic Stack to a single version. You can find the release notes or head straight to the page if you can't wait to try it out. IMPORTANT: This is an alpha release and is intended for testing purposes only. There is no guarantee that Logstash 5.0.0-alpha1 will be compatible with other pre-releases, and 5.0.0 GA. Monitor All The Things!Over the last couple of releases, we've been working hard to make Logstash easier to manage operationally. Our goal is to make it a breeze to configure and deploy multiple Logstash instances, and in 5.x we'll continue to add features to support this initiative. In this release, we are pleased to introduce the first set of which will provide more visibility into the Logstash pipeline. Event StatsWant to measure the number of events processed by Logstash? We've got an API for that now - curl localhost:9600\/_node\/stats?pretty{ \"events\" : { \"in\" : 15000, \"filtered\" : 14875, \"out\" : 14000 }, \"jvm\" : { \"timestamp\" : 1459393492170, \"uptime_in_millis\" : 18731, \"mem\" : { \"heap_used_in_bytes\" : 245625232, \"heap_used_percent\" : 11, .... Hot ThreadsIf you've used the in Elasticsearch, you know how useful it can be for debugging hotspots in your cluster. Well, now, you can do the same thing in Logstash! The new provides stacktrace from top 3 Java threads that are consuming the most CPU.curl localhost:9600\/_node\/hot_threads?human Hot threads at 2016-03-30T20:08:22-07:00, busiestThreads=3: 5.22 % of of cpu usage by waiting thread named '[main]>worker3' java.lang.Object.wait(Native Method) java.lang.Object.wait(Object.java:460) org.jruby.RubyThread$SleepTask.run(RubyThread.java:1050) org.jruby.RubyThread.executeBlockingTask(RubyThread.java:1066) org.jruby.RubyThread.wait_timeout(RubyThread.java:1414) org.jruby.ext.thread.Queue.pop(Queue.java:152) org.jruby.ext.thread.Queue.pop(Queue.java:127) org.jruby.ext.thread.SizedQueue.pop(SizedQueue.java:111) org.jruby.ext.thread.SizedQueue$INVOKER$i$pop.call(SizedQueue$INVOKER$i$pop.gen) org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:134) 2.44 % of of cpu usage by timed_waiting thread named '[main]-pipeline-manager' java.lang.Object.wait(Native Method) .... We are big fans of APIs here at Elastic \u2014 we love providing access to all kind of metrics into the working of our software. Next up, in Logstash, we are targeting stats at a plugin level granularity. For example, it would be great to know how long (on average) an event spends in grok filter, geoip filter etc. You'll be able to do this soon. How 'bout a monitoring UI, you ask? A Kibana app to visualize all these metrics across a period of time is in the works! So, stay tuned!Kafka 0.9 SupportApache Kafka had 0.9 couple of months ago which brings in new security features (SSL, client based auth, access control), improved consumer API, and much more. This Logstash release provides support for SSL encryption and client auth features in Kafka. Some of the configuration options in the consumer have changed \u2014 as such this plugin is not backward compatible. To use these new security features, you'd need to upgrade the Kafka broker to 0.9bin\/plugin is now bin\/logstash-pluginWe'd like to note that bin\/plugin command \u2014 which is used to manage plugins \u2014 has been renamed to bin\/logstash-plugin command. The main reason was to prevent PATH being polluted when other components of the are installed on the same instance. Also, this new command will be enhanced in upcoming versions to work with cross-component plugin packs.Elasticsearch 5.0.0 CompatibilityThis alpha1 release works out of the box with Elasticsearch 5.0.0-alpha1! Also, you'll be able to use any 2.x Elasticsearch version with Logstash 5.0.0-alpha1. So, go ahead and give it a try!Moar FeaturesIn case you missed it, 5.0.0-alpha1 has all the goodies that came in version 2.3.0. We're excited about new features like dynamic config reloading and environment variables support in the configuration. Plus, there was a big bump in performance in 2.3.0! Read about all these features in our 2.3.0 .Known ChangeBe aware that if you're using the Ruby filter, your code may not execute as previously\u00a0expected in this release. We're working on a fix and please consult the workarounds \u00a0for now.FeedbackPlease try this pre-release and let us know what you think! Your feedback and contribution is really important as we continue to iterate on 5.0.0! You can create issues on our , find us on our , or hang out with us on IRC (#logstash). \n"}
{"index": {"_id": 681}}
{"title":"Where in the World is Elastic? - Lone Star PHP and Meetups Worldwide","seo_title":"Where in the World is Elastic? - Lone Star PHP and Meetups Worldwide","url":"\/blog\/witwies-lone-star-php-meetups-worldwide","author":{"name":"Megan Wieling"},"date":"April 05, 2016","category":"","locales":"","content":" Welcome to Find out which Elastic events and meetups are happening near you in the next two\u00a0weeks.Upcoming EventsApril 7-9: Upcoming MeetupsApril 7:\u00a0April 13: April 14: April 5: April 5: April 6: April 7: April 7: April 7: April 14: April 14: April 14: April 9: April 16: April 6: April 11: That's it for this week. Stay tuned next week for more Elastic happenings.- The Elastic TeamP.S.\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}
{"index": {"_id": 682}}
{"title":"Integrating Salesforce Event Monitoring with the Elastic Stack \u2014 An Elastic{ON}16<\/sup> Reflection","seo_title":"","url":"\/blog\/integrating-salesforce-event-monitoring-with-elastic-stack-an-elasticon-reflection","author":{"name":"Adam Torman"},"date":"April 05, 2016","category":"User Stories","locales":"","content":" Over a year ago, Abhishek Sreenivasa and I went to Strata + Hadoop World in San Jose to learn more about processing large amounts of Big Data using systems like Hadoop. Abhishek and I worked on a product called Event Monitoring, part of the Salesforce Shield product line.While at Strata + Hadoop World, Abhishek and I attended an awesome tutorial called hosted by . Why this particular tutorial? Well, as a product manager, I hear lots of requests from customers to work with event and log data and one of those requests was to visualize it using the Elastic Stack and Kibana. And as a kick-ass engineer, Abhishek loves building inspiring applications that demonstrate the power of our product, Event Monitoring. So we attended the tutorial, which became the inspiration for an Elastic Stack that Abhishek created with our intern, Mohammed Islam.Fast forward a year, Abhishek and I were at Pier 48, standing on stage at our first Elastic{ON} conference. We were talking about ', which was about the integration between Salesforce Event Monitoring and the Elastic Stack. The speaking engagement was stupendous \u2014 Abhishek crushed his explanation of how he designed and built the plug-in with Mohammed.But\u00a0the most remarkable connection that was made was in discovering that our host and emcee for the session was none other than Kurt Hurtado: the same instructor who gave us our introduction to the Elastic Stack. I wouldn\u2019t say that the students became the masters, but I would absolutely emphasize the amazingness of the people who work at Elastic to make open source a viable and supported solution for the enterprise.And that was really the experience we had with everyone we met at the conference, from the Elastic AMA (Ask Me Anything) genius bar to the spontaneous conversations struck up in the heart of the pier, where we connected with people who shared our respect for large scale event management and visualizations, all while eating artisan food truck-catered lunch.Connections and network effects were definitely the theme for the conference. There was a string wall where attendees could provide input about ourselves, while comparing Star Wars to Star Trek.Elastic{ON} was a uniquely enjoyable conference experience. Connecting with people spontaneously, sharing what we built on top of the Elastic Stack, and learning more about how we can continue to work with Elastic were all highlights of this fantastic conference.Adam has worked at Salesforce for the past 10 years, both in professional services and as a platform product manager. In that time, among other achievements, he introduced a new way of layering user access controls called Permission Sets and built a product called Event Monitoring that easily integrates low level server application logs with a customer's SIEM or business intelligence reporting tools. On his ,\u00a0Adam provides tips and tricks for building security into every customer organization.Abhishek Sreenivasa is a software developer at Salesforce. He works on Platform Monitoring team that develops self-service Event Monitoring feature. Events from this feature are used by Salesforce customers for security audits and measuring application performance and feature adoption. \n"}
{"index": {"_id": 683}}
{"title":"A Heap of Trouble: Managing Elasticsearch's Managed Heap","seo_title":"","url":"\/blog\/a-heap-of-trouble","author":{"name":"Jason Tedor"},"date":"April 04, 2016","category":"Engineering","locales":"","content":" A Heap of Trouble Engineers can except giving their processes more resources: bigger, better, faster, more of cycles, cores, RAM, disks and interconnects! When these resources are not a bottleneck, this is wasteful but harmless. For processes like Elasticsearch that run on the JVM, the luring temptation is to turn the heap up: what harm could possibly come from having more heap? Alas, the story isn't simple. Java is a . Java objects reside in a runtime area of memory called . When the heap fills up, objects that are no longer referenced by the application (affectionately known as ) are automatically released from the heap (such objects are said to have been ). The maximum size of the heap is specified at application startup and fixed for the life the application: this size impacts allocation speed, garbage collection frequency, and garbage collection duration (most notably the dreaded stop-the-world phase which pauses all application threads). Applications have to strike a balance between small heaps and large heaps: the heap . Too Small If the heap is too small, applications will be prone to the danger of out of memory errors. While that is the most serious risk from an undersized heap, there are additional problems that can arise from a heap that is too small. A heap that is too small relative to the application's allocation rate leads to frequent small latency spikes and reduced throughput from constant garbage collection pauses. Frequent short pauses impact end-user experience as these pauses effectively shift the latency distribution and reduce the number of operations the application can handle. For Elasticsearch, constant short pauses reduce the number of indexing operations and queries per second that can be handled. A small heap also reduces the memory available for indexing buffers, caches, and memory-hungry features like aggregations and suggesters. Too Large If the heap is too large, the application will be prone to infrequent long latency spikes from full-heap garbage collections. Infrequent long pauses impact end-user experience as these pauses increase the tail of the latency distribution: user requests will sometimes see unacceptably-long response times. Long pauses are especially detrimental to a distributed system like Elasticsearch because a long pause is indistinguishable from a node that is unreachable because it is hung, or otherwise isolated from the cluster. During a stop-the-world pause, no Elasticsearch server code is executing: it doesn't call, it doesn't write, and it doesn't send flowers. In the case of an elected master, a long garbage collection pause can cause other nodes to stop following the master and elect a new one. In the case of a data node, a long garbage collection pause can lead to the master removing the node from the cluster and reallocating the paused node's assigned shards. This increases network traffic and disk I\/O across the cluster, which hampers normal load. Long garbage collection pauses are a top issue for cluster instability. Just Right The crux of the matter is that undersized heaps are bad, oversized heaps are bad and so it needs to be . Oops!...I Did It Again The engineers behind Elasticsearch have long advised keeping the heap size below (some docs referred to a 30.5 GB threshold). The reasoning behind this advice arises from the notion of compressed ordinary object pointers (or ). An ordinary object pointer (or ) is a managed pointer to an object and it has the same size as a native pointer. This means that on a 32-bit JVM an oop is 32-bits in size and on a 64-bit JVM an oop is 64-bits in size. Comparing an application that runs on a 32-bit JVM to an application that runs on a 64-bit JVM, the former will usually perform faster. This is because 32-bit pointers require half of the memory space compared to 64-bit pointers: this is friendlier to limited memory bandwidth, precious CPU caches, and leads to fewer garbage collection cycles as there is more room available on the heap. Applications that run on a 32-bit JVM are limited to a maximum heap size of slightly less than 4 GB. For modern distributed server applications serving large volumes of data, this is usually too small. But there's a neat trick that can be employed: limit the heap to slightly less than 32 GB and then the JVM can get away with 35-bit oops (since 2 = 32 GB). Using thirty-five bits is not friendly to modern CPU architectures, though, so another trick is employed: keep all objects aligned on 8-byte boundaries and then we can assume the last three bits of 35-bit oops are zeros. Now the JVM can get away with 32-bit object pointers yet still reference 32 GB of heap. These are compressed oops. Then, exactly like the situation with going from a 32-bit JVM to a 64-bit JVM, comparing an application with a heap size just less than the compressed oops threshold to one with a heap size just more than the compressed oops threshold, the latter will perform worse. What is more, the heap useable to the application will be significantly smaller because of the additional space taken up by the 64-bit oops. Increasing the size of the heap to overcome this loss, however, leads to a larger heap that is subject to the long-pause problem already discussed. For Elasticsearch, our advice is to always stay below the compressed oops threshold. It's Complicated It turns out that the true story is more complicated than this as there are two additional cutoffs. The first is natural and easy to understand. If the heap is smaller than 4 GB, the JVM can just use 32-bit pointers. The second cutoff is less obvious. If the heap will not fit in the first 4 GB of address space, the JVM will next try to reserve memory for the heap within the first 32 GB of address space and then use a zero base for the heap: this is known as . When this reservation can not be granted, the JVM has to fall back to using a non-zero base for the heap. If a zero base can be used, a simple 3-bit shift is all that is needed for encoding and decoding between native 64-bit pointers and compressed oops. native oop = (compressed oop << 3) But when the base is non-zero, a null check is needed and that additional base must be added and subtracted when encoding and decoding compressed oops. if (compressed oop is null) native oop = null else native oop = base + (compressed oop << 3) This causes a significant drop in performance. The cutoff for using a zero base varies across operating systems but 26 GB is a conservative cutoff across a variety of operating systems. Less is More What frequently happens though is that our advice surrounding compressed oops is interpreted as advice to set the heap as high as it can go while staying under the compressed oops threshold. Instead though, it's better to set the heap as low as possible while satisfying your requirements for indexing and query throughput, end-user query response times, yet large enough to have adequate heap space for indexing buffers, and large consumers of heap space like aggregations, and suggesters. The smaller that you can set the heap, the less likely you'll be subject to detrimental long garbage collection pause, and the more physical memory that will be available for the filesystem cache which continues to be used more and more to great effect by Lucene and Elasticsearch. Straight Cache Homie Modern operating systems maintain a of pages accessed from disk. This cache only uses free memory and is handled transparently by the operating system. Once a page is read from the file system and placed in the cache, accessing it is as fast as reading from memory. This means that index segments, term dictionaries, and doc values can be accessed as if they are sitting in memory once they've been placed into the cache. What is more, this cache is not managed by the JVM so we get the benefits of blazingly fast memory speeds without the consequences of being on heap. This is why we continue to recommend having as much memory as possible for the filesystem cache. Garbage First The JVM engineers have developed a concurrent garbage collector known as that was first supported starting in JDK 7u4 and is set to be the . This collector divides the heap into regions and is designed to first collect regions that are mostly garbage (hence : garbage first). This collector still pauses application threads when collecting, but the idea is that by focusing on regions with the most garbage, these collections will be highly efficient so that application threads need to be paused only briefly. This enables G1 GC to operate on large heaps with predictable pause times. This is exactly what we want! Unfortunately, G1 GC has exhibited that lead to in indices. While the builds appear to be the ones most impacted by these issues, bugs are still being found even in the latest builds. We but at this time we recommend against and do not support running Elasticsearch with the G1 collector. Together We Can Prevent Forest Fires The Elasticsearch heap through the environment variable. The ideal scenario, if you can, is to size your heap below 4 GB. If you have to go above 4 GB, try to stay below the zero-based threshold for your system. You can check if you're under the zero-based threshold by starting Elasticsearch with the JVM options and looking for output similar to heap address: 0x000000011be00000, size: 27648 MB, zero based Compressed Oops showing that zero-based compressed oops are enabled instead of heap address: 0x0000000118400000, size: 28672 MB, Compressed Oops with base: 0x00000001183ff000 showing that zero-based compressed oops are not enabled. If you have to go above the zero-based threshold, stay below the compressed oops threshold. Starting with Elasticsearch 2.2.0, Elasticsearch whether or not it is using compressed oops, and the same information is also available in the . Here are some points-of-consideration for reducing the need for large heaps: The engineers behind Lucene and Elasticsearch continue to investigate ways to reduce the need for a large heap. Stay tuned as we push more components of indices off heap, and find ways within Elasticsearch to reduce the dependency on the heap for executing requests. The associated with this post is licensed under the and is cropped from the original. The full-bleed associated with this post is licensed under the and is cropped from the original. \n"}
{"index": {"_id": 684}}
{"title":"Elasticsearch 2.3.1 released","seo_title":"Elasticsearch 2.3.0 and Elasticsearch 2.2.2 released","url":"\/blog\/elasticsearch-2-3-1-released","author":{"name":"Clinton Gormley"},"date":"April 04, 2016","category":"Releases","locales":"","content":" Today we are pleased to announce the bug fix release of based on . This new release is already available on , our Elasticsearch-as-a-service platform.This release fixes a thread deadlock in Shield which can prevent nodes from joining the cluster. All users of Elasticsearch 2.3.0 with Shield are advised to upgrade.Latest stable release: \n"}
{"index": {"_id": 685}}
{"title":"Release Bonanza! Elasticsearch, Graph, Shield, Watcher, Marvel, Logstash 2.3, Beats 1.2, and Kibana 4.5 are Now Available!","seo_title":"","url":"\/blog\/release-bonanza-elasticsearch-graph-shield-watcher-marvel-logstash-2-3-beats-1-2-and-kibana-4-5-are-now-available","author":{"name":"Tyler Hannan"},"date":"March 30, 2016","category":"Releases","locales":"ja-jp","content":" .full-bleed-data h2 {font-size:22px: } The returns! Today, we are pleased to release Elasticsearch 2.3, Kibana 4.5, Beats 1.2, and updated versions of all the commercial products. But wait, there's more. Graph. Several thousands of you saw the presentation at . Several thousands more tuned into a recent webinar. Now, it is here. That's right, Graph is a GA product available for download. And, it just wouldn't be a Release Bonanza if we didn't have all the products available, now, on . Graph Existing products get bullets. New products get a paraGraph. (See what we did there?) When you store data in Elasticsearch, this data often contains references or properties that represent connections between objects, entities, people, machines, etc. We built the Graph product to allow you to ask a whole new type of question \u2014 focusing on these relationships. The best way to explore these connections is to see them, which Graph provides via a Kibana plugin. Like everything at Elastic, this UI is built on a simple, but powerful API, which leverages the same statistics that power search relevance (like bm25) to bring relevance to the relationship exploration process. Whether discovering and visualizing relationships through the Graph UI or directly integrating with the Graph API (recommendations anyone?), we are excited to see how you use Graph! Want to learn more? , to see it in action and learn more. Elasticsearch For detailed information, check out the post. Kibana For detailed information, take a look at the post. \n"}
{"index": {"_id": 686}}
{"title":"Elasticsearch 2.3.0 and 2.2.2 released","seo_title":"Elasticsearch 2.3.0 and Elasticsearch 2.2.2 released","url":"\/blog\/elasticsearch-2-3-0-and-2-2-2-released","author":{"name":"Clinton Gormley"},"date":"March 30, 2016","category":"Releases","locales":"de-de,fr-fr,ja-jp,ko-kr","content":" Today we are pleased to announce the release of based on , along with the bug fix release of based on . Both of these new releases are already available on , our Elasticsearch-as-a-service platform. This week\u2019s release bonanza also includes new versions of , , and .Latest stable release:Bug fixes in 2.2:Elasticsearch 2.3.0 delivers three of the most-asked-for features in the history of Elasticsearch: the , the , and the , along with to help you to prepare for Elasticsearch 5.0. \n"}
{"index": {"_id": 687}}
{"title":"Kibana 4.5.0 released","seo_title":"Kibana 4.5.0 released","url":"\/blog\/kibana-4-5-0-released","author":{"name":"Spencer Alger"},"date":"March 30, 2016","category":"Releases","locales":"","content":" Welp folks, the release bonanza has begun and with it comes Kibana 4.5.0. If you're ready to jump in, or just plain impatient, it's already available on \u00a0along with the latest releases for Elasticsearch, Logstash, and Beats. You can also download Kibana from our \u00a0page. As you have probably come to expect, Kibana 4.5.0 has been upgraded to take advantage of the latest features in Elasticsearch and therefore requires\u00a0at least .\u00a0Below\u00a0are some of the other changes\u00a0you'll find in Kibana 4.5.0. It's a smaller release, as we have been working hard to get Kibana 5.0 ready. Expect more on that soon! Features Bug FixesIn \u00a0we fixed a bug where pre-flight requests that failed would cause a full-screen \"fatal\" error. These requests happen just before Kibana sends queries to Elasticsearch in order to find out which indices should be searched, but were not using the same error handling logic as the actual search request. When a search fails it just shows an error at the top of the page with a dismiss button, and now eventually disappears. Now, errors that occur in these pre-flight requests will exhibit the same behavior. Another bug was caused by legend values that had funky characters. These values were being used to generate element selectors and were not being properly escaped before doing so. This meant that simply moving your mouse over the legend could sometimes result in the not-so-lovely \"fatal\" error screen. That was fixed in\u00a0. Some other bugs that we squashed: \n"}
{"index": {"_id": 688}}
{"title":"Beats 1.2.0 released","seo_title":"","url":"\/blog\/beats-1-2-0-released","author":{"name":"Monica Sarbu"},"date":"March 30, 2016","category":"Releases","locales":"","content":" Today we announce a new Beats release along with new versions of Kibana, Logstash, and Elasticsearch. Here are the highlights of the Beats release: Expand environment variables in configuration filesIt is now possible to use environment variables in the configuration file of any of the Beats. Here is an example for injecting the Elasticsearch host: output: elasticsearch: hosts: [\u201c${ELASTICSEARCH}:9200\u201d] Or if you would like to provide a default value in case the variable is not set: output: elasticsearch: hosts: [\u201c${ELASTICSEARCH:localhost}:9200\u201d] You can find more details in the . Managing the Elasticsearch templateThe mapping templates for Elasticsearch that we provide for each Beat need to be loaded before the Beat starts for the first time, otherwise Elasticsearch cannot know how to correctly assign types to the received data. So far we were asking our users to run a curl command to load the template, but that was easily forgotten and led to issues later on. With this release, the Beats themselves can load the Elasticsearch template by setting it in the configuration file, for example: template: name: filebeat path: filebeat.template.json overwrite: true By default the Elasticsearch template is not loaded. For more details check the . Topbeat: export command line\u00a0for a processTopbeat used to only collect the process name, but this information was not enough to differentiate between two processes of the same application. Starting with the 1.2 version, Topbeat exports the full command line used to start the process on all supported platforms:\u00a0Linux,\u00a0Windows and OS X. Filebeat: introduce close_older settingThe ignore_older setting in Filebeat used to do two things: ignore files with a modification time larger than a given value but also close the open files that had no activity for the given amount of time. The problem with having the two combined was that sometimes there\u2019s no single value that can be used for both. So we now introduced a configuration option, with a default of 1 hour, and we modified the option to no longer close the open files. Send us feedback!A big Thank You to everyone who contributed code, reported issues, created a new Beat or just tried the Beats. Start your experience with and let us know what you think on , , or open an issue on . \n"}
{"index": {"_id": 689}}
{"title":"Shield 2.3.0 Released","seo_title":"","url":"\/blog\/shield-2-3-released","author":{"name":"Uri Boness"},"date":"March 30, 2016","category":"Releases","locales":"","content":" It is with great pleasure that we announce the 2.3 release of Shield - the security extension for the Elastic Stack.This release, like previous releases, introduces bug fixes and enhancements to existing features (see for a complete change list). In addition, in this release we also introduce two important new features: A new native API-driven realm and the role management API.PrologueWhen Shield was first released (back in January 2015), we focused on getting the basic security model right and wanted to deliver the minimum required capabilities for you to safely secure your cluster. With this in mind, we introduced the realm for simple deployments, and a set of Enterprise grade realms (e.g. LDAP and Active Directory) for the more complex requirements out there.The realm was a simple authentication service that required defining the users in configuration files (very similar to unix\u2019s users\/groups or Apache\u2019s ). While it certainly did the job when it comes to protecting the Elasticsearch cluster, when working with this realm, you never truly felt at home - it wasn\u2019t aligned with the \u201cElasticsearch way\u201d. From day one, Elasticsearch was built around its APIs - you create an index, add data, run search, monitor the cluster, all of these were exposed via a set of well defined and dedicated APIs. And here came Shield, which required you to manipulate a set of files - clearly an outlier. served all of us well, but the intention was never to stop there. From the early days of Shield we were open about it and promised our users a better way for managing users. Today we\u2019re thrilled to deliver on that promise.Good Morrow, Sir The realm is a built-in realm in Shield that uses Elasticsearch itself to store all of its users. It\u2019s dynamic by nature and exposes a set of APIs for user management. Lets see how you can use it.First thing first, assuming you have Elasticsearch 2.3 installed, you\u2019ll need to install the License and Shield plugins:bin\/plugin install licensebin\/plugin install shieldNext, we\u2019ll add an admin (super) user using the tool:bin\/shield\/esusers useradd elastic -p changeme -r adminI know what you\u2019re thinking - \u201cWhat? esusers? But\u2026\u201d. Yes! Remember, with Shield, all APIs in Elasticsearch are protected. In order to manage users via APIs, you will need to be and authenticate as an admin user. We use the tool to enable that. Besides\u2026 having an admin (super) user defined in is not such a bad idea, but we\u2019ll get to that later.OK, you\u2019re all set! If you haven\u2019t done it yet, start up Elasticsearch:bin\/elasticsearchAnd add your first user:curl -XPOST -u elastic -p changeme 'localhost:9200\/_shield\/user\/romeo' -d '{ \"password\" : \"minejuliet \", \"roles\" : [ \"power_user\" ], \"full_name\" : \"Romeo\", \"email\" : \"romeo@montague.it\", \"metadata\" : { <5> \"moto\" : \"thus with a kiss I die\" } }'That is it. \u201cromeo\u201d is now a user in Elasticsearch. No need to run command-line tools, edit files or copy files from one node to another. In addition to that, as the example above shows, with the introduction of we also extended the notion of a user to include its full name, email and arbitrary metadata.Having a role, grants romeo the permission to create an index and add data. Running the following command will execute on behalf of the newly added user and will index a new document into the auto-created the index. curl -XPUT -u romeo -p minejuliet 'localhost:9200\/shakespeare\/tragedy\/1' -d '{ \"title\" : \"The Tragedy of Macbeth\", \"quote\" : \"All fair is foul, and foul is fair: Hover through the fog and filthy air\" }The realm exposes a full set of CRUD APIs to manage its users.You can get the users:curl -XGET -u elastic -p changeme 'localhost:9200\/_shield\/user\/romeo'Update users:curl -XPUT -u elastic -p changeme 'localhost:9200\/_shield\/user\/romeo' -d '{ \"password\" : \"minejuliet \", \"roles\" : [ \"user\" ], \"full_name\" : \"Romeo\", \"email\" : \"romeo@montague.it\", \"metadata\" : { \"moto\" : \"Love is a smoke raised with the fume of sighs\" } }'And delete users:curl -XDELETE -u elastic -p changeme localhost:9200\/_shield\/user\/romeoAs expected, once deleted, any attempt to executes requests on behalf of will be rejected. Try it out:curl -XPUT -u romeo -p minejuliet localhost:9200\/shakespeare\/tragedy\/2 -d '{ \"title\" : \"The Tragedy of Hamlet, Prince of Denmark\", \"quote\" : \"A little more than kin, and less than kind\" }'O , ! Wherefore Art Thou ?If you\u2019re already using Shield, one of the first things you\u2019ll notice in this release is that the realm disappeared from our documentation. Truth is, it didn\u2019t. It was simply renamed to realm. We believe that the name better describes what this realm is all about - configuring users in local files.Yet, now with the realm in place, do we really need to keep the \/ realm at all?The answer to this question is a definite \u201cYES!\u201d.There is no doubt that the realm displaced the realm from its throne, and indeed we expect it to become the de-facto realm to use when no other authentication services are required (e.g. LDAP, Active Directory, PKI, etc\u2026). But the realm is still very important and cannot be disposed.Imagine the following scenario: Your only user was configured via the realm and one day you forget its password. Without the realm, you\u2019ll be stuck in a catch 22 - You need to reset your password using the API, but you\u2019ll need your forgotten password to do so.That\u2019s where the realm proves to be essential. It enables you to login to the machines, use the command-line tool to add an admin user and from then on, use this admin user to update\/change the fogotten password.The realm is your only way out of situations where all users locked themselves out of the system. Roles - thou art not aloneHaving a native API-driven realm is a huge step forward when it comes to managing users in your cluster. But it only brings it half way. To have a complete control over user management, you need to be able to configure both authentication authorization.Authorization in shield is managed via roles. A role defines a set of permissions on the cluster and its data. The permissions a user has are therefore defined by the roles it\u2019s associated with.Until today, roles were defined in the configuration file. Just like the realm, in order to change\/add\/remove roles you needed to edit this file, on all the nodes.Shield 2.3 introduces a new Role Management API and just like with the realm, we now store roles in Elasticsearch itself.You can now add roles:curl -XPOST -u elastic -p changeme 'localhost:9200\/_shield\/role\/shakespeare_admin' -d '{ \"indices\": [ { \"names\": [ \"shakespeare\" ], \"privileges\": [ \"all\" ], } ] }'Get roles:curl -XGET -u elastic -p changeme 'localhost:9200\/_shield\/role\/shakespeare_admin'Update roles:curl -XPOST -u elastic -p changeme 'localhost:9200\/_shield\/role\/shakespeare_admin' -d '{ \"indices\": [ { \"names\": [ \"shakespeare\" ], \"privileges\": [ \"all\" ], } ], \"run_as\": [ \"romeo\" ] }'And delete roles:curl -XDELETE -u elastic -p changeme 'localhost:9200\/_shield\/role\/shakespeare_admin'The roles API, together with the new realm complement each other in defining a complete set of user management APIs. EpilogueWe consider the new realm and the Role Management API to be milestone features. Not only will they make your life simpler by letting you manage users and privileges via an API, it also opens the door for tighter integration between Shield and other products in the Elastic Stack. For example, in the near future you can expect to see user and role management UIs in Kibana.We really recommend you take Shield 2.3 for a spin, and as always, we\u2019d love to hear your . \n"}
{"index": {"_id": 690}}
{"title":"Logstash 2.3.0 and 2.2.3 Released","seo_title":"","url":"\/blog\/logstash-2-3-0-and-2-2-3-released","author":{"name":"Suyog Rao"},"date":"March 30, 2016","category":"Releases","locales":"","content":" : It's highly recommended to move directly to\u00a0the as they include various\u00a0important bug fixes.Logstash 2.3.0 has been released today, packed with extremely useful new features, an awesome performance boost and a few bug fixes. You can read the detailed release notes, or jump directly to our page if you can't wait to test drive this release!\u00a0Additionally, we've released an update to the 2.2.x series, with a bunch of important bugs packaged in 2.2.3. You can read the changelog for 2.2.3.Today, any changes made to Logstash configuration files requires the entire process to be restarted, which is not ideal when you manage a multi-instance deployment. Logstash is often run as a centralized service to process data from multiple sources, departments and users. In such deployments it is fairly common for operators to onboard new data sources, and update Grok patterns to extract fields from new, unstructured data. Therefore, each iteration means\u00a0you'd have to make config changes locally, push them to all Logstash instances and restart every instance to apply those changes. Starting, you can set Logstash to detect and reload configuration changes automatically! This feature also reduces the feedback loop as you develop and debug new configurations.To enable automatic config reloading, start Logstash with the (or) command-line option specified. For example:By default, Logstash checks for configuration changes every 3 seconds. To change this interval, use the - option, where seconds specifies how often Logstash checks the config files for changes.Alternatively, if you would like to manually force a reload and pipeline restart you can send a (signal hangup) to the process.Using environment variables is a common pattern to parameterize server instances, and many times it is convenient to use these variables to inject values into the Logstash configuration. Maybe you'd like to use the EC2 instance ID to tag the input, or use environment variables from your Dockerized Logstash instance to populate the hosts settings for Elasticsearch Output, and so on.. The possibilities are endless here.Prior to this release, users had to use m4 (or any templating system) to achieve this before launching Logstash. Thanks to an amazing contribution from our community member, you can now reference environment variables directly from Logstash configuration. Simply use the syntax and you're done. For exampleinput { tcp { port => \"${TCP_PORT:54321}\" } }A new chapter in Logstash implementation begins in 2.3. Some of you may know that Logstash is written in JRuby, and runs on JVM. In this release, we've completely rewritten the Event representation \u2014 a core component which encapsulates the data flow \u2014 in pure Java. So what does this mean for users? In our we've seen consistent throughput increases across multiple configurations. In some cases, we've seen up to 75% increase in events processed through Logstash. This change also provides the foundation for future persistence work where events will be persisted to disk while being processed by the pipeline. The Java implementation will make serialization to disk faster. Using the excellent interoperability between Java and JRuby, we were able to make this change 100% backward compatible \u2014 all the existing plugins and configuration will work seamlessly ().\u00a0The graph\u00a0below\u00a0illustrates the performance throughput between the 2.3.0 and 2.2.0 release:\u00a0\u00a0\u00a0\u00a0All benchmarks were performed using the tool, default settings, and\u00a0configurations available . Machine specifications can be found .We'd like to note that bin\/plugin command \u2014 which is used to manage plugins \u2014 has been deprecated in favor of bin\/logstash-plugin command. bin\/plugin will be removed in the next major version mainly to prevent PATH being polluted when other components of the are installed on the same instance. Also, this new command will be enhanced in future versions to work with cross-component plugin packsAdditionally, there have been dozens of bug fixes and minor enhancements spanning plugins and core. We've listed few of the important ones here:We are super excited for this release of Logstash and look forward to your feedback. You can reach us at our, open issues in your or twitter(). Happy 'stashing! \n"}
{"index": {"_id": 691}}
{"title":"How BigSpark levels up the price comparison for mobile tech services with Elasticsearch","seo_title":"","url":"\/blog\/how-big-sparks-levels-up-the-price-comparison-for-mobile-tech-services-with-elasticsearch","author":{"name":""},"date":"March 30, 2016","category":"User Stories","locales":"","content":" is the publisher of some of the biggest tech websites in the Netherlands, among which , and . Every month, more than two million consumers visit these websites on which we inform about and inspire with up-to-date news and in-depth articles on subjects like mobile tech, apps, games and devices. Furthermore, we advise them on specific purchases using our product and price comparison service. Our mission is to inspire consumers to get the most out of technology and to help them to make better choices. \u201c\u201d, says Peter Geurts - Founder of BigSpark. Dominant player in the NetherlandsIn just three years, BigSpark managed to become a dominant player on the Dutch market for product and price comparison services for mobile tech devices. Every month, the telecom experts of BigSpark advise customers on 70,000 purchases of smartphones, tablets, wearables and plans. Our price comparison service is powered by Elasticsearch, which makes it possible for BigSpark to claim a unique position in the market and continuously compare three million product prices of among others: Unique featuresThanks to Elasticsearch, consumers can easily search the complete product offerings of Dutch telecom providers and shops. They can use facets to filter on product features such as\u00a0color, storage,\u00a0data allowances,\u00a0provider, as well as\u00a0conditions such as time of delivery and user reviews of shops. Where we come fromOriginally, the setup of our price comparison service was based on Mongo DB and Node.js, but they did not keep up with our requirements\u00a0anymore. Our databases were getting too big, aggregations became too slow and the performance of the service became unpredictable. A new setup in PostgreSQL, connected with Elasticsearch, proved to be the right solution. Suddenly, it became easy to quickly search the database, taking different groups and facet preferences into account. \u201c\u201d, says one of BigSpark\u2019s Development engineers. Under the hoodElasticsearch has been installed on a cluster of two instances with 8GB RAM each.\u00a0The index with offers is around 3GB and has a very good performance in combination with a low load. With Elasticsearch, the average query takes around 50ms which is significantly faster than previous queries. We are very impressed by the way Elasticsearch allows us to still deliver big performance with relatively limited resources.The future with ElasticsearchElasticsearch has several interesting out-of-the-box features with which we can improve the power of our price comparison service. These are for example function scores, which enables us to add a higher value to certain factors (like conversion, changes in search volume or the profile of the consumer) in order to influence the search results. Furthermore, we are going to give our users the possibility to intelligent suggestions on free text queries such as\u00a0\"did you mean \"Galaxy S7\"?\"\u00a0when someone accidentally typed \"Galaxie S7\u201d.The success of BigSpark is partly thanks to the possibilities and accessibility of Elasticsearch: \u201c\u201d, concludes Peter Geurts. \n"}
{"index": {"_id": 692}}
{"title":"Brewing in Beats: JSON support in Filebeat","seo_title":"","url":"\/blog\/brewing-in-beats-json-support-filebeat","author":{"name":"Tudor Golubenco"},"date":"March 29, 2016","category":"Brewing in Beats","locales":"","content":" Welcome to Brewing in Beats! With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources. JSON support in Filebeat Since merging this last week, Filebeat can natively decode JSON objects from log lines. This is useful for structured logging, where the logging library writes the metadata directly formatted as JSON. Of course, this was already possible with Logstash, but \u00a0this enables people to take the direct Filebeat -> Elasticsearch path when they have their logs in JSON already. Another interesting use case for the JSON decoding is that it can be used to ship the logs from a Docker host. When writing the logs to files, Docker wraps the log lines of the application in JSON to add some meta-data. Because Filebeat decodes the JSON before applying line filtering and multiline rules, it is able to unwrap the JSON and then apply these rules, so these features combine well in the Docker and other similar use cases. Apachebeat and Redisbeat merged into Metricbeat Radovan Ondas, the creator of , and Chris Black, the creator of , have contributed modules for Apache and Redis to Metricbeat. It\u2019s a great sign for Metricbeat that the Beats community devs are embracing it. Metricbeat progress Speaking of Metricbeat, Nicolas continued to shape it over the last few weeks, adding a , a common way of handling , adding metadata, so its functionality can be shared in Metricbeat, adding , and many others. New 5.0 Elasticsearch templates After making sure that Elasticsearch 5.0 is able to upgrade automatically the mapping templates used by the Beats, Adrien opened a to upgrade our templates with the the options accepted by 5.0. These are the templates that\u00a0we will ship with\u00a0Beats 5.0-alpha1. Winlogbeat - select events by level, event_id, and provider Winlogbeat is now able to by these key fields. It does this efficiently by adjusting its Windows API query to only return the events needed. The details are\u00a0in the . Packetbeat - Split real_ip_header to only have one valueThis fixes an issue, where Packetbeat\u2019s Geoip resolving didn\u2019t work if the X-Forwarder-For (or similar) header had multiple IP addresses inside. With this\u00a0fix, Packetbeat takes the first IP address when there are multiple defined in the header. \u00a0The \u00a0fix will be available in 1.2. \n"}
{"index": {"_id": 693}}
{"title":"How HotelTonight Finds the Best Hotels in the Moment: An Elastic{ON} Reflection","seo_title":"","url":"\/blog\/how-hoteltonight-finds-the-best-hotels-in-the-moment-elasticon-reflection","author":{"name":"Paul Sorensen"},"date":"March 29, 2016","category":"User Stories","locales":"","content":" Elastic{ON} was a blast! The and the venue had so much to offer. I had never been to a conference with an AMA (Ask Me Anything) booth before, and I thought that was really one of the more valuable parts of the whole setup (I had been itching to ask questions about filter cache). I also really enjoyed the . It was inspiring to hear a recollection of each of their careers and how they ended up where they are now.Speaking at Elastic{ON} was an unforgettable experience. It was my first opportunity to speak at a conference, and I could not have been happier with the venue, coordination and the outcome. The atmosphere on stage was really great, and all the equipment was extremely easy to use. Everything went smoothly, and it was great to connect with so many people at the end.I once heard that stories make for good talks, and this is a . Behind the words and slides, smiles were had, tears shed, and glasses clinked throughout our journey. Hope you enjoy, and next time you\u2019re feeling spontaneous, try HotelTonight!Paul Sorensen is a Platform Engineer at HotelTonight. We plucked him from Chicagoland, where he was building Rails web apps, digging deeper into Elasticsearch, and rooting hard for the Bears. He now keeps busy scaling HT\u2019s infrastructure to support massive data demands, within a constantly changing real-time marketplace servicing millions of requests per day. You can find Paul taking his breaks at the ping-pong table, HT Bar, or playing soccer with the HotelTonight team. \n"}
{"index": {"_id": 694}}
{"title":"Where in the World is Elastic? - Code PaLOUsa and Lone Star PHP","seo_title":"Where in the World is Elastic? - Code PaLOUsa and Lone Star PHP","url":"\/blog\/witwies-code-palousa-lone-star-php","author":{"name":"Megan Wieling"},"date":"March 28, 2016","category":"","locales":"","content":" Welcome to Find out which Elastic events and meetups are happening near you in the next two\u00a0weeks. Upcoming Events March 28-30: April 7-9: Upcoming Meetups March 28: March 29: March 29: March 30: March 31: April 7:\u00a0 March 29: March 29: April 5: April 5: April 6: April 7: April 7: April 7: March 30: March 29: March 31: April 9: March 28: March 29: April 6: That's it for this week. Stay tuned next week for more Elastic happenings. - The Elastic Team P.S.\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}
{"index": {"_id": 695}}
{"title":"Reindex is coming!","seo_title":"","url":"\/blog\/reindex-is-coming","author":{"name":"Nik Everett"},"date":"March 25, 2016","category":"Engineering","locales":"ja-jp","content":" and are coming to Elasticsearch 2.3.0 and 5.0.0-alpha1! Hurray! reads documents from one index and writes them to another index. It can be used to copy documents from one index to another, enrich documents with fields, or recreate the index to change settings that are locked when the index is created. reads documents from an index and writes them back to the same index. It can be used to update fields in many documents at once or to pick up mapping changes that can be made online. copies documents The API is really just a convenient way to copy documents from one index to another. Everything else that it can do is an outgrowth of that. If all you want to do is to copy all the documents from the index into the index you invoke like this: curl -XPOST localhost:9200\/_reindex?pretty -d'{ \"source\": { \"index\": \"src\" }, \"dest\": { \"index\": \"dest\" } }' If you want to be a little more selective and, say, only copy docments tagged with you invoke like this: curl -XPOST localhost:9200\/_reindex?pretty -d'{ \"source\": { \"index\": \"src\", \"query\": { \"match\": { \"tags\": \"bananas\" } } }, \"dest\": { \"index\": \"dest\" } }' If you want to copy documents tagged with but you want to add the tag to all copied documents you invoke like this: curl -XPOST localhost:9200\/_reindex?pretty -d'{ \"source\": { \"index\": \"src\", \"query\": { \"match\": { \"tags\": \"bananas\" } } }, \"dest\": { \"index\": \"dest\" }, \"script\": { \"inline\": \"ctx._source.tags += \\\"chocolate\\\"\" } }' That requires that you have dynamic scripts enabled but you can do the same thing with non- scripts. Recreating an index to change settings that are locked at index creations is a bit more involved but still simpler than before : # Say you have an old index that you made like this curl -XPUT localhost:9200\/test_1 -d'{ \"aliases\": { \"test\": {} } }' for i in $(seq 1 1000): do curl -XPOST localhost:9200\/test\/test -d'{\"tags\": [\"bananas\"]}' echo done curl -XPOST localhost:9200\/test\/_refresh?pretty # But you don't like having the default number of shards # You can make a copy of it with the new number of shards curl -XPUT localhost:9200\/test_2 -d'{ \"settings\": { \"number_of_shards\": 1 } }' curl -XPOST 'localhost:9200\/_reindex?pretty&refresh' -d'{ \"source\": { \"index\": \"test\" }, \"dest\": { \"index\": \"test_2\" } }' # Then just swing the alias to the new index curl -XPOST localhost:9200\/_aliases?pretty -d'{ \"actions\": [ { \"remove\": { \"index\": \"test_1\", \"alias\": \"index\" } }, { \"add\": { \"index\": \"test_2\", \"alias\": \"index\" } } ] }' # Then when you are good and sure you are done with it you can curl -XDELETE localhost:9200\/test_1?pretty modifies documents The simplest way to invoke update by query isn't particularly useful on its own: curl -XPOST localhost:9200\/test\/_update_by_query?pretty That will just increment the document version number on each document in the index and fail if you modify a document while it is running. A more interesting example is adding the tag to all documents with the tag: curl -XPOST 'localhost:9200\/test\/_update_by_query?pretty&refresh' -d'{ \"query\": { \"bool\": { \"must\": [ {\"match\": {\"tags\": \"bananas\"}} ], \"must_not\": [ {\"match\": {\"tags\": \"chocolate\"}} ] } }, \"script\": { \"inline\": \"ctx._source.tags += \\\"chocolate\\\"\" } }' Like the last version this will fail if any documents are changed while it is running, but it is written in such a way that you can just retry it and it'll pick up from where it left off. If you've already modified whatever application is making the concurrent updates to add the tag whenever it sees then you can safely ignore version conflicts in the . You can tell it to do so by setting . It will just count the version conflicts and continue performing updates. Now the command looks like this: curl -XPOST 'localhost:9200\/test\/_update_by_query?pretty&refresh&conflicts=proceed' -d'{ \"query\": { \"bool\": { \"must\": [ {\"match\": {\"tags\": \"bananas\"}} ], \"must_not\": [ {\"match\": {\"tags\": \"chocolate\"}} ] } }, \"script\": { \"inline\": \"ctx._source.tags += \\\"chocolate\\\"\" } }' Finally, you can use to suck up mapping changes that only take effect when the document is modified like adding a new field to an existing field. For example: # Say I made an index with tags not_analyzed because, you know, they are tags after all curl -XPUT localhost:9200\/test_3?pretty -d'{ \"mappings\": { \"test\": { \"properties\": { \"tags\": { \"type\": \"string\", \"index\": \"not_analyzed\" } } } } }' for i in $(seq 1 1000): do curl -XPOST localhost:9200\/test_3\/test -d'{\"tags\": [\"bananas\"]}' echo done curl -XPOST localhost:9200\/test_3\/_refresh?pretty # But now I want to search on tags using the standard analyzer so I can search for banana and find bananas curl -XPUT localhost:9200\/test_3\/_mapping\/test?pretty -d'{ \"properties\": { \"tags\": { \"type\": \"string\", \"index\": \"not_analyzed\", \"fields\": { \"analyzed\": { \"type\": \"string\", \"analyzer\": \"standard\" } } } } }' # This doesn't take effect immediately curl 'localhost:9200\/test_3\/_search?pretty' -d'{ \"query\": { \"match\": { \"tags.analyzed\": \"bananas\" } } }' # :( # But we can _update_by_query to pick up the new mapping on all documents curl -XPOST 'localhost:9200\/test_3\/_update_by_query?pretty&conflicts=proceed&refresh' # And now the new mapping has been applied to the whole index! curl 'localhost:9200\/test_3\/_search?pretty' -d'{ \"query\": { \"match\": { \"tags.analyzed\": \"bananas\" } } }' Getting the status and can touch millions of documents so they can take a long time. You can fetch their status with: curl localhost:9200\/_tasks?pretty&detailed&actions=*reindex,*byquery That will contain a field that looks like: \"BHgHr0cETkOehwqZ2N_-aQ:28295\" : { \"node\" : \"BHgHr0cETkOehwqZ2N_-aQ\", \"id\" : 28295, \"type\" : \"transport\", \"action\" : \"indices:data\/write\/reindex\", \"start_time_in_millis\" : 1458767149108, \"running_time_in_nanos\" : 5475314, \"status\" : { \"total\" : 6154, \"updated\" : 3500, \"created\" : 0, \"deleted\" : 0, \"batches\" : 36, \"version_conflicts\" : 0, \"noops\" : 0, \"retries\": 0, \"throttled_millis\": 0 } } You can read the for more, but the gist is that _reindex plans to do operations and has already done of them. So you can estimate how complete the request is by dividing those numbers. Cancelling was so long in coming because Elasticsearch lacked a way to cancel running tasks. For short running tasks like and indexing that is fine. But, like I wrote above, and can touch millions of documents are take a long time. The tasks themselves are ok with that, but you may not be. Say you realize ten minutes into a three hour long that you made a mistake in the script. There isn't a way to rollback the changes that the reindex already made but you can cancel it so it won't make any more such changes: curl -XPOST localhost:9200\/_task\/{taskId}\/_cancel And where do you get the taskId? It is the name of the object returned by the task listing API in the last section of this blog post. The one in the example return is . In Elasticsearch task cancelation is opt in. It kind of has to be that way in any Java application. Anyway, tasks that can be canceled like and periodically check to see if they have been canceled and then shut themselves down. This means that you might see the task if you immediately list its status after it has been canceled. It will go away on its own and you can't cancel it any harder without stopping the node it is running on. Remember that Elasticsearch is a search engine Every update has to mark the document as deleted and index the entire new document. The deleted documents have to then be merged out of the index. and don't save anything in that process. They work just as though you performed a scroll query and indexed all the results. Running a zillion s or s is unlikely to be the most efficient use of computer resources to accomplish some task. You will almost always be better off making changes to the application that adds data to Elasticsearch rather than updating the data after the fact. and are most useful for turning the data that you already have in Elasticsearch into the data that you want to be in Elasticsearch. \n"}
{"index": {"_id": 696}}
{"title":"Adding Context to Queries: The Story Behind Adobe\u2019s API and UI: An Elastic{ON} Reflection","seo_title":"","url":"\/blog\/adding-context-to-queries-the-story-behind-adobes-api-and-ui-elasticon-reflection","author":{"name":"Marko Iskander"},"date":"March 22, 2016","category":"User Stories","locales":"","content":" Elastic{ON} just wrapped up and I am still trying to wind down from the excitement. Not only because I was invited to speak at this year\u2019s conference, but because it\u2019s one of the more engaging conferences with product announcements, user stories, and great networking. Meeting people like , the founder of the very tool that brought us all together, was surreal. Then add on top of that the Elastic Team being all under one roof for those few days -- it made for a lot of search power! Of course meeting people like , the Ruby and the Rails SDK core contributor, who I\u2019ve talked with over Github issues and pull requests, is always a plus. There is no other event where you can have access to so much Elastic knowledge and expertise.With talks like \u00a0and \u00a0it\u2019s hard not to geek out. Of course, the user story sessions do a great job of balancing out the reality of business use cases and the real problems we are working to solve. Stories from , , and all offered up a great insight into different ways Elasticsearch is used in the wild. However, the data nerd in me couldn\u2019t wait to see how the stored over 160 years of its stories in Elasticsearch.Speaking at Elastic{ON} was not only an honor but a great joy. Sharing the Adobe Typekit story was something that I\u2019ve wanted to do for a while now. It\u2019s a bit different than most of the talks given at this conference since our story is about a small cluster that handles small amounts of data, but at a very high throughput with complex queries. The introduction of Elasticsearch to our stack was not for log analysis, big data storage, and evaluation but rather for its robust query interface and stability under high throughput. I felt that many could benefit from hearing such a story and Elastic{ON} was the stage on which to do just that. With a diverse speakers list and even more diverse attendees, finding the right balance of content was key. The questions at the end of the talk not only affirmed that our story was one that others can relate to, but that it had answered some questions for people struggling through the same obstacles.If you are interested in the Adobe Typekit story, stop on over and enjoy .\u00a0In it, I share how we are able to use advanced scripting to make real-time, high-throughput queries to power our browse UI and API.Marko Iskander is a Senior Computer Scientist at Adobe on the Typekit team. He has implemented large scale implementation of Elasticsearch at various Fortune 500 clients before joining the Typekit team. After joining, his first initiative was to switch the core search and filtering of data from SQL to Elasticsearch for faster query times, simpler implementations, and support of complex business queries. Next up was the API. Currently, Marko is working on pioneering the next-level implementation of user-specific prepared data. \n"}
{"index": {"_id": 697}}
{"title":"Brewing in Beats: Packagebeat, Lmsensorsbeat and Soundbeat","seo_title":"","url":"\/blog\/weekly-beats-packagebeat-lmsensorsbeat-soundbeat","author":{"name":"Monica Sarbu"},"date":"March 21, 2016","category":"Brewing in Beats","locales":"","content":" Last week we released Beats 1.1.2.\u00a0The most interesting news and enhancements of the week are: Packagebeat Joe Hillenbrand from Elastic has started Packagebeat to gather Linux distribution package information and index them into Elasticsearch. The Beat is used internally by the infra team and it is actively developed and improved. LmsensorsbeatShane Connely from Elastic created Lmsensorbeat to monitor a variety of I2C\/SMBus sensors, such as CPU\/motherboard temperatures, fan speeds, voltages, etc. This is another example that creating a new Beat is easy and fun when using the beat-generator to generate all the boilerplate code for you. SoundbeatSoundbeat is another Beat developed inhouse by David Pilato from Elastic and it shows that Beats can have applications outside of the operations domain. It reads the MP3 files to extract the sound level for left and right channels using a given period for each sample. He wrote a nice blog post with all the detailed steps that he followed for writing the Beat. Packaging for community BeatsComing from a community Beat author, this PR adjusted the Makefile in our Beat packer so that it can be easily used by all community Beats. This means that a single make command can be used by any of the community Beats to get cross-compiled RPMs, DEBs, etc. The Beat generator was also updated to support for this, so it\u2019s really easy to use by the community Beats authors. Generic filteringGeneric filtering has now support for include_fields and drop_fields actions by merging the pull request in master. The include_fields action specifies a whitelist of fields to export. The drop_fields action defines the fields that are dropped if they exist. By default all fields are exported. The only fields that cannot be dropped via generic filtering are @timestamp and type, because they are required by the outputs. Both actions can receive in the fields argument full nested maps. For example to keep only the percentages of the cpu load and remove the cpu ticks, the configuration file looks like: filter: - include_fields: fields: [\u201ccpu\u201d] - drop_fields: fields: [\u201ccpu.user\u201d, \u201ccpu.system\u201d] Authenticate MySQL connection in Metricbeat\/Mysql moduleThis adds authentication support for connecting to the MySQL server in the mysql module of Metricbeat. You can configure the username and password as different options or you can define them in the DSN connection string: [username[:password]@][protocol[(address)]]. Enhancements in WinlogbeatFew improvements are done in Winlogbeat to provide the data from the event log messages in a structured format. In addition, more information are exported like activity_id, process_id, thread_id and others. Add support for double in templatesWith this pull request double values are also supported in the Elasticsearch templates for Beats. Remove count field for FilebeatAll Beats are exporting the count field that was meant to be used for sampling, but never used so far. To cleanup the exported fields, this removes the count field from the exported fields in Filebeat. \n"}
{"index": {"_id": 698}}
{"title":"Logstash Lines: Kafka 0.9 beta support, ES output memory fix","seo_title":"","url":"\/blog\/logstash-lines-2016-03-21","author":{"name":"Suyog Rao"},"date":"March 21, 2016","category":"The Logstash Lines","locales":"","content":" Welcome back to The Logstash Lines! In these weekly posts, we'll share the latest happenings in the world of Logstash and its ecosystem.Support for Kafka v0.9 Apache Kafka had 0.9 couple of months ago which brings in new security features (SSL, client based auth, access control), improved consumer API, and much more. The biggest asks from Logstash users were\u00a0support for SSL encryption and client auth features. Over the last few months we've been working on implementing these features into the input and output plugins, and this week, we beta versions. The new consumer library from Kafka has been greatly simplified - much of the logic (like rebalancing), has been pushed to the broker side. This meant we could directly use the Java APIs. While we're at this, added more integration tests running on travis, and cleaned up some configs. that these features need an upgrade to the Kafka broker -- 0.8 producer\/consumer will not work with 0.9 broker and Logstash plugins are not backward compatible. To install this version of plugin on your Logstash (> 2.0.0): bin\/plugin install --version 3.0.0.beta3 logstash-input-kafkabin\/plugin install --version 3.0.0.beta1 logstash-output-kafka Elasticsearch Output memory issue Users have recently ran into a when using the feature in Elasticsearch Output. This leak was caused by ES output frequently instantiating \u2014 the underlying http library used in Logstash \u2014 while tearing down and reconnecting, upon hosts being updated from sniffing. Manticore lib has been patched to be more efficient in this scenario and ES Output version 2.5.3 released. To install this on Logstash 2.2: Plugin Installation Bug While validating the fix for memory leak described above, we ran into a plugin installation issue when executing . Turns out we didn't know of hidden files produced by jar-dependencies library (use to package jars) and weren't correctly packaging dirs like in our gem building process. Fix is in, and life is good in plugins-land () Beats input certificate verification Continue to make progress on adding on the Beats input side. We found a while adding support for chained certs, but root CA verification works fine. Released a new version which includes certificate validation. Java Event Timestamp Fixes This bug surfaced in Gelf input when a timestamp conversion from JSON string was loosing precision. The Java BigDecimal type conversion to a proper Ruby BigDecimal was not handled, and has been fixed now. This issue of losing precision also showed up in JRuby Event implementation previously () Packs Installation Support Preliminary work of installing packs in Logstash has begun. This will use the offline install feature which creates an intermediate plugin state file and can be pointed to use this as source instead of RubyGems. Adding integration tests to validate this feature (). In progress:Plugins changes: \n"}
{"index": {"_id": 699}}
{"title":"Why Elastic Cloud is the Best Choice for Your Hosted Elasticsearch Needs","seo_title":"Why Use Elastic Cloud - #1 Choice for Hosted Elasticsearch","url":"\/blog\/why-elastic-cloud-is-the-best-choice-for-your-hosted-elasticsearch-needs","author":{"name":"Jason Dickson"},"date":"March 21, 2016","category":"News","locales":"","content":" Allow me to ask you a couple of questions that might seem silly. Do you only eat food that you've grown? No? Did you build your own home or apartment? No? Why not? Was it easier to simply buy or rent a place that suitably addresses your needs for shelter and comfort? Sometimes it's wise to just take the path of least complexity. That's pretty much what makes \u2014 the official hosted Elasticsearch service \u2014 a perfect choice for many companies, organizations, and individuals. Choosing us for your Elasticsearch needs simply makes good sense. We understand that every team and system has a set of unique requirements. However, if you think about hosting the Elastic Stack on your own and consider the time needed to deploy, setup, get started, and maintain \u2014 you or your boss may be thinking, \"How can I get this taken care of with a minimum of added stress?\" That's where Elastic Cloud comes in. It's the only hosted Elasticsearch offering from the creators of Elasticsearch, Kibana, Beats, and Logstash. Whether your team needs 1GB of memory or 4TB of storage, Elastic Cloud is the best hosted Elasticsearch experience. Fully hosted and providing the real-time search and analytics magics of , Elastic Cloud is always running the most current version of Elasticsearch and incorporates all of the latest and greatest . You can also get Elastic's world-class tech and security, alerting, and monitoring. And you can go try it out right now with a free . Don't take my word for it, experience it for yourself. For , over 1,800 users converged on San Francisco's Pier 48 to hear from the creators and engineers of the Elastic Stack. This included a fantastic presentation on the architecture and history of Elastic Cloud by Software Engineer Njal Karevoll and Site Reliability Engineer Erik Redding, as well as a live demo. In the recording below, watch Erik and Njal discuss the history and early architectures of what is now Elastic Cloud, a fascinating section about \"living with systems that fail\", an in-depth look at Elastic Cloud's current architecture, and the demo, in which they install Elastic Cloud Enterprise on three servers, all while shining a big flashlight to illuminate how it all works. If you enjoyed this presentation, you may also want to check out the Elastic{ON} , in which Njal and Elastic Cloud Team Lead Michael Basnight presented a demo of Elastic Cloud Enterprise, beginning at the 85-minute mark. For even more Elastic Cloud coolness: \n"}
{"index": {"_id": 700}}
{"title":"Where in the World is Elastic? - BreizhCamp","seo_title":"Where in the World is Elastic? - Great Wide Open & FOSSASIA 2016","url":"\/blog\/witwies-breizhcamp","author":{"name":"Megan Wieling"},"date":"March 21, 2016","category":"","locales":"","content":" Welcome to Find out which Elastic events and meetups are happening near you this week.\u00a0 Upcoming EventsMarch 23-25: \u00a0Upcoming MeetupsMarch 21: March 21: March 22: March 23: March 23: March 24: March 24: March 23: March 24: March 23: That's it for this week. Stay tuned next week for more Elastic happenings.- The Elastic Team P.S.\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}
{"index": {"_id": 701}}
{"title":"Brewing in Beats: SOCKS5 support when sending to Logstash","seo_title":"","url":"\/blog\/weekly-beats-sock5-to-logstash","author":{"name":"Tudor Golubenco"},"date":"March 17, 2016","category":"Brewing in Beats","locales":"","content":" Welcome to Weekly Beats! With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources. Merged this week: DNS eTLD+1 support in PacketbeatAs Andrew , \u201cthe effective top level domain plus one more label is really useful for clustering DNS requests (hostnames). For example, the eTLD+1 for \u00a0is .\u00a0This was the basis for the aggregations used in .\" The adds a field to the Packetbeat DNS transactions.SOCKS5 proxy for the connection to Logstash makes it possible for the Beats to connect to Logstash via SOCKS5 proxy. This can useful when sending the data between different Internet domains. It also opens the possibility of using username\/password for authenticating to Logstash. Cleaner separation between the Go unit tests and integration testsOur Go \u00a0files contain both unit and integration tests (defined as tests that require other services). We used to separate them via the \u201cshort\u201d flag on a test by test basis. This also meant that in order to run only the unit tests, one had to call . With this , the unit and integration tests are strictly separated in different files and we use build flags to select between them. From now, to run only the unit tests you simply write . To execute the integration tests, you now need . Fix Topbeat CPU time computation on Windows avoids some floating point arithmetic when converting from a Windows structure to a 64 bits value. We\u2019re hoping that this fixes a where huge numbers were reported for CPU usage. Track unavailability in MetricbeatIf a monitor system is not available at all, an error document is to Elasticsearch so it is easier to track downtime. And from the currently in progress pull requests: Generic event representationThe way we currently represent internally an event in Beats is in the form of . Translating from Go, that means a map from string to anything (because anything implements the empty interface). The only requirement is that all types inside are JSON serializable, but then again, pretty much everything in Go is. This makes it quite easy to write new Beats (just throw anything have into a map), but it means that we have to rely on reflection when working with the event in libbeat, for example for the . Reflection code is slow and error prone. Benchmarking also showed that the JSON serialization often dominates the performance of the Beats, and it is slow because it has to do reflection. So we want to move away from this \u201canything goes\u201d events. For the transition phase (we don\u2019t have control over the community Beats) and for convenience later, we\u2019ve written that takes a \u00a0event and uses reflection (no way around that) to transform it in a nested map that only contains a few accepted types. This makes the rest of the libbeat code easier, especially the filtering code. JSON support in FilebeatWe now have a l for implementing JSON support in Filebeat. The advantage of this one over the one I in last week\u2019s update is that you can combine it with multiline and line filtering in a more meaningful way. This makes it a good way from shipping logs from a Docker host, for example, while still being able to use multiline on the application logs. Dashboards per Beat & moduleWe to move the Kibana configuration for the inside the main repo and organize it per Beat and even per module (in Metricbeat). Nicolas wrote Python scripts to split the dashboards into \u201csnippets\u201d and combine them back. \n"}
{"index": {"_id": 702}}
{"title":"Integrating Bro IDS with the Elastic Stack","seo_title":"Integrating Bro IDS with the Elastic Stack","url":"\/blog\/bro-ids-elastic-stack","author":{"name":"Travis Smith"},"date":"March 17, 2016","category":"User Stories","locales":"","content":" Cyber\u00a0attacks are continually increasing in scope and complexity. Advanced persistent threats are becoming more difficult to detect, leading to what the calls a detection deficit. has found that the average time to detection for attacks is 205 days. The core of this detection deficit is the fact that the cost, complexity, and volume of data to be analyzed increases with the maturity of the security organization. Most organizations are collecting logs from\u00a0systems, applications, and network devices to generate operational statistics and\/or alert on abnormal behavior. Software engineers write the code that determines what gets logged within their applications. Unfortunately, a lot of valuable data is not written to logs, making it improbable for log management systems administrators to detect attacks quickly. The best method to detect attacks is to analyze the sessions\u00a0and full packet capture data within the environment. To detect a cyber\u00a0attack in real-time using packet-level inspection, as well as\u00a0provide historical analysis, a network security monitoring application should be used. One such option is the . Bro is an open\u00a0source network security monitor that has been around since 1995. Bro can inspect network traffic in real-time or look into previously captured packet capture files. Bro looks for known attacks in the same way a typical intrusion detection system would. The benefit of Bro is that all connections, sessions, and application level data are written to an extensive set of log files for later review.\u00a0This blog will take a deep look into using Elasticsearch, Logstash, and Kibana for managing and analyzing log data from Bro. Log CollectionElasticsearch, Logstash, and Kibana are for collection, normalization, storage, visualization and analysis of log data. You can either install the Elastic Stack on the same system as Bro or you can run it on a separate server and forward logs from Bro via syslog. This blog assumes that Elastic Stack and Bro are install on same server. By default, all Bro logs are written to and are rotated on a daily basis. The Logstash configuration below shows how to tail the Bro log files and index data into a local instance of Elasticsearch. The full Logstash config file can be found . In the next few section, we do a step-by-step walkthrough of the configuration. input { file { path => \"\/opt\/bro\/logs\/current\/*.log\" } } filter {\u2026} output { elasticsearch { host => localhost cluster => \"elasticsearch \" } } Logstash: FiltersNext, filters need to be added to normalize the logs and extract the metadata such as IP addresses, file names, ports, etc. We will apply the filter plugin which uses\u00a0regular expression to parse through the logs\u00a0and add structure. Logstash ships with a set of grok expressions, however custom expressions are needed\u00a0to parse Bro logs. We can directly embed\u00a0regular expressions in the section of the config file. However, I have found it better to simplify the configuration\u00a0by moving complex regular expressions to a separate rule file in the pattern directory. Below is an example configuration that shows how. filter { grok { match => { patterns_dir => \"\/path\/to\/patterns\" \"message\" => \"%{291009}\" } } } The regular expressions for custom pattern\u00a0\u00a0are stored in rule file in the directory mentioned above. Patterns for different devices can be stored in separate rule file, for example bro.rule, linux.rule, apache.rule, etc. A sample file will contain rule\u00a0such as shown below. 291009 (?\\d+\\.\\d{6})\\s+(?\\S+)\\s+(?:(?[\\d\\.]+)|(?[\\w:]+)|-)\\s+(?:(?\\d+)|-)\\s+(?:(?[\\d\\.]+)|(?[\\w:]+)|-)\\s+(?:(?\\d+)|-)\\s+(?\\S+)\\s+(?\\S+)\\s+(?\\S+)\\s+(?\\S+)\\s+(?[^:]+::\\S+)\\s+(?[^:]+::\\S+)\\s+(?\\S+(?:\\s\\S+)*)$ Logstash: Conditionals To further enhance the data with fields such as action, status, object, and device types, users can use Logstash , i.e. IF\u00a0statements to split the grok pattern for each normalization rule into their own code blocks. A quick way to get the match condition for each normalization rule is to use the regular expression code from the rule file and remove the columnn\u00a0data from the code. For example, if the grok pattern was , the match expression for the IF\u00a0statement would be . It is important to remember to use ELSE IF\u00a0statements for additional message matching so a message is not accidentally matched multiple times. Such conditional processing lets us enrich the messages with additional key value pairs using the add_field. For each message, users should assign a device type, object, action, status, and rule ID. The device type, object, action, and status are part of the Common Event Expression tags to help identify similar events across multiple devices. These will help when comparing Bro log data with data from other devices (firewall, other IDS, system logs, etc.) that may not use the same naming conventions. The use of rule ID will also help performance tune Logstash going forward. Each normalized message will now be tagged with a\u00a0rule ID. Since Logstash is using a top down approach with the IF statements, we can place most commonly used normalization rules\u00a0near the top of the filter plugin. This will bypass the processor-intensive regular expression matching for messages which are rarely seen. Logstash: GeolocationWhile Bro can leverage the LibGeoIP library for geolocating IP addresses, I recommend moving this functionality to Logstash. Place the plugin after all the IF\u00a0statements. The \u00a0filter\u00a0plugin requires a source column, a destination column, location of the GeoIP database, and fields to be added from the GeoIP database. Logstash ships with a built-in GeoLiteCity database, but it may be useful to provide a separate one that can be updated on demand if needed. Full list of fields included in the built-in GeoLiteCity database are listed . Only latitude and longitude are required to plot coordinates on the map in Kibana: the other fields are optional for additional contextual information. filter { geoip { source => \"evt_dstip\" target => \"geoip\" database => \"\/path\/to\/GeoLiteCity.dat\" add_field => [ \"[geoip][coordinates]\", \"%{[geoip][longitude]}\" ] add_field => [ \"[geoip][coordinates]\", \"%{[geoip][latitude]}\" ] add_field => [ \"[geoip][coordinates]\", \"%{[geoip][city\\_name]}\" ] add_field => [ \"[geoip][coordinates]\", \"%{[geoip][continent\\_code]}\" ] add_field => [ \"[geoip][coordinates]\", \"%{[geoip][country\\_code2]}\" ] add_field => [ \"[geoip][coordinates]\", \"%{[geoip][country\\_code3]}\" ] add_field => [ \"[geoip][coordinates]\", \"%{[geoip][country\\_name]}\" ] add_field => [ \"[geoip][coordinates]\", \"%{[geoip][dma\\_code]}\" ] add_field => [ \"[geoip][coordinates]\", \"%{[geoip][postal\\_code]}\" ] add_field => [ \"[geoip][coordinates]\", \"%{[geoip][region\\_name]}\" ] } } The that stores the Logstash data has a built-in mapping that sets the geoip\u00a0field as a object type. When geolocating multiple IP fields, multiple targets will need to be used. As such, the template will need to be modified to provide mappings for the new geoip fields. To get the current Elasticsearch template for logstash, use the following command. The geoip mapping will need to be modified or copied to add additional geoip fields. To update the template, enter the command , where \u00a0is the text of the template. Once this is done, multiple geoip plugins can be used with Logstash, changing the target from \"geoip\" to \"geoip_dst\" and \"geoip_src\" in the geoip filter code Logstash: Log TimestampThe final optional piece of configuration for Logstash will be modifying the timestamp on indexed logs. When collecting Bro logs in real-time, this will not be an issue. However, if the user wants to analyze packet capture files, Bro will use the timestamp from the packet capture file as the timestamp in the logs. When Logstash collects these Bro logs, it will use the collect time as the timestamp for the log messages. If any forensics analysis is going to be done, the timestamp should be preserved for posterity. This date plugin will need to go after the IF statements in order to use the appropriate time column from the log message. Code below uses the column as\u00a0the timestamp of the log. filter { date { match => [\"start_time\", \"UNIX\"] } } Threat Intelligence Integrations Threat intelligence feeds are known indicators of compromise, generally shared across industry verticals such as finance, healthcare, industrial, retail, etc. One such provider for Bro is \u00a0The Critical Stack agent is installed on the Bro system and is configured to pull feeds from the server. Critical Stack maintains a list of more than 98 threat feeds, including malicious IP addresses, known phishing email addresses, malicious file hashes, and domains known to host malware. These feeds contain over 800,000 indicators of compromise. A free account needs to be created on the Critical Stack \u00a0to obtain an API key to\u00a0enable the\u00a0agent\u00a0to pull data. New threat feeds can be added to the agent\u2019s lists with a simple click on the website. On the agent system, the feeds are pulled and converted into Bro scripts. To integrate these scripts into Bro, just reference the target directory at the end of the Bro command. For example:\u00a0 When malicious activity is detected by the Critical Stack scripts, logs will be written to the file in the Bro log directory. Logstash: Translate for Threat IntelLogstash does not have a direct integration with threat intelligence providers like Critical Stack. However, the \u00a0filter plugin allows users to perform lookups.\u00a0The translate\u00a0plugin takes a normalized field as a source, a destination field to populate, and a dictionary path to perform the lookup. The dictionary file is a YAML formatted file that contains two columns. The first column is the value that is compared to the source field from the translation. If there is a match, the second column in the YAML file is placed into the destination column from the translation. If there is no match, the column will not be created or populated for that log file.\u00a0A simply python script (for example, see )\u00a0can pull the\u00a0threat feed\u00a0and transform it\u00a0into a usable format for Logstash. filter { translate { field => \"evt_dstip\" destination => \"tor_exit_ip\" dictionary_path => \"\/path\/to\/yaml\" } } The example code above shows a lookup of the column. When a match is found it will populate the column with the corresponding data. For reporting purposes, I have been using \"IP_Address\": \"YES\" as the format for the YAML file. This allows reports and dashboards containing the translated fields with a value of YES to be displayed. There are many other publicly available threat feed alternatives which can be similarly utilized with Logstash translations. Kibana VisualizationsData is great, but it is useless unless the business can gain context from it. Kibana can hook directly into the Elasticsearch data and provide powerful visualizations to gain context around the Bro logs. The first layer of gaining context through Kibana is to search for the valuable data through the Discover tab. An example would to limit the search to Bro\u2019s intel.log file, which is where the Critical Stack threat intelligence alerts are written to. If you are using the configuration files explained in this blog, the search would look something like . Saving this search will allow us to use it for the next layer of Kibana, Visualizations. On the Visualize tab, Kibana allows you to choose from a set of eight visualizations: each has a unique perspective on the data. I recommend playing around with each to determine which gives you the best context for your business. In the image above, we can see the geolocation information (adding via data enrichment in the Logstash configuration file) plotted on a Tile map. The lower three visualizations are pie charts exposing the type of attack types and other information contained in the logs. The search bar on the top of the dashboard shows that we are searching for everything: however the underlying visualizations are using the saved search looking for only the \u00a0data. Any further search terms put in the search bar on the Dashboard tab will search only for the data visualized, which in this case is the intel.log data. The figure above shows visualizations using a saved search looking for \u201cMaliciousIP=YES\u201d. Based on the Logstash configurations described in this blog, this is looking for any known malicious IP addresses discovered by the Logstash transform plugin. A differentiator in this dashboard versus the previous dashboard is the usage of the Source IP pie charts and the histogram (area chart visualization). The Source IP pie charts can quickly identify critical assets in your environment, any critical assets shown here should be a red flag to the business. The area chart histogram can give the business context around when attackers may think you are most vulnerable. Conclusion Even without trying to add packet capture level data for analysis,\u00a0organizations are bombarded with data from system logs. By leveraging network security monitoring tools such as Bro, the packet data can be analyzed and stored in real-time, or saved in packet captures for future analysis. The Elastic Stack provides a wide array of functionality that can normalize, ingest and analyze Bro logs. All of the data collected by\u00a0Bro can then be enhanced with Threat Intelligence feeds to detect and block\u00a0attacks more quickly, lowering the detection deficit and allowing organizations to detect cyberattacks before valuable data is exfiltrated. Using these tools, organizations can observe, orient, decide, and act quickly to the advanced threats facing them today. \n"}
{"index": {"_id": 703}}
{"title":"OpenSource Connections: The Ghost in the Search Machine - An Elastic{ON}16 Recap","seo_title":"OpenSource Connections: The Ghost in the Search Machine - An Elastic{ON}16 Recap","url":"\/blog\/opensource-connections-the-ghost-in-the-search-machine-an-elasticon-recap","author":{"name":"Doug Turnbull"},"date":"March 16, 2016","category":"User Stories","locales":"","content":" I'm trying to put my finger on why I enjoyed Elastic{ON} so much. Certainly the talks were top-notch. I especially enjoyed the talk\u00a0\u2014\u00a0which walked through the math behind relevance scoring. I loved learning how using Elasticsearch. The walk through of had me spinning with ideas (which I ) and Mark Harwood\u2019s seeded my colleagues and me with many ideas.\u00a0 But I think my favorite part was how Elastic{ON} enabled amazing conversations. See I just finished on search relevance. So our company was primed to have a ton of awesome conversations about how to improve search. We weren't disappointed. Lunch, the coffee line, walking around, and our sponsor booth seeded innumerable intersecting discussions. We got to troubleshoot with engineers from Apple, Facebook, and Roku about their challenges and to share our enthusiasm for the Elastic Stack. This \"hallway track\" as it's called makes being a speaker even more inviting. You know your talk will trigger a dozen followup conversations. Personally, I don't want to speak to sound smart. I want to speak to be stumped by the audience and learn. I want to be asked hard questions\u00a0\u2014\u00a0and most importantly to find the folks better at what I'm talking about than me! This made being a \"spotlight theater\" speaker feel especially attractive. I enjoyed how speaking was very one-on-one and conversational. It let others share ideas that I hadn't thought of \u2014 which only created a snowball of additional ideas and conversations. The small, 50-seat \"spotlight\" venue enabled this back and forth, which I loved. Being a speaker at Elastic{ON} is also refreshing due to the amount of prep Elastic puts into you as a speaker. They meet with you, help you refine your slides, and make sure you're comfortable. You also meet with your stage manager \u2014 thanks Auberie! So for anyone uncomfortable with speaking, this is a great first \"major conference\" experience where you get a tad bit of extra guidance on the road to success. Oh, so what did I talk about? My talk \u00a0highlights all the crazy and weird ways you can use Elasticsearch's inverted index to find *anything* \u2014 images, at risk students etc.\u00a0 And if you'd like to see it or meet me live, catch me at any one of these Elastic\u00a0 \u00a0or) is a search relevance consultant at OpenSource Connections. Author of Relevant Search. Doug crafts search\/recommendation solutions that \u201cget\u201d users. To do this, Doug uses Elasticsearch, sprinkling a little natural language processing and machine learning on top for good measure. EndFragment \n"}
{"index": {"_id": 704}}
{"title":"Re-creating Kibana 3 dashboards in Kibana 4","seo_title":"","url":"\/blog\/recreating-kibana-3-dashboards-in-kibana-4","author":{"name":"Tanya Bragin"},"date":"March 15, 2016","category":"Engineering","locales":"","content":" In my role I speak with many Kibana 3 users in the process of re-creating their dashboards in Kibana 4. In these conversations, I find that one of the biggest struggles is wrapping your head around how Kibana 4 approaches UI organization and navigation differently from Kibana 3.\u00a0 \"Before\" screenshot: \"After\" screenshot: \u00a0 There are many\u00a0Kibana 4 features this video doesn't cover \u2014 for more ideas\u00a0refer to some of our , peruse the , or simply , install, and play with Kibana 4.\u00a0 If you have questions about Kibana 3 to 4 transitions, please join in on discussions\u00a0on IRC (#kibana on irc.freenode.net) or on \u00a0forums. Also, let us know what other Kibana video tutorials you'd like to see! \n"}
{"index": {"_id": 705}}
{"title":"Elasticsearch 2.2.1 released","seo_title":"Elasticsearch 2.2.1 released","url":"\/blog\/elasticsearch-2-2-1-released","author":{"name":"Clinton Gormley"},"date":"March 15, 2016","category":"Releases","locales":"","content":" Today we are pleased to announce the bug fix release of based on . This release is already available on , our Elasticsearch-as-a-service platform. Users are advised to upgrade if they find themselves affected by any of the bugs fixed in this version.Latest stable release:You can read the full release notes in the pages linked above, but some of the more important bug fixes are as follows:Please , try it out, and let us know what you think on Twitter () or in our . You can report any problems on the . \n"}
{"index": {"_id": 706}}
{"title":"Beats 1.1.2 released","seo_title":"","url":"\/blog\/beats-1-1-2-released","author":{"name":"Monica Sarbu"},"date":"March 15, 2016","category":"Releases","locales":"","content":" Today we are pleased to announce the bug fix release of Beats 1.1.2. The release notes are available\u00a0.Latest stable Beats releases:Send us feedback!A big Thank You to everyone who contributed code, reported issues, created a new Beat or just tried the Beats. Start your experience with Beats 1.1.2\u00a0and let us know what you think on\u00a0,\u00a0, or open an issue on\u00a0. \n"}
{"index": {"_id": 707}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-03-14","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-03-14","author":{"name":"Michael McCandless"},"date":"March 14, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsHow does build, test, & analyze DNA mods to microbes at scale? \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole Elastic\u00a0ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 708}}
{"title":"Where in the World is Elastic? - Great Wide Open & FOSSASIA 2016","seo_title":"Where in the World is Elastic? - Great Wide Open & FOSSASIA 2016","url":"\/blog\/witwies-great-wide-open-fossasia","author":{"name":"Megan Wieling"},"date":"March 14, 2016","category":"","locales":"","content":" Welcome to Find out which Elastic events and meetups are happening near you this week.\u00a0 Upcoming EventsMarch 18-20:\u00a0March 16-17: Upcoming MeetupsMarch 16: March 16:\u00a0 March 15: March 15: March 15: March 16: March 16: March 17: March 18: March 14: March 14: March 16:\u00a0March 15:That's it for this week. Stay tuned next week for more Elastic happenings.- The Elastic Team P.S.\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}
{"index": {"_id": 709}}
{"title":"Kibana 4.4.2, 4.3.3, and 4.1.6 Released","seo_title":"Kibana 4.4.2, 4.3.3, and 4.1.6 Released","url":"\/blog\/kibana-4-4-2-and-4-3-3-and-4-1-6","author":{"name":"Joe Fleming"},"date":"March 10, 2016","category":"Releases","locales":"","content":" Last month, we dropped some patch releases to address security fixes in Node. This month, we\u2019re doing the same thing again. Thankfully, the version bumps here address the OpenSSL CacheBleed issue. Since we\u2019re cutting releases again, we decided to roll in some bugfixes to the 4.3 and 4.4 versions while we were at it. We also made a major version bump to node to help address some memory leak issues when connecting to Elasticsearch over SSL. For more details on that, see . You can download the latest and greatest version of Kibana at our page, and for more details about the bugfixes that made it in, see below. 4.4.2 Changes 4.3.3 Changes 4.1.6 Changes \n"}
{"index": {"_id": 710}}
{"title":"Visualising Oracle Performance Data with the Elastic Stack","seo_title":"Visualising Oracle Performance Data with the Elastic Stack","url":"\/blog\/visualising-oracle-performance-data-with-the-elastic-stack","author":{"name":"Robin Moffatt"},"date":"March 09, 2016","category":"User Stories","locales":"","content":" IntroductionOne of the great things about the Oracle database is the level of diagnostics and performance data that is available from it. Used in conjunction with good instrumentation from the applications generating the workload on the database, it\u2019s a brilliant way\u00a0\u2013\u00a0arguably, the only way\u00a0\u2013\u00a0to accurately\u00a0and\u00a0efficiently get to the bottom of any performance problems that arise. By analysing what the database is doing at a point in time we can understand more about the load that it is under, and by looking at how a given session executes we can identify optimisation opportunities for it. The data is available natively through some of the V$ system views, and exposed through Enterprise Manager, and tools such as SQL Developer. What I\u2019m going to show in this article is how you can make use of the open-source Elastic Stack\u00a0\u2013\u00a0comprising Elasticsearch, Logstash, and Kibana\u00a0\u2013\u00a0to\u00a0extract this data and visualize it as an alternative to the aforementioned options. Why the Elastic Stack?Because is a great data visualization and exploration tool. Because is a great datastore that is dead easy to work with, and because makes getting data from a an absolute doddle. It\u2019s a stack I frequently use for monitoring and diagnosing applications including OBIEE, and including Oracle performance data in that analysis was an obvious thing to do. LicensingElasticsearch, Logstash, and Kibana are all open-source tools that are free to use. You can pay for a that gives you direct access to product support, as well as additional tools including for monitoring, security and alerting. The is required if you\u2019re using functionality in Oracle including (but not limited to) Active Session History (ASH) \u2013 if in doubt, speak to your Oracle Account Manager. VersionsThis article was written using Elasticsearch 2.2, Logstash 2.2, Kibana 4.4, pulling data from Oracle 12c (12.1.0.1.0). I used the excellent to generate load against the database. OverviewThe Elastic Stack gives you great flexibility to analyze exactly the data that you need, in exactly the way that you want to. In this article I\u2019m going to show how to get Active Session History (ASH) data streamed into Elasticsearch. You might want to then enrich it further with log data from your applications, or OS metrics from the servers \u2013 or anything else that might be useful for a full-stack view of your application\u2019s performance. Using Logstash\u2019s JDBC input, we pull data from the Oracle table, loading the data directly into Elasticsearch. From there we can analyze it with Kibana. It really is as simple as that. Setup You should see some output showing that Elasticsearch has started up successfully: If you Ctrl-C or close the terminal, you\u2019ll kill Elasticsearch. For this\u00a0\u2013\u00a0and a multitude of other purposes \u2013\u00a0I\u2019d always use\u00a0\u00a0in order to run multiple sessions in a single window\/SSH connection.\u00a0If you installed kopf in step 4 above you can now go to\u00a0\u00a0to see the status of Elasticsearch.\u00a0 After a moment go to and you should see a config screen like this:\u00a0 Getting the Data into ElasticsearchSo far, so easy. Download and run a handful of binaries. But, we\u2019ve not got any data yet. Enter . Logstash enables you to pull in data from , , and then output it to Elasticsearch and . Here we\u2019re using the Logstash input plugin. Note that this is relatively new (in the open-source sense) and previously was often done as a \u201cRiver\u201d\u00a0\u2013\u00a0something now deprecated in Elasticsearch but I mention it here as you may still find articles through Google that reference it. To use Logstash we need to build a configuration file. We\u2019ll build this up step by step to make sure it\u2019s all working along the way. First Steps with Logstash JDBC InputAll Logstash configuration files have the same simple structure : input, filter, output. And of those, filter is optional. Here\u2019s our starter for ten, that\u2019ll act as a smoke-test for the Logstash-JDBC-Oracle connectivity: input { jdbc { jdbc_validate_connection => true jdbc_connection_string => \"jdbc:oracle:thin:@oradb:1521\/orcl\" jdbc_user => \"system\" jdbc_password => \"Admin123\" jdbc_driver_library => \"\/opt\/ojdbc7.jar\" jdbc_driver_class => \"Java::oracle.jdbc.driver.OracleDriver\" statement => \"SELECT sysdate from dual\" } } output { stdout { codec => rubydebug } } The parameters in the input JDBC stanza are all pretty obvious\u00a0\u2013\u00a0connection string, credentials, path to JDBC driver that you\u2019ve installed, and the SQL to run. For the moment we\u2019re setting the output as simply back to the console, using some formatting provided by a codec (you don\u2019t need to worry about this detail here\u00a0\u2013\u00a0it just makes things easier to read).Save this local to the server where you\u2019re running Logstash (here I\u2019ve saved it to ), and then execute it : \/opt\/logstash-2.2.0\/bin\/logstash -f ~\/logstash-ora-01.conf After a few seconds of Logstash firing up, you should see the output including the SYSDATE that it\u2019s pulled through from Oracle Settings: Default filter workers: 2 Logstash startup completed { \"sysdate\" => \"2016-01-30T22:19:30.000Z\", \"@version\" => \"1\", \"@timestamp\" => \"2016-01-30T22:19:30.112Z\" } Logstash shutdown completed Note that you\u2019ve also got two internal Logstash fields in there:\u00a0 and . Polling OracleAs you saw above, when we ran Logstash it ran the query once and then finished. We\u2019re going to want to be polling the data out of Oracle on a continual basis in order to stream it into Elasticsearch. Let\u2019s see how we can do that here. As the for the Logstash JDBC input plugin shows, a can be specified in the parameters. The syntax matches that of cron. Our Logstash configuration file now looks like this, and will poll Oracle every two minutes: input { jdbc { jdbc_validate_connection => true jdbc_connection_string => \"jdbc:oracle:thin:@oradb:1521\/orcl\" jdbc_user => \"system\" jdbc_password => \"Admin123\" jdbc_driver_library => \"\/opt\/ojdbc7.jar\" jdbc_driver_class => \"Java::oracle.jdbc.driver.OracleDriver\" statement => \"SELECT sysdate from dual\" schedule => \"*\/2 * * * *\" } } output { stdout { codec => rubydebug } } When we run it (and wait patiently!) we\u2019ll see that every two minutes it\u2019s pulling new data from Oracle: Settings: Default filter workers: 2 Logstash startup completed { \"sysdate\" => \"2016-01-30T22:26:00.000Z\", \"@version\" => \"1\", \"@timestamp\" => \"2016-01-30T22:26:00.513Z\" } { \"sysdate\" => \"2016-01-30T22:28:00.000Z\", \"@version\" => \"1\", \"@timestamp\" => \"2016-01-30T22:28:00.062Z\" } Now that Logstash is running on a stream of input data we need to explicitly kill it to get it to stop \u2013 Ctrl-C will do the job here. ^CSIGINT received. Shutting down the pipeline. {:level=>:warn} Logstash shutdown completed Oracle to Logstash to ElasticsearchWe\u2019re getting closer now to the final configuration that we need. Let\u2019s see how Logstash can be configured to send the data we\u2019ve been pulling from Oracle into Elasticsearch, instead of just the console on stdout. It\u2019s really difficult, I\u2019m warning you now. () We\u2019ll use the same input stanza, but with one little extra line in the output: input { jdbc { jdbc_validate_connection => true jdbc_connection_string => \"jdbc:oracle:thin:@oradb:1521\/orcl\" jdbc_user => \"system\" jdbc_password => \"Admin123\" jdbc_driver_library => \"\/opt\/ojdbc7.jar\" jdbc_driver_class => \"Java::oracle.jdbc.driver.OracleDriver\" statement => \"SELECT sysdate from dual\" schedule => \"*\/2 * * * *\" } } output { stdout { codec => rubydebug } elasticsearch {} } Blink and you\u2019d miss it, right? That one little is all that it takes to send data to Elasticsearch, as well as still sending it to stdout. The supports lots of parameters, but if you\u2019re running a single Logstash instance locally to a single Elasticsearch node, that\u2019s really all you need. If you now look in kopf you\u2019ll see that an \u201cindex\u201d called logstash- followed by the current date has appeared. The number of \u201cdocuments\u201d should match however many entries you\u2019ve got on the console \u2013 each \u201cdocument\u201d is one record sent from Logstash to Elasticsearch. In RDBMS terms a document is roughly a row, and an index roughly a table. You\u2019ll also see in kopf that the top bar has turned from Green to Yellow, indicating the health of Elasticsearch. It\u2019s gone Yellow as a warning, because you\u2019re now storing data (which you weren\u2019t before, when it was green) and you\u2019ve only got a single node so no redundant copy of it for resilience. Elasticsearch, as the Elastic part of the name implies, scales horizontally by design and doing\u00a0\u2013\u00a0so is a doddle. Provisioning extra nodes in the cluster is pretty much a case of just installing the binaries and updating the configuration to use the same cluster name\u00a0\u2013\u00a0as soon as you fire them up Elasticsearch will automagically rebalance the data so that there are redundant copies \u2013 at which point the cluster health goes back to Green. Phew! Did Someone Say Oracle Performance Data?So far we\u2019ve just been proving out the connectivity. Now let\u2019s actually, finally, start pulling in some of the good stuff. Oracle\u2019s table holds a snapshot every second of what has been running on the database at that point in time. , as it\u2019s known, is one of the best ways to analyze the queries that have been running and what the database was doing whilst running them. We\u2019ll use the column on as our predicate, otherwise we\u2019ll pull back the whole contents of the table each time. The JDBC plugin can store on disk when it last ran, and it makes this available as a run-time variable to pass into the SQL. The SQL statement looks like this: statement => \"SELECT * FROM V$ACTIVE_SESSION_HISTORY WHERE SAMPLE_TIME > :sql_last_value\" . Now we\u2019re going to introduce a new stanza to the configuration:\u00a0a \u2013\u00a0they might enrich the data, conditionally drop it, manipulate it, and so on. Here we\u2019re just doing a straightforward field assignment, setting the date of the (the field that you can see in the sample output above) to that of the in the ASH data, rather than the current time of processing. By default Logstash will record each event that it processes (so in our case, a row of ASH data) as having occurred at the current time. If we\u2019re streaming data from a log file, that\u2019s probably true, but when we\u2019re polling data (or back-populating historical data) it is important to assign the actual time to it. You\u2019ll know if you\u2019ve not done it when all your historical data shows up in Elasticsearch and Kibana with today\u2019s date\u2026 Note that whilst is a timestamp field, it can\u2019t be directly assigned\u00a0\u2013\u00a0we have to cast it to string first and then pattern match it: mutate { convert => [ \"sample_time\" , \"string\" ]} date { match => [\"sample_time\", \"ISO8601\"]} If you don\u2019t cast it first, you\u2019ll get the error Thanks to for this workaround. Watch out also that field names are case sensitive. The completed configuration looks like this.\u00a0Note that the stdout is commented out\u00a0because there\u2019s going to be a lot of data flowing and dumping it to the console slows things down somewhat. For debugging though, it\u2019s useful to leave in. input { jdbc { jdbc_validate_connection => true jdbc_connection_string => \"jdbc:oracle:thin:@oradb:1521\/orcl\" jdbc_user => \"system\" jdbc_password => \"Admin123\" jdbc_driver_library => \"\/opt\/ojdbc7.jar\" jdbc_driver_class => \"Java::oracle.jdbc.driver.OracleDriver\" statement => \"SELECT * FROM V$ACTIVE_SESSION_HISTORY WHERE SAMPLE_TIME > :sql_last_value\" last_run_metadata_path => \"\/tmp\/logstash-oradb.lastrun\" record_last_run => true schedule => \"*\/2 * * * *\" } } filter { # Set the timestamp to that of the ASH sample, not current time. mutate { convert => [ \"sample_time\" , \"string\" ]} date { match => [\"sample_time\", \"ISO8601\"]} } output { #stdout { codec => rubydebug } elasticsearch {} } The first time that you run this, it\u2019s going to take a while, because the \u201clast_run\u201d value doesn\u2019t yet exist (since we\u2019ve never run it) and defaults to 1\/1\/1970. If you don\u2019t want a full dump of ASH loaded, you could probably write a crafty CASE clause into the SQL to cater for this, or pre-create the lastrun metadata file on disk\u00a0\u2013\u00a0it looks like this: --- 2016-02-02 23:02:06.470000000 Z Data CleansingWhen you run Logstash you may well get a screenful of errors like this: Failed action. {:status=>400, :action=>[\"index\", {:_id=>nil, :_index=>\"logstash-2016.02.02\", :_type=>\"logs\", :_routing=>nil}, #, @cancelled=false, @data={\"sample_id\"=>#, \"sample_time\"=>\"2016-02-02T18:37:00.680Z\", [...] and on Elasticsearch\u2019s console too: [2016-02-02 23:38:15,716][DEBUG][action.bulk ] [Ariel] [logstash-2016.01.30][3] failed to execute bulk item (index) index [...] MapperParsingException[failed to parse [force_matching_signature]]: nested: JsonParseException[Numeric value (12852529615260526791) out of range of long (-9223372036854775808 - 9223372036854775807) at [Source: org.elasticsearch.common.io.stream.InputStreamStreamInput@5795fe7d: line: 1, column: 334]]: at org.elasticsearch.index.mapper.FieldMapper.parse(FieldMapper.java:339) at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:314) What\u2019s happening here is that Logstash is sending data over to Elasticsearch that it\u2019s not happy with in the data type that Logstash is claiming, hence failed to parse [force_matching_signature] [...] and since we\u2019re not interested in storing it, we\u2019ll add another clause to just chuck it away: # Drop \"force_matching_signature\" because its value sometimes blows the limits of the long data type mutate { remove_field => [ \"force_matching_signature\" ] } Thanks to a recent change in Lucene (on which Elasticsearch is built), it is likely that in the future Elasticsearch will have more comprehensive support for large data types, as describe on . For here-and-now,\u00a0I guess if it was a field that we wanted to retain it could be cast to a string for storage (or on the fetch from Oracle). I found that p3 also trips up on the same, so dropped it too. This does give me opportunity to mention a great feature of Elasticsearch\u00a0\u2013\u00a0schemas (\u201cmappings\u201d) can evolve as needed, and if we want to start sending greater or fewer columns from Logstash to Elasticsearch we do just that, and Elasticsearch won\u2019t bat an eyelid. In general, the SELECT * [...]\u00a0is a bit of a lazy way to pull data out: much neater would be to build up a properly specified list of columns that we want and only the ones that we want. So What Have We Got Now?Having set Logstash running loading ASH data into Elasticsearch, you should see the volume of data in increasing as shown by kopf: Each row from ASH is one \u201cdocument\u201d in Elasticsearch, and Logstash will by default partition data in Elasticsearch by date. In the above screenshot there are two days\u00a0worth of data, and so two indicies (\u201clogstash\u20132016.01.30\u201d and \u201clogstash\u20132016.02.02\u201d). The date partitioning is\u00a0another reason the timestamp field that we set in the filter clause above is important. Even though as we\u2019ll see shortly Kibana can work with any timestamp field, we want to make sure that Elasticsearch is using the appropriate partitioning key:\u00a0event timestamp. Analytics on ASH - Enter KibanaSo far we\u2019ve collected the ASH data from Oracle with Logstash, and stored it in Elasticsearch. Let\u2019s see now how we can do some cool visualizations and analytics on it, using the third part of the Elastic Stack:\u00a0Kibana. Setting up KibanaThe first time you use Kibana (or add a new set of data to it in different indicies) you need to tell it what the index, or indicies pattern, is. Here we benefit from the tight integration within the Elastic Stack because Logstash by default writes to a partitioned index called [...], and Kibana by default reads data from an index called the same. Launch Kibana in your favourite web browser by going to (change localhost for the server on which you\u2019re running Kibana), and you should see the screen as seen above. Leave the as , and in the list, pick (remember that in the Logstash configuration we\u2019ve already mapped this directly to ): Click Create, and Kibana will then list out all of the fields that it can find in the Elasticsearch index: From here we\u2019re going to explore the functionality that Kibana offers. It\u2019s split up into three main areas:\u00a0, , and . Dashboards are a compendium of one or more visualizations and searches (built with Discover), so really it\u2019s only two that we need to learn! Discover This gives you access to the raw \u2018documents\u2019, viewing all the field values, and searching and filtering. The bar chart at the top of the page shows a count by time period of documents. The longer the time window shown, the greater the time period per bar. By default just the timestamp of an event and the whole document () are shown, which is of limited use if we\u2019ve got lots of fields of useful data. By hovering over a field on the left you can opt to add or remove it from the columns in the table shown:\u00a0 You can do neat things like see a summary of the proportion of occurrences of each value within a field (based on a sample): and from there opt to show only those values, or to exclude them: If you click on the toggle arrow next to a particular document the full contents is displayed, which can be a useful way to examine given record. From here you might identify fields that may be useful for data discovery and you therefore want to display as a column in the table, as well as data values that you want to specifically show-only, or exclude, from the table by adding a filter. To save the view of the records (in terms of fields\/columns shown, and filters applied), click the icon in the top right of the screen. VisualizeLet\u2019s head on over to now, where we can build useful aggregations on top of the data to help with our analysis of it. We\u2019ll start with an Area Chart: Under click X-Axis and set the to . You can specify a time interval if you want, or leave it as Auto. Click the Apply button (the big green triangle).\u00a0 You should see something similar to the bar chart in the Discover page that we saw previously. It\u2019s a count of the number of documents, per time period.\u00a0So here we\u2019re seeing the number of active sessions on the database, summarised up per time period. Let\u2019s add a dimension to the data, and look at the within these sessions. To do this click on , , and set the to . Click the dropdown and set it to (note the suffix) and hit the apply button again. OK, this is starting to look interesting. How about a third dimension - . This is one of those ones that any good application developer should be setting in order to improve the instrumentation and therefore diagnostics for their application. Read more about why this is so important in Cary Millsap\u2019s here. Anyway, here it is thrown into our Kibana visualization of ASH data: To build this, I added a further sub-bucket, using the option, and a aggregation on the module.raw field. Now save the visualization (top right of the screen), because we\u2019re going to use it shortly in a Dashboard. Once you\u2019ve got the hang of the Kibana interface you\u2019ll find it a doddle to start properly slicing & dicing data to suit what you\u2019re looking for. Here\u2019s another example of a visualization I put together, and it\u2019s so easy to do it only took a couple of minutes:\u00a0 I\u2019ve always scorned pie charts, but I think this one of ASH data is genuinely an appropriate use of the visualization. It shows what the user\u2019s doing (), and what the database is doing (). Perhaps as a standalone analytical visualization it still falls foul of the problem of pie charts (the human eye has difficulty perceiving the relative proportions of an area in a circle), but as we\u2019ll see in a moment, visualizations can be interactive filters, and combined with the tooltips, I think this pie gets to stay\u2026 Dashboards Standalone \u2018Discover\u2019 and \u2018Visualize\u2019 explorations can sometimes be enough in themselves to answer the questions you have for the data, but typically you\u2019ll want to pull several of them together. You might want a \u201cdashboard\u201d in the monitoring sense, or maybe just a way to show the detail rows of data for a given visualization. From the Dashboard tab click the + icon in the top right of the page. From here you\u2019ve got two tabs enabling you to select which visualizations and searches (from the Discover page) you want to include: When you add them in they\u2019ll first show up as small boxes which may well be too small to show the intended contents. Simply hover over the bottom-right corner of any of the boxes to resize (notice how the rest of the boxes rearrange themselves to make space \u2013\u00a0neat!). In no time at all, you can put together something like this:\u00a0 And now the really neat bit\u00a0\u2013\u00a0as I mentioned briefly before, the dashboard is interactive. You can hover over elements to see details about that data: What\u2019s more? You can click on any element such as a bar chart or pie chart segment to apply a filter for that segment of data. Here we can show all ASH records related to the identified module, action, and wait state: Note the filters at the top of the screen - you can toggle these to change the view on the data. For example, to show all ASH records for the given module and action but regardless of state etc: All the visualizations and data tables on the page show data as specified by the filters. This is a very intuitive, powerful, and flexible way for analysing your data! ConclusionThe Elastic Stack is a fantastic way to quickly ingest data, store it, and analyze it. It\u2019s so simple to install and get started with, and all of this can be done from a simple install on a laptop, or scaled up onto proper servers for production use with clustering for both resilience and performance. is Head of R&D (Europe) at , and an Oracle ACE. He specialises in OBIEE and Linux as well as ODI, and more recently delving into the worlds of Hadoop and Elasticsearch. His particular interests are systems architecture, administration, and performance testing and optimisation. He blogs at and and can be found tweeting grumpy geek thoughts as . \n"}
{"index": {"_id": 711}}
{"title":"Brewing in Beats: New community Beats, custom fields, performance improvements","seo_title":"","url":"\/blog\/beats-weekly-community-beats-custom-fields-performance","author":{"name":"Tudor Golubenco"},"date":"March 08, 2016","category":"Brewing in Beats","locales":"","content":" Welcome to Weekly Beats! With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources. Lots of positive energy in the team after Elastic{ON}, thank you everyone that attended and provided us with feedback. Custom fields for all Beats A common request was to add Filebeat-like custom fields to all other Beats. The tags we had in the common section of the configuration files just weren\u2019t enough. So all Beats have fields \u00a0tags in the common section and it is also easy to add them per Beat-specific element (e.g. prospector in Filebeat, protocol in Packetbeat, etc.). New Community Beats More goodies from the community: Better configuration file handling Up to now we were using a generic YAML parser for reading our configuration files. This is very clean and convenient from the code perspective, but there are several things about it that annoyed us: Those were the bad news. The good news is that Steffen is on fixing them, and not only for the Beats but for other Go programs that use YAML as well. He is writing ucfg (universal configuration) that adds a layer above the YAML parser (or any other parser) that will eventually be able to do configuration validation, accepts dots in field names (so we don\u2019t have to always rely on white space) and make the configuration definitions pluggable. This is already used for the output modules in libbeat as well as the \u00a0 truly self contained. Topbeat performance improvement When monitoring a large number of processes, the cost of getting their command line on each poll was significant, especially on Windows. This PR fixes it by the command line strings. Telling benchmarks for Windows and OS X are in the PR description. Improved shutdown logic in libbeat Shutting down is never easy when dealing with lots of channels. McStork, a community contributor, stepped up and helped i we have for shutting down the publisher. Metricbeat progress Nicolas is making good progress on getting the Metricbeat infrastructure ready before adding more modules. This includes a reworking of the handling and getting more metricsets in the existing , testing if and starting the to new Metricbeat modules. Filebeat fix for duplicates on restarting We discovered a that could cause Filebeat to re-read a complete file if it was restarted at the wrong time. It is now fixed and we\u2019re preparing a 1.1.2 release for next week to include this. Other notable merges since the last update And from the newly opened \/ in progress \/ discussion PR \n"}
{"index": {"_id": 712}}
{"title":"Women of Elastic: A look back and our steps forward","seo_title":"","url":"\/blog\/women-of-elastic-a-look-back-and-our-steps-forward","author":{"name":"Kristina Frost"},"date":"March 08, 2016","category":"Culture","locales":"","content":" For those of you who couldn\u2019t join us at , Thursday, February 18 was a pretty special day for the women of Elastic: we hosted our first ever\u00a0 at the conference. This marks our first attempt to make a space for the women of our community to come together, share experiences, and talk about the kinds of things we care about, from the best and most ergonomic women\u2019s backpacks (hey, that struggle is real), to career sponsorship, to further opportunities for meetups and hackathons. At the end of the breakfast, we asked for your feedback, information I promised our attendees I\u2019d publish out to the world as we think about what future diversity events look like and how this community is going to grow and thrive. Now here we are. Almost 50 different suggestions came in, including some feedback that was overwhelmingly positive and meant the world to all of us. I\u2019m sure more is on the way through post-conference surveys, and some we got in real time via the Elastic{ON}16 app.I\u2019m writing this as I sit on a flight to Denver, reflecting on the notes we\u2019ve received so far. Among these responses, the word \u201cmore\u201d appeared regularly in the things you wrote. More conversation. More events. More opportunities to meet women and exchange ideas. Relationships and networking were a huge theme. wrote one attendee, a comment echoed by other women who want or who think we need to keep spending time together Two attendees suggested we work with other companies to partner and sponsor these kind of events in the future: another, in writing about the possibility of a Bay Area meetup, gave a shoutout to our very own as a great host for these kinds of events.Training was a big theme, too. You asked us if we could get more hands-on in the future, if we could provide walk-throughs for newbies, things to get those of you who are approaching the Elastic Stack for the first time off the ground quickly. You want to see us participate in protecting and developing the interests of young girls, teaching them how to code. \u201cGirls 4-10 are being turned off from tech,\u201d one of you wrote, encouraging us to think about how we can encourage the women of the future to participate in technology, to \u201csee how cool it is!\" We are proud of several of the talks that were delivered by women at Elastic{ON}: in particular, I highly recommend the . Social scientist Dr. Sherry Forbes shared the ways in which Giant Oak is using Elastic to stop human trafficking and to find the individuals who endanger the world\u2019s rhino population by trading rhino horns on the black market. Of the talks that I attended at the conference, it was far and away the nearest and dearest to my heart as a woman who\u2019s crossed continents to be with women who\u2019ve been trafficked and who wants women everywhere to be able to flourish without fear. But other women speakers included of Cisco Talos, Netflix's , from Goldman Sachs, as well as Elastic's own , , and , and the talks are all for anyone who wasn\u2019t able to attend.Others wanted to see women executives come and speak. One attendee wrote, and one asked for session with women from all levels, all backgrounds, speaking as panelists and offering their insight. Another great suggestion we received was around crafting a track at the conference specific to women in tech, or even, perhaps, specific to diversity.As an interesting aside, a question that came up several times prior to the conference, including once in the Elastic{ON}app, was whether or not men were welcome to come and join us, and this desire to include them was reflected in one of my favorite comment cards from the entire morning: I\u2019ll be thinking about how to make it more clear in the future that we want and value every person who wants to participate in our conversations about Women in Tech, and how we broaden this movement to engage in all kinds of diversity conversations from a variety of perspectives.We look forward on collecting all of these great ideas and taking them into the next year, and we commit to keep making Elastic, and Elastic{ON} events, a place where diversity is showcased and where it thrives. Some of this is simple stuff, like making sure our staffing schedules reflect our own company diversity at our booths, that our speaker lineup showcases the even greater diversity that exists within our developer community, and that we double-down on making sure that our facilities are friendly and accessible to all attendees. But a lot of the ideas that you all had went beyond logistics, and were geared towards creating a community where people from all walks of life can support and encourage each other on the road to creating great products. Reading them gave me hope that we can build a software and technology industry that is more than just innovative -- that we can make it , too. As you can see the possibilities for where all of this could go are pretty endless. That\u2019s one of the things that I think is so exciting about it. The enthusiasm women have for this topic and the way we are all coming into our own together, exploring, triumphing, building a better future together is incredible. It\u2019s inspiring. And it was perhaps one of the highest honors of my career to start this dialogue with all of you. Several of you suggested that we find a way to keep the conversation going virtually, so that the exchange of ideas isn\u2019t just limited to a time and a place. That\u2019s a suggestion we\u2019re happy to take on, and proud to implement right away. Others are in the works. \u201cI live in the middle of nowhere,\u201d one woman wrote, rightly pointing out that virtual spaces let us have happy hour everywhere. To continue\u00a0the conversation, stay involved, and help build our community, join us on our \u00a0and stay tuned for more events and discussions in the near future.And if you're more of a visual person, we recorded this short video from Elastic{ON} to help capture our thoughts and plans for the future of the Women of Elastic. Hope you enjoy! \n"}
{"index": {"_id": 713}}
{"title":"Optimizing The Design of New Microbes Using Elasticsearch: An Elastic{ON} Reflection","seo_title":"","url":"\/blog\/optimizing-the-design-of-new-microbes-using-elasticsearch-elasticon-reflection","author":{"name":"Kiyan Ahmadizadeh"},"date":"March 08, 2016","category":"User Stories","locales":"","content":" At , we are combining biology, software, and automation to design new microbes that will revolutionize chemical and material production. To do this, we are creating an industrial biofactory that allows us to build, test, and analyze DNA modifications to microbes at scale. Technology like Elasticsearch has helped us take advantage of the data produced during this process. Thanks to Elasticsearch, our scientists can ask questions of our data that help us explore the vast space of possibilities in DNA.I attended Elastic{ON}\u00a0as a speaker, sharing our experience at Zymergen using Elasticsearch to help optimize the design of new microbes. The best technical conferences introduce you to new ideas you can apply to tough engineering problems. Elastic{ON}\u00a0was this kind of conference. For example, minutes after arriving on the first day I met Marko Iskander from Adobe, who is to improve search results by adding user context to queries. Although font discovery and microbe design are as different as use cases can be, my conversation with Marko and his talk immediately got me thinking about how this technique could be used to improve search results at Zymergen. Learning about Elasticsearch libraries (like the Hadoop, Beats, and Kibana Plugin frameworks) also stimulated exciting new ideas about ETL and analytics. Elastic{ON}\u00a0was rewarding not just for the chance to speak, but also for the chance to learn from fellow engineers developing exciting solutions.My experience as a speaker was equally rewarding. I was impressed by the support the Elastic\u00a0team gave as I was preparing my talk for the conference, and their advice was crucial in developing a talk that reached the audience. The lighting, seating, and screen setup at Stage A was energizing and made me feel like an announcer at a sporting event. I appreciated the audience\u2019s attention during my talk, and was delighted by the variety of questions as attendees looked to explore techniques they could apply to their own solutions. Others shared their experiences applying Elasticsearch to problems in bioengineering. This chance to share my experience at Zymergen and learn about the experiences of others was the primary reason I wanted to speak at Elastic{ON}.I hope you enjoy . It was a pleasure\u00a0to share our experiences with such a bright and engaging audience.Kiyan Ahmadizadeh builds software that helps organizations in complex industries (like utilities infrastructure or industrial bio-laboratories) make intelligent operational decisions. His work often utilizes cloud computing and NoSQL technologies. His hobbies include running, reading, music, and meditating. \n"}
{"index": {"_id": 714}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-03-07","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-03-07","author":{"name":"Michael McCandless"},"date":"March 07, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsWondering why queries don't always work? dives into the details of phrase-matching in : \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole Elastic\u00a0ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 715}}
{"title":"Phrase Queries: a world without Stopwords","seo_title":"Phrase Queries: a world without Stopwords","url":"\/blog\/phrase-Queries-a-world-without-stopwords","author":{"name":"Gabriel Moskovicz"},"date":"March 07, 2016","category":"Engineering","locales":"","content":" Analysis and query processing can be confusing when you start out with Elasticsearch. It\u2019s one of the most common problems that users run into, and one clear example is phrase matching. In this article we will dig into the process of understanding some of the complexity of Phrase queries, while working with languages and stopwords. The key of working with Elasticsearch is to have a better understanding of what a query is doing. Furthermore, we need to understand that the art of searching starts when a document is indexed, and all its field content is analyzed and finally indexed into Lucene. Most of the time, we are only thinking about how to query our data source, but in Elasticsearch we should first think about the insight that we want to get from our data, so we may then discover the best way to accomplish this. To achieve our goals in Elasticsearch we need to think about the entire picture: indexing and querying. Indexing means not only adding the structured document in Elasticsearch, but also including the analysis of each field. Each field is analyzed, and then the result of the analysis is indexed by Elasticsearch. But what is analysis? By definition it is the process of breaking a - complex - topic (or substance) into smaller parts in order to gain a better understanding of it. This word comes from an Ancient Greek word \u1f00\u03bd\u03ac\u03bb\u03c5\u03c3\u03b9\u03c2 (analysis, \u201ca breaking up\u201d, from ana- \u201cup, throughout\u201d and lysis \u201ca loosening\u201d). In concrete terms, Elasticsearch analysis is a process that consists of the following steps: For more information and details about the full analysis process please visit . Once the document is indexed, we can execute queries to retrieve the results based on different conditions. The query execution and matching will be strongly related to the way that we index data, hence why we say that Elasticsearch is not only about querying, but about creating a solution that suits user needs. Languages and a world with Stopwords The stopword definition is very simple: they are the most common words in a language. The important fact about stopwords is that, since they are very common, these are words that are going to frequently appear in our language, phrases and probably most of our text fields. Some examples of stop words are: \u201ca\u201d, \u201cand\u201d, \u201cbut\u201d, \u201chow\u201d, \u201cor\u201d, and \u201cwhat\u201d. Usually, when we search for something, we want to exclude them. This can be tricky, because excluding words is easy, but it will impact the results of certain queries. The art of Phrasing In linguistic analysis, a phrase is a group of words (or possibly a single word) that functions as a constituent in the syntax of a sentence: a single unit within a grammatical hierarchy. The phrase is composed of different words, one followed by the other, with a certain order. While two phrases can have the same meaning, the order of the words will create a completely different phrase. As an example: \u201cThis fox is brown\u201d is totally different to \u201cIs the fox brown\u201d. Why is this? Because each word has a position within the phrase that causes the meaning of the sentences to be similar, but the word chain to be completely different. As we were explaining in the introduction, the indexing process in Elasticsearch will execute the analysis process. Analysing phrases in Elasticsearch is simple, and can help to explain why two phrases are different. In Elasticsearch, we provide the Analyze API that can be used with a simple set of parameters to understand what a specific analysis process is doing. In the following example we will be using the English analyzer that is predefined in Elasticsearch to understand why the following phrases are different. GET _analyze?text=This fox is brown&analyzer=english { \"tokens\": [ { \"token\": \"fox\", \"start_offset\": 5, \"end_offset\": 8, \"type\": \" GET _analyze?text=Is the fox brown&analyzer=english { \"tokens\": [ { \"token\": \"fox\", \"start_offset\": 7, \"end_offset\": 10, \"type\": \" The output that we get from this API is not only the tokens generated by the analysis process, but its position and character offset, which is very useful to understand the different phrases. In both examples, the tokens generated are only and , however you can see that the position of each token within the phrase is different. Please note that in the first example the position from one word to the other differ in 2 locations. Searching our Phrases Searching for content is very straightforward, one can easily search for all those documents or fields that contain certain words. However, searching for full phrases is a completely different problem. Not only the words are important, but also the word chain and position of each word in the chain is important to ensure that the phrase is matching. This means that are needing to be met in order for a document to match a certain phrase. To have a better understanding of the problems that we can get we will index some documents, creating an index that uses the English analyzer for a string field. Here is the snippet code for this: # Create the index, with a test_type that contains a text field that uses the english analyzer PUT test { \"mappings\": { \"test_type\": { \"properties\": { \"text\": { \"type\": \"string\", \"analyzer\": \"english\" } } } } } # Index the first document POST test\/test_type { \"text\": \"This fox is brown\" } # Index the second document POST test\/test_type { \"text\": \"Is the fox brown\" } Now we are ready to execute some phrase searches. In the following example, i will search for the phrase \u201cfox brown\u201d, so i can get both results. The following simple query is the one that you can execute to retrieve this results: POST test\/_search { \"query\": { \"match_phrase\": { \"text\": \"fox brown\" } } } However, when we execute this search we can verify that a single document is matching. The actual result of this query will be: { \"took\": 3, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"failed\": 0 }, \"hits\": { \"total\": 1, \"max_score\": 0.38356602, \"hits\": [ { \"_index\": \"test\", \"_type\": \"test_type\", \"_id\": \"AVMtW9pP50vx9-KwTUbS\", \"_score\": 0.38356602, \"_source\": { \"text\": \"Is the fox brown\" } } ] } } Why is this? Because in the position of fox in the phrase is , and the position of brown in the phrase is , hence the only document that will match this query will be the one that contains the word fox followed (differing a single position) by brown. This is one of the common mistakes that we make when we try to search for phrases expecting some results that we are actually not getting. Another example will be searching for \u201cfox in brown\u201d. We will expect no results to be found by this phrase, however let\u2019s take a deeper look at this: # The following is the query to execute POST test\/_search { \"query\": { \"match_phrase\": { \"text\": \"fox in brown\" } } } And the result will be: { \"took\": 3, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"failed\": 0 }, \"hits\": { \"total\": 1, \"max_score\": 0.38356602, \"hits\": [ { \"_index\": \"test\", \"_type\": \"test_type\", \"_id\": \"AVMtW9W050vx9-KwTUbR\", \"_score\": 0.38356602, \"_source\": { \"text\": \"This fox is brown\" } } ] } } So we now see that \u201cfox in brown\u201d is matching \u201cThis fox is brown\u201d, while we don\u2019t expect this. So why is this document matching now? Let\u2019s go back to the analysis of our document. In the beginning of this article, we analyzed \u201cThis fox is brown\u201d resulting in two tokens, with specific positions: And when we are searching for the phrase \u201cfox in brown\u201d we are going to be searching for documents that: Since is a stopword, it is removed in the analysis process, as well as \u201cis\u201d was removed before, and all this will impact the result of all our queries. The conclusion of this article is that we need to strongly consider the entire process to understand if the queries that we are creating are going to match the information that we need. For all this, we should keep an eye on the way that we index the data to verify the entire process. The art of searching in Elasticsearch is not only about creating the exact queries, but mixing with a smart analysis process to sympathise with these queries. After all, Elasticsearch is all about . \n"}
{"index": {"_id": 716}}
{"title":"Where in the World is Elastic? - Big Data Paris & Javaland 2016","seo_title":"Where in the World is Elastic? - Big Data Paris & Javaland 2016","url":"\/blog\/witwies-big-data-paris-javaland-2016","author":{"name":"Megan Wieling"},"date":"March 07, 2016","category":"","locales":"","content":" Welcome to Find out which Elastic events and meetups are happening near you this week.\u00a0 Upcoming EventsMarch 7-8: March 8-10: Upcoming Meetups March 8: March 8: March 8: March 10: March 11: March 10: March 10: That's it for this week. Stay tuned next week for more Elastic happenings. - The Elastic Team P.S.\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}
{"index": {"_id": 717}}
{"title":"Logstash Lines: Environment variables in Config","seo_title":"","url":"\/blog\/logstash-lines-2016-03-07","author":{"name":"Suyog Rao"},"date":"March 07, 2016","category":"The Logstash Lines","locales":"","content":" Welcome back to The Logstash Lines! In these weekly posts, we'll share the latest happenings in the world of Logstash and its ecosystem.Fallout from 2.2 changes In 2.2, we changed the pipeline to combine filters and output stages into one worker unit\/thread. Some users upgrading to 2.2 complained about drop in throughput, mostly because of misconfiguration in pipeline workers setting. In 2.2, it is safe to bump the pipeline workers to say 2x * number of cores because there will be IO idle time resulting from filters and workers on the same execution unit. Although it seems that pipeline needs more threads, its also doing the additional output work. To help users upgrade, we released a \u00a0details this info. Another side effect of this change was that certain outputs like ES now use more resources like file handles, sockets etc because the outputs were never optimized for running in so many threads. This week we worked on making ES output (and underlying elasticsearch-ruby client) to be thread-aware and to share resources like connections () Expanding Environment\u00a0Variables inside LS Config has been a popular enhancement request by users, but since there's a workaround using config management tools and\/or things like sed, awk we had been pushing it down the road. Recently, we decided to bite this bullet, and have\u00a0been working with to implement this enhancement. It just got merged to master and 2.x. So now you can do: input { tcp { port => \"${LS_TCP_PORT:9999}\" } } output {# file { path => \"${HOME}\/file.log\" } } Pretty sweet and convenient. The syntax is This behavior is also consistent with Beats product. Many thanks to Fabien for contributing this enhancement! Beats input certificate verification Beats input and its predecessor Lumberjack input had never actually verified client certificates against the CA (on the server side). We are fixing , and also adding end to end Filebeat and Logstash\u00a0integration tests with SSL. Dynamic Config Reload This feature has been backported to 2.3. With this, you don't have to restart Logstash when any configuration changes have been made. Stay tuned for the release of version 2.3.0 soon. Other fixes: \n"}
{"index": {"_id": 718}}
{"title":"The evolving story about the Logstash File Input","seo_title":"","url":"\/blog\/the-evolving-story-about-the-logstash-file-input","author":{"name":"Guy Boertje"},"date":"March 02, 2016","category":"Engineering","locales":"","content":" In this post, we explore the popular file input, and its many use cases. We offer a peek into the evolution of this input and contrast it with alternatives like Filebeat. Some History (before version 2.2.0) The file input is a popular way in Logstash to ingest contents of a file. From the onset, it was designed to solve the tailing file use case where the file is being constantly updated. Many users have also tried to use it for uploading static file content into Logstash, and we'll explore this dichotomy in this post. File input saves information of how far along in the file Logstash has processed so Logstash can resume when it is restarted. For this, it uses sincedb, a file-based persistent store that records the number of bytes read against the file inode (*nix) or identifier (windows). Most of the real work behind the file input is done by the filewatch library, which is responsible for watching path globs and tailing files. Filewatch has two phases of operation, discovery and processing. During the first discovery, the watch pattern glob detects files, and each file is put into an internal store. In later discovery phases, only newer files will be put in the store. In the first processing phase, reading: for each stored file, we open, seek to the last byte read position, and read it in 32K chunks. We extract each line from the chunk, send it to the file input, and record the line byte count to the sincedb. Note: The file stays open, and we compare its inode with what we have from the sincedb to decide whether we have seen the file before. In the subsequent processing phase, tailing: if the file has grown, it is read in chunks as above. Some problems with this are: The concept of identity mapping was introduced to the file and other inputs, to ensure that data from the same origin went to the same codec instance, so each time a new identity is seen (path or socket connection), we add a mapping to a clone of the codec specified. To avoid boundless growth of the map, we set the limit to 20,000 identities, because we did not imagine that there would be setups that have more than 20,000 active connections or files being actively . Internally there is a mechanism to evict identities that have not been used for a while (1 hour). Eviction is non-destructive. However in the true setup, all the files may be \"hot\" and their identity (path) may be \"hot\" too \u2014 meaning that the identity may never be evicted. However, if the number of discovered files is greater than 20,000 \u2014 they are all opened \u2014 then the hard limit will be reached before the eviction mechanism can do anything. If the number of open file handles hits the limit, then Logstash starts failing to read\/write other files e.g., sincedb, templates, and sockets. In version 2.1.0 we implemented: In this version the behaviour bypasses reading and tailing if a file was last modified more than the setting seconds ago. The behaviour is to close a file if it was last modified more than the setting seconds ago. We found two problems with this release: for , files were opened then closed (because the open function did the sincedb update) but this consumed file handles unnecessarily and, for , we should have used a time to decide if a file can be closed. File Input version 2.2.0 We introduced a tracking object to hold state on each file we discover and process. In discovery for each file path, a tracking object is stored. This object holds the current state and the previous state history as well as many other attributes e.g., path, inode, , stat info, and some timestamps. Files satisfying the setting are put into the 'ignored' state during discovery and all others are put in the 'watched' state. Files in the ignored state are not opened but are monitored for changes. We changed the behaviour to use time to decide if a file can be closed. Files in the closed state are monitored for changes. We have added a config option (default 4095). This is implemented as a 'sliding window' of files in the active state across the list of files in the watched state. CCCCC|AAAAA|WWWWWWWWWW CCCCCCCCC|AAAAA|WWWWWW C = Closed, A = Active, W = watched (waiting) During the processing phase we now have the following steps: Multiple File Inputs While it is true that multiple inputs will read files in parallel, inputs fight each other for access to the shared queue which is only drained as fast as the filters + outputs will go. However multiple file inputs are a good idea, if\u00a0the files\u00a0can be\u00a0separated\u00a0into different directories\u00a0to overcome the 20K identity limit and to have data from the same time period processed together. Option Tuning Tailing Use Case Read File Use Case (files are content complete) Sometimes people want to process many, many thousands of files with sizes that vary from hundreds of bytes to gigabytes in size. The file input as it stands now can do this with a combination of and settings. Filebeat is a lightweight, open source shipper for log file data. As the next-generation Logstash Forwarder, Filebeat tails logs and quickly sends this information to Logstash for further parsing and enrichment or to Elasticsearch for centralized storage and analysis. Filebeat is really the way forward for the tailing use case.\u00a0 It is constantly evolving to support filtering, multiline, and more. You can find out more about Filebeat . In many cases it is preferable to install the lightweight Beats components on the machines that generate the logs. Future What needs fixing in the file input? The sincedb needs to store more information so better decisions can be made about whether a discovered file has been seen before. At the moment, filewatch communicates to the file input via method calls that certain actions, e.g., open, line(data), and close have taken place. The filewatch communicates the path (identity) only once when the file is opened \u2014 meaning the file input must hold state, the path, while the file is read. It would be better if the filewatch passed a context object when making calls to the file input. The context object can hold the path, file size, read position, and any other info that establishes the provenance of the line of data. Filewatch needs to have separate functionality optimised to the use case. Work in this area has begun for a new input plugin code named ''. Features that filewatch will have (features common to the existing file input and the new input): Features that the Logstash input plugin will have: While we develop these features, we would love to hear about the read file use case to make sure that we are building the right thing. Please open an in GitHub with a short description of your setup and expectations. You could also find us on our or us. \n"}
{"index": {"_id": 719}}
{"title":"Process transparency and error categorization at 1&1 by using the Elastic Stack and ETL","seo_title":"Process transparency and error categorization at 1&1 by using the Elastic stack and ETL","url":"\/blog\/process-transparency-and-error-categorization-at-1-1-by-using-the-elastic-stack-and-etl","author":{"name":"Benjamin Speckmann"},"date":"March 02, 2016","category":"User Stories","locales":"de-de","content":" What operating drivesSo what do we operate? We are working on 10 BPMN processes with approx. 50,000 process instances a week. The logs generated by these processes are about 50GB a day. The log files contain technical information as well as business information. The Elastic Stack gives us the ability to analyze these logs in real-time and provides transparency on customer orders. As an operations team we are driven by errors and incidents that attack customer orders. Our primary goal is customer satisfaction which we are trying to maintain by observing process SLAs like \u201cin time provisioning\u201d of customer orders. For being meaningful about the health of our processes we needed an overview as well as a categorization of errors in our processes. The questions we needed to answer were: Extending the Elastic StackNot all of the information can be taken from our process logs. To completely answer our questions we needed to enrich our application logs with information from other sources like issue tracker, databases, etc. The data sources in detail are:\u00a0 For conditioning this information we use the ETL tool Pentaho Kettle. Dashboard as a toolOur Kibana dashboard helps us working with our processes every day. (1) Number of errors by process (pie and table) (2) Number of errors by issue tool ticket (pie and table) (3) Number of errors by description text (pie and table)\u00a0(4) Full list of errors In order to make operations more efficient, the dashboard integrates other tools for example linking to related bugs in our issue tracker. In detail the dashboard provides: (1) Link to issue tracker (2) Link to central support tool showing detailed contract and customer information (3) Link to Kibana dashboard showing all log information concerning that order (for drilldown)(4) Link to information tool showing detailed order and customer information OutcomeWe are now using the Elastic\u00a0Stack for 2 months. The outcome is significant. More focus on what is better now e.g. increased error detection and addressing rate by 30 to 90 percent.\u00a0 In the future\u2026\u2026we will concentrate on using the Elastic Stack for real-time monitoring purposes. For example a visualization of order content will help us to cluster our orders for estimation of campaigns (e.g. new product release). Therefore we need to deal with Apache SPARK for data processing and computations.\u00a0Spark will calculate different KPIs (Key Performance Indicators) for us e.g. the duration of different process periods. is Business Process Manager at 1&1 Internet SE. Previously he was working as a consultant at NTT DATA Deutschland GmbH. Since the beginning of his career Benjamin deals with executable BPMN processes (Business Process Model and Notation). Monitoring, Data-Analysis and Reporting of KPI\u2019s was always a part of his work. He holds a M.S. in Computer Science from Eastern Michigan University as well as the University of Applied Sciences in Karlsruhe.\u00a0 is Advanced System Analyst at 1&1 Internet SE. Previously Christian was working as a\u00a0Requirements Engineer delivering business concepts for offshore developed business process monitoring solutions. He is experienced in JBoss EAP and BPM dominated infrastructure. In 2015 Christian implemented the Elastic Stack for efficient monitoring and analysis of technical and business data in Order Management. \n"}
{"index": {"_id": 720}}
{"title":"Upgrade Guide for Logstash 2.2","seo_title":"","url":"\/blog\/upgrade-guide-for-logstash-2-2","author":{"name":"Andrew Cholakian"},"date":"March 01, 2016","category":"Engineering","locales":"de-de,fr-fr,ja-jp,ko-kr","content":" Hello Logstashers! In this post, we\u2019ll talk about considerations when upgrading to . Specifically how to avoid situations where some new behavior (and a bit of soon to be fixed misbehavior by the Elasticsearch output plugin), can cause a larger than desired number of file handles to be used. I will also discuss some of the new tuning considerations for 2.2.0. To help users with upgrading to 2.2.0, we\u2019ve also added a new documentation section . The good news is that Logstash 2.2 brings with it some very significant performance improvements! The down side is that one of the changes we made to the default settings in Logstash cause issues for some configurations. For example, we are hearing reports of Logstash taking up many more file handles than it previously would. Lets dive deeper into these changes. Worker Units There are two types of worker in Logstash 2.2, pipeline workers (formerly filter workers) and output workers. In previous versions of Logstash the filters and outputs ran in their own threads. In 2.2 we unified our threading model, putting both filter and output worker threads in one \u2018pipeline\u2019 worker thread type. This has given us some significant performance gains. The output worker concept remains, but rather than mapping directly to a thread it maps to a pool of available output objects. During execution these are grabbed by a pipeline worker for use and returned when done. You will find that you need to set higher than before, and in fact Logstash may require more total threads than before. However, this is by design! You will find that you have more threads doing less work. Sure, a fair number of them may be idle in IO wait, however the work they do is now much more efficient, and with less context switching. To tune the setting just keep increasing it, even to a multiple of the number of cores on your system (remember, those threads are often idle) until you see throughput go down. By default, is set to match the number of cores in your system. Batching Events There is also a new batch size setting which you can tune in a similar way. Please that explains these options in more detail. This batch size is now also the default flush size for the Elasticsearch output. The option on that now only changes the maximum flush size and will no longer set the minimum flush size. New Pipeline and Outputs In our performance testing we found that increasing the number of output workers to stay in lock step with pipeline workers yielded some nice performance gains. However, for our Elasticsearch output there\u2019s an undesired behavior that stayed hidden until now. If you use multiple Elasticsearch output workers they won\u2019t share the same backend connection pool! That means if you have 5 backend ES instances and 5 workers you may have up to 5*5=25 connections! If you have 40 ES nodes the effect is amplified! We understand the current situation isn\u2019t ideal in some cases. The fix isn\u2019t to change the Logstash core behavior, but to make the Elasticsearch output handle connections responsibly in the new pipeline model. We are targeting a new release in the 2.2 series that addresses this. We\u2019re currently working on a for this that will only require a plugin upgrade, but until that\u2019s released you\u2019ll want to stick with a relatively low number of ES output workers. The workaround in 2.2 is to just set your count low explicitly, try only 1 or 2 workers. Feedback I hope we\u2019ve clarified some aspects about our new pipeline architecture and upgrading to 2.2. Please let us know if you have any feedback! You can always reach us on Twitter (@elastic), on our , or report any problems on the GitHub page. \n"}
{"index": {"_id": 721}}
{"title":"This Week in Elasticsearch and Apache Lucene - Core Changes","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-core-changes","author":{"name":"Michael McCandless"},"date":"February 29, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsWhat would life be like without ? attendees answer: \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole Elastic\u00a0ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 722}}
{"title":"TAP(ping) Out Security Threats at FireEye: An Elastic{ON} Reflection","seo_title":"Elastic{ON}16: Tapping Out Security Threats at FireEye","url":"\/blog\/reflections-from-elasticon-tapping-out-security-threats-at-fireeye","author":{"name":"Chris Rimondi"},"date":"February 29, 2016","category":"User Stories","locales":"","content":" FireEye is a security company that provides real-time threat protection to enterprises and governments against cyber-attacks. Its real-time threat protection platform operates without the use of signatures to protect an organization across the primary threat vectors and across the various stages of an attack life cycle.Elasticsearch has been a critical part of the Threat Analytics Platform (TAP) at FireEye for the past two years. Our engineering and operations teams had the opportunity of watching the maturity of Elasticsearch through multiple versions. The conferences have become mile markers in the product\u2019s progress. FireEye sent attendees to the conference in 2015 and was privileged to have a speaking spot in 2016.One of the most valuable aspects of the conference is that Elastic sent its entire company \u2014 including engineers, product managers, and executives \u2014 to the conference this year. They laid out the vision of aligning their products and how these improvements will impact features and versioning. As an organization that is looking to leverage different Elastic products within its development roadmap, it was valuable to get the insight directly from the source. Various product management from Elastic were there including . I shared some of FireEye\u2019s objectives and queried Tanya about Elastic\u2019s roadmap related to analytic capabilities.. As a speaker, the best part of presenting was getting to talk to attendees afterwards about their use cases and compare war stories. I easily learned as much (and probably more) from chatting afterward with attendees as I did from other sessions. It was a healthy exchange of what worked and what didn\u2019t when deploying Elasticsearch.I hope you enjoy hearing how FireEye built a security analytics\u00a0platform that indexes hundreds of thousands of events per second and allows its enterprise customers to find evil in their organizations across petabytes of data. \u00a0Chris Rimondi runs the Site Reliability Engineering team for the Cloud business unit at FireEye. He started at Mandiant, three years ago, prior to its acquisition by FireEye. Since then he is focused on building and supporting the next generation of FireEye applications in its public and private cloud infrastructure.\u00a0 \n"}
{"index": {"_id": 723}}
{"title":"Elastic @ RSA Conference 2016","seo_title":"","url":"\/blog\/elastic-at-rsa-conference-2016","author":{"name":"Asawari Samant"},"date":"February 29, 2016","category":"News","locales":"","content":" On the heels of our annual user conference, , this week we are at RSA Conference showcasing how the touches a variety of security use cases.Like parsing through massive rows and columns of data (which we love), if you are on the show floor, we\u2019d love to have you stop by to see our collection of demos ranging from finding events of interest in honeypot data, ingesting and spotting trends in variety of security logs, and using the power of graph analysis to track interesting connections and relations. Oh but one thing, this year, we didn\u2019t sign up for a booth on-time, but thanks to our partner, , we\u2019ve joined them at their Booth #444 in South Moscone. So if you\u2019d like to meet Elastic experts and talk about how our products Elasticsearch, Logstash, Beats, Kibana and our plugins for security, alerting, and monitoring can help you, please come visit us.Additional Elastic Security Resources: \n"}
{"index": {"_id": 724}}
{"title":"Loading Wikipedia's Search Index For Testing","seo_title":"Loading Wikipedia's Search Index For Testing","url":"\/blog\/loading-wikipedia","author":{"name":"Nik Everett"},"date":"February 20, 2016","category":"Engineering","locales":"","content":" A month ago I published\u00a0a post testing query speeds with data from English Wikipedia and mentioned that the loading process deserved its own blog post. Well here it is!Step 0: WhyThis gets you a copy of the search index used to power on site search for Wikipedia. The index is quite large because it's used to support all the funky things that Elasticsearch is used for there. It may have mistakes, old data, strange leftovers from previous versions of the indexing code that have yet to be cleaned up. In short: it's imperfect, just like any real production deploy.Step 1: Download a smaller wikiThe Wikimedia Foundation makes everything about Wikipedia and the other wikis it powers\u00a0public. Well, everything that is safe to make public anyway. That includes a dump of the search index. Head and you'll get a list of dates when the dump runs began. Click on the latest date and download the file that looks like . The naming scheme is where: By now you've figured out that I didn't have you download English Wikipedia's search index. I had you fetch English Wikiquote. You can follow my instructions below to load English Wikiquote and then\u00a0start over to load any other wiki you'd like from the dumps page. If\u00a0one particular wiki caught your eye, go and start downloading it now while you follow along to the end of the blog post using English Wikiquote. If all goes well it'll be ready by the time you want it.Step 2: Get the index readyWhile the dump downloads you can setup Elasticsearch to handle it the index. You'll need the plugin. You can do that by this into your bash shell:You'll have to restart Elasticsearch after installing that for it to take.Then you'll need for some of the json-foo you'll do next. For me it's just but your command may vary.Finally you can create you index with these bash shell commands:export es=localhost:9200 export site=en.wikiquote.org export index=enwikiquote curl -XDELETE $es\/$index?pretty curl -s 'https:\/\/'$site'\/w\/api.php?action=cirrus-settings-dump&format=json&formatversion=2' | jq '{ analysis: .content.page.index.analysis, number_of_shards: 1, number_of_replicas: 0 }' | curl -XPUT $es\/$index?pretty -d @- curl -s 'https:\/\/'$site'\/w\/api.php?action=cirrus-mapping-dump&format=json&formatversion=2' | jq .content | sed 's\/\"index_analyzer\"\/\"analyzer\"\/' | sed 's\/\"position_offset_gap\"\/\"position_increment_gap\"\/' | curl -XPUT $es\/$index\/_mapping\/page?pretty -d @- Let me walk you through that: Clear as mud? Ok.Step 3: Prepare the wiki for loadingCrack open the file with zless and have a look at it. Don't worry, you can do that before it finishes downloading. Its contents are conveniently in the format that Elasticsearch uses for bulk loading. Hurray! We'll unzip and cut this file into smaller chunks so it'll work properly with curl and the API. It'll also you a way to pause and resume the process. After it has finished downloading you can do that with these bash shell commands:export dump=enwikiquote-20160201-cirrussearch-content.json.gz export index=enwikiquote mkdir chunks cd chunks zcat ..\/$dump | split -a 10 -l 500 - $index For English Wikiquote that should finish in a few seconds. English Wikipedia takes longer than a coffee break.Step 4: Load the wikiThe last step is to load the actual data with these bash commands:export es=localhost:9200 export index=enwikiquote cd chunks for file in *: do echo -n \"${file}: \" took=$(curl -s -XPOST $es\/$index\/_bulk?pretty --data-binary @$file | grep took | cut -d':' -f 2 | cut -d',' -f 1) printf '%7s\\n' $took [ \"x$took\" = \"x\" ] || rm $file done The first three lines should be familiar from above. The loop loads each file and deletes it after it's loaded. If the file fails to load it isn't deleted and the loop moves on to the next file.I find setting the to will speed this process up some. You can apply it by running this in a different terminal:curl -XPUT \"$es\/$index\/_settings?pretty\" -d '{ \"index\" : { \"refresh_interval\" : -1 } }' You can monitor the progress with:date: curl $es\/$index\/_refresh?pretty: curl $es\/$index\/_count?pretty The makes the current process visible regardless of the . The just counts how many documents you've loaded.Loading English Wikiquote is an excellent opportunity to have a coffee break. Loading English Wikipedia takes all night. When it is all done you should flush the index with to make sure that the next time you restart Elasticsearch it doesn't have a large translog to replay.Step 5: Now do it with a bigger wikiNow that you've loaded a smaller wiki you can just repeate the process with other statements to load a larger wiki. While loading English Wikiquote took something like 20 minutes total you'll find loading English Wikipedia to be an overnight job.Regarding space: I find that gzip gives English Wikipedia about a 1:6 compession ratio and when the Elasticsearch index is comlete it's only slightly bigger. Since the load process removes that files after they are loaded into Elasticsearch it should be safe if you budget 10 time the file size for this process. When I last loaded English Wikipedia the Elasticsearch index ended up being 7 times the size of the gzip and I kept the gzip on disk in case I wanted to load it again. Its small enough not to be a big deal on a spinning disk but large enough to be a pain on an SSD.Step 6: Now what?After you've loaded the index you can do whatever you want with it: presumably you'll want to test some queries or something. You can do that now. You'll notice a huge performance boost if you but that is cheating to some degree because it causes trouble if you ever modify the index. For testing maybe it's fine but it doesn't simulate a system that is constantly being updated. \n"}
{"index": {"_id": 725}}
{"title":"Video: Life Without Elasticsearch?","seo_title":"Video: Life Without Elasticsearch?","url":"\/blog\/life-without-elasticsearch-elasticon16","author":{"name":"Scott Fingerhut"},"date":"February 19, 2016","category":"Culture","locales":"","content":" \"My life would cease to exist as I know it today if I did not have Elasticsearch.\" \"I would cry, there'd be tears.\" \"Without Elasticsearch, life would be a lot slower.\" Amidst the science experiments, colored lights, and pulsing dance music of San Francisco's Exploratorium at the kickoff party, many folks were faced with the apocalyptic question: \"What would your life be like without Elasticsearch?\" See what many more had to say (and laugh about), in this short video from the Elasticsearch user conference. \n"}
{"index": {"_id": 726}}
{"title":"Elasticsearch and SIEM: implementing host portscan detection","seo_title":"","url":"\/blog\/elasticsearch-and-siem-implementing-host-portscan-detection","author":{"name":"Antonio Bonuccelli"},"date":"February 18, 2016","category":"Engineering","locales":"","content":" Intro: using a SIEM approach Effectively monitoring security across a large organization is a non-trivial task faced everyday by all sorts of organizations.The speed, scalability and flexibility of the Elastic stack can play as a great asset when trying to get visibility and proactively monitoring large amounts of data. The traditional SIEM approach relies on normalization of the data from raw, based on a schema. For example a failed login, be it from a Linux Nov 26 12:15:04 zeus sshd[19571]: Failed password for ciro from 10.0.4.23 port 57961 ssh2 or a Windows host, Log Name: Security Source: Microsoft-Windows-Security-Auditing Date: 27\/11\/2015 2:07:33 PM Event ID: 4625 Task Category: Logon Level: Information Keywords: Audit Failure User: N\/A Computer: minerva Description: An account failed to log on. Subject: Security ID: NULL SID Account Name: - Account Domain: - Logon ID: 0x0 Logon Type: 3 Account For Which Logon Failed: Account Name: gennaro <.....> will be indexed observing a common structured format: Using a field naming convention allows to build correlation logic abstracting from which source the event originated from, be it a Windows or a Linux failed login. Also some tagging or categorization of the data can be performed, grok{ match => { \"message\" => [\"%{SSH_AUTH_1}\",\"%{SSH_AUTH_2}\"] } add_tag => [ \"auth_success\" ] } grok{ match => { \"message\" => [\"%{SSH_AUTH_3}\",\"%{SSH_AUTH_4}\"] } add_tag => [ \"auth_failure\" ] } where SSH_AUTH_X are our custom defined grok patterns to match success\/failure events. Using this approach, correlation logic can be applied to all the events, regardless of the datasource from which the event originated from. Following the same approach, we will show how to use the Elastic stack to cover a basic network security use case, TCP host portscan detection, for which we'll implement alerting via email. Implementation I: datasource When trying to detect whether a portscan against a given host on your premises was carried on , network traffic data becomes relevant. For this use case we will want to monitor all events indicating a new TCP connection being initiated from source to target host, in short all TCP packets with SYN=1, ACK=0. While we impatiently wait for to be released and allow more out-of-the-box network protocol level capture capabilities, we'll use tcpdump capture using the below command for the purpose of this blog: sudo tcpdump -i eth0 -n -tttt tcp[13] == 2 | nc localhost 5001 the above command will listen on the eth0 network interface of the monitored host and capture all and only the TCP packets indicating that a new TCP connection handshake was initiated, also avoiding resolving IP to hostnames for faster execution: then we pipe the results to netcat to send them to our Logstash instance for event processing, which we assume here to be running locally. For convenience, we can launch the above command using a all time favourite linux CLI utility, . !\/bin\/bash screen -d -m \/bin\/bash -c 'sudo tcpdump -i eth0 -n -tttt tcp[13] == 2 | nc localhost 5001' This is what the captured raw data looks like 2016-02-09 13:51:09.625253 IP 192.168.1.105.60805 > 192.168.1.1.80: Flags [S], seq 2127832187, win 29200, options [mss 1460,sackOK,TS val 259965981 ecr 0,nop,wscale 7], length 0 Implementation II : event processing We'll use logstash to mangle the data and extract the information relevant to this use case, namely timestamp, src_ip and dst_port. grok{ match => {\"message\" => \"%{TCPD_TIMESTAMP:timestamp} IP %{IP:src_ip}\\.%{INT:src_port} > %{IP:dst_ip}\\.%{INT:dst_port}(?[^$]+)\"} add_tag => [\"network\",\"tcp_connection_started\"] } where TCPD_TIMESTAMP is a custom defined grok pattern to match . As we have extracted the information we were after (,,) we can decide to trash and fields: mutate{ remove_field => [\"message\",\"payload\"] } Next we send these events to Elasticsearch index elasticsearch { hosts => \"es-server:9200\" index => \"logstash-tcpdump-%{+YYYY.MM.dd}\" user => \"logstash\" password => \"verysecretpassword\" ssl => true cacert => \"\/path\/to\/cacert.pem\" } Implementation III: searching for a portscan We're now at the stage where events are coming into Elasticsearch and we want to be automatically alerted when our monitored host will receive (or launch!) a portscan. This is what our indexed event looks like: { \"@version\": \"1\", \"@timestamp\": \"2016-02-08T00:56:58.407Z\", \"host\": \"127.0.0.1\", \"port\": 41433, \"type\": \"tcpdump\", \"timestamp\": \"2016-02-08 01:56:58.407625\", \"src_ip\": \"192.168.1.105\", \"src_port\": \"55203\", \"dst_ip\": \"192.168.1.1\", \"dst_port\": \"80\" } We can define a TCP host portscan as a large amount of connections attempted within a short amount of time between a source and a target host, where the target port is always changing from connection to connection. How would this translate to an elasticsearch query? GET logstash-tcpdump-*\/_search { \"size\": 0, \"query\": { \"bool\": { \"must\": [ { \"match\": { \"tags\": \"tcp_connection_started\" } }, { \"range\": { \"@timestamp\": { \"gte\": \"now-30s\" } } } ] } }, \"aggs\": { \"by_src_ip\": { \"terms\": { \"field\": \"src_ip\" }, \"aggs\": { \"by_target_ip\": { \"terms\": { \"field\": \"dst_ip\", \"order\": { \"unique_port_count\": \"desc\" } }, \"aggs\": { \"unique_port_count\": { \"cardinality\": { \"field\": \"dst_port\" } } } } } } } } We leverage here a killer feature of Elasticsearch: aggregations. Specifically \u00a0and \u00a0aggregations. Note we're purely interested in aggregated results, hence setting . The response we receive looks like: { \"took\": 9, \"timed_out\": false, \"_shards\": { \"total\": 24, \"successful\": 24, \"failed\": 0 }, \"hits\": { \"total\": 46, \"max_score\": 0, \"hits\": [] }, \"aggregations\": { \"by_src_ip\": { \"doc_count_error_upper_bound\": 0, \"sum_other_doc_count\": 0, \"buckets\": [ { \"key\": \"192.168.1.17\", \"doc_count\": 44, \"by_target_ip\": { \"doc_count_error_upper_bound\": 0, \"sum_other_doc_count\": 0, \"buckets\": [ { \"key\": \"192.168.1.105\", \"doc_count\": 44, \"unique_port_count\": { \"value\": 41 } } ] } }, { \"key\": \"192.168.1.105\", \"doc_count\": 2, \"by_target_ip\": { \"doc_count_error_upper_bound\": 0, \"sum_other_doc_count\": 0, \"buckets\": [ { \"key\": \"192.168.1.10\", \"doc_count\": 1, \"unique_port_count\": { \"value\": 1 } }, { \"key\": \"192.168.1.32\", \"doc_count\": 1, \"unique_port_count\": { \"value\": 1 } } ] } } ] } } } From the above we can infer that host 192.168.1.17 has initiated 41 different TCP connections against host 192.168.1.105 which seems suspicious: 192.168.1.17 is our attacker. Also host 192.168.1.105 has initiated 2 TCP connections against hosts 192.168.1.10 and 192.168.1.32, which seems legitimate. Next we'll see how we can use Watcher to automatically receive an email when an event like this happens. Implementation IV: alert me! \u00a0is our friend here, all we need to do is to \u00a0a service email account, then define a new Watch and define how to act when a portscan is detected. First we define a schedule, how often should the Watch be executed: \"trigger\": { \"schedule\": { \"interval\": \"10s\" } } Next, define what query search_type to run, on what indices and document types: \"input\": { \"search\": { \"request\": { \"search_type\": \"query_then_fetch\", \"indices\": [ \"logstash-tcpdump-*\" ], \"types\": [ \"tcpdump\" ], \"body\": { # } Now specify what condition would trigger the watch: \"condition\": { \"script\": { \"inline\": \"for (int i = 0: i < ctx.payload.aggregations.by_src_ip.buckets.size(): i++) {for (int j = 0: j < ctx.payload.aggregations.by_src_ip.buckets[i].by_target_ip.buckets.size(): j++) {if (ctx.payload.aggregations.by_src_ip.buckets[i].by_target_ip.buckets[j].unique_port_count.value > threshold) return true: }: }: return false: \", \"params\": { \"threshold\": 50 } } } The above groovy script will scan our aggregated results and look for a bucket where the is greater than 50: so putting within context, if a host has established within 30 seconds timerange, more than 50 connection each using a different port against another host, we will call this a portscan. Last, what action should our Watch perform once its conditions are met? Send a nice email to warn us! \"actions\": { \"email_administrator\": { \"transform\": { \"script\": { \"inline\": \"def target='': def attacker='': def body='': for (int i = 0: i < ctx.payload.aggregations.by_src_ip.buckets.size(): i++) {for (int j = 0: j < ctx.payload.aggregations.by_src_ip.buckets[i].by_target_ip.buckets.size(): j++) {if (ctx.payload.aggregations.by_src_ip.buckets[i].by_target_ip.buckets[j].unique_port_count.value > threshold) {target=ctx.payload.aggregations.by_src_ip.buckets[i].by_target_ip.buckets[j].key: attacker=ctx.payload.aggregations.by_src_ip.buckets[i].key: body='Detected portscan from ['+attacker+'] to ['+target+']. '+ctx.payload.aggregations.by_src_ip.buckets[i].by_target_ip.buckets[j].unique_port_count.value+ ' unique ports scanned.': return [ body : body ]: }: }: }: \", \"params\": { \"threshold\": 50 } } }, \"email\": { \"profile\": \"standard\", \"attach_data\": true, \"priority\": \"high\", \"to\": [ \"info@elastic.co\" ], \"subject\": \"[Security Alert] - Port scan detected\", \"body\": \"{{ctx.payload.body}}\" } } } What we do here is scanning again through the results to pick the attacker and target hosts, plus the count of how many unique ports were scanned. The resulting watch then becomes: PUT _watcher\/watch\/port_scan_watch { \"trigger\": { \"schedule\": { \"interval\": \"10s\" } }, \"input\": { \"search\": { \"request\": { \"search_type\": \"query_then_fetch\", \"indices\": [ \"logstash-tcpdump-*\" ], \"types\": [ \"tcpdump\" ], \"body\": { \"size\": 0, \"query\": { \"bool\": { \"must\": [ { \"match\": { \"tags\": \"tcp_connection_started\" } }, { \"range\": { \"@timestamp\": { \"gte\": \"now-30s\" } } } ] } }, \"aggs\": { \"by_src_ip\": { \"terms\": { \"field\": \"src_ip\" }, \"aggs\": { \"by_target_ip\": { \"terms\": { \"field\": \"dst_ip\", \"order\": { \"unique_port_count\": \"desc\" } }, \"aggs\": { \"unique_port_count\": { \"cardinality\": { \"field\": \"dst_port\" } } } } } } } } } } }, \"condition\": { \"script\": { \"inline\": \"for (int i = 0: i < ctx.payload.aggregations.by_src_ip.buckets.size(): i++) {for (int j = 0: j < ctx.payload.aggregations.by_src_ip.buckets[i].by_target_ip.buckets.size(): j++) {if (ctx.payload.aggregations.by_src_ip.buckets[i].by_target_ip.buckets[j].unique_port_count.value > threshold) return true: }: }: return false: \", \"params\": { \"threshold\": 50 } } }, \"throttle_period\": \"30s\", \"actions\": { \"email_administrator\": { \"transform\": { \"script\": { \"inline\": \"def target='': def attacker='': def body='': for (int i = 0: i < ctx.payload.aggregations.by_src_ip.buckets.size(): i++) {for (int j = 0: j < ctx.payload.aggregations.by_src_ip.buckets[i].by_target_ip.buckets.size(): j++) {if (ctx.payload.aggregations.by_src_ip.buckets[i].by_target_ip.buckets[j].unique_port_count.value > threshold) {target=ctx.payload.aggregations.by_src_ip.buckets[i].by_target_ip.buckets[j].key: attacker=ctx.payload.aggregations.by_src_ip.buckets[i].key: body='Detected portscan from ['+attacker+'] to ['+target+']. '+ctx.payload.aggregations.by_src_ip.buckets[i].by_target_ip.buckets[j].unique_port_count.value+ ' unique ports scanned.': return [ body : body ]: }: }: }: \", \"params\": { \"threshold\": 50 } } }, \"email\": { \"profile\": \"standard\", \"attach_data\": true, \"priority\": \"high\", \"to\": [ \"antonio@elastic.co\" ], \"subject\": \"[Security Alert] - Port scan detected\", \"body\": \"{{ctx.payload.body}}\" } } } } Testing our setup: you got mail! Now on to seeing some action, let's login to a host that has connectivity towards our monitored host (in this example 192.168.1.105) and launch a port scan against it: Elastic-MacBook-Air:~ user$ nmap 192.168.1.105 -p1-500 Starting Nmap 6.47 ( http:\/\/nmap.org ) at 2016-02-09 15:38 CET Nmap scan report for w530 (192.168.1.105) Host is up (0.0078s latency). Not shown: 495 closed ports PORT STATE SERVICE 22\/tcp open ssh 80\/tcp open http 139\/tcp open netbios-ssn 389\/tcp open ldap 445\/tcp open microsoft-ds Explicitly looking to probe privileged ports from 1 to 500. A few seconds later, we receive an email: Et voila! The alert was triggered and intended watch action was performed. Note that we could have multiple detections from different hosts, however for the purpose of this blog post we limit ourselves to detecting and reporting only the first one in the list. As a side node, if you like NMap, take a look at this to see all the awesome things you can do using . This is just an example of how to leverage the Elastic stack for performing security monitoring, creativity is the only limit. Happy alerting! \n"}
{"index": {"_id": 727}}
{"title":"Logstash 2.2.2 released","seo_title":"Logstash 2.2.2 released with important security bug fix","url":"\/blog\/logstash-2-2-2-released","author":{"name":"Suyog Rao"},"date":"February 18, 2016","category":"Releases","locales":"","content":" A short post to announce that Logstash version 2.2.2 has been released today with an important security bug fix! Jump to the page for the binaries, where you can also find the full list of . Elasticsearch Output SSL Configuration Issue Logstash version 2.2.1 is vulnerable to a man in the middle attack when used with Elasticsearch output. In version 2.2.1, the config which enables SSL\/TLS default has been disabled inadvertently, so a malicious user could access payload data sent via HTTP during the initial handshake. This has been fixed in 2.2.2. User who do not wish to upgrade immediately to 2.2.2 can use prefix in their configuration. For example, replace value of to . Please restart Logstash after you make this change. \n"}
{"index": {"_id": 728}}
{"title":"Introducing Elastic Cloud and Elastic Cloud Enterprise","seo_title":"Introducing Elastic Cloud and Elastic Cloud Enterprise","url":"\/blog\/introducing-elastic-cloud-and-elastic-cloud-enterprise","author":{"name":"Shay Banon"},"date":"February 17, 2016","category":"News","locales":"ja-jp,ko-kr","content":" We \u201cFound\u201d A New Name! string theStory = \u201cStart at the Beginning\u201d At last year\u2019s Elastic{ON}15, we announced the acquisition of Found, the company. Our goal, at the time, was to provide the simplest, most complete Elasticsearch as a service offering that was available in market. Of course, the team behind Found was a key element in the decision making process. We are proud that, as a company, we have made major strides in achieving our stated objective. Today, more than 1,000 companies are running a portion of their business on the hosted offering that we provide. So what, you may ask, have we been doing behind the scenes over the last year? string theStory = \u201cNaming is Hard!\u201d If you\u2019ve been following the announcements from Elastic{ON}, you will have heard about the renaming of our commercial products \u2014 Shield (security), Marvel (monitoring), and Watcher (alerting) \u2014 as X-Pack, a single extension that bundles these meaty features and more. As we began to align the name of products with the functionality that they provide it was necessary to reconsider what we call our hosted offering as well. Elasticsearch as a Service. It seems fairly straightforward. But the reality is that Found provides much more than just Elasticsearch. Each cluster includes a free Kibana instance, integration with Shield (now called security). Premium users can leverage the monitoring and alerting capabilities of the X-Pack. And many of them ingest using Beats, Logstash, or a combination of both. So what do we call a thing that is the entire Elastic Stack hosted and maintained so that you don\u2019t have to? Welcome, Elastic Cloud. string theStory = \u201cA Rose by Any Other Name\u2026\u201d The Elastic Cloud is everything about Found that you\u2019ve come to know and love. Or, perhaps, don\u2019t know is available to make your life easier. You can setup a cluster and have it running in a matter of minutes (with a 14-day free trial) and it includes 16GB of storage for every 1GB of memory. Additionally, it includes updates to the latest release of the Elastic Stack and is tightly integrated with the X-Pack features like security, alerting, monitoring, and even Re{Search} features like Timelion. But, most importantly, the team that has built \u2014 and maintains \u2014 Elastic Cloud is a part of Elastic. We release on the same schedule. We test together. We solve issues together. It is the Elastic that you know and trust\u2026only hosted. string theStory = \u201cBut Wait, There\u2019s More!\u201d The benefit of being a company driven, in large part, by listening to the community is that we are able to make decisions for a multitude of reasons. Several of our customer (those with whom we have a commercial relationship) have asked about \u201chow\u201d we run Elastic Cloud. Or, have asked about best practices for attempting to build their own Elastic Cloud. I\u2019m pleased to introduce Elastic Cloud Enterprise. It is the same product that is powering our hosted offering, available for installation on the hardware \u2013 or in the environment \u2013 that you choose. If you manage multiple deployments be that across multiple teams or geographies, you can leverage the same technology that we do to centralize and manage the provisioning, monitoring and management, scaling, replication, and upgrades of your Elasticsearch clusters. Elastic Cloud and Elastic Cloud Enterprise. One product that allow you to choose your own deployment adventure. And yes, we treat Elastic Cloud as a product. We don\u2019t simply offer a service. Rather, we build a product that can be consumed as a service or installed to manage multiple clusters or offer a service inside of your organization. Want to be part of it? Learn more, or sign-up for the private Beta of Elastic Cloud Enterprise. If you happen to be at Elastic{ON} join the session by Njal Karevoll and Erik Redding entitled \n"}
{"index": {"_id": 729}}
{"title":"Heya, Elastic Stack and X-Pack","seo_title":"","url":"\/blog\/heya-elastic-stack-and-x-pack","author":{"name":"Shay Banon"},"date":"February 17, 2016","category":"News","locales":"ja-jp,ko-kr","content":" string theStory = \"ELKB, BELK, what?\" string theStory = \"The Elastic Stack, more than a name, 5.0.0\"I'm excited to announce that, unveiled today at Elastic{ON}16, all of Elastic's open source products \u2014 , , , and \u2014 will be called the Elastic Stack. This is more than just a name: going forward, we will be building, testing, and releasing all components of the Elastic Stack together and they will all share the same version number \u2014 . Our goal is that this evolution will speed your deployments, simplify compatibility testing, and make it even easier for developers to add new functionality across the stack. , the first alpha release of 5.0.0 will be shipping soon. string theStory = \"Introducing Packs \u2014 Extensions for the Elastic Stack\"Each of the products in the Elastic Stack have always had great support for extensions. With Elasticsearch, plugins can add language analyzers, extend snapshot\/restore, and even create new APIs. The Logstash plugin ecosystem is a wonderful example of how powerful extensions can be, and Kibana introduced plugin infrastructure in recent releases, which we have used to create extensions like Timelion. However, as we use these extension points to build our own products, we realized that there is a tremendous benefit to thinking bigger: extending the whole stack. Today, we announced the introduction of Packs \u2014 extensions that apply to the whole stack. On the surface, this is a simple concept \u2014 a single zip that contains extensions for one or more of the products in the Elastic Stack. With aligned releases and versions across the stack, packs make it easy to build, test, and release extensions that span the stack. We saw this need ourselves, when building product like Marvel, which plug into Elasticsearch to capture telemetry and metrics, while also installing into Kibana to provide the UI for monitoring your infrastructure. We will be releasing our own pack (read on!), but we are most excited to see how you extend the Elastic Stack, and what new use-cases you uncover. string theStory = \"X-Pack: Shield, Watcher, Marvel and more in a single extension\"Today, we also announced our own pack, known as X-Pack \u2014 delivering security, alerting, monitoring to the entire Elastic Stack through a single extension. And with the release of X-Pack, we're super excited to announce new reporting capabilities for users to generate, schedule, and email Kibana dashboards as PDF reports, and a new graph API and UI, which allow you to explore, visualize, and analyze your existing data in new ways. With X-Pack, we hope that our users gain time to value by having features that seamlessly work with the Elastic Stack, as well as meet today's IT, security, and regulatory requirements. We hope you can give the and a whirl! \n"}
{"index": {"_id": 730}}
{"title":"Detecting DNS Tunnels with Packetbeat and Watcher","seo_title":"","url":"\/blog\/detecting_dns_tunnels_with_packetbeat_and_watcher","author":{"name":"Andrew Kroh"},"date":"February 16, 2016","category":"Engineering","locales":"","content":" This post was updated to reflect changes in Packetbeat 5.x and Elasticsearch 5.x. Full-bleed source: https:\/\/commons.wikimedia.org\/wiki\/File:IDF_Uncovers_Terror_Tunnels_in_Gaza_(14684360244).jpg Thumbnail source: https:\/\/flic.kr\/p\/3QVF7S
Detecting DNS Tunnels with Packetbeat and Watcher<\/h1> Data observed from monitoring DNS traffic on a network can be used as an indicator of compromise (IOC). This blog post will discuss how Elasticsearch and Watcher can be used with Packetbeat to alert when possible malware activity is detected. is our open source packet analyzer. It monitors the traffic on your network and indexes the DNS requests and responses into Elasticsearch where aggregations can be used to help make sense of the data. (formerly ) is part of and it provides alerting and notifications based on changes in your data. There are many use cases for alerting on data collected by Packetbeat such as alerting when the response times for web requests are above a threshold or when there is spike in HTTP errors returned by your web servers. The alerting described in this article has applications in network security. We are going to look at one specific use case -- detecting data exfiltration over DNS tunnels. Detecting DNS Tunnels Tunnels can be established over the DNS protocol to covertly move data or provide a command and control channel for malware. Often this technique is used to bypass the protections of corporate firewalls and proxy servers. Tunneling works by encoding data in DNS requests and responses. The client issues a query for a hostname and that query is eventually forwarded to the authoritative name server associated with the domain. There are a lot of different techniques that can be employed for detecting such traffic. We are going to look at using the number of unique hostnames for a domain as an IOC. DNS tunneling utilities must use a new hostname for each request which leads to a much higher number of hostnames present for the malicious domains in comparison to legitimate domains. Packetbeat Setup The first step is to install Packetbeat and configure it to collect DNS traffic. For this setup, the server running Packetbeat is connected to a port mirror so that Packetbeat can observe all the traffic between the local network and the Internet. The Packetbeat documentation has a great that explains installation and setup procedure, so I will just show the configuration used. # \/etc\/packetbeat\/packetbeat.yml packetbeat.interfaces.device: en0 packetbeat.protocols.dns: ports: [53] include_authorities: true include_additionals: true output.elasticsearch: hosts: [\"localhost:9200\"] Watch your DNS Traffic The complete is stored in our repository along with all of the supporting files shown here. We are going to walk through the creation of this watch step-by-step. Watch Trigger The watch trigger specifies when the execution should start. This watch is scheduled to execute every 15 minutes. \"trigger\": { \"schedule\": { \"interval\": \"15m\" } }, Watch Input This first step in creating this watch is to design a set of aggregations to be used as the input to the watch. We want to find the cardinality of the hostnames associated with each second-level domain (e.g. ). We start with a query that has just two components, a time window and a whitelist. The time window and whitelist can be customized. Find more on this in the section. Next we use a terms aggregation to create buckets for each second-level domain. Then we apply a sub-aggregation to get the cardinality of the hostnames within that bucket. Finally we apply a bucket selector aggregation to select only the buckets having more than 200 unique hostnames. The watch will generate an alert when the number of unique hostnames breaks this threshold. GET packetbeat-*\/dns\/_search { \"query\": { \"bool\": { \"filter\": { \"range\": { \"@timestamp\": { \"from\": \"now-4h\" } } }, \"must_not\": { \"terms\": { \"dns.question.etld_plus_one\": [ \"akadns.net.\", \"amazonaws.com.\", \"apple.com.\", \"apple-dns.net.\", \"cloudfront.net.\", \"icloud.com.\", \"in-addr.arpa.\", \"google.com.\", \"yahoo.com.\" ] } } } }, \"size\": 0, \"aggs\": { \"by_domain\": { \"terms\": { \"size\": 1000, \"field\": \"dns.question.etld_plus_one\" }, \"aggs\": { \"unique_hostnames\": { \"cardinality\": { \"field\": \"dns.question.name\" } }, \"total_bytes_in\": { \"sum\": { \"field\": \"bytes_in\" } }, \"total_bytes_out\": { \"sum\": { \"field\": \"bytes_out\" } }, \"high_num_hostnames\": { \"bucket_selector\": { \"buckets_path\": { \"unique_hostnames\": \"unique_hostnames\" }, \"script\": \"params.unique_hostnames > 200\" } } } } } } The query above relies on the field provided by Packetbeat 5.x to bucket all requests for a single domain. Packetbeat creates this field using an embedded copy of the . Watch Condition The watch condition is what determines if an alert is triggered. The condition here is simple. This says that if any buckets were returned then trigger the alert. \"condition\": { \"script\": { \"inline\": \"ctx.payload.aggregations.by_domain.buckets.size() > 0\" } }, Watch Actions The watch actions are executed after the condition is met, and define the \"output\" of a watch. For this watch we are sending an email and also writing a message to the Elasticsearch log. A\u00a0 \u00a0script is being used to manipulate the data so that it renders better in an email. \"transform\": { \"script\": { \"file\": \"dns_transform\" } }, \"actions\": { \"log_domains\": { \"logging\": { \"text\": \"The following domain(s) have a high number of unique hostnames: {{ctx.payload.alerts}}\" } }, \"email_alert\" : { \"email\": { \"to\": \"'John Doe '\", \"subject\": \"Suspected DNS Tunnel Alert\", \"body\": \"The following domain(s) have a high number of unique hostnames: {{ctx.payload.alerts}}\" } } } Below is the dns_transform Painless script. It should be placed into the config\/scripts directory of Elasticsearch. \/\/ File: config\/scripts\/dns_transform.painless def alerts = ctx.payload.aggregations.by_domain.buckets.stream().collect(Collectors.toMap(p->p.key,item->[ \"total_requests\" : item.doc_count, \"unique_hostnames\" : item.unique_hostnames.value, \"total_bytes_in\" : item.total_bytes_in.value, \"total_bytes_out\" : item.total_bytes_out.value, \"total_bytes\" : item.total_bytes_in.value + item.total_bytes_out.value ])): return [\"alerts\":alerts]: Here is a sample alert. Notice it contains a some additional metrics that can be used to gauge the severity of the situation. Date: Fri, 16 Feb 2016 11:00:01 -0500 (EST) From: Watcher Message-Id: <201602161600.u0SG01ks024814@example.com> To: John Doe Subject: Suspected DNS Tunnel Alert The following domain(s) have a high number of unique hostnames: {badguy.co.={total_requests=222, unique_hostnames=222, total_bytes_in=16716.0, total_bytes_out=35161.0, total_bytes=51877.0}} When this alert is received, the recipient can take the domain and do a search using the Discover application in Kibana to find the network clients responsible for the tunnel. Testing and Results This chart shows the top ten domains with the highest number of unique hostnames over a period of 4 hours. This data was collected from a network with about 100 devices. During that time window I replayed a network capture containing a tunnel created by\u00a0 . The tunnel which is operating under the fictitious domain\u00a0 \u00a0was up for just 20 seconds, and yet it has the highest number of domains. If the whitelist from the watch is applied then the tunnel really stands out among the other domains as seen below. Tuning the Detector There are two variables that can be tuned -- the time window and the unique hostnames threshold. A smaller time window can be used with a smaller threshold to make the watch more sensitive to short duration tunnels. In a shorter time window, domains not being used for tunneling will generally accumulate fewer unique hostnames. Tunnels that move data slowly can be detected using a larger time window. But using a larger time window means that valid domains with a lot of unique hostnames, such as CDNs, will cause false positives. So if you use a large time window you will likely need to add domains to the query's whitelist. Conclusion It was fun combining Packetbeat and Watcher to look for DNS tunnels. Remember \"defense in depth\" if you implement a solution like this. It is important to layer your defenses so that if one layer fails there is another one in place to detect. \n"}
{"index": {"_id": 731}}
{"title":"LotaData Asks, Will Your Neighborhood Shine Red or Blue?","seo_title":"LotaData Studies Your Neighborhood - Will It Shine Red or Blue","url":"\/blog\/lotadata-will-neighborhood-shine-red-blue","author":{"name":"Apu Kumar"},"date":"February 16, 2016","category":"User Stories","locales":"","content":" The past few years have brought about a renaissance in American neighborhoods with strong economies, healthy workforce and diverse communities. Nextdoor has done well to recognize this trend. The simplicity and elegance of Nextdoor's local community network provides a convenient and useful way for residents to stay in touch with their neighbors. While most people intuitively understand the colloquial definition of \"neighborhood\", it is an intriguing exercise to research how neighborhoods manifest in spatial and temporal dimensions, along sociological, philosophical and cultural vectors. What makes a neighborhood? How exactly are neighborhoods defined and who defines them? Do the boundaries change over time? How does one find the information for the thousands of neighborhoods and communities across the US? Is there such a thing as a \"neighborhood search engine\"? Deep knowledge about neighborhoods can set the tone and context for businesses and brands trying to serve the needs of the local market. As published in a\u00a0, the data scientists at\u00a0\u00a0have studied the composition, characteristics, trends and correlations across multiple location-based datasets to understand the physical attributes, the social structure and the digital fabric of local communities. The resulting profiles represent the active identity for each neighborhood, constructed from hundreds of geo-temporal variables, including: Marketers and advertisers look at neighborhoods as a collection of unique people with distinct practices. Neighborhoods provide a sense for the types of audiences one can expect to find in the area, thereby influencing advertising campaign decisions and marketing budget allocations. The increased focus on location-based campaigns in 2016 is starting to put the spotlight back on our neighborhoods. Neighborhood profiles, structured in the form of APIs, can make it possible for marketers to seamlessly search through unwieldy datasets, to unearth meaningful and actionable intelligence for designing hyper-targeted campaigns. As an example, it would be a marketer's dream to be able to \u201ccreate and monitor geo-temporal zones, 100 feet in radii, around all caf\u00e9 locations in neighborhoods that voted against Prop 8, with median home value above $400K and mean household income over $100K, with an average of 3 members per household, located near venues scheduled to host +5 music events with projected attendance of +1000 per event, with <5% chance of precipitation, over the next 16 weeks\u201d. To enable complex queries like these,\u00a0\u00a0has published the detailed profiles for +6800 neighborhoods and made them accessible and searchable through the\u00a0\u00a0and the\u00a0. LotaData's technology platform is powered by\u00a0. Our machine learning recipes extract, collect, cleanse, de-dupe, structure, classify and publish geo-temporal data from tens of thousands of sources, across +80 countries, +35,000 cities and towns, +680,000 local deals and promotions, +145,000 performers, musicians, actors, athletes, teams, +1,800,000 venues, +9,000,000 local events, activities, and an ever growing list of businesses and brands. The speed, scalability and performance of Elasticsearch are the foundation for our platform. The massively distributed architecture with cluster resiliency allowed us to scale horizontally. To get the full story, find our Co-founder and CTO\u00a0\u00a0at\u00a0, offer to buy him a Cortado and he'll spill the beans faster than you can collect. Neighborhood insights are of tremendous value to businesses and brands looking to reach the right audience at the right place, the right time and in the right mood. The New York Times recently wrote about a national brand with an effective local campaign that significantly exceeded the industry average for mobile ad engagement.\u00a0\u00a0profiled neighborhoods that have a high density of bars in order to reach liquor consumers aged 21 to 34. Their mobile ad used location targeting to present consumers in bars with a discount for a ride-sharing service, when they performed specific actions on their smartphones. Regional brands and local businesses can also benefit from targeted campaigns, both digital and physical, powered by neighborhood intelligence. Local restaurants and bars could earn more business by staying open past regular hours to serve audiences exiting late evening music, theater, comedy or sporting events in the neighborhood. Music brands like\u00a0\u00a0could accelerate the direct-to-consumer strategy by promote their instruments at local guitar meetups, jam sessions and music workshops. Food brands like\u00a0\u00a0could monitor neighborhood profiles including youth ratios, ethnicities, income levels and the microclimate to determine the ideal locations to launch their new froyo flavors, Green Tea and Pina Colada. Many of us might recollect the amusing online survey by ABC News that revealed Democrats trust brands like Starbucks and Jeep, while Republicans prefer Dunkin Donuts and BMW. While most brands will not take a stand on partisan issues, it turns out that political preferences and the hundreds of other neighborhood attributes can provide deep insights into consumer purchase decisions. Marketers, advertisers, brands and businesses know this well. As the country gears up for a long-drawn-out election campaign, you can expect marketers to comb through the cities and towns across the US, zoom into your red, white and blue neighborhood, and allocate their green based on the intensity of red or blue. Apu, also an acronym for \"Accelerated Processing Unit\", was born in technology and is rumored to have been conceived in a silicon fab near Springfield, where he went on to found Kwik-E-Cart, an AI-powered sharing economy services company of unicorn stature, that anticipates and predicts your needs and your wants, with antimatter propelled drones delivering to your doorstep prior to even the thought having occurred to you. On a more formal note, Apu Kumar has over 18 years of technology experience in Silicon Valley across software, hardware and cloud services for the mobile, PC and TV ecosystems. Apu's proven record in conceptualizing new products, accelerating adoption and establishing new markets, led him to his newest adventure, LotaData, a company that provides geo-temporal intelligence and location context for businesses and brands. Prior to that, Apu was the SVP and Chief Deal Hacker at BlueStacks (including GamePop), a profitable startup venture-funded by Andreessen-Horowitz, Redpoint, Ignition, Radar, Helion, Presidio, Intel, Samsung and Qualcomm. BlueStacks achieved 1+ billion mobile app downloads with 100+ million MAUs. Apu has also held senior leadership roles at iconic technology brands like Hewlett Packard, Phoenix Technologies (acquired by HP), CNET.com and mySimon (acquired by CNET). Apu is a dynamic and resourceful executive, a motivational leader and manager of cross-functional and cross-geographical, high-performing teams. He is passionate about mobile gaming, wearables, iot, location-based services, health and fitness. While he is not globe-trotting and deal-hacking, you are likely to run into Apu on the trails and tennis courts in the San Francisco Bay Area. Apu has a Master\u2019s degree in Engineering from Stanford University and a Bachelor\u2019s degree in Engineering from the University of Mumbai. LinkedIn: Twitter: Email: \n"}
{"index": {"_id": 732}}
{"title":"Where in the World is Elastic? - Elastic{ON}16","seo_title":"Where in the World is Elastic? - Elastic{ON}16","url":"\/blog\/witwies-elasticon-2016","author":{"name":"Megan Wieling"},"date":"February 15, 2016","category":"","locales":"","content":" Welcome to Find out which Elastic events and meetups are happening near you this week.\u00a0 Upcoming EventsFebruary 17-19: Upcoming Meetups February 15: February 15: February 16: February 16: February 17: February 18: February 18: February 15: February 17: That's it for this week. Stay tuned next week for more Elastic happenings. - The Elastic Team P.S.\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}
{"index": {"_id": 733}}
{"title":"Multi-dimensional points, coming in Apache Lucene 6.0","seo_title":"","url":"\/blog\/lucene-points-6.0","author":{"name":"Michael McCandless"},"date":"February 15, 2016","category":"Engineering","locales":"","content":" Coming in Lucene's next major release (6.0) is a new feature called\u00a0, using the \u00a0geo-spatial\u00a0data structure to offer fast single- and multi-dimensional numeric range and geo-spatial point-in-shape filtering. As of this writing, Elasticsearch has not\u00a0yet exposed points, but I expect that will change\u00a0soon. This feature replaces the\u00a0\u00a0numeric fields and numeric range query since it has better overall performance and is more general, allowing up to 8 dimensions (versus 1) and up to 16 bytes (versus the\u00a0\u00a0today) per dimension. The\u00a0k-d\u00a0tree variant we implemented is the\u00a0\u00a0which is specifically designed for efficient IO, such that most of the data structure resides in on-disk blocks, with a small in-heap binary tree index structure to locate the blocks at search time. This means you will finally be able to use Lucene to efficiently index and range-filter anything that can be encoded as fixed-length, ordered \u00a0, such as\u00a0\u00a0,\u00a0,\u00a0, etc., along with 2D and 3D (and higher!) geo-spatial indices, and times-series values. k-d\u00a0trees Block k-d\u00a0trees are a simple yet powerful\u00a0data structure. At index time, they are built by recursively partitioning the full space of N-dimensional points\u00a0to be indexed into smaller and smaller rectangular cells, splitting equally along the widest ranging dimension at each step of the recursion. However, unlike , a block k-d tree stops recursing once there are fewer than a pre-specified (1024 in our case, by default) number of points in the cell. At that point, all\u00a0points within that cell are written into one\u00a0\u00a0on disk and the starting file-pointer for that block is saved into an in-heap binary tree structure. In the 1D case, this is simply a full sort of all values, divided into adjacent leaf blocks. There are k-d tree\u00a0variants that can support removing values, and rebalancing, but Lucene does not need these operations because of its write-once per-segment design. At search time, the same recursion takes place, testing at each level whether the requested query shape intersects the left or right sub-tree of each dimensional\u00a0split, and recursing if so. In the 1D case, the query shape is simply a numeric range\u00a0whereas in the 2D and 3D cases, it is a geo-spatial shape (circle, ring, rectangle, polygon, cube,\u00a0etc.). Here is a\u00a0video showing how the leaf\u00a0blocks are visited to find all 2D (latitude\/longitude) points\u00a0inside the London, UK polygon based on the\u00a0\u00a0data:\u00a0 #bkdvideo { width: 854px: height: 480px: } Once the recursion ends at a leaf block, if the cell overlaps the shape's boundary (blue cells) then each full-precision point in that block is tested against the shape. This check (\"does the query\u00a0shape contain this point?\") may be somewhat costly since it is computed per-hit against a possibly complex shape, however it is only done for those leaf cells overlapping the boundary of the shape. If instead the leaf block is fully contained inside the query shape (the pink cells), the documents with values in that cell are efficiently collected without having to test each point. K-d trees are fast because they naturally adapt to each data set's particular distribution, using small leaf blocks where the indexed values are dense: notice how\u00a0central London, where there is a higher density of points, is assigned\u00a0smaller leaf cells. K-d trees also naturally find the right tradeoff of how deeply to recurse, by splitting up the dimensional\u00a0space, versus\u00a0at what point simply scanning the full-precision\u00a0values in one cell is appropriate. \u00a0This is\u00a0in contrast to\u00a0legacy numeric fields which always index the same precision levels for every value (4 terms for a long value, by default)\u00a0regardless of how the points are distributed.\u00a0 Lucene's implementation Each indexed value, for example\u00a0a single\u00a0\u00a0added to your document, is translated into\u00a0a fixed-length\u00a0\u00a0for a specific number of dimensions. There are classes for each native type (, , etc.) that handle converting values of that type to the matching .\u00a0For a given field name, all documents in the index must have the same number of dimensions and same\u00a0\u00a0length across dimensions. Multi-valued fields are allowed, by adding the same field name multiple times in one document. Lucene's\u00a0\u00a0buffers the points\u00a0you have indexed, and then uses\u00a0, a newly added codec component, to write the values to a new segment. \u00a0The\u00a0\u00a0supports points, but\u00a0the\u00a0\u00a0does\u00a0as well (it was the first implementation!), so you can see the leaf blocks in a simple, human-readable plain text file if you are curious (do not use it in production!). In developing the feature there were also some exciting low-level infrastructure improvements required, including switching our offline sorter to\u00a0\u00a0instead of direct filesystem IO,\u00a0\u00a0and\u00a0. There are already several Lucene geo-spatial queries that are based on dimensional values, including the sandbox geo spatial queries (,\u00a0,), and the\u00a0\u00a0module indexes and searches 3D (x, y, z) dimensional values. In Lucene's core there is also , to filter by an N-dimensional box, and to query for exactly a single point. 2D Performance To assess the 2D performance impact, I created\u00a0a simple benchmark (all\u00a0sources are ) to\u00a0index\u00a0and filter\u00a0a 60.8 Million latitude\/longitude points subset of the \u00a0data set generously provided by the , querying with a set of regularly spaced varying sized rectangles around London, UK. I\u00a0recorded these four metrics: I compare the legacy spatial module, the recently added GeoPoint queries ( with coming in Elasticsearch 2.3.0 and included in these tests) and the new dimensional points, coming in Lucene 6.0.0: google.charts.load('current', { packages: ['corechart', 'bar'] }): google.charts.setOnLoadCallback(drawQueryTime): function drawQueryTime() { var data = google.visualization.arrayToDataTable([ ['Approach', 'Query time (msec)', { role: 'style' }], ['Points', 13.5, '#e62739'], ['Spatial', 17.6, '#9068be'], ['Geopoint', 26.9, '#6ed3cf'], ]): var options = { title: 'Query time (msec)', chartArea: { width: '50%' }, hAxis: { minValue: 0 }, vAxis: { }, legend: { position: \"none\" }, }: var chart = new google.visualization.BarChart(document.getElementById('query_time_div')): chart.draw(data, options): } google.charts.setOnLoadCallback(drawIndexTime): function drawIndexTime() { var data = google.visualization.arrayToDataTable([ ['Approach', 'Index time (sec)', { role: 'style' }], ['Points', 443.3, '#e62739'], ['Spatial', 1480.8, '#9068be'], ['Geopoint', 87.5, '#6ed3cf'], ]): var options = { title: 'Index time (msec)', chartArea: { width: '50%' }, hAxis: { title: 'Index time (msec)', minValue: 0 }, vAxis: { }, legend: { position: \"none\" }, }: var chart = new google.visualization.BarChart(document.getElementById('index_time_div')): chart.draw(data, options): } google.charts.setOnLoadCallback(drawIndexSize): function drawIndexSize() { var data = google.visualization.arrayToDataTable([ ['Approach', 'Index size (MB)', { role: 'style' }], ['Points', 630, '#e62739'], ['Spatial', 7987.2, '#9068be'], ['Geopoint', 772, '#6ed3cf'], ]): var options = { title: 'Index size (MB)', chartArea: { width: '50%' }, hAxis: { title: 'Index size (MB)', minValue: 0 }, vAxis: { }, legend: { position: \"none\" }, }: var chart = new google.visualization.BarChart(document.getElementById('index_size_div')): chart.draw(data, options): } google.charts.setOnLoadCallback(drawSearchHeap): function drawSearchHeap() { var data = google.visualization.arrayToDataTable([ ['Approach', 'Search time heap (MB)', { role: 'style' }], ['Points', 2.3, '#e62739'], ['Spatial', 238.5, '#9068be'], ['Geopoint', 4.9, '#6ed3cf'], ]): var options = { title: 'Search time heap (MB)', chartArea: { width: '50%' }, hAxis: { title: 'Search time heap (MB)', minValue: 0 }, vAxis: { }, legend: { position: \"none\" }, }: var chart = new google.visualization.BarChart(document.getElementById('search_heap_div')): chart.draw(data, options): } Overall, both GeoPoint and the new dimensional points show substantial improvements across the board over the legacy spatial module, with an especially large reduction in index size and search time heap used, while GeoPoint\u00a0has\u00a0much faster indexing time than dimensional points, and dimensional points show faster querying time, smaller heap and slightly smaller index size. Remember that no\u00a0benchmark is\u00a0perfect, and this one is no exception!\u00a0 First, it runs only the geo filter in isolation, but\u00a0in practice a\u00a0geo filter\u00a0would normally be\u00a0executed along with other MUST clauses where\u00a0optimizations like\u00a0\u00a0should have a big impact. \u00a0Second, it tests single-valued documents, while multi-valued cases will likely have different behavior. \u00a0Third, it's a standalone benchmark, so the hotspot compiler gets to unnaturally focus only on the specific indexing and searching code.\u00a0Finally, the query shapes are a set of regularly spaced\u00a0rectangles around London, UK, not actual user queries. 1D Performance To test the 1D case, I indexed only latitude from the same data set, quantized to an integer (1D 4 byte point), and compared dimensional points with the legacy\u00a0, using regularly spaced varying sized range filters (just the 1D projection of the 2D test queries): google.charts.setOnLoadCallback(draw1DQueryTime): function draw1DQueryTime() { var data = google.visualization.arrayToDataTable([ ['Approach', 'Query time (msec)', { role: 'style' }], ['Points', 24.7, '#e62739'], ['Numeric Field', 32.2, '#9068be'], ]): var options = { title: 'Query time (msec)', chartArea: { width: '50%' }, hAxis: { minValue: 0 }, vAxis: { }, legend: { position: \"none\" }, }: var chart = new google.visualization.BarChart(document.getElementById('query_time_1d_div')): chart.draw(data, options): } google.charts.setOnLoadCallback(draw1DIndexTime): function draw1DIndexTime() { var data = google.visualization.arrayToDataTable([ ['Approach', 'Index time (sec)', { role: 'style' }], ['Points', 86.8, '#e62739'], ['Numeric Field', 173.9, '#9068be'], ]): var options = { title: 'Index time (msec)', chartArea: { width: '50%' }, hAxis: { title: 'Index time (msec)', minValue: 0 }, vAxis: { }, legend: { position: \"none\" }, }: var chart = new google.visualization.BarChart(document.getElementById('index_time_1d_div')): chart.draw(data, options): } google.charts.setOnLoadCallback(draw1DIndexSize): function draw1DIndexSize() { var data = google.visualization.arrayToDataTable([ ['Approach', 'Index size (MB)', { role: 'style' }], ['Points', 364, '#e62739'], ['Numeric Field', 744, '#9068be'], ]): var options = { title: 'Index size (MB)', chartArea: { width: '50%' }, hAxis: { title: 'Index size (MB)', minValue: 0 }, vAxis: { }, legend: { position: \"none\" }, }: var chart = new google.visualization.BarChart(document.getElementById('index_size_1d_div')): chart.draw(data, options): } google.charts.setOnLoadCallback(draw1DSearchHeap): function draw1DSearchHeap() { var data = google.visualization.arrayToDataTable([ ['Approach', 'Search time heap (MB)', { role: 'style' }], ['Points', 2.16, '#e62739'], ['Numeric Field', 14.4, '#9068be'], ]): var options = { title: 'Search time heap (MB)', chartArea: { width: '50%' }, hAxis: { title: 'Search time heap (MB)', minValue: 0 }, vAxis: { }, legend: { position: \"none\" }, }: var chart = new google.visualization.BarChart(document.getElementById('search_heap_1d_div')): chart.draw(data, options): } Dimensional points shows faster querying and indexing time, and a substantial reduction in search time heap used and index size. The indexing time in particular benefited from a\u00a0. I suspect a similar optimization may be possible in the 2D case but it has not yet been explored (patches welcome!). Moving forwards Please keep in mind that as of this writing, dimensional points\u00a0are not yet released, so if you play with this new feature, using a snapshot build\u00a0from\u00a0Lucene's master branch, index file formats and APIs are free to suddenly and drastically change up until when 6.0 is released (). We would love to\u00a0! Note that the dimensions need not all be spatial! One exciting potential use case is mixing geo-spatial dimensions with other dimensional values, such as median household income, into a single 3D dimensional index. This would then allow fast range filters against both median household income and arbitrary\u00a0geo-spatial shapes. Another example is indexing time as one dimension along with other numeric dimensions to support business-intelligence use cases. Currently, dimensional values must be single points, but some geo-spatial use cases require indexing shapes as well, which can be done with a generalization of the k-d tree called an ,\u00a0for example,\u00a0and I expect that will be a future improvement to Lucene (patches welcome again!). [The image on the top was generated by the\u00a0\u00a0project] \n"}
{"index": {"_id": 734}}
{"title":"Logstash 2.2.1 Released","seo_title":"","url":"\/blog\/logstash-2-2-1-released","author":{"name":"Suyog Rao"},"date":"February 13, 2016","category":"Releases","locales":"","content":" [This post has been updated to include 2.1.3 release] We are happy to announce that Logstash version 2.2.1 and 2.1.3 has been released today! Jump to the page for the binaries, where you can also find the full list of for 2.2.1 and 2.1.3 . Bug Fixes These are bug fix releases, some of which we highlight below: Reinstating CLI option In , we re-architected the pipeline to have both filters and outputs execute in the same thread\/worker unit, and introduced an option () to configure them. Inadvertently, we removed an existing CLI option which has been used to control the number of threads used for filter stage. In 2.2.1, we\u2019ve reinstated this flag, and made it an alias to configure pipeline workers. This option () has also been marked deprecated, and will be removed in the next major version. Please note that the short option will continue to work in both 2.2.0 and future versions. Our apologies for any inconvenience this has caused. Flushing issue in new pipeline Fixed a bug where filters that periodically flush buffered events would not work in v2.2.0. This bug affects filters like multiline, metrics, aggregate filter () Others Please Logstash 2.2.1 and let us know what you think on Twitter (@elastic) or on our . You can report any problems on the GitHub issues page. \n"}
{"index": {"_id": 735}}
{"title":"Kibana 4.4.1, 4.3.2, and 4.1.5 released","seo_title":"","url":"\/blog\/kibana-4-4-1-and-4-3-2-and-4-1-5","author":{"name":"Court Ewing"},"date":"February 12, 2016","category":"Releases","locales":"","content":" Today we\u2019re releasing patch versions of Kibana 4.4, 4.3, and 4.1 that bump the bundled version of node to include recent security fixes in node.js. We recommend that all users upgrade their Kibana installs immediately. The 4.4.1 release also includes a bug fix in Kibana itself that was deemed \u201cway too annoying not to fix\u201d. \u200b 4.4.1 Changes 4.3.2 Changes 4.1.5 Changes Where to download You can download Kibana at our page. If you encounter any bugs with either of these versions, please file them on the github page. If you have any questions or concerns, do no hesitate to reach out on or our discussion . \n"}
{"index": {"_id": 736}}
{"title":"What It's Like to Attend Elastic Training","seo_title":"What It's Like to Attend Elastic Training","url":"\/blog\/what-its-like-to-attend-elastic-training","author":{"name":"Jason Dickson"},"date":"February 10, 2016","category":"Culture","locales":"","content":" The best thing that I heard all day was, \"This class isn't going to be too technical.\" Unlike many of you reading this post, I don't have a programming background. I'm a writer-editor guy and I'm new to both Elastic (the company) and the Elastic Stack \u2014 you know, Elasticsearch, Logstash, Kibana, and Beats. The gentleman who made the statement above was , software engineer, a core Logstash developer, and one of two official Elastic instructors for the day-long course I was taking, . After introducing himself, Kurt also provided a quick overview of what we would learn in the sunny conference room, which was full of IT, operations, and engineering pros. And there I was, an Elastic employee seeking a better understanding of our open source offerings, feeling like a fish out of water among dozens of very smart people. For me, hearing that the course contained sections like \"Intro to the Elastic Stack\" and \"Understanding Event Data\" was a great relief. Kurt's co-instructor was , also an Elastic software engineer. A former biologist\/ecologist, he fell in love with creating visualizations while using JavaScript at Beats Electronics and is now a Kibana data visualization engineer. A Data StoryFirst up was a cool data story using a data set about UK-based cars. I counted at least a dozen different charts and graphs created with Kibana, as Kurt talked us through interesting conclusions including a spike in car models due to the geographic distribution of the fans of legendary rally driver and taxi cabs in London with over 1 million miles on their odometers. Next, Kurt talked through the Elastic Stack overview, and although I've been part of Elastic's team since last year, I gained more understanding of the big picture. Following this, we all dove into learning about event data. Did you know that the timestamp of some logs reflect the number of seconds since the year 1970? I didn't. We also listened as Kurt explained time-based data, indexing in Logstash, and aggregations in Elasticsearch. The best takeaway for me during this was Kurt's analogy about needles in a haystack: He said that with Elasticsearch and Kibana, we can turn the simple idea of searching for a single needle upside down. Finding out the average length of every needle in the haystack is now possible, as is finding out how many needles came from this field and how many from the field a hundred yards away. The power of Kibana, and the Elastic Stack as a whole, is that ingesting, searching, and visualizing the information about the needles is easier and far less time-consuming than with other offerings. In the whiteboard diagram above, Kurt gave us an example of how you can break down aggregations into categories for use in Kibana \u2014 generic sales data, broken down by days of the week (buckets), then by total sales dollars and average sales dollars (metrics). This helped me tremendously during the afternoon session, which featured a lot of hands-on lab activities. After a little over an hour of lecture and question-answer time, Kurt said, \"OK. Non-technical people may want to close your eyes now.\" I kept mine open. I felt ready, after the extremely helpful intro presentations. Hosted ElasticsearchAfter a tasty lunch, each of the attendees received a training cluster on . Since it comes with a free instance of Kibana, this made it super easy for us to learn and explore Kibana 4 by actually utilizing the stack. For me, just logging in successfully was a \"Wooooo!\" moment. I even helped a couple of classmates who got lost. (It helped me to look at the presentation slides before the class \u2014 they are provided to attendees in advance.) Highlights of the Kibana CourseBy the time we began learning how to use , I was doing great. Inverting filters is awesome: on a given data set, there were lots of geographic locations that you could sift through, so I inverted a search for the U.S. city of San Antonio and found 2 results (out of hundreds of thousands total) in other countries. Learning Kibana can be challenging, because it's so customizable. Once you start learning to use it, you're on a Kibana-coaster of fun, discovering new options and new ways to visualize all your valuable data. While learning, I was also observing. What I really noticed was Shelby took time to consider every question he was asked. He often stopped the presentation and took time to walk out from behind his lectern, helping one-on-one at the attendees' tables. This was incredibly helpful when someone fell behind or felt lost, and it was an invaluable in-person experience. A lot of instructors sidestep or brush off questions, but Shelby is an experienced trainer who is not only an expert, but also wholeheartedly tried to help everyone. It Definitely Gets TechnicalDo not think that because I really liked the introductory lecture that Elastic's Kibana 4 Workshop skims over the technical details. By the end of the day, we were on a deep dive into Kibana, its features, and its amazing capabilities. I also realized that most of the companies represented in the room had incredibly complex and unique Elastic Stack deployments, and they were learning a lot from the the lectures, demo sessions, and the give-and-take with Shelby and Kurt. One attendee suggested that Kibana's \"split rows should be renamed [to] add dimension column.\" And though I don't really know if that's a better name, I really liked the reply from our instructor as he typed into his personal laptop. \"We take notes here and that is good feedback,\" Shelby said. \"We think one way [while developing Kibana], but it's great to hear how other people think, or what is confusing to you.\" A few moments later, someone pointed out a circumstance which caused a Save button to become unavailable. \"We just found that bug,\" Shelby replied. \"Actually that's mine \u2014 I'm assigned to fix that.\" Where else on Earth can you have that one-on-one interaction, when you need to learn about Kibana? Nowhere. are by far the best places to get the knowledge you need, whether you're an old pro at using our stack, or you're like I was: you know a little and want to learn more. Stay tuned for another post in this series by Kurt Hurtado that will describe what it's like to be an Elastic training\u00a0instructor.One last thing: if you're interested in learning more about Kibana 4, Elastic recently offered a free webinar, The Contributor's Guide to the Kibana Galaxy, which you can now access on-demand.\u00a0. \n"}
{"index": {"_id": 737}}
{"title":"GA Release of NEST 2.0, our .NET client for Elasticsearch","seo_title":"","url":"\/blog\/ga-release-of-nest-2-0-our-dot-net-client-for-elasticsearch","author":{"name":"Martijn Laarman"},"date":"February 09, 2016","category":"Engineering","locales":"","content":" This marks the first GA release of our 2.0 client with well over a 1000 commits since 1.7.1 (the currently last released NEST version in the 1.x range). Back to the drawing boardWe took some time to go back to the drawing board. NEST was originally started in 2010 and there are many choices that have accumulated in the code base that don't make sense anymore. So we stepped back to properly formalize how we see the lifetime of a call and worked off of that. Armed with the following diagram, we completely rewrote NEST's internals: The old based code is now replaced with with a much saner approach to exceptions and errors in addition to exposing enough information as an audit trail so you don't ever have to guess what went down during a call. Our internals now also reflect this: This pipeline now handles all of the failover\/sniffing\/pinging logic and directly reflects the flow diagram. We also simplified down just 2 methods. This means the outer edges are clean ( and ) and implementing your own should be really really simple. All of these (and also and ) can be injected on the constructor of the client. Test FrameworkAnother huge endeavour is the rework of our test framework. NEST 1.x was always well tested but used 5 different test projects and 5 years worth of changing our minds as how best to write tests and assertions, thus becoming a big hodgepodge of , , , combined with several different ways to compare json with object graphs and vice-versa. Trying to write a new test quickly became because there was no clear cut way for how best to write said test. So the first thing we did as part of our 2.0 branch was to completely delete all of our tests. This gave us carte blanche during our rewrite. As of 2.0, we have one test project, , with all tests written in such a way that they can be run in unit test mode and integration test mode. . All of the API endpoint tests test all four request variations - two DSL's (using fluent and object initializer syntax) with both synchronous and asynchronous variations of each. We also test all of the moving parts of the Elasticsearch DSL (Aggregations, Sorting, IndexSettings, etc) in the same way. In addition to the more formal unit and integration tests, we also implemented a thing we dubbed to allow us to write tests in a more story telling form, with multi-line comments serving as the narrative for our asciidoc documentation while using the to pick out the interesting bits of code. This gives us the benefit of always compiling our documentation in addition to having only one place where we document, test and assert how a piece of code is supposed to work. Another huge component of our testing framework is the that allows us to write tests for any situation and how we expect the client to behave. For example: \/** we set up a 10 node cluster with a global request time out of 20 seconds. * Each call on a node takes 10 seconds. So we can only try this call on 2 nodes * before the max request time out kills the client call. *\/ var audit = new Auditor(() => Framework.Cluster .Nodes(10) .ClientCalls(r => r.FailAlways().Takes(TimeSpan.FromSeconds(10))) .ClientCalls(r => r.OnPort(9209).SucceedAlways()) .StaticConnectionPool() .Settings(s => s.DisablePing().RequestTimeout(TimeSpan.FromSeconds(20))) ): audit = await audit.TraceCalls( new ClientCall { { BadResponse, 9200 }, \/\/10 seconds { BadResponse, 9201 }, \/\/20 seconds { MaxTimeoutReached } }, \/** * On the second client call we specify a request timeout override to 80 seconds * We should now see more nodes being tried. *\/ new ClientCall(r => r.RequestTimeout(TimeSpan.FromSeconds(80))) { { BadResponse, 9203 }, \/\/10 seconds { BadResponse, 9204 }, \/\/20 seconds { BadResponse, 9205 }, \/\/30 seconds { BadResponse, 9206 }, \/\/40 seconds { BadResponse, 9207 }, \/\/50 seconds { BadResponse, 9208 }, \/\/60 seconds { HealthyResponse, 9209 }, } ): This showcases the tests combined with and the extensive audit trail information available on each response (or exception). I'm pleased to say we are back at a decent coverage rate (60%) and will continue to iterate and improve this. Exception handlingAnother big change in NEST 2.0 is how we deal with exceptions. In NEST 1.x, the client threw a multitude of exceptions: , , , , etc.. This made it challenging for users to handle exceptions and invalid responses, and understand the root cause of errors. On top of that, the types of exceptions thrown depended on what kind of was injected, in order to maintain maximum backwards compatibility with NEST 0.x. In NEST 2.x, exceptions are much more deterministic. The former setting has been replaced with the more succinct , which determines whether the client should ever throw an exception or not (client side and server exceptions). Furthermore, the types of exceptions have been reduced and simplified down to three types of exceptions: These are exceptions, either an exception that occurred in the request pipeline(such as max retries or timeout reached, bad authentication, etc...) or Elasticsearch itself returned an error (could not parse the request, bad query, missing field, etc...). If it is an Elasticsearch error, the property on the response will contain the the actual error that was returned. The inner exception will always contain the root causing exception. These are exceptions, for instance a response from Elasticsearch not properly deserialized. These are usually bugs in the client and . This exception also inherits from so an additional catch block isn't necessary to handle but can be helpful in distinguishing between the two. These are CLR exceptions like , etc. that are thrown when an API in the client is misused. Breaking ChangesEven though a lot of work went into the interior, the exterior did not escape unscathed! On top of the many breaking changes that Elasticsearch 2.0 introduces, there are more then a few NEST 2.0 introduces. We revalidated all the request and response domain objects against Elasticsearch 2.0. A pretty complete list of breaking changes are available: Elasticsearch 2.x supportNEST 2.0 supports all the new features in Elasticsearch 2.0 including pipeline aggregations. have not yet been mapped. Here we'll just highlight a couple features that are reflected in the NEST changes to whet your appetite! Filters are In Elasticsearch 2.0, and NEST 2.0 reflects this. So if you were previously using the , this is now\u00a0the : beware however\u00a0that some of these filters have been obsoleted and chances are high . Isolated descriptorsIn NEST 1.x we took pride in being a 1-to-1 mapping with the Elasticsearch API. In some cases however, this hid the real depth of parameters. As an example, in NEST 1.x you could add sorts on using: client.Search(s=>s .SortAscending(...) .SortScript(...) ) in NEST 2.0 you have to stoop down a level first in order to access the same functionality client.Search(s=>s .Sort(ss=>ss .Field() .Script() .Ascending() .GeoDistance() ) ) This encapsulates all of the sort options properly and adheres stricter to the 1-to-1 mapping. NEST 1.x did also contain this full descriptor however the mix and matching of the convenience methods of the parent meant that some fluent methods were additive whilst others overwrote what was previously set. With NEST 2.0, this discrepancy is gone! This happens in more places e.g index settings and mappings. Filtered query deprecationWith the removal of filters, NEST has added a special construct in its Query DSL to easily create a with a filter clause .Query(q=> +q.Term(p=>p.Name, \"NEST\")) the will cause\u00a0the term query to be wrapped inside a bool query's clause You can even combine with .Query(q=> !+q.Term(p=>p.Name, \"NEST\")) This will wrap the term query inside a and subsequently inside a \u00a0clause.\u00a0This approach also works with the object initializer syntax (OIS) !+new TermQuery {} Attribute based mappingThe single has been broken up into individual attributes per property type. For instance, the following: [ElasticType(Name = \"othername\", IdProperty = \"MyId\")] public class Foo { [ElasticProperty(Type = FieldType.String)] public Guid MyId { get: set: } [ElasticProperty(Type = FieldType.String)] public string Name { get: set: } [ElasticProperty(Type = FieldType.String, Analyzer = \"myanalyzer\", TermVector = TermVectorOption.WithOffsets)] public string Description { get: set: } [ElasticProperty(Type = FieldType.Date, Format = \"mmmddyyyy\")] public DateTime Date { get: set: } [ElasticProperty(Type = FieldType.Integer, Coerce = true)] public int Number { get: set: } [ElasticProperty(Type = FieldType.Nested, IncludeInParent = true)] public List Bars { get: set: } } becomes [ElasticsearchType(Name = \"othername\", IdProperty = \"MyId\")] public class Foo { [String] public Guid MyId { get: set: } [String] public string Name { get: set: } [String(Analyzer = \"myanalyzer\", TermVector = TermVectorOption.WithOffsets)] public string Description { get: set: } [Date(Format = \"mmddyyyy\")] public DateTime Date { get: set: } [Number(NumberType.Integer, Coerce = true, DocValues = true)] public int Number { get: set: } [Nested(IncludeInParent = true)] public List Bars { get: set: } } Aside from a simpler and cleaner API, this allows each attribute to only reflect the options that are available for the particular type instead of exposing options that may not be relevant (as did). Inferred typesMany places that only took a string or primitive type now take a more strongly typed object such as , , , , , , , , etc. It's good to know that in most cases you can still pass a string or primitive type and it will be implicitly converted to the type where it makes sense. If you are using you can also statically import the static class using , allowing to write so on and so forth. If you are using the fluent API using these infer methods is not required since the fluent API is strongly typed through lambda expressions, but they are another tool at your disposal nonetheless. C# 6 supportNEST's codebase has been largely rewritten to take advantage of all the cool new c# features making almost all the fluent code one liners using static Nest.Infer: \/\/later.. Field(p => p.Name): Index(): Indices().And(): DNX SupportThe 2.0 release has been released with a version on nuget that can be used on both the Desktop and Core CLR runtimes of DNX rc1. We are actively tracking , the and the new NuGet target framework, with a plan to release compatible packages once these hit the scene. FeedbackWe'd like to thank everyone who took the alpha and rc releases out for a spin and provided invaluable input while we incubated the 2.0 release. A special shoutout to for sharing his screen with us so we could see firsthand where the pain points were during an upgrade from 1.x to 2.0. As always we very much welcome all feedback on \n"}
{"index": {"_id": 738}}
{"title":"The Logstash Lines: 2.2 Release, Dynamic Config Reloading","seo_title":"","url":"\/blog\/logstash-lines-2016-02-09","author":{"name":"Suyog Rao"},"date":"February 09, 2016","category":"The Logstash Lines","locales":"","content":" Welcome back to The Logstash Lines! In these weekly posts, we'll share the latest happenings in the world of Logstash and its ecosystem.This week, we are super excited to report that dynamic config reloading feature has been merged to master. With this feature, any config changes made to the file will be picked up dynamically,\u00a0and the internal\u00a0pipeline restarted to apply these changes. This means Logstash as a process does not need to be restarted to update configuration.\u00a0To enable this, run LS with:bin\/logstash -f config_file --auto-reload --reload-interval 2 is how often LS watches the config file for changes, defaulting to 3 secondsThis is also getting back ported to 2.3 release, so look out for that!2.2.0 and 2.1.2 ReleaseAs part of release bonanza, LS 2.2.0 and 2.1.2 was released with new pipeline architecture being the highlight among other features\/bugs. See for details.\u00a0A user reported a with the new pipeline which affects a subset of LS filters (metrics, multiline, etc). These filters use flushing logic to periodically emit events which are in-flight. This has been fixed and we're targeting a 2.2.1 release this week.LS MetricsThe aim of this project is to\u00a0expose\u00a0internal metrics of Logstash using an API. Follow for more details.Others:Many exciting things are in store for Logstash and we'll talk about that in detail at our user conference - . Our entire engineering team will be at this conference, so please come by and say hi! We'd love to talk about roadmap, issues\u00a0and upcoming features. See you in San Francisco! \n"}
{"index": {"_id": 739}}
{"title":"Create an AMI from your own VM image","seo_title":"Create an AMI from your own VM image","url":"\/blog\/create-an-ami-from-your-own-vm-image","author":{"name":"Dimitrios Liappis"},"date":"February 08, 2016","category":"Engineering","locales":"","content":" Creating your own AMI from scratchContinuing the trend of AWS-related articles, this time I am looking at how to generate an Amazon Machine Image (AMI) from an ISO source. Why?There are a large number of publicly available AMIs. For example the ones owned by Amazon can be searched per region using aws --region eu-central-1 ec2 describe-images --owner amazon Those AMIs can be used as a basis for customized AMIs, generated for example using the excellent builder. Some times though there is a need to create an AMI from an existing virtualization source e.g. a file from VirtualBox. It would be great if we could create our customized OS image either through an interactive installation or in an automated way via Packer and import it as an AMI in EC2. It turns out that this is possible using . Prerequisites and limitations Manual stepsWith the prerequisites satisfied the process is: Automating the processThe above steps can be tedious and since I needed to import vagrant boxes, I created a tool to automate this: The required parameters are: The s3bucket and the (temporary) key used for uploading the VM. is optional but if you omit it, expect a certain naming convention like For example .\/oel7.1-x86_64-virtualbox.box is a valid name. Displays progress statistics. Very useful if the script is not run from another program. By default it will create copies of the temporary AMI that AWS import-image creates in three regions -- us-east-1, us-west-2, eu-central-1. It's easy to add or remove destination regions in ExampleFor an existing oracle linux vagrant box: $ .\/amiimporter.py --s3bucket mybucket --vboxfile .\/oel7.1-x86_64-virtualbox.box --verbose INFO:root:Uploading .\/tmpdir\/packer-virtualbox-iso-1453910880-disk1.vmdk to s3 99% INFO:root:Running: aws --region eu-west-1 ec2 import-image --cli-input-json {\"Description\": \"temp-hvm-oel-7-20160129134521\", \"DiskContainers\": [{\"UserBucket\": {\"S3Bucket\": \"mybucket\", \"S3Key\": \"temp-hvm-oel-7-20160129134521\"}, \"Description\": \"temp-hvm-oel-7-20160129134521\"}]} INFO:root:AWS is now importing vdmk to AMI. 98% INFO:root:Done, amiid is ami-7c7bcc0f INFO:root:Successfully created temporary AMI ami-7c7bcc0f Created ami-8d322ae1 in region eu-central-1 Created ami-8d16f1ed in region us-west-2 Created ami-89e4c9e3 in region us-east-1 INFO:root:Deregistering temporary AMI ami-7c7bcc0f INFO:root:Deleting updateded s3 file s3:\/\/mybucket\/temp-hvm-oel-7-20160129134521 WarningsIf you use a Vagrant box as a source for your AMIs make sure that the vagrant user does not have the default password and\/or insecure key as otherwise your deployed instances will be easily hacked. Also, depending on the distribution, may be unable to resize your root partition automatically. This may come handy. ConclusionDespite the fact that AWS public AMI store is very rich in images, there are always corner cases where you need to create something from scratch. I hope the process illustrated above is not too daunting and perhaps the included script will make it even easier! \n"}
{"index": {"_id": 740}}
{"title":"Brewing in Beats: Kafka output","seo_title":"","url":"\/blog\/weekly-beats-1-1-0-released","author":{"name":"Monica Sarbu"},"date":"February 08, 2016","category":"Brewing in Beats","locales":"","content":" Welcome to Weekly Beats! With this series, we're keeping you up to date with all that's new in\u00a0, from the details of work in progress pull requests to releases and learning resources. Early last week we released Beats 1.1.0 together with the first version of Winlogbeat. You can read more details about it on the . Other notable things going on: Add support for Redis and Kafka outputsCurrently you can configure Elasticsearch, Logstash and Redis as outputs. Redis became deprecated after we added support for Logstash as you can simply use the to dump your data to Redis. What happened was that a lot of people deployed it like this: Beats -> Logstash -> Redis -> Logstash -> Elasticsearch We received many requests from the community to add support for more outputs, besides Elasticsearch and Logstash to avoid having an additional Logstash instance to translate the data to the desired queuing system. After internal discussions, we decided to follow the community feedback, so we will un-deprecate the Redis output and add support for the Kafka output. So the deployment scenario becomes: Beats -> Redis\/Kafka -> Logstash -> Elasticsearch More details can be found in the . Merge together the scripts for generating docs and templateEach Beat had two scripts to generate the Elasticsearch template and the documentation based on the fields.yml. The fields.yml file contains details about all exported fields and it is located in each Beat repository. The scripts were sharing a lot of common code among all the Beats, so we decided to them together into two generic scripts that are able to generate the template and the documentation no matter what the Beat is. The scripts are now part of libbeat and they can also be used by the community Beats. \n"}
{"index": {"_id": 741}}
{"title":"This Week in Elasticsearch and Apache Lucene - Query Profiler and Geopoint Fields","seo_title":"This Week in Elasticsearch and Apache Lucene - Query Profiler and Geopoint Fields","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-query-profiler-geopoint-fields","author":{"name":"Michael McCandless"},"date":"February 08, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsElasticsearch 2.2.0 released with a query profiler and supercharged geopoint fields. Already available on Found\u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole Elastic\u00a0ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 742}}
{"title":"Calling All Lady Avengers","seo_title":"","url":"\/blog\/calling-all-lady-avengers","author":{"name":"Kristina Frost"},"date":"February 08, 2016","category":"Culture","locales":"","content":" Community.Community is a word that means a lot to all of us here at Elastic, be it in regards to the community of engineers who use and even contribute to our Stack, or our community of over 300 employees scattered across the globe. I think often about the communities I consider myself a member of, and how they might keep getting stronger, keep getting better. Better is a tricky word and it can look like a lot of things: it can look like more fun, for instance, with my friends: it can look like more efficiency, for my team: but for the context of this blog post, it looks like more diversity for my company and for our industry.\u00a0I\u2019m not sure when, exactly, it became apparent to me that membership in certain communities afforded the people within them more privilege and power than those without. This is not knowledge we\u2019re born with, after all. Kids have unparalleled imaginations, and those imaginations usually don\u2019t come with glass ceilings. The ceilings come later. At some point, I assented to the fact intellectually: I knew, for example, that certain schools had better reputations than others: I knew that my own race and socio-economic class afforded me luxuries that not all of my peers received. Maybe because I was so privileged in that respect, the gender divide didn\u2019t feel like a real limitation for me for a long time. Emotional assent to that fact came along much, much later: when I\u2019d entered the workforce, and the stereotypes so many of us are familiar with started to appear in a real way, like, for example, that in nearly all of my performance reviews I\u2019ve been applauded for passion, efficiency, and leadership whilst simultaneously being hit with that word we seem to use only for women: \u201cbossy.\u201d I know I\u2019m not alone. I know the science, now: all of the sociological work that tells us that the hurdles put in front of women in the workplace are very real, and that the hill we climb is very steep.I came to Elastic from a big company, and part of the reason why I was so excited to come here was the prospect of building things for the first time, from the ground up. Not because I think I can do so flawlessly, but because whatever mistakes I make, and whatever mistakes my team makes, they\u2019ll be new mistakes, our mistakes, mistakes that we own: not mistakes we\u2019re inheriting that were set in place five or ten years ago, or processes still tied to \u201c\u201d One of these things, and I\u2019m excited to introduce you all to it, is our \u201cLady Avengers,\u201d a name we\u2019ve basically made up because of the company love of superheroes.\u00a0A recent gathering of the Mountain View Chapter of the Lady Avengers\u00a0Who are the Lady Avengers? We\u2019re \u00a0every female employee of Elastic, and we meet monthly to talk about what it\u2019s like to be a woman who works in the technology space, and what it\u2019s like to be a woman who works for Elastic, and how we can make both of those things better. We haven\u2019t been at this for very long, so we\u2019re a scrappy bunch of superheroes, and we\u2019re just getting started when it comes to deciding what kinds of things we want to do and build for the very first time. It\u2019s my pleasure on behalf of all of us to invite those of you who are attending Elastic{ON} to join us for our Lady Avengers Breakfast, on Thursday morning at 8:45 AM.What is the Lady Avengers Breakfast? Think of it as one part community kick-off, one part guided meet-and-greet, and one part \u2026 well, breakfast. It\u2019s hosted by us, and we\u2019ll be breaking up into themed groups, to host roundtables on things like working with emerging technologies, culture and diversity crafting, professional development, or even just as a place to share experiences and network. Women from all parts of Elastic will be there to participate: from every department from Engineering to Sales, from all around the world, including many of our recruiters and our new VP of Human Resources (one of our newest Lady Avengers!). So if you\u2019re attending the conference, and if this is a topic that you\u2019re passionate about, please plan to come by and see us. We\u2019ll have some special swag and giveaways, but I think more importantly, you\u2019ll have the opportunity to connect with other women at the conference, and you\u2019ll get to join a conversation that we want to keep going for a very, very long time.\u00a0We have big dreams for this community and what it can do, and we want all of you to play a part in collaborating with us. If you can\u2019t attend, stay tuned, because like I said, this is just going to be our first conversation, but I promise you it won\u2019t be the last.So come on by, eat some breakfast, and talk to some brilliant, amazing women. I\u2019m not Nick Fury, and trust me, I\u2019d never play him on TV, but the Lady Avengers are enlisting superheroes, and this is a community that won\u2019t be the same if it doesn\u2019t have you. \n"}
{"index": {"_id": 743}}
{"title":"Where in the World is Elastic? - DrupalGov Canberra 2016","seo_title":"Where in the World is Elastic? - DrupalGov Canberra 2016","url":"\/blog\/witwies-drupalgov-canberra-2016","author":{"name":"Megan Wieling"},"date":"February 08, 2016","category":"","locales":"","content":" Welcome to Find out which Elastic events and meetups are happening near you this week.\u00a0 Upcoming Events February 8: Upcoming Meetups February 8: February 8: February 9: February 9: February 10: February 13: February 14: That's it for this week. Stay tuned next week for more Elastic happenings. - The Elastic Team P.S.\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}
{"index": {"_id": 744}}
{"title":"Securing Fields and Documents with Shield","seo_title":"","url":"\/blog\/securing-fields-and-documents-with-shield","author":{"name":"Martijn van Groningen"},"date":"February 03, 2016","category":"Engineering","locales":"","content":" Securing data with Shield was already possible at the index level by defining privileges for indices and aliases via Shield's\u00a0. Since Shield 2.0 data can be secured at an even lower level, up to the field and document levels inside an index, let's set up field level security for an imaginary ticketing platform. Assume the following: { \"subject\" : \"Missing emails\", \"message\" : \"Last week when...\", \"severity\" : \"low\", \"time_spent_in_minutes\" : 5, \"escalated\" : false, \"private_notes\" : [\"This is likely caused by a bug\"] } There are two kinds of users using this data, the customers creating tickets and the support engineers interacting via the ticket system with the user and eventually resolving the ticket. Both have access to the same tickets, but customers shouldn't have to see all properties of a ticket. The \u2018time_spent_in_minutes', \u2018escalated' and \u2018private_notes' are properties of the ticket data that are private to the only support engineers and these fields can be made hidden and inaccessible by enabling field level security for the \u2018customer' role: customer: indices: 'ticket_index': privileges: read fields: - subject - message - severity As can been seen in the example \u2018roles.yaml' file is that enabling field level security is as easy as defining a list of fields that are accessible for a role. Configuring document level security is similar, only then a query needs to be defined that includes documents that are accessible. More details about how to configure field and document level security can be found in the\u00a0\u00a0documentation. The need for lower level access controlThere are many other use cases can benefit from controlling access to the data on the field and document level. For example when data is shared across many organizations or departments within an organization, but not all parties involved are allowed to see all properties of the data. Before Shield 2.0 data would have to be duplicated. This would mean that each department in an organization would have its own index and then in Shield each department role would only allow access to their own index. With field and document level security duplicating data is no longer needed. All departments will share the same index and each department role will have a list of allowed fields and optionally a query that dictate the visible fields or documents. When field and document level security is enabled it is applied for all Elasticsearch read APIs, in a secure manner, so how could this implemented? Filter response approachA naive approach would be to filter responses. Each api that returns data would need to check if keys or values inside the response are allowed to be returned. This might work out for filtering fields or documents that aren't visible in the search and get APIs, but doesn't prevent someone from running a query or an aggregation of a field that isn't visible. For example the total hit key in the search response would then still indicate that there is more than is visible. So in order for field and document access control to work correctly, the request needs to be filtered too, which means that queries and aggregations on not allowed fields need to be removed. By removing disallowed queries and aggregations this means the request needs to rewritten before execution and this is harder than it looks, especially if a search request contains many compound queries and complex aggregations. Also with what query should a disallowed query be replaced with? And if this modified request is ran through the explain or profile api how would that look? Also how would field or document level access control be implemented in other read APIs? There are many APIs in Elasticsearch and not all APIs are structured in the same way. On the ES side this would require to do access control checking in many different places. Data security leaks should be avoided at all cost and with this approach there is a high chance that there is an accidental data leak because of a mistake during development now or in the future. If instead access control is only applied in one place than the chances for mistakes are much slimmer. This clearly shows that filtering on out keys and values in the response is applying field and document level access control on the wrong level. A better approach would be to apply field and document level access control at the Lucene level. In fact this is how Shield implements field and document level access control. Securing data with LuceneEach Elasticsearch index has one or more shards and each shard is a Lucene index. In Lucene the inverted index, stored fields, doc values and term vectors are independent data structures accessible and separated on a per field basis. Applying field level access control is required deep understanding of how Lucene works, and making sure they are not exposed. This means queries and aggregations on disallowed field are skipped, because these queries and aggregations think that the required field doesn't exist. For the end user there is no difference in querying a field that doesn't exist or a field that he or she isn't allowed to see, because the end result is the same, no results. This makes it very convenient to apply field level access control at the Lucene level instead of filtering queries \/ aggregations the request level and keys and values at the response level, which doesn't provide the same level of security. Implementing access control on the Lucene level has another benefit and that is that the logic is applied once for all Elasticsearch APIs the data is exposed. The same logic would be triggered if search request with a query and an aggregation is executed, when the get api is executed to fetch a particular document, when term vectors are requested for a particular field via the\u00a0\u00a0or when field stats are requested via the\u00a0. But wait, what about document level access control? Also the Lucene level is the right place to apply document level access control. A similar low level solution can be applied on Lucene level, where effectively, we can \u201chide\u201d documents from the rest of ES infrastructure making them inaccessible regardless of how they are called. Secure and shareSince we released Field and Document level security in Shield, it has been widely adopted by our users as it allowed our users to share data between different types of users at a level that wasn't possible before. We are very excited about the opportunities it opens up for our users, on Elasticsearch level, and Kibana. DemoIf you want to see Shield\u2019s field level security in action then follow the following demo to see how fields are secured. Download the latest Elasticsearch version, extract in a convenient directory and make this directory your current directory in the console. Install the License and Shield plugins by running the following commands: Add a\u00a0support engineer user that has the builtin admin role. The option assigns the user the role, which is a predefined role. The option sets the password of the user to . Add the following setting to the file which is located in the conf directory: shield.dls_fls.enabled: true Start Elasticsearch Add a sample document: curl -XPUT \"http:\/\/support_engineer1:changeme@localhost:9200\/ticket_index\/ticket\/1\" -d' { \"subject\" : \"Missing emails\", \"message\" : \"Last week when...\", \"severity\" : \"low\", \"time_spent_in_minutes\" : 5, \"escalated\" : false, \"private_notes\" : [\"This is likely caused by a bug\"] }' Run a sample query as user : curl -XGET \"http:\/\/support_engineer1:changeme@localhost:9200\/ticket_index\/_search?pretty\" -d' { \"query\": { \"match\": { \"severity\": \"low\" } } }' All fields are visible as can be seen in this response: { \"took\": 98, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"failed\": 0 }, \"hits\": { \"total\": 1, \"max_score\": 0.30685282, \"hits\": [ { \"_index\": \"ticket_index\", \"_type\": \"ticket\", \"_id\": \"1\", \"_score\": 0.30685282, \"_source\": { \"subject\": \"Missing emails\", \"message\": \"Last week when...\", \"severity\": \"low\", \"time_spent_in_minutes\": 5, \"escalated\": false, \"private_notes\": [ \"This is likely caused by a bug\" ] } } ] } } Add the customer role by adding the following yaml snippet with your favourite editor to the file in the Elasticsearch config directory: customer: indices: 'ticket_index': privileges: read fields: - subject - message - severity Add a customer user: Rerun the same sample query, but now as the user: curl -XGET \"http:\/\/customer1:changeme@localhost:9200\/ticket_index\/_search?pretty\" -d' { \"query\": { \"match\": { \"severity\": \"low\" } } }' The following response will be returned: { \"took\": 98, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"failed\": 0 }, \"hits\": { \"total\": 1, \"max_score\": 0.30685282, \"hits\": [ { \"_index\": \"ticket_index\", \"_type\": \"ticket\", \"_id\": \"1\", \"_score\": 0.30685282, \"_source\": { \"subject\": \"Missing emails\", \"message\": \"Last week when...\", \"severity\": \"low\" } } ] } } As can been seen field level security is active as only the allowed fields are returned. You can also try to query or aggregate on the other fields as and as you will find out no results will be returned and if you switch back to all fields are then visible and accessible. \n"}
{"index": {"_id": 745}}
{"title":"Kibana 4.4.0 is eye meltingly colorful","seo_title":"","url":"\/blog\/kibana-4-4-0","author":{"name":"Court Ewing"},"date":"February 02, 2016","category":"Releases","locales":"","content":" Kibana 4.4.0, with support for Elasticsearch 2.2.0 has landed. There are oh so many changes and we totally understand if you can't contain yourself and are just too impatient and just absolutely need to download it right now.\u00a0If you\u2019re already sick of all these words, grab the right now. But hey, you might want to try some breathing exercises, slow down a bit. Now then, take a deep breath, and walk with me through the magical forest of new features. So many colors\u00a0You want to select specific colors for your visualizations? Done. Click the legend for the value you want to change and BEHOLD the color palette! Not only that, but you can now filter legend values in or out with the click of a button. Shared URL shorteningDon't you love massive URLs? No? Huh, ok, well that explains this new feature. Kibana now has a built in URL shortener. Just click the shorten button and tah-dah, easily shareable tiny URLs RPMs, DEBs, oh my!\u00a0Get ready to simplify those deployment scripts, Kibana 4.4.0 is available as an RPM and Debian (and Ubuntu!)\u00a0packages. Check out the \u00a0for repo info! Shield your eyes!But that\u2019s not all! If you act now (or any time from this point onward), you can also start using the brand new , which is an infinitely better way to handle user logins. All that and more! Bug fixes Plugin stuffWell aren't you ambitious? We added some new plugin functionality. Feel free to hack around and ping us in #kibana on irc.freenode.net if you have questions. Go get it!That's it, that's all. You don't have to go home, but you can't stay here. Well, you can, but there's nothing else to read. And come to think of it, you should probably only go home if its not the middle of the work day for you. We're totally not taking the blame for you getting in trouble. Ok, so instead of going home, how about you upgrade to Elasticsearch 2.2.0 and ? If you make anything cool, share it with us . \n"}
{"index": {"_id": 746}}
{"title":"Elasticsearch 2.2.0, 2.1.2, and 1.7.5 released","seo_title":"Elasticsearch 2.2.0, 2.1.2, and 1.7.5 released","url":"\/blog\/elasticsearch-2-2-0-and-2-1-2-and-1-7-5-released","author":{"name":"Clinton Gormley"},"date":"February 02, 2016","category":"Releases","locales":"de-de,fr-fr,ja-jp,ko-kr","content":" Today we are pleased to announce the release of based on , and bug fix releases of , and . All of these new releases are already available on , our Elasticsearch-as-a-service platform. This week\u2019s release bonanza also includes new versions of , , , and .Elasticsearch 2.2.0 contains two awesome new features: a and greatly improved . It ships with and contains an important fix for a bug which caused slow shard recovery in Elasticsearch 2.1.0, along with .All users are encouraged to upgrade.Latest stable release:Bug fixes in 2.1:Bug fixes in 1.7.5: \n"}
{"index": {"_id": 747}}
{"title":"Beats 1.1.0 & Winlogbeat released","seo_title":"","url":"\/blog\/beats-1-1-0-and-winlogbeat-released","author":{"name":"Monica Sarbu"},"date":"February 02, 2016","category":"Releases","locales":"","content":" Today, we announce new versions of the entire Elastic Stack, including a tighter\u00a0 and an updated version of ES-Hadoop. Detailed blogs for product releases are available in the of the blog. And yes, the blog has categories -- you know, for searchability.Here are the highlights from the . For more details check out the . Winlogbeat: A new beat for Windows Event logsYou like Filebeat, but you want to also send Windows Event logs to Elasticseach? There\u2019s a Beat for that! It\u2019s called Winlogbeat, and you can download it from . Winlogbeat supports both the new and old styles of the Windows event log APIs, meaning that you can use it on any Windows version starting with XP. Just like Filebeat, Winlogbeat has a registry file that tracks which events were acknowledged by Elasticsearch or Logstash, so you don\u2019t lose events in case of restarts, network partitions, or Elasticsearch\/Logstash unavailability. Winlogbeat comes with a sample Kibana dashboard that you can use as a starting point for your customized dashboard. You can easily load the sample dashboards by using the load command described in the . Multiline supportA commonly requested feature for Filebeat is to be able to merge related log lines into a single event. Think of the way most applications dump their exceptions into logs. Wouldn\u2019t it be nice to have a single event per exception? This was already possible by using the Logstash multiline codec, but for many users, it\u2019s more convenient to configure multiline in the same file where they configure the file paths. The following example shows how to configure Filebeat to handle a multiline message where the first line of the message begins with a bracket ( ). multiline: pattern: ^\\[ negate: true match: after Filebeat takes all the lines that do not start with [ and combines them with the previous line that does. For example, you could use this configuration to join the following lines of a multiline message into a single event: [beat-logstash-some-name-832-2015.11.28] IndexNotFoundException[no such index] org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.resolve(IndexNameExpressionResolver.java:566) org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndices(IndexNameExpressionResolver.java:133) org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndices(IndexNameExpressionResolver.java:77) org.elasticsearch.action.admin.indices.delete.TransportDeleteIndexAction.checkBlock(TransportDeleteIndexAction.java:75 For more details about multiline, please check the . Filtering improvementsIt\u2019s now possible to very efficiently filter lines out in Filebeat by using regular expressions. So if you were, for example, using Logstash to drop all debug messages, you can save a lot of bandwidth and CPU power by doing the filtering at the source. You can configure Filebeat to drop all the log lines that match a certain regular expression or to include only the log lines that match a specific regular expression. To export any lines that start with or : include_lines: [\u201c^ERR\u201d, \u201c^WARN\u201d] To drop any debug lines that start with : exclude_lines: [\u201c^DBG\u201d] It\u2019s also possible to ignore files based on the file names. Filebeat handles this efficiently by simply not opening the matching files. To ignore all the files that have a extension: exclude_files: [\u201c.gz$\u201d] Beats dashboards for windows usersWindows users are now able to load the default Kibana dashboards by using the script. It has similar options as the load.sh script for Unix systems, so you can use -url for passing the Elasticsearch URL or -user to authenticate with Elasticsearch by username and password. Send us feedback!A big Thank You to everyone who contributed code, reported issues, created a new Beat or just tried the Beats. Start your experience with Beats 1.1.0 and let us know what you think on\u00a0,\u00a0, or open an issue on\u00a0. \n"}
{"index": {"_id": 748}}
{"title":"Logstash 2.2.0 and 2.1.2 released","seo_title":"Logstash 2.2.0 and 2.1.2 released","url":"\/blog\/logstash-2-2-0-and-2-1-2-released","author":{"name":"Andrew Cholakian"},"date":"February 02, 2016","category":"Releases","locales":"","content":" The release bonanza continues\u2026 Today, we announce new versions of the entire Elastic Stack, including a tighter of Shield with Kibana and an updated version of ES-Hadoop. Detailed blogs for product releases are available in the category of the blog. And yes, the blog has categories \u2013 you know, for searchability. Logstash 2.2.0 and 2.1.2 is available for today as part of the release bonanza! 2.2.0 release includes changes to the internal architecture of the pipeline, but is still backward compatible with old configuration. Read below for highlights, and check the for more details. Logstash 2.1.2 is mainly a bug fix release, and its changelog can be found . Next Generation Pipeline The single largest change in Logstash 2.2 release is the addition of the \u201cNext Generation Pipeline\u201d (also known as the \u201cNG pipeline\u201d). We\u2019ve fully re-architected the pipeline to provide more performance and pave the way for future persistence efforts. Where the previous pipeline processed one event at a time, the new pipeline works in micro-batches, processing groups of events at a time. Additionally, the filter and output stages now run as separate execution phases in the same thread, vs. running in separate thread pools. Check out the diagram below for a richer view of these changes. As illustrated above, the new pipeline first has each worker accumulate a batch of events before processing the filter + output stages. This batch has a maximum size of and will wait at most milliseconds from the last event taken from the queue to proceed with filter\/output processing. The new pipeline no longer has distinct threads for filtering and outputting as the old pipeline did, but rather runs the filter and output stage in sequence in each worker thread. You will most likely find that you need more worker threads to achieve the same throughput as the old pipeline\u2013perhaps even more than the number of real CPU cores\u2013but that these threads run much more efficiently. The reason you\u2019ll need more worker threads is that the output stage of execution is often idle waiting on IO while talking to, say, Elasticsearch or another remote service. We\u2019ve seen performance increases of up to vs. the original pipeline on real-world workloads. This comes from dramatically lowering overhead per-thread, and letting the OS scheduler smartly allocate resources. For an in-depth guide to tuning the NG pipeline, check out the revamped . Smarter Defaults, and Better Output management. We\u2019ve made managing the performance of outputs much simpler in Logstash 2.2 with automatic output worker scaling. With the NG pipeline an output worker works in a fundamentally different way than previous Logstash releases. Before, each output worker would get its own thread. This led to increased cross-thread communication and context switching and was less efficient, in addition to complicating future persistence work. In the NG pipeline the number of output workers determines how many instances to fill an output worker \u2018pool\u2019 with. Output instances are pulled from this pool by pipeline worker threads as needed. In previous versions of Logstash the default number of output workers was 1. In Logstash 2.2 this number is by default the number of pipeline workers, which now default to be equal to the number of cores on the system. So, if you have a four core system expect to see four pipeline workers with four output \u2018workers\u2019 available.This is actually a conservative number for the NG pipeline, as these threads are often idle when in I\/O wait. Be sure to read the for the full story on tuning values here. The internals of the output stage of logstash have changed quite a bit as well, in ways that have significant implications for both users and plugin authors. Output plugins are now encouraged to implement as the primary interface for receiving events, and are discouraged from managing their own buffers. When run with Logstash 2.2 the Elasticsearch output will no longer use a special internal event buffer, but rather use to receive events in the batch size the pipeline is using. This was a hard requirement to move us closer to persistence, and should also simplify user\u2019s mental model of Logstash (no having to worry about buffers inside of individual plugins). Plugins that manage their own internal buffers will never be able to correctly persist events and guarantee no data loss in the event of a crash. We also added the ability to declare plugins as fully threadsafe, meaning a single instance would be shared across all pipeline workers, allowing plugin authors to manage their own locking for even greater performance. Threadsafe plugins ignore any \u2018workers\u2019 settings a user might provide, because that number is effectively infinite. We also have improved the API for declaring plugins as not allowing for more than one worker. You can find the details in the revamped page. Elasticsearch Output Enhancements Bundled with Logstash 2.2 is the newest version of the Elasticsearch output, designed to work optimally with the NG pipeline, while remaining backward compatible with older 2.x Logstash releases. This version has a vastly simplified and more correct algorithm around retry handling. In this new release each batch going through the NG pipeline blocks until all operations that do not produce unrecoverable errors succeed. This means that network connectivity errors, s, and s are retried indefinitely now. Previously, the plugin retried these a limited number of times, but we\u2019ve decided to err on the side of data preservation here. Additionally, 409 conflict handling is now only retryable via the parameter. Elasticsearch output now supports scripts to update documents (thanks to for the contribution). New config options to set the script, language, and variable name have been added. Deprecating Support For Node Protocol We would like to announce that Elasticsearch node protocol will no longer be actively developed and no new features will be added. In 2.0 release, we changed the default communication protocol from to . This change makes it operationally easy to run Logstash and Elasticsearch, and provides out of the box support for newly released Elasticsearch versions. More details can be found in our post . Bug Fixes Below we highlight some of the bugs fixes in this release: Feedback Many thanks to our users and contributors for making 2.2.0 a successful release. Please the GA binaries and give it a spin! Let us know what you think on our , IRC, and . \n"}
{"index": {"_id": 749}}
{"title":"Elasticsearch for Apache Hadoop 2.2.0 and 2.1.3 released","seo_title":"Elasticsearch for Apache Hadoop 2.2.0 and 2.1.3 released","url":"\/blog\/es-hadoop-2-2-0-and-2-1-3-released","author":{"name":"Costin Leau"},"date":"February 02, 2016","category":"Releases","locales":"","content":" The release bonanza continues\u2026 Today, we announce new versions of the entire Elastic Stack, including a tighter of Shield with Kibana and an updated version of ES-Hadoop. Detailed blogs for product releases are available in the category of the blog. And yes, the blog has categories \u2013 you know, for searchability. I am pleased to announce that ES-Hadoop is joining the release bonanza through the GA release of Elasticsearch for Apache Hadoop (ES-Hadoop) and the bug fix release of ES-Hadoop . As always, the artifacts are available at the and or . Highlights in ES-Hadoop 2.2 Bug-fixes aside, ES-Hadoop 2.2 introduces a series of new features: GA release compatible with ES 2.x ES-Hadoop 2.2 is officially compatible with Elasticsearch 2.x while backwards compatibility with Elasticsearch 1.X (though we really upgrading). ES-Hadoop automatically detects the target Elasticsearch version and act accordingly without any user intervention. Overhauled geo support Similar to Elasticsearch, support has been overhauled in ES-Hadoop 2.2 - not only and types are properly detected, but also their schema is inferred (despite being over a dozen data formats across both types). Network improvements ES-Hadoop 2.2 introduces support for Elasticsearch environments where access is done only through one central point. This extends the number of topologies that ES-Hadoop works with, along side client-node only and direct connection. The latter scenario has also been optimized by specifically routing traffic only to data nodes and filtering out master nodes. The configuration options have been improved to allow configuration of the JVM HTTPS proxy along with resolving of hostnames to IPs (useful when using Elasticsearch with network publishing enabled). Better runtime diagnostics To prevent user error and misconfigurations, ES-Hadoop 2.2 introduced classpath checks to make sure only one version is used at a given time: this alleviates scenarios where different versions of the project are deployed leading to an unsupported scenario. Further more, incorrect usage of libraries (such as saving a without the Spark SQL support) are also reported. Apache Spark 1.5 and 1.6 support ES-Hadoop 2.2 tracked the releases of all its libraries, in particular those of Apache Spark, in both cases leveraging the new features added such as or the simplified \u201ces\u201d , both available in Spark 1.5 or eliminating (Spark 1.6). All while still with the previous versions of Spark. Such features provide not just richer constructs for the user but also improve performance by to Elasticsearch more and more of Spark SQL. Extended configuration options The support for multi-dimensional fields (arrays) has been enhanced as one can now specify upfront the dimensions for a given field (whether nested or not), quite useful in strictly typed environments (like Spark SQL) especially when the data does not conform exactly to its declaration. Additionally, options to include or exclude certain fields as long as the number of documents being read were added. YARN enhancements A batch of updates were done to the YARN module by upgrading to Elasticsearch 2.2.x and introducing the option for the JVM system properties to be passed directly to the children container. Repository HDFS is moving soon The HDFS snapshot and restore plugin (repository HDFS) has been and is undergoing a overhaul in terms of security. Shout out to for his support in making this happen. It has been quite an effort considering Hadoop is with the Java Security Manager, simply asking a plethora of permissions with many of them way too dangerous (such as execute on all permissions during a basic startup). The is for the plugin to be officially part of Elasticsearch proper as an official plugin in an upcoming release. Until that happens, it is still available as part of the ES-Hadoop project. More about it, in a future blog post. Improved reliability While not something tangible to the user, behind the scenes ES-Hadoop 2.2 has increased its test suites by 50% (!) closing to over 4900 tests. The plan is for the next major release to pass over the 5K threshold. Last 2.1.X release Along side 2.2, ES-Hadoop 2.1.3 is released as the last planned maintenance release in the 2.1.X line. It contains a series of backported bug-fixes for those with conservatory upgrade paths. However even if you are on ES 1.x, upgrading to ES-Hadoop 2.2 is highly recommended. Feedback Looking forward to hearing your feedback on ! You can find us on , Twitter () or the . works too. \n"}
{"index": {"_id": 750}}
{"title":"Brewing in Beats: Redisbeat from community","seo_title":"","url":"\/blog\/weekly-beats-redisbeat-community","author":{"name":"Monica Sarbu"},"date":"February 01, 2016","category":"Brewing in Beats","locales":"","content":" Welcome to Weekly Beats! With this series, we're keeping you up to date with all that's new in\u00a0, from the details of work in progress pull requests to releases and learning resources. Last week we continue working on the big features that will be available in the next major release: add in Packetbeat and in libbeat. Beside these features, we are improving continuously the documentation based on our users feedback. The highlights this week are: New community Beat: Redisbeat is used for Redis monitoring. It is a lightweight agent that periodically reads the status from the Redis INFO command. It exports general information about the Redis server, about the clients, memory statistics, persistence statistics, redis general statistics, replication statistics, CPU statistics, Redis commands statistics, cluster statistics and keyspace statistics. Enhancements in PacketbeatWe are thrilled to receive two big pull requests this week from the community to and in Packetbeat. Big Thank you to the contributors and we will do our best to merge them as soon as possible. Enhancements in TopbeatTopbeat adds more information to the running processes. It now exports the username that started the process. This information might be useful in case the same command is started by different users and username seems to be the only way to differentiate between them in the Kibana dashboards. This enhancement is available on Unix and Windows systems and the implementation can be found . \n"}
{"index": {"_id": 751}}
{"title":"This Week in Elasticsearch and Apache Lucene - Cluster Cloning in Hosted Elasticsearch","seo_title":"This Week in Elasticsearch and Apache Lucene - Cluster Cloning in Hosted Elasticsearch","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-cluster-cloning-hosted-elasticsearch","author":{"name":"Michael McCandless"},"date":"February 01, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsJust how easy is it clone your cluster in our hosted service? (Hint: very) \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole Elastic\u00a0ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 752}}
{"title":"Logstash Moving Away from Node Protocol and Multiline Filter","seo_title":"Logstash Moving Away from Node Protocol and Multiline Filter","url":"\/blog\/logstash-moving-away-from-node-protocol-and-multiline-filter","author":{"name":"Alvin Chen"},"date":"February 01, 2016","category":"Engineering","locales":"","content":" The Logstash project has been constantly evolving and seeking out novel ways to become more robust and feature rich. At this juncture, it\u2019s time to leave certain legacy things behind to make life easier both for Logstash users and developers. The topics to be outlined in detail here are the node protocol for Elasticsearch output and the multiline filter. Below is a brief overview of the Elastic recommended migrations for these respective components. Discouraging the Node Protocol The node protocol for the Elasticsearch output plugin has been a formidable pain for both Logstash users and developers. It\u2019s tough to debug and difficult to maintain. In Logstash 2.0, the as it\u2019s very fast and possesses a much better operational experience. Additionally, a is coming soon which will circumvent any use cases where the node protocol was previously used as a way to monitor Logstash node health. Lastly, the node protocol isn\u2019t supported for communication with protected Elasticsearch clusters. Therefore, usage of the node protocol is now discouraged, and it\u2019s strongly recommended for any current users of this protocol to migrate to the HTTP protocol in the next few months prior to the next major Logstash release. The HTTP protocol with Logstash is also the easiest way to ingest data into your clusters on - the best hosted Elasticsearch solution. For any questions or concerns, please feel free to discuss in this . Deprecating the Multiline Filter Historically, there\u2019s been two different ways to process multiline events in Logstash. In the last couple months, the has been strengthened on various fronts, inclusive of an enhancement which reconciled the stream identity bug. In order to mitigate confusion between the usage of the codec and filter plugins, the single-threaded multiline filter will effectively be deprecated at the Logstash 2.2 GA. As multiline events are best processed earlier in the pipeline, it\u2019s strongly recommended to migrate to the more scalable multiline codec in the next few months prior to the next major Logstash release. Additionally, if you\u2019re using the awesome, lightweight platform for shipping your data, this can also be done on the edge with . For further details, please review this . \u200bMany exciting things are happening in Logstash land and we\u2019ll be talking about them in detail at our user conference in San Francisco, CA. Please join us to learn more about the Elastic stack and network with many other enthusiastic Elastic users! \n"}
{"index": {"_id": 753}}
{"title":"Where in the World is Elastic? - OOP Konferenz 2016 & linux.conf.au","seo_title":"Where in the World is Elastic? - OOP Konferenz 2016 & linux.conf.au","url":"\/blog\/witwies-oop-konferenz-2016-linux-conf-au","author":{"name":"Megan Wieling"},"date":"February 01, 2016","category":"","locales":"","content":" Welcome to Find out which Elastic events and meetups are happening near you this week.\u00a0 Upcoming Events February 1-5: February 1-5: Upcoming Meetups February 2: February 3: February 3: February 4: February 5: February 1: February 2: February 2: February 4: February 2: That's it for this week. Stay tuned next week for more Elastic happenings. - The Elastic Team P.S.\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}
{"index": {"_id": 754}}
{"title":"Cluster cloning in the cloud","seo_title":"","url":"\/blog\/cluster-cloning-in-the-cloud","author":{"name":"Konrad Beiske"},"date":"January 29, 2016","category":"Engineering","locales":"","content":" This article refers to\u00a0our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud.One of the advantages of using a SaaS offering is flexibility for on-demand scaling. With Found this means you can create and delete clusters as you like and only pay for the hour APIs they\u2019re running. Building on the Snapshot and restore API of Elasticsearch, Found makes it easy to duplicate a cluster. In this blog post we will see how this works and how it may be used in a few different scenarios. Finally we will have a brief look at how it is implemented which will also serve to show why the clone operation has absolutely no performance impact on the source cluster. Use casesA common denominator in all of these use cases is that they benefit from the isolation that a separate cluster provides, whether that is isolation of hardware resources or data resources. Ad hoc analyticsFor most logging and metrics use cases it is cost prohibitive to have all the data in memory, even if that is what provides the best performance for aggregations. Cloning the relevant data to an ad hoc analytics cluster that can be discarded after use can be a very cost effective way to experiment with your data, and at the same time without risk of hurting performance in production. Test upgradesThe safest way to check that both your indexes and your application is ready for the next Elasticsearch version is to copy the indexes to a new cluster and test the entire upgrade path by first upgrading Elasticsearch and then making sure that your application works. Enable your developersRealistic test data is crucial for uncovering unexpected errors early in the development cycle. What can be more realistic than actual data from the production cluster? Giving the developer team access to experiment with real production data is not only great for breaking down silos, but may also provide new insights about the domain. A safe and isolated playground is the essential benefit for this use case. Test Mapping changesMapping changes almost always require reindexing. Unless your data volume is trivial it also takes some time. Tweaking the parameters to achieve best performance usually takes a little trial and error. While this use case could also be handled by running the scan and scroll query directly against the source cluster, it is worth noting that a long lived scroll has the side effect of blocking merges even if the scan query is very light weight. Integration testingTest your application against a real live Elasticsearch instance with actual data. If you automate this, you could also aggregate performance metrics from the tests and use those metrics to detect if a change in your application has introduced a performance degradation. How to clone a clusterThe steps required: Prepare the target clusterIn order for the restore to be successful the target cluster must meet the following conditions: Both clusters have to be in the same region in order to have access to each others backups. In most cases any Elasticsearch version equal to or higher than the version of the source cluster will be compatible. The exception is if upgrading more than one major version at a time as Elasticsearch then might not have a Lucene version capable of reading the indexes. Same thing happens when an index originally created on an Elasticsearch version older than the current version have segments written in an old Lucene format, but this is usually not a problem as the the format is upgraded automatically during merges. The target cluster is not required to have all the plugins and dictionaries of the source cluster, just the ones required to open the cloned indexes. In practice this means any dictionary or synonym file referenced by a custom analyser in any of the indexes, aka user bundles on the cluster config page. Slightly less common, but just as hard a requirement is if any of the indexes use a custom field type provided by a plugin like mapper-attachments or murmur3. The final requirement of the target cluster is that it doesn\u2019t have any conflicting indexes defined. If any of the indexes to be copied already exist in the target cluster they must either be deleted \/ closed before issuing the restore. Optionally you may use a rename pattern when issuing the restore to have the indexes restored with a different name. Selecting the snapshotThe cluster cloning capabilities on Found is really an extension of the automated backup service that issues a snapshot every 30 minutes. To select a snapshot, sign in to the console on\u00a0\u00a0and go to the clusters page. There you will find a \u201cSnapshots\u201d item for each of your clusters in the left hand menu. The snapshots page lists each snapshot by timestamp. Click on one and it takes you to the restore snapshot page. Issue a restoreOnce you\u2019ve selected a snapshot to restore from, you should see a form with the fields indexes, rename pattern, rename replacement and cluster. Things included and not includedIndexes and index settings are included, but cluster settings are not. This decision is a consequence of the fact that the indexes may be restored to a cluster with a very different plan, but it can be an important distinction to be aware of if performance testing reveals different results between different clusters. Another consideration for performance comparisons is that copying indexes from one cluster to another with the snapshot and restore API is not the same as copying indexes with a scan\/scroll query and bulk indexing. The former copies Lucene segments and the latter JSON documents. If the source index has segments in an old Lucene format, these are not modified, but copied as they are. Under the hoodFor every restore to a different cluster issued by the found console, three things happen: One important takeaway here is that the data is not transferred from the source cluster when the restore is issued, but copied from the backup in S3. This means that issuing a restore to a different cluster will not have any performance implication on the source cluster. After the restore is complete, the repository in the target cluster is not removed, making it easy issue another restore through the Elasticsearch API. If you would like to include this initialization in a script, the steps required are described in our\u00a0. ConclusionAt the Found team we aim to provide all the cool features in Elasticsearch in combination with the ease and flexibility of a good SaaS offering. If you have any suggestions, we would love to hear them on\u00a0. \n"}
{"index": {"_id": 755}}
{"title":"Using Nmap + Logstash to Gain Insight Into Your Network","seo_title":"","url":"\/blog\/using-nmap-logstash-to-gain-insight-into-your-network","author":{"name":"Andrew Cholakian"},"date":"January 28, 2016","category":"Engineering","locales":"","content":" In this post we\u2019ll look at a brand new logstash codec plugin: . This plugin lets you directly import scan results into Elasticsearch where you can then visualize them with Kibana. Nmap is somewhat hard to describe because its a sort of swiss army knife of network tools. It crams many different features into a single small executable. I\u2019ve put together a small list of things you can do with Nmap below, though it is by no means complete! Using Logstash, Elasticsearch, and Kibana you can create neat dashboards, like the one I have for my home LAN below: Monitoring Host Availability with Nmap Let\u2019s start by just poking around with some Nmap basics. Let\u2019s say we simply want to check if a host is up or not with an ICMP ping. We can do this by simply running . You should see the output below: You may be wondering why we need to run our ping command with . The reason is that ICMP ping packets be sent as root, otherwise the method will be used. This is on most platforms. While the output here is nice and human readable, it is not something Logstash can parse. To get machine readable XML output you\u2019ll need to use the option, which if is used for the filename redirects to stdout. Let\u2019s try running . You should see the same output, but with more verbosity and in XML format. Now that we\u2019ve got our bearings let\u2019s setup a Logstash server to receive this data. To understand this setup let\u2019s quickly recap what a Logstash codec is. Logstash codecs simply provide a way to specify how raw data should be decoded, regardless of source. This means that we can use the Nmap codec to read Nmap XML from a variety of inputs. We could read it off a message queue or via syslog for instance, before passing the data on to the Nmap codec. A very flexible solution for a lot of people is to use the . This input sets up a webserver inside the logstash process which listens for requests and turns the request body into a Logstash event\u2013in our case using the nmap codec. For now we\u2019ll use a the output on to let us see the parsed nmap data. Try out the config below: Then, in your Logstash folder, run . Once you have the Nmap codec installed you can start logstash with . Logstash is now ready to watch for Nmap XML on port 8000. You can send a simple ping by running the following in your shell. We\u2019ll use cURL to transport the Nmap XML to Logstash. Note that we\u2019re using with Nmap to send XML to stdout, and to set stdin as the request body for our request. We\u2019re also setting a custom header: .The Logstash HTTP input will make this header available to us as part of our events. After sending this request you should see a bunch of output in your terminal from logstash. There should be two Logstash events in your terminal now, one with a of , the other (note that this \u2018type\u2019 field is distinct from the Logstash convention of \u2018@type\u2019). You should also see a bunch of HTTP metadata from the HTTP input, including our custom header. Nmap Codec Event Types OK! So, now we know how to get some basic info out of nmap. Let\u2019s take a deeper look at the data coming out of the Nmap codec, which does some restructuring and denormalization of the Nmap XML. Since we did a ping scan these were the only types of event created. However, for richer Nmap scans more types are created, the types are listed below: A Small Network Monitor Using the Elasticsearch output and Kibana we can setup a more fully featured example. This is something I run on my own home network to check a few different things. Here we\u2019ll use some of Nmap\u2019s more powerful features, the ability to target an entire subnet at once. My home network runs on the subnet 192.168.1.0\/24, for instance. We can turn all pretty much all the useful options with the flag, which will per the giving us the command below. . In the line above we\u2019ve used a different descriptive HTTP header in this example. We could use this in our Logstash configuration to help divide and filter the output of different cURL commands, though in this case we will not. Next, to put this into Elasticsearch in a sane manner we\u2019ll need an . Luckily, I\u2019ve created one that handles the necessary document types for this demo, which you can find . You\u2019ll want to download this file somewhere locally, then point to it in , where is specified. Since this mapping template is so radically different than the default Logstash template we\u2019ve configured the Logstash Elasticsearch output to send data to timestamped indexes prefixed with , instead of the usual , to prevent template collisions. If you put that in place with a simple cronjob and let it run for a while you\u2019ll see some interesting results in your network over time. After we have some data we can run some tests and see what we get! Loading the results up in Kibana I can use this data to break down OSes on my network over time, like so: You could also use this data to chart your typical outbound network routes by aggregating based on the in the produced documents, as well as correlate that with those link\u2019s RTT. There\u2019s a rich set of data in these documents, too rich to go into detail here. I highly recommend browsing the details of the output to see what\u2019s possible. Visualizing Outbound Routes We might also be interested in our outbound connectivity, not just what\u2019s live on the network. We can use Nmap to both help us discern our outbound routes via traceroutes, as well as determine if we\u2019ve lost connectivity to the outsound world. To do that we\u2019ll need to, as you might imagine, hit some targets outside our network. We can do this by running the following Nmap command: This will test if we can ping the outside world, and provide a traceroute that could be helpful in diagnosing network problems as well. If you put this in cron along with the previous command you can check for host uptime, ping time, as well as the latency for all hosts along the path. Next Steps This module is in its early stages! Look for more from me regarding this codec in coming blog posts. \n"}
{"index": {"_id": 756}}
{"title":"W\u00dcRTHPHOENIX NetEye: Our Elastic Stack Story","seo_title":"W\u00dcRTHPHOENIX NetEye: Our Elastic Stack Story","url":"\/blog\/elastic-stack-at-wurthphoenix-neteye","author":{"name":"Georg Kostner"},"date":"January 28, 2016","category":"User Stories","locales":"de-de,fr-fr","content":" This article was published on on January 27. Market Requirements \u2013 Why Log Management?It all began with the new decree (the \"Garante per la protezione dei dati personali\") issued by the Italian data protection authorities in 2008. This regulation ( | )\u00a0stipulates that all companies must log all administrators' system access data and keep them archived for at least six months. This approach is intended to facilitate and standardize the monitoring of system administrators' activities and, above all, protect sensitive company data. In other words: Security Auditing. Carrying out a detailed analysis of the requirements stipulated by the data protection authorities allowed us to identify the following four categories: In 2010, we were therefore faced with the challenge of providing our customers with an appropriate solution for all these categories within our NetEye IT Systems Management solution. Existing Options \u2013 What was already available in the world of open source?As our NetEye monitoring tool is based on a number of open source modules, it seemed a natural first step for us to take an in-depth look at the existing options in the world of open source. We wanted to find out about the tools that were already available for gathering log data. Our research revealed that Snare and Epilog were suitable for collecting logs. This combination presented some limitations, however: After analyzing these weaknesses, we came to the conclusion that we were not prepared to put up with such shortcomings. We therefore decided to develop our own agent. The SAFED (ecurity uditing orwardr aemon) agent we created was based on Snare and Epilog and was made available to the community as a new option for collecting logs. []. We decided to use rsyslog to capture events in Linux. In the first version, we settled on Solr from Apache for the indexing of logs. We also developed our own interface to search logs via Solr. All this meant that we were extremely well equipped to face the demands of 2010. Added Value \u2013 We want more!Although our solution enabled compliance with the prescribed directives, it did not present any particularly large advantages for IT management. We were therefore very keen to develop our solution further so that it would provide our customers with additional benefits in terms of IT service management. Customer feedback allowed us to get to know the more sophisticated requirements in the world of log management and security information and event management (SIEM). Before we knew it, our task was no longer just about gathering and archiving logs. Instead, we were faced with a new list of demands: The combination of the SAFED agent, rsyslog and Solr was no longer sufficient. We thus began searching once again for suitable tools to adapt NetEye to the new market requirements. We came across the\u00a0Elastic Stack in January 2014. Our developers spent a good amount of time evaluating it and detected an opportunity to expand NetEye into a fully-fledged log management solution with the help of the Elastic Stack. We elected to integrate the Elastic Stack into NetEye. The main reasons for this decision were: [To be exact, in the interim we used Grok as a parser, which was technically quite complex. When Grok was integrated into Logstash, it became easier to use. This was a further argument for the integration of the Elastic Stack.] Our web search interface was replaced with Kibana. Solr gave way to Elasticsearch. From that point on, we used Logstash as a log parser. In addition, Elasticsearch allowed us to carry out aggregation and indexed searches.\u00a0 The only thing we still lacked for the essential SIEM functions was an event handler, an element that reacts proactively to event inputs and, depending on the type of incident involved, triggers a specific action. We developed the NetEye Event Handler to gather Syslog events, e-mails, SNMP traps, and SMS messages and assign appropriate actions using a \"rule matching engine\". (You can find more details on the NetEye Event Handler by visiting our ). The Result \u2013 We're proud of what we've achieved!Our in-house developments and the integration of the Elastic Stack resulted in the release of NetEye 3.5 with a comprehensive log management module in 2014. This tool gathers, indexes, and aggregates events. It also enables individual searches and can react to all events automatically. We are pleased with the result and are happy that our clients no longer have to limit themselves to following the data protection directives. Instead, they now have all of the advantages of a at their disposal. The Future \u2013 There's still a lot to do!Software MeteringWe realized that there are a great deal more fields of application that we can cater to using the foundations we have created. We currently have customers requesting the ability to display application metering. In more specific terms, this refers to software metering using a Citrix Farm. We use our SAFED agent to gather events for this purpose (application start \u2013 end per user). The events are then stored in Elasticsearch and presented via the Kibana dashboard. This example underlines once again how flexible NetEye log management is when based on the Elastic Stack. Network Performance MonitoringIn the field of Network Performance Monitoring, we measure the usage of networks by gathering NetFlow data with the help of our nBox appliance. There is also potential here to store the collected NetFlow data directly in the Elastic Stack. Logstash is capable of receiving NetFlow v5 and v9 (we had to make a few improvements to NetFlow v9, but these were relatively uncomplicated). NetFlow dashboards can be presented in Kibana 4. As the Kibana dashboards are so powerful in terms of navigation and aggregation, they present the IT world with a plethora of possibilities. This is where the next group of challenges comes knocking at our door. How well can Elasticsearch deal with millions of NetFlow flows? We have deployed our network probes in 10G networks where millions of such flows arise every second. Performance Data at the I\/O LevelA further project we want to address is the collection of performance data in a VMWare ESX environment and in SAN systems at the I\/O level. In this project, we will select data from the VM using VMWare SDK, Datastore and Lun, and thereby identify the Top Talkers of the VM(s). This allows an admin to see immediately which VM is generating an extreme amount of I\/O load on the SAN. Should several SANs (and also various manufacturers) be present, the admin won't lose track and will be able to find an answer to his\/her question in a reasonable amount of time. SummaryTo conclude, I would like to say that we have only begun to scratch the surface of the potential applications of the Elastic Stack within NetEye. It will be exciting to see which market demands can be met using the Elastic Stack in the future. New possibilities and fields of application for such a flexible technology are also constantly emerging in the community. \n"}
{"index": {"_id": 757}}
{"title":"Brewing in Beats: Beat generator","seo_title":"","url":"\/blog\/weekly-beats-generator","author":{"name":"Tudor Golubenco"},"date":"January 27, 2016","category":"Brewing in Beats","locales":"","content":" Welcome to Weekly Beats! With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources. Quite a few things going on while we\u2019re working on the next major and preparing for Elastic{ON}. This week also brings us a new community Beat. Beat generator: template for creating a new Beat We started , a new project that makes it a lot easier to start a new Beat. One command and you get all the boiler code required, the Makefile to build it, a correct Go dependency setup and a way to keep up to date with the libbeat changes (: ). We hope to not only make it easier to start new Beats, but also to have a more unified dev process around the community Beats. \u00a0 If you plan to create a new Beat, we recommend using it already. New community Beat: Elasticbeat It was bound to happen, a community Beat to monitor Elasticsearch: . We\u2019ll be following this one for sure. Improved system testing Also on the theme of making it easier for the community Beats creators, the system tests were refactored to avoid duplication and to be importable from new Beats. In addition, they were improved to automatically fail on panics in the logs or on non-zero exit code from the Beat. Special thanks go to community contributor , who proposed several improvements and helped with implementing them. Filebeat: introduced close_older setting The ignore_older setting in Filebeat used to do , which used to cause issues because sometimes there was no single value convenient for both. This splits them and also changes the defaults. ignore_older is now disabled by default and close_older is set to one hour. Topbeat: added support for capturing the full command line Topbeat used to only collect the process name, now it captures the full , which was an often requested feature request. This also works on Windows! Performance improvements in the publisher pipeline We\u2019ve talked in the past about the performance issues we\u2019re having on the \u201cat-least-once\u201d communication between Filebeat \u00a0and Logstash. It\u2019s a fairly difficult issue because the Beat needs to balance between sending large batches fast to increase throughput and being able to reduce the output when Logstash is busy. We refactored the code and while waiting for the current one to be ACKed. This helps with the overall throughput by enabling load balancing between multiple output threads, at the cost of memory usage. With the right settings and enough memory and CPU power, we\u2019ve seen Filebeat pushing around 45K events\/s, compared to around 18K before this change. Freebsd and Solaris are now part of our CI Jenkins now runs the tests on these two new platforms, which is the first step in supporting them. All tests from Filebeat and Packetbeat are passing already. Topbeat would require more work. Work in progress on generic filtering in libbeat Monica is making on the generic filtering feature in libbeat, from which all Beats are expected to benefit. For the moment it is possible to filter fields from a generic event, which already covers a lot of the feature requests that we received. Work in progress on Packetbeat flows Steffen on a very promising Packetbeat feature, ability to extract information about TCP\/UDP\/TLS flows for which we don\u2019t understand the upper layers. This should open a new set of possible use cases for Packetbeat. \n"}
{"index": {"_id": 758}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-01-25","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-01-25","author":{"name":"Michael McCandless"},"date":"January 25, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsBuilding an image search engine with deep learning and : \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole Elastic\u00a0ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 759}}
{"title":"Where in the World is Elastic? - OSC2016.Enterprise","seo_title":"Where in the World is Elastic? - OSC2016.Enterprise","url":"\/blog\/witwies-osc2016-enterprise","author":{"name":"Megan Wieling"},"date":"January 25, 2016","category":"","locales":"","content":" Welcome to Find out which Elastic events and meetups are happening near you this week.\u00a0Upcoming EventsJanuary 29: Upcoming MeetupsJanuary 25: January 26: January 27: January 27: January 25: January 25: January 27: January 28: January 31: January 28:\u00a0That's it for this week. Stay tuned next week for more Elastic happenings.- The Elastic TeamP.S.\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}
{"index": {"_id": 760}}
{"title":"Elasticsearch Queries, or Term Queries are Really Fast!","seo_title":"Elasticsearch Queries, or Term Queries are Really Fast!","url":"\/blog\/elasticsearch-queries-or-term-queries-are-really-fast","author":{"name":"Nik Everett"},"date":"January 21, 2016","category":"Engineering","locales":"","content":" I remember a couple years ago I was at a convention talking to folks about Elasticsearch or Lucene and one of them said something like \"Everyone knows that if you really want to search fast you need to just use term queries.\" He was certainly right about term queries being fast but I really wanted to run some numbers and see just how right he was. And that felt like a good time to write a blog post to help with the \"everyone knows\" part. Term queries are really fast Term queries are pretty fast! On my development desktop with a single spinning disk I get 8,000 searches containing a single term query a second. Once you start adding multiple terms to the query it gets faster if they are ed together and slower if they are ed together. This is because OR queries find more hits and scoring and counting those hits takes more time. We can control for this using . If is set then each shard stops searching as soon as it has hit that many results. If the document that would have had the best score wasn't hit because the shard terminated early then it's just not returned. If you are sorting by something other than score this is still a problem because the documents aren't encountered in a useful order. It also breaks the total hit count because each shard stops counting after hits. On the other hand it really improves the performance of unselective queries so it's worth thinking about even though it'll only be appropriate for somewhat niche use cases. Values of less than 10,000 make s faster than s and values greater than 10,000 make s faster than s. In my dataset. With my two term queries. This is because s accept every candidate document so they have to find fewer candidates. Testing methodology Now a note about testing methodology: this isn't super scientific. I'm using a rather old dump of English Wikipedia's search index for its content namespaces (available , the file looks like ). How to load your own copy would be a great topic for another .... Anyway! I'm using for generating the actual load which uses a Lua script to generate the queries. The terms I'm using for the queries come from . I'm running both wrk and Elasticsearch on the same machine. I'm using a single shard and all the default arguments for Elasticsearch 2.1.1 including its 1GB heap. So I have about 30GB of free memory for Linux to use for the page cache. Every query I run has so I don't spend time loading the , highlighting, or any of that stuff that a real search has to do. After loading the index I d it which is totally cheating. A real production system can't optimize an index that is always changing and Wikipedia is always changing. But the index is 124GB and my development desktop's SSD only has 101GB of space total so I'm having to use my spinning drive, a 1TB WD Blue spinning at 7200RPM. If I don't optimize I very quickly saturate the poor disk and my tests just show that I need to buy a better disk. Which doesn't make for a great blog post. I want to talk about the CPU overhead of these queries and optimize does a good job of making that possible. But take everything here with a grain or two of salt. Benchmark for yourself. My goal is to put you in the right ballpark. I use for all of my queries because it's convenient. I don't believe you should use for queries sent by users because it's too powerful and too brittle but it super convenient for my lua query generator to just generate a string query rather than worry about generating JSON. Various query types All being said, have a look at the graph above which compares some different types of queries. A couple of things: first and foremost I've shifted this graph to log scale. Sorry! Without doing that the fast queries just overwhelm the slow queries and you can't see anything. The horizontal axis is how frequently the term comes from a list of \"common\" words. All queries contain just two words. This doesn't use . Finally, I'm using a home grown notation for the query types. Its short and super readable if you are me but in case you aren't: A couple things jump out at me: makes them faster Above is the same chart of different query types, this time with set to . I picked because its pretty that inflection point between and which just seemed fun. I also kept the same range on the horizontal axis. Here is what I noticed: Configured queries You'll notice that I ignored phrase slop when talking about phrase queries. Its because the slop value doesn't really matter. A slop of 0 is faster than a slop of 1 but beyond that all slops are just as fast as one another. i also skipped over of in the graphs above and only had and . Its not super clear to me why, but has the same performance as . As expected the longer the prefix on the prefix query the faster it finishes. Here is as good a place as any to describe how I build these prefix queries because its important that you know: I use the random word picker to get a word, slice it down to the prefix length or smaller if it was fewer code points than the prefix length, and then I make a prefix query out of it. This mixes in shorter prefix queries with longer ones which artificially depresses the scores, especially closer to the right hand side of these graphs which have more common, shorter words. For a while I was using the word picker over and over again until I got a long enough word. This artificially increased the scores of long prefixes because they found far fewer documents than the term queries I was comparing them against because the term queries contained more shorter, more common words. The moral of this story is that graphs hide lots of complexity. Conclusion So my advice: \n"}
{"index": {"_id": 761}}
{"title":"Share your community spirit with #ElasticSnap","seo_title":"Share your community spirit with #ElasticSnap","url":"\/blog\/share-your-community-spirit-with-elastic-snap","author":{"name":"Michelle Carroll"},"date":"January 21, 2016","category":"Culture","locales":"","content":" Here's something you may not know about Elastic: During new employee training, we have a fun tradition of sharing pics of ourselves with the theme of an . It's inspired by our CTO's affinity for black t-shirts, and the fact that all the newbies have just received their first wearable Elastic swag. All around the world, folks sport their Elastic gear in cool locations and share photos over chat. Our company is pretty distributed, and it's awesome to get a visual of all the different people (and places) flying the Elastic flag. With coming up fast, we're expanding this tradition to help visualize the Elastic community. After all, the event is the single largest face-to-face gathering of Elasticsearch users and knowledge. We want to see (and share) your best Elastic in the wild photos. How to participateWe're collecting high-res photos of the Elastic community using Elasticsearch, working on Elastic Stack projects, or just having fun, all while our t-shirts, logo stickers, or other be-clustered items are on display. There are two ways to join in on the fun: As always, only submit photos that you are comfortable (and have permission) to share publicly. Creativity is greatly appreciated \u2013 and welcomed :). Five participants will be randomly chosen to receive an Elastic cluster t-shirt, so get snapping! \n"}
{"index": {"_id": 762}}
{"title":"Elastic stack for Root Cause Analysis at Mapp","seo_title":"Elastic stack for Root Cause Analysis","url":"\/blog\/elastic-stack-for-root-cause-analysis-at-mapp","author":{"name":"Sun-Tsung Kim"},"date":"January 21, 2016","category":"User Stories","locales":"","content":" The vitality of the Elastic technology stackDifferent modules of our software produce their own logs, in different formats. Previously, we did all those dirty grep, sed, awk moves to extract certain patterns out of the raw logs and then do analysis on this. It was absolutely difficult, and it was impossible to see any trends based on different parameters. When we started using the power of the Elastic Stack, the whole log analysis became faster, more proactive, meaningful, and accurate. With Elasticsearch we can now do full text search in near real time. Using Logstash and its powerful plugins, we can deal with different types of logs from different software modules and extract valuable fields out of logs. Kibana gives us the power of creating and using dashboards as well as extracting the analysis results based on the logs. Also, passing the information from team to team became easy by\u00a0sharing dashboards. Plugins such as Kopf, Curator and Marvel help us to manage Elasticsearch and its indices. \u00a0 The Elastic technology stack from head to toeWhen we say that we use the Elastic Stack, this means that we are covering the full logfile analysis story, content and technology. Let's start with the application that produces the logs. We know it and the people behind it because of our Root Cause Analysis (RCA) role. So we can give recommendations on the content of the logfile, and also on the structure. Next we make this visible in the Elastic stack, either by feeding it into an existing cluster or by creating a new stack. In the latter case, it's us who set up Elasticsearch, Logstash and Kibana. Then we go back to the users to ask how this works for them. Working with the Kibana dashboards, they will start to think differently and come up with new use cases. We'll keep developing the Elastic Stack, configure Logstash, do the sizing, optimize and upgrade all components. The Elastic Stack users are Third Level Support, DevOps, Developers and Product Management. And us. This is very important, there's no better way to understand your user than being one yourself. A powerful combination: Elastic Stack and RCAIn this post, I'll argue that this is an amazingly powerful combination: RCA, the Elastic Stack and a full team.\u00a0For one, as RCA, we've always been bridging teams and departments. We talk to everyone who is affected by incidents, and to everyone who knows about their causes and helps to prevent them - in short, to everyone.\u00a0Second, we have a\u00a0vital interest in the Elastic Stack, using it a lot, while at the same time the\u00a0Elastic Stack\u00a0has a\u00a0great \"Power to the User\" built in philosophy that\u00a0makes it possible to answer questions from many perspectives.\u00a0Third - let me take one step back. Jez Humbel wrote in \u00a0that \"Bad behavior arises when you abstract people away from the consequences of their actions.\" In this spirit, we don't tell people \"Don't worry, we take care of this\", but aim at bringing people back in touch with the consequences of their actions. The Elastic stack is a great tool for this.\u00a0Fourth, the Elastic Stack is flexible, so we are, too. Every component, Elasticsearch, Logstash and Kibana, adapts very well to many situations. It processes all kinds of input and lets you combine this with other data sources. For example, we extract information on human readable names from a database, build a dictionary, then use the Logstash translate plugin to\u00a0add this information to our events.Attack of the BuzzwordsNow, what happens when you have a team with the mission to identify and analyse incidents and the tool and the knowledge to spread this across the company? I'd like to show how this relates to Agile, Microservices, DevOps and Lean - sorry about this avalanche of buzzwords, but I promise that I have a reason to use them. The Elastic Stack is a natural microservice. It is small, it serves one purpose, and it is deployable independently. We are so lucky. Enjoy it, use it, and build a team that can handle it. Some members who are close to the content and interpretation, like experienced RCA people, and one or two DevOps. This team is a cross-functional group of people that have everything, and everyone, necessary to get your Logstash analysis flying - and is an agile team by this definition. There will be requests for more Elastic Stacks\u00a0springing up all over the place. You have one in production, you need one for\u00a0smoke tests. You have one for this\u00a0applications, you need one for\u00a0another one, too. You have one in EMEA, you need one in the U.S.. And so on. This in turn means that your team will be setting up Elastic Stacks in all kinds of environments. If server setups differ, they will be feeling it. If the configuration is not the same, this will show in the dashboards. If automation isn't simple, they'll be slowed down. They say that you can recognize the vanguard by the arrows sticking out of their breast - let's have a look, yes, there's a number. But this is what a vanguard is for. We push for smoother deployment processes and automation, and we cross department borders. We aren't the only ones, of course, but we have a good chance to succeed because our service is so small. When we do, this paves the road for a more agile culture. We've already dealt with most those buzzwords, except for \"Lean\". This comes in when you look at the Build-Measure-Learn Circle: Full presentation of Eric Ries can be viewed . Focus on the lower left: From \"Measure\" to \"Learn\". There tend to be gaps. The Elastic Stack \/ RCA cannot fill all of them, but help some. The Elastic stack is good for \"Measure Faster\", and RCA is good for \"Learn Faster\u201d. And this is something worth working for. OutlookWe are constantly working on our Elastic Stacks, presently implementing Shield and Watcher. Shield is important to enforce multitenancy, while retaining all the data in one cluster to facilitate analysis across customers. Watcher will help us to give special attention to issues, new workflows or jumpy customers. There are more adventures waiting for us with the Elastic stack. Sun-Tsung Kim started working with Elasticsearch end of 2012 at Autoscout24 and has been working with it ever since. She has a background in statistics, programming, OS and database administration, various data stores like meetups or coursera. Additionally Sun-Tsung is interested in new ways to work and organise. \n"}
{"index": {"_id": 763}}
{"title":"Categorizing images with deep learning into Elasticsearch","seo_title":"Categorizing images with deep learning into Elasticsearch","url":"\/blog\/categorizing-images-with-deep-learning-into-elasticsearch","author":{"name":"Emmanuel Benazera"},"date":"January 20, 2016","category":"User Stories","locales":"","content":" is a young open source deep-learning server and designed to help in bridging the gap toward machine learning as a commodity. It originates from a series of applications built for a handful of large corporations and small startups. It has support for , one of the most appreciated libraries for deep learning, and it easily connects to a range of sources and sinks. This enables deep learning to fit into existing stacks and applications with reduced effort. Machine learning is the next expected commodity on the developer's stack. Many software packages, most of them open source, are slowly but surely empowering the developers with these new technologies for automation. As the developer of , an open source deep-learning server, I've been building a range of smart applications for a variety of large corporations and small startups. In most of these production settings, the existing stack relies on a series of data backends, among which Elasticsearch is prominent. For this reason Deepdetect builds a direct connection to all backends through a little trick: the server supports output templates so that data can be molded to fit any sink backend. We recently applied this trick to in just a few steps. The result is that you send images to Deepdetect, images get tagged (a hedgehog, a plane, etc.), then the tags and the image URL get indexed into Elasticsearch directly without any glue code. This is it. You can now search images with text, even when no caption was available. Beyond cool, this is also scalable as prediction works over batches of images, and multiple prediction servers can be set to work in parallel. We tell you below how to reproduce this very simple setting for your own applications. Machine Learning and Deep LearningBut first, if you are not familiar with the topic, machine learning has become a ubiquitous technology that is powering a growing number of high automation software offerings, sometimes referred to as smart or intelligent applications. These range from and to , , , audio and video recognition (and even !). In a nutshell, machine learning automates classification tasks in two steps: the training step builds a model out of data for a targeted task, i.e. for image classification, while the prediction step leverages that model to predict \u2014 for instance, the category of more images. There are some cool demonstrations out there: do you believe we can accurately ? Machine learning dates back to the 1960s, though it is the last decade's surge in data, cheap computational resources, and crucial scientific achievements that truly unlocked its potential in production.(1) The most advanced applications these days leverage the field of , a set of models in the form of complex neural networks with the ability to capture high-level abstractions in data. These models are of course computed by dedicated algorithms that for the most part apply a small set of linear and nonlinear operators repeatedly over slices of the training data. Because these operations need to be repeated millions of times over matrices that can reach up to billions of entries, they are best parallelized on special processors, originally dedicated to graphical computations such as video games, and known as Graphic Processing Units (GPUs). Deep learning continues to reveal spectacular properties, such as the ability to recognize images or classify text without much engineering. Raw images or text are fed to the algorithm along with the desired output, and the resulting model can be used to predict the output on more data. This prediction has very high accuracy, ! This is a big step forward compared to previous machine learning systems in which engineers had to half-blindly help the algorithms tricks and transforms to the data. Machine Learning as a CommodityFor these reasons, it is believed that . This compares to the way Elasticsearch is a storage and search engine commodity for many of us today. We're not exactly there yet with machine learning, and this crucial step requires a lot of work. Deepdetect is only one young deep learning commodity. Much more mature \u00a0frameworks exist, like , , , , to name a few. In all honesty, it becomes difficult to make a choice. Not all of them provide support for state-of-the-art deep learning, and their respective APIs vary from low level algorithm parametrization to higher application level. Check them all out as more than one may fit your needs. Among the data sinks, Elasticsearch is a primary choice among developers. Moreover, most of the machine learning tasks require a fast and scalable data back-end to feed the algorithms, a trend even aggravated by the greedy deep learning algorithms. Building a search engine of imagesSo let us use Deepdetect to set a classification service that distinguishes among 1000 different image categories, from 'ambulance' to 'padlock' to 'hedgehog', and indexes images with their categories into an instance of Elasticsearch. For every image, the Deepdetect server can directly post and index the predicted categories into Elasticsearch. This means there's no need for glue code in between the deep learning server and Elasticsearch. This has more background on the true cost of building machine learning applications. First you need to and . This should take just a few minutes. Now power up an instance of Elasticsearch. In the following, we assume that it is listening on localhost:9200. Categorizing images into ElasticsearchDeepdetect supports output templates. An output template allows transforming the standard output of the server into any custom format. Here we use this capability to directly index the Deepdetect output into Elasticsearch. Here is our first image: Scene from . Copyright \u00a9 2014 by Paramount Pictures. All Rights Reserved. Let's predict the categories for it and index them along with the image URL into Elasticsearch: curl -XPOST \"http:\/\/localhost:8080\/predict\" -d '{\"service\":\"imageserv\",\"parameters\":{\"mllib\":{\"gpu\":true},\"input\":{\"width\":224,\"height\":224},\"output\":{\"best\":3,\"template\":\"{ {{#body}}{{#predictions}} \\\"uri\\\":\\\"{{uri}}\\\",\\\"categories\\\": [ {{#classes}} { \\\"category\\\":\\\"{{cat}}\\\",\\\"score\\\":{{prob}} } {{^last}},{{\/last}}{{\/classes}} ] {{\/predictions}}{{\/body}} }\",\"network\":{\"url\":\"http:\/\/localhost:9200\/images\/img\",\"http_method\":\"POST\"}}},\"data\":[\"http:\/\/i.ytimg.com\/vi\/0vxOhd4qlnA\/maxresdefault.jpg\"]}' and equivalently using the Deepdetect Python client: from dd_client import DD dd = DD('localhost') dd.set_return_format(dd.RETURN_PYTHON) mllib = 'caffe' data = ['http:\/\/i.ytimg.com\/vi\/0vxOhd4qlnA\/maxresdefault.jpg'] parameters_input = {'id':'id','separator':',',scale:True} parameters_mllib = {'gpu':True} parameters_output = {\"best\":3,\"template\":\"{ {{#body}}{{#predictions}} \\\"uri\\\":\\\"{{uri}}\\\",\\\"categories\\\": [ {{#classes}} { \\\"category\\\":\\\"{{cat}}\\\",\\\"score\\\":{{prob}} } {{^last}},{{\/last}}{{\/classes}} ] {{\/predictions}}{{\/body}} }\",\"network\":{\"url\":\"http:\/\/localhost:9200\/images\/img\",\"http_method\":\"POST\"}} predict_output = dd.post_predict('imageserv',data,parameters_input,parameters_mllib,parameters_output) which yields: {\"_index\":\"images\",\"_type\":\"img\",\"_id\":\"AVCvBfg7zqwAL3DK-gQ0\",\"_version\":1,\"created\":true} which is the output of Elasticsearch, as reported by the Deepdetect server. Let's check that our image is within the index: curl -XGET \"http:\/\/localhost:9200\/images\/_search?q=helmet\" { \"took\" : 3, \"timed_out\" : false, \"_shards\" : { \"total\" : 5, \"successful\" : 5, \"failed\" : 0 }, \"hits\" : { \"total\" : 1, \"max_score\" : 0.09492774, \"hits\" : [ { \"_index\" : \"images\", \"_type\" : \"img\", \"_id\" : \"AVCvc16VzqwAL3DK-gQ8\", \"_score\" : 0.09492774, \"_source\": {\"doc\": { \"uri\":\"http:\/\/i.ytimg.com\/vi\/0vxOhd4qlnA\/maxresdefault.jpg\",\"categories\": [ { \"category\":\"n03868863 oxygen mask\",\"score\":0.225514 } , { \"category\":\"n03127747 crash helmet\",\"score\":0.209176 } , { \"category\":\"n03379051 football helmet\",\"score\":0.0739932 } ] } } } ] } } The best prediction the image tagging model comes up with is 'oxygen mask' and the second one is 'crash helmet'. We could expect 'astronaut' instead as a better answer, and the reason why it is missing here is that 'astronaut' is not among the classes the model has been trained to recognize. The full set of classes for this particular model is available . This means that for every targeted application, you usually need to build a dedicated model. Also, note the two main parameters in the prediction and indexing calls to the deep learning server: These simple two parameters can accommodate a variety of connections to external software applications, far beyond Elasticsearch. Bulk categorizationLet's improve on the categorization call above to categorize and index multiple images at once. We add the following image: For categorizing and indexing the two images at once, this time we use the Elasticsearch Bulk API: curl -XPOST \"http:\/\/localhost:8080\/predict\" -d '{\"service\":\"imageserv\",\"parameters\":{\"mllib\":{\"gpu\":true},\"input\":{\"width\":224,\"height\":224},\"output\":{\"best\":3,\"template\":\"{{#body}} {{#predictions}} { \\\"index\\\": {\\\"_index\\\": \\\"images\\\", \\\"_type\\\":\\\"img\\\" } }\\n {\\\"doc\\\": { \\\"uri\\\":\\\"{{uri}}\\\",\\\"categories\\\": [ {{#classes}} { \\\"category\\\":\\\"{{cat}}\\\",\\\"score\\\":{{prob}} } {{^last}},{{\/last}}{{\/classes}} ] } }\\n {{\/predictions}} {{\/body}} }\",\"network\":{\"url\":\"http:\/\/localhost:9200\/images\/_bulk\",\"http_method\":\"POST\"}}},\"data\":[\"http:\/\/i.ytimg.com\/vi\/0vxOhd4qlnA\/maxresdefault.jpg\",\"http:\/\/ak-hdl.buzzfed.com\/static\/enhanced\/webdr05\/2013\/9\/17\/5\/enhanced-buzz-1492-1379411828-15.jpg\"]}' {\"took\":156,\"errors\":false,\"items\":[{\"create\":{\"_index\":\"images\",\"_type\":\"img\",\"_id\":\"AVCvc16VzqwAL3DK-gQ8\",\"_version\":1,\"status\":201}},{\"create\":{\"_index\":\"images\",\"_type\":\"img\",\"_id\":\"AVCvc16VzqwAL3DK-gQ9\",\"_version\":1,\"status\":201}}]} Simple and fast, the two images are now indexed! Let's check on the second one by looking a hedgehog up in our index: curl -XGET \"http:\/\/localhost:9200\/images\/_search?q=hedgehog\" { \"took\" : 6, \"timed_out\" : false, \"_shards\" : { \"total\" : 5, \"successful\" : 5, \"failed\" : 0 }, \"hits\" : { \"total\" : 1, \"max_score\" : 0.057534903, \"hits\" : [ { \"_index\" : \"images\", \"_type\" : \"img\", \"_id\" : \"AVCvc16VzqwAL3DK-gQ9\", \"_score\" : 0.057534903, \"_source\": {\"doc\": { \"uri\":\"http:\/\/ak-hdl.buzzfed.com\/static\/enhanced\/webdr05\/2013\/9\/17\/5\/enhanced-buzz-1492-1379411828-15.jpg\",\"categories\": [ { \"category\":\"n02346627 porcupine, hedgehog\",\"score\":0.783433 } , { \"category\":\"n02138441 meerkat, mierkat\",\"score\":0.0204417 } , { \"category\":\"n02442845 mink\",\"score\":0.0182722 } ] } } } ] } } We have a hedgehog indexed, which means our prediction appears to have done a good job. So images can now easily be retrieved by keywords from Elasticsearch. Try it out on your own collections and applications. Notes: So we've built a short pipeline for using deep learning over images (e.g. for image categorization) and indexing them into Elasticsearch. This can easily be scaled to millions of images as needed. With Deepdetect we are touching upon a variety of application fields, from cybersecurity to image and text classification. In cybersecurity especially, the Elastic Stack is among the common tools, and slight modifications to the settings above ensure we can use deep learning as a commodity to better qualify the data points before pushing them into Elasticsearch and Kibana. (1)\u00a0 About Emmanuel BenazeraEmmanuel holds a PhD in Computer Science & AI from University Toulouse-III in France. He worked as a researcher in CS, AI and robotics at a variety of labs, from NASA Ames Research Center to DFKI, CNRS and Inria, and founded or co-founded a few startups around intelligent software solutions. His main applied research interests lie in automated decision systems, machine learning, information retrieval, p2p networks and open source software. \n"}
{"index": {"_id": 764}}
{"title":"Deploying Elasticsearch with Ansible","seo_title":"Deploying Elasticsearch with Ansible","url":"\/blog\/deploying-elasticsearch-with-ansible","author":{"name":"Dale McDiarmid"},"date":"January 20, 2016","category":"Releases","locales":"","content":" With the recent release of Elasticsearch 2.0.0 a completely new Ansible role has been released as well. This post will show you how to install and configure multiple Elasticsearch nodes using this new role. As Consulting Engineers at Elastic we regularly deploy large Elasticsearch clusters across multiple machines. These clusters vary in topology and configuration and are often deployed on heterogeneous hardware in complex architectures. Repeating the same task of software deployment and configuration, on potentially hundreds of machines per customer, is a great opportunity for automation. In the interests of both efficiency and accuracy \u2014 as well as our sanity! \u2014 we regularly review and seek new tools to simplify this process. By minimizing the time spent on actual software deployment, we maximize the time for more interesting problems that our customers regularly pose! We continue to support a Puppet module which was recently updated to support Elasticsearch 2.x. Whilst an excellent configuration and orchestration management tool, Puppet can present a steep learning curve and significant investment for some organizations. For deploying new self-contained clusters \u2014 with no history of Puppet within the organization \u2014 Ansible's push architecture can represent a simpler alternative. Ansible is a Python-based automation tool that wraps SSH, allowing complex idempotent commands to be sequenced. It can configure systems, deploy software, and orchestrate more advanced IT tasks such as continuous deployments or zero-downtime rolling updates. With no requirement for an agent, or external dependencies other than SSH access and Python 2 on the target host, it represents an ideal solution for deploying an Elasticsearch cluster on a set of newly provisioned servers. Whilst Puppet remains a popular configuration management tool for Linux systems, Ansible has obtained equivalent interest in the last few years. In response to both our own requirements and a growing community interest, we are now officially releasing an Ansible role to simplify the deployment of Elasticsearch. The role's structure directly maps to its key capabilities:\u00a0installation of prerequisites (e.g. Java), installation of Elasticsearch based on the target platform, Elasticsearch configuration, management of plugins and finally service management. The assignment of the role to a host results in the installation of an Elasticsearch instance. For hosts where multiple instances are required, simply assign the role multiple times \u2014 as illustrated in the below example. The configuration of Elasticsearch is supported through a map, which is in turn serialized to yaml, thus requiring no changes when new parameters are added. To help with illustrating the capabilities of the role we've assembled a quick example using an Ubuntu-based docker image. The user will require: The following assumes Ansible has been installed in \/opt\/ansible on your desktop. Where not specified, the user should assume all actions should be performed from this machine. sudo mkdir -p \/opt\/ansible\/playbooks\/ sudo chown -R \/opt\/ansible\/playbooks cd \/opt\/ansible\/playbooks && git clone https:\/\/github.com\/elastic\/ansible-elasticsearch-example.git cd \/opt\/ansible\/playbooks\/ansible-elasticsearch-example\/git clone https:\/\/github.com\/elastic\/ansible-elasticsearch.git roles\/elasticsearch The file playbook.yml declares a very simple playbook with one play. This play applies the Elasticsearch role twice to a server belonging to the \u201cnodes\u201d group. The first application of the role will install a dedicated master node, whilst the second installs a data node. Users can easily modify this file to contain either more plays, more roles or a combination of both. dockerpull gingerwizard\/ansible-test docker run -d -P --name ansible-test -h ansible-test gingerwizard\/ansible-test docker ps -a docker inspect | grep \"IPAddress\" [nodes] ansible-test ansible_ssh_host= ansible_ssh_port= Although the role installs Java where required, the provided docker image includes this to keep the deployment time minimal. ansible-playbook playbook.yml -u root -i hosts --ask-pass The user will be prompted for the root password -'Ansible!' The play should complete with: PLAY RECAP ********************************************************************* ansible-test : ok=69 changed=25 unreachable=0 failed=0 curl http:\/\/:\/ The playbook illustrates some of the available configuration parameters available to the user. For further details and features refer to the provided . Over the coming weeks we expect to release Ansible roles for both the Beats products and Logstash, whilst also continuing to add features to the Elasticsearch role, with the aim of being able to deploy the complete Elastic stack with a single command. Per usual, we welcome community \u00a0and ! \n"}
{"index": {"_id": 765}}
{"title":"Brewing in Beats: More community Beats","seo_title":"","url":"\/blog\/weekly-beats-more-community-beats","author":{"name":"Tudor Golubenco"},"date":"January 19, 2016","category":"Brewing in Beats","locales":"","content":" Welcome to Weekly Beats! With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources. Unifiedbeat - Beat for IDS\/IPS event logs reads records from binary files generated by network intrusion detection software like Snort or Suricata, and indexes the records in Elasticsearch. Its author wrote a in which he explains why Elasticsearch is a great option for storing these logs. We agree and think this is a great use of the Beats framework. Factbeat - Beat for Puppet Facter info is a new community Beat, created by from Elastic. It runs Facter periodically and sends the results to Elasticsearch. Having all the facts about your servers available in\u00a0Elasticsearch makes it easy to query and visualize your infrastructure in new and interesting ways. Expand env variables in configuration files A commonly requested feature was to be able to use environment variables for configuring the Beats. Andrew came up with an elegant that allows you to use environment variables in the configuration files, while allowing for default values. This works automatically for all Beats. Winlogbeat new field names In time for the first release of Winlogbeat, we\u2019ve the fields exported by Winlogbeat to be more uniform with the ones exported by the other Beats. Filebeat refactoring We\u2019ve made more to the Filebeat code, making it possible to cleanly shutdown Filebeat in all the corner cases. PowerShell script for loading the dashboards Thanks to a , our next release will include a that makes it easy to load our sample dashboards on Windows. Testing environment We now have a dockerized for the manual QA phase. This makes it very easy to test against specific versions of Elasticsearch, Logstash, and Kibana. \n"}
{"index": {"_id": 766}}
{"title":"Knowledge Scaling: Versatility over all else","seo_title":"Knowledge Scaling at Allovue: Versatility over all else","url":"\/blog\/allovue-knowledge-scaling-versatility-over-all-else","author":{"name":"Ted O'Meara"},"date":"January 19, 2016","category":"User Stories","locales":"","content":" For school districts, every financial decision they make - be it as hot button as labor contracts and books provided to students or as benign as which light bulbs to purchase - has ramifications on the ability of every teacher to do their job of providing the best learning environment for their students. But too often these decisions are made without input from those teachers and students who are most affected by cuts or expenditures. The team at has developed a solution that provides easy access to all account books and tables for school districts, so even those not directly involved in the decision process can easily track when funds are going and more importantly where funds are lacking. In turn, financial decisions can be made knowing the whole picture of real effects on children and teachers as opposed to just simply a business bottom line. Allovue chose Elasticsearch to provide a replacement for their Postgres backend search functionality to their industry-leading tool as it easily allows for aggregation across multiple unique datasets and structures, all while reducing response times from 2 seconds to under 20ms.\u00a0 How can a school run out of paper before the holiday break? Jess Gartner was faced with this question, among many others tossed onto the heap of questions and tasks that the third-year teacher had perpetually running in the cusp of her conscious thought. These questions kept flowing in and out of thoughts mixed with the lesson planning, scheduling, and other activities that are core to a teacher\u2019s day-to-day tasks. It turns out that her situation happens often. Teachers all across the United States have to shell out money from their own pockets to keep their classrooms going. Buying pens and pencils. Buying classroom decorations. Buying supplemental materials for a special lesson.Now as CEO of , Jess is able to see how big of an impact financial decision-making in a school district can mean for individual teachers and their classrooms. The more she explored this problem, the clearer it became that most school districts lack systems and processes to build financial literacy outside of their accounting and budget offices. They also cannot supply financial data with the same quality, timeliness, and supports as academic data. Between central office accountants and school district superintendents, chief academic officers, principals, and board members, a lot of valuable information is lost. As a result, the conversation about effective resource allocation and the conversation about effective education practice are siloed. Scaling for school districtsAmong the challenges with education finance are the ways in which financial transactions can be categorized. Because school districts are funded with local, state, and federal dollars, and all of these sources have different reporting requirements and restrictions on how those dollars can be spent, school districts have a very robust . A is a collection of metadata that describes the source and purpose of each dollar spent in a school district. All businesses have a chart of accounts, but the detailed reporting and compliance needs of schools lead to varied and complex charts of accounts. A well-organized chart of accounts is made up of several , each of which can be thought of as an independent dimension to describe an expenditure measure. Each segment looks very much like a tree. There are parent nodes, and then there are children, grandchildren, and so on. They mostly use numeric codes that follow certain rules. For instance, you may have a chart segment that has a parent node of with a code of . has a child: , which in turn has a child node: . Each school district has their own chart of accounts, which can have any number of segments, which themselves can have any number of elements and hierarchical depths.When you create a budget, you specify how much money should be allocated for various combinations of nodes in a . For instance, an account could consist of at for used from the : the account has a budgeted amount of $100,000 and spent amount of $70,000. This account is then stored as something like [] as separate columns in most district databases. In order to gain any context around the record stored, you\u2019d need to make 4 joins from separate lookup tables. This also provides a challenge if we are trying to be agnostic to the structure of that could themselves be very different.Our team was looking at solutions to the problem of ingesting that could be very different from one school district to another. We knew that we needed to be as flexible as possible with the chart data, but we also needed to have the consistency that an ACID database provides. It was around this time that Postgres 9.4 was in beta with JSONB: a binary JSON format that is akin to MongoDB\u2019s BSON. We saw this as the way to get the best of both worlds \u2014 Our chocolate in our peanut butter, our peanut butter in our chocolate. Speeding up chart queriesThe strategy of denormalizing the data and building JSONB trees worked out really well for us. We were using materialized views and getting cached result sets to make things a bit faster. Around this time, we were also looking into solutions for search indexing, primarily to provide suggested search terms for filtering data to our users, most of whom don\u2019t have their entire chart of accounts. The two biggest solutions that we were evaluating were Solr and Elasticsearch. We decided on Elasticsearch for a number of reasons, but we really were won over by the API and the sorts of things that you could do with aggregations.In just a couple of weeks, we had Elasticsearch running in production and began working on a feature that utilized aggregations extensively. We saw incredibly fast turnaround from Elasticsearch using aggregations and search requests in general. Using materialized views in Postgres was working fine, but required a fair bit of computation during our ETL process. Postgres was also quickly hitting unacceptably slow performance as we started to work with more complex queries. If Elasticsearch was doing so well with suggested searches and aggregations, why not move all of our data retrieval over to it and see if there are additional performance gains? We decided to try Elasticsearch as a sort of cache layer without the work of setting up something like Redis or some other queueing\/caching system, considering all the challenges associated with cache invalidation and asynchronous task management.We moved a good deal of the queries, joins, and views from Postgres into indices in Elasticsearch. Moving JSONB to JSON documents in Elasticsearch went on without a hitch, and the result was a 100x speed-up compared to our most complex queries from Elasticsearch. We went from 2 seconds to 20ms on one particular query that our users needed to perform often. We used just a bit more time for creating the indices in the ETL process: a tradeoff we were more than happy to make with the time saved from no longer needing to build materialized views in Postgres. We are now consistently turning around responses in under 50ms round-trip from the front-end client and back. Flexibility in storing dataAnother interesting facet of the way we are using Elasticsearch is that we are only running it as a single node. That is working well for us, even though that isn\u2019t a \u201cgolden path\u201d way of using the service. We have separate environments for each of our customers for a variety of reasons, but mostly so that we can legally ensure that their data is isolated. Once we have the financial and chart data in PostgreSQL, we have a persistent data store in which we can keep the level of fidelity in a place that we can build and abstract on. However, in Elasticsearch, we are dealing much more with the presentation of the data that we ingest. We can treat this abstraction as something that is more of a commodity: we aren\u2019t completely concerned if it all gets blown away by the end of the day, because we have our \"source of truth\u201d in another location. This sentiment provides us with a great deal of flexibility and ultimately allows us to maneuver in more flexible ways, since we don\u2019t need to worry as much about whether the data in Elasticsearch gets lost at the end of the day. We can always rebuild in a matter of seconds.As a result, we haven\u2019t had to turn toward building complex OLAP cubes like many other past data reporting systems have. We can work comfortably with Elasticsearch to perform all of our filtering and aggregation operations fast, with an API that is comfortable and integrates well with our application layer. The flexibility we desired in our persistent Postgres data store does not have to be sacrificed to achieve performance like it would in a traditional OLAP setup. On top of that, our team really didn\u2019t require any new specialized knowledge to implement this solution. Versatility in applied knowledgeIn some ways, we fell into Elasticsearch by chance. We were looking for a tool to be great at one thing: surfacing suggested terms to our users who are exploring complex data. It is no surprise that Elasticsearch was great at search (of course!), but we also found a great solution to a much wider domain of problems associated with fast querying of data. Maybe we could eek out more performance through the tried and true methods of OLAP or more extensive caching, but how much more performance? Would it be worth the cost of another dependency? We already send back results in 50ms!Elasticsearch gets us much more than the marginal performance more complex tools may get us. The flexibility and versatility that we gain is unmatched by the other solutions that we investigated. Not only can we use it for search and caching, but we can retain that knowledge for building a logging solution with the Elastic Stack. We can also easily pipeline to data mining solutions like Spark and Hadoop as our data grows. And while we currently only need a single node for stellar performance, Elasticsearch offers a tried and true path to scaling way beyond our current needs. Ted O'Meara is CTO of Allovue.\u00a0Ted has worked with more than a hundred companies across all industry sectors, from startups to Fortune 100 companies, including Amazon, Citi, and JP Morgan Chase. He has a solid foundation of developing software and managing global software development teams.\u00a0One of his most notable consulting projects include leading the front-end redesign of Amazon\u2019s Mechanical Turk. Ted worked with the client and their internal team, as well as managing a team of consultants to provide a better UX for different groups of users of Mechanical Turk.\u00a0Another key project was designing and building a custom analytics solution for an audio product company that was acquired for several billion dollars. He and his team created a unified consumer persona that helped the company to better understand and interact with its customers by providing more complete consumer analytics and integrating systems from disparate business units, including ERP to payment gateways.\u00a0Most recently, Ted and the Allovue team have built Balance, their flagship product to help school districts better handle their accounting data and processes. As of early 2016, Balance is handling close to $4B of school district finances. \n"}
{"index": {"_id": 767}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-01-18","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-01-18","author":{"name":"Michael McCandless"},"date":"January 18, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsLooking to upgrade your deployment from 1.x to 2.x? We\u2019ve got the video for you & it\u2019s OnDemand now! \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole Elastic\u00a0ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 768}}
{"title":"Where in the World is Elastic? - SnowCamp & SCaLE 14x","seo_title":"Where in the World is Elastic? - SnowCamp & SCaLE 14x","url":"\/blog\/witwies-snowcamp-scale14x","author":{"name":"Megan Wieling"},"date":"January 18, 2016","category":"","locales":"","content":" Welcome to Find out which Elastic events and meetups are happening near you this week.\u00a0Upcoming EventsJanuary 20 - 21: \u00a0January 21 - 24:\u00a0Upcoming MeetupsJanuary 18: January 19: January 20: January 20: January 21: January 21: January 23: January 20: That's it for this week. Stay tuned next week for more Elastic happenings.- The Elastic TeamP.S.\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}
{"index": {"_id": 769}}
{"title":"A case for self-monitoring systems","seo_title":"A case for self monitoring systems","url":"\/blog\/a-case-for-self-monitoring-systems","author":{"name":"Jay Greenberg"},"date":"January 18, 2016","category":"Engineering","locales":"","content":" TheoryNetwork infrastructure has evolved in recent years. \u00a0Systems reside in a combination of the corporate office, datacentre co-locations, and the cloud. \u00a0Trends in automation and configuration management have simplified massive scaling. A single security domain interconnected by private lines is no longer a luxury that engineers can expect. \u00a0 Ad-hoc measures must be implemented such as virtual private networks and least privilege firewall permissions, on a case-by-case basis, requiring extensive architecture and maintenance. \u00a0 System logging and monitoring are essential components in stable and intelligent business operations - but too often, security is complicated - or worse, compromised. \u00a0 A smart engineer will usually choose the simplest approach, as it is often the most stable and secure. In most of today\u2019s networks, logging and monitoring are mutually exclusive, one pushing back to a central location, and the other polling from a central location. \u00a0 The polling piece of this dual-architecture has several problems: Theoretically, it is now possible to simplify the traditional architecture, streamlining logging, monitoring, performance statistics and business reporting into a single platform - Elasticsearch. Proof of ConceptBeatsIn order for a solution to be viable, it must ultimately address any need that arises, on any platform. \u00a0The platform is a lightweight, open source data shipper, and runs on most . \u00a0The community has already begun to monitor their favourite services. A wealth of Nagios Checks already exist (currently over 5000 in the ), and can be integrated with Beats via . \u00a0 Here is an example of how we would configure nagioscheckbeat to check the redis service every 10 seconds: period: \"10s\" name: \"redis\" cmd: \"\/usr\/lib\/nagios\/plugins\/check_redis.pl\" args: \"-H 127.0.0.1 -R -m -T -f -A\" ElasticsearchBeats must have an output, such as Logstash or an Elasticsearch cluster. \u00a0 Self-hosted, or , the organization\u2019s cluster must be secure and\u00a0accessible by all end systems. \u00a0 KibanaElasticsearch and serve nicely for reporting performance metrics: Apache Workers fit perfectly into a percentage visualization: Kibana\u2019s new plugin allows for more detailed time series analysis. \u00a0For example, we could overlay arbitrary metrics in a single visualization, for custom correlations during an RCA. Alerting on Crossed Thresholds or Unresponsive Services does two things. \u00a0It publishes performance metrics \u2014 for making pretty graphs \u2014 but also reports the status of each check against warning & critical thresholds defined in the configuration. \u00a0Those checks are published separately from the metrics, so we can watch the results directly. \u00a0 Elastic\u2019s plugin can be configured to alert with little effort, and even supports notifications. This Watcher configuration will send an email when any has reported a\u00a0CRITICAL status\u00a0in the last 30 minutes: PUT _watcher\/watch\/critical_watch { \"trigger\" : { \"schedule\" : { \"interval\" : \"1m\" } }, \"input\" : { \"search\" : { \"request\" : { \"indices\" : [ \"nagioscheckbeat*\" ], \"body\" : { \"query\":{ \"filtered\":{ \"query\" : { \"bool\" : { \"must\" : [ { \"term\" : {\"_type\": \"nagioscheck\"} }, { \"range\" : {\"@timestamp\" : {\"gte\" : \"now-30m\"}} }, { \"term\" : {\"status\" : \"CRITICAL\" } } ] } } } } } } } }, \"condition\" : { \"compare\" : { \"ctx.payload.hits.total\" : { \"gt\" : 0 }} }, \"actions\" : { \"send_email\" : { \"throttle_period\": \"30m\", \"email\" : { \"to\" : \"me@elastic.co\", \"subject\" : \"Alert from Watcher - Service(s) Critical\", \"body\" : \"One or more services reported a CRITICAL state within the last 30 minutes. See the attached file for details. You will not receive another notification for 30 minutes.\", \"attach_data\" : true } } } } Notice the directive, which ensures that alerts are only sent periodically until the condition is resolved. \u00a0\u00a0 Alerting on Lost HeartbeatsNo monitoring system would be complete without knowing if a host is down. \u00a0Consider this experimental approach: \u00a0On each host, a special \u201cheartbeat\u201d is published every several seconds. name: \"heartbeat\" cmd: \"\/usr\/lib64\/nagios\/plugins\/check_dummy\" args: \"0 Hello\" period: \"10s\" The watch works like this: Any host that sent a heartbeat in the last 1 day, and whom we have not heard from in the last 5 minutes is considered \u201cdown\u201d. \u00a0The watch uses an Elasticsearch aggregation to show us the most recent heartbeat from each host.\u00a0 ... \"condition\" : { \"script\" : { \"file\" : \"monitor-hosts\", \"params\" : { \"threshold\" : 0 } } } ... () Notice that our in the watch is a script, which looks like this: def minutes = 5 def now = DateTime.now().getMillis() ctx.vars.hosts = [ up: [], down: [] ] ctx.payload.aggregations.hosts.buckets.each { def last_heartbeat = it.latest_heartbeat.hits.hits[0].sort[0]: def ms_ago = now - last_heartbeat if (ms_ago > (minutes * 1000) ){ ctx.vars.hosts.down.add( [ hostname: it.key, last_heartbeat: new Date(last_heartbeat) ]) } } return ctx.vars.hosts.down.size() > 0 A Complete Open Source solution As an alternative to Watcher, Integrating Elasticsearch with any existing monitoring system would be trivial - one could simply set up a check that alerts and escalates under similar conditions. \u00a0A monitoring system communicating with a single Elasticsearch cluster is more secure and scalable than reaching out to every service on each end system. Also, in Kibana, we can easily report on services that are running in a CRITICAL threshold: ConclusionWhen various Beats are used in combination, we have a unified solution for exporting system logs, application data, and performance metrics. \u00a0\u00a0 In the changing landscape of infrastructure operations, networks are relying on cloud services such as and Software as a Service such as . \u00a0Leveraging these services is trending because it simplifies architecture and operations. Modern automation technologies have simplified the host-configuration process. \u00a0Cohesively, when a host\u2019s monitoring configuration is applied via automation, that configuration is spun up and torn down, autoscaling with each host. Please see the entire , and feel free to clone and run it yourself. \n"}
{"index": {"_id": 770}}
{"title":"Brewing in Beats: new community Beat for Nagios checks","seo_title":"","url":"\/blog\/weekly-beats-run-nagios-checks","author":{"name":"Tudor Golubenco"},"date":"January 12, 2016","category":"Brewing in Beats","locales":"","content":" Welcome to ! With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources. New community Beat: NagioscheckbeatThere\u2019s a new community Beat, written by Elastic\u2019s , and it\u2019s really interesting. runs Nagios checks and sends the results to Elasticsearch. I don\u2019t think it was ever easier than this to scale and get analytics insights from all those Nagios scripts. \u00a0Huge potential here, if you ask me. Thank you, Jay :-) New community Beat: hsbeat (HotSpot VM metrics) is another very interesting and promising community Beat. It collects performance data from the Java HotSpot VM by reading and decoding the binary performance logs created by the VM. Filebeat to Logstash throughput improvementsSteffen continued to investigate the about low throughput performance when sending synchronously to Logstash, and for a significant (9x) increase in the Filebeat -> LS throughput. These new libbeat defaults are at odds with the maximum memory usage of Packetbeat due to the multiplication of buffers (buffer size * bulk size), so there is another that solves this issue by making the publisher know if the\u00a0message contains one event or multiple (possibly thousands). This also improves the configurability of these buffers from the configuration file. With these changes, Filebeat is at around 60% of the throughput achieved by the Logstash Forwarder. The difference seems to come from the JSON serialization, which we need for creating new features easier, and from making the protocol safer for\u00a0back pressure situations. Steffen has ideas for closing and even reversing this gap, but they require larger code changes. Metricbeat (name not final) design startedNicolas put together a , which stirred up very pragmatic conversations about what we want to achieve with Metricbeat, how it relates to other Beats (especially the existing community beats), and even how the implementation will look like. If you want to join the discussion, you can do so in this , which also contains our current vision for Metricbeat. Unified release processTo improve the way all Elastic projects are being built, tested, and released, a common interface needs to be implemented by all of them. We started on this interface, which included moving the code into the main beats repository. Topbeat exports total CPU times instead of user CPU timesTopbeat used to export user times\u00a0for each process, but the Linux top command shows total times, which are arguably more important. So we topbeat to export total times instead. \n"}
{"index": {"_id": 771}}
{"title":"The Logstash Lines: 2.2 Release prep, JDBC Input enhancements!","seo_title":"","url":"\/blog\/logstash-lines-2016-01-12","author":{"name":"Suyog Rao"},"date":"January 12, 2016","category":"The Logstash Lines","locales":"","content":" Happy New Years to our users and welcome back to The Logstash Lines! In these weekly posts, we\u2019ll share the latest happenings in the world of Logstash and its ecosystem. Prepping for the 2.2 release: This past week was spent testing internal release candidates for our next feature release - 2.2. We found and fixed the following issues: Manageability Plugins: Beats Input: Refactored beats input to primarily fix under high data volume. Replaced the in-house blocking size queue implementation with Java\u2019s Synchronous Queue. Reorganized code to make testing easier. File Input: Added new settings - and to mirror existing functionality in Filebeat. This will help close file descriptors for files which are not being actively written to. Previously, users had to restart LS to release these resources. ES Output: Reviewed and merged scripted update support for HTTP protocol. Fixed a regression where http errors would not sleep for , sending the CPU into a spin. Kafka output: Work continues on rewriting Kafka input to use the new 0.9 version of consumer API. Also adding SSL support for both producer and consumer based on the new APIs. JDBC input: Added functionality to save query run state by using any column number, not just time-based columns . Until next time! \n"}
{"index": {"_id": 772}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2016-01-11","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2016-01-11","author":{"name":"Michael McCandless"},"date":"January 11, 2016","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsHere\u2019s your cookbook on how to deploy 2.0.0 with . \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole Elastic\u00a0ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 773}}
{"title":"Where in the World is Elastic? - AWS New York and Boston Meetup","seo_title":"Where in the World is Elastic? - AWS New York and Boston Meetup","url":"\/blog\/witwies-aws-newyork-boston-meetup","author":{"name":"Megan Wieling"},"date":"January 11, 2016","category":"","locales":"","content":" Welcome to\u00a0Happy new year! We are back again with\u00a0Elastic meetups happening near you this week!Upcoming MeetupsJanuary 12:\u00a0January 12:\u00a0January 12:\u00a0January 13:\u00a0January 14:\u00a0January 14:\u00a0January 12:\u00a0January 13:\u00a0January 14:\u00a0January 14:\u00a0January 12:\u00a0That's it for this week. Stay tuned next week for more Elastic happenings.- The Elastic TeamP.S.\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}
{"index": {"_id": 774}}
{"title":"Elasticsearch for Apache Hadoop 2.2 RC1 is out","seo_title":"Elasticsearch for Apache Hadoop 2.2 RC1 is out","url":"\/blog\/es-hadoop-2-2-rc1-released","author":{"name":"Costin Leau"},"date":"January 08, 2016","category":"Releases","locales":"","content":" Celebrating the start of 2016, Elasticsearch for Apache Hadoop (ES-Hadoop) 2.2 rc1 has been . Packing a significant number of bug fixes and enhancements, this release candidate is the last step towards a full general availability release for the current development branch. As always, the artifacts are available at the or . ling updatesES-Hadoop 2.2 RC1 introduced support for the just-released Spark 1.6, in particular skipping that otherwise would be processed again in Spark (despite being already handled by the connector). For large result sets, this results in an important optimization. The push-down translation has been improved, in particular when dealing with filters by providing better matching when dealing with raw terms vs. values (such as dates or timestamps). Speaking of Spark SQL, the schema declaration has been to handle multi-valued\/array fields in a simple and elegant fashion (whether the fields are nested or not). In addition, the connector configuration is now sanitized and passed throughout a Spark job: this addressed a subtle bug caused by command\u00a0line-only properties being discarded during a job stage and causing abnormal behavior. YARN EnhancementsA batch of updates were done to the YARN module by upgrading to Elasticsearch 2.1.x and allowing JVM system properties to be passed directly in the children container. Repository HDFS The repository HDFS plugin has seen a lot of activity. While currently for Elasticsearch 2.0 and 2.1, it requires the JVM security manager to be disabled (as Hadoop is significantly greedier than Elasticsearch itself in terms of permissions), starting from Elasticsearch 2.2, due to the security improvements\u00a0the plugin can customize its own code base grants. Please\u00a0note that the migration of the plugin to Elasticsearch core has and is currently scheduled for Elasticsearch 2.3. More about that\u00a0in a future blog post! Network improvementsThe wan\/cloud has seen a lot of uptake which exposed the connector to more varied network topologies and configuration. This led to a number of fixes in the way ES-Hadoop handles Elasticsearch clusters with hostnames and IPs (typically with network publishing enabled) and the translation between the two. Overall, the connector picks up more information about its environments, reducing the amount of extra configuration on the user's behalf. FeedbackPlease let us know what you think about RC1! We love to hear from you on , or the . ( works too). Looking forward to 2016! \n"}
{"index": {"_id": 775}}
{"title":"Supercharging geo_point fields in Elasticsearch 2.2","seo_title":"Supercharging geo_point fields in Elasticsearch 2.2","url":"\/blog\/supercharging-geopoint","author":{"name":"Nick Knize"},"date":"January 07, 2016","category":"Engineering","locales":"","content":" \u201cI want to location enable my application but where do I start? Elasticsearch has had geo support for some time but how does it work? What are all of those for? What kind of performance can I expect?\u201d The explosive growth of geospatial and spatiotemporal data for so many diverse emphasizes the need for efficient geospatial data structures and analysis tools. With many Geospatial specialty applications and libraries already available, few offer the scalability and flexibility of combined full text search and aggregations with location based information. Enter Elasticsearch. We hope this post answers some of those nagging questions regarding how geospatial field types work and how you can begin location enabling your Elasticsearch-driven applications. So what's new? Elasticsearch has supported for some time: and a short while ago we provided a demo and overview of the available in . While the existing benefit from some of the low level improvements in 2.0 (specifically ), the 2.2 release supercharges fields by improving the underlying data structure and query approach. Indexed by default Prior to 2.2, fields used no default indexing structure (aside from a \u201clat,lon\u201d ). This is because, until Lucene 5.3, a core Geo data structure based on the internal (that did not require a third-party library associated with a ) did not exist. In order to circumvent this limitation, so the could be used, the required specifying at least one of: : , : . At the implementation level the option stored latitude and longitude data as two separate fields, while the option encoded all fields\u00a0as an . Since both structures are based on the , and core types, respectively, supporting 2D geo data indexing required no additional indexing code. With the release of Lucene 5.3, a new specialized GeoPointField type is now available. This field type is built on the internal inverted index structure and all of the amazing work accomplished by the Lucene Community to make this structure as efficient and performant as possible. While an inverted index is not a typical structure used for geospatial data, it can be remarkably fast when applied correctly: and since the structure reuses all of the same codec logic implemented by Lucene, all of the dangerous corruption issues related to introducing new file types for new data structures are less of a concern. In order to work with the inverted index, the GeoPointField type uses a quad-tree raster graphics based approach by encoding latitude and longitude values as a single 64 bit integer and using variable length prefix codes for the terms in the term dictionary. The following graphic illustrates this technique for geo_point data. \u00a0 Further encoding were then applied to minimize the size of the terms dictionary, thus minimizing the overall size of the index. With the performance improvements to there is no need to store every prefix term up to the full resolution. Each point can be approximated using the prefix as a precision step of the top 32 most significant bits. Points along the search boundary can then be further scrutinized using full precision obtained from . This two-phase approach strikes a balance between index size and processing time. Rasterized queries The new approach brings improved efficiency for all available in Elasticsearch. Prior to 2.2, field queries were accomplished using a two-phase approach ( in the 2.0 release). The first phase used either a prefix stemmer for indexed points, or lat\/lon for indexed points to query based on the bounding box of the search area. The full precision results were then checked against the search criteria (e.g., , , ). While the improvements to the two-phase iterator improved query efficiency (especially for ), complex distance and polygon queries still required a check of every point within the bounding box. The 2.2 indexing improvements minimize these checks by applying the benefits provided by the inverted index. As illustrated by the following distance query graphic (taken from a live demo in this ), each query is \u201crasterized\u201d into a set of \u201c\u201d and \u201c\u201d terms. To minimize the number of terms visited, the rasterization step attempts to maximize the coverage area of each term (cell). Terms that intersect the query shape use doc values to further scrutinize candidate points, while terms that are fully contained by the query area simply return all documents from the postings list. This raster decomposition technique reduces the number of brute force checks required by throwing out all terms that are represented by the bounding box but not the shape. Streamlined mapping parameters Prior to 2.2, the field included 8 optional whose default values were partially based on best practices. For example, whether to index or (or both) was often a question that could not be answered until much later in the maturity of the application use-case. By that time geo queries may have already become the culprit for poor quality of service. Compliance with geospatial data standards, created by the and , have been a work in progress requiring leniency options such as and . Other \u201cexpert\u201d parameters such as and are becoming more \u201clook don\u2019t touch\u201d than valuable performance enhancing tools. Since the new structure is designed to obtain the best geospatial index and search performance possible within the construct of the inverted index, the number of parameters is being reduced in the coming releases. The image below provides the parameters for the 2.2 release. The and options are completely removed as they are already handled by the new type. The option will remain to provide users with the flexibility of throwing an exception if Elasticsearch receives non-compliant data (e.g., points outside the standard coordinate system). For backward compatibility the remaining parameters will remain. Users can still store in and\/or sub-fields (setting the numeric , , and parameters will still affect the size of the terms dictionary) but the will no longer search using these sub-fields. They are purely for retrieving the data using the , , or path. Performance results The performance results below are a 1.5 week average benchmark using the following parameters: index 60.8M documents (attributed to ) using 8 client threads and 5000 docs per request against a single node running on a (4 real cores, 8 with hyperthreading), 16 GB RAM and 500 GB Samsung 840 EVO mSATA SSD. While the benchmarks demonstrate a significant supercharge in performance using the new indexing and query approach, we feel we can do far better using a data structure designed specifically for multi-dimensional geospatial data. For this reason we are working hard to bring a new specifically designed for spatial data to a future version of Lucene and Elasticsearch. Stay tuned... \n"}
{"index": {"_id": 776}}
{"title":"Putting our Butts to Work for Your Elastic{ON} Comfort","seo_title":"Elasticsearch User Conference - our butts trying the chairs for ElasticOn comfort","url":"\/blog\/elasticon-chairs-for-your-butts","author":{"name":"Scott Fingerhut"},"date":"January 07, 2016","category":"Culture","locales":"","content":" So, after doing our inaugural Elastic{ON} conference last year, then a 12-city global tour (raising over $150,000 for charity)\u00a0we learned a lot. Two big things were: Behold, the collection of candidate chairs we had sent to the Elastic Mountain View offices for us to put to the test. We didn't even have the cheap seats sent to our office. All of these cost considerably more than typical default conference chairs. Unfortunately, our budget couldn't support the killer reclining\/massaging Lazy Boys we would have all loved. We didn't just look at these and sit in them for a minute, we spent an entire day in them. Here's the status: We've (well some of us) eliminated these chairs (which were the same but different colors) really quickly. We sat in them and although they nicely cradled our bums, when we started rocking in them we quickly came to the conclusion that there was some risk of the legs (of the chair) just snapping off. Then we noticed that the clear chairs gave a perfect view of well, our butts. Upon sitting in the chair, someone in back of me (not to be named) said \"I'm getting crackitis. Are you going to repair some plumbing Scott?\" That was enough for me. Even so, Jason, our other tester persevered and logged this: Jason's report \u2014 \"Captain's Log 0830\" Then I came back from lunch to this: At first this one felt like a nice cupped hand under us. It provided some lower back support and looked sort of cool, but when we leaned back, it just hurt. #3 is done, not much more to say. These are all very similar chairs in structure but have different fabric, so we are doing more rigorous testing. We want to know how slippery they are, how they deal with extra moisture and overall, how comfy they are. . Nice and cool to sit in but a little slippery. If we put our butt near the front end we might just fall right off. We need to figure out the absorbent power of this chair. . These have got the best ratings from our folks. I'm torn a little between the two of these. Like the white fake leather chair, they feel good on the entire back. At this point, the color seems to be more of the debate in the office versus the feel. I have a great comeback for those that prefer based on color. That is \"hey, you don't get to make a call unless you log at least 5 hours in this chair.\" Sadly, many people don't take me up on it. But, for those that do, here's their commentary: \"You know I think the blue is better looking, but if I close my eyes, they both seem almost identical. When I feel the chairs, the blue fabric is a bit softer and the darker color might hide spill and stains more.\" \"Scott, why are you making me sit in this chair?\u00a0I hate you.\" \"Here's the deal, if you sit in any chair long enough it's going to hurt\u2026 Well, except a massage chair, where someone is rubbing your back with medium pressure, and there is soft, tranquil music in the background... Wait, what were we talking about?\" \"Scott, do you have to say 'butt' so much? Tuchus, caboose and toosh are perfectly good alternatives!\" Final conclusion \u2014 It's going to be either 4, 5, or 6. We'll make it a mystery. But, we realized that it's important to take breaks and stretch every so often. So, we'll be trying to suggest small stretch breaks and we encourage you to just stand up once in awhile (apologize to the person behind you) and strike your best yoga pose. We hope to see you at in San Francisco! \n"}
{"index": {"_id": 777}}
{"title":"Elastic donation helps upgrade AbilityNet expert resources","seo_title":"Elastic donation helps upgrade AbilityNet expert resources","url":"\/blog\/elastic-donation-helps-upgrade-abilitynet-expert-resources","author":{"name":"Mark Walker"},"date":"January 07, 2016","category":"Culture","locales":"","content":" StoryEvery year helps hundreds of thousands of disabled people use digital technology to achieve their goals at work, at home and in education. Although thousands of people use our face-to-face services and call our free telephone helpline, our web-based resources are the number one way for people to\u00a0access to our expert knowledge.\u00a0That\u2019s why the support of Elastic was so important to us.The website offers free access to our expert resources and knowledge.\u00a0That could be downloading factsheets, reading our blogs, attending our free webinars\u00a0or using - our guide to every accessibility feature built in to every mainstream desktop computer, laptop, tablet and smartphone. As a charity we need to continually invest in these expert resources and recent funding from Elastic will help us reach even more people. Elastic is a fast-growing\u00a0technology provider of search, logging, and analytics software, used by some of the biggest businesses in the world to power a huge range of services. From live trading data used by banks to the Guardian newspaper\u2019s live content, their tools are designed to take data from any source and search, analyse\u00a0and visualise it in real time.A key part of its success is that Elastic works with a huge community of developers\u00a0who actively grow the open source tools at the core of the Elastic services.\u00a0Nurturing this community has been a vital part of\u00a0its success and the Elastic team recently hit the road for a whistle-stop global tour to connect with users and share knowledge.Each conference of the \u00a0featured a charity partner and AbilityNet was chosen as the beneficiary for the London event.TestimonyHead of Marketing Mark Walker attended the event on behalf of AbilityNet: \u201c\u201c\"\u201d \n"}
{"index": {"_id": 778}}
{"title":"Hosted Elasticsearch: Monitoring Now Available on Found","seo_title":"Hosted Elasticsearch: Monitoring Now Available on Found","url":"\/blog\/hosted-elasticsearch-monitoring-available-on-found","author":{"name":"Cecilie Myhre"},"date":"January 06, 2016","category":"News","locales":"","content":" Today marks a milestone: we have achieved the goal we set when Found joined forces with Elastic back in March last year by making the entire Elastic stack available to our hosted Elasticsearch customers. First, we integrated Kibana 4 in July, Shield for security in September, Watcher for alerting in October, and today, we're excited to announce that the Elastic monitoring plugin, Marvel, is now available on Found, our hosted Elasticsearch product. This is a major engineering milestone for us as it means that all of our Elastic\u00a0plugins are now available on Found. is a monitoring plugin that lets you view and analyze the health and performance of your Elasticsearch clusters in real time as well as historically. The is built on top of Kibana 4, which features a complete UI redesign. To start using Marvel on Found, all you need to do is to enable Marvel and then select a cluster to which you want to ship your Marvel metrics data. We recommend creating a dedicated Elasticsearch cluster for this so it doesn't interfere with any production clusters you are running. Next, you simply launch Kibana on your Marvel cluster and select the Marvel app on the Kibana menu bar to access the key metrics of your clusters, indexes, and nodes. No additional configuration is needed. That's it \u2014 just Marvel-ous. Want to try it out? Sign up for a ! This milestone signifies an end, but also a beginning. As a highly engineering-driven company, there's always going to be a \u2018but wait, there's more', so let's have a peek at what's on the horizon. But first let's take a quick look at how we got to where we are today. Developer's Best Friend in the CloudA few years ago, we were a tiny startup in Norway with some\u00a0wonderful customers who were all fanatic Elasticsearch users looking\u00a0for a better way to host and manage their Elasticsearch clusters than simply doing it themselves on AWS. We stood up to the challenge, and back\u00a0in 2012 we launched the public beta of our hosted Elasticsearch service. We hit challenges early on and \u2018failed fast', which gave us a wealth of experience enabling us to execute well in a fast moving cloud space. Our mission was to be the developer's best friend, by hiding complexity while remaining flexible, and last but not least, by delivering a rock solid, reliable hosted Elasticsearch service. It was still early days in the hosted Elasticsearch domain when we went GA in 2013, but the product showed significant traction in the following months. By the time Elastic acquired Found short of one year ago, we had hundreds of paying customers. Since then, the ride has been simply amazing. A Dream Come True: Found + ElasticWe were secretly hoping to one day become a part of \u2018the core Elasticsearch team', and we had good reasons to believe that Elastic was planning to enter the hosted Elasticsearch market. As it turned out, we were right and Elastic had such faith in what we built that they scrapped the plan of building their own service and instead \u2018popped the question'. In March 2015, . Usually, acquisitions tend to be rather bumpy, but based on strikingly similar culture,\u00a0ethos, and a vision for the future, it was simply a great fit for us and our customers. One result was that many more and also larger companies signed up for Found as they entrusted in the fact that the company who created Elasticsearch was now supporting the Found hosted Elasticsearch service. Today, we are humbled that we are hosting three times as many clusters as before the acquisition and honored to have awesome customers such as HotelTonight, Docker and Instacart enjoying the benefits of Elasticsearch in the cloud. Story complete with MarvelWith a steadily growing cloud team in 2015 and access to the people who built the Elastic products, we have finally packaged all Elastic products into our hosted Elasticsearch solution. As Elastic continues to enhance \u2018the stack\u2019, as well as develop new products, we can assure you that all of these goodies will be packaged with our hosted Elasticsearch service. Already, new Elasticsearch versions and Kibana apps - such as Sense and Timelion - are made available on Found as soon as they are released.Hosted Elasticsearch in Your CloudsIf you see us with shades, it's because the future's so bright... With the usage of Elasticsearch snowballing and more and more businesses adopting the cloud model, we're in a good place. But complacency is not in our DNA. We're all about helping developers, devops, and our customers start and grow their businesses, and what we have come to realize is that despite the increasing demand for Elasticsearch as a Service, there's an unmet demand that we can help deliver: a fully packaged Elastic stack for on-premise environments and private clouds. So if you choose to run Elasticsearch in your own data centers, you can look forward to a downloadable, feature-complete version of the Elastic Stack to run in your own datacenter or private cloud, built by a team with many years of experience managing thousands of clusters. Our goal is to let you use Elastic's products to solve even more challenges and accelerate your business further \u2013 without having to expand your operations teams or ship data out of your data center. So stay tuned! And we promise, there's lots more \u2018Found 2.0' awesomeness to come. Cecilie Myhre and Morten Ingebrigtsen,Directors of Marketing and Product Management (Found Team) \n"}
{"index": {"_id": 779}}
{"title":"AMA (Ask Me Anything) World Recap, Bigger Than Ever For Elastic{ON}16","seo_title":"","url":"\/blog\/ama-booth-elasticon-tour-2015-recap","author":{"name":"Ryan Schneider"},"date":"January 06, 2016","category":"Culture","locales":"","content":" At Elastic, we love the community that uses the Elastic Stack to build amazing products and help solve problems. We recently just wrapped up the world Elastic{ON} Tour where we held 12 one-day events sharing roadmaps, customer use cases, demos, and much more. One of the mutual favorite parts of the Elastic{ON} Tour was the AMA Booth (Ask Me Anything). We read and listen to every piece of feedback and know that asking our engineers, consultants, and architects about details of the various parts of the Elastic Stack is what our users loved the most. We love working the AMA as well and it helps us share new features, explain how things are implemented, share architectures, and offer guidance to make things faster or debug pesky problems. Coming this February 17 - 19 in San Francisco at , the AMA will be a station of amazement full of Elastic engineers, tech leads, founders, and the creators of open source projects Logstash, Kibana, and Beats. Due to this popularity, without further ado, here is a list of our favorite AMA Booth moments and questions: Popular Questions AMA Booth Moments These reasons ultimately are why we feel the AMA Booth is a critical part of our events and will continue to be. For (San Francisco, February 17-19) we are going bigger and better with the AMA. We'll have the largest AMA Booth ever, with every single technical resource in our company at the conference. The AMA will be open almost the entire time of the conference too. So bring your thirst for knowledge, your hardest questions and we look forwarding to Answering Anything\u2026. well almost anything. \n"}
{"index": {"_id": 780}}
{"title":"Practicing The Art of Zen(desk) With The Elastic Stack","seo_title":"Practicing The Art of Zen(desk) With The Elastic Stack","url":"\/blog\/practicing_the_art_of_zendesk_with_the_elastic_stack","author":{"name":"Pius Fung"},"date":"January 05, 2016","category":"Engineering","locales":"","content":" is a popular lightweight helpdesk solution. In this blog post, I will demonstrate how to use the Elastic Stack to provide discovery and visualization capabilities on data that is extracted from Zendesk via a custom Logstash plugin. Logstash: Gather What Matters (Not Just For Logs)Logstash is often used for log collection. However, it is highly extensible and has an intuitive plugin framework developers can use to build their own plugins to fetch data from other sources. To give a perspective on what it will take to build a custom Logstash plugin: I am a software support engineer (not a seasoned developer) with some experience writing internal tools and integrations. With no prior Ruby knowledge, I was able to follow the and write a custom Logstash Zendesk plugin that fetches objects from Zendesk using the official . The majority of the time (~60%) was actually spent on learning the basics of Ruby and interaction with the Zendesk REST API and Zendesk Ruby API Client. The rest was writing code, testing and tweaking the implementation. The custom\/community mentioned above supports fetching various Zendesk objects like organization, user, ticket, comment and topic. The following is an example input block (refer to the Github repository linked above for additional details). You can control the types of objects fetched, fetch mode (full or incremental based on last updated time) and whether to append comments to the ticket in chronological order, etc. input { zendesk { domain => \"company.zendesk.com\" user => \"user@company.com\" # password => \"your_password\" api_token => \"your_api_token\" organizations => true users => true tickets => true tickets_last_updated_n_days_ago => 1 comments => true append_comments_to_tickets => true topics => true sleep_between_runs => 60 } } And the logging output of the plugin at --verbose level: Kibana: Open Up Your MindWith the Zendesk data ingested into Elasticsearch via Logstash, you can use the popular tool to search, discover and visualize the data. For example, here\u2019s a date histogram aggregated by the severity levels of tickets over time. Imagine the other possibilities such as returning the top N customers mentioning keywords like ldap, hadoop, etc.. in their comments. Watcher: Help Others Be MindfulWith the commercial plugin (), you have endless opportunities to create watches not just to help streamline support operations (eg. tracking high severity and aging tickets, etc..). With the power of text search and aggregations, you can also monitor and alert on product quality trends. For example, the following watch\u2019s identifies tickets with comments mentioning out of memory conditions in the past 30 days and aggregates the result by week showing the top 10 tickets sorted by version and date. This will produce a payload that can be to your desire and then sent to an output action. To whom do you send this to? Imagine setting up an output action for the payload to alert the product management team using their or \/ room so they can determine if there are areas in the product that can be improved (eg. circuit breakers). Shield: Block Out DisturbancesYou don\u2019t want your customer data to be wide open. Use the commercial plugin () to require and access control, and set up to further secure your data. Classified customers? No problem, Shield provides more granular role based access control via . Found: Find Peace Of MindDeploying the Elastic Stack on is quick and simple. It literally takes just minutes to spin up a Found cluster provisioned with the latest and greatest Elastic releases. Since it is important to prevent unauthorized access to the data set, you can choose which includes the commercial plugins mentioned above (Shield and Watcher). Once the Found cluster has started, you can simply configure the in your Logstash pipeline to reference the Found cluster\u2019s host(s), Shield user and password, and start indexing! The data will begin to appear in the Kibana app. The best part is that Found is a managed service of the Elastic Stack so you will not have to worry about the uptime of the cluster or spend hours explaining to your infrastructure team what you have deployed or waiting for them to perform operational tasks. It also takes automatic\/periodic backups of your indices. This means you will have more time to build impressive dashboards, work on your regular job, or walk the dog :)As you can see, the Elastic Stack is applicable to many different use cases, not limited to logging. Its flexibility is in its name. With Found, you can also get up and running quickly! \n"}
{"index": {"_id": 781}}
{"title":"Development Tooling Behind Kibana","seo_title":"Development Tooling Behind Kibana","url":"\/blog\/kibana-development-tooling","author":{"name":"Joe Fleming"},"date":"January 05, 2016","category":"Engineering","locales":"","content":" Here on the Kibana team, we're in a unique position: we consume the products that other teams are building as part of what we are building. At a minimum, we have to stand up an Elasticsearch instance and we have to index some data. Short of that, we can't run Kibana, and we can't do our jobs.\u00a0 This may seem simple enough, but it starts to get complicated pretty quickly when we need to test against many different versions of Elasticsearch. We also often need to test different plugin configurations, different datasets, and even run\u00a0development versions of Elasticsearch. With all these varying requirements, things can get complicated and time consuming quickly. In order to make our lives easier, it's in our best interest to automate as much of that process as possible. Naturally, we've built some tools to help with that. Automating DataLet's work backwards and start with indexing data first. To help us with that task, we use a tool called . As the project states, it\u00a0pushes fake HTTP traffic logs into Elasticsearch. There's a little bit of edge-case data that it generates, but it's basically the kind of logs you expect from any Apache or nginx server, with a bell shaped traffic pattern and everything. It's a quick and dirty -\u00a0and very convenient -\u00a0way for us to get data indexed so that we can start creating visualizations. It's really handy for smoke-testing things, particularly when we are spinning up new clusters, which we do a lot. It's also a great way to get people new to the team up and running, before they find something real that they want to index. Automating ElasticsearchMakelogs is great, but its scope is tiny, and its utility outside of Kibana development is limited. Perhaps more interesting is the tool we use to automate Elasticsearch, a tool named . Short for Elasticsearch Version Manager, esvm was born out of our need to maintain not just multiple versions of Elasticsearch, but also multiple clusters, each with its own unique configuration and\u00a0data. It will download the specified version of Elasticsearch, start it up with the default configuration, use your computer's hostname for the cluster name to prevent external auto-joining, and even wrap its output to help make it a little easier to read. If you want to run the latest version of Elasticsearch, no arguments are required, just run . If you want a different version, just pass it as an argument, like . If, instead of a version, you need to run a build from a specific branch, something like will do just that. All of that is handy, but esvm gets really interesting, and really powerful, when you use it with a JSON config file.\u00a0 Automating Cluster ConfigurationThe esvm config takes all the settings from the standard elasticsearch.yml and passes them as runtime settings. Common settings like enabling CORS, turning on mlock, and turning off multicast make great default settings. Any clusters you define will inherit the default settings, but also allow you to override them as needed. Plus, you can define the version or branch to use, and any plugins to install. For example, if you wanted to run a 3 node cluster built from the latest commit on the master\u00a0branch, this is all it takes: \"clusters\": { \"latest\": { \"branch\": \"master\", \"nodes\": 3 }, } Then run and you're up and running. From there, adding plugins is\u00a0easy,\u00a0just add a \"plugins\" section\u00a0to the\u00a0cluster configuration and a list of the plugins you'd like to install. \"plugins\": [ \"license\", \"shield\" ] Relaunch the cluster and now you've got Shield installed with an evaluation license ready to go. And if you'd like to\u00a0pre-define some users and their roles, just add this to the configuration: \"shield\": { \"users\": [ { \"username\": \"kibana\", \"password\": \"notsecure\", \"roles\": [\"kibana4_server\"] }, { \"username\": \"user\", \"password\": \"notsecure\", \"roles\": [\"kibana4\"] } ] } And because you can define\u00a0as many cluster configurations as you'd like, a single JSON file will allow you to easily spin up whatever configuration\u00a0you need. Of course, once you have\u00a0a few clusters defined you may find yourself forgetting what's available. Enter the \u00a0flag. So that's and , two tools that make our jobs easier and help us focus on building Kibana, instead of setting up infrastructure.\u00a0 We're also working on building tools that will make our users' lives easier too, the first of which is our , which helps you get started writing your own Kibana plugins.\u00a0But that's a topic for another post. Stay tuned! \n"}
{"index": {"_id": 782}}
{"title":"Key points to be aware of when upgrading from Elasticsearch 1.x to 2.x","seo_title":"Elasticsearch 2.x upgrade","url":"\/blog\/key-point-to-be-aware-of-when-upgrading-from-elasticsearch-1-to-2","author":{"name":"Miguel Bosin"},"date":"January 04, 2016","category":"Engineering","locales":"de-de,fr-fr,ja-jp,ko-kr","content":" Overview As part of any software deployment life cycle, one is often faced with the need to upgrade to the latest release of a product: both to keep up with new features and bug fixes as well as ensure supportability. Elasticsearch is no different and with the release of version 2.0 a number of major changes have been included, which can result in breaking an existing 1.x installation upon upgrade. This is referred to as in the documentation. Please note that a FULL cluster restart will be needed. on\u00a0upgrading from Elasticsearch 1.x to 2.x. So how do I upgrade to Elasticsearch 2.x smoothly? With a bit of testing in a non-production environment, there should be very little reason for any upgrade to fail or create inconsistencies in your data. This does, however, require some planning which could be summarised as follows: \u00a0 \u00a0 \u00a0 \u00a0\u00a0\u00a0 \u00a0 \u00a0 \u00a0\u00a0 My upgrade is broken, please help! Should the upgrade gremlins appear and attempt to wreak havoc in your life, regardless of having carefully followed the previous set of steps, there are some additional avenues you can pursue: Looking for ways to minimize your downtime or reduce your maintenance window for a full cluster restart? If the risks seem too great or the upgrade mountain too high to climb, there are some options you can also consider: Although this approach will require more physical (or virtual) resources initially (although the likes of a test environment could be repurposed for this function temporarily at little additional capacity cost), it will be for a very short period of time. Once the new cluster is able to match the data of the old, along with all required functionality for your front-end application, the full switch-over may be an easier alternative. Known Issues Below are a list of issues that have been seen which may be of value when considering your upgrade plan, along with any troubleshooting you need to perform with failed or partial upgrades: \n"}
{"index": {"_id": 783}}
{"title":"Log In, Upgrade, Be Happy","seo_title":"","url":"\/blog\/log-in-upgrade-be-happy","author":{"name":"Erik Redding"},"date":"December 30, 2015","category":"Engineering","locales":"","content":" This article refers to\u00a0our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud.There are a few different types of users on Found, the official Elasticsearch as a Service by Elastic. We have customers that want the latest and greatest and are first to jump on the latest releases of Elasticsearch. On the other hand, we also have customers that want to keep things where they are because they\u2019re satisfied with the cluster\u2019s feature set. Either way, we\u2019re glad you\u2019re on board but we want to make sure you\u2019re getting the most from your cluster. Upgrades are Easy on FoundOne of the best things about using Found is the ability for customers to be able to upgrade Elasticsearch versions and cluster sizing with just a couple of clicks. Another great feature of Found is the same-day availability of the latest Elasticsearch releases. We bill by the hour, so spinning up a test cluster is affordable. As an Ops guy, the features on Found make me smile because I can make sure my Elasticsearch clusters are running with the latest bug fixes, security patches and performance gains in Elasticsearch. At Elastic we use Found in a myriad of ways, from site search to BI and analytics. The fast upgrade paths in combination with high-availabilty configurations let me rest easy while we dog-food Found clusters to support the running of our business. When I\u2019m looking to upgrade a cluster to a new release, I\u2019ll typically build out a quick checklist of tasks. Here\u2019s my abbreviated minor-version upgrade checklist: If everything goes well, we\u2019ll carry out the upgrade. Major release versions typically require much more testing, but again, smoke-testing a major release upgrade can be just as easy depending on your configuration. The\u00a0\u00a0has some more information around renaming indexes on restore and other tips. The LatestWhy upgrade versions, you ask? There are some key features for different Elasticsearch versions that we want our Found customers to be made aware of and embrace. 1.X ClustersIn general, clusters running anything older than 1.7.4 are encouraged to move to 1.7.4. Breaking changes are outlined in our\u00a0: most customers will find that they can upgrade easily to 1.7.4. If you\u2019re wondering what\u2019s new for the 1.7 releases, there have been a series of blog posts around the release announcements for\u00a0,\u00a0,\u00a0, and\u00a0. These posts outline high-level notable features for each release. 2.0.X and 2.1.X ClustersIf you\u2019re running an Elasticsearch 2.0.X or 2.1.0 cluster without replicas, please upgrade to 2.0.2 or 2.1.1 today because there is a very important fix around\u00a0. The default cluster configuration on Found is to have a single replica shard, but many people adjust settings for their use case. Kibana ReleasesWe manage all the details behind the Kibana releases so you don\u2019t have to worry about keeping those up to date. If there\u2019s a security-related patch like we saw with the\u00a0, we will upgrade the Kibana instance. Finding Out What\u2019s NewCustomers interested in keeping up with the latest releases and improvements in Elasticsearch can follow the\u00a0\u00a0for the latest release announcements and more. The\u00a0\u00a0are a great way to keep up with the community and include\u00a0. In Conclusion\u2026 \n"}
{"index": {"_id": 784}}
{"title":"Being Exceptionless with Elasticsearch","seo_title":"Exceptionless with Elasticsearch","url":"\/blog\/being-exceptionless-with-elasticsearch","author":{"name":"Blake Niemyjski"},"date":"December 22, 2015","category":"User Stories","locales":"","content":" is an open source technology company that deals in real-time event reporting and logging, focusing specifically on error reporting. Our goal is to help the world's developers improve their applications and user experience by being\u2026 well... exceptionless. To be Without ExceptionExceptionless provides real-time error reporting for JavaScript, Node, , Web API, WebForms, WPF, Console, and MVC apps. Everything is pulled into a dashboard that organizes each event into a simple yet robust and fully-featured view that gives you quick access to actionable data that will help your app become exceptionless! We\u2019ve learned quite a bit since the first version of Exceptionless, and we\u2019d love to share our story on why we ended up migrating to Elasticsearch with great success. In the first version of Exceptionless, we were using MongoDB for our primary document data store. We chose it for it\u2019s ease of use, ability to scale out instead of up, and the cross platform story. It worked pretty well until we started to grow, then we began having issues scaling several features, such as real-time dashboards with automatic time zone shifting, backups, restores, and storage. Real-time DashboardsWhen we first built our real-time based dashboards with MongoDB, we had to do a ton of research on timezones, which is a monumental task in and of itself. We found that we would need to pre-aggregate data into 15 minute buckets of time (to account for different time zone offsets) into separate collections, in addition to our event collections. This would allow us to quickly return statistics data for any 15 minute time frame, but it also added the expense of additional storage and processing time needed to shift the buckets of stats into the desired time zone with each request. We were really excited to learn that, by moving to Elasticsearch, we would not only solve this difficult problem using the , but that it would also allow us to: Fig. 2: Exceptionless Kibana 3 Dashboard Backup and RestoringOne of the huge pain points prior to moving to Elasticsearch was backing up MongoDB. There isn\u2019t a lot of documentation for doing so in production, which leads users to bring down the cluster to do a quick backup via MongoDump, zip the backup, and upload it to some destination. The other option is to pay monthly fees and run an extra node for the MMS service, which does oplog backup and restore. One of the most underrated features of using Elasticsearch is backups and restores! It has been the most pleasant experience to configure and use. We setup a on one of our nodes to run for cleanup, and to run a backup to azure blob storage via the . The nicest thing about this is you can quickly choose exactly what index to restore to a development machine if you wish to debug production data, while keeping your data secure and backed up in the cloud. Disk SpaceAfter migrating our data we found\u00a0that it used about one-fifth the disk space as MongoDB (please note that wasn\u2019t released until sometime after we migrated). This allows us to cut our storage costs across the board. Scaling OutThere is nothing worse than waking up to find that a VM reboot of one of the nodes or adding a new node caused your MongoDB cluster configuration to become corrupted. This is a very scary situation we once had to deal with and resolve by restoring the cluster configuration. We always found that dealing with the MongoDB cluster configuration is something you don\u2019t touch if it\u2019s working. We love how easy it is to an Elasticsearch cluster. It\u2019s a dream come true! No matter how you want it to run, it\u2019s just a simple configuration setting or REST call away! Best of all, you can share your configuration with others to get feedback! ConclusionWe are very happy with the move to Elasticsearch and continue to receive additional value from it with every release. We really like that it\u2019s easy to setup and is open source friendly! \n"}
{"index": {"_id": 785}}
{"title":"Brewing in Beats: Filebeat filtering inputs","seo_title":"","url":"\/blog\/weekly-beats-filebeat-filtering-inputs","author":{"name":"Monica Sarbu"},"date":"December 21, 2015","category":"Brewing in Beats","locales":"","content":" Welcome to ! With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources. Last week we released Beats 1.0.1. \u00a0, and send us your feedback on . Jstatbeat We are happy to see another Beat created by the community: created by. \u00a0It used for monitoring the JVM garbage collector monitoring by reading jstat results and indexing them in Elasticsearch. There is a blog post about the new Beat (in Japanese). Fixing ignore outgoing transactions in Packetbeat An regarding configuration option was reported last week. The problem appeared as the configuration option was working only when the topology map was created. The allows usage of ignore_outgoing configuration option without the need to have the toplogy map enabled. Additionally, setting the \u201cdirection\u201d to outgoing is fixed in the same. \u00a0 Reduce bulk size The bulk size value is changed from 10k to 200 with the. The high value of 10k caused memory issues when Logstash was not available or slow to process data. This is because the 10k gets multiplied with the worker queue size (1000). Exclude files in Filebeat The adds support for the \u201cexclude_files\u201d configuration option to the Filebeat prospector. You can specify a list of regular expressions to match the files that will be ignored. This is useful if you want to include all the files in a directory (\/vat\/log\/apps), but exclude those that have been rotated and zipped (.gz). filebeat: prospectors: - paths: [ \"\/var\/log\/apps\/*\"] exclude_files: \"\\\\.gz$\" Non-string fields values in Filebeat This adds support for non-string values of the custom Logstash fields in the \u00a0configuration file. Each field can now be a scalar value, an array, a dictionary, or any nested combination of these. Add basic instrumentation to the Publisher extends the -httpptof interface to export a few basic metrics from the libbeat publishers over. These are very useful for us to troubleshoot performance issues and to detect when there are drops in Packetbeat and Topbeat. Working on adding multiline support in Filebeat support in Filebeat is an important feature request by our community. We started working on it and you can follow its status in this. Winlogbeat in the next releaseThe first version of Winlogbeat is almost ready and it will be included in the next minor release. It has the ability to read event logs from Windows Event Log API and Event Logging API. You can follow the Winlogbeat status under the. \n"}
{"index": {"_id": 786}}
{"title":"The Giving Culture of Elastic","seo_title":"The Giving Culture of Elastic","url":"\/blog\/the-giving-culture-of-elastic","author":{"name":"Kristina Frost"},"date":"December 21, 2015","category":"Culture","locales":"","content":" I'm an only child from a big family.Growing up, my family lived pretty far away from the rest of my relatives, so every holiday season it was off \"to Grandmother's house we go\" -- not in a sleigh through a picturesque winter landscape, but in a car, driving anywhere from six to fourteen brutal hours across the American midwest. Both of my parents come from pretty big families, and so Christmas and Thanksgiving have always been the time of year when I'm thrust out of my comfortable, quiet family unit of three and into a circle of countless relatives. I joke with friends of mine that only children are tyrants. There are pros and cons to this: con - if you are an only child you don't share dishwasher duty with your siblings a few nights a week. You do it every night of the week. But on the flip side, when there's a child's birthday in the house, every present is for you. I guess what I'm getting at is that these early Christmases were the first time that I ever really remember watching other people open presents, the first place where I learned about giving and receiving in the context of a community. The first place where the principle of \"it is better to give than to receive\" ever made itself evident in my life.Of course, now I'm a grown-up, and so I don't just receive presents, I give them. In fact, I have a lot of fun every year trying to find the funniest gift, or the coolest one, or the one that people will really remember for more than just a month. I think these kinds of holidays are a way to celebrate each other perhaps as much as whatever is that our particular family tradition suggests we reflect on at this and other times of the year. And our family and friends are very often the easiest people to celebrate. What I've been reflecting on this holiday season, amidst a world in which tragic events surround us and frighten us, amidst divisive rhetoric that tends to suggest people who aren't from our tribe, whatever that tribe looks like, aren't worth our time or our energy or even our charity is: how much harder it is to celebrate the people we don't know.And I've been reflecting on what the world looks like for lots of children who don't get a share in the kinds of privileges that I grew up with. About a world where none of the presents are ever for them. Where every year the holiday season comes and goes, and it's never their turn at the table.Which is why, this month, I'm glad to be here at Elastic. Don't get me wrong: I've been glad to be here, because we build a product that an enormous community of folks out there in the world are using to try to solve problems for all kinds of companies, companies that build apps that are used by all kinds of people. I've been glad because I work for a , and because I finally work somewhere with a crack analytic team that might be able to solve one of life's biggest mysteries and tell me which White Elephant gift is really the most bang for my buck.More than all that, though, I'm also extremely proud: we've capped off a series of tour stops around the world where we raised nearly $150,000 for 9 local charities each with a concentration on boosting STEM (science, technology, engineering & math) programs for underserved\u00a0youth. I lead a Women of Elastic brunch here in our Mountain View office (another blog post for another day, that), and we ladies challenged ourselves to double down on our own philanthropy efforts this holiday season. \"I just don't believe any child should ever go hungry,\" said one of our most tenured Territory Managers. But she doesn't just say it, she lives it, and she's the one who set up a donation drive in the office for a local food bank which wound up providing 3,240 meals. Canned food drives are great, don't get me wrong, but at wholesale rates, most food banks can really stretch the dollars of any donation, and it was fantastic to see just how far we were able to go. Our men of the office, not to go unmatched, led a Movember campaign that raised over a thousand dollars towards this worthy cause. Our User Success Teams around the world regularly engage in organizing everything from charity walks to pet shelter days.And in December, our Mountain View and London\u00a0offices rallied around getting loads of gifts for underprivileged children locally:\u00a0\u00a0 \u00a0It was my job, last week, to pile all these gifts into my vehicle and haul them over to the warehouse where they'd be wrapped and delivered. In addition to each present, the respective\u00a0organizations we worked with in both Mountain View and London\u00a0asked that we provide each child with a new toothbrush. Imagine that: a toothbrush. A colleague of mine suggested having his own children shop for the gift, so that they, too, get to participate in this paying it forward to strangers who may never see our faces or even have an opportunity to reciprocate our generosity.So I'm glad, and I'm proud, and I'm also thankful. It's been a long time since I've gotten to be that child I was writing about a few paragraphs before, looking at a pile of presents, wondering who was going to get what, and every time I walked through our lunch room last week, I had the privilege of revisiting some of that community spirit and some of the incredible wonder that children have. And I got to marvel about how for as much as things change (there's several iPod Minis in that pile), the more they stay the same (there's also a simple red tricycle).Most of all, though, I get the privilege of spending this month with a bunch of incredibly smart folks who have decided that this year not only will we celebrate each other or even our company: we're going to celebrate these kids we don't know and who we may never going to get to meet. We're going to make sure they, too, get a seat at the table. We're not very big, and we can't do it all, but there's a quote I like that this type of stuff always makes me think of, attributed to Edward Everett Hale:Somewhere out there is a family who got one extra meal because we made the effort to make it so. Somewhere out there, a little boy will wake up over the holidays, and perhaps there will be a tree, or perhaps there won't be one at all, because maybe trees aren't what his family is into. In either case, there will be a box with his name on it. He will tear into it with the excitement and the anticipation that I so clearly remember, and inside there will be a shiny red tricycle that somebody else got, just for him, for no other reason than the fact that he, too, is deserving of delight.Whatever tradition it is that you celebrate, happy holidays from the folks here at Elastic. May we all keep finding the little somethings that we can do for the communities we know, but also for the ones that we don't. Enough of those little things, all piled up together, might look like the trunk of my car, overflowing with gifts.---Kristina Frost is a Manager of Strategic Sales Operations at Elastic. \n"}
{"index": {"_id": 787}}
{"title":"Powering ITV\u2019s DevOps Engine with the Elastic stack","seo_title":"Powering ITV\u2019s DevOps engine with the Elastic stack","url":"\/blog\/powering-itvs-devops-engine-with-the-elastic-stack","author":{"name":"Efstathios Xagoraris"},"date":"December 21, 2015","category":"User Stories","locales":"fr-fr","content":" The ChallengeAt ITV we have several legacy products and several teams working on them. At the same time the teams are trying to deliver new and exciting products. Those systems emit logs to standard locations and designing a logging system was mostly a task for the product itself. There were different teams acting in a SILO mode, delivering a solution that worked only for them. We wanted a solution that works for all our products and different teams can easily inherit. This is the solution we came up with at ITV: Our objective was simple: One of the problems we tried to solve was around logging. Logging is one of the things that is constantly changing along with the product life. Traditionally we used to store logs in the file system and create reporting applications along with custom dashboards & interfaces for both development and management teams to search the logs. The problem with that approach is that it\u2019s not repeatable, it\u2019s not common and it is difficult to develop additional dashboards. We don\u2019t want to SSH into servers to search application logs in 2015. We want to surface information to a higher level interface and give access to users through dashboards to search logs. The\u00a0Elastic\u00a0Stack to the RescueWe started using the Elastic technology stack 1.5 years ago and recently we made the decision to put the full Elastic stack deep in our Common Platform specification as the standard logging mechanism for all ITV products hosted by the platform. We tried and tested every component. It had to play nicely with our configuration management and our cloud environment before we adopted it. Elasticsearch\u2019s ability to index & search million of log entries daily was impressive. The ability to create dashboards and share them using Kibana was unbelievably easy compared to the past. Finally, Logstash convinced us handling multiple sources with so many filter capabilities. All of that together lead to the fact that the Elastic stack won a thumbs up by our operations team. Using the Elastic Stack in our Brand New ITV HUBITV has replaced both\u00a0ITV Player and ITV.COM with a new destination for catch-up content and online services, the . With over 11 million registered users and 726 million long form requests (video requests for actual programs and not short clips)\u00a0last year we have a web platform that generates lots of logs. We use the Elastic stack to create useful dashboards for Ops & Devs to display operation metrics. Our Elasticsearch instances live on AWS and already handle millions of logs every day. Logstash ability to handle logs from multiple sources allow us to handle AWS logs such as Cloudtrail & ELB logs in the same Elastic stack. Elasticsearch\u2019s curator keeps things tidy and everything is managed through our configuration management in a scalable solution.Below we have an example for some useful dashboard\u2019s created by our developers to help them debug production issues: . What's Next?ITV Hub is only one of the many products within ITV that uses the Elastic stack. We already started building other products based on Kibana 4. Also we want to try the new Elasticsearch 2.0 and the time series data store as a potential replacement of our existing data store. It looks very promising and some of the early demos are exciting! Our core logging system is powered by the Elastic stack so all our product teams directly benefit from having a logging solution covered right at the beginning of the life of a product. System & Application dashboards really tear down the wall between Dev & Ops and the logs stream very smooth with the Elastic stack :) \n"}
{"index": {"_id": 788}}
{"title":"Beats 1.0.1 released","seo_title":"","url":"\/blog\/beats-1-0-1-released","author":{"name":"Tudor Golubenco"},"date":"December 17, 2015","category":"Releases","locales":"","content":" Today we are releasing a patch release for the Beats, fixing some of the issues reported since the 1.0.0 release. Changed the default bulk size for the communication with LogstashThe previous default was quite high (10000), which worked good in normal operations but could cause a significant increase in memory usage when Logstash was temporary unavailable. We have reduced the default to 200, which worked good in the real world installations that we tried it on. The setting can be changed from the option from the logstash setting in the configuration of any of the Beats. Improved the force_close_files configuration settingThe settings exists in Filebeat to deal with the way Windows still shows deleted files in the file system until they are closed by all the processes that have them open. We tweaked its behavior a little to better detect when files are rotated on Windows. See this for the discussion. Fixes and performance improvements for the Redis and MongoDB parsersSeveral performance issues and crashes in the Redis and MongoDB protocol implementation in Packetbeat have been solved. Please see the release notes for the links to the relevant tickets and pull requests. \n"}
{"index": {"_id": 789}}
{"title":"Elasticsearch 2.1.1, 2.0.2, and 1.7.4 released","seo_title":"Elasticsearch 2.1.0 and 2.0.1 released","url":"\/blog\/elasticsearch-2-1-1-and-2-0-2-and-1-7-4-released","author":{"name":"Clinton Gormley"},"date":"December 17, 2015","category":"Releases","locales":"","content":" Today we are pleased to announce bug fix releases of based on , , and Elasticsearch 2.1.1 contains a number of important bug fixes. Where possible, these have been backported to Elasticsearch 2.0.2. All users of Elasticsearch 2 are advised to upgrade to Elasticsearch 2.1.1 if possible, or at least to Elasticsearch 2.0.2. Bug fixes in 2.0: Bug fixes in 1.7.4: Elasticsearch 1.7.4 contains a few improvements to delayed shard allocation that will make recovery after node restarts more efficient. The most important changes in 2.1.1 and 2.0.2 are as follows: Translog corruption when disk fullThe transaction log could be corrupted when writing to disk fails for some reason such as a full disk. When Elasticsearch detects the corruption it will fail the shard and recover to a new node. However, if replication is disabled\u2009\u2014\u2009a configuration that we advise against\u2009\u2014\u2009then this bug could lead to data loss. ( , backported to 2.0.2) We have also removed a spurious log message indicating that a temporary transaction log file could not be deleted (, backported to 2.0.2) and another reporting failures to write to a transaction log which has already been closed (, backported to 2.0.2). Preventing conflicting mappingsFields with the same name in different types in the same index must have the same mapping\u2009\u2014\u2009conflicting mappings are not allowed. Unfortunately, when using dynamic mappings, only the first attempt to add a conflicting field would be rejected. Subsequent attempts could succeed. This was a serious bug as the conflicting mappings prevent shards from the index from being relocated to a different node or from being recovered after a restart. (, backported to 2.0.2). This change also fixes an issue that prevented users of field datatypes provided by plugins from upgrading, e.g.\u00a0, , . NullPointerException during indexingA number of users of 2.1.0 reported NullPointerExceptions while indexing, which turned out to be caused by a failure to clear an empty during refresh. This has been fixed in and in . Children aggregation missing documentsThe aggregation only evaluated segments that contained matching parent documents, which meant that it might miss child documents that existed in other segments and so report incorrect results. (, backported to 2.0.2) Tribe node configurationA bug was introduced in 2.1.0 that caused Tribe nodes to require their own configuration directory for each cluster, instead of accepting their settings from the main configuration. () Index and alias name conflictsA bug in 1.x allowed an index template to create an alias with the same name as an index (fixed in ). This is an illegal state that prevents users from upgrading to 2.x. Any index that has an alias with the same name must be deleted before upgrading. However, the exception thrown in 2.x was incomprehensible and has been replaced with a more meaningful message. ( , backported to 2.0.2) Performance regression after deleting an indexIn 2.1.0, creating an index, indexing some docs, deleting the index, then creating an index with the same name led to a performance regression on further indexing requests. () Watcher email alertsA classloader bug which sometimes prevented Watcher from sending emails has been fixed in both 2.1.1 and 2.0.2.ConclusionPlease , try it out, and let us know what you think on Twitter () or in our . You can report any problems on the . \n"}
{"index": {"_id": 790}}
{"title":"Kibana 4.3.1, 4.2.2, and 4.1.4 released","seo_title":"","url":"\/blog\/kibana-4-3-1-and-4-2-2-and-4-1-4","author":{"name":"Court Ewing"},"date":"December 17, 2015","category":"Releases","locales":"","content":" Today we\u2019re releasing stability and security updates to Kibana 4.3, 4.2, and 4.1. We strongly recommend that all users upgrade their Kibana installs immediately. Due to the security fixes, Found customers are being updated automatically. \u200b 4.3.1 Changes 4.2.2 Changes 4.1.4 Changes Where to download You can download Kibana at our page. If you encounter any bugs with either of these versions, please file them on the github page. If you have any questions or concerns, do no hesitate to reach out on or our discussion . \n"}
{"index": {"_id": 791}}
{"title":"Deploying Elasticsearch 2.0.0 with Chef","seo_title":"ES Chef Cookbook","url":"\/blog\/deploying-elasticsearch-200-with-chef","author":{"name":"Martin Smith"},"date":"December 17, 2015","category":"User Stories","locales":"fr-fr","content":" Chef is a configuration tool written in Ruby and Erlang. It uses a pure-Ruby, domain-specific language (DSL) for writing system configuration \u201crecipes\u201d. Chef is used to streamline the task of configuring and maintaining a company\u2019s servers, and can integrate with cloud-based platforms such as Rackspace, Internap, Amazon EC2, Google Cloud Platform, OpenStack, SoftLayer, and Microsoft Azure to automatically provision and configure new machines. As mentioned above, the can help you move from a demo environment to a full-fledged production ready cluster. With the newest 2.0.0 release, the cookbook can help you automate and maintain the following: Features of the Chef cookbook for Elasticsearch: Pre-requisites Before we begin, there a few things you should have already for this tutorial. Namely With those out of the way, let\u2019s start by showing how to build a wrapper cookbook that can install, configure, and start the Elasticsearch software on a new server. Build your wrapper cookbook Now we\u2019re ready to build our new cookbook. We\u2019re using the here, which means we\u2019re making a new cookbook that we run directly on our new ES server: it will be the only cookbook we run on our ES server, and it will for the new server as well. We will be calling our wrapper cookbook elasticsearch-chef-blog, and we\u2019ll use ChefDK\u2019s chef command to create it: root@chef-workstation01:~# chef generate cookbook elasticsearch-chef-blog-demo Compiling Cookbooks... Recipe: code_generator::cookbook ... root@chef-workstation01:~# cd elasticsearch-chef-blog-demo\/ root@chef-workstation01:~\/elasticsearch-chef-blog-demo# ls -la total 48 drwxr-xr-x 6 root root 4096 Nov 22 20:39 . drwx------ 8 root root 4096 Nov 22 20:39 .. -rw-r--r-- 1 root root 47 Nov 22 20:39 Berksfile -rw-r--r-- 1 root root 1029 Nov 22 20:39 chefignore drwxr-xr-x 7 root root 4096 Nov 22 20:39 .git -rw-r--r-- 1 root root 126 Nov 22 20:39 .gitignore -rw-r--r-- 1 root root 355 Nov 22 20:39 .kitchen.yml -rw-r--r-- 1 root root 267 Nov 22 20:39 metadata.rb -rw-r--r-- 1 root root 77 Nov 22 20:39 README.md drwxr-xr-x 2 root root 4096 Nov 22 20:39 recipes drwxr-xr-x 3 root root 4096 Nov 22 20:39 spec drwxr-xr-x 3 root root 4096 Nov 22 20:39 test Next, we\u2019re going to add the Elasticsearch cookbook as a dependency in metadata.rb in our new cookbook. We\u2019ll add the line at the bottom of metadata.rb, so that our full file now looks like so: name 'elasticsearch-chef-blog-demo' maintainer 'The Authors' maintainer_email 'you@example.com' license 'all_rights' description 'Installs\/Configures elasticsearch-chef-blog-demo' long_description 'Installs\/Configures elasticsearch-chef-blog-demo' version '0.1.0' depends 'elasticsearch', '>= 2.0.0' elasticsearch Write your recipe Next, we need to write the simple recipe that utilizes Chef resources to install a simple Elasticsearch node. We will edit the file recipes\/default.rb, and we\u2019ll place the following snippets there: A note about resource names Many of the resources provided in this cookbook need to share configuration values. For example, the resource needs to know the path to the configuration file(s) generated by and the path to the actual ES binary installed by . And they both need to know the appropriate system user and group defined by . Search order: In order to make this easy, all resources in this cookbook use the following search order to locate resources that apply to the same overall Elasticsearch setup:\u00a0 Create a user Whether we decide to install from a .tar.gz archive or using the provided OS packages, we use the elasticsearch_user resource here to be sure that a user and group are created for Elasticsearch on our system. The later resources will use this resource to determine what the appropriate user should be for Elasticsearch. By default, we name this user elasticsearch. elasticsearch_user 'elasticsearch' Alternately, if you\u2019re installing by package, and would rather let the package create the user, you can set the action to on this resource, but it for the other resources to look up and retrieve the desired user. Here\u2019s what that would look like: elasticsearch_user 'elasticsearch' do action :nothing end An even more complete example, with many of the defaults explicitly set, would be: elasticsearch_user 'elasticsearch' do username 'elasticsearch' groupname 'elasticsearch' shell '\/bin\/bash' comment 'Elasticsearch User' action :create end Install Elasticsearch Next, with a user and group in place, it\u2019s time to install elasticsearch. By default, the cookbook chooses the package installation, so the most minimal installation can simply be , however for our case, we want to remind ourselves of the default installation method, so we explicitly list it: elasticsearch_install 'elasticsearch' do type :package end This resource will download the correct package (using a default version from the elasticsearch chef cookbook, currently 2.0.0), and install it using the package manager. If you\u2019d like to override the version, here\u2019s a more elaborate example that specifies exactly what version to downloading and install: elasticsearch_install 'elasticsearch' do type :package version \"1.7.2\" action :install end If you\u2019re wondering how the elasticsearch chef cookbook knows about specific versions, or figures out where to download them from, check out the file. That file has a complete list of known versions. If a newer version isn\u2019t listed yet, we might be behind and would appreciate your to let us know that we need an update! If you want even more control over the downloaded package, you can even specify a full URL using the url and checksum parameters to the resource: elasticsearch_install 'elasticsearch' do type :package version \"1.7.2\" download_url \"https:\/\/download.elasticsearch.org\/elasticsearch\/elasticsearch\/elasticsearch-1.7.2.deb\" download_checksum \"791fb9f2131be2cf8c1f86ca35e0b912d7155a53f89c2df67467ca2105e77ec2\" # sha256 checksum action :install end It\u2019s important to remember that Chef is idempotent here. It will query the package manager on each run, verifying that the specific package name at the given version is already installed. If a server is updated to a newer package, or is on an older package version, Chef will try to downgrade or upgrade as appropriate. It\u2019s always critical that any upgrade or downgrade attempted via chef is tested before being applied to a production system. If you need to force a particular package manager operation, there is an as well. Configure Elasticsearch Now that we\u2019ve written our install resource into the recipe, it\u2019s time to configure an Elasticsearch instance. In our pre-requisites, we specified that you should have a server with at least a 1GB of memory, so we\u2019re going to define an instance that uses 512M of memory. We\u2019ve also given a cluster and node name for our instance. It\u2019s important to note that , unlike in previous versions of the cookbook where you could nest these hashes. elasticsearch_configure 'elasticsearch' do allocated_memory '256m' configuration ({ 'cluster.name' => 'mycluster', 'node.name' => 'node01' }) end While this is a trivial example, this resource . If you , you can see that you might want to override. Most importantly, take note that most configuration parameters for the resource are a hash with defaults both for the packaged installation and the tarball\/binary installation. elasticsearch_configure 'elasticsearch' do allocated_memory '256m' path_data package: \"\/mnt\/high_performance_data_disk\" configuration ({ 'cluster.name' => 'mycluster', 'node.name' => 'node01' }) end Above is another example of configuring an elasticsearch instance. While normally path.data must be supplied in the configuration hash.\u00a0We\u2019re taking advantage of the fact that that will automatically be populated in the configuration hash if we use the corresponding resource attribute. If you\u2019d like to see our entire template for elasticsearch.yml, too. Run Elasticsearch as a system service Now that our instance has some configuration files written, it\u2019s time to be sure it has a system service. The defines a system service and enables it on boot. Note that, however, like the packaged version of Elasticsearch, , to protect you from accidental data loss or joining the wrong cluster (this is extremely common on some cloud providers). If you\u2019d like to start the service immediately, you can configure the service_actions parameter of the resource with any actions you want passed to Chef\u2019s service resource implementation. In our example below, we are asking Chef to start the enable (start on boot) and start the service right now. elasticsearch_service 'elasticsearch' do service_actions [:enable, :start] end In addition to using the provided init script, you can ask the elasticsearch_service resource to use a template from your own wrapper cookbook. While we haven\u2019t done that in our demo, here is the syntax for what it would look like: elasticsearch_service 'elasticsearch' do init_source 'my_custom_initscript.erb' init_cookbook 'elasticsearch-chef-blog-demo' service_actions [:enable, :start] end Finally, it\u2019s worth pointing out that with any notifications and they will be passed through to the underlying service resource. We take advantage of this in the next section. Install some plugins for Elasticsearch Last, but not certainly not least, we install some plugins. To do this, we\u2019re using the resource. Note that the , and you can use the url parameter to specify the argument(s) used for the Elasticsearch plugin install command. If you wish to name the resource something else, you can provide the parameter as well. elasticsearch_plugin 'head' do url 'mobz\/elasticsearch-head' notifies :restart, 'elasticsearch_service[elasticsearch]', :delayed end Note that the example above , automatically restarting Elasticsearch if the plugin was changed in any way (if we installed or removed it on this chef run). This in a cluster, if too many nodes are restarted at once, or if a plugin causes Elasticsearch to fail to start.\u00a0 Here are some examples of using the additional attributes too. Note how some of the special supported plugins require no url parameter at all, and how you can use a in the URL. elasticsearch_plugin 'shield' do action :install end elasticsearch_plugin 'kopf' do url 'lmenezes\/elasticsearch-kopf\/1.5.7' action :install end elasticsearch_plugin 'xyzzy' do name 'kopf' url 'lmenezes\/elasticsearch-kopf' action :install end If you\u2019d like to download the complete working example, . Also, note that we provided many examples above, but we\u2019re going to use the very basic ones for the provided sample code\/cookbook. Upload your work to Hosted Chef We\u2019ll use Berkshelf to get all of our dependencies, and again, use Berkshelf to upload them all to Hosted Chef. After running berks install && berks upload, you should see the two relevant cookbooks we care about being fetched and eventually uploaded to Hosted Chef: root@chef-workstation01:~\/elasticsearch-chef-blog-demo# chef exec berks install && chef exec berks upload Resolving cookbook dependencies... Uploaded elasticsearch (2.0.0) to: 'https:\/\/api.chef.io:443\/organizations\/es-chef-demo' Uploaded elasticsearch-chef-blog-demo (0.1.0) to: 'https:\/\/api.chef.io:443\/organizations\/es-chef-demo' Deploying Elasticsearch on the node using Chef Now that we have a cookbook uploaded and ready to go, we\u2019ll bootstrap the fresh server we created as part of the list of pre-requisites (remember, , too). We\u2019ll specify that we want to use our brand new wrapper cookbook on it, as well.\u00a0 The\u00a0 from the log below for brevity. root@chef-workstation01:~\/elasticsearch-chef-blog-demo# knife bootstrap -r \"recipe[elasticsearch-chef-blog-demo::default]\" -N es01 104.130.170.231 Connecting to 104.130.170.231 root@104.130.170.231's password: 104.130.170.231 -----> Installing Chef Omnibus (-v 12) 104.130.170.231 downloading https:\/\/www.opscode.com\/chef\/install.sh 104.130.170.231 to file \/tmp\/install.sh.4973\/install.sh 104.130.170.231 trying wget... 104.130.170.231 Downloading Chef 12 for ubuntu... 104.130.170.231 downloading https:\/\/www.opscode.com\/chef\/metadata?v=12&prerelease=false&nightlies=false&p=ubuntu&pv=14.04&m=x86_64 104.130.170.231 to file \/tmp\/install.sh.4977\/metadata.txt 104.130.170.231 trying wget... 104.130.170.231 url https:\/\/opscode-omnibus-packages.s3.amazonaws.com\/ubuntu\/14.04\/x86_64\/chef_12.5.1-1_amd64.deb 104.130.170.231 md5 d8fec2da288e94a7e2d649803a9d70f4 104.130.170.231 sha256 656a4c4a8fd64d74d1d970fb0d07076d6f1d8230d37d751f2c3698a52d82c070 104.130.170.231 downloaded metadata file looks valid... 104.130.170.231 downloading https:\/\/opscode-omnibus-packages.s3.amazonaws.com\/ubuntu\/14.04\/x86_64\/chef_12.5.1-1_amd64.deb 104.130.170.231 to file \/tmp\/install.sh.4977\/chef_12.5.1-1_amd64.deb 104.130.170.231 trying wget... 104.130.170.231 Comparing checksum with sha256sum... 104.130.170.231 Installing Chef 12 104.130.170.231 installing with dpkg... 104.130.170.231 Selecting previously unselected package chef. (Reading database ... 52958 files and directories currently installed.) 104.130.170.231 Preparing to unpack ...\/chef_12.5.1-1_amd64.deb ... 104.130.170.231 Unpacking chef (12.5.1-1) ... 104.130.170.231 Setting up chef (12.5.1-1) ... 104.130.170.231 Thank you for installing Chef! 104.130.170.231 Starting the first Chef Client run... 104.130.170.231 Starting Chef Client, version 12.5.1 104.130.170.231 Creating a new client identity for es01 using the validator key. 104.130.170.231 resolving cookbooks for run list: [\"elasticsearch-chef-blog-demo::default\"] 104.130.170.231 Synchronizing Cookbooks: 104.130.170.231 - elasticsearch-chef-blog-demo (0.1.0) 104.130.170.231 - elasticsearch (2.0.0) 104.130.170.231 - yum (3.8.2) 104.130.170.231 - apt (2.9.2) 104.130.170.231 - chef-sugar (3.1.1) 104.130.170.231 - ark (0.9.0) 104.130.170.231 - windows (1.38.4) 104.130.170.231 - 7-zip (1.0.2) 104.130.170.231 - chef_handler (1.2.0) 104.130.170.231 Compiling Cookbooks... 104.130.170.231 Converging 5 resources 104.130.170.231 Recipe: elasticsearch-chef-blog-demo::default 104.130.170.231 * elasticsearch_user[elasticsearch] action create 104.130.170.231 * group[elasticsearch] action create 104.130.170.231 - create elasticsearch 104.130.170.231 * user[elasticsearch] action create 104.130.170.231 - create user elasticsearch 104.130.170.231 104.130.170.231 * group[elasticsearch] action nothing (skipped due to action :nothing) 104.130.170.231 * user[elasticsearch] action nothing (skipped due to action :nothing) 104.130.170.231 * elasticsearch_install[elasticsearch] action install 104.130.170.231 * remote_file[\/var\/chef\/cache\/elasticsearch-2.0.0.deb] action create 104.130.170.231 - create new file \/var\/chef\/cache\/elasticsearch-2.0.0.deb 104.130.170.231 - update content in file \/var\/chef\/cache\/elasticsearch-2.0.0.deb from none to f846ca 104.130.170.231 (file sizes exceed 10000000 bytes, diff output suppressed) 104.130.170.231 - change mode from '' to '0644' 104.130.170.231 * dpkg_package[\/var\/chef\/cache\/elasticsearch-2.0.0.deb] action install 104.130.170.231 - install version 2.0.0 of package \/var\/chef\/cache\/elasticsearch-2.0.0.deb 104.130.170.231 104.130.170.231 * remote_file[\/var\/chef\/cache\/elasticsearch-2.0.0.deb] action nothing (skipped due to action :nothing) 104.130.170.231 * dpkg_package[\/var\/chef\/cache\/elasticsearch-2.0.0.deb] action nothing (skipped due to action :nothing) 104.130.170.231 * elasticsearch_configure[elasticsearch] action manage 104.130.170.231 * directory[\/etc\/elasticsearch] action create 104.130.170.231 - change mode from '0750' to '0755' 104.130.170.231 - change owner from 'root' to 'elasticsearch' 104.130.170.231 * directory[\/etc\/elasticsearch\/scripts] action create 104.130.170.231 - change mode from '0750' to '0755' 104.130.170.231 - change owner from 'root' to 'elasticsearch' 104.130.170.231 * directory[\/var\/log\/elasticsearch] action create (up to date) 104.130.170.231 * directory[\/usr\/share\/elasticsearch] action create 104.130.170.231 - change owner from 'root' to 'elasticsearch' 104.130.170.231 - change group from 'root' to 'elasticsearch' 104.130.170.231 * template[elasticsearch.in.sh] action create 104.130.170.231 - update content in file \/etc\/default\/elasticsearch from 333105 to 1d15e2 104.130.170.231 --- \/etc\/default\/elasticsearch 2015-10-22 08:35:02.000000000 +0000 104.130.170.231 +++ \/etc\/default\/.elasticsearch.in.sh20151123-5118-10fssxf 2015-11-23 15:27:07.265261999 +0000 104.130.170.231 @@ -1,73 +1,20 @@ 104.130.170.231 ################################ 104.130.170.231 +# THIS FILE IS MANAGED BY CHEF 104.130.170.231 +################################ 104.130.170.231 +CONF_DIR=\"\/etc\/elasticsearch\" 104.130.170.231 +DATA_DIR=\"\/usr\/share\/elasticsearch\" 104.130.170.231 +ES_GROUP=\"elasticsearch\" 104.130.170.231 +ES_HEAP_SIZE=\"256m\" 104.130.170.231 +ES_HOME=\"\/usr\/share\/elasticsearch\" 104.130.170.231 +ES_JAVA_OPTS=\"-server -Djava.awt.headless=true -Djava.net.preferIPv4Stack=true -Xms256m -Xmx256m -Xss256k -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+HeapDumpOnOutOfMemoryError -XX:+DisableExplicitGC -Dfile.encoding=UTF-8 -Djna.nosys=true \" 104.130.170.231 +ES_USER=\"elasticsearch\" 104.130.170.231 +LOG_DIR=\"\/var\/log\/elasticsearch\" 104.130.170.231 +MAX_LOCKED_MEMORY=\"unlimited\" 104.130.170.231 +MAX_OPEN_FILES=\"64000\" 104.130.170.231 +PID_DIR=\"\/var\/run\/elasticsearch\" 104.130.170.231 - change mode from '0644' to '0755' 104.130.170.231 * template[logging.yml] action create 104.130.170.231 - update content in file \/etc\/elasticsearch\/logging.yml from 58b25a to 4ce76a 104.130.170.231 --- \/etc\/elasticsearch\/logging.yml 2015-10-22 08:35:02.000000000 +0000 104.130.170.231 +++ \/etc\/elasticsearch\/.logging.yml20151123-5118-91px6c 2015-11-23 15:27:07.277261999 +0000 104.130.170.231 @@ -1,38 +1,40 @@ 104.130.170.231 +# ----- Configuration set by Chef --------------------------------------------- 104.130.170.231 - change mode from '0750' to '0755' 104.130.170.231 - change owner from 'root' to 'elasticsearch' 104.130.170.231 * template[elasticsearch.yml] action create 104.130.170.231 - update content in file \/etc\/elasticsearch\/elasticsearch.yml from b17a8d to ebb6be 104.130.170.231 --- \/etc\/elasticsearch\/elasticsearch.yml 2015-10-22 08:35:02.000000000 +0000 104.130.170.231 +++ \/etc\/elasticsearch\/.elasticsearch.yml20151123-5118-7cipao 2015-11-23 15:27:07.289261999 +0000 104.130.170.231 @@ -1,97 +1,57 @@ 104.130.170.231 +# THIS FILE IS MANAGED BY CHEF, DO NOT EDIT MANUALLY, YOUR CHANGES WILL BE OVERWRITTEN! 104.130.170.231 - change mode from '0750' to '0755' 104.130.170.231 - change owner from 'root' to 'elasticsearch' 104.130.170.231 104.130.170.231 * directory[\/etc\/elasticsearch] action nothing (skipped due to action :nothing) 104.130.170.231 * directory[\/etc\/elasticsearch\/scripts] action nothing (skipped due to action :nothing) 104.130.170.231 * directory[\/var\/log\/elasticsearch] action nothing (skipped due to action :nothing) 104.130.170.231 * directory[\/usr\/share\/elasticsearch] action nothing (skipped due to action :nothing) 104.130.170.231 * template[elasticsearch.in.sh] action nothing (skipped due to action :nothing) 104.130.170.231 * template[logging.yml] action nothing (skipped due to action :nothing) 104.130.170.231 * template[elasticsearch.yml] action nothing (skipped due to action :nothing) 104.130.170.231 * elasticsearch_service[elasticsearch] action configure 104.130.170.231 * directory[\/var\/run\/elasticsearch] action create (up to date) 104.130.170.231 * template[\/etc\/init.d\/elasticsearch] action create (up to date) 104.130.170.231 * service[elasticsearch] action enable 104.130.170.231 - enable service service[elasticsearch] 104.130.170.231 * service[elasticsearch] action start 104.130.170.231 - start service service[elasticsearch] 104.130.170.231 104.130.170.231 * directory[\/var\/run\/elasticsearch] action nothing (skipped due to action :nothing) 104.130.170.231 * template[\/etc\/init.d\/elasticsearch] action nothing (skipped due to action :nothing) 104.130.170.231 * service[elasticsearch] action nothing (skipped due to action :nothing) 104.130.170.231 * elasticsearch_plugin[head] action install 104.130.170.231 104.130.170.231 * elasticsearch_service[elasticsearch] action restart 104.130.170.231 * service[elasticsearch] action restart 104.130.170.231 - restart service service[elasticsearch] 104.130.170.231 104.130.170.231 104.130.170.231 Running handlers: 104.130.170.231 Running handlers complete 104.130.170.231 Chef Client finished, 19\/36 resources updated in 09 seconds As you can see in the log above, . You can also see was restarted because the head plugin was installed. If we run chef-client a second time, you can also see that Elasticsearch is not restarted, and everything reports (up to date): root@es01:~# chef-client Starting Chef Client, version 12.5.1 resolving cookbooks for run list: [\"elasticsearch-chef-blog-demo::default\"] Synchronizing Cookbooks: - elasticsearch-chef-blog-demo (0.1.0) - elasticsearch (2.0.0) - yum (3.8.2) - apt (2.9.2) - chef-sugar (3.1.1) - ark (0.9.0) - windows (1.38.4) - 7-zip (1.0.2) - chef_handler (1.2.0) Compiling Cookbooks... Converging 5 resources Recipe: elasticsearch-chef-blog-demo::default * elasticsearch_user[elasticsearch] action create * group[elasticsearch] action create (up to date) * user[elasticsearch] action create (up to date) (up to date) * group[elasticsearch] action nothing (skipped due to action :nothing) * user[elasticsearch] action nothing (skipped due to action :nothing) * elasticsearch_install[elasticsearch] action install * remote_file[\/var\/chef\/cache\/elasticsearch-2.0.0.deb] action create (up to date) * dpkg_package[\/var\/chef\/cache\/elasticsearch-2.0.0.deb] action install (up to date) (up to date) * remote_file[\/var\/chef\/cache\/elasticsearch-2.0.0.deb] action nothing (skipped due to action :nothing) * dpkg_package[\/var\/chef\/cache\/elasticsearch-2.0.0.deb] action nothing (skipped due to action :nothing) * elasticsearch_configure[elasticsearch] action manage * directory[\/etc\/elasticsearch] action create (up to date) * directory[\/etc\/elasticsearch\/scripts] action create (up to date) * directory[\/var\/log\/elasticsearch] action create (up to date) * directory[\/usr\/share\/elasticsearch] action create (up to date) * template[elasticsearch.in.sh] action create (up to date) * template[logging.yml] action create (up to date) * template[elasticsearch.yml] action create (up to date) (up to date) * directory[\/etc\/elasticsearch] action nothing (skipped due to action :nothing) * directory[\/etc\/elasticsearch\/scripts] action nothing (skipped due to action :nothing) * directory[\/var\/log\/elasticsearch] action nothing (skipped due to action :nothing) * directory[\/usr\/share\/elasticsearch] action nothing (skipped due to action :nothing) * template[elasticsearch.in.sh] action nothing (skipped due to action :nothing) * template[logging.yml] action nothing (skipped due to action :nothing) * template[elasticsearch.yml] action nothing (skipped due to action :nothing) * elasticsearch_service[elasticsearch] action configure * directory[\/var\/run\/elasticsearch] action create (up to date) * template[\/etc\/init.d\/elasticsearch] action create (up to date) * service[elasticsearch] action enable (up to date) * service[elasticsearch] action start (up to date) (up to date) * directory[\/var\/run\/elasticsearch] action nothing (skipped due to action :nothing) * template[\/etc\/init.d\/elasticsearch] action nothing (skipped due to action :nothing) * service[elasticsearch] action nothing (skipped due to action :nothing) * elasticsearch_plugin[head] action install (up to date) Running handlers: Running handlers complete Chef Client finished, 0\/34 resources updated in 01 seconds Testing your Elasticsearch instance Now that we have a working Elasticsearch node, we can run some commands to validate that it\u2019s up and working. We\u2019ll do some basic health checks to see if it\u2019s responding, as well as check the health of the new node: root@es01:~# service elasticsearch status * elasticsearch is running root@es01:~# curl http:\/\/127.0.0.1:9200\/ { \"name\" : \"node01\", \"cluster_name\" : \"mycluster\", \"version\" : { \"number\" : \"2.0.0\", \"build_hash\" : \"de54438d6af8f9340d50c5c786151783ce7d6be5\", \"build_timestamp\" : \"2015-10-22T08:09:48Z\", \"build_snapshot\" : false, \"lucene_version\" : \"5.2.1\" }, \"tagline\" : \"You Know, for Search\" } root@es01:~# curl http:\/\/127.0.0.1:9200\/_cat\/health?v epoch timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent 1448293963 15:52:43 mycluster green 1 1 0 0 0 0 0 0 - 100.0% Conclusion and Next steps I hope this post has been useful in deploying Elasticsearch with Chef. Next time, I\u2019ll demonstrate how to build a cluster of three nodes, configure firewall rules, and install Java before Elasticsearch. In the mean time, I hope you\u2019ll check out the new 2.0.0 version of the Elasticsearch Cookbook, as well as Elasticsearch and all of the other projects that participated in the release bonanza. If you have any questions or concerns, please leave a comment below or reach out to me using the contact links on the left-hand side of the blog. See also the original from 2012. \n"}
{"index": {"_id": 792}}
{"title":"Making Advanced Energy Policy Documents Searchable and Actionable for the First Time","seo_title":"Why AEE switched from Postgres to Elasticsearch as a Service","url":"\/blog\/aee-found-solution-with-elasticsearch-as-a-service","author":{"name":"Eric Fitz"},"date":"December 17, 2015","category":"User Stories","locales":"","content":" The ChallengeMuch of energy -- especially utilities -- is regulated at the state level. That means 50 different legislatures and executive branches to monitor and engage with. But the most challenging policymaking entities to keep track of are the Public Utilities Commissions (PUC). PUCs influence\u00a0$100 billion of investment annually through market rules, gas and electricity rates, and access to the grid. They have tremendous power to either foster or thwart innovation. To survive and prosper, advanced energy companies must be able to access and track what is happening across all 50 states. Similarly, a host of nonprofit organizations, government agencies, and the media, charged with reforming, regulating, and reporting on this critical piece of our national infrastructure requires similar information, and to be useful, it needs to be accurate and up to date. More pages of content than Wikipedia To help address this challenge, we have aggregated and indexed over 45M pages of regulatory documents from across the country, a collection larger than the English version of Wikipedia. In the past two years alone, PUCs and participants in their proceedings have generated over 10 million pages of text. While typically stored in 50 different PUC websites, many of which are difficult to navigate, all of these filings are available on our PowerSuite platform, which makes this energy policy data searchable and actionable for the first time. Our users range from private companies with memberships or paid subscriptions (e.g. Opower, GE, and EnerNOC) to a large number of users with free accounts including government employees (e.g. DOE, EPA, and NREL), journalists (e.g. GreentechMedia, InsideEPA, and E&E news), and higher education (e.g. Harvard, MIT and Berkeley). \u00a0 Full text search on Postgres? When we launched our core platform in the summer of 2014, our data was being served from a PostgreSQL database. In our initial testing (with a more limited dataset) we had determined that its full text search would meet the majority of our initial search needs with the maintenance benefits of a single ACID data store. However, as our user base grew and we continued to aggregate more data, we started to hit some challenges. Our nightly index maintenance tasks were creating tremendous index bloat leading to longer and longer processing times and reduced search performance, and memory requirements to performatively serve highly normalized data were becoming cost prohibitive. At the same time, our users were asking to perform ever more complex queries with exact phrases, boolean logic, and on-the-fly categorizations to support drill-down searching. Solution \u201cFound\u201d: Elasticsearch as a Service We had considered Elasticsearch as an alternative in the past, but did not have the resources to manage additional servers. With our users in need of a more complete set of search features and our Postgres cluster at the practical limit for vertical scaling, we launched a transition to Elasticsearch. \u00a0 As a small development team inside a nonprofit, we still could not afford the DevOps engineering time required to quickly set up and then manage this novel type of server cluster. We discovered , among other Elasticsearch as a Service firms, and selected them after witnessing the announcement of their acquisition by Elastic at the first annual Elastic{ON} conference. With Found, we could stand up and configure a large production cluster fully compliant with Elasticsearch best practices in mere hours, adjusting its size and configuration on the fly as we observed our data loading and search utilization in real time. Our setup We began our cluster with a generous 64GB of memory and 512GB of disk space. After observing the disk size of our initial data load and the memory requirements of normal user activity, we scaled this back in steps all the way to a 16GB memory and 128GB disk space plan. \u00a0A few days of running on that configuration showed greater than 75% heap utilization, so we scaled back up to the sweet spot for our application at 32GB of memory and 256GB of disk space. Along the way, we performed several push-button upgrades all the way from Elasticsearch 1.4 to 2.0.1, a smooth process we attribute to the the highly optimized, and yet carefully controlled, configuration of Found clusters. Our front end application is hosted on Heroku and running on Ruby on Rails framework. \u00a0Postgres remains our ACID datastore for our primary PUC regulatory filing objects as well as supplemental user and administrative data, while Elasticsearch stores a highly denormalized flat view of our searchable content optimized for millisecond return times across tens of millions of full-text documents. After a few months in production, we have lots of ideas about how to improve our mappings and take advantage of new features in Elasticsearch 2.0, so we are using Found to deploy and populate new versions of our index to which we can switch with a mere repointing of an index alias, or at worst a restart of our web application. It was an amazing transition from being barely able to keep the lights on with Postgres, to push button no down time continuous development. Full text search and beyond The combination of using Elasticsearch and hosting on Found allowed our small three-person team to build a highly scalable full text search platform without any of the distractions of managing our own cluster. Found allowed us to effortlessly scale our cluster until we found just the right cost\/performance sweet spot for our application. Shield was a one-click install thanks to Found, and Watcher will hopefully soon be powering our action alerts. Beyond advanced search, Elasticsearch is the backbone of our next major product offering -- advanced analytics and visualizations of policy and legislative trends. Already, members of our team and close partners are using Kibana 4 to ask questions that literally took hours to explore even partially in Postgres.\u00a0 We have accomplished all of this because of simplicity and power of Elasticsearch on Found. Without any investment in our own infrastructure and custom configurations, we can also look forward eagerly to the new tools in the works at Elastic confident that those tools will work smoothly on Found\u2019s infrastructure. That enables our team to focus on what really matters: delivering compelling user facing features that help to transform the energy policy landscape and open new markets for the advanced energy economy. \n"}
{"index": {"_id": 793}}
{"title":"Implementing a Statistical Anomaly Detector in Elasticsearch - Part 3","seo_title":"Implementing a Statistical Anomaly Detector in Elasticsearch - Part 3","url":"\/blog\/implementing-a-statistical-anomaly-detector-part-3","author":{"name":"Zachary Tong"},"date":"December 16, 2015","category":"Engineering","locales":"","content":" Welcome to the third and final installment of this series on building a statistical anomaly detector in Elasticsearch. \u00a0As a quick recap, let\u2019s look at what we\u2019ve built so far: Today, we\u2019ll take what we built in Part 1 and 2 and automate it completely using\u00a0, Elastic\u2019s real-time alerting and notification plugin for Elasticsearch. With Watcher\u2019s ability to use mustache templating and groovy scripting, it is a remarkably powerful alerting engine. \u00a0We can encode the entire Atlas system in just two watches. \u00a0The first watch will generate all of the surprise data (just like Part 1) while the second watch will create the threshold and check for anomalies (like Timelion in Part 2). Let\u2019s get started! Data Collection WatchThe first watch\u2019s job is to collect the top 90th surprise values for each metric on an hourly basis, emulating the data collection process we built in Part 1. \u00a0This means we can leverage most of the hard work from that section (e.g. the pipeline aggregation).\u00a0\u00a0 First, here is the entire watch (then we\u2019ll break it down piece-by-piece): PUT _watcher\/watch\/atlas { \"trigger\":{ \"schedule\":{ \"hourly\" : { \"minute\" : 0 } } }, \"input\":{ \"search\":{ \"request\":{ \"indices\":\"data\", \"types\": \"data\", \"body\":{ \"query\":{ \"filtered\":{ \"filter\":{ \"range\":{ \"hour\":{ \"gte\":\"now-24h\" } } } } }, \"size\":0, \"aggs\":{ \"metrics\":{ \"terms\":{ \"field\":\"metric\" }, \"aggs\":{ \"queries\":{ \"terms\":{ \"field\":\"query\" }, \"aggs\":{ \"series\":{ \"date_histogram\":{ \"field\":\"hour\", \"interval\":\"hour\" }, \"aggs\":{ \"avg\":{ \"avg\":{ \"field\":\"value\" } }, \"movavg\":{ \"moving_avg\":{ \"buckets_path\":\"avg\", \"window\":24, \"model\":\"simple\" } }, \"surprise\":{ \"bucket_script\":{ \"buckets_path\":{ \"avg\":\"avg\", \"movavg\":\"movavg\" }, \"script\":\"(avg - movavg).abs()\" } } } }, \"largest_surprise\":{ \"max_bucket\":{ \"buckets_path\":\"series.surprise\" } } } }, \"ninetieth_surprise\":{ \"percentiles_bucket\":{ \"buckets_path\":\"queries>largest_surprise\", \"percents\":[ 90.0 ] } } } } } } }, \"extract\":[ \"aggregations.metrics.buckets.ninetieth_surprise\", \"aggregations.metrics.buckets.key\" ] } }, \"actions\":{ \"index_payload\":{ \"transform\":{ \"script\": { \"file\": \"hourly\" } }, \"index\" : { \"index\" : \"atlas\", \"doc_type\" : \"data\" } } } } It\u2019s long, but don\u2019t panic! \u00a0A lot of it is repeated code from Part 1. \u00a0Let\u2019s start looking at the individual components: PUT _watcher\/watch\/atlas { \"trigger\":{ \"schedule\":{ \"hourly\" : { \"minute\" : 0 } } }, The first thing in our request is the HTTP command. \u00a0Watches are stored inside your cluster, so we execute a PUT command to the endpoint and add a new watch called \u201catlas\u201d. \u00a0Next, we schedule the watch to run with a\u00a0\u201ctrigger\u201d. \u00a0Triggers allow watches to run on schedules, much like a cronjob. \u00a0We are going to use an , which fires every hour\u00a0on the hour. After our trigger, we define the \"input\" to the watch: \"input\":{ \"search\":{ \"request\":{ \"indices\":\"data\", \"types\": \"data\", \"body\":{...}, \"extract\":[ \"aggregations.metrics.buckets.ninetieth_surprise\", \"aggregations.metrics.buckets.key\" ] } }, Inputs provide the data that a watch uses to make decisions. \u00a0There are a variety of inputs available, \u00a0but we\u2019ll use a input. \u00a0This input\u00a0executes an arbitrary Elasticsearch query and allows a watch to use the response for later processing. \u00a0The \u201crequest\u201d parameter defines the details about the request: the indices\/types to query and the request body (which is the pipeline aggregation we built in Part 1). \u00a0Combined with the trigger, our watch will execute the large pipeline agg against the raw data every hour. The \u201cextract\u201d parameter lets us extract\u00a0details that we are interested in, to simplify further processing in the watch. \u00a0It is conceptually very similar to , merely a filtering mechanism to reduce response verbosity. \u00a0Here we are using it to extract the five top-90th percentile surprises and their keys. Finally we define an \"action\": \"actions\":{ \"index_payload\":{ \"transform\":{ \"script\": { \"file\": \"hourly\" } }, \"index\" : { \"index\" : \"atlas\", \"doc_type\" : \"data\" } } } } The action is executed after the query has run, and defines the \"output\" of a watch. \u00a0 can send emails, send messages to Slack, post to custom webhooks, etc. \u00a0For our purposes, we actually want to put data back inside Elasticsearch. \u00a0We need to index the results of the pipeline aggregation so we can alert on it. \u00a0To do that, we setup an action which will index documents back into Elasticsearch for us. But before we can index anything, we need to convert the JSON aggregation response into a set of indexable\u00a0documents. \u00a0That is done via the transform\u00a0script which resides on our node (in the directory). \u00a0It looks like this: def docs = []: for(item in ctx.payload.aggregations.metrics.buckets) { def doc = [ metric : item.key, value : item.ninetieth_surprise.values[\"90.0\"], execution_time: ctx.execution_time ]: docs << doc: } return [ _doc : docs ]: Its function is very simple: iterate over the 90th percentile buckets and create an array holding the key, the value and the execution time. \u00a0Then append that to a bulk array and return it when done iterating over the buckets. The returned array is in the Bulk API syntax, which Watcher will insert into the \u201catlas\u201d index under the \u201cdata\u201d type. \u00a0Once this watch is added to the cluster, Elasticsearch will begin collecting hourly surprise metrics just like we did in the simulator. \u00a0Perfect! \u00a0Let\u2019s write the watch that finds anomalies now. Anomaly Detection WatchThe goal of this watch is to replicate what we did in Part 2 with Timelion. \u00a0Namely, it needs to construct a threshold that is three standard deviations above the moving average of the 90th surprise...per metric. \u00a0Then it needs to raise some kind of alert if that threshold is broken. This watch follows a similar layout as the last one, but has a bit more custom logic. \u00a0The whole watch looks like this: PUT _watcher\/watch\/atlas_analytics { \"trigger\": { \"schedule\": { \"hourly\" : { \"minute\" : 5 } } }, \"input\": { \"search\": { \"request\": { \"indices\": \"atlas\", \"types\": \"data\", \"body\": { \"query\": { \"filtered\": { \"filter\": { \"range\": { \"execution_time\": { \"gte\": \"now-6h\" } } } } }, \"size\": 0, \"aggs\": { \"metrics\": { \"terms\": { \"field\": \"metric\" }, \"aggs\": { \"series\": { \"date_histogram\": { \"field\": \"execution_time\", \"interval\": \"hour\" }, \"aggs\": { \"avg\": { \"avg\": { \"field\": \"value\" } } } }, \"series_stats\": { \"extended_stats\": { \"field\": \"value\", \"sigma\": 3 } } } } } } }, \"extract\": [ \"aggregations.metrics.buckets\" ] } }, \"condition\": { \"script\": { \"file\": \"analytics_condition\" } }, \"transform\": { \"script\": { \"file\": \"analytics_transform\" } }, \"actions\": { \"index_payload\": { \"logging\": { \"text\": \"{{ctx.alerts}}\" } }, \"email_alert\" : { \"email\": { \"to\": \"'John Doe '\", \"subject\": \"Atlas Alerts Triggered!\", \"body\": \"Metrics that appear anomalous: {{ctx.alerts}}\" } } } } We'll walk through it step-by-step again. \u00a0Similar to the first watch,\u00a0we PUT the watch into the cluster with a specific name (\u201catlas_analytics\u201d) and setup an hourly schedule for it to run. However, the schedule is offset by five minutes this time to allow the first watch time to complete.We also use a input again: \"input\": { \"search\": { \"request\": { \"indices\": \"atlas\", \"types\": \"data\", \"body\": { \"query\": { \"filtered\": { \"filter\": { \"range\": { \"execution_time\": { \"gte\": \"now-6h\" } } } } }, \"size\": 0, \"aggs\": { \"metrics\": { \"terms\": { \"field\": \"metric\" }, \"aggs\": { \"series\": { \"date_histogram\": { \"field\": \"execution_time\", \"interval\": \"hour\" }, \"aggs\": { \"avg\": { \"avg\": { \"field\": \"value\" } } } }, \"series_stats\": { \"extended_stats\": { \"field\": \"value\", \"sigma\": 3 } } } } } } }, \"extract\": [ \"aggregations.metrics.buckets\" ] } }, This search is a little different. \u00a0First, it is querying instead of : \u00a0this watch is aggregating the results of the previous watch instead of\u00a0the raw data. \u00a0The query is also filtering to\u00a0just the last\u00a0six hours which\u00a0allows us to scope the time frame to a specific window.\u00a0 An\u00a0aggregation is used\u00a0to build a date_histogram per metric (e.g. a time-series per metric). \u00a0Inside each series we calculate the average and standard deviation (making sure to ask the stats agg for three standard deviations via the parameter). \u00a0Finally, we extract out just the buckets because we don\u2019t care about the rest of the response. You\u2019ll notice that in Part 2 we used a moving average and standard deviation to calculate this data, while here it is a plain average \/ stddev. \u00a0Why is that? \u00a0Because this watch executes every hour, the window of time will naturally slide across the data.\u00a0Unlike the Timelion implementation -- which had to display all points of time in one graph -- we are only concerned with generating the data points for this hour, so a simple avg works fine. So at this point, our watch has all the required information to flag an anomaly...but we need to run some custom logic to tie it together. \u00a0That\u2019s what happens next, in the clause: \"condition\": { \"script\": { \"file\": \"analytics_condition\" } }, A condition is a : if the condition evaluates true, the action is run. \u00a0Our condition uses another groovy script, : def docs = []: def status = false: for(item in ctx.payload.aggregations.metrics.buckets) { def std_upper = Double.valueOf(item.series_stats.std_deviation_bounds.upper): def avg = Double.valueOf(item.series.buckets.last().avg.value): if (std_upper == Double.NaN || avg == Double.NaN) { continue: } if (avg > std_upper) { status = true: break: } } return status: The script is really very simple: extract the standard deviation upper bound (which is provided by the aggregation natively) and the average, then see if the average is greater than the upper bound. \u00a0If the average is indeed greater, set a flag and return true At this point, if the condition returned false is returned empty, the watch ends: nothing is anomalous. \u00a0But if it returns true, we continue onwards to the clause: \"transform\": { \"script\": { \"file\": \"analytics_transform\" } }, Transformations can be used to . \u00a0We\u2019ll use the transformation to tidy up the data so that a list of alerts can be embedded in an email easily. \u00a0Again, we use a groovy script to do the transformation, this one called : def alerts = []: for(item in ctx.payload.aggregations.metrics.buckets) { def std_upper = Double.valueOf(item.series_stats.std_deviation_bounds.upper): def avg = Double.valueOf(item.series.buckets.last().avg.value): if (Double.isNaN(std_upper) || Double.isNaN(avg)) { continue: } if (avg > std_upper) { alerts << item.id: } } return [alerts: alerts]: Look familiar? \u00a0This is basically the same as the script used in the clause. \u00a0The only difference is that any anomalous metrics are appended to an array, instead of changing a flag. \u00a0The array is then returned, which we can use in our final email action: \"actions\": { \"index_payload\": { \"logging\": { \"text\": \"{{ctx.alerts}}\" } }, \"email_alert\" : { \"email\": { \"to\": \"'John Doe '\", \"subject\": \"Atlas Alerts Triggered!\", \"body\": \"Metrics that appear anomalous: {{ctx.alerts}}\" } } } } In the last part of the watch, we perform two actions. \u00a0First, we log the anomalies (for debugging purposes). \u00a0We also define an , which will fire off an email. \u00a0The body of the email can use mustache for templating, which is how we can embed the list of alerts (via , the array we built in the transformation step) ConclusionAnd that\u2019s it! \u00a0The watches are long, but relatively straightforward when you work through them step-by-step. \u00a0All the difficult work was done in Part 1 and\u00a02...moving the logic into Watcher is mostly\u00a0trivial. Once these watches are enabled, the cluster will automatically start monitoring and alerting on an hourly basis. \u00a0It is very tunable because watches can be modified at any time via API calls. You could make the interval shorter or longer, extend the amount of data in each aggregation pass, modify any of the aggregation settings, change the types of moving averages in the pipeline agg, introduce entirely new metrics,\u00a0etc. \u00a0It is a very easy system to tweak even once it is live and in production. I hope you\u2019ve enjoyed this three-part series. \u00a0It was a very fun project to work on, and really helped me understand the power that pipeline aggregations, Timelion and Watcher bring to the table (especially when combined). \u00a0Until next time! \n"}
{"index": {"_id": 794}}
{"title":"Django Girls review of Elastic{ON} Tour Munich","seo_title":"Django Girls review of Elastic{ON} Tour Munich","url":"\/blog\/django-girls-review-of-elasticon-tour-munich","author":{"name":"Lucie Daeye"},"date":"December 15, 2015","category":"Culture","locales":"","content":" is a non-profit organization that empowers and helps women to organize free, one-day programming workshops by providing tools, resources and support. It was born in Berlin in July 2014 and started by two Olas:\u00a0\u00a0and\u00a0. Today, Django Girls is a volunteer run organization with hundreds of people contributing to bring more women into the Python & Django communities. This summer, Django Girls celebrated its : nearly one hundred event have happened since its inception. Growing that quickly has been amazing but also a bit scary: to make it more sustainable, the support team decided to recruit someone to help them. I was lucky enough to be selected and I started working for Django Girls in September.\u00a0 One of the perks of being the Django Girls Awesomeness Ambassador is receiving cool emails. Some of these emails include those from future organizers really excited about their workshops, as well as from attendees and coaches who just want to say thank you. When we received an email from expressing interest in supporting the Django Girls mission, I was only starting the job and I have to say, I was as excited as our organizers: sponsorship for Django Girls and going to Munich to run a booth, count me in! I started to prepare a booth, think about what to say to people and what swag to bring with me. A few days before going to Munich, we received another email from Elastic saying they managed to raise almost\u00a015,000 \u20ac for us (see slide below from the event presentation. I went to Munich still not believing that all this money was for us! \u201cOf course it is!\u201d, said Livia, my contact from Elastic and she asked me what we planned to do with it. I'm especially excited, because thanks to the Elastic sponsorship my future as a Awesomeness Ambassador is secured: currently, most of the money Django Girls Foundation receives covers my role in the organization. My job is to make the life of the easier so they can work on other projects: a , cool , etc. My main job is to stay on top of the Django Girls inbox and make sure that anyone who asks for help will be answered swiftly with the necessary support, especially making sure everyone is happy and that planned events are happening as scheduled. I also help maintain our website and resources: our and its translations, , . On top of securing the existence of the Awesomeness Ambassador position, we also plan to use this money on two cool initiatives. The first one is sending swag boxes to organizers full of stickers, buttons and tattoos - it will be our \u201cDjango Girls Organizer Starter Kit\u201d. If you haven\u2019t heard about us already, you have to look at of our events: we want a positive learning atmosphere and all these little details contribute to it. The second initiative is working on the inaugural Django Girls Summit! Yes, the Summit! We are extremely excited about this plan. We want to organize a two day unconference where organizers could meet and share their experiences about \u00a0Django Girls workshops: what was hard, how they handled problems, how they find sponsors and so on and so on. We imagine it as a place where people who are making Django Girls what it is now could meet in person and learn from each other. We are really excited about this and can\u2019t wait to start planning it! Thank you again Elastic for the visibility you\u2019ve gave to our organization, for the booth at Munich and for this awesome sponsorship. You have been with us from almost the very beginning, supporting us on many different levels: as mentors, supporters and sponsors. Thank you for being awesome! \n"}
{"index": {"_id": 795}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2015-12-14","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-12-14","author":{"name":"Michael McCandless"},"date":"December 14, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsShould you put your data into a new index or into a new type of an existing index? \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole Elastic\u00a0ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 796}}
{"title":"Brewing in Beats: Webinar and Performance Optimizations","seo_title":"","url":"\/blog\/weekly-beats-webinar-performance-optimizations","author":{"name":"Monica Sarbu"},"date":"December 14, 2015","category":"Brewing in Beats","locales":"","content":" Learn more about the Beats from our Webinar Last week we demoed Topbeat, Filebeat and Packetbeat in front of a big audience. Check the summary of the Webinar and watch the one hour demo to see the Beats in action and the hands on training presented directly by the Beats development team. Unified ChangelogWe combined all CHANGELOG.md files from all the Beats repositories into a single CHANGELOG.asciidoc in this . For each release the following sections are available: Breaking changes, Bugfixes, Added and Deprecated and contain details about the changes \u00a0in each Beat including libbeat. Group cpu usage per core informationThanks to a , cpu usage information is exported for each available core under the main root. Currently it is available only on Unix systems. Depending on the number of cores on your server, the number of exported fields can be quite high. To have a cleaner and organized output, we decided to group all the cpu usage per core information into the cpus group and is the result. Additionally the is added to make all this specific information optional. TCP layer drop connection state on gapA appeared when there was a gap in the TCP stream that caused parser errors, crashes and current packet data lost. To the issue the connection is dropped and re-initalized when a gap occurs. Winlogbeat The Winlogbeat is currently able to read the event logs from the Event Logging API that is provided in Windows XP, Windows 2003 and works also on all newer versions, but some events cannot be read through this API. The next step would be to read the event logs from Windows Event Log API that is available on the newer Windows systems: Windows Vista, Windows Server 2008 and give you additional information. You can watch the evolution of the new Beat under this . Change default configuration file pathIn the previous version, the default directory of the configuration file was set differently depending on the OS, so each binary package had a different default path to the configuration file. The simplifies it by setting the default directory of the configuration file to the directory where the binary is placed. Benchmarking \u00a0PacketbeatPacketbeat is parsing each message received on the network and allocates memory for each set of data to extract. This week we run some small experiments to reduce the number of memory allocations in the and . New Blog Post All the Beats are now leaving together in the same. Read about how we merged all the GitHub repositories into one. \n"}
{"index": {"_id": 797}}
{"title":"Autoresize EBS root volume on Linux-based Amazon AMIs","seo_title":"Autoresize EBS root volume for AWS AMIs","url":"\/blog\/autoresize-ebs-root-volume-on-aws-amis","author":{"name":"Dimitrios Liappis"},"date":"December 14, 2015","category":"Engineering","locales":"","content":" I can\u2019t increase the size of my EBS root volume when I launch a new Debian instance!Setting a larger than default (8GiB) root EBS device, when launching Debian AMIs, does not result in a similarly sized root filesystem. In this article we are investigating why this doesn\u2019t work out of the box, and how to create new AMIs that will be resized correctly after launch. Example:You want to launch a new Debian instance with the root device on Amazon EBS. So you select an appropriate root EBS AMI, for example:\u00a0 In the \u201cAdd Storage\u201d step, change the default size from 8 GiB to something larger: 33 GiB in\u00a0this example: After the instance has come up, ssh using your keypair and your root\u00a0filesystem\u00a0is still showing 8GiB: admin@ip-172-31-2-65:~$ df -h Filesystem Size Used Avail Use% Mounted on \/dev\/xvda1 7.8G 641M 6.8G 9% \/ Where did my space go?Digging a bit deeper with we can see: admin@ip-172-31-2-65:~$ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT xvda 202:0 0 33G 0 disk \u2514\u2500xvda1 202:1 0 8G 0 part \/ The Amazon EBS disk () presented to the OS has the right size: 33G However the partition where the OS resides () is stuck at 8G. Linux AMIs come preinstalled with a customized version of the package. This includes Python modules that can and , CLI tools like and . On standard Debian AMIs, they aren\u2019t there. CentOS AMIs\/EPEL in comparison have the rpm package available providing the tool. cloud-init tools will also detect if the root file system (\/) size differs from the partition size and utilize the appropriate filesystem expansion tool (e.g. for ext4) to match the partition size. Resizing an online partition on a linux AMINaturally we would like our AMIs to resize the root partition by themselves, to use all available space. Since is not available in Debian AMIs, we can accomplish this with and an init script that runs on the first boot (when the instance gets launched). Making work non-interactivelyOne challenge here is that most tools will complain about resizing the partition containing a mounted [root]\u00a0file system. The version of parted shipped with Debian jessie allows us to and -- albeit not so well documented -- non interactively as well. Normally, a command like this would suffice, but because the partition is in use, prompts for confirmation which would\u00a0interrupt\u00a0the flow in a script: root@ip-172-31-2-65:~# \/sbin\/parted \/dev\/xvda resizepart 1 100% Warning: Partition \/dev\/xvda1 is being used. Are you sure you want to continue? \/sbin\/parted: invalid token: 100% Yes\/No? Luckily has an\u00a0 that allows us force grow the partition without prompts: root@ip-172-31-2-65:~# \/sbin\/parted ---pretend-input-tty \/dev\/xvda resizepart 1 yes 100% Warning: Partition \/dev\/xvda1 is being used. Are you sure you want to continue? Information: You may need to update \/etc\/fstab. The output may not be very encouraging, but it worked: root@ip-172-31-2-65:~# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT xvda 202:0 0 33G 0 disk \u2514\u2500xvda1 202:1 0 33G 0 part \/ The only thing remaining is to resize the filesystem. This will be done automatically by the tools after a reboot or by running Putting it all togetherIf you are building your own custom AMI, it makes sense to add an init script that does the above steps immediately after a new instance gets launched and\u00a0ensures\u00a0it won\u2019t rerun itself again. An important requirement is to have parted installed: you can either do that inside the script or ensure gets preinstalled as part of the scripts building your custom AMI. For Debian AMIs running the will create an init script linked to that will take care of all the resizing. As the last step it will deactivate itself and report activities under Are other AMIs affected by this problem?Yes! CentOS6 AMIs are affected. Instead of though -- which is an old version that can\u2019t resize online partitions -- make sure is installed from the package \u00a0This package is part of the . The resize command is: \u00a0 Finally SLES11.x AMIs seem to suffer from the same issue. ConclusionSome Linux AMIs will fail to utilize the whole EBS volume size you've chosen when you launch them! If you have been bitten by this issue, I'd\u00a0love to hear about it and whether the ideas presented here were of help. A\u00a0few tips to keep in mind: Script for Debian AMIs#!\/bin\/bash # Run this to create init script for Debian 8 AMIs that autoresizes the root EBS partition ROOTDEV=\"xvda\" ROOTPART=\"xvda1\" rootdevsize=$(blockdev --getsize \/dev\/${ROOTDEV}) rootpartsize=$(blockdev --getsize \/dev\/${ROOTPART}) if ! grep -q ${ROOTPART} \/proc\/partitions then # EBS volume is unpartitioned ... no work for us exit 0 fi source \/etc\/os-release if [ $VERSION_ID -gt 8 ] then # Exclude future Debian AMIs that hopefully will have this fixed exit 0 fi cat >\/etc\/init.d\/ami-resizerootpart.sh <<'EOF' #! \/bin\/sh ### BEGIN INIT INFO # Provides: ami-resizerootpart # Required-Start: $local_fs $syslog # Required-Stop: # Should-Start: # Default-Start: 2 3 4 5 # Default-Stop: # Short-Description: Resize root partition on AWS if it smaller than the size of the device # Description: When using the Debian 8 AWS AMIs with root EBS fs, EBS is partitioned. # As a result, when launching a new instance with a larger than default # root EBS size, \/dev\/xvda has desired size but not \/dev\/xvda1 root # partition. # \/etc\/init.d\/ami-resizerootpart detects this discrepancy and resizes # the partition, triggering a reboot and fsck. cloud-init will resize the # fs by itself after the reboot. ### END INIT INFO . \/lib\/init\/vars.sh . \/lib\/init\/mount-functions.sh . \/lib\/lsb\/init-functions PATH=\/sbin:\/bin:\/usr\/sbin:\/usr\/bin do_start() { ROOTDEV=\"xvda\" ROOTPART=\"xvda1\" LOGFILE=\"\/var\/log\/resizerootfs.log\" rootdevsize=$(blockdev --getsize \/dev\/${ROOTDEV}) rootpartsize=$(blockdev --getsize \/dev\/${ROOTPART}) if ! grep -q ${ROOTPART} \/proc\/partitions then # EBS volume is unpartitioned ... no work for us echo \"Unpartitioned EBS volume no need to run\" >>$LOGFILE return 0 fi # Check if raw EBS device and partition differ by more than 10MB if [ ! $(($rootdevsize-$rootpartsize)) -ge 10485760 ] then # No need to resize echo \"EBS partition is <=10MB of the device size: no need to act\" >>$LOGFILE return 0 fi # Resize root partition \/sbin\/parted ---pretend-input-tty \/dev\/${ROOTDEV} resizepart 1 yes 100% if [ ! $? -eq 0 ] then echo \"Resize failed\" >>$LOGFILE return 0 fi echo \"Successfully resized rootfs!\" >>$LOGFILE # Force fsck on next reboot \/usr\/bin\/touch \/forcefsck # Disable myself job done rm \/etc\/rc5.d\/S05ami-resizerootpart.sh sync reboot } case \"$1\" in start|\"\") do_start : : stop|status) # No-op : : *) echo \"Usage: ami-resizerootpart.sh [start|stop]\" >&2 exit 3 : : esac EOF chmod 755 \/etc\/init.d\/ami-resizerootpart.sh chown root:root \/etc\/init.d\/ami-resizerootpart.sh ln -s \/etc\/init.d\/ami-resizerootpart.sh \/etc\/rc5.d\/S05ami-resizerootpart.sh \n"}
{"index": {"_id": 798}}
{"title":"Introducing Community Maintainers for Logstash Plugins","seo_title":"Introducing Community Maintainers for Logstash Plugins","url":"\/blog\/introducing-community-maintainers-for-logstash-plugins","author":{"name":"Alvin Chen"},"date":"December 14, 2015","category":"Engineering","locales":"","content":" Through the years, the Logstash project has evolved into a kind of swiss army knife for data ingestion, collecting and unifying a variety of data from a myriad of data sources into Elasticsearch and other destinations. Beyond classic logging use cases, you can now unlock deeper insights from , monitor or any , and easily derive value out of network packet data, system metrics, and more with the\u00a0 framework. It just keeps on growing... \n"}
{"index": {"_id": 799}}
{"title":"Where in the World is Elastic? - Elastic{ON}Tour Tokyo","seo_title":"Where in the World is Elastic? - Elastic{ON}Tour Tokyo","url":"\/blog\/witwies-elasticontour-tokyo","author":{"name":"Megan Wieling"},"date":"December 14, 2015","category":"","locales":"","content":" Welcome to Find out which Elastic events and\u00a0meetups are happening near you this week.\u00a0Upcoming EventsDecember 16:\u00a0Upcoming MeetupsDecember 14: December 15: December 15: December 16: December 15: December 16: December 14: December 19: December 20: That's it for this week. Stay tuned next week for more Elastic happenings.- The Elastic Team P.S. if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}
{"index": {"_id": 800}}
{"title":"Nuxeo, Search and Lucene, Oh My!","seo_title":"","url":"\/blog\/nuxeo-search-and-lucene-oh-my","author":{"name":"Thierry Delprat"},"date":"December 14, 2015","category":"User Stories","locales":"","content":" Content Repository & SearchAt , our job is to provide a content repository, a stack of associated services and the needed assembly tools so that people can build their own content-centric business application in a clean, maintainable and scalable way.When it comes to scalability, the first challenge is usually not so much the storage volume but the ability to quickly execute search queries.Indeed, most of the screens of applications heavily rely on queries: searching for documents under a given hierarchy, in a given state or associated to a task... As a result, pretty much all screens of the application are issuing one or several queries.In addition, platform users can configure both the data structures and the screens so the used queries can vary a lot and can become very complex. Our History with LuceneWe've been building a content repository for more than 10 years, so we know about this search challenge. Since everything we do is open source, we have a long history with Apache Lucene.Strangely enough, we started using Lucene at a time where our repository was running on Python\/Zope. We used to build an XML-RPC search service. This hybrid solution was a pain to setup (compile Lucene to native code via GCJ), but when it was finally up and running the performance was just amazing.When we moved the whole platform to Java, Lucene was logically one of the building blocs we re-used. At this time, our repository backend was and since the built-in Lucene index was not enough to fulfill our requirements for complex queries, we integrated that was providing a transactional layer on top of Lucene (and had an interesting ). This Lucene integration was not so successful for us since we ended up with a lot of missing sync and transaction deadlocks issues at the index level.Along with Jackrabbit limitations, we decide to re-write completely the repository implementation, 100% SQL based and then 100% ACID.The result is a very reliable storage where everything relies on the SQL database. However, there are some limitations in terms of queries: So in 2013, we started implementing Elasticsearch connector for the Nuxeo Platform with the goal to get rid of these problems: spend less time on complex SQL tuning and focus on Elasticsearch index mapping. Elasticsearch Integration OverviewHybrid StorageThe idea was to build an additional index on top of the repository: One of the main advantages of this approach is that queries are written once using NXQL and then, depending on the configuration, it will be executed by the repository or the Elasticsearch index. On a per query basis, transactional behavior or search speed can be favored.Later, when we introduced the MongoDB backend for the repository, this demarcation became synchronous vs asynchronous, but still, Elasticsearch remains the solution for blazing fast search.How do we know that? Well, we did actual benchmarks! PerformancesAs soon as we had a first version of the \u00a0connector, we started doing performances benchmarks.One of the first tests we did was comparing the performances the same NXQL query between a Nuxeo Repository internal SQL index and the Elasticsearch index.The results are very significants: Happy with these first results, we finished the integration and did some more benchmarks.One of the key performance aspects is re-indexing speed: We tested re-indexing speed and measured a throughput of about 3,500 documents\/s. This is fast enough so that a full re-indexing would not be a problem. But, we actually saw that the bottleneck for the re-indexing was not Elasticsearch, but the repository SQL backend. So, we ran again the same test with the MongoDB backend and measured a re-indexing throughput of 10,000 documents\/s.We also tested the Elasticsearch capacity to handle scale out. For that, we injected a lot of queries on a Nuxeo Repository via REST API. The limit reached was about 3,000 queries\/s. Then adding a second Elasticsearch node gave us about 6,000 queries\/s, showing a linear scale-out capability.During these tests, we leveraged the fact that Elasticsearch keeps a copy of the source JSON document stored inside the index: this allows us to off-load the query and the retrieval from the database to Elasticsearch. This is magic!Within the technical team, we were very impressed by the Elasticsearch technology and how well everything was working.Then, the Solutions Architects team started playing with it and they discovered that in addition of high-end performances, Elasticsearch also brings a lot of new features (more on this later).Finally, it was our client's turn to discovered Elasticsearch. For several of them, solving their performances or scalability concerns was as simple as to say\u00a0\"\".This is so true, that we integrated the plugin as the default deployment option in Nuxeo 6.0 and also \"back-ported\" to make it available for people using the previous LTS. Technical Integration of ElasticsearchWe knew from Elasticsearch previous work on integrating Lucene that the main challenges we had to address were: Security FilteringInside the Nuxeo Repository, the documents are associated with security descriptors (ACLs) that are used to determine \"\"\u00a0on the document. This is also true when it comes to viewing a document, so this also applies to search: search results must be filtered according to user credentials.Doing post-filtering is not an option as we would loose all the added-value of Elasticsearch (speed, aggregates...).In the past, we also tested solutions based on joining Lucene Indexes together: this ended up being a pain and since anyway it was not compliant by Elasticsearch distributed architecture, this option was ruled out.So, we decided to index the ACLs inside Elasticsearch. For that, we build a synthesis of the users and groups who have access to the document and we make it part of the JSON representation of the document. ecm:acl: [\"Management\", \"Supervisors\", \"bob\"] Then, when translating NXQL queries to Elasticsearch JSON DSL, Nuxeo will always add a filter clause of .Because the ACLs can be inherited, a change of security will usually trigger a recursive re-index, putting more pressure on the infrastructure that must keep the index in sync with the repository. Keeping the Index in SyncOur past experience with Lucene has led us to believe that trying to make Lucene transactional is a mistake.So, we decided to accept this limitation and build a system that will make the indexing safe even if asynchronous and non-transactional.The idea is simple: To make this safe, the asynchronous jobs must be persistent and re-triable, but since the Nuxeo Platform uses Redis to back the processing queues, this is not an issue. Mitigating Consistency IssuesSearch is executed against data structures that require some processing to build, which means it is best to batch up some documents before building one. So while Elasticsearch guarantees that documents can be retrieved by ID immediately, it may take a second before Lucene makes the same document visible to search. This is actually a very good trade-off considering the speed it provides and the very short time interval during which problems may be visible.Still, there are some cases where this can be an issue. If a user lists documents to process and validate one of them, he logically expects this document to disappear from the list. But when the list is built using Elasticsearch, there might be a small \"refresh issue\" because the index is not updated in real time. To mitigate this issue, we added a \"\": when the indexing events are caused by a \"\", the indexing jobs is run on the of the repository transaction and will issue a . Results in ProductionWe have some customers with past bad experience with Compass\/Lucene and logically they were worried about index consistency when their fist Nuxeo + Elasticsearch clusters went live.So, we built to check the Elasticsearch index and verify that it is really \"in sync\" with the repository. Having these tools was useful to make everyone more relaxed, and we did not find any real issue.The feedback of our customers regarding Elasticsearch integration is very good. Additional BenefitsIntegrating Elasticsearch into the Nuxeo Platform gave us a way to really boost the performance of the platform.However, we also quickly saw that Elasticsearch can provide us more than raw performances. AggregatesOnce we had integrated Elasticsearch as a backend for NXQL Queries, it became possible to leverage the aggregate feature.To do so, we extended the PageProvider model (our model for named queries) to allow to define aggregates and the result is a powerful Faceted Search feature. Advanced IndexingElasticsearch index semantic is much richer than what we had inside a SQL Database.This allows for index fine tuning like: To be able to leverage that, we had to extend our NXQL query language to support some . Audit TrailAudit Log is a typical nightmare for an SQL database: write an intensive and huge amount of free form entries. Here we can use Elasticsearch as a primary storage for what he does the best a write once, search many. In addition, it allows for very cool queries mixing documents and history. StatisticsThis open the way for doing real-time data analytics on the documents and Audit Log that are available in Elasticsearch.For this, we added a that basically re-exposes the Elasticsearch HTTP on top of , the main goal being to integrate the security filtering.We use this feature to provide configurable dashboards for workflows and searches: About the Next StepsBecause we are very happy with the features we gained from integrating Elasticsearch, we want to go further.The roadmap includes: \n"}
{"index": {"_id": 801}}
{"title":"The Beats are Moving Together into a Single Git Repository","seo_title":"","url":"\/blog\/the-beats-are-moving-together-into-single-git-repository","author":{"name":"Tudor Golubenco"},"date":"December 11, 2015","category":"Engineering","locales":"","content":" A time comes in the life of many development teams when they consider switching from multiple source code repositories to one (or the other way around). For the team behind the Beats open source projects, this time was a few weeks ago, and it resulted in us merging , , , and into a single git repository last week. The Why We were all feeling for some time that having to constantly keep our eight or so repositories in sync was time consuming, but I personally thought about it more as a necessary annoyance that we can live with, rather than something we must fix in the short term. So when someone casually brought up the idea during an internal chat, I didn\u2019t think the cost of switching would be worth it. For one thing, with the Beats being open source, the way we organize the repositories is not just our internal business, but it is part of the way we communicate with the wider developer community around the projects. I was worried that a single repo would make the individual Beats feel less independent and might discourage folks from creating their own Beat under their personal Github account. Nevertheless, we started to gather in a document the pros and cons and we payed more attention to all the tasks that we have to do because of the multiple repos. Small things like bumping the version number in the docs before releasing, creating new Github labels, closing and merging the changelog files, \u00a0publishing the Github release, or just checking the open issues across repositories take a significant amount of time when you have to do them four times. Yes, most of this stuff can be automated, and indeed we had various scripts and tools that helped us a lot. But even then, there was a lot of time wasted, and creating these tools also didn\u2019t come for free. We do everything via pull requests and we review every single one, no matter how trivial. We also don\u2019t merge them until the continuous integration systems give the green light. So, in the last few days before a release all of the tiny changes added up and were taking forever. Then there were the tasks that are not so easy to automate, like backporting features or bug fixes between release branches. If the feature or bug affected more than one repository, the tedious and error-prone task of solving rebase conflicts had to be done more than once. Another important aspect for us was how friendly we were to the occasional external contributor. If someone wanted to fix a bug in Packetbeat but the code was actually in libbeat, they would first have to find the code in a different repository. Then after fixing it, figure out how to update the libbeat code into Packetbeat (godep), test it, and open pull requests in both libbeat and Packetbeat. A libbeat change can potentially break the tests in another Beat as well, and we could not expect an occasional contributor to clone three more repositories and run the tests before submitting the PR. After debating these points, we all agreed that a single repository would help us move faster and with fewer errors. The How We thought that switching would be easy, because except for Packetbeat, all the other repositories are only one to six months old. But even for our young projects, there were quite a few things to consider. Timing The more in-progress work you have at the time of the migration, the bigger the disruption is, so we chose to do the migration in the week after a major release, when most new projects were still in the design phase. Git history We felt keeping the Git history was important, both to credit our external contributors and for us to be able to track down changes. Luckily the command makes this extremely easy. We imported the code from each Beat into a subdirectory in the final repository. One special requirement we had here was to have both the master and our latest release branch 1.0.0 available, so we actually did the subtree import twice, once for master and once for the 1.0.0 branch. The resulting graph is messy for sure, but you can clearly see the four repositories merged into one and the 1.0.0 branch being spawned just before the merge. Issues and links We also had to keep in mind that GitHub issues cannot be moved cleanly between repositories. There are scrpts out there that can close the original issues and create copies with the same content in the new repository, but the new issues will all be created by the same username. Links between issues, as well as links from commit messages to issues, get broken. For these reasons, we decided to keep the old repos around and only replace their README files with a move notice. We didn\u2019t use a script to migrate the issues. Rather, because there weren't many issues, we moved the open tickets one by one by hand. This gave us an opportunity to clean house. To minimize the negative effects of the migration, we kept and renamed the repository that had the most history (Packetbeat) and merged the other repositories into it. Open Pull Requests You can\u2019t take over pull requests from one repository to another, so before the cutoff moment, we went through all open pull requests and either worked with the author to get them merged or closed them. Thank you everyone who helped with this effort. Dependencies This one is fairly specific to Go. We vendor our dependencies in the source tree, which means that before the migration we had a dependencies folder (Godep) in each of the repositories. Because taking over that structure would negate many of the benefits of the single repository, we decided to switch at the same time to use the and put all our dependencies in a single top-level vendor folder. We started using to manage this repository, and the transition from godeps was fairly simple. We prepared the glide.yml file in advance in an experimental merged repository, so at the cutoff time, we only had to copy the glide.yml file and use glide to create the vendor folder. Integration tests and build systems These systems depend on the repository structure, so they needed configuration adjustments. In our environment, we are using , and our own instance to provide test coverage over the different platforms we support. Preparation was key here again. In our experimental merged repository, we prepared new travis.yml and appveyor.yml files that we could simply copy over at the cutoff time. One negative side effect (and the biggest so far) of the migration is that these systems now have to run the tests from all the Beats on every change, making them slower in giving us feedback. This is especially a problem with Travis, which immediately after the cutover had to run , some of them taking quite long. Because some of the tests use Docker, it means all the tests have to run on a non-containerised system, further adding to the wait time. To mitigate this, we moved the most time-consuming Travis targets to be executed by Jenkins only, and we\u2019ll continue to work on making our tests faster. What does this mean for you? If you are using one of the Beats, not much changes for you. Our next release will be built from the merged repository, but hopefully this won\u2019t be noticeable to you at all. Please post new issues to the new , and if you have open issues on the old repositories, please help us by moving them to the new one. If you are maintaining a Beat or other project that depends on libbeat, we left the old libbeat repository alive, so we don\u2019t break any existing code. However, we recommend you update your import paths to use the new libbeat path: github.com\/elastic\/beats\/libbeat. Other than that, nothing really changes. You should continue to maintain your Beat under your GitHub account and we\u2019ll continue to support you in maintaining it to the best of our abilities. We apologize if this caused \/ will cause any issues to you. It helps us move the Beats platform forward faster and safer. \n"}
{"index": {"_id": 802}}
{"title":"GoDaddy & the Quest to Find Out Why Can't I Have Ninja.Com?!","seo_title":"Why Can't I Have Ninja.Com","url":"\/blog\/godaddy-and-the-quest-to-find-out-why-cant-i-have-ninja-com","author":{"name":"Daniel Palay"},"date":"December 11, 2015","category":"User Stories","locales":"","content":" When setting up your website, what\u2019s in a name, really? Is it long? Short? Personally meaningful? Or is it just a random collection of words, words, words (or characters - lookin\u2019 at you there, xkcd)? And after you figure out the name, then comes the even harder part...do you want to be a .com or a .co (hey, take it from us, those m\u2019s can be expensive), a .org, .net. or a .banana?If you are like most people, your first step to domain name ownership could be a quick visit to GoDaddy - after all it\u2019s the web\u2019s largest URL registry. And wouldn\u2019t you know, their search function, recommendation engine, and even some other fun stuff are all powered by Elasticsearch. Wait a tick, how do I know all of this? \u00a0Yes, they did publish an about it, but really it\u2019s because we had the pleasure of sitting down with Chris Ambler, Principal Software Development Engineer at GoDaddy, at Elastic{ON}15 to get the , face to face. He walked us through the star-crossed journey of a URL-seeker. It can an arduous journey from concept (some people try\u00a0keywords while\u00a0others are just clicking around for divine inspiration) to dead ends (WHAT?!? WHY CAN\u2019T I HAVE NINJA.COM) to resolution (hey look, that recommendation is perfect, why didn\u2019t I think of that?). But as you\u2019ll see, the final act of getting that perfect URL is well worth\u00a0the complete works that come before it.And in the name of brevity - it is the soul of wit after all - if you get nothing else from this video or blog, understand these two points: It's not that you can't have ninja.com, it's just that you actually wanted something better and GoDaddy already knew it.\u00a0 \n"}
{"index": {"_id": 803}}
{"title":"Microsoft Azure Marketplace: Elasticsearch, Kibana, and More Now Available","seo_title":"","url":"\/blog\/microsoft-azure-marketplace-elasticsearch-kibana-and-more-now-available","author":{"name":"Shay Banon"},"date":"December 10, 2015","category":"News","locales":"","content":" Over the past few years, we\u2019ve had a wonderful relationship with Microsoft.Earlier this year at our user conference\u00a0\u2014\u00a0\u00a0\u2014\u00a0we had the privilege of having Pablo Castro, an early .NET, Azure, and SQL Server engineer, present the many different use cases of Elastic\u2019s technology at Microsoft during his keynote. It included powering search for MSN.com, one of the Internet\u2019s biggest web portals: using Elasticsearch within the Dynamics CRM product line for enhancing the user experience: and as the search framework within Azure.With a shared goal to make it as easy as possible to deploy our technologies, today, I\u2019m really excited to announce that we\u2019ve worked with Microsoft to make the Elastic stack available on the . As more and more developers build and deploy apps on Azure, using an (ARM) Solution template created by Elastic, developers can easily set up an Elasticsearch cluster directly, thus simplifying their deployment. In addition, we\u2019ve made it possible to deploy all of our open source products, such as, Kibana, Logstash and Beats. And for those who want support and our commercial plugins Shield (security & authentication), Watcher (alerting), and Marvel (monitoring), an Elastic subscription is now available for any Azure-based deployments. Most importantly, this ensures that developers using Azure have a full and native Elasticsearch experience.In addition to creating the ARM template and the Marketplace listing with Microsoft, I\u2019m also thrilled that our teams have been able to work closely on some open source innovation. One example is enabling Elasticsearch to run more efficiently on like Azure File Storage that will benefit both Elastic and Microsoft users with lower costs.Thank you Microsoft, and to our users, please let us know your experience.\u00a0 \n"}
{"index": {"_id": 804}}
{"title":"Index vs. Type","seo_title":"","url":"\/blog\/index-vs-type","author":{"name":"Adrien Grand"},"date":"December 09, 2015","category":"Engineering","locales":"","content":" Who has never wondered whether new data should be put into a new type of an existing index, or into a new index? This is a recurring question for new users, that can\u2019t be answered without understanding how both are implemented. In the past we tried to make elasticsearch easier to understand by building an analogy with relational databases: indices would be like a database, and types like a table in a database. This was a mistake: the way data is stored is so different that any comparisons can hardly make sense, and this ultimately led to an overuse of types in cases where they were more harmful than helpful. What is an index?An index is stored in a set of shards, which are themselves Lucene indices. This already gives you a glimpse of the limits of using a new index all the time: Lucene indices have a small yet fixed overhead in terms of disk space, memory usage and file descriptors used. For that reason, a single large index is more efficient than several small indices: the fixed cost of the Lucene index is better amortized across many documents. Another important factor is how you plan to search your data. While each shard is searched independently, Elasticsearch eventually needs to merge results from all the searched shards. For instance if you search across 10 indices that have 5 shards each, the node that coordinates the execution of a search request will need to merge 5x10=50 shard results. Here again you need to be careful: if there are too many shard results to merge and\/or if you ran an heavy request that produces large shard responses (which can easily happen with aggregations), the task of merging all these shard results can become very resource-intensive, both in terms of CPU and memory. Again this would advocate for having fewer indices. What is a type?This is where types help: types are a convenient way to store several types of data in the same index, in order to keep the total number of indices low for the reasons exposed above. In terms of implementation it works by adding a \u201c_type\u201d field to every document that is automatically used for filtering when searching on a specific type. One nice property of types is that searching across several types of the same index comes with no overhead compared to searching a single type: it does not change how many shard results need to be merged. However this comes with limitations as well: This means types can be helpful, but only if all types from a given index have mappings that are similar. Otherwise, the fact that fields also consume resources in documents where they don\u2019t exist could make things worse than if the data had been stored in separate indices. Which one should I use?This is a tough question, and the answer will depend on your hardware, data and use-case. First it is important to realize that types are useful because they can help reduce the number of Lucene indices that Elasticsearch needs to manage. But there is another way that you can reduce this number: creating indices that have fewer shards. For instance, instead of folding 5 types into the same index, you could create 5 indices with 1 primary shard each. I will try to summarize the questions you should ask yourself to make a decision: In conclusion, you may be surprised that there are not as many use cases for types as you expected. And this is right: there are actually few use cases for having several types in the same index for the reasons that we mentioned above. Don\u2019t hesitate to allocate different indices for data that would have different mappings, but still keep in mind that you should keep a reasonable number of shards in your cluster, which can be achieved by reducing the number of shards for indices that don\u2019t require a high write throughput and\/or will store low numbers of documents. \n"}
{"index": {"_id": 805}}
{"title":"How the Elastic Stack Keeps our Taxis Rolling","seo_title":"How the Elastic Stack Keeps our Taxis Rolling","url":"\/blog\/how-the-elastic-stack-keeps-our-taxis-rolling","author":{"name":"Sebastian Herzberg"},"date":"December 09, 2015","category":"User Stories","locales":"de-de,fr-fr,ko-kr","content":" The Logging-Cluster We started out in 2013 with a pretty simple standard configuration of the Elastic technology stack. It had two Elasticsearch nodes and one node for Logstash and Kibana. This worked well back in the days before our exponential growth started in 2014. This setup was running until mid 2015. The cluster was abandoned during our growth phase and thus it was lacking performance. By mid 2015 we had about 2 TB of data stored in Elasticsearch. Also, in 2013 we decided to move away from a monolithic backend structure towards microservices. By now we have split our backend into around 50 microservices. We needed to gather logs from all of these services in one place. By July 2015 we decided to set up a new cluster that would support our needs for the upcoming years. The requirements were: Hardware setup and installation procedure With these requirements we went to AWS and checked for a reasonable instance size. Three instance sizes were in line with our requirements (prices may be outdated): The m1.xlarge seemed to be gold here. They are cheap and they have 4 HDDs which could be combined to a RAID0. Ten m1.xlarge instances would form a cluster with 150 GB RAM and 16,8 TB of disk. With this much disk we could easily increase the amount of time that we keep the logs. To configure ten nodes and install an equal configuration of Elasticsearch, we used Ansible. The playbook combined roles for: Logcluster architecture \u00a0Logcluster usage examples Conclusion It is our goal to provide the best taxi experience in Europe and expand our service to do more and more cities over the next years. With around 50 microservices we need an information hub to get an overview of the overall system status. For us the Elastic-Technology-Stack provides this overview. But it also gives developers the chance to dig deep into bugs and closely follow the impact of changes. \n"}
{"index": {"_id": 806}}
{"title":"Elastic Fantastic: Excelian's review of Elastic{ON} Tour London","seo_title":"Elastic Fantastic: Excelian's review of Elastic{ON} Tour London","url":"\/blog\/elastic-fantastic-excelians-review-of-elasticon-tour-london","author":{"name":"Jay Chin"},"date":"December 09, 2015","category":"User Stories","locales":"","content":" In this particular project we were tasked with creating a for one of the large investment banks. The project used\u00a0Elasticsearch, Logstash, and Kibana\u00a0to store and provide analytics on grid performance, capacity, logs, and so forth. It was a very successful project for Excelian and had fantastic feedback from the client. I believe one of the reasons for the success of this project was the close relationships that developed between Excelian and some of the Elastic engineers. They were able to optimise the setup but were also on hand to troubleshoot any issues that arose. When I conveyed the feedback to Elastic they were delighted and that is when they invited me to present at . Elastic{ON}Tour was a fantastic and genuinely inspiring event. From a personal perspective, I managed to meet up with various users within the Elasticsearch community and discovered many interesting use cases for Elasticsearch. I already knew that many large organisations such as Netflix, Facebook, Microsoft, and Cisco are using Elasticsearch for building out their search capabilities within the organisation. However, it was also really interesting to learn about some of the more unusual use cases. I wasn\u2019t previously aware that NASA uses Elasticsearch to store and analyse data sent back from the Mars Curiosity Rover, or how the Victoria and Albert Museum plans to use Elasticsearch to analyse visitor data to determine how they could optimise the placement of their artifacts within the museum. The event was very well structured. The morning of the conference was focused on the Elastic roadmap and introducing the new features of Elasticsearch 2.0, Kibana 4.2, Beats, Watcher, and Found. A nice little insight into the creation of Elasticsearch was revealed when Shay Banon (the creator of ElasticSearch) began his keynote speech by explaining how he created Elasticsearch in order to create a tool for his wife to search for cooking recipes! The later part of the day was more focused on real life user stories and how they use Elasticsearch within their organisation. Graham Tackley from The Guardian gave us a walkthrough of the tools they have built with the Elasticsearch stack to do real-time media analytics that can process up to 40 million documents a day. There were also two presentations from Goldman Sachs on how they utilise Elasticsearch to build a Goldman Sachs search engine and also a firm-wide task list. My particularwas focused on how we decided on the use of Elasticsearch, some of the reporting requirements from the user and details on the architecture we built out. There were only a handful of people in the audience who were from the financial services industry but I did manage to get some very interesting questions during the talk and even during the drinks reception. It was really good to see how the technology was able to be transferred across multiple industries, and how we can all learn from each other. After the presentations, it was time for the more informal part of the conference and everyone adjourned for beer and food. It was during this time that I got the chance to talk to Shay Banon and discussed some interesting trends within financial services which are perfect candidates for Elasticsearch, e.g. fraud detection, market sentiment analysis, and suchlike. I also had an opportunity to talk to Elastic's co-founder Uri Boness on the challenges of deploying Elasticsearch in the financial services industry and some upcoming features in the roadmap that would help with this, i.e. data centre replication. Elastic{ON} Tour\u00a0London 2015 was an enlightening experience for me. I discovered so many novel use\u00a0cases for Elasticsearch and I had a chance to talk to the people who built those solutions. I was also very excited to be able to share my experience in building out an Enterprise Grid reporting solution based on Elasticsearch. This definitely will not be my last Elastic\u00a0conference. \n"}
{"index": {"_id": 807}}
{"title":"Logstash 2.1.1 and 1.5.6 released","seo_title":"","url":"\/blog\/logstash-2-1-1-and-1-5-6-released","author":{"name":"Suyog Rao"},"date":"December 08, 2015","category":"Releases","locales":"","content":" We are happy to announce that Logstash versions 2.1.1 and 1.5.6 has been released today! Jump to the page for the binaries, where you can also find the full list of changes that made these releases. Bug Fixes This is mainly a bug fix release, some of which we highlight below: Windows Memory Leak Issue This release bundles a new version of JRuby - , which fixes an important memory leak issue reported on Windows when using the file input (). Check our on how we debugged this issue and collaborated with the JRuby team to resolve it. This fix has also been backported to version 1.5.6. File Input Elasticsearch Output (2.1.1): Others (2.1.1): Please Logstash 2.1.1 and 1.5.6 and let us know what you think on Twitter () or on our . You can report any problems on the GitHub issues page. \n"}
{"index": {"_id": 808}}
{"title":"Brewing in Beats: The Git repository merge","seo_title":"","url":"\/blog\/weekly-beats-merged-git-repositories","author":{"name":"Tudor Golubenco"},"date":"December 07, 2015","category":"Brewing in Beats","locales":"","content":" The past week we did a reorg of our Github repositories and worked on the design for a few key features we\u2019re planning for the next future releases. Repository merging We merged libbeat and the four officially supported beats into a single repository: . We\u2019ll have a blog post detailing the reasons, but we essentially found a single repo to result in a lot less work for us but also be more efficient in terms of communication with the rest of the community. Filebeat filtering One of the most often requested features for Filebeat is to be able to do basic line filtering before sending to Logstash. Think of it as doing a \u201cegrep -v\u201d to filter out, for example, debug messages before sending the logs out. If you were previously dropping those lines in Logstash, there are now two handy options in Filebeat that can save you network traffic and CPU load: include_lines and exclude_lines. All the details are in the and the . Design for generic filtering In addition to the simple filtering described above, we started thinking also about a more generic way to filter events or fields, from which all Beats will benefit. The discussion is happening in this and you are invited! Design for multiline Another Frequently Requested Feature for Filebeat is about being able to merge related lines (like the ones from an exception, for example) into a single event. This can be done in Logstash already with the , but doing this closer to where the files are read might make it more reliable for some people and easier to configure and maintain for others. This is also in the design phase, see this . Once again, your input here would be valuable. Design for Packetbeat\u2019s HTTP body handling Another interesting on which design is discussed is about making Packetbeat be able to understand the application specific HTTP payload. For example, if we know that the body is JSON created by an Elasticsearch client or server, we could extract some more interesting information, like the index name, the search query, the number of results, etc. The same can be done, and with relatively little effort, for any protocol that works over http, like CouchDB, Docker\u2019s protocol, XML-RPC, JSON-RPC, etc. Apachebeat We are very happy to see another Beat created by the community: created by . Similar to the existing , Apachebeat can be used to insert the key Apache metrics into Elasticsearch. Connect to Elasticsearch over proxies It\u2019s now for all Beats to also use an HTTP proxy when connecting to Elasticsearch. Packetbeat performance improvements Steffen has been profiling and improving the performance of the and parsers in Packetbeat. These are still in progress and being discussed. Winlogbeat Winlogbeat is slowly getting closer to being releasable, and now it also has his own . \n"}
{"index": {"_id": 809}}
{"title":"This Week in Elasticsearch and Apache Lucene - 2015-12-07","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-12-07","author":{"name":"Michael McCandless"},"date":"December 07, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsWhy multiple clusters can be easier to manage than one giant cluster: \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole Elastic\u00a0ecosystem including news, learning resources and cool use cases! \n"}
{"index": {"_id": 810}}
{"title":"Where in the World is Elastic? - Elastic{ON}Tour Sydney and Melbourne","seo_title":"Where in the World is Elastic? - Elastic{ON}Tour Los Angeles and Seattle","url":"\/blog\/witwies-elasticontour-sydney-melbourne","author":{"name":"Megan Wieling"},"date":"December 07, 2015","category":"","locales":"","content":" Welcome to Find out which Elastic events and\u00a0meetups are happening near you this week.\u00a0Upcoming EventsDecember 8:\u00a0December 10: Upcoming MeetupsDecember\u00a07: December 7: December 8: December 10: December 10: December 10: December 11: That's it for this week. Stay tuned next week for more Elastic happenings.- The Elastic Team P.S. if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}
{"index": {"_id": 811}}
{"title":"Building real-time dashboard applications with Apache Flink, Elasticsearch, and Kibana","seo_title":"Building real-time dashboard applications with Apache Flink, Elasticsearch, and Kibana","url":"\/blog\/building-real-time-dashboard-applications-with-apache-flink-elasticsearch-and-kibana","author":{"name":"Fabian Hueske"},"date":"December 07, 2015","category":"User Stories","locales":"","content":" Gaining actionable insights from continuously produced data in real-time is a common requirement for many businesses today. A wide-spread use case for real-time data processing is dashboarding. A typical architecture to support such a use case is based on a data stream processor, a data store with low latency read\/write access, and a visualization framework. In this blog post, we demonstrate how to build a real-time dashboard solution for stream data analytics using Apache Flink, Elasticsearch, and Kibana. The following figure depicts our system architecture. In our architecture, Apache Flink executes stream analysis jobs that ingest a data stream, apply transformations to analyze, transform, and model the data in motion, and write their results to an Elasticsearch index. Kibana connects to the index and queries it for data to visualize. All components of our architecture are open source systems under the Apache License 2.0. We show how to implement a Flink DataStream program that analyzes a stream of taxi ride events and writes its results to Elasticsearch and give instructions on how to connect and configure Kibana to visualize the analyzed data in real-time.Why use Apache Flink for stream processing?Before we dive into the details of implementing our demo application, we discuss some of the features that make Apache Flink an outstanding stream processor. Apache Flink 0.10, which was recently released, comes with a competitive set of stream processing features, some of which are unique in the open source domain.\u00a0The most important ones are: [if gte mso 9]> Normal<\/w:View> 0<\/w:Zoom> <\/w:TrackMoves> <\/w:TrackFormatting> <\/w:PunctuationKerning> <\/w:ValidateAgainstSchemas> false<\/w:SaveIfXMLInvalid> false<\/w:IgnoreMixedContent> false<\/w:AlwaysShowPlaceholderText> <\/w:DoNotPromoteQF> EN-GB<\/w:LidThemeOther> JA<\/w:LidThemeAsian> X-NONE<\/w:LidThemeComplexScript> <\/w:BreakWrappedTables> <\/w:SnapToGridInCell> <\/w:WrapTextWithPunct> <\/w:UseAsianBreakRules> <\/w:DontGrowAutofit> <\/w:SplitPgBreakAndParaMark> <\/w:EnableOpenTypeKerning> <\/w:DontFlipMirrorIndents> <\/w:OverrideTableStyleHps> <\/w:Compatibility> <\/m:mathFont> <\/m:brkBin> <\/m:brkBinSub> <\/m:smallFrac> <\/m:dispDef> <\/m:lMargin> <\/m:rMargin> <\/m:defJc> <\/m:wrapIndent> <\/m:intLim> <\/m:naryLim> <\/m:mathPr><\/w:WordDocument> <\/xml> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LsdException> <\/w:LatentStyles> <\/xml> \/* Style Definitions *\/ table.MsoNormalTable {mso-style-name:\"Table Normal\": mso-tstyle-rowband-size:0: mso-tstyle-colband-size:0: mso-style-noshow:yes: mso-style-priority:99: mso-style-parent:\"\": mso-padding-alt:0cm 5.4pt 0cm 5.4pt: mso-para-margin:0cm: mso-para-margin-bottom:.0001pt: line-height:115%: mso-pagination:widow-orphan: font-size:11.0pt: font-family:Arial: color:black: } <\/style> <![endif]StartFragmentThe combination of these features makes Apache Flink a unique choice for many stream processing applications.Building a demo application with Flink, Elasticsearch, and KibanaOur demo ingests a stream of taxi ride events and identifies places that are popular within a certain period of time, i.e., we compute every 5 minutes the number of passengers that arrived at each location within the last 15 minutes by taxi. This kind of computation is known as a sliding window operation. We share a of this application (among others) on . You can easily run the application from your IDE by cloning the repository and importing the code. The file provides more detailed instructions.\u00a0Analyze the taxi ride event stream with Apache FlinkFor the demo application, we generate a stream of taxi ride events from a (TLC). The data set consists of records about taxi trips in New York City from 2009 to 2015. We took some of this data and converted it into a data set of taxi ride events by splitting each trip record into a ride start and a ride end event. The events have the following schema:\u00a0 rideId: Long time: DateTime \/\/ start or end time isStart: Boolean \/\/ true = ride start, false = ride end location: GeoPoint \/\/ lon\/lat of pick-up or drop-off location passengerCnt: short travelDist: float \/\/ -1 on start events We implemented a custom to serve a from the ride event data set. In order to generate the stream as realistically as possible, events are emitted by their timestamps. Two events that occurred ten minutes after each other in reality are ingested by Flink with a ten minute lag. A speed-up factor can be specified to \u201cfast-forward\u201d the stream, i.e., with a speed-up factor of 2.0, these events are served five minutes apart. Moreover,\u00a0the source function adds a configurable random delay to each event to simulate the real-world jitter. Given this stream of taxi ride events, our task is to compute every five minutes the number of passengers that arrived within the last 15 minutes at locations in New York City by taxi.As a first step we obtain a and set the to . Event time mode guarantees consistent results even in case of historic data or data which is delivered out-of-order. val env = StreamExecutionEnvironment.getExecutionEnvironment env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime) Next, we define the data source that generates a with at most 60 seconds serving delay (events are out of order by max. 1 minute) and a speed-up factor of 600 (10 minutes are served in 1 second). \/\/ Define the data source val rides: DataStream[TaxiRide] = env.addSource(new TaxiRideSource( \u201c.\/data\/nycTaxiData.gz\u201d, 60, 600.0f)) Since we are only interested in locations that people travel to (and not where they come from) and because the original data is a little bit messy (locations are not always correctly specified), we apply a few filters to first cleanse the data. val cleansedRides = rides \/\/ filter for ride end events .filter( !_.isStart ) \/\/ filter for events in NYC .filter( r => NycGeoUtils.isInNYC(r.location) ) The location of a taxi ride event is defined as a pair of continuous longitude\/latitude values. We need to map them into a finite set of regions in order to be able to aggregate events by location. We do this by defining a grid of approx. 100x100 meter cells on the area of New York City. We use a utility function to map event locations to cell ids and extract the passenger count as follows: \/\/ map location coordinates to cell Id, timestamp, and passenger count val cellIds: DataStream[(Int, Long, Short)] = cleansedRides .map { r => ( NycGeoUtils.mapToGridCell(r.location), r.time.getMillis, r.passengerCnt ) } After these preparation steps, we have the data that we would like to aggregate. Since we want to compute the passenger count for each location (cell id), we start by keying (partitioning by key) the stream by cell id (). Subsequently, we define a sliding time window and run a <code>WindowFunction<\/code>: by calling :val passengerCnts: DataStream[(Int, Long, Int)] = cellIds \/\/ key stream by cell Id .keyBy(_._1) \/\/ define sliding window on keyed stream .timeWindow(Time.minutes(15), Time.minutes(5)) \/\/ count events in window .apply { ( cell: Int, window: TimeWindow, events: Iterable[(Int, Short)], out: Collector[(Int, Long, Int)]) => out.collect( ( cell, window.getEnd, events.map( _._2 ).sum ) ) } The \u00a0operation groups stream events into finite sets of records on which\u00a0a window or aggregation function can be applied. For our application, we call apply() to process the windows using a . The \u00a0receives four parameters, a Tuple that contains the key of the window, a Window object that contains details such as the start and end time of the window, an \u00a0over all elements in the window, and a to collect the records emitted by the . We want to count the number of passengers that arrive within the window\u2019s time bounds. Therefore, we have to emit a single record that contains the grid cell id, the end time of the window, and the sum of the passenger counts which is computed by extracting the individual passenger counts from the iterable () and summing them ().\u00a0Finally, we translate the cell id back into a (referring to the center of the cell) and print the result stream to the standard output. The final call takes care of submitting the program for execution. val cntByLocation: DataStream[(Int, Long, GeoPoint, Int)] = passengerCnts \/\/ map cell Id back to GeoPoint .map( r => (r._1, r._2, NycGeoUtils.getGridCellCenter(r._1), r._3 ) ) cntByLocation \/\/ print to console .print() env.execute(\u201cTotal passenger count per location\u201d) If you followed the into your IDE, you can run the program by executing its methods. You will see Flink\u2019s log messages and the computed results being printed to the standard output. You might wonder why the the program produces results much faster than once every five minutes per location. This is due to the event time processing mode. Since all time-based operations (such as windows) are based on the timestamps of the events, the program becomes independent of the speed at which the data is served. This also means that you can process historic data which is read at full speed from some data store and data which is continuously produced with exactly the same program. Our streaming program will run for a few minutes until the packaged data set is completely processed but you can terminate it at any time. As a next step, we show how to write the result stream into an Elasticsearch index.Prepare the Elasticsearchhe Flink Elasticsearch connector depends on Elasticsearch 1.7.3. Follow these steps to setup Elasticsearch and to create an index.\u00a0 [if gte mso 9]><xml> <w:WordDocument> <w:View>Normal<\/w:View> <w:Zoom>0<\/w:Zoom> <w:TrackMoves><\/w:TrackMoves> <w:TrackFormatting><\/w:TrackFormatting> <w:PunctuationKerning><\/w:PunctuationKerning> <w:ValidateAgainstSchemas><\/w:ValidateAgainstSchemas> <w:SaveIfXMLInvalid>false<\/w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false<\/w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false<\/w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF><\/w:DoNotPromoteQF> <w:LidThemeOther>EN-GB<\/w:LidThemeOther> <w:LidThemeAsian>JA<\/w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE<\/w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables><\/w:BreakWrappedTables> <w:SnapToGridInCell><\/w:SnapToGridInCell> <w:WrapTextWithPunct><\/w:WrapTextWithPunct> <w:UseAsianBreakRules><\/w:UseAsianBreakRules> <w:DontGrowAutofit><\/w:DontGrowAutofit> <w:SplitPgBreakAndParaMark><\/w:SplitPgBreakAndParaMark> <w:EnableOpenTypeKerning><\/w:EnableOpenTypeKerning> <w:DontFlipMirrorIndents><\/w:DontFlipMirrorIndents> <w:OverrideTableStyleHps><\/w:OverrideTableStyleHps> <\/w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\"><\/m:mathFont> <m:brkBin m:val=\"before\"><\/m:brkBin> <m:brkBinSub m:val=\"&#45: -\"><\/m:brkBinSub> <m:smallFrac m:val=\"off\"><\/m:smallFrac> <m:dispDef><\/m:dispDef> <m:lMargin m:val=\"0\"><\/m:lMargin> <m:rMargin m:val=\"0\"><\/m:rMargin> <m:defJc m:val=\"centerGroup\"><\/m:defJc> <m:wrapIndent m:val=\"1440\"><\/m:wrapIndent> <m:intLim m:val=\"subSup\"><\/m:intLim> <m:naryLim m:val=\"undOvr\"><\/m:naryLim> <\/m:mathPr><\/w:WordDocument> <\/xml><![endif][if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"0\" QFormat=\"true\" Name=\"heading 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"0\" QFormat=\"true\" Name=\"heading 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\"><\/w:LsdException> <\/w:LatentStyles> <\/xml><![endif][if gte mso 10]> <style> \/* Style Definitions *\/ table.MsoNormalTable {mso-style-name:\"Table Normal\": mso-tstyle-rowband-size:0: mso-tstyle-colband-size:0: mso-style-noshow:yes: mso-style-priority:99: mso-style-parent:\"\": mso-padding-alt:0cm 5.4pt 0cm 5.4pt: mso-para-margin:0cm: mso-para-margin-bottom:.0001pt: line-height:115%: mso-pagination:widow-orphan: font-size:11.0pt: font-family:Arial: color:black: } <\/style> <![endif]StartFragmentThe program is prepared to write data to the Elasticsearch index you just created but requires a few parameters to be set at the beginning of the main() function. Please set the parameters as follows: EndFragment[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal<\/w:View> <w:Zoom>0<\/w:Zoom> <w:TrackMoves><\/w:TrackMoves> <w:TrackFormatting><\/w:TrackFormatting> <w:PunctuationKerning><\/w:PunctuationKerning> <w:ValidateAgainstSchemas><\/w:ValidateAgainstSchemas> <w:SaveIfXMLInvalid>false<\/w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false<\/w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false<\/w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF><\/w:DoNotPromoteQF> <w:LidThemeOther>EN-GB<\/w:LidThemeOther> <w:LidThemeAsian>JA<\/w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE<\/w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables><\/w:BreakWrappedTables> <w:SnapToGridInCell><\/w:SnapToGridInCell> <w:WrapTextWithPunct><\/w:WrapTextWithPunct> <w:UseAsianBreakRules><\/w:UseAsianBreakRules> <w:DontGrowAutofit><\/w:DontGrowAutofit> <w:SplitPgBreakAndParaMark><\/w:SplitPgBreakAndParaMark> <w:EnableOpenTypeKerning><\/w:EnableOpenTypeKerning> <w:DontFlipMirrorIndents><\/w:DontFlipMirrorIndents> <w:OverrideTableStyleHps><\/w:OverrideTableStyleHps> <\/w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\"><\/m:mathFont> <m:brkBin m:val=\"before\"><\/m:brkBin> <m:brkBinSub m:val=\"&#45: -\"><\/m:brkBinSub> <m:smallFrac m:val=\"off\"><\/m:smallFrac> <m:dispDef><\/m:dispDef> <m:lMargin m:val=\"0\"><\/m:lMargin> <m:rMargin m:val=\"0\"><\/m:rMargin> <m:defJc m:val=\"centerGroup\"><\/m:defJc> <m:wrapIndent m:val=\"1440\"><\/m:wrapIndent> <m:intLim m:val=\"subSup\"><\/m:intLim> <m:naryLim m:val=\"undOvr\"><\/m:naryLim> <\/m:mathPr><\/w:WordDocument> <\/xml><![endif][if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"0\" QFormat=\"true\" Name=\"heading 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"0\" QFormat=\"true\" Name=\"heading 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\"><\/w:LsdException> <\/w:LatentStyles> <\/xml><![endif][if gte mso 10]> <style> \/* Style Definitions *\/ table.MsoNormalTable {mso-style-name:\"Table Normal\": mso-tstyle-rowband-size:0: mso-tstyle-colband-size:0: mso-style-noshow:yes: mso-style-priority:99: mso-style-parent:\"\": mso-padding-alt:0cm 5.4pt 0cm 5.4pt: mso-para-margin:0cm: mso-para-margin-bottom:.0001pt: line-height:115%: mso-pagination:widow-orphan: font-size:11.0pt: font-family:Arial: color:black: } <\/style> <![endif]StartFragmentval writeToElasticsearch = true val elasticsearchHost = \/\/ look up the IP address in the Elasticsearch logs val elasticsearchPort = 9300 EndFragment Now, everything is set up to fill our index with data. When you run the program by executing the main() method again, the program will write the resulting stream to the standard output as before but also insert the records into the Elasticsearch index. If you later want to clear the nyc-idx index, you can simply drop the mapping by running curl -XDELETE 'http:\/\/localhost:9200\/nyc-idx\/popular-locations' and create the mapping again with the previous command.Visualizing the results with KibanaIn order to visualize the data that is inserted into Elasticsearch, we install Kibana 4.1.3 which is compatible with Elasticsearch 1.7.3. The setup is basically the same as for Elasticsearch. [if !supportLists] 1.\u00a0\u00a0\u00a0\u00a0 [endif] Download Kibana 4.1.3 for your environment . [if !supportLists] 2.\u00a0\u00a0\u00a0\u00a0 [endif] Extract the archive file. [if !supportLists] 3.\u00a0\u00a0\u00a0\u00a0 [endif] Enter the extracted folder and start Kibana by running the start script: [if !supportLists] 4.\u00a0\u00a0\u00a0\u00a0 [endif] Open in your browser to access Kibana. Next we need to configure an index pattern. Enter the index name \u201cnyc-idx\u201d and click on \u201cCreate\u201d. Do not uncheck the \u201cIndex contains time-based events\u201d option. Now, Kibana knows about our index and we can start to visualize our data. First click on the \u201cDiscover\u201d button at the top of the page. You will find that Kibana tells you \u201cNo results found\u201d. This is because Kibana restricts time-based events by default to the last 15 minutes. Since our taxi ride data stream starts on January, 1st 2013, we need to adapt the time range that is considered by Kibana. This is done by clicking on the label \u201cLast 15 Minutes\u201d in the top right corner and entering an absolute time range starting at 2013-01-01 and ending at 2013-01-06. We have told Kibana where our data is and the valid time range and can continue to visualize the data. For example we can visualize the arrival counts on a map. Click on the \u201cVisualize\u201d button at the top of the page, select \u201cTile map\u201d, and click on \u201cFrom a new search\u201d. See the following screenshot for the tile map\u00a0Another interesting visualization is to plot the number of arriving passengers over time. Click on \u201cVisualize\u201d at the top, select \u201cVertical bar chart\u201d, and select \u201cFrom a new search\u201d. Again, have a look at the following screenshot for an example for how to configure the chart. Kibana offers many more chart types and visualization options which are out of the scope of this post. You can easily play around with this setup, explore Kibana\u2019s features, and implement your own Flink DataStream programs to analyze taxi rides in New York City. We\u2019re done and hope you had some funIn this blog post we demonstrated how to build a real-time dashboard application with Apache Flink, Elasticsearch, and Kibana. By supporting event-time processing, Apache Flink is able to produce meaningful and consistent results even for historic data or in environments where events arrive out-of-order. The expressive DataStream API with flexible window semantics results in significantly less custom application logic compared to other open source stream processing solutions. Finally, connecting Flink with Elasticsearch and visualizing the real-time data with Kibana is just a matter of a few minutes. We hope you enjoyed running our demo application and had fun playing around with the code. \n"}<br>{"index": {"_id": 812}}<br>{"title":"Implementing a statistical anomaly detector in Elasticsearch - Part 2","seo_title":"Implementing a statistical anomaly detector in Elasticsearch - Part 2","url":"\/blog\/implementing-a-statistical-anomaly-detector-part-2","author":{"name":"Zachary Tong"},"date":"December 02, 2015","category":"Engineering","locales":"","content":" Last week, we which distills thousands of data-points into a handful of representative metrics. \u00a0This forms the basis of Atlas, and does all the heavy lifting required to implement the anomaly detector. This week, we'll finish the implementation and generate some fun graphs. The aggregation we built is designed to be run over a specific window of time: given a date range, it will emit a 90th percentile surprise value for each metric. To fully implement Atlas, we need to plot those 90th percentile values themselves over time. This functionality is not currently possible\u00a0using just\u00a0Pipeline aggs (although a \"sliding histogram\" functionality has been proposed which would fill the gap). \u00a0 Instead, we are going to move the responsibility to , which is well suited for this type of post-processing (Timelion is a new {Re}search project to put fluent time-series manipulation inside Kibana: you ). If you revisit the simulator code, you'll see that after the data has been generated. \u00a0We slide our Pipeline agg across the data in one-hour increments (with a window size of 24 hours). \u00a0We also use to minimize the response output: we don't actually care about the 60,000 buckets\u2026 we just want the \"ninetieth_surprise\" from each metric. \u00a0Filtering the response cuts down network transfer considerably. \u00a0The values are then indexed back into\u00a0Elasticsearch so we can chart them later. We pre-processed these values ahead of time in the simulator\u00a0to simplify the demonstration, but in a real system you'd likely have a Watcher or cronjob executing the query every hour and saving the results. Plotting 90th percentile surprise With the heavy lifting done last week, we can turn to TimeLion to finish the implementation. The first order of business is to pull down the 90th values for a particular metric.\u00a0 We can do that with the following TimeLion syntax: .es('metric:0', metric='avg:value').label(\"#0 90th surprise\") Which will generate a graph that looks something like this: Well that looks fun! \u00a0There is definitely\u00a0\u00a0happening. \u00a0Let's walk through what this chart means, since it is fundamental to how Atlas works: Effectively, if we see a spike we can conclude the underlying data has changed enough to shift our normal variance, likely due to a disruption. \u00a0This is the heart of Atlas: don't watch your data because there is just too much. \u00a0Instead, watch the variance of the\u00a090th percentile of\u00a0deviations from the mean. If you compare the above graph to the actual data for metric #0, you\u2019ll see the stark difference: Building the Atlas Dashboard Of course, the trick is to now automatically identify those spikes and graph\/alert on them. \u00a0Let's start building that logic. \u00a0Atlas alerts when the 90th percentile surprise is 3 standard deviations above the moving average. If you decompose that problem, you'll see several necessary\u00a0components: First, we construct the rolling three standard deviations. \u00a0We do this with a custom function (see footnote for source, it is essentially identical to a function), then multiply it by three to get the third sigma: .es('metric:0', metric='avg:value') .movingstd(6) .multiply(3) Next we write a snippet to\u00a0calculate a rolling average of the data itself: .es('metric:0', metric='avg:value') .movingaverage(6) And finally, we combine those two snippets by adding them together\u00a0to create the \"threshold\". \u00a0This will create a line that is three standard deviations above the moving average of the data: .es('metric:0', metric='avg:value') .movingaverage(6) .sum( .es('metric:0', metric='avg:value') .movingstd(6) .multiply(3) ) Now that we have a \"threshold\", we can plot this with the original data and see how they compare: Hmm, ok. \u00a0It's not really clear right now if the threshold is working or not. \u00a0The chart is difficult to read: \u00a0as soon as the surprise value spikes\u00a0it causes a subsequent spike in the threshold. \u00a0This happens because the spike causes a large change in variance, which the rolling stddev picks up, causing the threshold itself\u00a0to shoot up. \u00a0 If we zoom in on the first spike, we can see that the 90th percentile passes the threshold before the rolling stddev \"catches up\": It's now clear: we\u00a0want to show is the moment in time when the surprise crosses the threshold, and ignore the threshold otherwise (since it is only useful in that first instant). \u00a0Let\u2019s display a single bar when it crosses the threshold instead of a continuous line. To do that, we add a custom function. \u00a0This will only show data-points in the first series if they are greater than the data-points in the second series (see footnote for source): .es('metric:0', metric='avg:value').showifgreater(...) And to complete our query, we only want to show the data if it is greater than three standard deviations (aka if it breaches than the threshold), and then we want to show it as bars instead of lines. \u00a0That gives us our final query: .es('metric:0', metric='avg:value') .showifgreater( .es('metric:0', metric='avg:value') .movingaverage(6) .sum( .es('metric:0', metric='avg:value') .movingstd(6) .multiply(3) ) ).bars() .yaxis(2) .label(\"#0 anomalies\") Which generates a much nicer looking chart: Finally, let's add back the data itself so we have something to compare against: .es('metric:0', metric='avg:value') .label(\"#0 90th surprise\"), .es('metric:0', metric='avg:value') .showifgreater( .es('metric:0', metric='avg:value') .movingaverage(6) .sum( .es('metric:0', metric='avg:value') .movingstd(6) .multiply(3) ) ).bars() .yaxis(2) .label(\"#0 anomalies\") Voila! \u00a0We've implemented Atlas! \u00a0The complete dashboard includes a chart for each metric, as well as a chart showing when disruptions were created (which you obviously would not have in a production environment, but is useful for verifying our simulation): Analysis of anomalies If you work through the disruption chart (top-left), you'll find an associated anomaly in at least one of the metric charts,\u00a0often in several simultaneously. \u00a0Encouragingly, anomalies are tagged for all types of disruptions (node, query, metric). \u00a0The footnote contains a list of the disruptions and their magnitude to give you an idea of impact. \u00a0For example, one \"Query Disruption\"\u00a0lasted three hours and only affected 12 of the 500 total queries (2.4%) One phenomenon you see in the charts are spikes that stay elevated for a while. \u00a0This is in part due to the duration of the disruption, some which last multiple hours. \u00a0But it is also due to the limitation in our pipeline agg mentioned last week: namely, we are selecting the \"largest\" surprise from each timeseries, not the \"last\" surprise. \u00a0That means disruptions are drawn out for an extra 24 hours in the worst case, because the surprise only resets once the disruption falls out of the window. \u00a0This is entirely dependent on the chosen window sizes, and the sensitivity can be tuned by increasing\/decreasing the window. This phenomenon doesn't affect anomaly detection much, although it becomes more apparent if you try to use longer windows of time. \u00a0Once pipeline aggs have the ability to select \"last\", this should be resolved. Conclusion So, that's Atlas. \u00a0A fairly simple -- but very effective -- statistical anomaly detection system built at eBay, and now implemented in Elasticsearch + Timelion. Prior to Pipeline aggs, this could have been implemented by a lot of client-side logic. \u00a0But the prospect of streaming 60k buckets back to the client every hour for processing is not enticing... pipeline aggs have moved the heavy lifting to the server for more efficient processing. Pipeline aggs are still very young, so expect more functionality to be added over time. \u00a0If you have a use-case that is difficult to express in pipelines, please let us know! The end! Or is it... \u00a0\u00a0you say, \u00a0For that answer, , when we implement the TimeLion syntax as a Watcher watch so that you can get automated alerts to email, Slack, etc. See you next week! Footnotes \n"}<br>{"index": {"_id": 813}}<br>{"title":"Movember: It's a wrap","seo_title":"","url":"\/blog\/movember-wrap-up","author":{"name":"Loggy D. Wood"},"date":"December 01, 2015","category":"Culture","locales":"","content":" Ahoy! It\u2019s Loggy D. Wood here with a Movember recap! Stay tuned for other causes that Elastic employees are supporting with our,campaigns. \n"}<br>{"index": {"_id": 814}}<br>{"title":"Scaling Elasticsearch Across Data Centers With Kafka","seo_title":"Scaling Elasticsearch Across Data Centers With Kafka","url":"\/blog\/scaling_elasticsearch_across_data_centers_with_kafka","author":{"name":"Dara Gies"},"date":"December 01, 2015","category":"Engineering","locales":"","content":" Overview Organizations often produce and consume data in multiple regions, sometimes within a country and sometimes globally. \u00a0Regions often have local data centers to meet local security, privacy or performance requirements. Data created in one region may need to be accessed in other regions. Requirements that may play a role in determining an appropriate architecture include high availability, fault tolerance, disaster recovery, ingestion latency and search and access latency. Limited network bandwidth and high latency between data centers can be key considerations for determining a multi-region and multi-data center architecture. Queueing data is a central theme in distributed architectures for reasons including guaranteed message delivery, low network bandwidth and message throughput variation. The purpose of this blog is to show and discuss proposed solutions to a use case where distributed departments produce data locally that must be replicated across data centers and be made accessible for search and access. Use Case Assume a creative agency with offices in New York and London where media assets, such as images, videos, HTML documents, CSS documents, etc are created in the respective offices and maintained in separate Digital Asset Management (DAM) systems. Media assets are shared between New York and London and are discoverable through a search user interface. \n"}<br>{"index": {"_id": 815}}<br>{"title":"Clustering Across Multiple Data Centers","seo_title":"Clustering Across Multiple Data Centers","url":"\/blog\/clustering_across_multiple_data_centers","author":{"name":"Pius Fung"},"date":"November 30, 2015","category":"","locales":"","content":" We are frequently asked whether it is advisable to distribute an Elasticsearch cluster across multiple data centers (DCs). The short answer is \"no\" (for now), but there are some alternate options available described below. This blog post is intended to help you understand why this is the case, and what other options are available to you.But Why?The architecture and design decisions that we make in Elasticsearch are based on certain assumptions, including the assumption that nodes are located on a local network. This is the use case that we optimize and extensively test for, because this is the environment that the vast majority of our users operate in.Network disruptions are much more common across WAN links, between geographical distributed DCs. Even if there is a dedicated link between DCs. \u00a0Elasticsearch is built to be resilient to networking disconnects, but that resiliency is intended to handle the exception, not the norm.Running a single Elasticsearch cluster that spans multiple DCs is not a scenario we test for and there are a number of additional reasons why it is not a recommended or supported practice we will go into below.\u00a0(Note: \u00a0On AWS, running a cluster across availability zones within a single region is supported as Amazon provides consistent high bandwidth and low latency.)Expect the UnexpectedLatency is a problem in distributed systems. \u00a0\u00a0High latency slows indexing because the indexing request is for indexing, and all cluster-wide communications (eg. cluster state updates) in Elasticsearch.If connectivity between nodes in a cluster is momentarily lost, it\u2019s likely that remote shards will be out of date and any single update processed while in disconnected state will invalidate all content held on isolated replicas.This means that Elasticsearch requires the copying of these out of date shards to sync up replicas from their primaries to ensure consistency of data and search responses.Sending full shards for multiple indices may overwhelm a WAN based connection or cause considerable slowdown, leaving your cluster in a degraded state for an extended period of time.Assuming the correct setting of , in the event of a network disconnect between two or more DCs, only the DC with the elected master node will remain active. This can cause many issues for applications in the different DCs which may be attempting to index new data, as the nodes not part of the active cluster will reject any attempted writes.This also provides a challenge with cluster sizing. When the link between the two DCs is broken, the active half of the cluster will need to bear the full load of indexing and queries for all requests.When the link is restored, these nodes will also be pushing data and documents across the network while still handling the full indexing and request load. This necessitates larger or more powerful clusters to ensure enough CPU and IOPS to maintain acceptable performance during such events.What Are The Options ?Here are 3 common scenarios on how this may look to give you some ideas.Here you would have your application code write to a replicated queuing system (e.g. Kafka, Redis, RabbitMQ) and have a process (e.g. ) in each DC reading from the relevant queue and indexing documents into the local Elasticsearch cluster.This way if network connectivity is lost between the DCs, when it is restored, the indexing will continue where it left off. can be used to backup indices at regular intervals (eg. to S3) and restore to the passive DC for disaster recovery. Tools such as make automation of the Snapshot process very simple. Restoration can either be done as soon as the Snapshot has completed or at scheduled times such as hourly or even just once daily.The Snapshot and Restore only copies the segments files that do not already exist in the snapshot repository, so except for the initial snapshot, your backups are incremental which reduces the amount of space needed to store them.Even if you aren\u2019t using Snapshot and Restore to replicate data between DCs, we definitely recommend it to make sure you have a backup!For cases where the data is local to each DC (eg. 1 dataset in Hong Kong, another in London) and there is a need to search across all of them, \u00a0can be used to give a view of both datasets.This allows you to query both clusters as if they were one big cluster, reducing complexity in having to merge datasets. \u00a0Note that master write operations like create index should be performed against the individual clusters.In an\u00a0upcoming (separate)\u00a0blog post, we will elaborate on a multiple data center architecture for a proposed set of use cases.Final WordsAs you can see, this is an area that we think a lot about, and we continue to keep these in mind as we design and develop the multi-cluster replication functionality that is on the Elasticsearch roadmap. \n"}<br>{"index": {"_id": 816}}<br>{"title":"This Week in Elasticsearch and Apache Lucene - 2015-11-30","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-11-30","author":{"name":"Michael McCandless"},"date":"November 30, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsFrom the Found vault: Understanding the Memory Pressure Indicator \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole Elastic\u00a0ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 817}}<br>{"title":"Brewing in Beats: 1.0.0 released","seo_title":"","url":"\/blog\/weekly-beats-1-0-0-released","author":{"name":"Monica Sarbu"},"date":"November 30, 2015","category":"Brewing in Beats","locales":"","content":" The past week was memorable for the Beats team as we finally released 1.0.0. \u00a0 Release bonanza! Beats 1.0, updates to , , \u2014 & Found has the latest. Learn more: \u2014 elastic (@elastic) Change proc type in TopbeatBecause we were using as a type, but also in the field names (e.g. ), this made the requests ambiguous and the result was wrong when using Elasticsearch 1.x for some of the widgets in our sample dashboards. To fix it, we have the to in Topbeat. This change breaks backward compatibility.\u00a0 Community BeatsWe are excited to see two new community Beats created last week: Give these two Beats a try and let us and the authors know what you think! Elasticsearch Ping over httpsFix the Ping function by setting the credentials into the HEAD request sent by the Beat to Elasticsearch. The fix is . Set default ignore_older to 24h in FilebeatThere were some issues with Filebeat failing to reopen files after it closed them, so we decided to of the ignore_older option to 24h. This is the value that was also used by the Logstash Forwarder and it is a safer default. Simplify the main functionFor each Beat the main function looks similar, so we decided to simplify it by moving all the common parts into the run function in libbeat and call it from each Beat. With this change the main function of each Beat resumes to one line of code: , and . \n"}<br>{"index": {"_id": 818}}<br>{"title":"Where in the World is Elastic? - Elastic{ON}Tour Los Angeles and Seattle","seo_title":"Where in the World is Elastic? - Elastic{ON}Tour Los Angeles and Seattle","url":"\/blog\/witwies-elasticontour-losangeles-seattle","author":{"name":"Megan Wieling"},"date":"November 30, 2015","category":"","locales":"","content":" Welcome to Find out which Elastic events and\u00a0meetups are happening near you this week.\u00a0Upcoming EventsDecember 1:\u00a0December 3:\u00a0December 1:\u00a0December 3 - 4: December 1 - 2:\u00a0Upcoming MeetupsNovember 30: December 1: December 1: December 1: December 1: December 2: December 1: November 30: That's it for this week. Stay tuned next week for more Elastic happenings.- The Elastic Team P.S. if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 819}}<br>{"title":"Post-mortem: Memory Leak Hunting on Windows","seo_title":"","url":"\/blog\/postmortem-memory-leak-hunting-windows","author":{"name":"Antonio Bonuccelli"},"date":"November 30, 2015","category":"","locales":"","content":" At Elastic we stand next to our users to help them designing their deployments, architecting their solutions but also troubleshooting problems that can be encountered in day to day operations. Nasty bugs come out now and then and sometime identifying their root cause can be a painful and frustrating exercise, going through debug logs, heap\/thread dumps, OS metrics and failed reproduction attempts. In this blog post, we will go through the story of our investigations to identify a bug which has been impacting a large amount of users and their logstash deployments and tell how we have joined forces between support and development teams in Elastic in order to solve it. This all started with several reports of abnormal behaviour in terms of memory consumption have been reported by our users to our support team but also through GitHub issues, see and . In this case, an analysis of the JVM heap usage over time using JConsole showed no significant anomalies within heap memory consumption, showing the classic healthy \u201csawtooth\u201d, where garbage collection periodically frees memory: Interestingly though, the process total memory footprint on Windows would keep growing and growing over time, well beyond the configured JVM limits (1GB). So where to start from to understand where is this memory being used? Reproducing the problem When there are no steps to follow, in order to recreate a problem, the only approach that usually gives results is just to recreate an environment as close as possible, in terms of OS and application configuration and versions, as the one where the problem has been showing its symptoms: every little detail can make the difference. Using the same configuration and log files from one of our customers we have started monitoring a test environment where we have set up Logstash on a Windows 2012 instance and started observing the behavior as new files to be processed were automatically generated. As reported by the users impacted by this bug, the problem with the high memory consumption of the Logstash process would develop in time, only after several hours of usage: this is usually a common pattern when dealing with memory leaks, however as seen in JConsole picture above, no signs of leak were observable within the Java heap. At this point, we\u2019ve started looking around for alternative more comprehensive memory monitoring\/troubleshooting tools as it became evident after hours of tests that what we were looking for was not something that JConsole could show us. VMMap is part of Microsoft Sysinternals and is a process virtual and physical memory analysis utility. It shows a breakdown of a process\u2019s committed virtual memory types as well as the amount of physical memory (working set) assigned by the operating system to those types. Using VMMap, a very granular breakdown of memory usage for the Logstash process was revealed to us, after we\u2019ve attached it to the test Logstash instance: this allowed us to go beyond the simple Heap\/Off Heap distinction available in JConsole and keep our investigations going. What jumped out fairly quickly was the amount of memory reported as \u201cUnusable\u201d: Unusable Memory Window\u2019s virtual memory manager has a which means that allocating a smaller chunk will result in \u201cwasted\u201d virtual memory. In itself this isn\u2019t a problem, but such a big size of Unusable Memory indicates that there\u2019s a high number of < 64KB allocations which aren\u2019t being freed. Selecting \u201cUnusable Memory\u201d in VMMap confirmed this: All these 56KB chunks meant that the each resulted from a 8KB allocation, which we were able to confirm in \u201cPrivate Data\u201d. In VMMap this section refers to the memory used by the process\u2019s heap, including both and other non JVM memory usage (e.g. through native allocations). Since JConsole and other JVM heap analysis tools showed low memory consumption, this indicated off-heap allocations. At this stage, after days of testing and some non-negligible amount of frustration, we\u2019ve started seeing the light at the end of the tunnel, we had found a smoking gun: the continuous off-\u201cJVM heap\u201d allocations of 8KB which were never freed, easily observed by their counterpart \u201cUnusable Memory\u201d. Narrowing down the leak root cause Now that there was reproducible evidence of the problem (the increase in \u201cUnreachable\u201d memory), we started progressively reducing the scope of the test while ensuring VMMap would still report the off heap allocations. Where to start? The first task was to find the minimal set of plugins - hopefully one - that caused the problem. All memory leaks used pipelines with file input, many filters (mutate, grok, date, etc.) and elasticsearch output, so first we removed all filters and confirmed the leak still happened, then replaced elasticsearch output with stdout and again confirmed the leak. This meant we had very good candidate for the root cause: the plugin! Suspect: Logstash file input This plugin uses a library called , that takes care of observing a list of files, reporting changes and keeping score of read progression for each file. Knowing that the leak came from file input plugin, and that filewatch is responsible for most of its logic, we hacked a small ruby script that used filewatch directly to watch few files. As a reminder, at this point it was easy and quick to know if the leaky code was still being used because any Unreachable allocations were immediately evident in VMMap. This meant we no longer required stress tests for long periods of time, and each hypothesis could be confirmed in seconds. Running this script with only filewatch also triggered the leak so we were on the right path! Suspect: FileWatch ruby library FileWatch has two functionalities: Since the test script used both, the next step was to skip any Tail functionality and just have a script monitoring a list of files using FileWatch::Watch and doing nothing with it. Again, the memory leak was evident in VMMap! Going back to the information previously found in VMMap, we can see that the leak builds up from multiple small allocations and also the data found in private data contained names of files. Looking at the FileWatch::Watch code is Ruby\u2019s method. is used to retrieve information about a file such as its permissions, size, modified time and more. At this point we understood this was a serious bug because\u2026 Suspect: JRuby A simple command line test that continuously requested information for a path was used to check the presence of the leak on : Watching the JRuby instance with VMMap made it clear we had found the responsible for the leak as VMMap showed a huge increase in off heap allocations that weren\u2019t being freed. Identifying the version of the JRuby regression Github issues reported that Logstash 1.4.4 (JRuby 1.7.17) and 1.5.0 (JRuby 1.7.19) were OK and not affected by this which mean the memory leak wasn\u2019t always present in Logstash. To make the lives of the JRuby\u2019s core developers easier, we narrowed down version of JRuby that had introduced the leak using the command line loop shown above as reliable reproduction test. While JRuby 1.7.19 showed no abnormal volumes of \u201cUnusable\u201d memory allocations after 5 minutes: In JRuby 1.7.20, after 5 minutes, the story was completely different, showing 1.7.20 had introduced the leak: The Fix Fortunately the JRuby core team is very active on IRC and, as soon as we presented the case in the #jruby channel, Tom Enebo and others came forth and started investigating the leak. Issue was created as a result and we ended up serving as testers for the proposed fixes. Thanks to an awesome effort of the JRuby team, the bug was traced back into , a POSIX emulation layer for Java. In about two weeks JRuby and were released for the memory leak! So all that remains is\u2026 New Logstash releases! Stay tuned for this week\u2019s releases of Logstash 1.5.6 and 2.1.1 which will include JRuby 1.7.23! \n"}<br>{"index": {"_id": 820}}<br>{"title":"Multiple Elasticsearch Clusters or a Monster Cluster?","seo_title":"Multiple Elasticsearch Clusters, or a Monster Cluster?","url":"\/blog\/multiple-elasticsearch-clusters","author":{"name":"Alex Brasetvik"},"date":"November 30, 2015","category":"Engineering","locales":"","content":" This article refers to\u00a0our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud.Elasticsearch provides a pretty large toolbox for composing complex cluster topologies. You can make heterogenous clusters with beefy nodes hosting your hot indices, and have less expensive nodes host historical data, e.g. using node attributes and . While you can use these features to make the One Monster Cluster to rule them all, this post presents some arguments on why managing multiple separate clusters can actually be simpler than having a single large multi-purpose cluster, even though it means managing more nodes. Performance Reasoning and Limiting Blast RadiusElasticsearch is , and the different use cases can have wildly different performance characteristics and things to learn. While you can have a single cluster handling your app\u2019s autocompletion, full text search, analytics, and logging, at some point the success or failure of one of these will cause grief. A bug or traffic surge can cause your logging activity to go through the roof, overwhelming your cluster and therefore bringing your search to a crawl, possibly causing your site to be unusably slow exactly when it shouldn\u2019t be. Autocompletion workloads require having almost everything in memory and a lot of CPU to respond within the tight \u201cinstantaneous\u201d time budget. So do e-commerce style searches with a lot of aggregations backing navigational aids. Plain \u201cfull text search\u201d can be less demanding, as can write-only indexing of logs until someone suddenly runs a fancy aggregation over a huge timespan. Mixing all these different workloads together makes reasoning about performance hard. Is it OK to drop some logs while your site is seeing a sudden burst of traffic? How slow can autocompletion or navigational search be while still providing an acceptable user experience? How do we ensure high priority searches remain fast when unexpected things happen? Can we scale high priority workloads separately? How would a failure cascade? Analysing how both load and failures cascade through your system are highly related \u2013 a slow system can be indistinguishable from one that is dead. Therefore, separating different priority workloads into completely separate clusters (and processes) makes it much simpler to contain the \u201cblast radius\u201d of a failure. If your autocompletion cluster fails, it shouldn\u2019t bring down the rest of your search and analytics with it. Handling multi-tenancy is hard, and better left to the operating system, which has full control of the memory- and CPU-limits and -priorities of processes. Upgrading by CloningWhile most upgrades of Elasticsearch can be done inline through rolling restarts, major version upgrades require a full cluster restart. If you want to do the upgrade without any downtime, you will need to clone the cluster and route traffic to the new cluster when it is ready. If you do not index continuously, this should be a rather simple process. If you do need to do this while also handling index requests, things get a bit more tricky, and your indexing\/syncing process needs to be able to index to multiple clusters. Our post on may have some interesting pointers here. Since Elasticsearch cannot be downgraded once upgraded, it\u2019s important to test carefully when upgrading. Upgrading through cloning is arguably the safest way to upgrade: no changes are done to the cluster you know works. Rolling back means just continuing to use the existing cluster, while resolving any issues that were discovered with the new version. A Cluster in Every ContinentIf you have users all over the world, having the ability to index to multiple clusters enable globally distributed replicas of your indices. This will let you do latency-based routing, where you route users' requests to the cluster closest to them. Extreme availability requirements can also be achieved, as you can failover across continents and data centres with absolutely nothing in common. In the future, Elasticsearch is likely to be able to \u201cmulti-DC replication\u201d like this for you, through a \u201cchanges-API\u201d. The infrastructure necessary to achieve this is currently , but as of this writing you will need to handle this in your application layer. Bulk (re-)IndexingIf you need to do a large initial bulk indexing, e.g. because you\u2019re adding a new data source or need to reindex due to mapping improvements, it can make sense to create a new cluster specifically for that purpose. Creating an index-only cluster will let your production search cluster continue serving searches without the additional burden of doing large scale indexing, and you can get the indexing done faster by running a large cluster for a few hours. When your indexing is done, use snapshot\/restore to migrate the indices to the search cluster. Then delete the temporary indexing cluster. Testing and ExperimentingExperimenting with new searches and aggregations on a production cluster can lead to great new insights, but if you\u2019re not careful, it can also . If you need to test new things, such as a new aggregation in the newest Elasticsearch version or your redesigned ranking model whose performance characteristics are yet unknown, your safest option is again to create a new cluster to run your experiments. To get real insights, you need realistic test data \u2013 such as your production data that you can clone. (Just make sure you also !) Multiple Clusters on FoundWhile there are several advantages to having multiple clusters, the downside is of course having to more moving parts. We have made sure the enables you to easily manage a fleet of clusters. Creating or upgrading a cluster is done in a few clicks. We , making the service excellent for short-lived throwaway clusters, in addition to your continuous production workloads. We have also made it simple to to copy indices between clusters, which is important when implementing the strategies discussed above. Found\u2019s snapshot restore page lets you select a snapshot and customise which indices you want restored to your destination cluster. SummaryWhile managing multiple clusters comes at a cost, and cloning a massive cluster to upgrade it can be impractical, this post has presented a few cases where you should consider separating your workloads into multiple different clusters: \n"}<br>{"index": {"_id": 821}}<br>{"title":"Elastic Goes Back To School","seo_title":"Elastic Goes Back To School","url":"\/blog\/elastic-goes-back-to-school","author":{"name":"Megan Wieling"},"date":"November 27, 2015","category":"","locales":"","content":" Just when you think you\u2019ve graduated from university, there\u2019s always something that pulls you right back in. We all remember the fun of exams, the deadlines, the never ending books, the long days, and of course, the partying. And then there\u2019s that amazing moment when you finally graduate and say goodbye to university. But who would\u2019ve thought that going back to school could actually be quite interesting? We\u2019re happy to say that we got invited to give a guest lecture at the VU University in Amsterdam to teach computer science and engineering students the basics of Elasticsearch. , one of our core software engineers, was the lucky one to give this presentation to around 100 students. Surprisingly enough only two students have heard about Elasticsearch and Lucene before but guess what, that was about to change... \n"}<br>{"index": {"_id": 822}}<br>{"title":"Movember Data Dive: Eating & Drinking Patterns in the US","seo_title":"","url":"\/blog\/movember-data-dive-part-2","author":{"name":"Loggy D. Wood"},"date":"November 25, 2015","category":"Culture","locales":"","content":" [if gte mso 9]><xml> <o:OfficeDocumentSettings> <o:AllowPNG><\/o:AllowPNG> <\/o:OfficeDocumentSettings> <\/xml><![endif][if gte mso 9]><xml> <w:WordDocument> <w:View>Normal<\/w:View> <w:Zoom>0<\/w:Zoom> <w:TrackMoves><\/w:TrackMoves> <w:TrackFormatting><\/w:TrackFormatting> <w:PunctuationKerning><\/w:PunctuationKerning> <w:ValidateAgainstSchemas><\/w:ValidateAgainstSchemas> <w:SaveIfXMLInvalid>false<\/w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false<\/w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false<\/w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF><\/w:DoNotPromoteQF> <w:LidThemeOther>EN-US<\/w:LidThemeOther> <w:LidThemeAsian>JA<\/w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE<\/w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables><\/w:BreakWrappedTables> <w:SnapToGridInCell><\/w:SnapToGridInCell> <w:WrapTextWithPunct><\/w:WrapTextWithPunct> <w:UseAsianBreakRules><\/w:UseAsianBreakRules> <w:DontGrowAutofit><\/w:DontGrowAutofit> <w:SplitPgBreakAndParaMark><\/w:SplitPgBreakAndParaMark> <w:EnableOpenTypeKerning><\/w:EnableOpenTypeKerning> <w:DontFlipMirrorIndents><\/w:DontFlipMirrorIndents> <w:OverrideTableStyleHps><\/w:OverrideTableStyleHps> <w:UseFELayout><\/w:UseFELayout> <\/w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\"><\/m:mathFont> <m:brkBin m:val=\"before\"><\/m:brkBin> <m:brkBinSub m:val=\"&#45: -\"><\/m:brkBinSub> <m:smallFrac m:val=\"off\"><\/m:smallFrac> <m:dispDef><\/m:dispDef> <m:lMargin m:val=\"0\"><\/m:lMargin> <m:rMargin m:val=\"0\"><\/m:rMargin> <m:defJc m:val=\"centerGroup\"><\/m:defJc> <m:wrapIndent m:val=\"1440\"><\/m:wrapIndent> <m:intLim m:val=\"subSup\"><\/m:intLim> <m:naryLim m:val=\"undOvr\"><\/m:naryLim> <\/m:mathPr><\/w:WordDocument> <\/xml><![endif][if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\"><\/w:LsdException> <\/w:LatentStyles> <\/xml><![endif][if gte mso 10]> <style> \/* Style Definitions *\/ table.MsoNormalTable {mso-style-name:\"Table Normal\": mso-tstyle-rowband-size:0: mso-tstyle-colband-size:0: mso-style-noshow:yes: mso-style-priority:99: mso-style-parent:\"\": mso-padding-alt:0in 5.4pt 0in 5.4pt: mso-para-margin:0in: mso-para-margin-bottom:.0001pt: mso-pagination:widow-orphan: font-size:12.0pt: font-family:Cambria: mso-ascii-font-family:Cambria: mso-ascii-theme-font:minor-latin: mso-hansi-font-family:Cambria: mso-hansi-theme-font:minor-latin: } <\/style> <![endif]StartFragmentIn our first , we explored the physical activity and exercise patterns in the 2013 data. In part deux, we will continue to explore this rich health dataset, this time focusing on the eating and drinking patterns in the United States. As you all know, nutrition and exercise go hand-in-hand towards maintaining a healthy lifestyle. Besides, Thanksgiving (aka food coma day) is around the corner and food is on my mind.#EatYourVeggiesYour mom always said, \u201cEat your veggies.\u201d\u00a0So, which states paid most heed to that wise advice? If you look at daily vegetable consumption patterns, the western states emerge as clear winners, with California leading the pack. Considering that California grows a sizable majority of most vegetables consumed in the US, it\u2019s no surprise that Californians <3 their veggies. Beans, Beans, They're Good for Your HeartThe above vegetable consumption map also includes bean consumption. If you isolate the bean consumption metrics, a very different picture emerges. Puerto Rico leads by a large margin, with average consumption of 0.6 times per day (in other words, 3 times every 5 days). If we exclude Puerto Rico from the map, you see that the southern states lead the bean consumption chart on the US mainland. According to the , households with hispanic heritage are dominant consumers of beans. Given the higher prevalence of Hispanic population in Puerto Rico and southern states, the bean consumption metric is no surprise.It is well known that income has a significant impact on eating habits. In the chart below, you can see that average bean consumption is inversely proportional to income, and average green consumption (shown by dot size) is directly proportional to income. Maintaining a healthy, vegetable-rich diet is expensive in the US, and the results below are likely a reflection of the cost of healthy eating.An Apple a Day \u2026Moving on to fruit consumption, if you look at the average daily fruit consumption pattern (excluding fruit juice), you see that coastal residents do a little better than the rest of the country. One could argue that the difference is quite small - once a day for California vs. 0.5 times a day for Puerto Rico. However, if you normalize that on a per week or per month basis, the difference could add up to be quite significant. Considering that Puerto Rico is home to so many tropical fruits, it is kind of surprising to see Puerto Rico at the bottom of the fruit consumption list. However, Puerto Rico ranked first on fruit juice consumption. Perhaps, Puerto Ricans like consuming their fruits in liquid form. Either that, or Puerto Ricans think of Pina Colada as fruit juice. Speaking of\u00a0, let\u2019s move on to alcohol consumption patterns. To Binge or not to Binge?We don\u2019t really have data to answer that question, but it made for a good section title. The BRFSS survey defines binge drinking as 5 or more drinks per occasion for men, and 4 or more drinks per occasion for women. We were curious about the effect of demographic variables like age, income, education, and marital status on binge-drinking patterns for men in the US.Binge-drinking behavior shows a strong positive correlation to age. Older people have more binge-drinking days per month than younger people, which seems a little counter-intuitive considering the effects of hangovers are amplified with age (not that I would know anything about that). However, the absolute monthly consumption sort of goes the other way with age, with high consumption in the 18-24 years bracket and reduced consumption in the older groups.If we factor the income level into the mix, you see that alcohol consumption (vs. age) patterns actually vary quite a bit across the various income groups. For men in the highest income group (> $50,000), the monthly alcohol consumption drops during their peak working years (35-60 years) and picks up again in post-retirement age (> 60 years). On the other hand, the alcohol consumption in the lowest income group (< $15,000) is the highest during their peak earning years, and only dips in old age.Education has a strong positive impact on binge-drinking habits, as well as absolute alcohol consumption. If we also factor in the marital status, you see that the monthly alcohol consumption for married men is significantly lower than unmarried \/ divorced \/ separated men. If we look at binge patterns, you see that divorced \/ separated men have significantly more binge-drinking days compared to men in other marital categories. On this, I will simply state \u201ccorrelation does not imply causation\u201d and leave it at that.\u00a0GitHub is your OysterIf you enjoyed our Movember data dive, be sure to check out the code in our on GitHub for this and more. Happy Turkey Day! Gobble, Gobble, Gobble.EndFragment \n"}<br>{"index": {"_id": 823}}<br>{"title":"Elasticsearch 2.1.0 and 2.0.1 released","seo_title":"Elasticsearch 2.1.0 and 2.0.1 released","url":"\/blog\/elasticsearch-2-1-0-and-2-0-1-released","author":{"name":"Clinton Gormley"},"date":"November 24, 2015","category":"Releases","locales":"","content":" Today we are pleased to announce the release of based on and a bug fix release of .Latest stable release:Bug fixes in 2.0:If you can't wait to get your hands on the new, shiny goodness\u2026we understand. Get on with downloading the latest and greatest, or spin up a cluster on \u2014 the only hosted Elasticsearch service built and supported by the people building the software.Elasticsearch 2.1.0 adds some great new features and has a number of important enhancements: \n"}<br>{"index": {"_id": 824}}<br>{"title":"The Beats 1.0.0","seo_title":"Beats 1.0.0","url":"\/blog\/beats-1-0-0","author":{"name":"Monica Sarbu"},"date":"November 24, 2015","category":"Releases","locales":"de-de,fr-fr,ja-jp,ko-kr","content":" A big Thank You to everyone who contributed code, reported issues, or just tried the Beats during the beta stage. Start your experience with Beats 1.0.0 and let us know what you think on , , or open an issue on . \n"}<br>{"index": {"_id": 825}}<br>{"title":"Logstash 2.1.0 released","seo_title":"","url":"\/blog\/logstash-2-1-0-released","author":{"name":"Suyog Rao"},"date":"November 24, 2015","category":"Releases","locales":"","content":" We are happy to announce that Logstash 2.1.0 has been released today! This release is packed with enhancements, some of which we highlight below. Jump to the page for the binaries, where you can also find all the that made this release.Installing Plugins OfflineLogstash has a thriving where our community is constantly adding the ability to connect to different inputs, outputs, and processing data. The latest count of plugins you ask? 210 plugins. Previously, with the 1.5.0 release, we made it really easy to install and update available plugins by hosting them on public . Users who deployed Logstash in an environment which did not have internet connectivity - air-gapped datacenter or firewalled access - wanted to interact with plugins. In this release, we provide multiple solutions to address this situation. Details below:As mentioned before, Logstash uses the public as a repository for its plugins. If you are in a situation where you don't have access to this server, or maybe you are developing plugins for internal use, you can mirror RubyGems.org and use this as the installation source. Several open source projects enable you to run your own plugin server, for example - Geminabox, Artifactory, etc. Once you have this setup, you can simply point the Gemfile shipped with Logstash deployment to point to this source. Detailed steps .We've added to the plugin script to prepare plugin packages (with dependencies) so they can be installed in an offline box. The solution requires a staging machine running Logstash that has access to a public or private Rubygems server. This staging machine downloads and packages the files used for offline installation. Once you have this package, you can transfer this to your air-gapped machine or host it on a shared network drive. This becomes the installation source for plugins. With this you can simply do In addition to the above solution, we've decided to periodically publish - every point release - a full-resolved Logstash binary that includes all known plugins and dependencies. You can download this uber package .Shutdown ImprovementsBuilding on shutdown enhancements which were in Logstash 2.0.0, we've added the ability to start Logstash with a CLI option () that allows it to predictably shutdown when the operator initiates it. This is particularly useful in situations where the processing pipeline is blocked, trying to communicate to external sources. Users were frustrated with not being able to shutdown Logstash in these situation. Please be aware that shutting down Logstash could still lead to loss of any in-flight messages.To help with the shutdown situation, logic has been added to detect a potential stall while processing events. The stalled detection uses both the count of inflight events in internal queues and an analysis on busy worker threads. A staleness in both count and running threads triggers the warning mechanism and forces an unsafe shutdown. A report is published when this happens:^CSIGINT received. Shutting down the pipeline. {:level=>:warn} Received shutdown signal, but pipeline is still waiting for in-flight events to be processed. Sending another ^C will force quit Logstash, but this may cause data loss. {:level=>:warn} {:level=>:warn, \"INFLIGHT_EVENT_COUNT\"=>{\"input_to_filter\"=>20, \"total\"=>20}, \"STALLING_THREADS\"=>{[\"LogStash::Filters::Ruby\", {\"code\"=>\"sleep 10000\"}]=>[{\"thread_id\"=>15, \"name\"=>\"|filterworker.0\", \"current_call\"=>\"(ruby filter code):1:in `sleep'\"}]}} The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information. {:level=>:error} {:level=>:warn, \"INFLIGHT_EVENT_COUNT\"=>{\"input_to_filter\"=>20, \"total\"=>20}, \"STALLING_THREADS\"=>{[\"LogStash::Filters::Ruby\", {\"code\"=>\"sleep 10000\"}]=>[{\"thread_id\"=>15, \"name\"=>\"|filterworker.0\", \"current_call\"=>\"(ruby filter code):1:in `sleep'\"}]}} {:level=>:warn, \"INFLIGHT_EVENT_COUNT\"=>{\"input_to_filter\"=>20, \"total\"=>20}, \"STALLING_THREADS\"=>{[\"LogStash::Filters::Ruby\", {\"code\"=>\"sleep 10000\"}]=>[{\"thread_id\"=>15, \"name\"=>\"|filterworker.0\", \"current_call\"=>\"(ruby filter code):1:in `sleep'\"}]}} Forcefully quitting logstash.. {:level=>:fatal}Twitter Input EnhancementsNumerous enhancements have been made in the popular twitter input which is based on :Bug FixesBelow we highlight some of the bugs fixed in this release:FeedbackMany thanks to our users and contributors for making 2.1.0 a successful release. Please the GA binaries and give it a spin! Let us know what you think on our , IRC, and . \n"}<br>{"index": {"_id": 826}}<br>{"title":"Release Bonanza! Beats 1.0, Elasticsearch, Shield, Watcher, Marvel, Logstash 2.1 and Kibana 4.3 are Now Available!","seo_title":"","url":"\/blog\/release-bonanza-beats-1-0-elasticsearch-shield-watcher-marvel-logstash-2-1-and-kibana-4-3-are-now-available","author":{"name":"Shay Banon"},"date":"November 24, 2015","category":"News","locales":"","content":" The returns! Today, we're thrilled to announce new versions of the entire Elastic Stack, and the first generally available version of Beats! \n"}<br>{"index": {"_id": 827}}<br>{"title":"Brewing in Beats: Last step before the GA","seo_title":"","url":"\/blog\/weekly-beats-last-step-before-ga","author":{"name":"Tudor Golubenco"},"date":"November 23, 2015","category":"Brewing in Beats","locales":"","content":" Welcome to ! With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources.In the past week we released 1.0.0-rc2 and we are now ready for our first generally available\u00a0release!Two more important bugs were reported, tracked down, cornered, and fixed. was about lines above 1023 character potentially getting truncated due to a buffer that was .The could cause Filebeat to get stuck in case of quickly rotating files and we\u2019ve got reports for it , so we are quite happy that we could before the GA.We found an with the error handling code of the response from Elasticsearch. The code assumed the \u201cerror\u201d key to be of type string, which is no longer true in Elasticsearch 2.0. The came just in time for RC2.The beats use the \u201cbeat.hostname\u201d for the hostname where the Beat is running, but other Logstash plugins typically use the \u201chost\u201d field for the same thing. This caused annoyance to users, so we listened and found the compromise of having the Logstash Beats plugin automatically .The Winlogbeat (ICYMI, the Beat for Windows events logs) got and i to mirror the automated tests for our other officially supported Beats.Our own Robin Clarke played with cross-compiling Topbeat for ARM and tried it on his RaspberryPi. It just worked :-). Not quite an official supported platform for the Beats yet, but it\u2019s good to know that\u2019s well within reach.We\u2019re doing the last bits of work in preparation for the GA release. Stay tuned! \n"}<br>{"index": {"_id": 828}}<br>{"title":"This Week in Elasticsearch and Apache Lucene","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-11-23","author":{"name":"Michael McCandless"},"date":"November 23, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsMy blog about using as a time series database: \u2014 Felix Barnsteiner (@felix_b) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole Elastic\u00a0ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 829}}<br>{"title":"Implementing a Statistical Anomaly Detector in Elasticsearch - Part 1","seo_title":"","url":"\/blog\/implementing-a-statistical-anomaly-detector-part-1","author":{"name":"Zachary Tong"},"date":"November 23, 2015","category":"Engineering","locales":"","content":" This graph shows the min\/max\/avg of 45 million data points (75,000 individual time series over 600 hours). There are eight large-scale, simulated disruptions in this graph...can you spot them? No? It\u2019s ok, I couldn\u2019t either. When you aggregate all your data together into a single graph, the variability of your data tends to smooth out all but the most obvious changes. In contrast, here are a random selection from the 75,000 series that make up the first graph: These individual charts make it obvious where disruptions might be occurring. But now we have a new problem: there are 75,000 such charts to keep an eye on! And since every chart has its own dynamic range and noise profile, how do you set a threshold for all of them? This conundrum is faced by many companies. As data collection increases, we need new ways to automatically sift through the data and find anomalies. This is exactly what eBay has done with their new . The authors of the algorithm realized that any individual series may look anomalous simply due to chance so simple thresholds won\u2019t work, while at the same time aggregating all the data together smooths the data out too much. Instead, Atlas aggregates together correlated changes in the variance of the underlying data. This means it is robust to noise, but remains sensitive enough to alert when there is a real, correlated shift in the underlying distribution due to a disruption. After reading the paper, I wanted to see if it could be implemented in Elasticsearch. Over the next three parts of this article, we\u2019ll be exploring how Atlas works and how to build it with a combination of Pipeline aggregations, TimeLion graphs and Watcher alerts. To give you a sneak peak, our final chart will look like this: Which accurately places an \u201canomaly bar\u201d on top of each simulated disruption that was generated for this subset of data. Let\u2019s get to it! Simulating a production cluster The first order of business is to generate some data. Since we aren't eBay, we'll have to settle for simulated data. I wrote a which generates our dataset. At a high-level, the simulation is very simple: To make the simulation realistic, each has a unique gaussian distribution which it uses to generate values. For example, the tuple may pull values from a normal distribution centered on and a width of 2 std, while the tuple may pull values from a distribution centered on 70 and 1 std. This setup is important for several reasons. First, the same query and metric combination will have a different distribution on each node, introducing a wide amount of natural variability. Second, because these distributions are normal Gaussian, they are not limited to a hard range of values but could theoretically throw outliers (just statistically less likely). Finally, even though there is a large amount of variability between the tuples...the individual tuples are very consistent: they always pull from their own distribution. The final piece in the simulator is simulating . Each tuple also has a \"disrupted\" distribution. At random points in the timeline, the simulator will toggle one of three disruptions: The disruptions randomly last between 2 and 24 hours each, and may overlap. The goal of these disruptions are to model a wide variety of errors, some which may be subtle (handful of queries which show abnormal results) while others are more obvious (an entire node showing abnormal results). Importantly, these disruptions pull from the same dynamic range as the \"good\" distributions: they aren't an order of magnitude larger, or have drastically wider spread (which would both be fairly easy to spot). Instead, the distributions are very similar...just different from the steady-state \"good\" distributions, making them rather subtle to spot. Find the disruptions! Ok, enough words. Let's look at some graphs of our data. We saw this graph earlier: it is the min\/max\/avg of all data across a month of simulated time. I simulated 30 nodes, 500 queries and 5 metrics, polled every hour for 600 hours. That comes out to 75,000 points of data per hour and 45m total. We already know this graph isn\u2019t super useful, so let\u2019s try to partition the data a bit to gain more insight. The next graph shows Metric #0, which experienced two direct disruptions (e.g. all node\/query pairs involving Metric #0 were affected, totaling 15k \"disrupted\" data-points per hour, for several hours each disruption): If you squint closely, you can see two minor bumps in the average. Both bumps are indeed caused by simulated disruptions...but only the second bump is actually due to a direct \"outage\" of Metric #0. The first bump is caused by a different disruption. The other direct outage of Metric #0 we are looking for isn't visible here. Ok, let's try one last time. What if I told you that Query #204 had a direct outage where all node\/metric pairs involving #204 were affected? Can you see it on this graph: Well, you can see disruptions to the average...but none of those are the direct disruption (they are related to other disruptions to individual nodes or metrics). Ok, so at this point I think you can appreciate the subtlety of these disruptions. They are very small, and even when you have foreknowledge about which chart to look at it can be very hard to pin down the error. If you don't a disruption is occurring, you have to monitor all the individual time-series (which is not feasible at eBay\u2019s scale). Implementing Atlas in Elasticsearch The first step is to design a set of aggregations. Here is the final query, which we'll walk through step-by-step: { \"query\": { \"filtered\": { \"filter\": { \"range\": { \"hour\": { \"gte\": \"{{start}}\", \"lte\": \"{{end}}\" } } } } }, \"size\": 0, \"aggs\": { \"metrics\": { \"terms\": { \"field\": \"metric\", \u201csize\u201d: 5 }, \"aggs\": { \"queries\": { \"terms\": { \"field\": \"query\", \"size\": 500 }, \"aggs\": { \"series\": { \"date_histogram\": { \"field\": \"hour\", \"interval\": \"hour\" }, \"aggs\": { \"avg\": { \"avg\": { \"field\": \"value\" } }, \"movavg\": { \"moving_avg\": { \"buckets_path\": \"avg\", \"window\": 24, \"model\": \"simple\" } }, \"surprise\": { \"bucket_script\": { \"buckets_path\": { \"avg\": \"avg\", \"movavg\": \"movavg\" }, \"script\": \"(avg - movavg).abs()\" } } } }, \"largest_surprise\": { \"max_bucket\": { \"buckets_path\": \"series.surprise\" } } } }, \"ninetieth_surprise\": { \"percentiles_bucket\": { \"buckets_path\": \"queries>largest_surprise\", \"percents\": [ 90.0 ] } } } } } } It's long, but not super complicated. Let's start looking at the components individually. First, we set up our query scope with a simple filtered query (or bool + filter if you are on 2.0)\u00a0over a time range. We'll use this to generate data points for each 24 hour window in our data: \"query\": { \"filtered\": { \"filter\": { \"range\": { \"hour\": { \"gte\": \"{{start}}\", \"lte\": \"{{end}}\" } } } } }, Next is the aggregation, which is where all the heavy lifting takes place. This aggregation uses a two-tiered set of aggregations on and : \"aggs\": { \"metrics\": { \"terms\": { \"field\": \"metric\" }, \"aggs\": { \"queries\": { \"terms\": { \"field\": \"query\", \"size\": 500 }, \"aggs\": { \"series\": { \"date_histogram\": { \"field\": \"hour\", \"interval\": \"hour\" }, We want a single \u201csurprise value\u201d per metric, so our first aggregation is a on \u201cmetric\u201d. Next, we need to partition each term by query (and ask for all 500 queries). Finally, for each query, we need to generate a window of data over the last 24 hours, which means we need an hourly date histogram. At this point, we have a time-series per query per metric, for any given date range defined in our query. This will generate 60,000 buckets (5 metrics *\u00a0500 queries\u00a0*\u00a024 hours) which will then be used to calculate our actual statistics. With the bucketing done, we can move onto the statistical calculations embedded inside the date histogram: \"avg\": { \"avg\": { \"field\": \"value\" } }, \"movavg\": { \"moving_avg\": { \"buckets_path\": \"avg\", \"window\": 24, \"model\": \"simple\" } }, \"surprise\": { \"bucket_script\": { \"buckets_path\": { \"avg\": \"avg\", \"movavg\": \"movavg\" }, \"script\": \"(avg - movavg).abs()\" } } Here we calculate the average of each bucket, which acts to \u201ccollapse\u201d all the values in that hour to a single value we can work with. Next, we define a Moving Average Pipeline aggregation. The moving average takes average bucket values (since the points to \"avg\") and uses a simple average over the 24 hour period. In the Atlas paper, eBay actually uses a moving median, instead of an average. We don't have a moving median (yet!), but I found that the simple average works just fine. The average is used here, instead of the weighted variations, because we don't want any time-based weighting...we actually just want the average of the window. Next, we define the \"surprise\" aggregation, which calculates each bucket's deviation from the average. It does this by using a Bucket Script pipeline agg which subtracts the \"avg\" from the \"moving average\", then takes the absolute value (which allows us to detect both positive and negative surprises). This surprise metric is end-goal for each time-series. Since surprise is the deviation from the average, it is a good indicator when something changes. \u00a0If a series is averaging \u00a010 +\/- 5, and the values suddenly start reporting as 15 +\/- 5 ... the surprise will spike because it deviates from the previous averages.\u00a0 In transient outliers, this is smoothed out quickly. \u00a0But when an actual disruption occurs and the trend changes, the surprise will alert us. Collecting the relevant data The Atlas paper doesn't really care about all the surprise values, it just wants the top 90th percentile. \u00a0The top 90th represents the \"most surprising\" surprise.\u00a0So we need to extract that from our giant list of calculated surprise. The Atlas design takes the last surprise value from each series, finds the 90th percentile and records that. Unfortunately, that isn't quite possible with pipeline aggregations yet. We don't have a way to specify the \"last\" bucket in a series (although I've opened a ticket to include this functionality in the future). Instead, we can \"cheat\" and record the largest surprise from the series, which works as an acceptable proxy. We can then accumulate all the largest values and find the 90th percentile: \"largest_surprise\": { \"max_bucket\": { \"buckets_path\": \"series.surprise\" } } } }, \"ninetieth_surprise\": { \"percentiles_bucket\": { \"buckets_path\": \"queries>largest_surprise\", \"percents\": [ 90.0 ] } } } } } } Which concludes the aggregation. The end result is that we will have a single \"ninetieth_surprise\" value per metric, which represents the 90th percentile of the largest surprise values from each query in each metric. This aggregation crunches through 60,000 buckets to calculate 5 aggregated values. Those 5 aggregated values are the pieces of data that we will use in the next step. To be continued This article is already getting quite long, This aggregation gets us about 80% of the way towards implementing Atlas. The next step is to take these calculated 90th percentile metrics and graph them, as well as alert when they go \"out of bounds\". \n"}<br>{"index": {"_id": 830}}<br>{"title":"Where in the World is Elastic? - Elastic Meetup in London and Paris","seo_title":"Where in the World is Elastic? - Elastic Meetup in London and Paris","url":"\/blog\/witwies-elastic-meetup-london-paris","author":{"name":"Megan Wieling"},"date":"November 22, 2015","category":"","locales":"","content":" Welcome to Find out which Elastic events and\u00a0meetups are happening near you this week.\u00a0Upcoming EventsEuropeNovember 26:\u00a0\u00a0AsiaNovember 28:\u00a0\u00a0Upcoming MeetupsNovember 23: November 24: November 24: November 25: November 25: November 25: November 26: November 26:\u00a0November 25: That's it for this week. Stay tuned next week for more Elastic happenings.- The Elastic Team P.S. if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 831}}<br>{"title":"The Fine Manual: Documentation Processes at Elastic","seo_title":"","url":"\/blog\/the-fine-manual","author":{"name":"Paul Echeverri"},"date":"November 19, 2015","category":"News","locales":"","content":" More than any other company where I\u2019ve worked, Elastic understands the value of clear, useful documentation. A year and a half ago, when I started work as Elastic\u2019s first technical writer, I walked into a place where there was an established culture of engineers that considered documentation a vital part of the software, as attested by the , which was already in place before I started. Building on that culture as we grow the technical publications staff is one of the things that makes this job so exciting. The Process The core process is similar to how it\u2019s done anywhere else: Product Management sets priorities, and Technical Publications talks to the engineers about the current projects to gather requirements and initial insight regarding the new features or improvements. Documentation tasks are tracked with issues on GitHub, just as any other request to improve the software\u2019s usability or functionality. This unified process keeps documentation and engineering effort aligned. When documentation is ready to review, Engineering reviews the material for technical accuracy, we make the necessary corrections, and when there\u2019s a consensus that the material is ready, the source is merged into the repo. But what do I mean by with respect to technical documentation? The Technical Details Documentation at Elastic is written in , a markup language similar to MarkDown, but with a broader feature set. A script invokes the tools that transform the AsciiDoc, first to DocBook XML, then to HTML. The script was created and is maintained by , and you can take a look at it yourself at the docs repository. That repository also contains a that governs which repositories are polled for source AsciiDoc, which books to build, and how version selectors are laid out. To build all the that you see on our site, a cron job makes sure this happens every half hour: This process lets us be very responsive to documentation issues. Fixes typically go live to the Web less than an hour after we merge them into the relevant repository. What this Means to You: Contributing to Documentation Elastic is committed to open source, and one of the signal joys of open source is finding a problem and fixing it. Just as with any other request on a project, you can always open an issue with the documentation on any of our public projects. We\u2019ll assign the issue and get it taken care of. To contribute more directly, open a pull request with your proposed changes. To make the adoption of your changes smoother, here are some best practices: Understand the Documentation Structure The overview of our process earlier in this post is a good high-level description of how things work, but for a good documentation pull request, it helps to understand how documentation is structured at a more granular level. For example, we make use of AsciiDoc declarations, which are defined with pairs of characters, as in this example: Call a defined variable by using the variable\u2019s name in braces: Typically, documentation for a given Elastic software release starts with the file in the directory for that software\u2019s GitHub repository, and is where any attributes used for that documentation are defined. The file has statements that incorporate the text of all the other files in the directory. Files in that directory that use attributes will give you errors about undefined attributes if you don\u2019t build them from . If your contribution relies on new attributes, be sure to specify them in , or they won\u2019t work outside of the one file you did specify them in. Minimize Use of Tables A lot of tables are just used to present two-columnar data, like lists of term definitions or parameter values. For that kind of data, the or work well. Test Build Your Contribution Go to the docs repo on GitHub, download the build script, and make sure your contribution builds cleanly. If you want to go the extra mile, post the rendered HTML online somewhere like so reviewers can look at it. \n"}<br>{"index": {"_id": 832}}<br>{"title":"Elasticsearch plus StreamSets for reliable data ingestion","seo_title":"","url":"\/blog\/elasticsearch-plus-streamsets-reliable-data-ingestion","author":{"name":"Arvind Prabhakar"},"date":"November 18, 2015","category":"User Stories","locales":"","content":" Elasticsearch provides a powerful platform for real-time analytics at scale. Reliable and high-quality data ingestion is a critical component of any analytics pipeline. The recently launched Data Collector provides an enhanced data ingestion process to ensure that data streaming into Elasticsearch is pristine, and remains so on a continuous basis.The StreamSets Data Collector provides an ingestion infrastructure that helps you build continuously curated ingestion pipelines, and improves upon legacy ETL and hand-coded solutions in three important ways: StreamSets customers ingest data from a variety of sources, including 3rd-party data feeds, internal systems, and physical sensors.\u00a0The more they sanitize their data while in motion, the greater the confidence in their analysis using Elasticsearch and Kibana. The less downtime and data loss in their data pipelines, the more complete and accurate their analysis is. Data Drift Breaks and Corrodes PipelinesA chief culprit in the battle for data quality and pipeline reliability is data drift, which is the accumulation of numerous unanticipated changes that occur in data streams. Data drift can break ingest pipelines or corrupt data.In the brittle world of schema-centric ETL, opaque pipelines can break due to the smallest upstream alteration - such as a re-ordering or renaming of fields or minor changes in data type formatting. \u00a0Each time there is an upstream change it risks stopping the ingest process in its tracks, or worse - causing silent data corruption that goes unnoticed for months. When ETL pipelines break, doing forensics and diagnosing their logic is difficult if not downright impossible for large distributed pipelines. \u00a0The entire pipeline is a black box requiring substantial effort to debug and get back online.Data drift also creates an insidious second consequence. It acts as a silent killer of data quality. When semantic changes are missed or ignored - as is common - data quality erodes over time with the accumulation of dropped records, null values and changing meaning of values.The operational impact of data drift and the resulting corrosion is that the results of real-time analysis become unreliable or, due to frequent outages, the analysis becomes impossible to perform. The business impact is that bad data leads to bad decisions and entire areas of analytic potential are left on the shelf. StreamSets Makes Continuous Big Data Ingest SimpleStreamSets was designed from the ground up to allow customers to easily build reliable pipelines in the face of data drift. You can use a drag-and drop interface to connect sources to Elasticsearch and also connect pre-built data preparation functions such as field parsing or PII masking. \u00a0You can route data based on pre-conditions such as creating an error queue for unexpected values.As an example, the screenshot below shows a pipeline for analyzing payment transactions using Elasticsearch as a destination (1). \u00a0The pipeline includes data routing for credit card vs. cash transactions (2), masking of credit card data (3) and routing of suspect location data into a Kafka message queue (4). \u00a0All of this was set up, tested, activated, and monitored without writing any code. In addition to its user interface, StreamSets provides a wide array of APIs for extensibility and customization, making it not a special purpose tool but rather a core piece of modern data infrastructure. \u00a0Early uses for it have been wide and varied, including: Elasticsearch and StreamSets are naturally complementary and critical components in a real-time analytics architecture. \u00a0Customers can use StreamSets to connect a wide variety of sources to both Elasticsearch and Found to provide real-time search capabilities using a constantly curated data flow. Both are built for real-time in-memory performance. Both scale out gracefully through distributed architectures. And both are open source. \n"}<br>{"index": {"_id": 833}}<br>{"title":"The Logstash Lines: 2.0 Feedback","seo_title":"","url":"\/blog\/logstash-lines-2015-11-17","author":{"name":"Suyog Rao"},"date":"November 17, 2015","category":"The Logstash Lines","locales":"","content":" Welcome back to The Logstash Lines! In these weekly posts, we\u2019ll share the latest happenings in the world of Logstash and its ecosystem. 2.0 Feedback Thanks to our users for downloading and trying Logstash 2.0 \u2013 we\u2019ve received great feedback so far! In particular, a few users ran into issues while upgrading both their Elasticsearch and Logstash versions to 2.0. These were caused by breaking changes introduced in 2.0, which is a major version upgrade. You can find more information about upgrading Logstash and Elasticsearch to 2.0 We started an to rewrite the class in pure Java. Event is the main object which encapsulates data and provides an API for the plugins to perform processing on the event content. Having Event implemented in pure Java will improve performance, make possible faster serialization by avoiding costly type conversion between JRuby and Java which in turn will help with an efficient persistence implementation. These changes are internal and will not involve any breaking changes to users. As you can see, there\u2019s been a ton of activity in the past week. We are gearing up for another feature release, so stay tuned! \n"}<br>{"index": {"_id": 834}}<br>{"title":"Beats 1.0.0-rc2 released","seo_title":"Beats 1.0.0-RC2 released","url":"\/blog\/beats-1-0-0-rc2-released","author":{"name":"Monica Sarbu"},"date":"November 17, 2015","category":"Releases","locales":"","content":" We are pleased to announce the release of Beats 1.0.0-rc2. This is the last planned release candidate before 1.0.0-GA. The more beta testers we have, the sooner we can release Beats 1.0.0 GA, so please\u00a0,\u00a0, or\u00a0, try it out, and let us know what you think on Twitter () or on our\u00a0. You can report any problems on the\u00a0,\u00a0, or\u00a0\u00a0GitHub issues page. \n"}<br>{"index": {"_id": 835}}<br>{"title":"Elastic{ON}<sup>16<\/sup>: The Biggest Elasticsearch Gathering Ever is Coming Soon!","seo_title":"Elastic{ON}16 : The Biggest Elasticsearch Gathering Ever is Coming Soon!","url":"\/blog\/elasticon-16-biggest-elasticsearch-gathering-ever-is-coming-soon","author":{"name":"Shay Banon"},"date":"November 17, 2015","category":"News","locales":"","content":" On the heels of our and our , we're now less than 90 days from our second annual user conference, , from February 17-19, 2016. Last year's event was a huge success, with more than 1,100 amazing attendees and talks from NASA's Mars Rover team, Goldman Sachs, Netflix, and Microsoft. What I enjoyed most was that it was a conference about learning, and that amongst each other, our users, customers, and employees got to share ideas about how they use Elasticsearch, Logstash, and Kibana. With our new products like Beats, Found (Elasticsearch as a Service), and our security, alerting, and monitoring extensions (Shield, Watcher, and Marvel), I'm certain that conversations at will extend beyond our wildest imagination. So this year, we're not only making even bigger and expecting more than 2,500 attendees, but we're also using this as an opportunity to make it even better! Some things I'm most excited about for Elastic{ON}. I hope you can join us! And I hear from our team that we have more than 500 people registered in our first week of open registration and that will be ending soon. If you want to , please do so ASAP as we'd love to hear your topic. See everyone in February, and here is a taste of last year: \n"}<br>{"index": {"_id": 836}}<br>{"title":"Kibana 4.2.1 and 4.1.3 released","seo_title":"","url":"\/blog\/kibana-4-2-1-and-4-1-3","author":{"name":"Rashid Khan"},"date":"November 17, 2015","category":"Releases","locales":"","content":" Today we're releasing stability and security updates to Kibana 4.1 and 4.2.\u00a0The 4.2.x series requires Elasticsearch 2.0+, while the 4.1.x series supports Elasticsearch 1.4.4\u00a0-\u00a01.7.\u00a0Grab 4.2.1 or 4.1.3 right here:\u00a0 4.2.1 Fixes and enhancements 4.1.3 Fixes and enhancements \n"}<br>{"index": {"_id": 837}}<br>{"title":"Brewing in Beats: Last changes before RC2","seo_title":"Weekly Beats: Last changes before RC2","url":"\/blog\/last-changes-before-rc2","author":{"name":"Monica Sarbu"},"date":"November 16, 2015","category":"Brewing in Beats","locales":"","content":" With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources. During the past week we continued fixing the issues that were reported from the community and we took our last opportunity to simplify and clarify some field names and configuration options before the 1.0.0 GA release. All these changes, some breaking compatibility since RC1, were based on the feedback from the community. Winlogbeat for shipping Windows Event Logs Andrew published to Github this week. It ships Windows Event Logs to Elasticsearch directly or via Logstash. It installs as a Windows service on all versions since Windows XP. Note that the is for now a proof of concept project and is not yet released. See this for the current status. Export beat.name instead of shipper With this each Beat is now exporting instead of , which is more clear, and also adds which is often needed\/useful. Before, we used the shipper field to both indicate the Beat name and the OS hostname depending on configuration, so separating the two is meant to simplify the configuration and usage. Fix memory leak in Topbeat A memory leak in Topbeat caused problems on Windows. This is fixing it. It also instructs the go tooling to use the built in race detector when running our tests. This should catch a few bugs in the future. Rename -test with -configtest The option, that is passed to the command line of any Beat, is option to make it clear that this is for testing the configuration file and not for the Beat itself. Remove enabled as a configuration option for outputs This simplifies the configuration file options around the enabled\/disabled outputs. The enabled\/disabled configuration options for outputs and TLS options are removed and instead you can just comment out or uncomment in the configuration file to disable or enable a certain output or TLS. Remove line from the Filebeat exported fields Filebeat anymore. The line number was not correctly set in case of Filebeat restarts, and making it correct would have affected the performance. We always recommend using the offset field instead as it gives you the correct value in all cases. Update all Beats repositories automatically Currently each Beat has its own repository in GitHub and they share a few common files defined in the libbeat repository. The defines a script to automatically copy the common files of all Beats in libbeat to each Beat by executing make update in the Beat repository. Check for more details on what files are copied from libbeat. Add system tests to Topbeat are added to Topbeat, using the model used by Packetbeat and Filebeat. They are executed by Jenkins and Travis on Linux and OS X and by on Windows. \n"}<br>{"index": {"_id": 838}}<br>{"title":"Where in the World is Elastic? - Elastic{ON}Tour New York and Chicago","seo_title":"Where in the World is Elastic? - Elastic{ON}Tour London & Paris","url":"\/blog\/witwies-elasticontour-newyork-chicago","author":{"name":"Megan Wieling"},"date":"November 16, 2015","category":"","locales":"","content":" Welcome to Find out which Elastic events and meetups are happening near you this week.\u00a0Upcoming EventsNovember 17: November 16-18: November 17: November 18: November 19: Upcoming MeetupsNovember 18: November 19: November 19: November 16: November 17: November 18: November 18: November 22: That's it for this week. Stay tuned next week for more Elastic happenings.- The Elastic Team P.S. if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 839}}<br>{"title":"Where in the World is Elastic? - Elastic{ON} Tour Wrap Up","seo_title":"Where in the World is Elastic? - Elastic{ON}Tour Wrap Up","url":"\/blog\/witwies-elasticontour-wrap-up","author":{"name":"Megan Wieling"},"date":"November 16, 2015","category":"","locales":"","content":" Welcome to There are no Elastic events or\u00a0meetups taking place\u00a0this week. However, with last Wednesday in Tokyo marking the official end of our tour, we\u00a0thought we'd share some of our favorite moments. Enjoy!Did we not come to your city? Trying to join in on the fun? Check out our upcoming Elasticsearch User Conference, We just announced a bunch of and there will be 2 pre-conference you're going to want to check out.\u00a0Elastic{ON} TourAs always, stay tuned next week for more Elastic happenings.- The Elastic Team P.S. if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 840}}<br>{"title":"Timelion: The time series composer for Kibana","seo_title":"","url":"\/blog\/timelion-timeline","author":{"name":"Rashid Khan"},"date":"November 12, 2015","category":"News","locales":"de-de,fr-fr,ja-jp,ko-kr","content":" The install commands towards the end of this post have been updated to include\u00a0Kibana 5. So I\u2019m putting together a demo of Kibana, and thinking: . At the same time, I\u2019d been mulling a new expression syntax for Kibana: . I had a trans-atlantic flight the next day, and I had a plan: A tiny, in-flight, one-person, hack-a-thon to build an experiment that scratched both the time series and expressions itches. By the time I landed in Houston, I had a syntax, a grid of charts and a few simple functions. A few more hours of hacking and I was in Phoenix answering questions I\u2019d never been able to ask before: Timelion makes all that possible, and more. Timelion is an Elastic {Re}search project into time series, but its more than just an experiment: Its completely usable. By you. Right now. Elastic {Re}search? {Re}search is Elastic\u2019s lab for cutting edge technology. {Re}search is our playground, the sandbox in which we build our wildest sand castles. {Re}search projects are launched by Elastic engineers that want to grab an idea, run with it, and share it. The projects launched under the {Re}search tag highlight our next-big-things, in packages you can use (and abuse) today. Some are standalone, but many are plugins and extensions for our existing products. We invite you to install, experiment, and communicate your experiences with our {Re}search: Thats why they exist, to gather feedback on our ideas. This is TimelionTimelion, pronounced brings together totally independent data sources into a single interface, driven by a simple, one-line expression language combining data retrieval, time series combination and transformation, plus visualization. Every Timelion expression starts with a data source function. For example (or for short). That\u2019s about as simple as it gets right? Count everything in Elasticsearch over time. . As you can see, functions always start with a '.' (dot). What if I want to answer that first question above: . Well, I could plot the two parts together on the same chart, by separating them with a comma. But there's a better way ... We can do more than individual functions, we can chain functions! What I want is to divide total hits by unique users. What we're doing here is saying: Get everything, then divide every point in that series, by every point in this cardinality-of-user-field series I'm passing to We can do that, we can do more: , using the exact same syntax. For example, the Worldbank\u2019s Data API. Series even can be grouped together into lists with parenthesis and a function applied to the grouping. All data sources can receive an offset argument, eg offset=-1M to compare last month as if it was happening now. Timeline can even fit series with dissimilar intervals to a reference, then enabling you to divide you by-the-minute Elasticsearch series with say, yearly Worldbank data. That means we can mix and match these sources, even within the same expression.Thus we can ask crazy questions like \u201cWhat percentage of the US Gross Domestic Product is my company personally responsible for year-to-date?\u201d Also, if that number is big, how about sharing with your old buddy Rashid? Just kidding. Or am I? Funk-shun Al There\u2019s 25 different functions, from simple arithmetic like addition and division to moving averages, cumulative sums and derivatives. That said, Timelion functions and data sources are totally pluggable and super easy to write. We\u2019d love your help rounding out the offering, so get hacking! Go get itI won't give it all away, there\u2019s more to it than just this post. Timelion will launch a tutorial to step you through configuration and some simple starter functions, the rest is up to you to discover. Installing it is easy, run this, bounce the Kibana server. and refresh your browser: . Or you can try it on Found, the best hosted Elasticsearch in the history of the universe, for free: . If you're on 5.x the correct command is: Now use it. Abuse it.Once you've installed it, you'll have a new icon in Kibana, which opens the If you've joined us on Elastic{ON} tour you've already seen this video. If you didn't join us on Elastic{ON}, well, I guess you've learned your lesson? Maybe you should come to ? Keep an eye on this blog for tips and tricks. Keep an eye on for sweet sweet eye candy. Have a great idea? Wrote a new awesome timelion function? . \n"}<br>{"index": {"_id": 841}}<br>{"title":"Movember Data Dive: Physical Activity Behavior in the US","seo_title":"","url":"\/blog\/movember-data-dive-part-1","author":{"name":"Loggy D. Wood"},"date":"November 12, 2015","category":"Culture","locales":"","content":" Howdy! As you all know from last week, I have decided to this November and raise money for the Movember Foundation. The is a global charity that aims to increase\u00a0awareness and funds for men\u2019s health issues, with a focus on 4 key areas: prostate cancer, testicular cancer, poor mental health, and physical inactivity., which is the 3rd leading risk factor for global mortality, is the newest focus area for the Movember Foundation. I have decided to jump in on this initiative by doing what I do best: analyzing data with my partners-in-crime, Elasticsearch and Kibana. And in order to help raise awareness around physical inactivity, I decided to look\u00a0into the from the Centers for Disease Control & Prevention (CDC).Every year, the CDC conducts approximately 500,000 telephone surveys to collect data on a variety of personal health-related topics, such as nutrition, drinking habits, physical activity\u00a0and health history. With this data set, I investigated macro patterns of physical activity and exercise in the United States. Next week, we will dive into relations between personal behavior and health risks such as diabetes, hypertension, and cardiovascular conditions.The big picture!The 2013 survey included ~491,000 respondents, with 40% men and 60% women. Given the Movember focus on , we will only be looking at the male respondent data in the rest of the analysis here.It is heartening to see that almost 75% of the male respondents had at least some exercise in the last 30 days. On the flip side, only about 52% met their recommended aerobic guidelines and an even lower 30% met their recommended muscle strength guidelines. So, there\u2019s definitely some room for improvement there.Conducting large scale surveys is tricky because you want to make sure that survey design and execution do\u00a0not pollute or bias the results in any way. For example, in this survey you see a slight impact of interview month on the results. The graph below shows that\u00a0people interviewed in summer months showed slightly better aerobic fitness levels. People tend to be more active during summer, and what we are observing here is likely the effect of in the survey.Walk on America!Walking is by far the most popular physical activity, with close to 60% of the male respondents listing it as their primary physical activity. Running, weightlifting, and gardening figure in the 2nd, 3rd and 4th spot. Given my woody roots, I was psyched to see Gardening and Yard Work in the top 10.Interestingly, if you look at how much time people spend on their primary physical activity per week, the picture changes a bit as expected. Popular fitness activities like walking, running and weightlifting figure pretty low on the duration metric. Outdoors activities like farming, fishing, skiing, and hunting rise to the top of the chart.Yoga and Pilates are great, but ...Relating the exercise type to the recommended goals, you can see that activities like yoga, weightlifting, and pilates are great for muscle strengthening, but don\u2019t help much with meeting recommended aerobic guidelines. Activities like boxing, rock climbing, wrestling, calisthenics, and aerobics provide a more balanced cardio + strength workout.Buck up, Texas!The BRFSS survey measures personal behavior and health risk patterns at the state level, and this information can be then used by local authorities to design and deploy targeted health initiatives and disease prevention programs. \u00a0Let\u2019s continue exploring the big picture from a geospatial angle. Montana residents\u00a0takes the top spot\u00a0as the most active state, with an average 650 minutes of total physical activity per week. Texas is at the bottom of the rung with total weekly activity of 368 minutes per respondent.Exercise and DemographicsMoving on to demographic factors, it\u2019s interesting, but not surprising, to see how the type of exercise varies with age. You can see that as people age, they gravitate towards activities with lower , i.e lower energy cost activities like gardening and walking. However, it is surprising that on an estimated workout intensity scale, a greater fraction of people in the older age brackets are getting a vigorous workout compared to younger respondents. This seemed counter-intuitive and made me wonder if the formula used to estimate the intensity of a workout was somehow inversely dependent on age.Exploring along other demographic dimensions like education and income level, you can see there is a strong correlation between fitness and both these demographic factors. Educated people and people from higher income brackets show a higher likelihood of meeting their recommended fitness guidelines. However, income and education are typically highly correlated, and it is quite likely that we are not looking at independent effects here.Stay tuned for more!That\u2019s it in this edition of Movember Data Dive. Next week, we will investigate eating and drinking patterns, as well as the relations between health risks and personal behavior. We will also be publishing the example code to the soon. Be sure to check back at the Elastic blog for more. \n"}<br>{"index": {"_id": 842}}<br>{"title":"Octopart on Elasticsearch: All New, Basically the Same","seo_title":"","url":"\/blog\/elasticsearch-on-octopart","author":{"name":"Sam Bobb"},"date":"November 11, 2015","category":"User Stories","locales":"","content":" This article refers to\u00a0our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. Ever worked hard on a project but when you show it off everyone says, \u201cwait, what\u2019s different?\u201d In this post, we\u2019re going to attempt to show off one of those projects. Four weeks ago, we replaced our SolrCloud cluster and custom document store with a shiny new Elasticsearch cluster. While this is a major change to the backend that powers Octopart, on the surface everything looks the same History and our decision to changeAt Octopart we have a search index, which provides ordered results to user queries, a document store, which returns content for the results and detail pages, and a relational database that provides persistent data storage. ThriftDB is an application built at Octopart to keep the Solr search index, Thrift document store, and relational database synchronized while supporting schema changes and multiple document types. Longtime Octopart and HackerNews users may remember ThriftDB.com and hnsearch.com \u2014 projects built on Octopart\u2019s ThriftDB technology stack. When Octopart was founded in 2007, Elasticsearch did not exist yet. Solr was the most full featured open-source search engine. ThriftDB leveraged Thrift definitions to automate the creation of Solr schemas while providing many useful features not available at the time like document storage, dynamic fields, and schema introspection. ThriftDB worked well for Octopart over the years and enabled quick iteration on schema design and search implementation. In 2014, we discontinued hnsearch.com and the public ThriftDB service to focus completely on part search. However, Octopart continued to use ThriftDB internally. As internal libraries tend to do, ThriftDB accumulated cruft and hacks over the years. New developers had to understand many layers before making changes. It lacked tooling and was difficult to debug. As Octopart grew, we had performance problems as well: our search index lagged hours behind the document store. When we decided it was time to replace ThriftDB, Elasticsearch was a natural fit. Many of the custom features in ThriftDB are available out-of-the box in Elasticsearch. As a popular open-source project, Elasticsearch has a great community and powerful debugging and monitoring tools. We wanted to go with a hosted Elasticsearch solution, and we chose Elastic\u2019s own service, Found. It was simple to set up, and we were able to focus our energy on our application instead of configuring and managing the cluster. Found made it easy to incrementally scale our cluster as we transitioned more of our application to Elasticsearch. The Found blog and forum were tremendous resources for understanding the resiliency and performance implications of different cluster configurations. Migration and testingWith careful planning and the support of the entire company, we were able to accomplish this change in three months with a team of two software engineers. First, we modified the code that populates our search index with denormalized part records to write to two places: the legacy system and our new Elasticsearch cluster. While the legacy system continued to power the website, we were free to build, test, and tear down the new system many, many times. Next we wrote a \u201cshim\u201d to replace our existing ThriftDB API with a version that talked to Elasticsearch and continued supporting all of the options exposed via our public API like faceting, ad-hoc filter queries, drilldown and more. Starting with basic part pages we worked progressively to simple searches and then tackled faceting and filtering. Along the way, we refined our Elasticsearch mapping. Finally, we ran searches on both the legacy and new system, compared the results, and fixed many bugs until we were happy with feature parity, result quality, and speed. Four weeks ago the new system went live. ResultAfter our recent acquisition by Altium we needed to quickly integrate with CircuitMaker. Elasticsearch made it easy to add new fields to our search schema and develop specialized queries. We\u2019re providing better search results because it\u2019s now easier to make changes to our ranking algorithm. The delay to update part data has been reduced from hours to one minute. Using the great Elasticsearch debugging and monitoring tools, we\u2019ve discovered and eliminated some expensive queries from our application. This reduced load on the cluster and improved performance, which is reflected in reduced load time of the search sidebar. Our Elasticsearch cluster serves approximately 250 document GETs per second and 20 queries per second. The futureWhile the goal of this project was a seamless transition, we are excited about the new potential afforded for future change. We plan to use this new foundation to make our search experience better and faster in the months to come. \n"}<br>{"index": {"_id": 843}}<br>{"title":"Am\u00e9lioration de la pertinence d'Elasticsearch chez Decitre","seo_title":"Am\u00e9lioration de la pertinence d'Elasticsearch chez Decitre","url":"\/blog\/amelioration-de-la-pertinence-d-elasticsearch-chez-decitre","author":{"name":"Adrien Gallou"},"date":"November 11, 2015","category":"","locales":"fr-fr","content":" \u00a0 Introduction & Contexte Ces hypoth\u00e8ses seront \u00e0 d\u00e9finir en fonction du r\u00e9sultat des \u00e9tudes pr\u00e9c\u00e9dentes. Travail sur le nombre de r\u00e9sultats \n"}<br>{"index": {"_id": 844}}<br>{"title":"Brewing in Beats: Shipped RC1","seo_title":"","url":"\/blog\/weekly-beats-shipped-rc1","author":{"name":"Monica Sarbu"},"date":"November 09, 2015","category":"Brewing in Beats","locales":"","content":" Welcome to ! With this series, we're keeping you up to date with all that's new in , from the details of work in progress pull requests to releases and learning resources. Release 1.0.0-RC1We released 1.0.0-RC1 this past week after closing a total of 100 pull requests in Github.\u00a0 See the for more details. 100 pull requests later, we bring you Beats 1.0.0-rc1: \u2014 elastic (@elastic) When using Logstash as output in your Beat, you need to make sure you have the latest Logstash Beats Input plugin installed by . Note that the current version of Logstash is not coming with the latest Logstash Beats Input plugin, so you need to after installing . We are thrilled to see that so many people are trying out our software and help us improve it by posting issues on the or Github. of issues were fixed during this week. The most interesting ones are: New Community BeatThis week another community Beat was created, called , that is used for uWSGI monitoring. It is a lightweight agent that reads stats from uWSGI server periodically. uWSGI server must expose its stats via . Give it a try and let us know what you think about it. Thank you for creating your second Beat! Configurable Topbeat outputThanks to another community contributor, you can now what type of data Topbeat is outputting. You can select if you want system wide statistics, per process statistics, file system statistics or all of them. Export actual memory usage in Topbeat Add timestamp to Beat log events \n"}<br>{"index": {"_id": 845}}<br>{"title":"Introducing the de_dot filter","seo_title":"","url":"\/blog\/introducing-the-de_dot-filter","author":{"name":"Aaron Mildenstein"},"date":"November 09, 2015","category":"Engineering","locales":"","content":" Hello, fellow Logstashers! We\u2019ve been pleased with the community response to our recent 2.0 release. \u00a0As this was a major release, there were some breaking changes, especially in conjunction with the Elasticsearch 2.0 release. \u00a0One of these changes was that . \u00a0A few Logstash plugins had to be changed to not use dotted fields to be compatible, like the metrics and elapsed filters. \u00a0Unfortunately, many users have no control over the sources of their fields. \u00a0This has resulted in a poor user experience where dotted fields existed. \u00a0To address this issue, the \u00a0filter has been created. \u00a0You can find the plugin documentation for it . You can install the de_dot filter using the plugin command: bin\/plugin install logstash-filter-de_dotThe de_dot filter will replace dots with underscores by default. \u00a0It\u2019s as simple as that! \u00a0If I had a dotted field called , the de_dot filter would change the field name to . \u00a0You can also choose the separator with the \u00a0configuration option. \u00a0A separator does not have to be a single character, either. \u00a0You can make a separator anything you want, except a dot. \u00a0Please remember to change your queries and filters in Kibana to match whatever you change in the de_dot filter! We also added an option to translate dots into nested fields. \u00a0If you set \u00a0in your configuration, Logstash will ignore the \u00a0and attempt to convert dotted fields into nested fields. \u00a0For example, if I had a dotted field called , it would become . \u00a0The flexibility is yours to choose. We\u2019ve provided a \u00a0configuration option to allow you to specify which fields need to be processed. \u00a0If no fields are provided, Logstash will check \u00a0of your fields for dots. \u00a0The de-dot process can be a performance hit to your pipeline, so pre-specifying fields will prevent Logstash from having to check each for dots. \u00a0\u00a0 The idea behind specifying \u00a0manually is to prevent Logstash from having to check every field, which can result in improved performance. \u00a0If you are in a situation where you do not know all possible field names, it may be helpful to tag events which \u00a0have dotted fields, and put the de_dot filter within a conditional that checks for that tag. The \u00a0option also allows you to de_dot nested fields. \u00a0The current release of the de_dot filter will only check the top level of an event for dotted fields. \u00a0If you have a dotted field in a nested object, the de_dot filter cannot find it without help. \u00a0In this case you must use the \u00a0directive to specify a nested field. \u00a0This can be done by using the field reference syntax: \u00a0will find the nested dotted fields \u00a0and . \u00a0You can use either the \u00a0or \u00a0options to act on these fields. We hope that the de_dot filter will help ease your transition to Logstash 2.0 and Elasticsearch 2.0. \u00a0If you need help configuring the de_dot filter, please visit our discussion forum at . \u00a0If you have suggestions or find an issue, please submit a ticket at . Happy Logstashing! \n"}<br>{"index": {"_id": 846}}<br>{"title":"Where in the World is Elastic? - Elastic{ON}Tour Munich","seo_title":"Where in the World is Elastic? - Elastic{ON}Tour London & Paris","url":"\/blog\/witwies-elasticontour-munich","author":{"name":"Megan Wieling"},"date":"November 09, 2015","category":"","locales":"","content":" Welcome to Find out which Elastic events and meetups are happening near you this week.\u00a0Upcoming EventsNovember 10: November 9-10:\u00a0November 12: November 14: Upcoming MeetupsNovember 9: November 10: November 11: November 12: November 12: November 10: November 11: November 11: November 11: That's it for this week. Stay tuned next week for more Elastic happenings.- The Elastic Team P.S. if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 847}}<br>{"title":"Beats 1.0.0-rc1 released","seo_title":"Beats 1.0.0-rc1 released","url":"\/blog\/beats-1-0-0-rc1-released","author":{"name":"Monica Sarbu"},"date":"November 05, 2015","category":"Releases","locales":"","content":" We are pleased to announce the release of Beats 1.0.0-rc1. Lots of fixes and improvements Thank you everyone for testing the 1.0.0-beta4 release and for the help making the Beats better! We received a lot positive feedback along with a long list of issues, many of them Windows-related. There have been going into this release! For more details on changes that went into each Beat, have a look at release notes for , , and . Breaking changes Up to the beta4 release, Beats were using the \u201ctimestamp\u201d field for storing the date and time information. With the addition of Filebeat and the Logstash integration, this started to cause confusion because Logstash uses \u201c@timestamp\u201d for date and time, and automatically adds it to the record. Having two timestamps with almost the same information ended up being redundant. So, based on your feedback, we decided to rename \u201ctimestamp\u201d to \u201c@timestamp\u201d in all Beats before the GA release, resulting in only one consistently-named timestamp field. \u00a0Unfortunately, this change changes the structure of the Beats events, so the data generated with older Beats is not compatible with the new Kibana dashboards distributed with each Beat. However, the existing dashboards will continue to work with the old data. When upgrading to 1.0.0-rc1, you need to reload the template and the dashboards to visualize the new data in Kibana. \u00a0Follow the getting started guide on loading the , the , the , and also for loading the sample . If you have configured the Beat to send data via Logstash, you need to to the latest version in order to work with the \u201c@timestamp\u201d change. Apt and yum repositories It\u2019s now easier to install Packetbeat, Filebeat, and Topbeat, using the . All packages are now signed and uploaded to where all the other Elastic products are also available. Happy testing The more beta testers we have, the sooner we can release Beats 1.0.0 GA, so please , , or , try it out, and let us know what you think on Twitter () or on our . You can report any problems on the , , or GitHub issues page. \n"}<br>{"index": {"_id": 848}}<br>{"title":"Elasticsearch as a Time Series Data Store","seo_title":"","url":"\/blog\/elasticsearch-as-a-time-series-data-store","author":{"name":"Felix Barnsteiner"},"date":"November 04, 2015","category":"User Stories","locales":"de-de,fr-fr,ja-jp,ko-kr","content":" As the project manager of , an open source performance monitoring tool, I've recently been looking for a database to replace the cool-but-aging Graphite Time Series DataBase (TSDB) as the backend. TSDBs are specialised packages for storing (performance) metric data, like the response time of your app or the CPU utilisation of a server. Ultimately, we were looking for a datastore that is easy to install, scalable, supports a variety of functions, and has great support for visualizing the metrics.We've previously worked with Elasticsearch, so we know it is easy to install, scaleable, offers many aggregations, and has a great visualisation tool in Kibana. But we didn't know if Elasticsearch was suited for time series data. We were asking the question. In fact, (you know, those folks who shoot protons in circles) did a between Elasticsearch, InfluxDB and OpenTSDB and declared Elasticsearch the winner.The Decision ProcessElasticsearch is a fantastic tool for storing, searching, and analyzing structured and unstructured data \u2014 including free text, system logs, database records, and more. With the right tweaking, you also get a great platform to store your time series metrics from tools like collectd or statsd.It also scales very easily as you add more metrics. Elasticsearch has built in redundancy thanks to shard replicas and allows simple backups with Snapshot & Restore, which makes management of your cluster and your data a lot easier.Elasticsearch is also highly API driven, and with integration tools like Logstash, it's simple to build data processing pipelines that can handle very large amounts of data with great efficiency. Once you add Kibana to the mix you have a platform that allows you to ingest and analyse multiple datasets and draw correlations from metric and other data side-by-side.Another benefit that isn't immediately obvious is instead of storing metrics that have been transformed via a calculation to provide an endpoint value that gets graphed, you are storing the raw value and then running the suite of powerful aggregations built into Elasticsearch over these values. This means that if you change your mind after a few months of monitoring a metric and you want to calculate or display the metric differently, it's as simple as changing the aggregation over the dataset, for both historic and current data. Or to put it another way: You have the ability to ask and answer questions that you didn't think about when the data was stored!With all that in mind, the obvious question we wanted to answer is: What's the best method for setting up Elasticsearch as a time series database?First Stop: MappingsThe most important part to start is your mapping. Defining your mapping ahead of time means that the analysis and storage of data in Elasticsearch is as optimal as possible.Here's an example of how we do the mappings at stagemonitor. You can find the original over in our :{ \"template\": \"stagemonitor-metrics-*\", \"settings\": { \"index\": { \"refresh_interval\": \"5s\" } }, \"mappings\": { \"_default_\": { \"dynamic_templates\": [ { \"strings\": { \"match\": \"*\", \"match_mapping_type\": \"string\", \"mapping\": { \"type\": \"string\", \"doc_values\": true, \"index\": \"not_analyzed\" } } } ], \"_all\": { \"enabled\": false }, \"_source\": { \"enabled\": false }, \"properties\": { \"@timestamp\": { \"type\": \"date\", \"doc_values\": true }, \"count\": { \"type\": \"integer\", \"doc_values\": true, \"index\": \"no\" }, \"m1_rate\": { \"type\": \"float\", \"doc_values\": true, \"index\": \"no\" }, \"m5_rate\": { \"type\": \"float\", \"doc_values\": true, \"index\": \"no\" }, \"m15_rate\": { \"type\": \"float\", \"doc_values\": true, \"index\": \"no\" }, \"max\": { \"type\": \"integer\", \"doc_values\": true, \"index\": \"no\" }, \"mean\": { \"type\": \"integer\", \"doc_values\": true, \"index\": \"no\" }, \"mean_rate\": { \"type\": \"float\", \"doc_values\": true, \"index\": \"no\" }, \"median\": { \"type\": \"float\", \"doc_values\": true, \"index\": \"no\" }, \"min\": { \"type\": \"float\", \"doc_values\": true, \"index\": \"no\" }, \"p25\": { \"type\": \"float\", \"doc_values\": true, \"index\": \"no\" }, \"p75\": { \"type\": \"float\", \"doc_values\": true, \"index\": \"no\" }, \"p95\": { \"type\": \"float\", \"doc_values\": true, \"index\": \"no\" }, \"p98\": { \"type\": \"float\", \"doc_values\": true, \"index\": \"no\" }, \"p99\": { \"type\": \"float\", \"doc_values\": true, \"index\": \"no\" }, \"p999\": { \"type\": \"float\", \"doc_values\": true, \"index\": \"no\" }, \"std\": { \"type\": \"float\", \"doc_values\": true, \"index\": \"no\" }, \"value\": { \"type\": \"float\", \"doc_values\": true, \"index\": \"no\" }, \"value_boolean\": { \"type\": \"boolean\", \"doc_values\": true, \"index\": \"no\" }, \"value_string\": { \"type\": \"string\", \"doc_values\": true, \"index\": \"no\" } } } } } You can see here we have disabled and as we are only ever going to be building aggregations, so we save on disk space as the document stored will be smaller. The downside is that we won't be able to see the actual JSON documents or to reindex to a new mapping or index structure (see the documentation for for more information), but for our metrics based use case this isn't a major worry for us.Just to reiterate: For most use cases you !We are also not analyzing string values, as we won't perform full text searches on the metric documents. In this case, we only want to filter by exact names or perform term aggregations on fields like , or so that we can filter our metrics by certain hosts or to get a list of all hosts. It's also better to use doc_values as much as possible to reduce heap use.There are two more quite aggressive optimisations which may not be suitable for all use cases. The first one is to use for all metric values. This reduces the index size but also means we can't search the values \u2014 which is fine if we want to show all values in a graph and not only a subset, like values between 2.7182 and 3.1415. By using the smallest numeric type (for us it was float) we can optimize the index further. if your case request values are out of the range of a float you could use doubles.Next Up: Optimising for long term storageThe next important step in optimising this data for long term storage is to force merge () the indices after all the data has been indexed into them. This involves merging the existing shards into just a few and removing any deleted documents in the same step. \u201cOptimize\u201d, as it was known, is a bit of a misleading term in Elasticsearch \u2014 the process does improve resource use, but may require a lot of CPU and disk resources as the system purges any deleted documents and then merges all the underlying Lucene segments. This is why we recommend force merging during off peak periods or running it on nodes with more CPU and disk resources.The merging process does happen automatically in the background, but only while data is being written to the index. We want to explicitly call it once we are sure all the events have been sent to Elasticsearch and the index is no longer being modified by additions, updates, or deletions.An optimize is usually best left until 24-48 hours after the newest index has been created (be it hourly, daily, weekly, etc) to allow any late events to reach Elasticsearch. After that period we can easily use to handle the optimize call:$ curator optimize --delay 2 --max_num_segments 1 indices --older-than 1 --time-unit days --timestring %Y.%m.%d --prefix stagemonitor-metrics- Another great benefit of running this optimise after all data has been written is that we automatically apply that assists in cluster recovery speed and restarts of nodes.If you are using stagemonitor the optimize process is triggered automatically every night, so you don't even need to use curator in that case.The OutcomeTo test this, we sent a randomised set of just over 23 million data points from our platform to Elasticsearch, equal to roughly a week's worth. This is a sample of what the data looks like:{ \"@timestamp\": 1442165810, \"name\": \"timer_1\", \"application\": \"Metrics Store Benchmark\", \"host\": \"my_hostname\", \"instance\": \"Local\", \"count\": 21, \"mean\": 714.86, \"min\": 248.00, \"max\": 979.00, \"stddev\": 216.63, \"p50\": 741.00, \"p75\": 925.00, \"p95\": 977.00, \"p98\": 979.00, \"p99\": 979.00, \"p999\": 979.00, \"mean_rate\": 2.03, \"m1_rate\": 2.18, \"m5_rate\": 2.20, \"m15_rate\": 2.20 } After running a few indexing and optimising cycles we saw the following figures: You can see how important the optimize process was. Even with Elasticsearch doing this work in the background, it is well worth running for long term storage alone.Now with the all this data in Elasticsearch, what can we discover? Well, here's a few samples of what we have built with the system: If you'd like to replicate the testing that we did here you can find the code in the .The FutureWith Elasticsearch 2.0 there are a lot of features that make it even more flexible and suitable for time series data users. open a whole new level for analyzing and transforming of data points. For example, it is possible to smooth graphs with , use a , or even calculate derivatives.And finally, in the mapping described above we had to manually enable doc_values to improve heap efficiency. In 2.0, for any not_analyzed field which means less work for you!About the Author \u2014 Felix BarnsteinerFelix Barnsteiner is the developer of the open source performance monitoring project . During the day he works on eCommerce solutions at iSYS Software GmbH in Munich, Germany. \n"}<br>{"index": {"_id": 849}}<br>{"title":"Performance Considerations for Elasticsearch 2.0 Indexing","seo_title":"","url":"\/blog\/elasticsearch-performance-indexing-2-0","author":{"name":"Michael McCandless"},"date":"November 03, 2015","category":"Engineering","locales":"","content":" A little over a year ago I\u00a0\u00a0with Elasticsearch, but a lot has changed since then so here I explain the changes that affect indexing performance in Elasticsearch 2.0.0. Store throttling is now automaticPrior to 2.0.0, Elasticsearch throttled ongoing merges at fixed rate (20 MB\/sec by default), but this was often far too low and would easily\u00a0lead to merges falling behind and subsequent index throttling.\u00a0 As of 2.0.0, Elasticsearch now\u00a0: when merges are starting to fall behind, the allowed IO rate is increased, and decreased when merges are keeping up. This means a sudden but rare large merge on a low-throughput indexing use case should not saturate all available IO on the node, minimizing impact to ongoing searches and indexing. But for heavy indexing, the allowed merge IO will increase to match the ongoing indexing. This is good news! \u00a0It\u00a0means you shouldn't need to touch any throttling settings: just use the defaults. Multiple\u00a0Using multiple IO devices (by specifying multiple\u00a0\u00a0paths)\u00a0to hold the shards on your node is useful for increasing total storage space, and improving IO performance, if that's a bottleneck for your Elasticsearch usage. With 2.0, there is an important change in how Elasticsearch spreads the IO load across multiple paths: previously, each low-level index file was sent to the best (default: most empty) path, but now that switch is per-shard instead. \u00a0When a shard is allocated to the node, the node will pick\u00a0which path\u00a0will hold all files for that shard.\u00a0 The improves resiliency to IO device failures:\u00a0if one of your IO devices crashes, now\u00a0you'll only lose the shards that were on it, whereas before 2.0\u00a0you would lose any shard that had at least one file on the affected device (typically this means nearly all shards on that node). Note that\u00a0an OS-level RAID 0 device is also a poor choice as\u00a0you'll lose all shards on that node when any device fails, since files are striped at the block level,\u00a0so multiple\u00a0\u00a0is the recommended approach. You should still have at least 1 replica for your indices so you can recover the lost shards from other nodes\u00a0without any data loss. The Auto-ID optimization is removedPreviously, Elasticsearch optimized the auto-id case (when you didn't provide your own id for\u00a0each indexed document) to use append-only Lucene APIs under-the-hood, but this proved\u00a0problematic in error cases and so\u00a0. We also\u00a0\u00a0so that this optimization was no longer so important, and this allowed us to\u00a0\u00a0entirely as they consumed non-trivial heap but didn't offer much ID lookup performance gain. Finally, as of 1.4.0, Elasticsearch\u00a0\u00a0to generate its IDs, for better lookup performance over the previous UUIDs. All of this means you should feel free to use your own id field, with no performance penalty due to the now removed auto-id handling,\u00a0but just remember that your choice of\u00a0id field values\u00a0. More indexing changes...Beyond these changes there have been a great\u00a0many additional 2.0\u00a0indexing\u00a0changes\u00a0such as:\u00a0 (instead of using CPU- and heap-costly field data at search time), moving\u00a0the dangerous delete-by-query API from a core API to a safe\u00a0, exposing control over\u00a0, better and ,\u00a0reducing heap required when merging\u00a0and a number of improvements in resiliency such as . If you are curious about the low-level Lucene actions while indexing, add\u00a0\u00a0to your\u00a0, but be warned: this generates impressively copious\u00a0output! Our\u00a0\u00a0shows that we are generally\u00a0moving in the right direction with our defaults\u00a0over time: the docs\/sec and segment counts\u00a0for the defaults (4 GB) heap has caught up to the\u00a0\u00a0performance line. \n"}<br>{"index": {"_id": 850}}<br>{"title":"Brewing in Beats: On the way to RC1","seo_title":"","url":"\/blog\/weekly-beats-on-the-way-to-rc1","author":{"name":""},"date":"November 02, 2015","category":"Brewing in Beats","locales":"","content":" Welcome to ! With this series, we're keeping you up to date with all that's new in Beats, from the details of work in progress pull requests to releases and learning resources. Getting FeedbackThe Beta4 release brought us positive feedback from the community, but also more work for our team. There were many questions and issues opened that kept us busy for the week, but also motivated us to improve the Beats on the way to GA. Our current plan is to release an RC1 the middle of this week, and if things go well, release the GA a bit later. Apt and yum repositoriesIt\u2019s now easier to install Packetbeat, Filebeat, and Topbeat by using the apt and yum commands. The beta4 release packages, as well as previous releases, are now signed and uploaded to packages.elasticsearch.org where all the other Elastic products are also available. The steps to install the Elastic public key and then the packages from the repositories are in this . Renamed the \u2018timestamp\u2019 field to \u2018@timestamp\u2019Everything started with an reported against Filebeat where the timestamp information is available twice in Elasticsearch when Logstash output is enabled. Filebeat sets the `timestamp` to the time when the event is read, and Logstash adds an additional `@timestamp` field set to the time when the event was received or to the value parsed from the log line. Having two timestamp fields, usually with similar but not identical values, can be quite confusing. So we renamed `timestamp` to `@timestamp` in all Beats. Filebeat exports the `@timestamp` field, and if the Logstash date-filter is used, the field is overwritten with the real timestamp of when the event was produced. This keeps the field consistently named across Beats and also consistent with the file-input plugin from Logstash. On the downside, the meaning of the `@timestamp` field is different for each Beat. For Packetbeat, it means the time of the request, for Topbeat it is the time when system metrics were read, and for Filebeat it is the time when the log line was read. Filebeat Windows fixesWindows is a challenging platform for log readers due to its strict file locking rules. With the help of the community, we discovered and fixed an important this week. Because Filebeat was requesting GENERIC_WRITE access to the files, they were being marked as read-only for new open operations. \u00a0Our automatic tests failed to detect this issue because the tests are written in Python, and Python simply ignores this flag. \u00a0 fixed it. Add stdout as file outputWe added stdout as file output as the result of this on discuss. This output is useful for testing and potentially for chaining the Beats. Getting to an awesome documentationThis week we worked closely with , our great technical writer, on improving the Beats documentation. You can already see the improvements online for the , , , and . Closing other Beta4 IssuesA big Thank You to everyone who tried the Beta4 release and posted issues on or . We fixed this week. \n"}<br>{"index": {"_id": 851}}<br>{"title":"My First Movember","seo_title":"My first movember","url":"\/blog\/loggy-first-movember","author":{"name":"Loggy D. Wood"},"date":"November 02, 2015","category":"Culture","locales":"","content":" It\u2019s November: quick, what\u2019s the first thing you think of? \n"}<br>{"index": {"_id": 852}}<br>{"title":"The Logstash Lines: Release Bonanza Edition!","seo_title":"","url":"\/blog\/logstash-lines-2015-11-02","author":{"name":"Suyog Rao"},"date":"November 02, 2015","category":"The Logstash Lines","locales":"","content":" Welcome back to The Logstash Lines! In these weekly posts, we\u2019ll share the latest happenings in the world of Logstash and its ecosystem. Its been a busy week here in Logstash land! We released 2.0.0 and 1.5.5 for week! has Elasticsearch 2.0 compatibility, shutdown semantics, and some nice performance boosts across the board. is a bug fix release, and the last planned one for 1.5 series. It also included Beats input, so users don\u2019t necessarily have to upgrade to 2.0 to use Beats. Resiliency: Persistent Queues Yep, we\u2019ve talked about this feature , but had to put it on the back burner to clear some tech debt, and to lay out some foundation. Post 2.0, we\u2019ve renewed our efforts around this feature. First step is to rewrite in pure Java so we don\u2019t pay the serialization cost across jruby-java boundary while persisting data to disk. We made refactoring existing code around this class to create a pluggable Event gem - logstash-core-event. This will allow us to have a drop-in replacement for the existing ruby Event class. Centralized Config management Discussed functional requirements for and brainstormed few design approaches. Plugins Oh, hey, one more important update \u2013 its Movember and your favorite ! Go on, rock the \u2018stache! Until next time! \n"}<br>{"index": {"_id": 853}}<br>{"title":"Where in the World is Elastic? - Elastic{ON}Tour London & Paris","seo_title":"Where in the World is Elastic? - Elastic{ON}Tour London & Paris","url":"\/blog\/witwies-elasticontour-london-paris","author":{"name":"Megan Wieling"},"date":"November 02, 2015","category":"","locales":"","content":" Welcome to Find out which Elastic events and meetups are happening near you this week.\u00a0Upcoming EventsNovember 3: November 5:\u00a0November 6-7:\u00a0Upcoming MeetupsNovember 5:\u00a0November 5:\u00a0November 5: \u00a0November 7: Please note that not all the meetups posted here\u00a0are sponsored or organized\u00a0by Elastic, but we are all about supporting the community and bringing together those\u00a0who are talking about Elastic. That's it for this week. Stay tuned next week for more Elastic happenings.- The Elastic Team P.S. if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 854}}<br>{"title":"Tear away your ACLs: Upgrade Your Found Cluster To Shield","seo_title":"","url":"\/blog\/tear-away-your-acls-upgrade-your-found-cluster-to-shield","author":{"name":"Michael Basnight"},"date":"October 30, 2015","category":"Engineering","locales":"","content":" This article refers to\u00a0our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. One of the benefits of being a customer of Found, our official hosted Elasticsearch service,\u00a0is that you get to use Elastic\u2019s enterprise plugins, including\u00a0. Found uses Shield on every cluster to ensure that your data is secure. It also has user authentication, so you can set up users and roles, and with Shield 2.0 (available in Elasticsearch 2.0 on Found), you can even limit the fields and documents that users can access! As our awesome Elastic engineers come out with features, Found customers benefit from them! #winning. A brief history of Found ACLBefore Found implemented Shield, we had our own way of doing Access Control Lists (ACL). Some of our long time customers very likely implemented those\u00a0ACLs in production.\u00a0The legacy ACLs, while they worked very well, they had their downsides. It was a piece of infrastructure Found had to implement and maintain. It was also easy to make mistakes because of the syntax of the ACL.\u00a0 As you can imagine, we jumped at the chance to make our infrastructure less complicated by migrating all our clusters to use Shield.\u00a0Now we have a world class solution providing ACL and node-to-node security for every cluster on Found!\u00a0Now doesn\u2019t that just give you warm fuzzies? \n"}<br>{"index": {"_id": 855}}<br>{"title":"Modeling data for fast aggregations","seo_title":"","url":"\/blog\/modeling-data-for-fast-aggregations","author":{"name":"Adrien Grand"},"date":"October 29, 2015","category":"","locales":"","content":" When wanting to improve search performance, one common reaction is often to start looking at what settings can be tuned in order to make elasticsearch perform better. Unfortunately, even when successful, this approach rarely improves performance by more than a few percent. On the other hand changing the way that documents are modeled can have a dramatic impact on performance. For instance imagine that you want to find all documents that contain a given 3-letters substring (eg. \u201cump\u201d would find documents containing \u201cjumps\u201d). The naive approach would be to to index documents with the default configuration and then search using a query. Unfortunately, the wildcard query is one of the slowest queries that is exposed in Elasticsearch. On the other hand, you could change your analysis chain in order to index every substring using the tokenizer (so that \u201cjumps\u201d would generate three tokens \u201cjum\u201d, \u201cump\u201d and \"mps\") and the wildcard query could be replaced with a simple term query, which performs much faster. The general advice is that you should model your data in order to make search operations as lightweight as possible. A corollary is that you cannot make good data modeling decisions without knowing the queries that your users run. And what we just said about queries can also be applied to aggregations: we will look at an example in order to see how this could work. Imagine that you allow your users to search real-estate listings documents which might look like this: { \u201clocation\u201d: [-0.37, 49.2], \u201cprice_euros\u201d: 188000, \u201csurface_m2\u201d: 132, \u201chas_photo\u201d: true, \u201chas_swimming_pool\u201d: false, \u201chas_balcony\u201d: true } And in order to give your users insights about the listings, you might use an aggregation that would look like this: { \u201caggs\u201d: { \u201clocation_grid\u201d: { \u201cgeohash_grid\u201d: { \u201cfield\u201d: \u201clocation\u201d, \u201cprecision\u201d: 3 } } }, \u201cprice_ranges\u201d: { \u201crange\u201d: { \u201cfield\u201d: \u201cprice_euros\u201d, \u201cranges\u201d: [ {\u201cto\u201d: 20000}, {\u201cfrom\u201d:20000, \u201cto\u201d: 50000}, {\u201cfrom\u201d:50000, \u201cto\u201d: 100000}, {\u201cfrom\u201d:100000, \u201cto\u201d: 200000}, {\u201cfrom\u201d:200000} ] } }, \u201csurface_histo\u201d: { \u201chistogram\u201d: { \u201cfield\u201d: \u201csurface_m2\u201d, \u201cinterval\u201d: 20 } }, \u201chas_photo_terms\u201d: { \u201cterms\u201d: { \u201cfield\u201d: \u201chas_photo\u201d } }, \u201chas_swimming_pool_terms\u201d: { \u201cterms\u201d: { \u201cfield\u201d: \u201chas_swimming_pool\u201d } }, \u201chas_balcony_terms\u201d: { \u201cterms\u201d: { \u201cfield\u201d: \u201chas_balcony\u201d } } } Pre-compute data for aggregationsIf most requests would use the same ranges for the aggregation and the same interval for the aggregation, then it is possible to optimize this aggregation by directly indexing the ranges that a document belongs to and replacing these range and histogram aggregations with a terms aggregation. Here is what the document and aggregations would look like now: { \u201clocation\u201d: [-0.37, 49.2] \u201cprice_euros\u201d: 188000, \u201cprice_euros_range\u201d: \u201c100000-200000\u201d, \u201csurface_m2\u201d: 132, \u201csurface_m2_range\u201d: \u201c120-140\u201d, \u201chas_photo\u201d: true, \u201chas_swimming_pool\u201d: false, \u201chas_balcony\u201d: true } { \u201caggs\u201d: { \u201clocation_grid\u201d: { \u201cgeohash_grid\u201d: { \u201cfield\u201d: \u201clocation\u201d, \u201cprecision\u201d: 3 } } }, \u201cprice_ranges\u201d: { \u201cterms\u201d: { \u201cfield\u201d: \u201cprice_euros_range\u201d } }, \u201csurface_histo\u201d: { \u201cterms\u201d: { \u201cfield\u201d: \u201csurface_m2_range\u201d } }, \u201chas_photo_terms\u201d: { \u201cterms\u201d: { \u201cfield\u201d: \u201chas_photo\u201d } }, \u201chas_swimming_pool_terms\u201d: { \u201cterms\u201d: { \u201cfield\u201d: \u201chas_swimming_pool\u201d } }, \u201chas_balcony_terms\u201d: { \u201cterms\u201d: { \u201cfield\u201d: \u201chas_balcony\u201d } } } Merge aggregations togetherThis aggregation will likely perform a bit faster, but we can further improve it: all these terms aggregations are executed against a field that can only have a finite set of values and we could easily merge them all into a single terms aggregation: { \u201clocation\u201d: [-0.37, 49.2] \u201cprice_euros\u201d: 188000, \u201csurface_m2\u201d: 132, \u201chas_photo\u201d: true, \u201chas_swimming_pool\u201d: false, \u201chas_balcony\u201d: true, \u201cattributes\u201d: [ \u201cprice_euros_range_100000-200000\u201d, \u201csurface_m2_range_120-140\u201d, \u201chas_photo\u201d, \u201chas_balcony\u201d ] } { \u201caggs\u201d: { \u201clocation_grid\u201d: { \u201cgeohash_grid\u201d: { \u201cfield\u201d: \u201clocation\u201d, \u201cprecision\u201d: 3 } } }, \u201cattributes_terms\u201d: { \u201cterms\u201d: { \u201cfield\u201d: \u201cattributes\u201d } } } ConclusionAs you can see we managed to go down from 6 aggregations to only 2 that will likely perform faster and still give us exactly the same information. For instance if you want to know how many listings have a balcony, you just need to look up the number of documents that contain in the aggregation. However we lost flexibility: with such an approach, more logic needs to be moved to the client and you can\u2019t change the ranges for prices without reindexing. So if you want to let users decide on the ranges which should be used to compute buckets, it won\u2019t work. But both approaches can be complementary: as you can see we still kept the original data in our documents, we just added new fields. So if you have a default set of ranges that would be used by 95% of your requests, you could still benefit from this optimized approach for these requests that rely on the defaults, and fallback to a regular range aggregation when users want to dig more into the data. \n"}<br>{"index": {"_id": 856}}<br>{"title":"Elasticsearch for Apache Hadoop 2.2 beta1 and 2.1.2 released","seo_title":"","url":"\/blog\/elasticsearch-for-apache-hadoop-2-2-0-beta1","author":{"name":"Costin Leau"},"date":"October 29, 2015","category":"Releases","locales":"","content":" Continuing the from yesterday (or depending on your timezone, this morning), I am happy to announce the releases of Elasticsearch for Apache Hadoop (aka ES-Hadoop) and Both releases contain a number of important bug-fixes but also new features such as: Optimized data nodes routing To minimize memory pressure on master nodes, the default routing has changed to read and write data only through data nodes excluding masters all together. Consolidated and crowded clusters should see increased throughput and better stability especially in long running jobs. Support for Spark 1.5 Spark 1.5 is officially supported while maintaining compatibility with all the previous versions up to 1.x Enhanced push down operations in Spark Speaking of Spark, the push-down operations have been improved through the null-safe equality comparator (in Spark 1.5) and better generated clause. On top of that, ES-Hadoop features: Elasticsearch 2.0 GA support Yup, take the latest and greatest Elasticsearch release and run your Hadoop and Spark jobs against. As before, compatibility with Elasticsearch 1.x is preserved. Not only beta1 is compatible at the REST level but also the plugin has been rewritten to take advantage of the new plugin architecture in Elasticsearch 2.0. Support for restricted\/WAN installs Running Elasticsearch in the cloud or behind a restricted firewall? Is access allowed only through a predefined number of gateways (that might or might not be part of Elasticsearch)? With beta1 this scenario is supported out of the box through a simple configuration option. Do note that for performance reasons it is desired to have full access to the Elasticsearch data nodes. Option to restrict the number of documents being read For cases where only a restricted number of matches need to be returned for a given query, beta1 introduces a new configuration option to limit the results. Feedback ES-Hadoop 2.1.x users are recommended to upgrade to 2.1.2 while those wanting to upgrade to Elasticsearch 2.0, to use ES-Hadoop 2.2.0-beta1. Let us know what you think on Twitter (@elastic) or on our forum. You can report any problems on the GitHub issues page. Better yet, if you would like to chat live about Elasticsearch and Hadoop\/Spark, yours truly will be attending the (London, Paris, New York and Chicago). Looking forward to it! \n"}<br>{"index": {"_id": 857}}<br>{"title":"Logstash 1.5.5 released","seo_title":"","url":"\/blog\/logstash-1-5-5-released","author":{"name":"Suyog Rao"},"date":"October 29, 2015","category":"Releases","locales":"","content":" After Wednesday\u2019s , we still aren\u2019t done \u2013 one more today! We are happy to announce the of Logstash version 1.5.5 today. This is mainly a bug fix release and the last release planned for the 1.5 series. Enhancements Filebeat Support In case you missed it, we a beta version of \u2013 the next-generation Logstash Forwarder. Filebeat is an agent to ship file-based logs to Logstash for further processing. Logstash version 1.5.5 works out of the box with Filebeat version 1.0.0-beta4 using the plugin. Performance improvements Other fixes Feedback Please Logstash 1.5.5 and let us know what you think on Twitter (@elastic) or on our . You can report any problems on the GitHub issues page. \n"}<br>{"index": {"_id": 858}}<br>{"title":"Verifying Logstash Functionality Through Testing","seo_title":"","url":"\/blog\/logstash-functionality-through-testing","author":{"name":"Pere Urbon-Bayes"},"date":"October 29, 2015","category":"Engineering","locales":"","content":" At Logstash, testing is\u00a0fundamental to our engineering process. In this blog, we want to share this process with our amazing community. We\u2019ll share how we do testing, including process and tools we use, and for Logstash\u00a0plugin developers out there,\u00a0we'll briefly describe how to write tests. \n"}<br>{"index": {"_id": 859}}<br>{"title":"F5 High Speed Logging with Elastic Stack","seo_title":"","url":"\/blog\/f5-high-speed-logging-with-elastic-stack","author":{"name":"Jay Greenberg"},"date":"October 29, 2015","category":"","locales":"","content":" A load balancer often serves as a gateway into your production network. In this position, it has a unique perspective of seeing all traffic, while also being aware of the mapping between web services and servers. A great deal of high level information can be learned from the load balancer with minimal effort, and it is independent of web server, application, and platform. This flow of information is highly consistent, and serves well for baselines. Naturally, we can log from this point (as an alternative to processing web server logs) to gain visibility in web traffic patterns and application behavior. In this blog, we will take a look at how to pair the Elastic Stack\u00a0with an F5 , which is great at quickly balancing load across massive amounts of traffic. This is not unlike Elasticsearch & Kibana that gives us \u2018wire speed\u2019 access to our data for analysis, allowing us to answer important questions in near real time. : : : \u00a0 From there you can drill down on these answers by time period, or other HTTP metric , and even compare them side-by-side with other services. This information is of course useful - and the F5 and Elastic architectures mix particularly well making it quick and easy to get to these answers. The F5 distributes logging traffic across a pool of Logstash Servers, conveniently including information about the Virtual Service. HSL Pools for LogstashF5\u2019s High Speed Logging (HSL) mechanism is designed to pump out as much data as can be readily consumed, with the least amount of overhead, to a pool of syslog listeners. As it happens, Elastic Stack is designed to consume data in high volume. The HSL template packs the information into a parsable string, perfect for Logstash to interpret. Consult F5\u2019s documentation on Request Logging for the official (and more detailed) procedure, but in brief, one must follow these steps:\u00a0 GROK & The HSL TemplateOut of the box, we have accomplished a difficult task easily - we have our logs flowing into Logstash. Next, we need to tell logstash how to parse the messages before indexing them into Elasticsearch. Just like the Logstash cluster is analogous to the HSL Pool, the GROK pattern is analogous to the HSL Request Logging Template. The two can be thought of as a CODEC, converting HTTP request details to a parsable string, that can be subsequently parsed into JSON for output into Elasticsearch. Here is an example of a request logging template which will give us information about the load balancer\u2019s Virtual Server, Pool Name, Server IP, Response Time, in addition to other common attributes. $CLIENT_IP $DATE_NCSA $VIRTUAL_IP $VIRTUAL_NAME $VIRTUAL_POOL_NAME $SERVER_IP $SERVER_PORT \"$HTTP_PATH\" \"$HTTP_REQUEST\" $HTTP_STATCODE $RESPONSE_SIZE $RESPONSE_MSECS \"$Referer\" \"${User-agent}\" Now on the other side, in our Logstash cluster, we decode and process the log entry generated by the F5. Logstash has 3 primary phases: Input, Filter, and Output, known as the Logstash has a built-in syslog input. But because you are decoding the data manually, you should just use raw TCP and\/or UDP input plugins. The core of the filter phase is GROK - an unbiased parsing language - perfect for decomposing the log entry exactly as it was put together. Here is the GROK pattern used to decode the above template. \"%{IP:clientip} \\[%{HTTPDATE:timestamp}\\] %{IP:virtual_ip} %{DATA:virtual_name} %{DATA:virtual_pool_name} %{DATA:server} %{NUMBER:server_port} \\\"%{DATA:path}\\\" \\\"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP\/%{NUMBER:httpversion})?|%{DATA:rawrequest})\\\" %{NUMBER:response:int} %{NUMBER:bytes:int} %{NUMBER:response_ms:int} %{QS:referrer} %{QS:agent}\" After parsing, the filter phase can continue in any way you would like to enrich your data, such as IP address GeoLocation. DNS resolution, or even drop to Ruby for custom manipulation. Finally, the newly created event object is indexed into Elasticsearch via the Logstash Elasticsearch output plugin. Setting up Health ChecksYou will want the F5 to periodically check the health of your Logstash instances, to insure that they are alive and ready to accept logs. When setting up a health check, use caution with UDP. F5\u2019s UDP health check sends an arbitrary string (of your choice), and fails if it receives back an ICMP unreachable response. The caveat is that Logstash will try to process the arbitrary string, so be sure to filter it out! Logstash also ships with a that periodically says \u2018I\u2019m OK\u2019. This information can be output to Elasticsearch and checked by the load balancer. To set this up, you can use the following configuration example: First create your heartbeat index in Elasticsearch, and put this mapping: PUT \/heartbeats\/ PUT \/heartbeats\/_mapping\/heartbeat { \"properties\": { \"host\": { \"type\":\"string\", \"index\":\"not_analyzed\" } } } Then configure logstash to send a heartbeat every 5 seconds: input { heartbeat { interval => 5 type => \"heartbeat\" } } output { if [type] == \"heartbeat\" { elasticsearch { protocol => \"transport\" index => \"heartbeats\" document_id => \"%{host}\" } } } Finally, configure the load balancer to check Elasticsearch for a heartbeat within the last 15 seconds: GET http:\/\/es1:9200\/heartbeats\/heartbeat\/_search?q=host:logstash1 AND @timestamp:>now-15s You can test with curl: curl -s http:\/\/es1:9200\/heartbeats\/heartbeat\/_search?q=host:'logstash1'%20AND%20@timestamp:%3Enow-15s UDP vs TCP for HSLUDP or TCP can be used with HSL, and there are pros and cons to each. One important thing to note is that existing TCP connections are reused for long periods of time, in order to reduce what would be unrealistic overhead. While helpful, it does cause imperfect load balancing between logstash instances. Consider using a Least Connection Algorithm over Round Robin with TCP Based HSL. Alternatives for measuring HTTP Response TimeIf you don\u2019t have an F5, or if you are more comfortable working within the bounds of your automation infrastructure, glean the information from web servers via Logstash or Beats. Apache\u2019s Default Format, with corresponding GROK: LogFormat \"%h %l %u %t \\\"%r\\\" %>s %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" \"%{COMBINEDAPACHELOG}\" Modified for Response Time: LogFormat \"%h %l %u %t \\\"%r\\\" %>s %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\" %D\" \"%{COMBINEDAPACHELOG} %{NUMBER:response_microseconds}\" See Also \n"}<br>{"index": {"_id": 860}}<br>{"title":"Release, we have","seo_title":"","url":"\/blog\/release-we-have","author":{"name":"Shay Banon"},"date":"October 28, 2015","category":"News","locales":"de-de,fr-fr,ja-jp,ko-kr","content":" It is a big day here at Elastic, internally referred to as our \"release bonanza\" day. Most of our major products have fresh releases, and today they are aligned to make sure users will have the best experience when using them together. We have: \u00a0A lot of work has gone in Shield, our security product for Elasticsearch, and Watcher, our alerting and management product. Security wise we have implemented one of our most requested features, field and document level security, in a way that \u201cgoes all the way down\u201d to Lucene. We have also allowed for users to implement their own pluggable security handling. Watcher now allows to disable watches, and send notifications to Slack and HipChat (we do love our bot ops).\u00a0Official support for Elasticsearch 2.0, clean shutdown semantics, performance improvements across the board, and support. Phew, I am out of breath. What the team has done is impressive, humbling, and exciting! This is a great example of how working together, as a company at Elastic, and all of our users and contributors, results in our main mission: shipping products our users love, enjoy, succeed, and innovate on. Thank\u00a0you.\u201cA Lion, in Africa?\u201d - We are not done, I will end with this teaser, coming (really really) soon : ) \n"}<br>{"index": {"_id": 861}}<br>{"title":"Shield, Watcher, and Marvel 2.0.0 GA Released","seo_title":"","url":"\/blog\/shield-watcher-and-marvel-2-0-ga-released","author":{"name":"Uri Boness"},"date":"October 28, 2015","category":"Releases","locales":"de-de,fr-fr,ja-jp,ko-kr","content":" Today we're thrilled to announce the release of Shield, Watcher and Marvel 2.0. This is the first release of these extensions that is compatible with . Beyond Elasticsearch 2.0 compatibility, Shield and Watcher 2.0 introduce new and exciting features, expanding the security and alerting capabilities respectively. Shield Watcher MarvelWe\u2019re super excited to introduce Marvel 2.0. With a complete UI redesign, built on top of Kibana 4, we have taken all that we\u2019ve learned from Marvel 1.x and built an easier to use, streamlined monitoring UI. In the same spirit of Shield and Watcher, this first Marvel release lays the foundation for future growth and focuses on the key metrics required to efficiently monitor Elasticsearch 2.0. As part of the redesign, we reduced the interface to 6 pages: Cluster List An increasing number of our users and customers are running multiple clusters, and Marvel now makes it easy to monitor them all from a centralized monitoring cluster. Just configure each cluster to send data to the monitoring cluster, and Marvel does the rest. Cluster Overview The cluster overview shows the key performance metrics for a single cluster, allowing you to quickly identify spikes or valleys. The page also shows any active shard recoveries or relocations. Indices List The indices list shows all indexes in the cluster, along with a host of properties. The table updates live and supports interactive filtering and sorting. Ever wonder what your biggest index is? Wonder no more. Index Detail The index detail page shows the key performance metrics of your index, as well as providing a clear picture of where the shards are allocated. Nodes List The nodes list shows the set of nodes in the cluster, along with key performance metrics. The table updates live and supports interactive filtering. Easily identify nodes with high CPU usage or low disk space. Node Detail The node detail page captures the key performance metrics of an individual node, as well as the set of shards on the node. As part of being built on top of Kibana 4, there are some operational changes as well. Marvel now installs in two parts - the marvel-agent, and the Marvel user interface. Marvel AgentThe marvel-agent installs as a plugin into your elasticsearch cluster. It captures the key performance information and stores it locally or pushes it to a separate monitoring cluster. Marvel User InterfaceThe Marvel UI installs into Kibana as a plugin. This uses the new Plugin infrastructure in Kibana 4.2 to provide a separate Marvel App inside the Kibana interface, which is reachable with a new app-switcher control: The 2.0 release is a big one for our products, and we\u2019re eager to hear what you think. Reach out to us in the forums: or by email at . \n"}<br>{"index": {"_id": 862}}<br>{"title":"The Story of Sense - Announcing Sense 2.0.0-beta1","seo_title":"The Story of Sense - Announcing Sense 2.0.0-beta1","url":"\/blog\/sense-2-0-0-beta1","author":{"name":"Boaz Leskes"},"date":"October 28, 2015","category":"Engineering","locales":"de-de,fr-fr,ja-jp,ko-kr","content":" \n"}<br>{"index": {"_id": 863}}<br>{"title":"Elasticsearch 2.0.0 GA released","seo_title":"Elasticsearch 2.0.0 GA released","url":"\/blog\/elasticsearch-2-0-0-released","author":{"name":"Clinton Gormley"},"date":"October 28, 2015","category":"Engineering","locales":"de-de,fr-fr,ja-jp,ko-kr","content":" With 2,799 pull requests by 477 committers added since the release of Elasticsearch 1.0.0, we are proud to announce the release of , based on . As if that were not enough, we are also releasing version 2.0.0 of the , an all new streamlined which is now free to use in production, and a new open source . You can and read about the important here. The full changes list can be found here: Change logs for the commercial plugins can be found here: \n"}<br>{"index": {"_id": 864}}<br>{"title":"Kibana 4.2.0 released","seo_title":"","url":"\/blog\/kibana-4-2-0","author":{"name":"Rashid Khan"},"date":"October 28, 2015","category":"Engineering","locales":"de-de,fr-fr,ja-jp,ko-kr","content":" Elasticsearch 2.0 + Kibana 4.2 = \ud83d\udc9a We're happy to announce the very first release of Kibana with support for Elasticsearch 2.0. What does that mean for you? Speed. Stability. Sweet new features. If you're itching to get moving, , now. Otherwise, read on for the fun stuff you can expect in Kibana 4.2 Afraid of the dark?Never! While we always recommend using a light background while composing charts and dashboards, sometimes you want them on a big screen, in a dark room, and nobody wants a bright white screen staring them down. To mitigate that effect, we've introduced a dark mode. Now you can comfortably enjoy Kibana dashboards in the NOC, the observatory, my soul, or really anywhere dark. Custom map providersKibana's included map provider is a great, but we heard you wanted more options. If you fancy yourself a deft map handler, try out Kibana 4.2\u2019s support for WMS background maps. WMS is super powerful and there's a wealth of free services providing them, including the US Geological Survey: What's the scenario?If something is wrong, we want you to know right away, so we've created a server status page that will give you an overview of how Kibana is operating at that very moment, and if there are\u00a0any components that need your attention. Of course, if you just need the comfort of knowing everything is a-okay, it's always available right away from the Status tab under settings. Faster in every wayBrowser refreshes happen faster than ever thanks to the new code bundling system in Kibana 4.2 that optimizes the code it serves to just what you need at that moment. Also, remember memory? Kibana remembers. Kibana 4.2 includes a big memory cleanup allowing long long long running dashboards while maintaining a small small small memory footprint. And oh so much more...There are tiny tweaks around every corner and we\u2019ve laid the groundwork for some really exciting stuff in the coming weeks, so stay tuned to , our , and the and don\u2019t miss a moment of the action. \n"}<br>{"index": {"_id": 865}}<br>{"title":"Logstash 2.0.0 released","seo_title":"","url":"\/blog\/logstash-2-0-0-released","author":{"name":"Suyog Rao"},"date":"October 28, 2015","category":"Releases","locales":"de-de,fr-fr,ja-jp,ko-kr","content":" We are happy to announce that Logstash 2.0.0 has been released today! This introduces breaking changes in functionality for some configurations, so please read our for details, or the new documentation. You can read our previous posts for changes in other 2.0.0 pre-releases: Here\u2019s a recap of headlining changes in 2.0: Compatibility with Elasticsearch 2.0 Elasticsearch 2.0 is generally as of today which contains many new features and enhancements. Logstash 2.0 is compatible out of the box with this release. Previous releases of Logstash defaulted to using the Java client to communicate with Elasticsearch: 2.0 defaults to the HTTP client. This provides a seamless experience for users to get their data, enrich it, and store and analyze with Elasticsearch. HTTP has functional parity with the other protocols (node and transport), is only marginally slower when connected to a single client, yet far easier to administer and work with. When using the HTTP protocol, one may upgrade Elasticsearch versions without having to upgrade Logstash in lock-step. For more detailed information (including performance numbers) on the switch to HTTP as default, please check the . We\u2019ll continue to support the other (, ) protocols, but the plugin to use them requires manual installation: Compatibility Matrix The below table lists Logstash\u2019s compatibility with Elasticsearch versions. Compatibility with Shield 2.0 This release is compatible with Elastic Shield 2.0 release. For HTTP protocol, no additional plugins are required. Please follow the documentation described . For the protocol, a separate plugin has to be installed for integrating with Shield 2.0 and above: Performance improvements This release also includes performance improvements in many areas so you can process your data faster with Logstash. Below are a few mentions: Filebeat Support In case you missed it, we a beta version of \u2013 the next-generation Logstash Forwarder. Filebeat is an agent to ship file-based logs to Logstash for further processing. 2.0.0 works out of the box with Filebeat version 1.0.0-beta4 using the plugin. Shutdown Handling In previous Logstash releases, when a shutdown was initiated, an Exception mechanism was used to signal the plugins to start shutting down. This process was problematic because plugins frequently use third-party code. When Logstash did not know how to handle the exceptions, unpredictable behavior often resulted. We fixed this by adding API calls (for example, ) for each plugin to communicate a shutdown event and let the plugin gracefully stop itself. This meant updating over 200+ plugins in the Logstash ecosystem to adhere to the new APIs! Although shutting down Logstash is not completely fixed yet \u2013 stalled outputs can still delay the shutdown \u2013 we have all the breaking API changes in 2.0 and can start iterating on fixes in point releases. Plugin developers: If you have developed plugins for Logstash 1.5, please consult the breaking changes document for a list of new APIs related to shutdown. Also, the repo provides sample code for using this new shutdown mechanism. Documentation The updated documentation for 2.0 and all plugins are available . Please consult this reference for any configuration changes. Updating to 2.0 Before updating to 2.0, please consult the in our reference docs. Feedback Many thanks to our users and contributors for making 2.0 a successful release. We appreciate all the testing of pre-releases and numerous patches contributed to this release. Please follow our to stay tuned on future enhancements, releases, etc. So, go on, give 2.0 a and let us what you think! \n"}<br>{"index": {"_id": 866}}<br>{"title":"Brewing in Beats: First Filebeat release","seo_title":"","url":"\/blog\/weekly-beats-first-filebeat-release","author":{"name":"Tudor Golubenco"},"date":"October 26, 2015","category":"Brewing in Beats","locales":"","content":" Beats 1.0.0-beta4 release brings you Filebeat: the lightweight log shipper successor to Logstash-Forwarder: \u2014 elastic (@elastic) ICYMI, we on Thursday.\u00a0 The clear highlight of the release is the first version of FIlebeat, the lightweight log shipper successor of the Logstash Forwarder. Thank you everyone that helped testing the internal candidate, we caught at least one pretty bad issue and we got a ton of input on how we can improve the docs. Most of the work this week went into preparing and testing the\u00a0release. Other noteworthy things: Filebeat can on a per-glob basis to expect a particular encoding. This wasn\u2019t a problem for the Logstash Forwarder because its serialization protocol was encoding agnostic and the user could configure a codec in Logstash. It was a problem for Filebeat because (1) it uses JSON for communicating with Logstash and (2) it can send the data directly to Elasticsearch. With Windows using UCS-2 by default, it was important for us to have a solution for the beta4. Even if this means an extra configuration parameter for Filebeat, we expect that configuring the encoding close to where the files are is better for users, so it is likely a plus overall. With the beta4 release, which makes it possible for all Beats to send data to Logstash without any intermediaries, we the Redis output. See this , where the rationale behind this decision is further explained. The Lumberjack code -- used by both the new Beats input plugin and the Lumberjack input plugins in Logstash -- used to live in its own library, even though fairly different code paths were taken depending on the plugin in use. This caused some dependency conflicts at install time. To fix this, and also to gives the beats-input plugin more freedom in changes to the protocol, the protocol code in the plugin repo.\u00a0 Thanks to this change, installing the beats input is now as easy as `.\/bin\/plugin install logstash-input-beats`.\u00a0 With the next Logstash release, this step won\u2019t be required at all as the plugin will be bundled in the default distribution. We continued our push for improving the docs, with everyone in the team contributing. We now have a professional editor\u00a0helping with this, so we expect the docs quality to be rapidly improved. Related to the documentation effort, we have updated the sample configuration files to contain a lot more comments describing the available options. We found and fixed where the index names that we create (e.g. [packebeat-]YYYY.MM.DD) was not using the UTC timezone. We now have for the Filebeat -> Logstash communication also for the TLS enabled case, including server certificate validation. Yay for one less thing to manually check and worry about. The listing on the S3 bucket serving the is now easier to browse thanks to a new JS listing snippet. More importantly, the last built artifacts as their version and show up first on each page, so it is now easier to download the most recent build. We have an ongoing effort to execute the packaging tests daily on a bare metal machine (has to be bare metal because it makes use of Virtualbox machines), so having predictable download URLs was needed. \n"}<br>{"index": {"_id": 867}}<br>{"title":"This Week in Elasticsearch and Apache Lucene - October 26th 2015","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-10-26","author":{"name":"Michael McCandless"},"date":"October 26, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top News 2.0 is coming...join this Wed for a demo, feature Qs, and more! \u2014 elastic (@elastic) Elasticsearch CoreChanges in 2.0: Apache Lucene Watch This Space, where we'll share more news on the whole Elastic\u00a0ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 868}}<br>{"title":"Make an Elasticsearch-powered REST API for any data with Ramses","seo_title":"","url":"\/blog\/make-an-elasticsearch-powered-rest-api-for-any-data-with-ramses","author":{"name":"Chris Hart"},"date":"October 22, 2015","category":"","locales":"","content":" In this short guide, I'm going to show you how to download a dataset and create a REST API. This new API uses Elasticsearch to power the endpoints, so you can build a product around your data without having to directly expose Elasticsearch in production. This allows for proper authentication, authorization, custom logic, other databases, and even auto-generated client libraries. is a bit like for open source. It provides the convenience of a \"backend as a service\", except that you run the server yourself and have full access to the internals. I recently came across the Gender Inequality Index, an interesting dataset published by the UN Development Programme. This dataset is a twist on the classic Human Development Index. The HDI ranks countries based on their levels of lifespan, education and income. The GII, on the other hand, ranks countries based on how they stack up in terms of gender (in)equality. The metrics in the GII are a combination of women's reproductive health, social empowerment, and labour force participation. Unfortunately, this dataset is missing non-binary gender identities, so our exploration will be a bit limited until that information is added. You can from the United Nations Development Programme. This dataset enables us to dig into some really interesting questions. Let's make a REST API out of the GII and then query it in fun ways using the Elasticsearch query DSL via the endpoint URL. You can jump ahead to see . Set up the projectBefore we dive in, make sure these pieces are in place: $ mkdir gii_project && cd gii_project $ virtualenv venv $ source venv\/bin\/activate (venv)$ pip install ramses==0.5.0 (venv)$ pcreate -s ramses_starter gii_api When prompted by , choose PostgreSQL (option 1) as your database and open the new project in a text editor to look around. Then, start the server to make sure it works. It should look something like this: (venv)$ cd gii_api (venv)$ pserve local.ini ... Starting server in PID 40098. serving on http:\/\/0.0.0.0:6543 Model and post the dataThere are two main files in the boilerplate project right now: , and . is a file, which is a DSL for describing REST APIs in YAML. It configures your endpoints. is the schema that describes the fake boilerplate \"Item\" model. We are going to replace these files with real ones based on the GII data. First, download the data to the root of the project (), and rename the old to . $ wget https:\/\/raw.githubusercontent.com\/chrstphrhrt\/ramses-elasticsearch\/master\/gii_api\/gii_data.json ... 2015-08-31 15:58:34 (198 KB\/s) - 'gii_data.json' saved [75659] $ mv items.json gii_schema.json : you can also get the data directly from the . I cleaned it up a little for this guide. Now edit the file to describe the fields we see in the raw data. Look in for the field names and types. Here's the first record for example: { \"labour_force_participation_rate_aged_15_and_above_male_2012\" : \"69.5\", \"hdi_rank\" : \"1\", \"gender_inequality_index_value_2013\" : \"0.068\", \"gender_inequality_index_rank_2013\" : \"9\", \"population_with_some_secondary_ed_aged_25_and_up_fem_2005_2012\" : \"97.4\", \"country\" : \"Norway\", \"_2010_2015_adolescent_birth_rate_births_per_1_000_women_aged_15_19\" : \"7.8\", \"labour_force_participation_rate_aged_15_and_above_female_2012\" : \"61.5\", \"_2013_share_of_seats_in_parliament_held_by_women\" : \"39.6\", \"population_with_some_secondary_ed_aged_25_and_up_male_2005_2012\" : \"96.7\", \"_2010_maternal_mortality_ratio_deaths_per_100_000_live_births\" : \"7\" } Now look in : { \"type\": \"object\", \"title\": \"Item schema\", \"$schema\": \"http:\/\/json-schema.org\/draft-04\/schema\", \"required\": [\"id\", \"name\"], \"properties\": { \"id\": { \"type\": [\"integer\", \"null\"], \"_db_settings\": { \"type\": \"id_field\", \"required\": true, \"primary_key\": true } }, \"name\": { \"type\": \"string\", \"_db_settings\": { \"type\": \"string\", \"required\": true } }, \"description\": { \"type\": [\"string\", \"null\"], \"_db_settings\": { \"type\": \"text\" } } } } We want to replace the \"properties\" section with the field names and types from our dataset. Update the and fields, and make the field the primary key, like so: { \"type\": \"object\", \"title\": \"GII Country schema\", \"$schema\": \"http:\/\/json-schema.org\/draft-04\/schema\", \"required\": [\"country\"], \"properties\": { \"labour_force_participation_rate_aged_15_and_above_male_2012\": { \"_db_settings\": { \"type\": \"float\" } }, \"hdi_rank\": { \"_db_settings\": { \"type\": \"integer\" } }, \"gender_inequality_index_value_2013\": { \"_db_settings\": { \"type\": \"float\" } }, \"gender_inequality_index_rank_2013\": { \"_db_settings\": { \"type\": \"float\" } }, \"population_with_some_secondary_ed_aged_25_and_up_fem_2005_2012\": { \"_db_settings\": { \"type\": \"float\" } }, \"country\": { \"_db_settings\": { \"type\": \"string\", \"primary_key\": true } }, \"_2010_2015_adolescent_birth_rate_births_per_1_000_women_aged_15_19\": { \"_db_settings\": { \"type\": \"float\" } }, \"labour_force_participation_rate_aged_15_and_above_female_2012\": { \"_db_settings\": { \"type\": \"float\" } }, \"_2013_share_of_seats_in_parliament_held_by_women\": { \"_db_settings\": { \"type\": \"float\" } }, \"population_with_some_secondary_ed_aged_25_and_up_male_2005_2012\": { \"_db_settings\": { \"type\": \"float\" } }, \"_2010_maternal_mortality_ratio_deaths_per_100_000_live_births\": { \"_db_settings\": { \"type\": \"integer\" } } } } the is Ramses-specific and is used to tell the DB engine(s) how to configure themselves. There are a lot of fields that can be set in addition to the types. For a , have a look at the docs. Now that we have data and a schema to describe it, let's hook up the endpoints. Open and change the boilerplate Item endpoint to use the GII countries schema instead. Before: #%RAML 0.8 --- title: gii_api API documentation: - title: gii_api REST API content: | Welcome to the gii_api API. baseUri: http:\/\/{host}:{port}\/{version} version: v1 mediaType: application\/json protocols: [HTTP] \/items: displayName: Collection of items get: description: Get all item post: description: Create a new item body: application\/json: schema: !include items.json \/{id}: displayName: Collection-item get: description: Get a particular item delete: description: Delete a particular item patch: description: Update a particular item And after: #%RAML 0.8 --- title: gii_api API documentation: - title: gii_api REST API content: | Welcome to the gii_api API. baseUri: http:\/\/{host}:{port}\/{version} version: v1 mediaType: application\/json protocols: [HTTP] \/gii_countries: displayName: Collection of GII countries get: description: Get all countries post: description: Create a new country body: application\/json: schema: !include gii_schema.json \/{country}: displayName: A GII country get: description: Get a particular country delete: description: Delete a particular country patch: description: Update a particular country It's that simple! Now we can drop the database, delete the Elasticsearch index, and restart the server. (venv)$ dropdb gii_api (venv)$ http DELETE :9200\/gii_api HTTP\/1.1 200 OK Content-Length: 21 Content-Type: application\/json: charset=UTF-8 { \"acknowledged\": true } (venv)$ pserve local.ini ... Starting server in PID 45998. serving on http:\/\/0.0.0.0:6543 It's time to post all the data to the API so that we can start making queries. With the server already running, open a new terminal. I like to use our built-in script for this. Activate the virtual environment, and call the script like so: $ cd gii_project\/ $ source venv\/bin\/activate (venv)$ nefertari.post2api -f gii_api\/gii_data.json -u http:\/\/localhost:6543\/api\/gii_countries Posting: {\"_2010_maternal_mortality_ratio_deaths_per_100_000_live_births\": \"7\", \"gender_inequality_index_rank_2013\": \"9\", \"gender_inequality_index_value_2013\": \"0.068\", \"country\": \"Norway\", \"population_with_some_secondary_ed_aged_25_and_up_fem_2005_2012\": \"97.4\", \"_2013_share_of_seats_in_parliament_held_by_women\": \"39.6\", \"_2010_2015_adolescent_birth_rate_births_per_1_000_women_aged_15_19\": \"7.8\", \"labour_force_participation_rate_aged_15_and_above_female_2012\": \"61.5\", \"labour_force_participation_rate_aged_15_and_above_male_2012\": \"69.5\", \"hdi_rank\": \"1\", \"population_with_some_secondary_ed_aged_25_and_up_male_2005_2012\": \"96.7\"} 201 ... Querying the dataIf you want to get a complete picture of what you can do, go directly to . This covers all of the following techniques (and more). Now we can start poking around in the data to see what kinds of interesting facts we are able to extract with Ramses. Here's the most basic request, to show data for a specific country: $ http :6543\/api\/gii_countries\/Norway HTTP\/1.1 200 OK Cache-Control: max-age=0, must-revalidate, no-cache, no-store Content-Length: 723 Content-Type: application\/json: charset=UTF-8 Date: Tue, 01 Sep 2015 17:49:42 GMT Expires: Tue, 01 Sep 2015 17:49:42 GMT Last-Modified: Tue, 01 Sep 2015 17:49:42 GMT Pragma: no-cache Server: waitress { \"_2010_2015_adolescent_birth_rate_births_per_1_000_women_aged_15_19\": 7.8, \"_2010_maternal_mortality_ratio_deaths_per_100_000_live_births\": 7, \"_2013_share_of_seats_in_parliament_held_by_women\": 39.6, \"_pk\": \"Norway\", \"_self\": \"http:\/\/localhost:6543\/api\/gii_countries\/Norway\", \"_type\": \"GiiCountry\", \"_version\": 0, \"country\": \"Norway\", \"gender_inequality_index_rank_2013\": 9.0, \"gender_inequality_index_value_2013\": 0.068, \"hdi_rank\": 1, \"labour_force_participation_rate_aged_15_and_above_female_2012\": 61.5, \"labour_force_participation_rate_aged_15_and_above_male_2012\": 69.5, \"population_with_some_secondary_ed_aged_25_and_up_fem_2005_2012\": 97.4, \"population_with_some_secondary_ed_aged_25_and_up_male_2005_2012\": 96.7 } Limit and sortIf you make a GET request to the collection, you'll get the default limit of 20 records. How about something more interesting, like the top 50 countries sorted by their HDI ranking? $ http :6543\/api\/gii_countries _limit==50 _sort==hdi_rank If you want to reverse the sort order you can put a minus sign before the field name to be sorted by, e.g. . More paginationTo customize where in the records the pagination begins or which page of the sequence to return, we use the and parameters. Imaginary leaderboard app For example, let's say we have a leaderboard app that classifies the top 5 countries as \"gold medallists\", the next 5 as \"silver\" and the 5 after that as \"bronze\". Maybe we only care about particular metrics, and want to filter out the noise from the other fields. Here are some examples of how to do that. \"Gold medal\" countries for women's participation in the labour market:$ http :6543\/api\/gii_countries _limit==5 _sort==-labour_force_participation_rate_aged_15_and_above_female_2012 _fields==country,labour_force_participation_rate_aged_15_and_above_female_2012 HTTP\/1.1 200 OK Cache-Control: max-age=0, must-revalidate, no-cache, no-store Content-Length: 755 Content-Type: application\/json: charset=UTF-8 Date: Tue, 01 Sep 2015 18:38:57 GMT Expires: Tue, 01 Sep 2015 18:38:57 GMT Last-Modified: Tue, 01 Sep 2015 18:38:57 GMT Pragma: no-cache Server: waitress { \"count\": 5, \"data\": [ { \"_type\": \"GiiCountry\", \"country\": \"Tanzania (United Republic of)\", \"labour_force_participation_rate_aged_15_and_above_female_2012\": 88.1 }, { \"_type\": \"GiiCountry\", \"country\": \"Madagascar\", \"labour_force_participation_rate_aged_15_and_above_female_2012\": 86.8 }, { \"_type\": \"GiiCountry\", \"country\": \"Rwanda\", \"labour_force_participation_rate_aged_15_and_above_female_2012\": 86.5 }, { \"_type\": \"GiiCountry\", \"country\": \"Myanmar\", \"labour_force_participation_rate_aged_15_and_above_female_2012\": 85.7 }, { \"_type\": \"GiiCountry\", \"country\": \"Malawi\", \"labour_force_participation_rate_aged_15_and_above_female_2012\": 84.7 } ], \"fields\": \"country,labour_force_participation_rate_aged_15_and_above_female_2012\", \"start\": 0, \"took\": 4, \"total\": 206 } Way to go, Tanzania! (It would be interesting to learn more about the nature and quality of these jobs as well, but that is beyond our scope here.) \"Silver medallists\" in women's labour market participation:Let's add the argument to get the 6th-10th records, inclusive. $ http :6543\/api\/gii_countries _limit==5 _start==5 _sort==-labour_force_participation_rate_aged_15_and_above_female_2012 _fields==country,labour_force_participation_rate_aged_15_and_above_female_2012 HTTP\/1.1 200 OK Cache-Control: max-age=0, must-revalidate, no-cache, no-store Content-Length: 744 Content-Type: application\/json: charset=UTF-8 Date: Wed, 02 Sep 2015 19:59:44 GMT Expires: Wed, 02 Sep 2015 19:59:44 GMT Last-Modified: Wed, 02 Sep 2015 19:59:44 GMT Pragma: no-cache Server: waitress { \"count\": 5, \"data\": [ { \"_type\": \"GiiCountry\", \"country\": \"Burundi\", \"labour_force_participation_rate_aged_15_and_above_female_2012\": 83.2 }, { \"_type\": \"GiiCountry\", \"country\": \"Zimbabwe\", \"labour_force_participation_rate_aged_15_and_above_female_2012\": 83.2 }, { \"_type\": \"GiiCountry\", \"country\": \"Togo\", \"labour_force_participation_rate_aged_15_and_above_female_2012\": 80.7 }, { \"_type\": \"GiiCountry\", \"country\": \"Equatorial Guinea\", \"labour_force_participation_rate_aged_15_and_above_female_2012\": 80.6 }, { \"_type\": \"GiiCountry\", \"country\": \"Netherlands\", \"labour_force_participation_rate_aged_15_and_above_female_2012\": 79.9 } ], \"fields\": \"country,labour_force_participation_rate_aged_15_and_above_female_2012\", \"start\": 5, \"took\": 7, \"total\": 206 } : Because the index starts at zero, we use , to start at the 6th record.* Give it up for Burundi and Zimbabwe! \"Bronze medallists\":We can use the parameter here like we did for the silver medallists, but let's try using to get the bronze countries instead. This should give us the 11th-15th records, inclusive. The parameter, like , is also zero-indexed. $ http :6543\/api\/gii_countries _limit==5 _page==2 _sort==-labour_force_participation_rate_aged_15_and_above_female_2012 _fields==country,labour_force_participation_rate_aged_15_and_above_female_2012 HTTP\/1.1 200 OK Cache-Control: max-age=0, must-revalidate, no-cache, no-store Content-Length: 765 Content-Type: application\/json: charset=UTF-8 Date: Wed, 02 Sep 2015 20:37:11 GMT Expires: Wed, 02 Sep 2015 20:37:11 GMT Last-Modified: Wed, 02 Sep 2015 20:37:11 GMT Pragma: no-cache Server: waitress { \"count\": 5, \"data\": [ { \"_type\": \"GiiCountry\", \"country\": \"Eritrea\", \"labour_force_participation_rate_aged_15_and_above_female_2012\": 79.9 }, { \"_type\": \"GiiCountry\", \"country\": \"Cambodia\", \"labour_force_participation_rate_aged_15_and_above_female_2012\": 78.9 }, { \"_type\": \"GiiCountry\", \"country\": \"Ethiopia\", \"labour_force_participation_rate_aged_15_and_above_female_2012\": 78.2 }, { \"_type\": \"GiiCountry\", \"country\": \"Burkina Faso\", \"labour_force_participation_rate_aged_15_and_above_female_2012\": 77.1 }, { \"_type\": \"GiiCountry\", \"country\": \"Lao People's Democratic Republic\", \"labour_force_participation_rate_aged_15_and_above_female_2012\": 76.3 } ], \"fields\": \"country,labour_force_participation_rate_aged_15_and_above_female_2012\", \"start\": 10, \"took\": 3, \"total\": 206 } Nice showing, Eritrea! Elasticsearch DSL powersThis is where the real magic happens. Full-text searchWe already know that we can access individual country records by endpoints using the country's name e.g. , but I noticed that certain countries have more official\/legal names according to the UN, and might not be listed under their more common names. For example, I'm pretty sure Venezuela is a country, but if I try to request its endpoint: $ http :6543\/api\/gii_countries\/Venezuela HTTP\/1.1 404 Not Found Cache-Control: max-age=0, must-revalidate, no-cache, no-store Content-Length: 312 Content-Type: application\/json: charset=UTF-8 Date: Tue, 01 Sep 2015 19:08:17 GMT Expires: Tue, 01 Sep 2015 19:08:17 GMT Last-Modified: Tue, 01 Sep 2015 19:08:17 GMT Pragma: no-cache Server: waitress { \"explanation\": \"The resource could not be found.\", \"message\": \"'GiiCountry({'doc_type': 'GiiCountry', 'id': u'Venezuela', 'index': 'gii_api'})' resource not found\", \"request_url\": \"http:\/\/localhost:6543\/api\/gii_countries\/Venezuela\", \"status_code\": 404, \"timestamp\": \"2015-09-01T19:08:17Z\", \"title\": \"Not Found\" } No dice. Enter full-text search! $ http :6543\/api\/gii_countries country==Venezuela HTTP\/1.1 200 OK Cache-Control: max-age=0, must-revalidate, no-cache, no-store Content-Length: 914 Content-Type: application\/json: charset=UTF-8 Date: Tue, 01 Sep 2015 19:28:41 GMT Etag: \"b31365bc077839872f474e6bd8fe559c\" Expires: Tue, 01 Sep 2015 19:28:41 GMT Last-Modified: Tue, 01 Sep 2015 19:28:41 GMT Pragma: no-cache Server: waitress { \"count\": 1, \"data\": [ { \"_2010_2015_adolescent_birth_rate_births_per_1_000_women_aged_15_19\": 83.2, \"_2010_maternal_mortality_ratio_deaths_per_100_000_live_births\": 92, \"_2013_share_of_seats_in_parliament_held_by_women\": 17.0, \"_pk\": \"Venezuela (Bolivarian Republic of)\", \"_score\": 2.109438, \"_self\": \"http:\/\/localhost:6543\/api\/gii_countries\/Venezuela%20%28Bolivarian%20Republic%20of%29\", \"_type\": \"GiiCountry\", \"_version\": 0, \"country\": \"Venezuela (Bolivarian Republic of)\", \"gender_inequality_index_rank_2013\": 96.0, \"gender_inequality_index_value_2013\": 0.464, \"hdi_rank\": 67, \"labour_force_participation_rate_aged_15_and_above_female_2012\": 50.9, \"labour_force_participation_rate_aged_15_and_above_male_2012\": 79.2, \"population_with_some_secondary_ed_aged_25_and_up_fem_2005_2012\": 56.5, \"population_with_some_secondary_ed_aged_25_and_up_male_2005_2012\": 50.8 } ], \"fields\": \"\", \"start\": 0, \"took\": 3, \"total\": 1 } Aha! Turns out the full name for Venezuela is \"Venezuela (Bolivarian Republic of)\". RangesMaybe we'd like to know which countries have women holding at least 50% of the seats in parliament. Voil\u00e0: $ http :6543\/api\/gii_countries _2013_share_of_seats_in_parliament_held_by_women==\"[50 TO *]\" HTTP\/1.1 200 OK Cache-Control: max-age=0, must-revalidate, no-cache, no-store Content-Length: 1562 Content-Type: application\/json: charset=UTF-8 Date: Tue, 01 Sep 2015 19:48:02 GMT Etag: \"963212cb572b10eb4efaa38f0bfaf4c6\" Expires: Tue, 01 Sep 2015 19:48:02 GMT Last-Modified: Tue, 01 Sep 2015 19:48:02 GMT Pragma: no-cache Server: waitress { \"count\": 2, \"data\": [ { \"_2010_2015_adolescent_birth_rate_births_per_1_000_women_aged_15_19\": null, \"_2010_maternal_mortality_ratio_deaths_per_100_000_live_births\": null, \"_2013_share_of_seats_in_parliament_held_by_women\": 50.0, \"_pk\": \"Andorra\", \"_score\": 1.0, \"_self\": \"http:\/\/localhost:6543\/api\/gii_countries\/Andorra\", \"_type\": \"GiiCountry\", \"_version\": 0, \"country\": \"Andorra\", \"gender_inequality_index_rank_2013\": null, \"gender_inequality_index_value_2013\": null, \"hdi_rank\": 37, \"labour_force_participation_rate_aged_15_and_above_female_2012\": null, \"labour_force_participation_rate_aged_15_and_above_male_2012\": null, \"population_with_some_secondary_ed_aged_25_and_up_fem_2005_2012\": 49.5, \"population_with_some_secondary_ed_aged_25_and_up_male_2005_2012\": 49.3 }, { \"_2010_2015_adolescent_birth_rate_births_per_1_000_women_aged_15_19\": 33.6, \"_2010_maternal_mortality_ratio_deaths_per_100_000_live_births\": 340, \"_2013_share_of_seats_in_parliament_held_by_women\": 51.9, \"_pk\": \"Rwanda\", \"_score\": 1.0, \"_self\": \"http:\/\/localhost:6543\/api\/gii_countries\/Rwanda\", \"_type\": \"GiiCountry\", \"_version\": 0, \"country\": \"Rwanda\", \"gender_inequality_index_rank_2013\": 79.0, \"gender_inequality_index_value_2013\": 0.41, \"hdi_rank\": 151, \"labour_force_participation_rate_aged_15_and_above_female_2012\": 86.5, \"labour_force_participation_rate_aged_15_and_above_male_2012\": 85.5, \"population_with_some_secondary_ed_aged_25_and_up_fem_2005_2012\": 7.4, \"population_with_some_secondary_ed_aged_25_and_up_male_2005_2012\": 8.0 } ], \"fields\": \"\", \"start\": 0, \"took\": 6, \"total\": 2 } Not bad Andorra and Rwanda, not bad at all. AggregationsLet's say we want to know something that requires a little computation, like the average level of gender inequality worldwide. This (and all kinds of other questions) can be answered using aggregations. First, open and change to because this feature is disabled by default. Then, restart the server. $ http :6543\/api\/gii_countries _aggs.avg_gender_ineq.avg.field==gender_inequality_index_value_2013 HTTP\/1.1 200 OK Cache-Control: max-age=0, must-revalidate, no-cache, no-store Content-Length: 50 Content-Type: application\/json: charset=UTF-8 Date: Tue, 01 Sep 2015 20:13:57 GMT Expires: Tue, 01 Sep 2015 20:13:57 GMT Last-Modified: Tue, 01 Sep 2015 20:13:57 GMT Pragma: no-cache Server: waitress { \"avg_gender_ineq\": { \"value\": 0.3809693251533742 } } The average global gender inequality, expressed as a percentage of \"lost\" human development, is 38%. That is, if there was no gender inequality, the world would be considered 38% more developed than its current state. BonusTo see what the Elasticsearch query really looks like behind the scenes, you can add a logger to . Add a section like so: [logger_elasticsearch] level = INFO handlers = qualname = elasticsearch.trace Then make sure the new logger is added to the loggers list on line 47: [loggers] keys = root, gii_api, nefertari, ramses, elasticsearch Shut down and restart the server. Now if you rerun the above aggregation and look in the server log, you'll see the following: 2015-09-01 16:13:57,201 INFO [elasticsearch.trace][Dummy-3] base.log_request_success: curl -XGET 'http:\/\/localhost:9200\/gii_api\/GiiCountry\/_search?pretty&search_type=count' -d '{ \"aggregations\": { \"avg_gender_ineq\": { \"avg\": { \"field\": \"gender_inequality_index_value_2013\" } } }, \"query\": { \"match_all\": {} } }' With that information you can compare the queries that the server generates directly with the Elasticsearch aggregations documentation. Now you can explore and figure out how to build more advanced aggregations! Check out the . HelpThe Ramses team is available to chat on our Gitter channel, for help digging into the data, or for any help using the stack on your own projects. . \n"}<br>{"index": {"_id": 869}}<br>{"title":"Beats 1.0.0-beta4: lightweight log forwarding with Filebeat","seo_title":"","url":"\/blog\/beats-beta4-filebeat-lightweight-log-forwarding","author":{"name":"Tudor Golubenco"},"date":"October 22, 2015","category":"","locales":"","content":" We just released Beats version 1.0.0-beta4. It contains improvements for and but also something new: the first version of Filebeat, our new open source log forwarder that ships to Logstash or Elasticsearch. The goal of Filebeat is to tail logs and to ship them off servers to a central location for further processing. It is very lightweight in terms of consumed resources and has no dependencies or plugins to manage. Based on the Logstash Forwarder code baseWhile Filebeat is a new project, significant parts of its code base are based on the project, which has been\u00a0used in production by many companies for years. Because Logstash Forwarder and Logstash don\u2019t share any code and they are written in different programming languages (Go and Ruby), Logstash Forwarder was unfortunately neglected for too long by the dev community around Logstash and tended to lag behind in terms of improvements and bug fixes. A few community forks have been created, for example the and this by Etsy. By making Logstash Forwarder a project, which has a dedicated team of Go developers inside Elastic, we make sure the Elastic stack has a well maintained log forwarder. Over the\u00a0past couple of months, we took the Logstash Forwarder code, split it into parts, replaced the more rusty bits, added tons of unit, integration and system tests and then put it back together in a Beat. Filebeat now shares a lot of code with our other Beats via , making the projects benefit from each other\u2019s improvements. The logs are the queueOne of the core features of the Logstash Forwarder, which we have inherited in Filebeat is that after sending the log lines to Logstash it waits for a confirmation that the message was received. Only after this ack is received the persistent registry where it remembers how far it advanced in each file. This means that if there is a network partition between Filebeat and Logstash and the connection is temporarily lost, Filebeat simply waits for the connection to be re-established before advancing its pointer in the log files. Unless the connection cannot be established for a very long time and the logs are rotated, no log lines are lost. Similarly, if you restart Logstash, no log lines are lost. If you restart Filebeat, no log lines are lost. If there\u2019s network congestion on the path, no log lines are lost. You get the idea. Note that there is also drawback to this \u201cat-least-once\u201d approach. Because we retransmit unacknowledged messages, log lines might be duplicated. For most people duplicate log messages are better than lost log messages, but we\u2019ve been working on reducing this effect. I'm a lumberjack and I'm ok The protocol used between the Logstash Forwarder and Logstash already supports encryption, message batching and acknowledgements. The current version of Filebeat uses the same protocol but with a few improvements. Notably, for minimizing congestion situations that can result in duplicates, a slow start mechanism is used for the batch size, similar with the approach taken by TCP to avoid congestion. Partial ACKs were also introduced to help in this area.\u00a0To allow for a simple migration path from the Logstash Forwarder, we have created a new input plugin for Logstash, called , and we made sure it can be used in parallel with the existing input plugin used by the Forwarder. Another change is making the certificate-based authentication optional so that it\u2019s easier to use Filebeat while testing or developing. Yes, Filebeat works on WindowsI\u2019m glad you asked. Just like Packetbeat and Topbeat, the other Beats projects that we have so far, Filebeat supports Windows. The Logstash Forwarder already worked on Windows but there were\u00a0a few issues that severely crippled its functionality on that platform. We fixed those and now we run the same tests that we have for Linux and OS X on Windows as well, so you don\u2019t have to worry about differences in behaviour when you have a mixed environment. The Beats packaging framework also makes it a bit easier to run Filebeat as a Windows service. Migrate from the Logstash Forwarder To be more like the other Beats, Filebeat uses YAML for its configuration file, rather than the JSON+comments language used by Logstash Forwarder. Since we started a new project and re-configuration is needed anyway, we took the opportunity to clean up some configuration options. For example, many of the options that Logstash Forwarder received as CLI options are now configuration file options. Don\u2019t worry though, it\u2019s all quite simple, and we\u2019ve written a fairly extensive to help you on the process. Packetbeat and TopbeatWhile the main focus during this release cycle was Filebeat, we continued to improve Packetbeat and Topbeat. You can find the respective change logs and . Notably they now both support sending the data to Logstash via the same protocol that Filebeat uses, so Redis is no longer needed for the integration with Logstash. This also means that you can now easily use Logstash as a gateway to the many outputs supported by Logstash. The (near) futureWe intend to have the first GA release for all the Beats in a matter of weeks. Shortly after removing the beta label, we will add to Filebeat the three most commonly requested features: multi-line support, Windows event log support, and simple grep-like filtering based on the log message. The three new planned enhancements are tracked in this . We always love hearing from you, so why not give , or a try and let us know what you think on the ? Image credits: , ,\u00a0 \n"}<br>{"index": {"_id": 870}}<br>{"title":"Logstash 2.0.0-rc1 released","seo_title":"","url":"\/blog\/logstash-2-0-0-rc1-released","author":{"name":"Suyog Rao"},"date":"October 22, 2015","category":"Releases","locales":"","content":" We are pleased to announce the release of Logstash 2.0.0-rc1. This is the last planned release candidate for 2.0.0. This is a release candidate. Please do not deploy release candidates to your production environment. Changes We\u2019ve had one change go into this release since : Prior implementations of the metrics filter plugin used dotted field names. Elasticsearch does not allow field names to have dots, beginning with version 2.0, so a change was made to use sub-fields instead of dots in this plugin. Please note that these changes make version 3.0.0 of the metrics filter plugin incompatible with previous releases. You can Logstash 2.0.0-rc1 and check the changes list . As always, we value your feedback, so please try RC1 and let us know what you think! \n"}<br>{"index": {"_id": 871}}<br>{"title":"Grid Monitoring at CERN with Elastic","seo_title":"","url":"\/blog\/grid-monitoring-at-cern-with-elastic","author":{"name":"Pablo Saiz"},"date":"October 21, 2015","category":"User Stories","locales":"de-de,fr-fr","content":" Mission & BackgroundThe mission of the WLCG project is to provide global computing resources to store, distribute and analyze the ~30 petabytes of data annually generated by the Large Hadron Collider (LHC) at CERN on the Franco-Swiss border. The accomplishment of this mission currently requires more than 300 petabytes of disk and 200 petabytes of tape. The WLCG Grid Monitoring team at CERN is in charge of providing tools and services that allow the monitoring and understanding of the complex WLCG infrastructure. Without this understanding, an efficient use of the system would be impossible. The team has developed multiple applications to retrieve, display, and analyze the monitoring data. The different applications are tuned to the expected audience: high-level views for management, detailed views for service administrators and individual users and illustrative views for the general public. Most of these applications are based on web servers on top of relational databases. Recently, the increased volume and complexity of monitoring data required the move to modern, state-of-the-art technologies. The next section describes three monitoring tasks which we use as pilot applications for our Elasticsearch evaluation. They cover various areas of the computing activities on the WLCG infrastructure: data access and distribution, data processing, and services health and performance. There are dedicated dashboards for each of these areas. The WLCG Data Collection \n"}<br>{"index": {"_id": 872}}<br>{"title":"Brewing in Beats: Preparing the first Filebeat release","seo_title":"","url":"\/blog\/this-week-in-beats-first-filebeat-release","author":{"name":"Tudor Golubenco"},"date":"October 20, 2015","category":"Brewing in Beats","locales":"","content":" Welcome to ! With this series, we're keeping you up to date with all that's new in , from\u00a0the details of work in progress pull requests to\u00a0releases\u00a0and learning resources.Here is what we worked on over the past week. Preparing for the first Filebeat releaseWe\u2019re very close to releasing Filebeat (the Logstash-Forwarder successor) and we are\u00a0excited to share it with the rest of the world. \n"}<br>{"index": {"_id": 873}}<br>{"title":"To shade or not to shade","seo_title":"To shade or not to shade","url":"\/blog\/to-shade-or-not-to-shade","author":{"name":"David Pilato"},"date":"October 20, 2015","category":"","locales":"","content":" Before version 2.0, Elasticsearch was provided as a JAR with some (but not all) common dependencies shaded and packaged within the same artifact. This helped Java users who embed Elasticsearch in their own applications to avoid version conflicts of modules like Guava, Joda, Jackson, etc. Of course, there was still a list of other unshaded dependencies like Lucene that could still cause conflicts. Unfortunately, shading is a complex and error prone process which for some people while for others. Shading makes it very difficult for developers and plugin authors to write and debug code properly because packages are renamed during the build. Finally, we used to test Elasticsearch unshaded then ship the shaded jar, and we don\u2019t like to ship anything that we aren\u2019t testing. We have decided to ship Elasticsearch without shading from 2.0 onwards. Dealing with version conflictsIf you want to use Elasticsearch in your Java application, you may have to deal with version conflicts with third party dependencies like Guava and Joda. \u00a0For instance, perhaps Elasticsearch uses Joda 2.8, while your code uses Joda 2.1. \u00a0You have two choices: The simplest solution is to upgrade. Newer module versions are likely to have fixed old bugs. The further behind you fall, the harder it will be to upgrade later. Of course, it is possible that you are using a third party dependency that in turn depends on an outdated version of a package, which prevents you from upgrading. \u00a0 The second option is to relocate the troublesome dependencies and to shade them either with your own application or with Elasticsearch and any plugins needed by the Elasticsearch client. How to shade ElasticsearchTo help you achieve this, we have put together an example application which allows you to run: Your project\u2019s probably looks something like this: The problem with the above is the Joda dependency: your project requires Joda 2.1, but Elasticsearch 2.0.0-beta2 requires Joda 2.8. Shading ElasticsearchTo resolve this situation, we create a new maven project that shades Elasticsearch and Shield. \u00a0The should look like this: Shade and relocate conflicting packagesNow shade and relocate all the packages which conflict with your own application by adding something like the below to the . \u00a0This example adds Joda 2.8: Running will create a shaded version of Elasticsearch, Shield, and Joda 2.8 which you can depend on in your application. Embed this jar within your applicationIn your project, you can now depend on: You can build and use the Elasticsearch TransportClient as before: To use your own version of Joda, just import . You can even access the shaded version of Joda by importing , although we don\u2019t recommend doing so. Here\u2019s an example showing how both versions can be accessed within the same JVM: It will print: Take a look at this which shows a full running example of the above. Future developmentsDealing with version conflicts is a perennial problem, but in the future we would like to make it easier than it is today. The simplest way to reduce conflicts between third party dependencies is to reduce the number of dependencies that Elasticsearch has. \u00a0We will never be able to remove all dependencies, but we\u2019re making a start by in favour of native Java 8 code. We will also be investigating replacing (also in Java 8), and possibly even creating a thin Java client for Elasticsearch with minimal dependencies. Of course, these changes are not small. \u00a0Whatever we end up deciding is the right path to follow in the long term, it will take time for us to reach the destination. \u00a0In the meantime, we wanted to provide a relatively simple solution for today\u2019s problems. \n"}<br>{"index": {"_id": 874}}<br>{"title":"Logstash Lines: Preparing for the 2.0 release","seo_title":"","url":"\/blog\/logstash-lines-2015-10-19","author":{"name":"Suyog Rao"},"date":"October 20, 2015","category":"","locales":"","content":" Welcome back to\u00a0! In these weekly\u00a0posts, we'll share the latest happenings in the world of Logstash and its ecosystem. Road to\u00a0Logstash 2.0This week, we shipped and versions for Logstash 2.0.0. These releases include few breaking changes, so its recommended you read the blogs and \u00a0for details. Many of our users\u00a0were expecting a 1.6 release which was originally slated\u00a0after version\u00a01.5 -- since we had to introduce breaking changes, we decided to call our next release\u00a02.0 (a major version). Our team is still focused to deliver on the themes mentioned in the -- resiliency, manageability and performance. We will target new enhancements like persistent queues as minor versioned releases (like 2.1, 2.2). We explain in detail in our previous\u00a0.Beta2 also adds TLS 1.2 support (default), faster JSON serialization\/deserialization, and better out of the box defaults. For example, the filter worker settings now\u00a0default\u00a0to half the number of cores available, allowing\u00a0you to do more heavy lifting in your filters. Road to Filebeats We are working closely with the Beats team to help launch\u00a0Filebeat, a successor for Logstash Forwarder. We created a new input called which will interact with the beats agent\u00a0and receive messages over the Lumberjack protocol. \n"}<br>{"index": {"_id": 875}}<br>{"title":"Docteur Souris and Elastic Help Hospitalized Kids in France","seo_title":"Docteur Souris and Elastic Help Hospitalized Kids in France","url":"\/blog\/docteur-souris-and-elastic-help-hospitalized-kids-in-france","author":{"name":"Gaspard Du Jeu"},"date":"October 20, 2015","category":"","locales":"","content":" \"We are proud to support the cause fought by Association Docteur Souris that makes the lives of hospitalized children a little less painful.\" -\u00a0 Docteur Souris will have a booth at the event to educate attendees about its activity, the various actions it is taking in more than 30 hospitals all around France with more than 1100 computers operating every day. The implementation, the follow-up, and the devices\u2019 maintenance are free for the hospitals and free\u00a0for the children and teenagers to use. Docteur Souris\u2019 concept has been developed with a long-term solution of support, which will ensure the maintenance of the various measures and devices set up in health care facilities. With such a system, the computers can be long-distance controlled, easing their maintenance and reducing deadlines and costs. Therefore, thanks to the support of Elastic, more than 1200 children and teenagers will be able to connect themselves to the internet safely with a secured PaloAlto Network system. They will access Docteur Souris\u2019 portal, rich in educational and entertaining content. \u201cWe feel honoured to partner with Elastic and thank the managing team to have chosen Docteur Souris for Elastic{ON} Tour Paris. Thanks to this partnership, Docteur Souris will continue to help more hospitalized children all over France to break their isolation.\"\u00a0 If you need further information or wish to register for the Elastic{ON} Tour event in Paris, click . Currently Paris is sold out, but sign up on the waiting list and Elastic will contact you if a spot opens up. [if gte mso 9]><xml> <w:WordDocument> <w:View>Normal<\/w:View> <w:Zoom>0<\/w:Zoom> <w:TrackMoves><\/w:TrackMoves> <w:TrackFormatting><\/w:TrackFormatting> <w:PunctuationKerning><\/w:PunctuationKerning> <w:ValidateAgainstSchemas><\/w:ValidateAgainstSchemas> <w:SaveIfXMLInvalid>false<\/w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false<\/w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false<\/w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF><\/w:DoNotPromoteQF> <w:LidThemeOther>EN-US<\/w:LidThemeOther> <w:LidThemeAsian>JA<\/w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE<\/w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables><\/w:BreakWrappedTables> <w:SnapToGridInCell><\/w:SnapToGridInCell> <w:WrapTextWithPunct><\/w:WrapTextWithPunct> <w:UseAsianBreakRules><\/w:UseAsianBreakRules> <w:DontGrowAutofit><\/w:DontGrowAutofit> <w:SplitPgBreakAndParaMark><\/w:SplitPgBreakAndParaMark> <w:EnableOpenTypeKerning><\/w:EnableOpenTypeKerning> <w:DontFlipMirrorIndents><\/w:DontFlipMirrorIndents> <w:OverrideTableStyleHps><\/w:OverrideTableStyleHps> <\/w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\"><\/m:mathFont> <m:brkBin m:val=\"before\"><\/m:brkBin> <m:brkBinSub m:val=\"&#45: -\"><\/m:brkBinSub> <m:smallFrac m:val=\"off\"><\/m:smallFrac> <m:dispDef><\/m:dispDef> <m:lMargin m:val=\"0\"><\/m:lMargin> <m:rMargin m:val=\"0\"><\/m:rMargin> <m:defJc m:val=\"centerGroup\"><\/m:defJc> <m:wrapIndent m:val=\"1440\"><\/m:wrapIndent> <m:intLim m:val=\"subSup\"><\/m:intLim> <m:naryLim m:val=\"undOvr\"><\/m:naryLim> <\/m:mathPr><\/w:WordDocument> <\/xml><![endif][if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\"><\/w:LsdException> <\/w:LatentStyles> <\/xml><![endif][if gte mso 10]> <style> \/* Style Definitions *\/ table.MsoNormalTable {mso-style-name:\"Table Normal\": mso-tstyle-rowband-size:0: mso-tstyle-colband-size:0: mso-style-noshow:yes: mso-style-priority:99: mso-style-parent:\"\": mso-padding-alt:0cm 5.4pt 0cm 5.4pt: mso-para-margin:0cm: mso-para-margin-bottom:.0001pt: line-height:115%: mso-pagination:widow-orphan: font-size:11.0pt: font-family:Arial: color:black: } <\/style> <![endif]StartFragment EndFragment \n"}<br>{"index": {"_id": 876}}<br>{"title":"Docteur Souris et Elastic aident les enfants hospitalis\u00e9s en France","seo_title":"Docteur Souris et Elastic aident les enfants hospitalis\u00e9s en France","url":"\/blog\/docteur-souris-et-elastic-aident-les-enfants-hospitalises-en-france","author":{"name":"Gaspard Du Jeu"},"date":"October 20, 2015","category":"","locales":"","content":" A l\u2019occasion du passage de Elastic{ON} Tour le jeudi 5 Novembre \u00e0 Paris, la soci\u00e9t\u00e9 Elastic, sp\u00e9cialis\u00e9e dans la cr\u00e9ation de logiciels d\u2019analyse de donn\u00e9es, s\u2019engage \u00e0 reverser l\u2019ensemble des frais d\u2019inscriptions de son s\u00e9minaire parisien \u00e0 pour permettre aux enfants et adolescents hospitalis\u00e9s \u00a0de se divertir, communiquer avec leurs proches et \u00e9viter toute rupture scolaire. L\u2019Association Docteur Souris sera pr\u00e9sente sur l\u2019\u00e9v\u00e9nement pour pr\u00e9senter les diff\u00e9rentes actions mises en place dans plus de 30 h\u00f4pitaux en France avec plus de 1100 ordinateurs disponible\u00a0chaque jour. La mise en \u0153uvre, le suivi et la maintenance des dispositifs est gratuit pour les h\u00f4pitaux et l\u2019usage gratuit pour les enfants. Pour en savoir plus sur le s\u00e9minaire Elastic{ON} Tour\u00a0\u00e0 Paris et pour vous\u00a0inscrire, cliquez . Nous sommes complets mais vous pourriez vous ajouter\u00a0sur notre liste d'attente et nous vous laisserons savoir quand il y a des places disponible. [if gte mso 9]><xml> <w:WordDocument> <w:View>Normal<\/w:View> <w:Zoom>0<\/w:Zoom> <w:TrackMoves><\/w:TrackMoves> <w:TrackFormatting><\/w:TrackFormatting> <w:PunctuationKerning><\/w:PunctuationKerning> <w:ValidateAgainstSchemas><\/w:ValidateAgainstSchemas> <w:SaveIfXMLInvalid>false<\/w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false<\/w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false<\/w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF><\/w:DoNotPromoteQF> <w:LidThemeOther>EN-US<\/w:LidThemeOther> <w:LidThemeAsian>JA<\/w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE<\/w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables><\/w:BreakWrappedTables> <w:SnapToGridInCell><\/w:SnapToGridInCell> <w:WrapTextWithPunct><\/w:WrapTextWithPunct> <w:UseAsianBreakRules><\/w:UseAsianBreakRules> <w:DontGrowAutofit><\/w:DontGrowAutofit> <w:SplitPgBreakAndParaMark><\/w:SplitPgBreakAndParaMark> <w:EnableOpenTypeKerning><\/w:EnableOpenTypeKerning> <w:DontFlipMirrorIndents><\/w:DontFlipMirrorIndents> <w:OverrideTableStyleHps><\/w:OverrideTableStyleHps> <\/w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\"><\/m:mathFont> <m:brkBin m:val=\"before\"><\/m:brkBin> <m:brkBinSub m:val=\"&#45: -\"><\/m:brkBinSub> <m:smallFrac m:val=\"off\"><\/m:smallFrac> <m:dispDef><\/m:dispDef> <m:lMargin m:val=\"0\"><\/m:lMargin> <m:rMargin m:val=\"0\"><\/m:rMargin> <m:defJc m:val=\"centerGroup\"><\/m:defJc> <m:wrapIndent m:val=\"1440\"><\/m:wrapIndent> <m:intLim m:val=\"subSup\"><\/m:intLim> <m:naryLim m:val=\"undOvr\"><\/m:naryLim> <\/m:mathPr><\/w:WordDocument> <\/xml><![endif][if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\"><\/w:LsdException> <\/w:LatentStyles> <\/xml><![endif][if gte mso 10]> <style> \/* Style Definitions *\/ table.MsoNormalTable {mso-style-name:\"Table Normal\": mso-tstyle-rowband-size:0: mso-tstyle-colband-size:0: mso-style-noshow:yes: mso-style-priority:99: mso-style-parent:\"\": mso-padding-alt:0cm 5.4pt 0cm 5.4pt: mso-para-margin:0cm: mso-para-margin-bottom:.0001pt: line-height:115%: mso-pagination:widow-orphan: font-size:11.0pt: font-family:Arial: color:black: } <\/style> <![endif]StartFragment EndFragment \n"}<br>{"index": {"_id": 877}}<br>{"title":"This Week in Elasticsearch and Apache Lucene - October 19th 2015","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-10-19","author":{"name":"Michael McCandless"},"date":"October 19, 2015","category":"","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsJust released new clients - 2.0.0 for upcoming Elasticsearch 2.0 and 1.8.0 for 1.x versions - \u2014 Honza Kr\u00e1l (@HonzaKral) Elasticsearch CoreLast week we\u00a0\u00a0which contained some good bug fixes for the Tribe node, synced flushing, and snapshot restore. Changes in 2.0: Changes in 2.x\/3.x: In progress: Apache Lucene Watch This Space, where we'll share more news on the whole Elastic\u00a0ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 878}}<br>{"title":"Logstash 2.0.0 beta3 released","seo_title":"","url":"\/blog\/logstash-2-0-0-beta3-released","author":{"name":"Suyog Rao"},"date":"October 19, 2015","category":"Releases","locales":"","content":" Quick update to announce release for Logstash 2.0.0. Since we released last week, we found two important defects which are resolved in this release. This is a beta release and is intended for testing purposes only. There is no guarantee that Logstash 2.0.0-beta3 will be compatible with Logstash 2.0.0 GA. Bug Fixes Feedback Many thanks to users who tried beta2 and provided us feedback! As always, your input is very valuable. Head to our page and give it a try! If you find issues you can start a topic in our or create an . \n"}<br>{"index": {"_id": 879}}<br>{"title":"Where in the World is Elastic? - CFCamp","seo_title":"Where in the World is Elastic? - CFCamp","url":"\/blog\/witwies-cfcamp","author":{"name":"Megan Wieling"},"date":"October 19, 2015","category":"","locales":"","content":" Welcome to Find out what is\u00a0happening near you\u00a0this week\u00a0in Elastic\u00a0events and\u00a0meetup\u00a0land! Upcoming Events October 22 - 23: Upcoming Meetups October 22:\u00a0October 22: October 23: October 20:October 21: October 22: October 22: October 22: October 22: October 22: October 21: October 25: That's it for this week. Stay tuned for Elastic happenings next week! - The Elastic Team P.S. if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 880}}<br>{"title":"Hired Taps into Elasticsearch as a Service for Job Marketplace","seo_title":"Hired Taps into Elasticsearch as a Service for Job Marketplace","url":"\/blog\/hired-taps-elasticsearch-as-a-service-for-job-marketplace","author":{"name":"Andrew Evans"},"date":"October 19, 2015","category":"","locales":"","content":" This article refers to\u00a0our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. \n"}<br>{"index": {"_id": 881}}<br>{"title":"The 2015 Elastic Blackout","seo_title":"","url":"\/blog\/the-2015-elastic-blackout","author":{"name":"Haley Eshagh"},"date":"October 15, 2015","category":"Culture","locales":"","content":" There was a blackout yesterday, but you probably didn't notice. On October 14, 2015, darkness of the best kind consumed Elastic offices all around the world. What started out as a company onboarding activity for the latest batch of employees to join our Elastic cluster turned into a worldwide challenge: Take an awesome photo wearing Elastic gear around town. Colleagues represented Elastic during an afternoon MRI scan in Ohio, strolling by Big Ben in London, and saying \"hiya\" from Amsterdam, Singapore, New York, Austin, Seattle, Stockholm, Japan, France, Boston, Mountain View, and beyond. We thought we'd share some of the pictures with you. With over 80 people joining Elastic since August representing more than 15 countries, there were a lot of great photos to choose from.\u00a0 And why black shirts? Do a quick image search of \"Shay Banon.\" (Yeah, there are a few outliers, but you get the idea.) Plus, they're standard issue at the company after our first . The lights are back on and there's more Elastic goodness in the works. Stay tuned. (And if you'd like a black shirt of your own, .) \n"}<br>{"index": {"_id": 882}}<br>{"title":"Elasticsearch 1.7.3 released","seo_title":"Elasticsearch 1.7.3 released","url":"\/blog\/elasticsearch-1-7-3-released","author":{"name":"Clinton Gormley"},"date":"October 15, 2015","category":"Releases","locales":"","content":" Today, we are happy to announce the bug fix release of , based on . This is the latest stable release. Users are advised to upgrade if they find themselves affected by any of the bugs which have been fixed.You can .Previous blog posts about the 1.7 series:This release contains a number of bug fixes including:Please , try it out, and let us know what you think on Twitter () or on our . You can report any problems on the . \n"}<br>{"index": {"_id": 883}}<br>{"title":"Easily Visualize Spreadsheet Data with Elasticsearch & Kibana","seo_title":"Easily Visualize Spreadsheet Data with Elasticsearch & Kibana","url":"\/blog\/introducing-google-sheets-to-elasticsearch-add-on","author":{"name":"Russ Savage"},"date":"October 14, 2015","category":"Engineering","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as . Also note that the add-on does not automatically work with versions 5.x and above. To benefit from 5.x using this add-on, you must index the data into a 2.4.4 cluster and then upgrade.\u00a0Our latest Google Sheets add-on makes visualizing your spreadsheet data a snap. Today, we're rolling out a new that makes it easy to do just that. Using this add-on, along with , you can push data from a spreadsheet to your Elasticsearch cluster and get up and running with Kibana visualizations in just a few minutes. Setting Up a ClusterIf you already have a cluster you want to push data into, you can skip to the next section about pushing data. If not, we recommend you take a moment to before continuing. With just a few clicks, you will have a secure cluster up and running, including Kibana 4 for visualizations. Watch this short demonstration video on how to spin up a free hosted Elasticsearch cluster. After completing the sign up and configuration for Found, you should see a couple of endpoints displayed that look like this: http:\/\/<some-long-id>.us-east-1.aws.found.io:9200 https:\/\/<some-long-id>.us-east-1.aws.found.io:9243 We will use those later to send data to your cluster. Pushing Data to Your ClusterOur cluster is ready to go, so now it's time to open up your Google Sheet and get started. The video below walks you through the steps in detail. Helpful TipsFor those of you interested in contributing or understanding how this works, feel free to check out the code hosted on the . Here are a few helpful tips in case you get stuck: Visualizing it with KibanaAfter you have your data indexed into Elasticsearch, the easiest way to visualize it is with Kibana. If you are using Found, the URL for Kibana 4 can be found under the \"Configuration\" section of your cluster. You can browse the or check out this helpful . \n"}<br>{"index": {"_id": 884}}<br>{"title":"Logstash 2.0.0 beta2 released","seo_title":"","url":"\/blog\/logstash-2-0-0-beta2-released","author":{"name":""},"date":"October 14, 2015","category":"Releases","locales":"","content":" We are pleased to announce the beta2 release for Logstash 2.0.0. Please note that there are some breaking changes in this release and we encourage you to read the entire blog. This is a beta release and is intended for testing purposes only. There is no guarantee that Logstash 2.0.0-beta2 will be compatible with Logstash 2.0.0 GA. Breaking Changes in 2.0.0.beta2 Releasing a major version of Logstash creates the opportunity to remove features and configuration options that have been deprecated in previous releases. The beta2 release changes the default value of the setting which is used to control the number of filter workers. This release also removes many plugin configuration options that are now obsolete. They are detailed below. Obsolete Configuration Options Until the introduction of conditionals, the only way to selectively apply filters and outputs to some events was to set the , and options. These configuration options have been deprecated for some time now and this release either removes them, or they are marked with the new tag. You will not be able to use them in your configuration file without a resulting error. Feedback when obsolete config options are used To make the removal of settings less aggressive to the user, an option to tag a plugin configuration setting as obsolete has been introduced. After a feature has been deprecated for some time, it will then be marked as obsolete. If an obsolete setting is used, a pre-configured message is presented to the user informing them of the obsolete status of the option, then Logstash terminates immediately. How does this look in real life? Imagine that a plugin has an option called and we wish to remove it. Here is a potential timeline of plugin releases: => plugin is shipped, includes the feature and option => minor version release, deprecates => major version, removes the code related to and marks it as => minor version, removes As you can see, the tag softens the user experience for a removed feature, making the user aware that the feature is gone and presenting the recommended alternative! A Better Shutdown Strategy This release improves shutdown handling in Logstash and its plugins. Up to and including 1.5.x, when a pipeline shutdown is initiated, either by SIGTERM or SIGINT, the following events occur inside Logstash: The way input plugins terminate in step 3 is problematic, since raising exceptions on the input plugin threads from the outside is unpredictable. Calling a means that any execution happening in that thread must deal with the exception or terminate. In the context of input plugins, the exception can happen during the execution of code from third party libraries that many input plugins use. Being unable to predict how the code behaves leads to undesirable outcomes. A plugin may exit normally, exit abruptly and lose buffered data, get stuck in an inconsistent state, or some other unknown behavior. The solution To make the input plugin shutdown more reliable, a strategy was proposed () to avoid and instead signal the plugin\u2014in a thread-safe way\u2014that a shutdown sequence has been started. Doing this delegates the responsibility of deciding how and when to shut down within each input plugin. This proposal was at the core level, such that now all input plugins have three methods for shutdown purposes: , and . The way to know a plugin is stopped is simply by waiting for the plugin run method to return. When the run method exits and the plugin thread exits, only then will the close method be called, and that only once. API Cleanup Making this change also created an opportunity to review the rest of the shutdown API between the plugins and the pipeline, and several methods in the Plugin Base class were found to be unnecessary and thus could be removed: , , , and . The method is renamed to and retains the responsibility of post-termination bookkeeping, as described above. Plugin Developers This change of shutdown strategy implies that all input plugins must take ownership of checking when it\u2019s time to shut down, either by checking or by implementing their own method. Also, filters and outputs that call the obsolete methods noted above needed to be changed. Changing so many plugins required some , but now the pipeline\/plugin contract is leaner and input plugins can perform a much safer and more predictable shutdown! To help new plugin developers, the plugin examples repositories (, , , ) have been updated to reflect and demonstrate the new shutdown contract. Setting better defaults A major release is also a good time to revisit the default values for configuration settings used in Logstash. Default value for filter_worker Until 1.5 the default value for the setting was 1, which severely limited the pipeline performance: having a single filter worker meant that only one event was handled at a time since filters are evaluated in sequence. Now, out of the box, the default value of the setting will be set to half of the CPU cores of the machine. Increasing the workers provides parallelism in filter execution which is crucial when doing heavier processing like complex grok patterns or the useragent filter. Note that, as before, this setting can be changed with the \u201cw\u201d flag, e.g. . Showing default settings at start-up It\u2019s important to inform the user which values are being used in the current running instance so now Logstash will inform the use of the values being used for the default settings, namely . Beta Feedback Give the a spin! If you find any bugs please report them as issues either on the or on the appropriate . You can also head over to . We\u2019re excited to release Logstash 2.0, but can\u2019t do it without your help! \n"}<br>{"index": {"_id": 885}}<br>{"title":"Getting to know your coworkers made easier","seo_title":"","url":"\/blog\/pingboard-employee-directory-app-powered-by-elasticsearch","author":{"name":"Bill Boebel"},"date":"October 14, 2015","category":"","locales":"","content":" When your company is small, information is readily accessible. As your company grows, though, people become disconnected and simple things become hard, such as remembering names and faces, knowing who does what, and simply finding someone\u2019s phone number. was started when we noticed that many companies were building their own internal employee directories to solve this problem. When we dug in, we found that companies were essentially building the same thing because they couldn\u2019t find an employee directory app that met their needs. These projects feel temporary from the start and typically fail because they lack an owner to push them forward and aren\u2019t integrated with other employee systems, meaning the data is soon out of date.Pingboard was born to solve this problem. Every company needs place for employees to find information about the people they work with -- from photos, org chart and contact info, to skills, interests, and favorite coffee shop. People expect great searchOur first implementation of search in our web, iPhone, and Android apps was entirely client-side. It was fast and allowed you to search for coworkers by name or job title. Right away we heard from our customers that they wanted to search for additional employee attributes, including skill, team, and email address. Some companies found creative workarounds. One of our customers, Adecco, stored their business unit, division, region, and branch name in the nickname field so they would show up in search. People expect everything in the tools they use to be searchable instantly from a single search box. Great search used to be a differentiator, but now it\u2019s essential. We knew we had to quickly move the search index to the server using a platform like Solr or Elasticsearch, in order to give our customers what they expect.Elasticsearch is a great fit for us because it's flexible, powerful, and fast. The Pingboard data model includes many different types of information, and we knew we needed a tool which would let us customize the way we search different fields. Finding a person by name requires a different indexing strategy than finding a group of people with the same skill, or looking up an email address. In addition, the data model can be extended by customers, and we wanted custom fields to be searchable as well.\u00a0 let us index these fields based on their data type without having to know ahead of time what fields exist. Elasticsearch also makes it easy for us to adjust how we rank the search results by using . Designing a great search experienceWe talked with customers to determine the most important fields to make searchable and settled on: name, nickname, job title, skills, interests, team, email and phone number. We also threw in birthday month and employment start year to make it easy to answer questions like \u201cWho\u2019s birthday is coming up?\u201d or \u201cWho joined the company this year?\u201dOur key design decisions were: Customers loved it, but still wanted moreUpgrading search was a big deal, so we announced it to all of our users via an in-app message. We got a lot of praise for the update, but we also started hearing things like: \u201cLove it! When will this be available in your Android app?\u201d\u201cCan we also search for what project people are working on, which we store in a custom field?\u201d\u201cIt would be cool if our employees could search the fun employee fields we added, including college and favorite drink.\u201d Our work wasn\u2019t done. We celebrated briefly and then got back to work. Searching everything, from anywhereIn Pingboard, you can add custom fields to store any type of employee information using text fields, number fields, lists, tags, links to other people, and more. Today, everything is searchable. In fact, companies can even choose which fields to include in their search index.Of course, searching the employee directory from the iPhone and Android employee directory app needs to be just as powerful. We built a simple wrapper to the Elasticsearch API and replaced the local client-side search in our mobile apps with the same rich search that we built for the web. Elastic is a fanThat\u2019s right, the team at Elastic is one of our customers. Prior to Pingboard, Elastic\u2019s corporate directory was just a regular spreadsheet that was frequently outdated. As the company grew, it became more difficult to find employees and their specific functions within the organization. That\u2019s where Pingboard came in \u2014 it was easy to implement, integrated directly with Google Apps, and employees were able to quickly search for all relevant employee information within a few clicks on the website or the mobile app. Overnight, Pingboard became an instant hit.Not only did Pingboard help centralize employee information, but it provided Elastic with a platform that continued to foster company culture. Though some US-based employees may never have the opportunity to meet their APAC colleagues, Pingboard allowed employees to stay connected through user profiles where we could share our profile pictures, skill sets, interests and biographies. Going furtherIt\u2019s amazing to have all of this data about your company at your fingertips, but it doesn\u2019t stop there. We also give companies access to their employee directory programmatically via the Pingboard API. The API includes the full power of search, which we could not have built without Elasticsearch. Our customers have come up with creative uses for this, including an app that matches employees with new hires to take them out to lunch, and a face\/name matching game built into HipChat.These ideas and the continuous feedback we get from our customers inspire us to transform the employee directory into an essential business tool that every company needs. \n"}<br>{"index": {"_id": 886}}<br>{"title":"This Week in Elasticsearch and Apache Lucene - October 13th 2015","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-10-13","author":{"name":"Michael McCandless"},"date":"October 13, 2015","category":"","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsElasticsearch 2.0.0-rc1 released! Not long until GA...\u2014 elastic (@elastic) Elasticsearch Core Apache LuceneWatch This Space, where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 887}}<br>{"title":"Where in the World is Elastic? - Bordeaux Developer eXperience, EuRuKo 2015","seo_title":"Where in the World is Elastic? - DevRelCon 2015","url":"\/blog\/witwies-bordeaux-developer-experience-euruko-2015","author":{"name":"Megan Wieling"},"date":"October 12, 2015","category":"","locales":"","content":" Welcome to Curious to find out which\u00a0Elastic\u00a0events and\u00a0meetups are happening near you\u00a0this week? Check them out now!Upcoming Events October 16: October 17 - 18: \u00a0Upcoming MeetupsOctober 12: October 13: October 13: October 14: October 13: October 14: October 15:\u00a0October 17: That's it for this week. Stay tuned for Elastic happenings next week! - The Elastic Team P.S. if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 888}}<br>{"title":"Logstash configuration tuning","seo_title":"Logstash configuration tuning","url":"\/blog\/logstash-configuration-tuning","author":{"name":"Robin Clarke"},"date":"October 08, 2015","category":"","locales":"","content":" Logstash is a powerful beast and when it\u2019s firing on all cylinders to crunch data, it can use a lot of resources.\u00a0The goal of this blog post is to\u00a0provide a methodology to optimise your configuration and allow Logstash to get the most out of your hardware. \n"}<br>{"index": {"_id": 889}}<br>{"title":"Elasticsearch 2.0.0-rc1 released","seo_title":"Elasticsearch 2.0.0-rc1 released","url":"\/blog\/elasticsearch-2-0-0-rc1-released","author":{"name":"Clinton Gormley"},"date":"October 07, 2015","category":"Releases","locales":"","content":" Today, we are happy to announce the release of , based on . Elasticsearch 2.0 is feature frozen. This is the last planned release candidate before 2.0.0 GA.: This is a release candidate and is intended for testing purposes only. Elasticsearch 2.0.0-rc1 is not compatible with 2.0.0-beta1 or 2.0.0-beta2, and there is no guarantee that it will be compatible with Elasticsearch 2.0.0 GA.You can .Change logs for the commercial plugins can be found here:The changes in this release candidate consist mostly of minor bug fixes and tidy ups, with the occasional enhancement like the and, in Shield, a caching interface which can be used by custom realms.Thank you to those of you who tested out 2.0.0-beta1 and 2.0.0-beta2 and reported problems. Given that this is the last planned\u00a0preview release before 2.0.0 GA, we would appreciate as many testers as possible so that we can catch and fix issues before releasing the GA. \n"}<br>{"index": {"_id": 890}}<br>{"title":"Found: Elasticsearch-as-a-Service, now with Alerts","seo_title":"","url":"\/blog\/found-elasticsearch-as-a-service-with-alerts","author":{"name":"Shay Banon"},"date":"October 07, 2015","category":"News","locales":"de-de,fr-fr,ko-kr","content":" I\u2019m excited to announce that today, , our alerting and notifications plugin, is now available in , our hosted Elasticsearch product. This is super exciting for us as Watcher represents the second commercial product to be integrated into our hosted Elastic offering following this summer\u2019s release of , our security plugin. In addition, for those of you in Asia, Found is in Sydney too, in addition to, being available in Tokyo and Singapore.Earlier this summer, I wrote a post on Found, our strategy, and how taking an open source product and turning it into a world-class service is more than just \u201chosting\u201d. As the creators of the open source products -- Elasticsearch, Logstash, and Kibana -- we\u2019ve worked hard to ensure Found leverages our 5 years of history of developing and supporting them to give you: Thanks to our teams working closely together, we can take the innovation we are doing in our open source and commercial products and easily extend it to Found, and provide massive benefits to our customers. For example: We\u2019re also super happy that Found is enabling our customers to focus on running their core businesses, and that companies like Docker, HotelTonight, Instacart, and several Fortune 500 companies, use Found to run their mission critical applications.Of course our customers are asking us for more.Our philosophy, which ties heavily to our open source roots, is to give freedom to our users while using our products. Today, Found runs on Amazon AWS, but we are working on allowing our users to use Found as a standalone product that can be installed on premise and later be offered across multiple cloud providers. This is extremely exciting to me, and points to the adoption and popularity of what we have built. It is also something I hear users, who juggle multiple clusters, asking for all the time. \n"}<br>{"index": {"_id": 891}}<br>{"title":"This Week in Elasticsearch and Apache Lucene - October 6th 2015","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-10-06","author":{"name":"Michael McCandless"},"date":"October 06, 2015","category":"","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsStretching Horizons with . Read on to find out how they do it: . \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 892}}<br>{"title":"Hacking Education with the Elastic Stack","seo_title":"Hacking Education with the Elastic Stack","url":"\/blog\/hacking-education-with-the-elastic-stack","author":{"name":"Asawari Samant"},"date":"October 05, 2015","category":"","locales":"","content":" Today, October 5th, is , and we wanted to celebrate it in our own geeky, Elastic way. We figured why not do something fun and interesting with a dataset related to education using Elasticsearch, Logstash, and Kibana to mark this special day and say thank you to teachers around the world. The DonorsChoose.org dataset immediately popped to mind. is an online charity founded in 2000 with the goal of directly connecting do-gooders that care about education with public schools and classrooms in need of resources. As it happens, the great folks at DonorsChoose.org also extend their \u201cmission to connect\u201d to their datasets. As a part of their initiative, they have provided about a decade\u2019s worth of donations, resources, and projects data, as well as\u00a0data APIs to data crunchers around the world for \u201chacking education\u201d as they put it.So, we downloaded the datasets and decided to have fun with them. In this blog, we will share some of our insights. But, be sure to check out the code from our 'examples'\u00a0 to join in on the fun and find your own insights. The Big PictureWe decided to start exploring the big picture, and the numbers are impressive. Between 2000 and 2014, DonorsChoose.org helped connect around donors to . This raised close to from that funded . Exponential Growth Absolute numbers are great, but we love dynamic trends too. We wondered how things had evolved since the early days of DonorsChoose.org. If you thought the above absolute numbers were impressive, the graph below showing the trend over time is equally stellar. You can see a steady growth in total monthly donations (in $) over time. Oh, and by the way, the Y-axis in the chart below is in log scale! Interestingly, we noticed that while the total monthly donation amount has steadily increased, the average donation value (indicated by the size of the dot above) has actually decreased \u2013\u00a0this is not surprising and can be expected as the initiative got wider adoption and more donors joined in. It is also perhaps influenced by the lack of a minimum donation policy, as DonorsChoose.org has adopted \u00a0a \u201cno amount is too small\u201d philosophy. And that brings us to our next insight: Every dollar matters!Every dollar matters!A quick look at the amount raised shows that even small donations (< $10) have a large impact over time, and have raised close to $1.7\u00a0million.\u00a0The subsequent donation bracket from $10 - $100 netted out a whopping $60\u00a0million.This made us wonder how the typical donation amount varied by the donor\u2019s location. So, we looked at the fraction of the donations in various dollar amount brackets by donor\u2019s state. The typical distribution seems pretty consistent across most states. But, some states do stand out. For example, a greater fraction of donations from Oklahoma and Arkansas are in the > $500 bracket. By contrast, a larger percentage of donations received from Idaho and Alabama are in the sub $10 bracket.Looking at where the donations were coming from prompted our next question: Where are the donations going to and which areas received the most aid? Where are the donations going?A quick geomap immediately highlights that most of the donations are going towards schools in big metropolitan areas: New York, Los Angeles, San Francisco, Philadelphia, Washington, D.C., Chicago, Indianapolis, etc. There\u2019s a strong correlation between number of projects \u00a0initiated in a city and the received aid. \u00a0But wait, there's more!As you can tell, we could go on and on with our insights. But, we would love for you to join in on the fun. Grab the code from our examples and mine your own insights. We have even included a to help you get started. The dashboards provide\u00a0a peek into many other interesting\u00a0facets of the data, like how donations have varied over time by different facets of the projects. We explored factors such as the project primary focus areas (Literature, Math, Science, etc),\u00a0requested resource type (technology, books, supplies, etc), grade-level, and poverty level. So, dig in and if you find something interesting, do Tweet us .Finally, don\u2019t forget to check out . It\u2019s a great platform that enables a noble cause \u2013\u00a0and as we showed you with data, every dollar makes a difference. And, there are many classrooms, teachers, and students that would love your help! \n"}<br>{"index": {"_id": 893}}<br>{"title":"Where in the World is Elastic? - Linuxcon, PuppetConf 2015 and AWS re:Invent","seo_title":"Where in the World is Elastic? - DevRelCon 2015","url":"\/blog\/witwies-linuxcon-puppetconf-2015-aws-reinvent","author":{"name":"Megan Wieling"},"date":"October 05, 2015","category":"","locales":"","content":" Welcome to Check out the\u00a0Elastic\u00a0events and\u00a0meetups\u00a0happening near you\u00a0this week!Upcoming Events October 5 - 7:\u00a0October 6:\u00a0October 8: October 5 - 9:\u00a0October 6 - 9:\u00a0Upcoming MeetupsOctober 7: October 8:\u00a0October 6:\u00a0That's it for this week. Stay tuned for Elastic happenings next week! - The Elastic Team P.S. if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 894}}<br>{"title":"Stretching Horizons with Elasticsearch","seo_title":"Stretching horizons with Elasticsearch","url":"\/blog\/stretching-horizons-with-elasticsearch","author":{"name":"Emmanuel Gueidan"},"date":"October 05, 2015","category":"","locales":"","content":" Emmanuel Gueidan is co-founder and CTO at, a Paris-based startup focused on enabling innovative operations and high performance applications through log management.\u00a0Emmanuel has over 10 years experience building BI platforms. Dedicated to R&D and driven by innovation, he previously worked for and took over development of several cutting-edge pieces of the core product at Quartet FS, working on one of the first in-memory analytics real-time business intelligence tools. [if gte mso 9]><xml> <w:WordDocument> <w:View>Normal<\/w:View> <w:Zoom>0<\/w:Zoom> <w:TrackMoves><\/w:TrackMoves> <w:TrackFormatting><\/w:TrackFormatting> <w:PunctuationKerning><\/w:PunctuationKerning> <w:ValidateAgainstSchemas><\/w:ValidateAgainstSchemas> <w:SaveIfXMLInvalid>false<\/w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false<\/w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false<\/w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF><\/w:DoNotPromoteQF> <w:LidThemeOther>EN-US<\/w:LidThemeOther> <w:LidThemeAsian>JA<\/w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE<\/w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables><\/w:BreakWrappedTables> <w:SnapToGridInCell><\/w:SnapToGridInCell> <w:WrapTextWithPunct><\/w:WrapTextWithPunct> <w:UseAsianBreakRules><\/w:UseAsianBreakRules> <w:DontGrowAutofit><\/w:DontGrowAutofit> <w:SplitPgBreakAndParaMark><\/w:SplitPgBreakAndParaMark> <w:EnableOpenTypeKerning><\/w:EnableOpenTypeKerning> <w:DontFlipMirrorIndents><\/w:DontFlipMirrorIndents> <w:OverrideTableStyleHps><\/w:OverrideTableStyleHps> <\/w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\"><\/m:mathFont> <m:brkBin m:val=\"before\"><\/m:brkBin> <m:brkBinSub m:val=\"&#45: -\"><\/m:brkBinSub> <m:smallFrac m:val=\"off\"><\/m:smallFrac> <m:dispDef><\/m:dispDef> <m:lMargin m:val=\"0\"><\/m:lMargin> <m:rMargin m:val=\"0\"><\/m:rMargin> <m:defJc m:val=\"centerGroup\"><\/m:defJc> <m:wrapIndent m:val=\"1440\"><\/m:wrapIndent> <m:intLim m:val=\"subSup\"><\/m:intLim> <m:naryLim m:val=\"undOvr\"><\/m:naryLim> <\/m:mathPr><\/w:WordDocument> <\/xml><![endif][if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\"><\/w:LsdException> <\/w:LatentStyles> <\/xml><![endif][if gte mso 10]> <style> \/* Style Definitions *\/ table.MsoNormalTable {mso-style-name:\"Table Normal\": mso-tstyle-rowband-size:0: mso-tstyle-colband-size:0: mso-style-noshow:yes: mso-style-priority:99: mso-style-parent:\"\": mso-padding-alt:0cm 5.4pt 0cm 5.4pt: mso-para-margin:0cm: mso-para-margin-bottom:.0001pt: line-height:115%: mso-pagination:widow-orphan: font-size:11.0pt: font-family:Arial: color:black: } <\/style> <![endif]StartFragment EndFragment \n"}<br>{"index": {"_id": 895}}<br>{"title":"This Week in Elasticsearch and Apache Lucene - September 29 2015","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-09-29","author":{"name":"Alexander Reelsen"},"date":"September 29, 2015","category":"","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsNow OnDemand: @ Scale: Reference Architecture & Common Pitfalls\u201d ft. lessons from & \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 896}}<br>{"title":"Code Coverage for your Golang System Tests","seo_title":"","url":"\/blog\/code-coverage-for-your-golang-system-tests","author":{"name":"Nicolas Ruflin"},"date":"September 28, 2015","category":"Engineering","locales":"","content":" To better understand which parts of our Golang applications are covered by test suites, we wanted to have a coverage report that aggregates data from all of our automated tests. However, we couldn't find any information on how to generate coverage reports from system tests of Golang applications. We found a solution using the Golang toolchain and this is a guide of how we did it. The screenshot below from Codecov.io shows an example test coverage report from our product. Having a code coverage report for unit tests is common practice and very well supported by the . The challenge with services which highly depend on the environment, like the operating system or other services, is that unit tests can only cover certain cases. Sometimes writing a simple test that runs the binary and compares the output with the expected output is much easier and faster. In addition, it reproduces what is happening when the binary is executed. Unfortunately in most cases these system tests do not count to the coverage report which also makes it hard to identify which parts of the code were actually run by executing the binary. Our Code Coverage Challenge At , we develop the products using Golang. Packetbeat is an open source project written in Golang that is designed to provide real\u2011time analytics for web, database, and other network protocols. During the implementation of Packetbeat, we faced the challenge that the most valuable tests were the system tests that executed the binary and checked the expected output. These tests allow us to generate files, feed it through Packetbeat and see if the outcome is as expected. Like this we are able to get files from users with problems and can fully reproduce the problem. In case we fixed a bug, we didn\u2019t have any insights if the specific test covered the code changes except through introducing lots of log messages. Based on this we looked for a simpler solution that allowed us to identify which lines were executed by system tests. Our Test Coverage Reports During the implementation of the test code coverage for the Packetbeat project we faced different challenges which we managed to overcome. Now all our Beats automatically generate a coverage report for unit and system tests. These coverage reports are generated by our continuous integration system for each pull request and are published. An excerpt of one of these reports can be seen below. The report does not only show us which lines were executed and which not, but also the number of times each line was executed. This can be seen by the small number 34 in the screenshot, which means the line above was executed 34 times. The red lines were not executed by the unit or system tests. System Test Coverage Guide The goal of this blog post is to have a guide on how to implement a coverage report for system tests in your own Golang project. If you just want to see it working check out our and repositories. Inside the the command generates all the reports and html outputs. To try it out, one of the repositories and run the command inside the repository. The paragraphs below give a step-by-step description how you can implement a coverage report for system tests in your own Golang project. Step 1: Generating the Binary To run system tests, a compiled binary of the application is required. This binary is then executed in different environments with different configurations. Golang offers a unique way to generate a coverage binary instead of the default binary generated by . The binary for the code coverage which is generated writes a unique counter after every line of code and checks how many times this counter was called after the binary was executed. More technical details on how this works can be found on the . When is executed, this coverage binary is automatically generated again and disposed of afterwards. Golang also allows to generate this coverage binary with the following command: go test -c -covermode=count -coverpkg .\/... The file generated is automatically called . To specify a different value, the param followed by the binary name can be used. The flag is used to generate the test binary and makes sure the binary is generated with coverage counting inside. at the end of the command makes sure the coverage binary is generated for all sub packages under the same path, but not imported packages. If you only want to have the coverage for specific packages, you can list them here separated with a comma. For more details run . Step 2: Create Main Test File Now that we know how to generate the binary, we have to make sure the binary will execute as expected. There are some requirements to your code base for the binary to work as expected. The first one is that there is at least one file in the package. Otherwise the binary is not generated. I recommend to create the file or a testfile with the same filename where your is in. In our case file has the following content: package main \/\/ This file is mandatory as otherwise the filebeat.test binary is not generated correctly. import ( \"testing\" \"flag\" ) var systemTest *bool func init() { systemTest = flag.Bool(\"systemTest\", false, \"Set to true when running system tests\") } \/\/ Test started when the test binary is started. Only calls main. func TestSystem(t *testing.T) { if *systemTest { main() } } The file defines a flag and contains a single test case which calls the main function. Running the test binary starts to execute the tests. In our case this means is called as this is the only test. Running means calling which starts the application as the normal binary would. This means running the test binary is identical to running the normal binary except that the lines executed are tracked. To prevent this test from running when the unit tests are running, the command line flag was added. In case it is not set, the function will not be called. To run the system tests, the flag must be set by appending during the execution of the test binary. Step 3: Global Command Line Flags In order to define different test environments for the system tests, using the command line flags is often quite important. Before the implementation of the system test coverage we used to keep flags as local as possible. Unfortunately with the coverage binary these didn't work as expected. For the test binary, all flags must be known before the execution of the tests. If a flag is defined during the execution of a test, the test binary will complain during startup that the flag is not defined. An example is shown below: $ .\/packetbeat.test -undefinedFlag flag provided but not defined: -undefinedFlag To make the command line flags work with the test binary, make sure that the required flags are defined as part of the main FlagSet and are defined outside methods and functions. It can be either done directly during the assignment of variables or as part of the functions which are called before starting the test. Here an example from : var configDirPath string \/\/ Init config path flag func init() { flag.StringVar(&configDirPath, \"configDir\", \"\", \"path to additional filebeat configuration directory with .yml files\") } To ensure your flags work correctly be sure to follow the rule above. Also make sure that your application flags do not conflict with the golang test flags. Verify that all your flags are part of the test binary by running . A list similar to the example below will be printed out. This list will include the golang test flags. $ .\/packetbeat.test -h Usage of .\/packetbeat.test: -I string file -N Disable actual publishing for testing -O Read packets one at a time (press Enter) -c string Configuration file (default \"\/etc\/beat\/beat.yml\") -cpuprofile string Write cpu profile to fil ... Step 4: Test your Binary To see if your binary works as expected, you can execute it manually and generate coverage data. For Packetbeat, it looks like this: packetbeat.test -systemTest -c config.yml -test.coverprofile coverage.cov The flag is used to start the main test as was discussed before. The flag is a Packetbeat specific flag which is required. Make sure to put all application specific flags before the test flags. The flag is a standard flag of the test binary and defines to which file the coverage output should be written. After running the binary with the command above, a file is generated in the same directory where the binary was executed. If no was generated then check if the binary actually started or if there were any errors in the output. The content generated in the files should look similar to: mode: count github.com\/elastic\/packetbeat\/sniffer\/pfring_stub.go:27.43,29.2 1 0 github.com\/elastic\/packetbeat\/sniffer\/pfring_stub.go:31.32,32.2 0 0 github.com\/elastic\/packetbeat\/packetbeat.go:72.13,82.2 1 1 github.com\/elastic\/packetbeat\/packetbeat.go:84.47,87.2 1 1 ... Step 5: Setup System Tests Additional code is needed to test the binary with various inputs and validate the outputs. In our case we created a small system test framework in Python. Any other language that can execute binaries and that fits you could be used for this. In the case of and , our test framework generates a new directory for each test where the log output of the test binary is recorded, where the input and output of the test binary are copied, and where the coverage report is stored. This makes it really simple to debug a failing test as all the information exists. The code of our test framework and the tests can be found . To get started with your system test framework, the first tests can also be executed manually and the outputs can be verified. Based on what you learn from the manual testing it can be better evaluated what the requirements are for the system test framework. For Packetbeat the system test framework was already in place before the system test coverage implementation as these tests were also run without the coverage. To add the coverage test binary only a change of the command line flags was necessary. If you already have a system test framework in place, it can probably be adapted to implement the coverage. If not, find the best way for you and your team to implement these executions. Step 6: Collect and Convert Coverage After running the test binary for all system tests, many different files exist. For the overall coverage report all the files from the system tests must be collected and merged into one file. This can be done with the following commands: mkdir coverage echo 'mode: count' > .\/coverage\/system.cov tail -q -n +2 .\/coverage\/*.cov >> .\/coverage\/system.cov The coverage reports are stored in the coverage directory which is created first. A file is generated which will contain all coverage reports. On top of each coverage file, the mode must be listed. In all our cases we use . As all reports also have this line on top, all the content of the files is aggregated ignoring the first line. In our case we use the command for this, which reads the full file starting at the second line. To make this file more human readable, Golang provides the which can convert the output to an HTML file. To generate the HTML file, run the following command: go tool cover -html=.\/coverage\/system.cov -o coverage\/system.html This generates the full coverage report in the file and makes it available to view in the browser. Conclusion In our case we now have a framework that runs our system tests on Windows, Linux and OS X and directly reports the coverage. The test binary created above can be executed in all cases where the normal binary is used, and it also generates a coverage report. It can even be used to run an application with some test traffic for a few minutes and then check what parts of the applications were executed. Microservice Environment Coverage Reports As Golang is a popular language for Microservices, having coverage reports for binaries offers an additional opportunity. Microservices are a suite of independently deployable services. To test if multiple Microservices work together as intended, a full environment with multple Microservices has to be started. This environment is then tested by sending requests to the services and monitoring the output. Then the output is compared with the expected outcome. Unfortunately the only indication on which parts of each Microservice were executed during these tests are logging and monitoring information. No detailed insight into which lines of code were executed exists. With the coverage test binary it is possible to gain these insights. Instead of testing one binary as we described in the guide above, during the Microservice environment tests multiple binaries are executed. With the coverage test binary, it is possible to have a coverage report for each Microservice running in the test environment. The only change needed to generate the report is to create a coverage test binary for each Microservice. This binary is then run inside the test environment instead of the standard binary. After the tests the coverage reports from each Microservice must be collected and processed as described in Step 6. This method allows to gain detailed insights into which services were run and which lines of code were executed during the tests. Based on this information each Microservice can be improved Multiple Coverage Files In our environment we run unit, integration, and system tests which all report coverage. For each test type we generate a separate coverage and html file. To also have a report which combines all these individual reports, we run the same command to aggregate the coverage files and generate a coverage file. This gives us a complete overview of which lines of code are covered by our different test suites. If you run the coverage report for larger applications or for longer times, be aware that the coverage reports can get quite large. Next Steps We use the same test framework for all of our Beats projects. Next we plan to refactor and extract the testing framework part so improvements from one project don't have to be copied to all the other projects. This could make it possible that the framework can also be used for other Golang projects to provide system test coverage and make the setup simpler. Contributions here are more than welcome. If you have questions, in the Elastic forum under the . \n"}<br>{"index": {"_id": 897}}<br>{"title":"Where in the World is Elastic? - Elastic{ON}Tour Amsterdam","seo_title":"Where in the World is Elastic? - Elastic{ON}Tour Amsterdam","url":"\/blog\/witwies-elasticontour-amsterdam","author":{"name":"Megan Wieling"},"date":"September 28, 2015","category":"","locales":"","content":" Welcome to October is coming to an end!\u00a0Check out which Elastic events and meetups are happening near you this week.\u00a0Upcoming Events October 26\u00a0- 27:\u00a0October 29: October 29:\u00a0 October 26: Upcoming Meetups October 26: October 27: October 28: October 29:\u00a0 October 27: October 28: October 26: Please note that not all the meetups posted here\u00a0are sponsored or organized\u00a0by Elastic, but we are all about supporting the community and bringing together those\u00a0who are talking about Elastic. That's it for this week. Stay tuned next week for more Elastic happenings.- The Elastic Team P.S. if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 898}}<br>{"title":"Where in the World is Elastic? - DevRelCon 2015 and Strata + Hadoop World NY","seo_title":"Where in the World is Elastic? - DevRelCon 2015","url":"\/blog\/witwies-devrelcon-2015-strata-hadoop-world-ny","author":{"name":"Megan Wieling"},"date":"September 28, 2015","category":"","locales":"","content":" Welcome to September is almost coming to an end and October is almost here.\u00a0Check out the\u00a0Elastic\u00a0events and\u00a0meetups\u00a0happening near you\u00a0this week.Upcoming Events September 30:\u00a0 September 29 - October 1: Upcoming MeetupsSeptember 29: September 30: That's it for this week. Stay tuned for Elastic happenings next week! - The Elastic Team P.S. if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 899}}<br>{"title":"Building Dashboards Using Data from the Federer & Djokovic Tennis Rivalry","seo_title":"Building Dashboards Using Data from the Federer & Djokovic Tennis Rivalry","url":"\/blog\/building-dashboards-using-data-from-the-federer-&-djokovic-tennis-rivalry","author":{"name":"Jurgen Altziebler"},"date":"September 28, 2015","category":"Engineering","locales":"","content":" As a double nerd who likes data viz and tennis, it wasn't long before I wondered what I would discover if I loaded tennis data into our popular open source products Elasticsearch, Logstash and Kibana. The Federer & Djokovic rivalry is one of the biggest in tennis, with a record breaking 42 matches and counting. As of September 2015, they are dead even at 21-21. Roger Federer won the first match in Monte Carlo in 2006 and he pretty much kept the upper hand until 2010. Djokovic kept improving and in 2011 he had his first blockbuster year, winning 3 out of 4 grand slams. Things were getting tighter and tighter between the two players. Djokovic won the last encounter in the final of the US Open 2015 in New York. Federer won 49.7% of all points played and lost. In tennis, a few points can mean the difference between winning the trophy or taking second place. It doesn\u2019t matter if we visualize serious data for work or play. \u00a0Here are some quick tips for your dashboards: Now back to the tennis data! The Federer\/Djokovic rivalry really heated up in the last four years, so we\u2019ll take a look at that data. They played 19 times in the last four years, with Djokovic winning 12 out of 19 matches. \u00a0What hurts most for Federer fans is that Djokovic won 4 out of 5 grand slam encounters. No doubt that Federer, Djokovic and Nadal will go down as some of the most successful players in history, winning over 40 combined grand slams. This is a new dashboard from the same data set. \u00a0These are all of Federer\u2019s matches from the last four years- 310 matches in total. Federer won 83% of all matches played. Although he is in his mid-thirties, his results are still impressive. And for extra kicks, this dashboard shows Roger Federer vs Rafael Nadal in the last four years with the Kibana dark theme. Enjoy your data and tell great stories! \n"}<br>{"index": {"_id": 900}}<br>{"title":"Avoiding Traps, Enjoying the Cheese as Mouseflow Uses Elasticsearch","seo_title":"Avoiding Traps, Enjoying the Cheese as Mouseflow Uses Elasticsearch","url":"\/blog\/avoiding-traps-enjoying-the-cheese-as-mouseflow-uses-elasticsearch","author":{"name":"Lasse Schou"},"date":"September 25, 2015","category":"User Stories","locales":"","content":" In 2015, the number of worldwide Internet users will surpass 3 billion and include nearly\u00a040% of the world\u2019s population (source: eMarketer). In analytics, the key to success is having data and knowing what to do with it. Our product, , is a website analytics tool that replays visitor\u00a0behaviour\u00a0(session replay) and generates heat maps showing where visitors click, move their mouse, scroll, interact, and are physically located. We collect more data from more clients than ever before and scalability is one of our top priorities.Our product is installed onto a website via a snippet of JavaScript which, collectively, captures\u00a0billions of events each month. These events are stored and analysed to reconstruct a full\u00a0session as it occurred, showing the who, what, where, and when of pertinent activity. This\u00a0enables clients to make informed decisions about their site: understanding problems, building\u00a0solutions, and deploying fixes.Tackling Scalability Issues as New Accounts Stream InIn the beginning, we used a sharded SQL-based database cluster for storage. This served quite well because our clients were mainly small and medium businesses. After a short time, bloggers wrote reviews and our clients started to refer others. This resulted in a stream of new accounts, some of them enterprise clients tracking millions of events, which stretched the limits of our platform. It became clear that, with growing message queues and data that wasn\u2019t easy to sort or filter, it was time for a change.We searched for a distributed and redundant database system known for performance and\u00a0found Elasticsearch. We installed it and started directing copies of inbound events to the\u00a0cluster. After a few days, we wrote more complex queries and refined our views even further. It was clear that we were onto something: common queries like \u201cfind all the sessions from\u00a0facebook.com, using an iPhone, who abandoned checkout\u201d (which previously took a long time\u00a0unless we had indices for that exact search) now took less than 1 second to execute. Our\u00a0freetext search operations were also, naturally, vastly improved.Clearly Onto Something After Installing ElasticsearchAfter further use, Elasticsearch started to show its numerous benefits:First, Elasticsearch is distributed and redundant, meaning our platform is more reliable and data is safer. We have other data stores used for storage and backup but, since uptime is so important, having redundancy in the search layer is key.Second, Elasticsearch is based on\u00a0Lucene\u00a0which ensures that free text search operations are much faster. This benefits clients who search multiple unknowable terms and expect results in milliseconds.Third, Elasticsearch has built-in support for aggregations which means we can query data in a more consumable format (used in most of our reports).These benefits free up developer resources, giving us the flexibility to focus on our product instead of operations tasks. In the last two weeks, we launched The New Mouseflow (our fully revamped user interface with tons of new features) and onboarded over 12,000 private beta users. This would not have been possible without tackling our own scalability issues which, in large part, were solved by moving to Elasticsearch. If your project has similar requirements, we highly recommend taking Elasticsearch for a test-drive.Lasse Schou is the CEO of Mouseflow, a Denmark-based SaaS tool for performing web analytics and real-time user studies on websites. Lasse has been working with tech start-ups since 2002 and started Mouseflow in 2010 where he saw a need for visualizing online user behavior. Mouseflow is now serving over 45,000 customers in 160 countries and is using Elasticsearch to deliver big-data analysis in real-time.[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal<\/w:View> <w:Zoom>0<\/w:Zoom> <w:TrackMoves><\/w:TrackMoves> <w:TrackFormatting><\/w:TrackFormatting> <w:PunctuationKerning><\/w:PunctuationKerning> <w:ValidateAgainstSchemas><\/w:ValidateAgainstSchemas> <w:SaveIfXMLInvalid>false<\/w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false<\/w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false<\/w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF><\/w:DoNotPromoteQF> <w:LidThemeOther>EN-US<\/w:LidThemeOther> <w:LidThemeAsian>JA<\/w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE<\/w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables><\/w:BreakWrappedTables> <w:SnapToGridInCell><\/w:SnapToGridInCell> <w:WrapTextWithPunct><\/w:WrapTextWithPunct> <w:UseAsianBreakRules><\/w:UseAsianBreakRules> <w:DontGrowAutofit><\/w:DontGrowAutofit> <w:SplitPgBreakAndParaMark><\/w:SplitPgBreakAndParaMark> <w:EnableOpenTypeKerning><\/w:EnableOpenTypeKerning> <w:DontFlipMirrorIndents><\/w:DontFlipMirrorIndents> <w:OverrideTableStyleHps><\/w:OverrideTableStyleHps> <\/w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\"><\/m:mathFont> <m:brkBin m:val=\"before\"><\/m:brkBin> <m:brkBinSub m:val=\"&#45: -\"><\/m:brkBinSub> <m:smallFrac m:val=\"off\"><\/m:smallFrac> <m:dispDef><\/m:dispDef> <m:lMargin m:val=\"0\"><\/m:lMargin> <m:rMargin m:val=\"0\"><\/m:rMargin> <m:defJc m:val=\"centerGroup\"><\/m:defJc> <m:wrapIndent m:val=\"1440\"><\/m:wrapIndent> <m:intLim m:val=\"subSup\"><\/m:intLim> <m:naryLim m:val=\"undOvr\"><\/m:naryLim> <\/m:mathPr><\/w:WordDocument> <\/xml><![endif][if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\"><\/w:LsdException> <\/w:LatentStyles> <\/xml><![endif][if gte mso 10]> <style> \/* Style Definitions *\/ table.MsoNormalTable {mso-style-name:\"Table Normal\": mso-tstyle-rowband-size:0: mso-tstyle-colband-size:0: mso-style-noshow:yes: mso-style-priority:99: mso-style-parent:\"\": mso-padding-alt:0cm 5.4pt 0cm 5.4pt: mso-para-margin:0cm: mso-para-margin-bottom:.0001pt: line-height:115%: mso-pagination:widow-orphan: font-size:11.0pt: font-family:Arial: color:black: } <\/style> <![endif]StartFragment EndFragment \n"}<br>{"index": {"_id": 901}}<br>{"title":"Kibana 4.2 beta 2: The dark side of the moon","seo_title":"","url":"\/blog\/kibana_4.2_beta2","author":{"name":"Rashid Khan"},"date":"September 24, 2015","category":"News","locales":"","content":" Kibana 4.2 is almost here. Any day now. Just around the corner. Wait for it\u2026or don\u2019t. Why wait? Who likes waiting? I don\u2019t. Instant gratification awaits within. It can be yours, today. Now. Right now. , and to go with it, right now. You are young and life is long and there is time to kill today, so read on for the \u201cdeets\u201d as the kids like to say. At least I think they say that, right? \u00a0 Kibana now supports WMS map servers, and thus no longer needs internet access for tile map visualizations. That said, you\u2019ll need to supply your own tiles if you\u2019re going that route, but there\u2019s also a plethora of totally open WMS servers out there. \u00a0 No one more blinding NOC screens! The dashboard now has a switch to turn out the lights! Great for status dashboards in dark rooms. I mean, not literal dark rooms, not photo negative processing friendly, but you probably know that if you\u2019re developing film in your closet. We\u2019ve fixed lots of bugs with importing and exporting objects, scripted fields, and complex dashboard performance. And of course, there\u2019s more to come, but don\u2019t let that stop you from trying out Kibana 4.2 beta 2 today! Ok, there it is! Enjoy! As always, with issues, suggestions and contributions. Or, if you love IRC like we do, join us in #kibana on Freenode. You can also find us at \n"}<br>{"index": {"_id": 902}}<br>{"title":"The Road to a Better User Search Experience","seo_title":"","url":"\/blog\/road-to-a-better-user-search-experience","author":{"name":"Shawn Anderson"},"date":"September 24, 2015","category":"User Stories","locales":"","content":" As one of the world's largest third party logistics (3PL) providers, (CHR) deals with a lot of data. We provide freight transportation and logistics, outsource solutions, produce sourcing, and information services to over 46,000 customers through a network of offices in North America, South America, Europe and Asia. To meet our customers' freight needs, we provide access to over 66,000 transportation providers worldwide. Accessing Shipment DataIn 2014, CHR handled approximately 14.3 million shipments. The transactional data supporting those shipments is represented by multiple terabytes of SQL data. In order to make the best decisions for our customers, our networks need access to this information as quickly as possible. As shipment volume increases and customer search requirements mature, we run into roadblocks with traditional SQL queries. For example: Elasticsearch has helped C.H. Robinson get past these roadblocks and opened new doors to providing an enjoyable user search experience.\u00a0 Dipping Our Toes in ElasticsearchOur first challenge was getting our SQL data into Elasticsearch. Fortunately, we had recently completed a service bus initiative - it was the perfect fit for building a pipeline of data into Elasticsearch. As data changes come in from different sources, notifications are sent out to be picked up by load processes. These processes gather the relevant SQL data for searching and forward it on to Elasticsearch. This solved the day-to-day operations, giving us \"near real-time\" data for searching.The second problem to solve was bulk loading SQL data to backfill into Elasticsearch. We explored Rivers - both JDBC and RabbitMQ (the backbone of our service bus). But with the deprecation of Rivers and some of the problems they presented, we opted to build a custom bulk load process to ensure we could control the load on both sides of the pipeline. Initially, we used a distributed, multi-threaded approach, but quickly ran into . We increased the bulk threadpool queue size slightly (200), and throttled our bulk inserts to a more manageable level. This solved our initial data load problem and gave us a push button \"rebuild this index\" when needed.With all this data now funneling into Elasticsearch, we were free to create much richer user search interfaces, including:\u00a0 The future of Elasticsearch @ C.H. RobinsonOne of the biggest challenges when moving to Elasticsearch is understanding user search expectations, and explaining what Elasticsearch relevancy means to your stakeholders. Users don't want to read , they just want to know why certain results are or are not being returned. This has been a challenge, because we have so many search use cases in different parts of the organization. However, initial reaction from our users on new search capabilities has been great, and we've already been able to iterate on feedback to improve our queries. Some improvements we\u2019ve made include: It's clear we're only seeing the tip of the iceberg in terms of potential use cases and problems that Elasticsearch might help solve. Partnering with Elastic has given us a great starting point, assisting us in building out a search cluster that meets our initial use cases and data needs, with room for growth. If Elasticsearch were a video game, it would definitely follow - easy to learn, hard to master. As we look to the future, we hope to utilize many more features of Elasticsearch such as: \n"}<br>{"index": {"_id": 903}}<br>{"title":"Getting Started with ELK","seo_title":"Getting Started with ELK","url":"\/blog\/getting-started-with-elk","author":{"name":"Asawari Samant"},"date":"September 23, 2015","category":"Engineering","locales":"","content":" Are you a new user looking for easy-to-use examples to get started with the ELK Stack (Elasticsearch, Logstash, and Kibana)? Or perhaps you're a not-so-new user looking for starter code to ingest standard logs (e.g., Nginx access logs, Twitter feed, etc.) and don't want to write a Logstash config file from scratch. We are thrilled to announce a new and improved in GitHub where we will share easy-to-use examples for getting started with Elasticsearch, Logstash and Kibana, i.e. . So, what's in an example?The objective of each example is simple: \u00a0To give you everything you need to go from raw data to an\u00a0insightful (and pretty) Kibana dashboard in a few easy steps. While the exact contents of each example may vary slightly, in general, each will include sample data (or instructions to obtain the data), a Logstash config file for ingest, custom Elasticsearch mapping\/template files, and Kibana files to load pre-built dashboards. And, of course, detailed instructions on how to download and run the example. \u00a0We have intentionally kept the structure and content simple and crisp to optimize the download-and-play experience. That said, if you have suggestions on how we can improve these further, we are eager to listen via , or . ContributingAt Elastic, we are all about sharing with \u2014 and learning from \u2014 our vibrant user community. Every day we are amazed by the new and fascinating ways in which our users are pushing the boundaries with our products. We would love to see that awesomeness shared in this example repo. If you have an example (however simple or complex) to share, simply in the GitHub repo with a short description of your example and we will work with you to package it and make it available to others to enjoy. The is laid out in the repo ReadMe. Don't have an example, but have an idea or suggestion for the demos team at Elastic? We are all ears! Once again, to let us know. While we may not be able to get to all of them, we promise to do our best. Give it a try!We hope you enjoy this new project, and we look forward to seeing your awesome contributions in the repo soon! \n"}<br>{"index": {"_id": 904}}<br>{"title":"From Online Retailer to Geographically Distributed Marketplace \u2013 with Elastic","seo_title":"From Online Retailer to Geographically Distributed Marketplace \u2013 with Elastic","url":"\/blog\/from-online-retailer-to-geographically-distributed-marketplace-with-Elastic","author":{"name":"Jean-Michel Gaud"},"date":"September 23, 2015","category":"User Stories","locales":"","content":" In late 2011, joined the myriads of hopeful dot-com billionaires by launching an e-commerce start-up with the aim of revolutionising the floral industry. While our initial website contained a few advanced B2B features specifically developed for the florist industry, it remained a largely stock-standard e-commerce implementation. It\u2019s hard to remember a world without e-commerce. Almost any product nowadays can be purchased over the internet and delivered to one\u2019s home \u2013 flowers are no exception. For merchants, creating an online presence is now easier than ever. There are a plethora of providers who offer feature-rich out-of-the-box e-commerce solutions. Some of these solutions can be set up and made ready to transact in minutes. For the SME (subject matter expert)\u00a0who requires a deeper level of customisation, there are free open-source frameworks that can be modified and scaled to enterprise levels with relative ease. The mass proliferation of e-commerce technology and its subsequent mass adoption have led to a situation, at least in our sector, where the e-commerce \u2018space\u2019 is heavily saturated. Consumers now have more providers to choose from than ever. On the other hand, differentiation between competing providers remains low. The South African online flower market is dominated by a single incumbent who, until fairly recently, remained largely unchallenged. Over the years, competitors have entered the market but none have managed to make any waves big enough to seriously challenge the incumbent\u2019s hold. Towards a Marketplace In 2014, SA Florist secured a seed series funding investment of ZAR 3 million (roughly 350000 USD) from the South African franchise of Dragons\u2019 Den. This allowed us to ramp up our operations. What\u00a0followed\u00a0was\u00a0a complete overhaul of our business model, heavily relying on Elastic to enable this rapid change. We realised that if we wanted to become a serious player in the market, we couldn\u2019t do things the same way as our competitors. We would have to differentiate ourselves and offer consumers a far better value proposition. After much research, and encouraged by the high-profile successes of companies such as Uber and Airbnb, we decided to pivot our business from an online retailer into a geographically distributed marketplace. Why Elastic Elastic was the obvious choice of technology to power our marketplace. Several factors led to this decision: In a .NET Environment As a company that uses a Microsoft .NET \/ ASP.NET \/ C# \/ MVC \/ SQL Server based web application technology stack, integrating and working with Elastic as a data source is a pleasure. Where are you sending to? As I mentioned earlier, our initial website contained a few advanced B2B features specifically developed for the florist industry. These B2B features allow florists (or other retailers who can\u2019t ship their products nationally) to take orders in their shops for distant areas, and relay them to a florist nearby the recipient. We extended the data structure underlying the B2B system, by adding to our code, a layer of JSON serializable data objects. The data objects were given a geo_point property that corresponds to the physical location of the florists\u2019 shops. We then built an index management utility to CRUD our objects. A bit of MVC\u2019ing later and voila! \u2013 a geographically distributed flower marketplace. In order to filter by distances, Elastic needs geo coordinates, so we used Google\u2019s APIs and an auto-complete lookup to verify and pinpoint customers' street addresses. Version 1.0 of the marketplace took us about a month to take\u00a0live. It took the time of two developers to accomplish this. Features we Love \"We highly recommend Elastic. It has allowed us to transform our business in\u00a0record time with minimal resources\" - Jean Michel Gaud, Senior Developer, SA Florist. [if gte mso 9]><xml> <w:WordDocument> <w:View>Normal<\/w:View> <w:Zoom>0<\/w:Zoom> <w:TrackMoves><\/w:TrackMoves> <w:TrackFormatting><\/w:TrackFormatting> <w:PunctuationKerning><\/w:PunctuationKerning> <w:ValidateAgainstSchemas><\/w:ValidateAgainstSchemas> <w:SaveIfXMLInvalid>false<\/w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false<\/w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false<\/w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF><\/w:DoNotPromoteQF> <w:LidThemeOther>EN-US<\/w:LidThemeOther> <w:LidThemeAsian>JA<\/w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE<\/w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables><\/w:BreakWrappedTables> <w:SnapToGridInCell><\/w:SnapToGridInCell> <w:WrapTextWithPunct><\/w:WrapTextWithPunct> <w:UseAsianBreakRules><\/w:UseAsianBreakRules> <w:DontGrowAutofit><\/w:DontGrowAutofit> <w:SplitPgBreakAndParaMark><\/w:SplitPgBreakAndParaMark> <w:EnableOpenTypeKerning><\/w:EnableOpenTypeKerning> <w:DontFlipMirrorIndents><\/w:DontFlipMirrorIndents> <w:OverrideTableStyleHps><\/w:OverrideTableStyleHps> <\/w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\"><\/m:mathFont> <m:brkBin m:val=\"before\"><\/m:brkBin> <m:brkBinSub m:val=\"&#45: -\"><\/m:brkBinSub> <m:smallFrac m:val=\"off\"><\/m:smallFrac> <m:dispDef><\/m:dispDef> <m:lMargin m:val=\"0\"><\/m:lMargin> <m:rMargin m:val=\"0\"><\/m:rMargin> <m:defJc m:val=\"centerGroup\"><\/m:defJc> <m:wrapIndent m:val=\"1440\"><\/m:wrapIndent> <m:intLim m:val=\"subSup\"><\/m:intLim> <m:naryLim m:val=\"undOvr\"><\/m:naryLim> <\/m:mathPr><\/w:WordDocument> <\/xml><![endif] [if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\"><\/w:LsdException> <\/w:LatentStyles> <\/xml><![endif] [if gte mso 10]> <style> \/* Style Definitions *\/ table.MsoNormalTable {mso-style-name:\"Table Normal\": mso-tstyle-rowband-size:0: mso-tstyle-colband-size:0: mso-style-noshow:yes: mso-style-priority:99: mso-style-parent:\"\": mso-padding-alt:0cm 5.4pt 0cm 5.4pt: mso-para-margin:0cm: mso-para-margin-bottom:.0001pt: line-height:115%: mso-pagination:widow-orphan: font-size:11.0pt: font-family:Arial: color:black: } <\/style> <![endif] StartFragment EndFragment \n"}<br>{"index": {"_id": 905}}<br>{"title":"This Week in Elasticsearch and Apache Lucene - September 22 2015","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-09-22","author":{"name":"Michael McCandless"},"date":"September 22, 2015","category":"","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsElasticsearch requires less disk than you may think: even less in 2.0 with best_compression! \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 906}}<br>{"title":"Where in the World is Elastic? - Percona, JDuchess","seo_title":"","url":"\/blog\/witwies-percona-jduchess","author":{"name":"Megan Wieling"},"date":"September 21, 2015","category":"","locales":"","content":" Welcome to Find out\u00a0what September has in store for you and check out the\u00a0Elastic\u00a0events and\u00a0meetups for this week.Upcoming Events September 21 - 23:\u00a0 September 22: \u00a0 Upcoming Meetups September 22: September 23: September 24: September 21: September 23: September 24: September 24: September 24:\u00a0\u00a0That's it for this week. Stay tuned for Elastic happenings next week! - The Elastic Team P.S. if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 907}}<br>{"title":"Hope to see you {ON} tour this Fall","seo_title":"","url":"\/blog\/hope-to-see-you-on-tour-this-fall","author":{"name":"Shay Banon"},"date":"September 21, 2015","category":"News","locales":"","content":" It\u2019s been almost 6 months since our first user conference -- -- and while we were able to bring together 1,000+ people in San Francisco, many of you have been waiting for us to come on tour and visit a city near you.As our community has grown to around the globe, I\u2019ve always felt that events like meetups, user conferences, and city tours are important to engage our community, foster new friendships, learn and share new ideas, and for you to hear from us as to what we\u2019re working on and how you can get involved.So starting this October and through December, the team at Elastic will be hitting the road across 12 cities in the U.S., EMEA and Asia. After a short break for the holidays, we\u2019ll be hosting our in San Francisco at Pier 48 from February 17 - 19 2016, so please save this date in your calendar as we\u2019ll be doubling this event in size and content. Based on lots of great feedback from the community, each tour stop will have a full-day of content, and will include products technical deep dive and roadmap covering Apache Lucene, Elasticsearch, Kibana, Beats, Logstash and Hadoop. Our customers and users will share their use cases ranging from search, logging, analytics, and more. By popular request, there will be an Ask Me Anything (AMA) booth open for the entire day for anyone to ask our developers any questions they want!Lastly, I\u2019m personally excited that 100% of the registration proceeds (approx $75 USD per ticket) will be\u00a0donated to local charities. Thanks to all of you, you\u2019ve helped us build a wonderful community, and I want everyone to know that they in addition to helping us build better products, by attending our tour events, you\u2019re helping others, such as: I can\u2019t wait to see you either on tour or in San Francisco at Elastic{ON} 16. as we already have more than 1,600 people registered and are nearing capacity for many of our cities. As always, if you have a great story to tell, don\u2019t forget to !\u00a0 \n"}<br>{"index": {"_id": 908}}<br>{"title":"Elasticsearch 2.0.0-beta2 released","seo_title":"Elasticsearch 2.0.0-beta2 released","url":"\/blog\/elasticsearch-2-0-0-beta2-released","author":{"name":"Clinton Gormley"},"date":"September 17, 2015","category":"News","locales":"","content":" Today, we are happy to announce the release of , based on . This is the last planned beta release before the 2.0.0 release candidate. : This is a beta release and is intended for testing purposes only. Elasticsearch 2.0.0-beta2 is not compatible with 2.0.0-beta1, and there is no guarantee that Elasticsearch 2.0.0-beta2 will be compatible with Elasticsearch 2.0.0 GA.\u00a0 You can . Thank you to those of you who tested out 2.0.0-beta1 and reported problems. The changes in Elasticsearch core since 2.0.0-beta1 consist mostly of bug fixes and tidy ups. Our commercial plugins, however, deliver some important new features in this release, which you can read about in . \u00a0The highlights are as follows: \n"}<br>{"index": {"_id": 909}}<br>{"title":"Shield and Watcher 2.0.0-beta2 released","seo_title":"Shield and Watcher 2.0.0-beta2 released","url":"\/blog\/shield-and-watcher-2-0-0-beta2-released","author":{"name":"Uri Boness"},"date":"September 17, 2015","category":"News","locales":"","content":" Today, we are happy to announce the releases of . These are the last planned beta releases before the 2.0.0 release candidates. These are beta releases and are intended for testing purposes only. There is no guarantee that either Shield or Watcher 2.0.0-beta2 will be compatible with their respective 2.0.0 GA. Shield This release comes with some exciting new features in Shield. When it comes to securing your data in Elasticsearch, one of the more commonly requested features is the ability to define access control on documents and fields. With Shield 1.x, you could simulate document level security using a combination of filtered aliases and index level permissions per role. While this approach works for some cases, there are certainly cases where this becomes unmanageable (due to the number of aliases and roles one needs to define). Furthermore, it is not a bulletproof solution as it doesn\u2019t work for some of the APIs (e.g. parent\/child searches), and it doesn\u2019t provide any form of field level security. We are delighted to announce that will be a first class feature in Shield 2.0 and is introduced in this beta2 release. What does being a \u201cfirst class feature\u201d mean? Well\u2026 it is no longer bound to index aliases. Instead, you can define what documents and fields are accessible by role as part of the role definition. For field level access control you can now specify a list of accessible fields per index. For document level access control you can specify a query per index. These two together effectively create a filtered view of the index prior to any search executed by users with the relevant roles. The following snippet shows what the configuration may look like as part of the role definition: With the above role definition, users with the us_customer_care role will only have read access to help desk issues for customers in the US, and this read access is limited to a 4 fields - , , , and . All other fields will be treated as non-existent for this user and attempting to search on those will yield no results. You can read more about Document and Field level security . Another feature we\u2019ve added in this release is support for . With this support, it is now possible to enable a user to impersonate other users and by that execute requests on their behalf. User impersonation comes in handy when authentication is applied on the application level (outside of Elasticsearch\/Shield), but the authorization should still be applied in Elasticsearch to ensure sensitive data is not compromised. Setting this \u201crun_as\u201d privilege is configured per role definition. As such, a best practice would be to create dedicated \u201crun_as\u201d roles for a set of impersonated users and assign this role to the relevant power users. The following snippet shows an example of such role: The example above uses wildcards to defines a new role that enables users to impersonate any other user with a principal with suffix. You can read more about user impersonation . Last but certainly not least, we\u2019re excited to announce that we\u2019ve opened up Shield for extensions. More specifically, you can now write a custom implementation of an authentication realm and plug it into Shield. If for any reason, you\u2019re forced to use an authentication mechanism that is not supported out-of-the-box by Shield, you can now write your own plugin just for the authentication part and still use all the other goodness Shield has to offer, including the extensive role-based access control over indices, document and fields, secured communication using SSL and IP filtering and of course the tightly integrated audit logging. To read more about extending Shield realms, please read the . We\u2019ve also created an example custom realm to serve as a reference. Watcher One of the more common requests for watcher was the ability to disable watches. Often users define watches to monitor different systems. But there comes a time when you want to consciously bring a system down for maintenance. The problem then is that the monitoring watches continue to execute periodically triggering notification about the monitored system being down. One way to work around this issue is to modify the watch schedule to some remote date in the future, such that it won\u2019t trigger for the duration of the system maintenance. But this is a wrong way to go about it. For this reason, we\u2019ve introduced a new to the watches, and with that, the ability to de\/activate a watch. An inactive watch is a watch that is still stored\/registered with watcher, but is never triggered. You can now proactively deactivate the monitoring watches and keep them inactive as long as you need. Once you\u2019re ready to continue monitoring your system, simply activate the monitoring watches. Read for more information about the in\/active state of a watch. In addition to the above we\u2019ve also added two new actions - and . If you or your organization uses either for internal communication, you can now send notifications to teams\/rooms or to other users directly from watcher. In the spirit of watcher, all messages are templated, enabling sending detailed and rich messages. To read more about about these new actions please refer to and . Closing Note introduces a wide range of new features in both Shield and Watcher. It also includes bug fixes and infrastructure enhancements in both products. Please refer to the release notes of and for a complete change list. If you have any questions or want to share your experience with us and the community, don't by shy and use our dedicated forums: If you haven't tried either of these products yet, don't worry, it's not too late to start. You're welcome to visit the and download pages where you'll be presented with a simple and quick getting started guide. \n"}<br>{"index": {"_id": 910}}<br>{"title":"How Avaaz uses the Elastic Stack to Improve their Production Systems","seo_title":"How Avaaz uses the ELK-stack to solve their logging issues","url":"\/blog\/how-avaaz-uses-the-elk-stack-to-improve-their-production-systems","author":{"name":"Peter Colclough"},"date":"September 17, 2015","category":"User Stories","locales":"","content":" - meaning \"voice\" in several European, Middle Eastern and\u00a0Asian languages - launched in 2007 with a simple democratic mission: organize citizens of all nations to close the gap between the world we have and the world most people everywhere want. Avaaz is a global petitioning site with more than 40 million members which was hitting some particularly interesting issues. Central, at the time, was the fact they were outgrowing their database architecture, and were hitting database access issues. A victim of their own success.The Issue is\u00a0to find out 'Why'\u00a0As we all know, we have logs: we have slow logs, we have Nagios, but all of these don't give the exact information of what a server is doing at any point in time. Briefly, I had come across Lucene three years ago as a 'search engine'. It was being used with Solr by a previous retail client. It was spectacular. At the time I had investigated using mysql-proxy in order to read the actual query metrics directly off the servers, using a hand crafted Lua script attached to Proxy. While never used in anger this was more than helpful in ironing out some database issues ... but we didn't have a sane place to plot the results on a graph and analyze them.Looking back at other ClientsAnother client of mine called Madbits, a startup in image interpretation (a dark art like no other ), had issues with a MongoDB setup, and also retrieving information in anything close to a reasonable time for a web site. Part of the issue was down to MongoDB, and the way it had been set up (never, ever, just have a single unit... not designed for that). After scaling out Mongo we had stunning results, but we then had issues with 'user generated tags'. Enter Lucene. We immediately faced a challenge in trying to use it. MongoDB stores documents in Bson (a binary json format) but Lucene uses Java objects. We could do the conversion our selves, but instead discovered Elasticsearch. We could flip documents between MongoDB and Elasticsearch with very little, if any changes. Wow! That works. So in came Elasticsearch and later Kibana.However, we also needed to log the DB. So with some handy Logstash parsing, we were able to push Mongo logs into ES using Logstash. We then used Kibana to graph it which was also stunning. Direct insight into the workings of a fully sharded DB (across 3 data centres) in graph form... cool.Introducing Elasticsearch at AvaazAt Avaaz we had issues with MySQL. So we put in mysql-proxy, altered the Lua script to output Json to a file, used Logstash to push into ES, and we were there. Not only did mysql-proxy give us the ability to scale out the slaves, we got actual insight to every query going into each machine. For the record, this now also includes a couple of AWS RDS instances too. We ran up some Kibana-3 dashboards, and the results were astonishing.The only issue we had was the sheer volume of data. We were recording off the live systems, onto a development ES cluster. Initially we were getting in excess of 150m documents per 24 hours on a normal day. On a busy day that could double. Elasticsearch was fine, it consumed with no issues, it was just storage and expansion. So we tweaked the cluster setup, added some more disk (Raid 0,and a reboot - simple), then made the decision to add a _ttl of 1 day\u00a0allowing Elasticsearch to manage the deletion, and built\u00a0a series of aggregation scripts. This enabled us to see the last 24 hours, and have Elasticsearch automatically drop the documents that were too old. The aggregated information helped us see what was happening on a day by day basis, aggregated by the hour. On our new production cluster we are saving 3 days at a time, so we can see what happened at the weekend.What changed?What did this show us? A lot - and please bear in mind that the code was 6 years old, and had been written with an expected size of 10% of current levels. So, using Elasticsearch indices, and Kibana graphs, we were able to query the dataset right the way down to threads.The graphs allow us to zero in on a given spike, so we can easily examine what caused the spike....and solve the issue. This showed, in no particular order:We have since expanded the process. We now graph table hits, allowing us to remove unneeded tables and columns, that were created eons ago, and never removed. We log disk usage by the DB, and actual Disk usage. We are now setting up warnings, as Elasticsearch is so very fast at producing information, we can find 'pinch' points very quickly.What's next?So where next? Avaaz has a particular need to target its audience. In a lot of cases we need to do this geographically. So, while we have some really cunning MySQL queries that will do a 'radius' search, we are now building into our cluster enough data to allow searches\u00a0by radius, shape, members within bounds of city limits. We will then add to that 'types of petition', so if you sign a petition on one type we will be able to produce 'you may also like...' type petitions to look at. All using the search capabilities of Elasticsearch, and the mapping that Kibana 4, using Leaflet JS, produces. How cool will this be? More to come on this when we have it running...[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal<\/w:View> <w:Zoom>0<\/w:Zoom> <w:TrackMoves><\/w:TrackMoves> <w:TrackFormatting><\/w:TrackFormatting> <w:PunctuationKerning><\/w:PunctuationKerning> <w:ValidateAgainstSchemas><\/w:ValidateAgainstSchemas> <w:SaveIfXMLInvalid>false<\/w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false<\/w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false<\/w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF><\/w:DoNotPromoteQF> <w:LidThemeOther>EN-US<\/w:LidThemeOther> <w:LidThemeAsian>JA<\/w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE<\/w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables><\/w:BreakWrappedTables> <w:SnapToGridInCell><\/w:SnapToGridInCell> <w:WrapTextWithPunct><\/w:WrapTextWithPunct> <w:UseAsianBreakRules><\/w:UseAsianBreakRules> <w:DontGrowAutofit><\/w:DontGrowAutofit> <w:SplitPgBreakAndParaMark><\/w:SplitPgBreakAndParaMark> <w:EnableOpenTypeKerning><\/w:EnableOpenTypeKerning> <w:DontFlipMirrorIndents><\/w:DontFlipMirrorIndents> <w:OverrideTableStyleHps><\/w:OverrideTableStyleHps> <\/w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\"><\/m:mathFont> <m:brkBin m:val=\"before\"><\/m:brkBin> <m:brkBinSub m:val=\"&#45: -\"><\/m:brkBinSub> <m:smallFrac m:val=\"off\"><\/m:smallFrac> <m:dispDef><\/m:dispDef> <m:lMargin m:val=\"0\"><\/m:lMargin> <m:rMargin m:val=\"0\"><\/m:rMargin> <m:defJc m:val=\"centerGroup\"><\/m:defJc> <m:wrapIndent m:val=\"1440\"><\/m:wrapIndent> <m:intLim m:val=\"subSup\"><\/m:intLim> <m:naryLim m:val=\"undOvr\"><\/m:naryLim> <\/m:mathPr><\/w:WordDocument> <\/xml><![endif][if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\"><\/w:LsdException> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\"><\/w:LsdException> <\/w:LatentStyles> <\/xml><![endif][if gte mso 10]> <style> \/* Style Definitions *\/ table.MsoNormalTable {mso-style-name:\"Table Normal\": mso-tstyle-rowband-size:0: mso-tstyle-colband-size:0: mso-style-noshow:yes: mso-style-priority:99: mso-style-parent:\"\": mso-padding-alt:0cm 5.4pt 0cm 5.4pt: mso-para-margin:0cm: mso-para-margin-bottom:.0001pt: line-height:115%: mso-pagination:widow-orphan: font-size:11.0pt: font-family:Arial: color:black: } <\/style> <![endif]StartFragment EndFragment \n"}<br>{"index": {"_id": 911}}<br>{"title":"Logstash 2.0.0 beta1 released","seo_title":"","url":"\/blog\/logstash-2-0-0-beta1-released","author":{"name":"Andrew Cholakian"},"date":"September 16, 2015","category":"Releases","locales":"","content":" If you\u2019ve followed our announcements recently, we have been releasing beta versions for our Elastic products to work with the recent release of Elasticsearch 2.0 beta. Logstash is getting on the too! Read along to find out what\u2019s in this release. This is a beta release and is intended for testing purposes only. There is no guarantee that Logstash 2.0.0-beta1 will be compatible with Logstash 2.0.0 GA. Why version 2.0? We\u2019ll be starting a new chapter in Logstash history with the forthcoming release of Logstash 2.0! This release is primarily about two things: Versioning scheme To provide better out of the box experience with Elasticsearch, we realized we needed to make breaking changes, and our current ad-hoc versioning strategy would not work for users. We would like to adhere to a versioning and release strategy that can better inform you, our users, about any breaking changes to the Logstash configuration formats, plugin APIs and other functionality. Logstash releases follows a three-placed numbering scheme X.Y.Z. where X denotes a major release version which break compatibility with existing configuration or functionality. Y denotes releases which includes features which are backward compatible. Z denotes releases which includes bug fixes and patches. In compliance with this scheme, today, we are releasing a beta1 version of 2.0.0 which introduces some breaking changes you can read about below. If you\u2019ve followed along with our please note that the overall path of our Roadmap remains the same, but only the numbers have changed. Our team is still focused to deliver on the themes mentioned in the Roadmap \u2013 resiliency, manageability and performance. We will target new enhancements like persistent queues as minor versioned releases (like 2.1, 2.2) since they\u2019ll be backwards compatible. The 2.0.0-beta1 release, specifically, will have the following changes: Elasticsearch Output now Defaults to HTTP We\u2019ve altered the Elasticsearch output to now default to HTTP. For those who want to use the \u2018node\u2019 and \u2018transport\u2019 protocols, support for those is now provided in a separate , that must be downloaded separately. We decided to not bundle this functionality with the core Logstash distribution because it adds a good 30MB of size to the download, and creates a weird situation for users wanting to use Elasticsearch 1.x node\/transport. While we have no plans to deprecate support for the node and transport protocols we strongly discourage their use for the reasons below: We will still be supporting both plugins. We have, in fact, performed a major refactor on both plugins to remove dead code and make more efficient use of internal client objects. So, if you still prefer to use the native protocols, by all means install the new plugin. If you want to use these java plugins with Elasticsearch 1.x cluster be sure to install specific versions in the 1.x plugin range. The 2.x releases of will only work with Elasticsearch 2.0. Configuration Changes The Elasticsearch output has a few configuration changes to be compatible with the 2.0 beta1 release of Elasticsearch. Please make sure to read the updated documentation for configuring the and protocols. These configurations are not backward compatible, so you will have to update your existing config files. How We Benchmarked the new HTTP Elasticsearch Output As mentioned above, we recently benchmarked the different protocols and found HTTP was only about 3% slower (when using multiple output workers) given a realistic logstash config for parsing apache weblogs. This is a small price to pay for a considerable improvement in operational simplicity. Moving to HTTP also provides much better compatibility across ES version upgrades. You won\u2019t have to upgrade the logstash Elasticsearch output every time you upgrade your Elasticsearch cluster if you use HTTP. We hit these issues ourselves in our benchmarking, finding that some versions of the new Elasticsearch betas don\u2019t work with the beta jars we ship. The test was setup with a 3-node Elasticsearch cluster running. Each node being a m3.large in a single AZ in us-east-1. There was a single Logstash node running on an m3.large in the same AZ. A variety of were tested to get the numbers below. Note that the HTTP based Elasticsearch output benefits greatly from having multiple set. There is very little reason not to boost up the config for this plugin. As you can see in the chart below, HTTP was slightly slower than the other protocols, but not enough to register much a difference for real world use cases. You can find the raw data backing this chart . If you\u2019re interested in running the benchmarks yourself, you can checkout our git repository and run them yourself. Elasticsearch HTTP Sniffing One of the most common reasons to use the node or transport protocols was that these protocols supported \u2018sniffing\u2019, whereby the Elasticsearch output would be able to connect to all nodes in the cluster in a round robin fashion, and update its list of hosts as members joined or left the cluster. We\u2019ve added sniffing support in to the HTTP plugin giving it these same capabilities. You can define the interval between \u2018sniffs\u2019 with the configuration option, which specifies how long in seconds to wait between sniffs. Optimizations to UserAgent and GeoIP Lookups Logstash is often used to parse logs from webservers such as Apache and Nginx. It is often desirable to perform GeoIP lookups on IP addresses found in these logs and to classify their user agent strings. Both of these operations are surprisingly expensive. Logstash 2.0 will see a large boost in performance parsing these common fields. In the case of the user agent filter we on our sample dataset. In the case of GeoIP we . This was achieved by adding an LRU cache that takes advantage of the clustering of IPs and user agents commonly seen in web requests. We highly recommend playing with the new option for both of these plugins, to see what gives your configuration the best bang for your buck. Keep in mind that larger values will speed up lookups (to a point), at the expense of memory. Kafka Output 2.0 This beta also packages a new version of Kafka output that implements included in the 0.8.2 release of Kafka. Unfortunately, the Logstash config options are not backward compatible with the previous release. If you are using the old version of Logstash output, you will have to update to the . You can still use this output with any 0.8.x Kafka server since the clients itself are protocol compatible. Beta Feedback Give the a spin! If you find any bugs please report them as issues either on the repo or on the appropriate repository. You can also head over to our . We\u2019re excited to release Logstash 2.0, but can\u2019t do it without your help! \n"}<br>{"index": {"_id": 912}}<br>{"title":"This Week in Elasticsearch and Apache Lucene - September 15 2015","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-09-15","author":{"name":"Michael McCandless"},"date":"September 15, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsLooking for some weekend reading? Check out \u2019s primer on \u201cHot-Warm\u201d architecture \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 913}}<br>{"title":"Analyzing Salesforce Data with Logstash, Elasticsearch, and Kibana","seo_title":"Analyzing Salesforce Data with Logstash, Elasticsearch, and Kibana","url":"\/blog\/analyzing-salesforce-data-with-logstash-elasticsearch-kibana","author":{"name":"Russ Savage"},"date":"September 15, 2015","category":"Engineering","locales":"","content":" In the spirit of Dreamforce and being part of Elastic, I\u2019m excited to introduce a new that makes it easy to pull vast amounts of data out of Salesforce and into Elasticsearch. This plugin allows you to query almost any object in Salesforce and pull it into the Logstash pipeline. \u00a0From there, you can output it to your analytics tool of choice (ours is Kibana) to discover insights that you may have missed otherwise. We use it internally to keep an eye on our our sales pipeline and customer health over time.\u00a0 Working directly with sales and marketing operations, we outlined a number of challenges they had that might be solved with this solution. Those included: It\u2019s very challenging to look back in time and see trends in the data. Many companies have configured Salesforce to save reporting snapshots, but if you're like me, you want to see the data behind the aggregate report. I want the ability to drill down to any level of detail, for any timeframe, and find any metric. We found that Salesforce snapshots just aren't flexible enough for that. Logstash already allows users to pull in vast amounts of data from a variety of sources, and with this plugin, we are adding Salesforce as a source. Once the data is in our Elasticsearch cluster, we use Kibana to quickly filter and display the data in ways we couldn't before using Salesforce\u2019s built in reporting. Now, let\u2019s focus on how you can set up the Logstash Input for Salesforce for your own organization. Querying Salesforce from LogstashAs I mentioned earlier, we\u2019ve been using the internally to handle all of this data. We decided others could benefit from this plugin as well so we and made it available for anyone to install using the standard Logstash plugin framework. With a fresh install of the latest Logstash, you should be able to install this plugin with: bin\/plugin install logstash-input-salesforce Based on your configuration, the plugin will query from Salesforce and create an event for each row of data returned. You can then filter and transform the data as needed before\u00a0pushing it to wherever it needs to go. To configure this plugin, we will need to gather some credentials from Salesforce. This involves creating a new in Salesforce and generating a user token. Depending on your Salesforce permissions, you might need to ask your Administrator to do this for you. You should only need to do this once. Here is an example of the minimum information you need to enter. Of course, the scope can be configured as needed but just make sure to give enough access for the sObjects you want to query. Also, for the callback URL, you can just enter localhost since the plugin will be using password authentication. Once you have a new application set up, you will need the Consumer Key and Consumer Secret values, so keep track of those. While you\u2019re in Salesforce, you should also go ahead and generate a token for the username you will be using for authentication. on how to generate or reset your token if you don\u2019t already have one. Now we have everything we need for connecting to Salesforce from Logstash. \u00a0Let\u2019s start with a simple Logstash config that will connect to your sandbox Salesforce instance (test.salesforce.com) and pull in all the Opportunity objects. input { salesforce { use_test_sandbox => true #you are testing in a sandbox right? client_id => 'CONSUMER_KEY_FROM_SALESFORCE' client_secret => 'CONSUMER_SECRET_FROM_SALESFORCE' username => 'you@example.com.sandbox' password => 's3crEt!' security_token => 'SECURITY_TOKEN_FROM_SALESFORCE' sfdc_object_name => 'Opportunity' } } output { stdout { codec => rubydebug } } Here, we are telling the plugin to use the test sandbox, connect with our credentials, and pull in all the Opportunity objects. By default, the input will pull in all the fields for that . If you would only like to see selected fields, you can specify them using the option: sfdc_fields => ['Id','Name','Type','CloseDate'] I like to pull everything in because it gives me the most flexibility later. By default, the input will use the standard Salesforce API Names as the document key fields. If you\u2019d like to normalize them from camel case (e.g. ) to something a little more Logstash like (e.g. ), you can set the option to . For a full list of input options and what they do, check out the . If you want additional loaded into Logstash, for now, you will need to duplicate that config for each object. We are currently pulling in Leads, Contacts, Accounts, Opportunities\u00a0and more using this process. Also, by default, the plugin uses version 26 of the Salesforce API. If you\u2019re using a newer object, you can specify a different api version using the config option. Pushing the Data to ElasticsearchNow that we have the data flowing into Logstash, we can adjust the output to write data wherever we need. For this example, we are going to push the data directly into our cluster using the : output { elasticsearch { index => \"salesforce\" index_type => \"opportunity\" host => \"localhost\" } } That\u2019s the simplest way to push data into an Elasticsearch instance running on your laptop. Of course, if you\u2019d like to not worry about managing your own cluster, you can push the data directly to a \u00a0(hosted Elasticsearch)\u00a0cluster as well. The advantage there is that in just a few clicks, you can have an Elasticsearch cluster up and running with Shield for security and Kibana for visualizations. We use it internally as much as possible. This is great for a single download of the data. If you want to keep gathering this information on a regular interval, it\u2019s trivial to setup a cron job to do just that. We have ours collect this data every 24 hours, but you can adjust yours as needed. 0 5 * * * \/opt\/logstash\/bin\/logstash -f \/opt\/logstash\/sfdc-snapshot.conf -w 4 Connecting the DataWhen you start pulling this data in, you will notice that Salesforce has a lot of Id and Lookup fields. Looking at an 18 character really doesn\u2019t help you much. \u00a0Once you have a process to load the raw data, you can start to enrich it by connecting the together. You might create a separate Logstash configuration for doing just that. As an input, it will query new data from the Salesforce index, use the to look up related documents\u00a0from an id, attach that\u00a0document\u00a0to the original, and finally write that information to the existing index or a separate one. A sample configuration might look like this: input { elasticsearch { hosts => ['localhost'] index => 'salesforce' query => '{ \"query\": { \"query_string\": { \"query\":\"_type:\\\"opportunity\\\" AND @timestamp:[now-12h TO now]\" } } }' #everything from the past 12 hours. } } filter { if [OwnerId] { elasticsearch { hosts => [ 'localhost:9200' ] query => 'id:\"%{[OwnerId]}\" AND _type:user AND @timestamp:[now-12h TO now]' fields => [\"Name\",\"sfdc_owner_name\"] } } } output { elasticsearch { index => \"salesforce-enriched\" index_type => \"opportunity\" host => \"localhost\" } } Of course you can add as many lookups as you want to connect Accounts, Opportunities, Contacts or whatever custom you might have as well. Visualizing the Data with KibanaOnce the data is in Elasticsearch, the easiest way to start visualizing trends is to use Kibana. There are lots of fun things to look at but you can start by creating a histogram and slicing the columns by a particular Salesforce field you are interested in. In the chart below we can see pipeline changes on a daily basis by stage. We noticed a drop in stage 2 pipeline on the 9th and because we have the data snapshots saved, we can easily see exactly which opportunities we changed at that time. This is just some sample data, but hopefully it gives you some ideas about how you can start slicing and dicing your pipeline. ConclusionLiberating your data from Salesforce and putting it into Elasticsearch will allow you to dive much deeper and see trends that you might have otherwise missed. Our new Logstash input plugin is a quick and easy way to pull your data out of Salesforce and start tinkering with it in Kibana. Please let us know what improvements you would like to see by filing issues in the and have a great time at Dreamforce! \n"}<br>{"index": {"_id": 914}}<br>{"title":"How Totango uses Elasticsearch to build the world\u2019s finest Customer Success Platform","seo_title":"","url":"\/blog\/how-totango-uses-elasticsearch-for-customer-successs-platform","author":{"name":"Oren Raboy"},"date":"September 15, 2015","category":"User Stories","locales":"","content":" is a Customer Success platform used by subscription and recurring revenue businesses to reduce customer churn, drive product adoption, and maximize customer lifetime revenue. \u00a0Today companies have unprecedented data and visibility into their users\u2019 behavior and the business results achieved by their customers. Totango monitors this data to generate insights on customer health and engagement. Using Totango, companies can pinpoint at-risk accounts that need attention: spot opportunities to increase user engagement and boost revenue: and then implement customer success best practices to scale up operations across a growing customer base.Totango is used by some of the fastest-growing technology companies, including public companies like Zendesk and Autodesk: mid-stage companies like BigCommerce and Jobvite: and innovative startups like Optimizely and Mixpanel. How Totango Drives Customer SuccessTotango is all about analyzing customer data and translating it into actions for improving Customer Success.With Totango, a Customer Success Manager can get instant feedback about which users require special attention, so they can better support them, increase adoption, and ultimately, grow \u00a0the lifetime value of a customer, all while reducing churn. For example, when using Totango a success manager gets notified when a user first starts using an advanced functionality, or if the number of active users in an account has declined to an all-time low. Totango can even send emails to users when certain conditions are met to fully automate the success process. Totango\u2019s Architecture RequirementsTo accomplish this, we designed the Totango technology platform with a few key architecture requirements: Balancing these requirements requires a solid Data Architecture and use of the best NoSQL technologies the industry has to offer. We were fortunate to be one of the early adopters of Elasticsearch and have been using it for the past 4 years as a core technology in our stack. It has enabled us to address the needs above while supporting our growing customer base. Elasticsearch's\u00a0flexibility has been key to us continuously innovating and delivering new functionality to the market.In this post, we will highlight how Elasticsearch has helped us build the world\u2019s finest data platform for Customer Success. Elasticsearch in The Totango Platform ArchitectureWithin the Totango data architecture, Elasticsearch serves as the data-store infrastructure in our serving layer. When a new event (such as a user logging in, or a new business transaction) is collected and processed by Totango, its results are indexed in realtime into the Elasticsearch index, making it available for use by the Totango users.Additionally, each day Totango processes all collected information, applying statistical models and other data-science techniques. It then indexes a daily snapshot of insights within our historical archive, which also leverages Elasticsearch. Using this archive, we can present daily and weekly trends of metrics to see how things progress overtime.In aggregate, Totango maintains multiple Elasticsearch indices for every one of our clients, each aggregating many millions of documents representing the state of a user or account in a snapshot in time.All this happens transparently to our customers who receive a virtual, cloud-based solution. Elasticsearch, along with the rest of our infrastructure is abstracted and wrapped in the beautiful, action-oriented user-interface we developed at Totango. \u00a0The user receives alerts of important events, analyzes customer usage through segmentation and reports and even setup rules to send an email-campaign when users perform certain actions. This all happens without having to consider the complexities of collecting, normalizing, processing, and storing complex multidimensional data.\u00a0 Benefits of Elasticsearch\u00a0We\u2019ve come to rely on the following aspects of Elasticsearch to help us build a rock solid and flexible data layer architecture: FutureWhile we make extensive use of Elasticsearch at Totango, we know there are still features and capability offered by Elastic that we have yet to fully utilize. Here are some of the items we look forward to include in one of our next projects: To learn more about visit our website or follow our technical writing on our . \n"}<br>{"index": {"_id": 915}}<br>{"title":"Part 2.0: The true story behind Elasticsearch storage requirements","seo_title":"","url":"\/blog\/elasticsearch-storage-the-true-story-2.0","author":{"name":"Peter Kim"},"date":"September 15, 2015","category":"Engineering","locales":"","content":" Several months ago we wrote about the and today we\u2019re here to refresh those tests with the new which includes several enhancements. For those of you looking for a quick answer, these tests showed an overall compression ratio of 0.732 (index size on disk \/ raw log file size) for those of you who are doing both search and visual analysis of your log data.But of course, the answer to \u201cHow much hardware will I need\u201d is still \u201cIt depends!\u201d Many factors need to be taken into account and both this post and our previous are meant to elaborate on these factors in detail so you can make informed choices for both the best performance and the right hardware purchases.Changes since last timeWhen we wrote our last blog post, we ran our experiments using Elasticsearch 1.4. Since then, there have been hundreds of new features, enhancements and bug fixes made to Elasticsearch. With respect to disk storage requirements, the key changes are: 1) the addition of a best_compression option for stored fields and 2) doc_values enabled by default. In addition, we found a bug in our original experiments that had a significant impact on index size.\u00a0DEFLATE: no footballs have been tampered in these testsAs described in this \u00a0by Adrien Grand, one of our engineers and core Lucene committers, Lucene 5.0 added a new compression option using the DEFLATE algorithm (the same algorithm behind zip, gzip, and png). Elasticsearch 2.0 is the first version of Elasticsearch to rely on Lucene 5.x and thus is able to leverage the new compression option. This is exposed via the .\u00a0In our tests, using\u00a0best_compression reduces our index size\u00a0between 15-25% depending on the configuration. This is substantial, especially when looking at larger clusters. Many large Elasticsearch clusters are 50-100 nodes and more, where cluster size is primarily driven by sheer data volume. When you can cut down the amount of hardware by 15-25%, that\u2019s a pretty significant change for the better.So what\u2019s the catch? The stored fields (value of the _source field) are what\u2019s compressed, so there\u2019s only a performance penalty due to decompression when the stored fields are returned in the query response. When the size=0 parameter is added to the request (as is recommended for pure aggregations queries and what Kibana does under the covers), there is no decompression penalty. There is a small performance penalty at index time: in many cases, people will gladly give up\u00a0the extra CPU required for compression in exchange for disk space but you\u2019ll have to consider this in the context of your requirements.\u00a0Alternatively, we expect many users will want to utilize a using the . In this scenario, time-based indexes on hot nodes can be configured to be created with the default LZ4 compression: \u00a0when they\u2019re migrated to the warm nodes (configured with index.codec: best_compression in elasticsearch.yml), the indexes can\u00a0be compressed by . It may be preferable to pay the CPU penalty of compression during this optimize process (which we often recommend executing when the cluster is known to be less utilized) than at the time of initial indexing.What's up doc_values? were introduced with Elasticsearch 1.0 as an alternative means of storing data that is better suited for analytics workloads by using a columnar representation and can be accessed off the JVM heap. Initially, using doc values was only recommended in specific scenarios but over time, we\u2019ve seen our users wanting to run analytics on continuously growing volumes of data that simply could not be executed under the constraints of the JVM heap. Fortunately, we\u2019ve made significant enhancements to eliminate most of the performance gap between using field_data and doc_values, to the point where we felt comfortable for fields of all types except analyzed string fields.There are two ways doc values can impact a cluster\u2019s hardware requirements. First, enabling doc_values requires more disk but this should be offset by the gains from enabling best_compression as described above. Second, doc_values can reduce overall hardware footprint by not letting the limits of the JVM heap define the hardware profile of the nodes or the horizontal scaling point. For example, without doc_values enabled, a node might have been sized\u00a0with a smaller indexed data volume to ensure that JVM heap utilization is kept under control to avoid frequent garbage collection. This becomes less of a concern when the data can be accessed off-heap.Dates and stringsIn our original tests, our Logstash configuration converts the string representation of the date\/time into a date-typed value. We forgot to delete the original string representation of the date\/time, which is safe to do if the date\/time parsing is successful. This oversight is significant since we discovered the date\/time string values made up about 20% of the overall index size in our test data set. Elasticsearch, as with most search engines, builds an inverted index to provide fast lookups: when you have a value that\u2019s highly unique (such as a timestamp), this can greatly increase the size of that index.The detailsThe test methodology hasn\u2019t changed so you can check out the or the \u00a0for the details.\u00a0With the standard LZ4-based compression, the indexed data size to raw data size ratio ranged from 0.575 to 1.394. After enabling DEFLATE-based compression using the best_compression index.codec option, the indexed data size to raw data size ratio range came down to 0.429 to 1.117. Enabling the best_compression option resulted in a 15.7% to 25.6% reduction in indexed data size depending on the test parameters.\u00a0As you can see, the ratio of index size to raw data size can vary greatly based on your mapping configuration, what fields you decide to create\/retain, and the characteristics of the data set itself. We encourage you to run similar tests yourself to determine what the data compression\/expansion factor is for your data set and application requirements.ConclusionThere were added to Elasticsearch 2.0 worth considering. As we\u2019ve discussed, two of these new features in particular can reduce the hardware footprint required for an Elasticsearch cluster by 15-25% or more: 1) the addition of a best_compression option and 2) enabling doc_values by default. This allows us to get to compression ratios between 0.429 and 1.117.Being an open source company means a lot more to us than just the licensing model of our core products. It means being open about the capabilities (and limitations) of our products. Our hope is that these experiments encourage you to discover the truth about Elasticsearch\u2019s capabilities with regards to storage requirements yourself and not just take our word (or anyone else\u2019s) for it. We\u2019d love to hear about the results of your own experiments using your own data and specific configuration or mapping settings that makes sense for your application. You can submit those config and data files or file issues at this Github repo: . \n"}<br>{"index": {"_id": 916}}<br>{"title":"Elasticsearch 1.7.2 released","seo_title":"Elasticsearch 1.7.2 released","url":"\/blog\/elasticsearch-1-7-2-released","author":{"name":"Clinton Gormley"},"date":"September 14, 2015","category":"Releases","locales":"","content":" Today, we are happy to announce the bug fix release of , based on . This is the latest stable release. Users are advised to upgrade if they find themselves affected by any of the bugs which have been fixed.You can .Previous blog posts about the 1.7 series:This release contains a number of bug fixes including:Please , try it out, and let us know what you think on Twitter () or on our . You can report any problems on the . \n"}<br>{"index": {"_id": 917}}<br>{"title":"Where in the World is Elastic? - Kiratech Event, Trax Tech, and LinkedIn Meetups","seo_title":"","url":"\/blog\/witwies-kiratech-trax-tech-linkedIn","author":{"name":"Megan Wieling"},"date":"September 14, 2015","category":"","locales":"","content":" Welcome to Check out this week's events and\u00a0meetups to find out what's happening near you! Upcoming Events September 17: September 18: Upcoming Meetups September 15: September 15: September 16: September 16: September 16: September 17: September 16: September 16: September 17: September 16: September 14: That's it for this week. Stay tuned for Elastic happenings next week! - The Elastic Team P.S. if you're interested in hosting a meetup or are giving a talk about Beats, Elasticsearch, Logstash or Kibana \u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 918}}<br>{"title":"\u201cHot-Warm\u201d architecture","seo_title":"","url":"\/blog\/hot-warm-architecture","author":{"name":"Samir Bennacer"},"date":"September 11, 2015","category":"Engineering","locales":"","content":" The current blog applies to Elasticsearch versions 1.x and 2.x. If you are looking for \u201cHot-Warm\u201d Architecture in Elasticsearch 5.x click When using Elasticsearch for larger time-data analytics use cases, we recommend using time-based indices and a tiered architecture with 3 different types of nodes (Master, Hot-Node and Warm-Node), which we refer to as the \"Hot-Warm\" architecture.Each node has their own characteristics, which are described below.Master nodesWe recommend running 3 dedicated master nodes per cluster having dedicated master nodes which run in their own JVM increases stability and resilience as they are not affected by garbage collection that can affect other types of nodes. These nodes do not handle requests and do not hold any data, and therefore only require less resources (such as CPU, RAM and Disk)Hot data nodesHot data nodes are designed to perform all indexing within the cluster and will also hold the most recent daily indices that generally tend to be queried most frequently. As indexing is a very IO intensive operation, these servers need to be powerful and backed by attached SSD storage.Warm data nodesWarm data nodes are designed to handle a large amount of read-only indices that are not queried frequently.\u00a0As these indices are read-only, warm nodes tend to utilise very large attached spinning disks instead of SSDs.Elasticsearch needs to know which servers contain the hot nodes and which server contain the warm nodes. This can be achieved by assigning arbitrary tags to each server.For instance, you could tag the node with , or you could start a node using .And the nodes on the warm zone are \"tagged\" with or you could start a node using The box_type parameter is completely arbitrary and you could name it whatever you like. These arbitrary values will be used to tell Elasticsearch where to allocate an index.We can ensure that today\u2019s index is on our SSD boxes by creating it with the following settings:PUT \/logs_2015-08-31 { \"settings\": { \"index.routing.allocation.require.box_type\" : \"hot\" } }After few days if the index no longer needs to be on our strongest boxes, we can move it to the nodes tagged as warm by updating its index settings:PUT \/logs_2014-08-31\/_settings { \"index.routing.allocation.require.box_type\" : \"warm\" }Now how can we achieve that using Logstash :We need update the index templates to include allocation filtering \"index.routing.allocation.require.box_type\" : \"hot\" so that any new indices are created on the nodes that are tagged with hot.Example:{ \"template\": \"logstash-*\", \"settings\": { \"index.refresh_interval\": \"5s\", \"index.routing.allocation.require.box_type\": \"hot\" }, \"mappings\": { \"_default_\": { \"_all\": { \"enabled\": true, \"omit_norms\": true }, \"dynamic_templates\": [ { \"message_field\": { \"match\": \"message\", \"match_mapping_type\": \"string\", \"mapping\": { \"type\": \"string\", \"index\": \"analyzed\", \"omit_norms\": true } } }, { \"string_fields\": { \"match\": \"*\", \"match_mapping_type\": \"string\", \"mapping\": { \"type\": \"string\", \"index\": \"analyzed\", \"omit_norms\": true, \"fields\": { \"raw\": { \"type\": \"string\", \"index\": \"not_analyzed\", \"ignore_above\": 256 } } } } } ], \"properties\": { \"@version\": { \"type\": \"string\", \"index\": \"not_analyzed\" }, \"geoip\": { \"type\": \"object\", \"dynamic\": true, \"properties\": { \"location\": { \"type\": \"geo_point\" } } } } } } }When indexes are no longer being written to and not being searched frequently they no longer need to be on the hot nodes. We can move them to the nodes tagged as warm by updating their index settings: \"index.routing.allocation.require.box_type\" : \"warm\".Elasticsearch will automatically migrate the indices over to the warm nodes.\u00a0Finally we recommend running an optimize on the migrated indices.\u00a0It would be a bad idea to optimize the index while it was still allocated to the strong boxes, as the optimization process could swamp the I\/O on those nodes and impact the indexing of today\u2019s logs. But the medium boxes aren\u2019t doing very much, so we are safe to optimize.Now that we have seen how to change the allocation of an index, let's look at how to use Curator to automate the process.In the example below we are using Curator 3.0 to move the indexes from hot nodes to warm nodes after 3 days.\/usr\/bin\/curator --logfile \/var\/log\/curator.log --loglevel INFO --logformat default --master-only --host localhost --port 9200 allocation --rule box_type=warm indices --time-unit days --older-than 3 --timestring '%Y.%m.%d'Finally we can use Curator to optimize the index, make sure you wait enough for the reallocation to finish before running optimize.\/usr\/bin\/curator --host localhost --port 9200 optimize indices --older-than 3 --time-unit days --timestring '%Y.%m.%d' \n"}<br>{"index": {"_id": 919}}<br>{"title":"A Post with a View: Elastic @ Viewpost","seo_title":"","url":"\/blog\/a-post-with-a-view-elastic-at-viewpost","author":{"name":"Daniel Palay"},"date":"September 10, 2015","category":"User Stories","locales":"","content":" At Elastic, we're constantly engaged with our customers and users to learn more about how they're using our software stack. I recently had the opportunity to learn more about\u00a0, a\u00a0leading provider of online invoice payment software, who\u00a0uses Elasticsearch to power search for its\u00a0financial application suite, allowing their\u00a0customers to find specific business partners, look up invoice payables and receivables, and quickly navigate around the application.\u00a0Because of the sensitive nature of the invoice and payment data, Viewpost aims to meet and exceed security regulations such as ISO 9000 and SSAE 16. They had been trying to use a community\u00ad-created Elasticsearch plugin to secure their data, but found it complicated to set up, maintain, and verify. After , Elastic\u2019s security plugin, was released, Viewpost was able to upgrade their deployment within a few weeks, leveraging tightly integrated authentication, encryption, and role-based access control to to meet their security requirements.Here's a snippet\u00a0from my conversation with\u00a0Tommy Bollhofer \u2013\u00a0Viewpost's resident Database Architect \u2013 who gives a bit more insight into how\u00a0Viewpost uses Elasticsearch and Shield to power their SaaS financial application:Database Architect. We are responsible for architecture, design, support, maintenance, administration, and optimization of relational and non-relational distributed database systems.Several uses cases for double wild card search functionality within the application lead us to review both Elasticsearch and Solr. We chose Elasticsearch for many reasons, including the speed at which Elasticsearch responds to user feedback and incorporates new features into the product, and that it's platform agnostic which allows us to run local instances of Elasticsearch\u00a0on our development machines.Security is the foundation to our product and we wanted to ensure we had both TLS and authentication enabled with our initial rollout of Elasticsearch. Prior to Shield, the only viable option was Jetty. The installation, configuration, maintenance, and integration of Elasticsearch using the Jetty plug-in was very cumbersome. It lacked support for LDAP integration, logging, etc. We started using the Shield plug-in during its initial beta release. It exceeded our expectations and we were able to quickly transition from Jetty to Shield with ease.Elasticsearch was one of the first non-relational distributed database systems in our environment which in and of itself was a big step forward. The rich feature set in Elasticsearch, in conjunction with the support we received, allowed us to move very quickly, delivering a rich, full-fledged search experience to our customers. \n"}<br>{"index": {"_id": 920}}<br>{"title":"PAYMILL: How Elasticsearch is our Swiss Army Knife for Data","seo_title":"PAYMILL: How Elasticsearch is our Swiss Army Knife for Data","url":"\/blog\/paymill-how-elasticsearch-is-our-swiss-army-knife-for-data","author":{"name":"Michael Rupp"},"date":"September 10, 2015","category":"User Stories","locales":"de-de","content":" At PAYMILL we provide an easy-to-use, reliable payment service for online merchants, which is a quite challenging task. As you directly deal with your customers\u2019 money everything has to be top-notch, stable and fast. Starting off with a fast growing monolithic code base and a SQL database we grew very fast within the last three years, both in data size and code complexity. As for the latter part we decided to go for a more service-oriented approach. We had to think about which tool could help us to handle big amounts of data for various use cases and fits into our architectural concept. Elasticsearch quickly came into our focus as it is very easy to setup, provides a JSON based, RESTful API and all kinds of libraries, which makes it easy to use from numerous services at once. Elasticsearch - Our Use Case To get into the technology we first used it as a kind of buffer for an export between our transactional MySQL database and Salesforce. To prevent long running or blocking queries from MySQL we moved small, immutable chunks of data to Elasticsearch every minute and then, in another process, pushed this data to Salesforce, which can take quite a while. This task was the perfect starting point as we got into fundamental concepts of Elasticsearch, learned how to use Elastica, the respective PHP library, and learned our first lessons in a not so critical process. As we were satisfied with the results we decided to go one step further with Elasticsearch and use it for our application logging. As a payment service provider you have to follow very strict rules when it comes to logging and traceability and you have to make sure not to lose any information. Basically you have to store every login, every action and every API call within your system and keep this information for years to fulfil\u00a0all compliance rules. To achieve this we developed a scalable, failsafe service, which stores all application level logging information into Elasticsearch and makes it accessible to our administration and support via a front end. This is still an on-going project as we want to integrate Logstash and Kibana there in the future but we already learned a lot about index and type management, data storage and data retrieval. This again worked out very nicely and we quickly came up with another use case for Elasticsearch. We offer a frontend to our customers, called the Merchant Centre, which gives them access to their account and data. One of its key features is a dashboard to show the most important business numbers at a glance and include some analytic graphs. Elasticsearch in the Merchant Centre As SQL based analytics can get slow and block tables very easily, Elasticsearch and its extensive aggregation functionality seemed to be the perfect fit to solve this problem for us. We integrated it as the data storage component in an ETL process and set up the data retrieval within our Merchant Centre to utilize our own access control mechanisms. Everyone knows how important load time of web pages is for a customer, so we were quite uncertain if the real time aggregation would work fast and stable enough for our needs. But Elasticsearch did not disappoint us here as it delivers the values really fast even for more complex aggregations. You can get a glance at the new dashboard in the picture above. It is not yet online but soon to be released, so stay tuned. Within the last months the Elastic technology stack really became one of the core components of our service architecture and serves us in many ways whenever we have to handle big, immutable datasets. We use it to log, search and analyse data both internally and for the customer. Our system administration set up the whole ELK stack to handle server logs, we plan to finally utilize it for the search in the Merchant Centre and the data science team thinks about Elasticsearch as a data source for their models. With a few hundred GB of data, our cluster is still very small compared to what others do with Elasticsearch. But it is growing fast and we are quite confident to be able to scale up to much bigger amounts without having to rewrite lots of stuff or change the technology for quite a while. Lessons learned I would also like to share some of our lessons learned so far to help you all to get into this technology: \n"}<br>{"index": {"_id": 921}}<br>{"title":"This Week in Elasticsearch and Apache Lucene - September 8 2015","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-09-08","author":{"name":"Michael McCandless"},"date":"September 08, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsNew from infrastructure guru : ' Command Line Debugging w\/The _cat API' \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 922}}<br>{"title":"When and How To Percolate - Part 2","seo_title":"When and how to Scale and Optimise Percolator for Elasticsearch","url":"\/blog\/when-and-how-to-percolate-2","author":{"name":"Dale McDiarmid"},"date":"September 08, 2015","category":"Engineering","locales":"","content":" In last week's blog \"\" we discussed the key differences between Watcher and Percolation and how to determine which is applicable to your use case. We followed this with an overview of the scaling properties of Percolator. In this week's post, we'll discuss the tools available for improving and optimising Percolator performance. Filters Filters represent the initial and preferred mechanism for reducing the percolation query set and thus making linear execution acceptable. Filters work by attaching metadata to the percolator queries. When percolating a document, a normal Elasticsearch filter is also included. This identifies a reduced subset of queries which need to be evaluated using the process in last week's post. Although filtering incurs some overhead, this cost is comparable to the use of Elasticsearch filters in standard search use cases, which scales significantly better on large index sizes. Candidates for filters are typically metadata fields, which exist on both the queries and percolator documents. Although not essential, these would ideally allow your queries to be grouped into approximately evenly distributed subsets. However, any metadata that allows subsets of queries to run should be considered for use in filtering. Let's consider the use case discussed in last week's post, where a shard contains 1 million percolation queries. Evaluating each of these against a document takes around 4.2 seconds. However, suppose we modify our percolator queries such that our category id is attached as metadata. We, in turn, pass the categories associated with a product, as a filter, when percolating its document. PUT \/best_buy\/.percolator\/2 { \"query\": { \/\/query }, \"category_id\": \"pcmcat209400050001\", \"user\": \"0dc7a91b9efb4f91e2a454907aeb9596fcb43bc2\" } POST \/best_buy\/.percolator\/_percolate { \"query\": { \"bool\": { \"filter\": { \"terms\": { \"category_id\": [ \"cat00000\", \"abcat0300000\", \"pcmcat165900050023\" ] } } } }, \"doc\": { \/\/document }, \"size\": 10 } See for further details. Across a corpus of 1 million queries, the category id has a cardinality of approx. 1500. These are not uniformly distributed across our data, with users expressing more interest in some categories than others. The following diagram illustrates the results of repeating the tests described in \"When and How To Percolate - Part 1\", with filtering applied using the category id. Adding the category id as a filter results in a significant performance increase. 1 million percolation queries now evaluate in around 100ms. Filtering requires: We recognise that filtering is not always possible. For example, in some instances users have the requirement to always evaluate all queries against a document(e.g. for an admin-focused use case). Alternatively, there may just be an absence of appropriate metadata for filters. Sharding and Routing Sharding of percolator indexes provides a mechanism to take advantage of additional resources and thus improve performance. By splitting percolate queries across multiple shards, the number of percolator queries requiring evaluation in each is reduced. Given the document is percolated on each shard in parallel, the total latency experienced therefore becomes the performance on the slowest shard - thus increasing throughput through parallel execution of smaller tasks. Once sharded, users can consider optimising further using routing. This techniques ensures documents are only percolated on the the shards which contain possible candidate queries for linear evaluation. To achieve this, percolator queries need to be partitioned by a custom routing value at index time. This same value is also used when passing a document to ensure it is only executed on the required shard - thus saving resources and increasing possible throughput. Multiple values can also be specified as a comma separated string, allowing a query and document to be indexed and executed on more than one shard. Routing keys candidates have the same characteristics as those used for filters - metadata fields shared by documents and queries. While Elasticsearch manages the routing, it ensures that distribution is fairly uniform across all your shards. However, once you start implementing your own custom schemes, it is entirely possible that this uniformity is lost resulting in an uneven execution load across the cluster. We, therefore, recommend you consider a meta field which has a uniform distribution of values across your percolator queries. Routing guarantees that all queries with the same key collocate on the same shard. The cardinality of your routing key is likely to be greater than the number of shards, resulting in multiple values hashing to the same shard. Where routing is used, the key should therefore always also be applied as a filter. Multi-Percolate and Replicas The multi-percolate API allows users to bundle multiple percolate requests into a single request, similar to what the multi-search API does to search request. For each request, the coordinating node will select one shard from the replication group (primary + replicas). How documents are distributed to these selected shards depends on whether routing is enabled. If not utilised, all documents will be sent to each of these shards in parallel. If routing is enabled, the documents will be batched according to their appropriate shard and each batch sent in parallel. Multi-percolate therefore allows you to execute percolations more efficiently but predominantly acts as a network optimisation. The selection of shards from a replica group is round-robin between requests, thus balancing resource utilisation across nodes. As described above, provided your client takes advantage of their availability, replicas provide increased throughput provided you have sufficient nodes to spread the load. Consider that nodes are likely to hold multiple shards, and replicas. A node can be potentially evaluating as many percolator queries as shards at any time. Whilst replicas can be used to increase throughput, users should load test in a representative environment whilst monitoring resource utilisation closely. Replicas provide the usual benefit of high availability. Resource Utilisation The memory required for Percolator queries is heavily dependent on the operators utilised. Wildcard queries operators are particularly expensive when evaluated against documents due to the creation of an FST. The Percolator cache is held within heap space, which can easily reach 80% capacity on large\/complex query volumes if allocated insufficient memory. This will in turn cause old generation garbage collector cycles which significantly impact query performance. Provided memory pressure is not an issue, users will see Percolation is CPU-bound with respect to performance and should see the linear scalability illustrated earlier. We encourage users index real queries and establish memory requirements per node. This may be a consideration, in addition to query latency, when deciding the number of queries to index per shard. Finally, given the CPU intensive nature of Percolator, we encourage users to consider a dedicated index and possibly cluster - especially if you anticipate high throughput and require consistent performance. Further details on the tests performed in both parts of this blog post, including the scripts and test environment utilised, can be found here [reference: https:\/\/github.com\/gingerwizard\/percolator_scaling]. \n"}<br>{"index": {"_id": 923}}<br>{"title":"Kibana 4.1.2 Now Available","seo_title":"Kibana 4.1.2 Now Available","url":"\/blog\/kibana-4-1-2-now-available","author":{"name":"Joe Fleming"},"date":"September 08, 2015","category":"Releases","locales":"","content":" Kibana 4.1.2 is now available, and you can . This is a bugfix\/maintenance release for the 4.1 branch Of\u00a0particular note in this release, we fixed a lot of labeling,\u00a0including\u00a0labels on filters and\u00a0visualizations, and related to\u00a0scripted fields, range\u00a0aggregations and pie charts.\u00a0A mostly complete list of fixes include, in no particular order: \n"}<br>{"index": {"_id": 924}}<br>{"title":"Where in the World is Elastic? - September 7, 2015","seo_title":"Where in the World is Elastic, September 7 2015","url":"\/blog\/2015-09-07-where-in-the-world-is-elastic","author":{"name":"Livia Froelicher"},"date":"September 07, 2015","category":"","locales":"","content":" Welcome to\u00a0 And September has started! See what's going on in Elastic meetups and events\u00a0land this week!Upcoming EventsSeptember 9-10: September 9-11: - Our own is giving a \u00a0on Wednesday, September 9 from 8:30a.m. - 12:00 p.m.Upcoming MeetupsSeptember 9: September 9: September 10: September 10: September 10: September 8:\u00a0September 8:\u00a0September 9: That's it for this week.\u00a0Stay tuned for Elastic happenings next week! - The Elastic Team P.S.\u00a0\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats,\u00a0Elasticsearch, Logstash or Kibana\u00a0\u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 925}}<br>{"title":"Beyond packets: Elastic Beats 1.0.0-beta3 released","seo_title":"","url":"\/blog\/beyond-packets-elastic-beats-beta3","author":{"name":"Tudor Golubenco"},"date":"September 04, 2015","category":"News","locales":"","content":" We are excited to announce a new release for the Beats, and , our trusted shippers of operational data. It\u2019s not just Packetbeat anymore, now we\u2019ve added Topbeat, which you can use to monitor your systems\u2019 resources and processes. And don\u2019t worry, we\u2019ve continued to improve Packetbeat as well. In fact, thanks to you -- our community -- we have increased the pace in improving Packetbeat. Here are the highlights of the new release. Topbeat It\u2019s like the top command that you know from the Linux\/Unix shell, but sends the data periodically to Elasticsearch. It captures system wide data like the system load, free\/used memory or disk stats as well as per process stats. You can monitor all the processes running on your system or just a subset. Oh, and it\u2019s not just for Linux, it works on Windows and OS X too. Guess what, using Kibana to monitor your operating system metrics is a lot of fun! DNS support in Packetbeat DNS support is probably our most requested protocol for Packetbeat. stepped up and added generic support for UDP protocols to Packetbeat and then DNS support on top of it. Check out the screenshot for some of the interesting facts Packetbeat reveals. Memcache support in Packetbeat Memcache is another commonly requested feature. With this release Packetbeat fully supports it, including the binary and text protocols, over UDP and over TCP. Here is a screenshot showing statistics about the Memcache errors that Packetbeat found: Windows support We now officially support Windows. It used to be possible to run Packetbeat on Windows but it wasn\u2019t an easy task. With this release we took several steps to make it simpler. This includes running as a native Windows service and logging to files. It\u2019s also easier now, with Packetbeat, to and pick the one you want to use for network traffic capturing. We plan to go even further with improving the Windows support, including adding a GUI installer to makes things even easier. Stay tuned. Wrong libpcap version no more We\u2019ve completely reworked our build system and now we can statically compile against C libraries. This means libpcap is no longer a runtime dependency for Packetbeat on Linux. This means Packetbeat and Topbeat binaries work not only on the officially supported Linux distributions but also on any other Linux distribution as long as glibc is newer than 2.11. Bonus: Developer Guides! Lots of you asked for developer guides for how to create your own Beats or for how to add a new protocol to Packetbeat. We have now published two fairly comprehensive guides: one for and one for to Packetbeat. If you have an idea for a new Beat or have a question about any of the above, please open a topic on the . Here are the download links for and . \n"}<br>{"index": {"_id": 926}}<br>{"title":"Make Your Config Cleaner and your Log Processing Faster with Logstash Metadata","seo_title":"Metadata use cases in Logstash 1.5","url":"\/blog\/logstash-metadata","author":{"name":"Pier-Hugues Pellerin"},"date":"September 03, 2015","category":"Engineering","locales":"","content":" With the release of Logstash 1.5 we have added the ability to add to an event. The difference between regular event data and metadata is that metadata is not serialized by any outputs. This means any metadata you add is transient in the Logstash pipeline and will not be included in the output. Using this feature, one\u00a0can add custom data to an event, perform additional filtering or add conditionals based on the metadata while the event flows through the Logstash pipeline. This will simplify your configuration and remove the need to define temporary fields. To access the metadata fields you can use the standard field syntax: [@metadata][foo] Use CasesLets us consider some use cases to illustrate the power of . In all our use cases, will be using the rubydebug\u00a0and the stdout output to check our transformation, so make sure you are correctly defining the output codec with the option set to true. The codec used in the stdout output is currently the only way to see what is in at output time. output { stdout { codec => rubydebug { metadata => true } } } Date filterSince logs arrive in a wide variety of formats, grok is used to extract them, and the date filter to convert them to ISO8601 and overwrite the field with the timestamp from the log event. It happens frequently that users omit to remove the source timestamp field after the conversion and overwrite, though. Here's a rough example of how the new field could be used with the date filter and prevent a temporary timestamp field from making it into Elasticsearch: grok { match => { \"message\" => '%{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:[@metadata][timestamp]}\\] \u201c%{WORD:verb} %{DATA:request} HTTP\/%{NUMBER:httpversion}\u201d %{NUMBER:response:int} (?:-|%{NUMBER:bytes:int}) %{QS:referrer} %{QS:agent}' } } date { match => [ \"[@metadata][timestamp]\", \"dd\/MMM\/YYYY:HH:mm:ss Z\" ] } Before Logstash 1.5, you would remove the redundant field by adding the line into the date filter as I outlined above. Theoretically, that will be a slower operation than this one. That makes using the field a performance booster! The field act like a normal field and you can do all the operations or filtering on it. Use them as a scratchpad if you don't need to persist the information. # Log sample: # 213.113.233.227 - server=A id=1234 memory_load=300 error_code=13 payload=12 event_start=1417193566\u00a0event_stop=1417793586input { file { sincedb_path => '\/dev\/null' path => \"\/source\/test.log\" start_position => 'beginning' } } filter { grok { match => { \"message\" => \"%{IP:ip} - %{DATA:[@metadata][components]}$\" } } kv { source => \"[@metadata][components]\" } date { match => [\"event_start\", \"UNIX\"] target => \"event_start\" } date { match => [\"event_stop\", \"UNIX\"] target => \"event_stop\" } ruby { code => \"event['@metadata']['duration'] = event['event_stop'] - event['event_start']\" } if [@metadata][duration] > 100 { mutate { add_tag => \"slow_query\" add_field => { \"[@metadata][speed]\" => \"slow_query\" } } } else { mutate { add_field => { \"[@metadata][speed]\" => \"normal\" } } } } output { stdout { codec => rubydebug { metadata => true } } } Elasticsearch outputSome plugins leverage the use of the metadata, like the elasticsearch input. It allows you to keep the document information in a predefined field. This information is available to various parts of the Logstash pipeline, but will not be persisted in Elasticsearch documents. input { elasticsearch { host => \"localhost\" # Store ES document metadata (_index, _type, _id) in metadata docinfo_in_metadata => true } } output { elasticsearch { document_id => \"%{[@metadata][_id]}\" index => \"transformed-%{[@metadata][_index]}\" type => \"%{[@metadata][_type]}\" } } Create your own id from your event dataOut of the box, Elasticsearch provides an efficient way to create\u00a0unique IDs for every documents that you are inserting. In most cases, you should let Elasticsearch generate the IDs. However, there are scenarios where\u00a0you would\u00a0want to generate an\u00a0unique identifier in Logstash\u00a0based on the content of the event. Using IDs based on event data lets\u00a0Elasticsearch perform\u00a0de-duplication. In our example, we will generate\u00a0the IDs using\u00a0the and use the default hash method (SHA1). To test it, use the following JSON event with this configuration: { \"IP\": \"127.0.0.1\", \"message\": \"testing generated id\"} input { stdin { codec => json } } filter { fingerprint { source => [\"IP\", \"@timestamp\", \"message\"] target => \"[@metadata][generated_id]\" key => \"my-key\" } } output { elasticsearch { protocol => \"http\" host => \"127.0.0.1\" document_id => \"%{[@metadata][generated_id]}\" } stdout { codec => rubydebug { metadata => true } } } Like in the previous examples, we are using the fieldref syntax to access the in the hash. The Elasticsearch output will use this value as the document id, but the intermediate variable will not be\u00a0saved as part of the inside Elasticsearch. If you do a query for the specific document using the generated ID you should see a similar document showing the saved information. # curl -XGET \"http:\/\/localhost:9200\/logstash*\/_search?q=_id:5f5b8e63da13c17405e940b5e8db703a19cd4485&pretty=1\" { \"took\" : 8, \"timed_out\" : false, \"_shards\" : { \"total\" : 35, \"successful\" : 35, \"failed\" : 0 }, \"hits\" : { \"total\" : 1, \"max_score\" : 1.0, \"hits\" : [ { \"_index\" : \"logstash-2015.09.03\", \"_type\" : \"logs\", \"_id\" : \"5f5b8e63da13c17405e940b5e8db703a19cd4485\", \"_score\" : 1.0, \"_source\":{\"IP\":\"127.0.0.1\",\"message\":\"testing generated id\",\"@version\":\"1\",\"@timestamp\":\"2015-09-03T20:27:25.206Z\",\"host\":\"sashimi\"} } ] } } Similarly, you can also use as fieldref syntax\u00a0in your configuration like any other fields: \"from server: %{[@metadata][source]}%\" ConclusionAs you have seen in the examples above, the addition of metadata provides a simple, yet convenient\u00a0way to store intermediate results. This makes configuration less complex -- you don't have to use explicitly. Also, we can\u00a0reduce\u00a0storage of unnecessary fields in Elasticsearch which helps reduce the size of your index. Metadata is a powerful addition to your\u00a0Logstash toolset.\u00a0Start using this feature today in your configuration! \n"}<br>{"index": {"_id": 927}}<br>{"title":"Elasticsearch Command Line Debugging With The _cat API","seo_title":"Elasticsearch Command Line Debugging With The _cat API","url":"\/blog\/elasticsearch-command-line-debugging-with-cat","author":{"name":"Tyler Langlois"},"date":"September 02, 2015","category":"Engineering","locales":"","content":" One of the most useful utilities for investigating Elasticsearch from the command line is the . Whereas the usual Elasticsearch API endpoints are ideal for consuming JSON from within a fully-fledged programming language, the cat API (as its name would imply) is especially suited for command-line tools.In we've explored some of the different endpoints for the API. We can build upon that and the existing plethora of command-line utilities to build even more useful patterns that we can combine for simple (and effective) monitoring and debugging use cases.A Primer for your CatA basic familiarity with the cat API is helpful before reading on. In particular: Diving Into The HeapAn oft-asked question is how to debug messages. You've taken , but after some time of normal use, heap usage grows again and instability ensues. How can you dig further?There are lots of good resources to track this sort of resource utilization: offers commercial monitoring, and there's many of as well. However, when you're debugging a red cluster at the last minute, you need immediate options. What tools can you reach for easily?The cat API offers many endpoints, and piping a command which retrieves heap metrics into can quickly answer the question, \"Which node is experiencing the most memory pressure right now?\"$ curl -s 'localhost:9200\/_cat\/nodes?h=host,heap.percent' | sort -r -n -k2 es02 71 es00 60 es01 59We can see that node is using 71% of the JVM heap. Following the pipeline: Coupled with other utilities like and , we can find both over- and under-utilitized nodes in very large clusters very quickly.This is useful, but we can do more. It would be nice if we could query heap usage at a more granular level in order to determine what, exactly, is using space on our nodes.It turns out we can:$ curl -s 'localhost:9200\/_cat\/nodes?h=name,fm,fcm,sm,qcm,im&v' name fm fcm sm es01 781.4mb 675.6mb 734.5mb es02 1.6gb 681.3mb 892.2mb es00 1.4gb 620.1mb 899.4mb: These are abbreviated column names for (fm), (fcm), and (sm). Other fields exist as well, consult for additional information.From this we can see that is consuming a fairly large part of our node's memory. Armed with this knowledge, mitigations such as increased use of doc_values can aid in shrinking that aspect of heap usage.Gazing Into The Thread PoolMany Elasticsearch operations take place in thread pools, which are useful when inspecting what your cluster is busy doing. During peak times, the thread pool can be a useful reflection of what operations (searching, indexing, etc.) are keeping machines busy.The cat API is useful here, too. By default it returns common thread pools' active, queued, and rejected pools, which can often help pinpoint requests that are backing up into queued pools under heavy load. Consider this generic output:$ curl -s 'localhost:9200\/_cat\/thread_pool' es03 10.xxx.xx.xxx 0 0 0 0 0 0 1 0 0 elk00 10.xx.xxx.xxx 0 0 0 0 0 0 1 0 0 es00 10.xx.xx.xxx 0 0 0 0 0 0 0 0 0: the table headers are omitted here, but the numbers following node IPs are the , , and pools for the , , and thread pools, respectively.This cluster is serving a single search request, which isn't terribly exciting. However, what if your cluster is having problems and you need to closely watch operations? A command can help here:$ watch 'curl -s localhost:9200\/_cat\/thread_pool | sort -n -k1' executes the command every 2 seconds by default. We sort on the first column to keep ordering consistent, and usefully highlights field values as they change so we can keep a close eye on thread pools as they change, so it's easy to spot problems such as a deluge of search requests getting queued if users are hitting the cluster hard.Diffing Indices for Fun and ProfitAnother common use case is migrating data from one cluster to another: there are several ways to do this including snapshots and utilities like logstash. With large datasets, this can take quite some time, so how can we gain visibility into the process?The cat API offers simple endpoints for index metrics through which includes information such as index disk usage and document count per index.Given a scenario in which we're streaming documents from one index to another on a different cluster, we can perform some command-line gymnastics to watch a diff between index document counts. Consider the following command:$ join <(curl -s localhost:9200\/_cat\/indices | awk '$3 ~ \/foo-index\/ { print $3 \" \" $6: }') <(curl -s otherhost:9200\/_cat\/indices | awk '$3 ~ \/foo-index\/ { print $3 \" \" $6: }') | awk '{ print $1 \" \" $2 - $3: }' foo-index -231700This command makes use of bash process substitution in order to create temporary file descriptors from the output of commands between the parenthesis. We use to find the index of interest, , and print the index name and document count for the local index and the remote one we're streaming to. Using the command on the host field merges them into one line, and we pipe the results through another in order to calculate a difference between the two indices.The results of the example command indicate that there's a disparity in document count that should converge as the stream nears completion and finishes replicating the data.By placing this command into either a command or bash loop, we can quickly whip up a small utility to watch the progress of our index import.Going FurtherThese are just a few examples of how everyday command line utilities can be paired with the cat API to make lives easier for administering Elasticsearch. There are plenty of other potential applications to consider - for example: Good luck, and may the cat be with you! \n"}<br>{"index": {"_id": 928}}<br>{"title":"This Week in Elasticsearch and Apache Lucene - September 1 2015","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-09-01","author":{"name":"Michael McCandless"},"date":"September 01, 2015","category":"","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsElasticsearch 2.0.0-beta1 released, with over 2,500 PRs from 469 contributors, get it while its hot! \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 929}}<br>{"title":"When and How To Percolate - Part 1","seo_title":"When and How to Scale Percolator","url":"\/blog\/when-and-how-to-percolate-1","author":{"name":"Dale McDiarmid"},"date":"August 31, 2015","category":"Engineering","locales":"","content":" As we move beyond search at Elastic, we are seeing a growing number of the requirements to take action based on changes in your data. Back in June, we released the first version of to bring alerting and notification functionality to the Elastic product stack, based on the principle that users and administrators should be able to alert on anything for which they can can create a query. Many of you who are familiar with the existing capabilities of Elasticsearch perceived some functional overlap with the percolate API [reference: ] and have expressed confusion as to when each is applicable. Although both match documents against queries and can be used to create alerting-type functionality, they each provide discrete capabilities and solve distinct use cases. This post aims to clarify when each is appropriate, before discussing the sizing and scaling considerations for percolator. Should I Watch or Percolate?Traditionally, you design documents based on your data, store them into an index, and then define queries via the search API in order to retrieve them. Percolator works in the opposite direction. First, you store queries into an index and then, via the percolate API, you match individual documents against these queries. Percolator provides the capability to ascertain which queries a discrete document would match. It does not consider the corpus of documents and thus does not allow the observation of trends (e.g. using aggregations to spot if avg volume of requests have gone up in last hour). A common misconception for those new to Percolator is that alerting is a side-effect of inserting documents, similar to a database trigger. This is not the case. There is no requirement to index percolated documents and any alerting-type functionality is left to the user. Percolator is also not limited to alerting use cases. For example, queries can represent categories and the percolation process is then used to classify documents which may or may not be inserted into Elasticsearch. By indexing the queries, Percolator demonstrates linearly scalability with respect to the number of registered queries, modulated by the number of concurrent shards processing each request. \u00a0\u00a0Because the Percolator evaluates a single document at a time, it is less suited for applications that must compare multiple documents at once. Furthermore, Percolator brings a real-time capability to matching in comparison to the scheduled nature of Watcher. Percolator is well suited to use cases where the requirement focuses on the need to spot new documents of interest in isolation to the corpus in real-time. Comparatively, Watcher periodically schedules pre-defined queries for executing against a document corpus before sending alerts and notifications on matches. It is able to consider either properties of the entire corpus or even a subset of documents (e.g. those recently indexed, thus providing trend identification). Functionally, Watcher takes this further by allowing the user to take actions on the matches to the above question without the requirement to write code. Watcher exhibits excellent scaling properties with respect to both the total document corpus size and the number of new documents. It is, however, less suited to requirements where there is a need for real time matches. Consider the following examples, \u00a0An e-commerce website, wishes to provide the capability for users to save searches. When a new item is listed, those users whose searches match the product are notified that the item is available for purchase. Approximately 1000 new products are listed per minute. The site has approximately 3 million users, who on average save 0.5 queries each. Searches for products consist of a product type, key terms, price range and geographical distance. Users should be notified within 1 minute of a new product being listed. A high number of queries preclude Watcher without significant hardware investment. The cardinality of the values (i.e. high queries), low document throughput, requirement to alert in real time and matching of documents in isolation mean this use case is well suited to Percolator. The same website as Use Case 1 monitors items purchased per minute and the number of items listed per minute. This count is measured continuously every 10 minutes and compared to seasonal trends. Should the values fall beneath pre-determined benchmark values a series of internal actions are initiated. The queries required to express the above is low. Additionally, the requirement for periodic monitoring and the need to consider more than one document make this a suitable application for Watcher.Next StepsOnce a user has selected the tool appropriate to their problem, the topic of scaling and sizing is then typically raised. With respect to Watcher, this evolves into the standard search sizing problem with a few extra dimensions: number of queries, query complexity, and frequency of scheduling. Percolator has some interesting scaling challenges and provides several tools for overcoming these. For the remainder of this post we will focus on the general considerations when scaling Percolator, before discussing techniques used to size and optimise performance next week. In future parts of this series, we will investigate the Watcher side of things. Scaling PercolatorRegistering a query with Percolator creates a document in a specific format, in an arbitrary index under a reserved type \u201c.percolator\u201d. Per normal search behaviour in Elasticsearch, and assuming the index has been sharded, each shard for the index receives a subset of these documents. Additionally, each shard keeps an in-memory store of parsed Lucene queries for those it has been assigned. On receiving a document for percolation, a node broadcasts this to every shard in the index - potentially utilising a replica to take advantage of available resources. For each shard, the document specified in the request gets parsed into a Lucene document and is stored in an in-memory index. The queries are in turn executed sequentially across this in-memory index as required using a single thread. This happens on each shard that the percolate request needs to execute. Assuming all percolator queries are broadly equal, we can expect response times that are linear with respect to the number of queries stored on a shard. Using a single shard and node on representative production hardware, begin your sizing process by identifying the required latency for a single document percolation. In a controlled manner, replay a set of documents against a percolator index containing a set sample of pre-optimised queries N. The number of queries used here should be a subset of the intended total. Tools such as JMeter [reference: ] allow this to be performed with simple configuration, assuming documents are prepared in a simple CSV file. \u00a0Documents can be fed sequentially in a single JMeter thread, recording the average response time*. This test can be repeated, resetting the index each time, with increasing percolator query volumes. Any testing here should be controlled and consistent to minimize potential influencing factors that may skew results. For example, utilize the same documents, hardware, and configuration between tests. For the purposes of this example, we utilized the a public corpus of Best Buy queries available here [reference: ]. This dataset, consisting of product listings and users queries, was originally made public for the purposes of a prediction challenge. We utilized two specific files from this dataset: Rather than solving the prediction challenge, we treated each user click as a saved percolator query. We assumed the common E-Commerce use case of users wishing to be alerted when a new product is available. For this purpose, we discarded the product id and created a percolation query for each user click consisting of the product category id and their search terms. The above training file was converted to queries using a script. Each query attempts to replicate a user's search, with a simple search and category filter (i.e. each query would allow a user to be alerted for a product containing terms X in category Y). \u00a0 PUT \/best_buy\/.percolator\/1 { \"query\": { \"bool\": { \"must\": { \"multi_match\": { \"query\": \"projector screen\", \"fields\": [ \"description\", \"name\", \"search_terms\" ] } }, \"filter\": { \/\/term filter } } } } \u00a0The above example utilizes Elasticsearch 2.0 syntax. \u00a0See for changes to 1.x. Practically, this query is likely to be more complex with recall and precision considerations. For the purpose of demonstrating scaling properties we simply utilized a multi_match query. \u00a0 500 products were selected from the product data and converted to the appropriate percolate doc format. Each document consisted of a name, description (if available) and list of categories to which it belonged. We also enriched each document with search terms commonly used to locate (using the query data), to ensure each document matched queries when percolated. The 500 documents were percolated against query sets of increasing size. 10 tests were performed, starting with an index of 100,000 queries. For each test, the number of queries was increased by 100,000 up to a maximum of 1 million. Each test was therefore a superset of all the previous tests. The following illustrates the linear performance relationship of Percolator: For the purposes of this example, we assumed we needed all document percolations returned in 1 second. The above relationship indicates each shard needs to evaluate at most 250,000 percolation queries to achieve this latency. For the above tests, we have assumed sufficient memory for all nodes - memory pressure and garbage collection are therefore not considered. Once we have identified the number of percolation queries that can be evaluated linearly in the available time, we have several tools for reducing the query set to this desired number. In next week's follow up Blog we\u2019ll discuss these and other recommended strategies for improving Percolator performance. Closing ConsiderationsThe above delineation between Watcher and Percolator highlighted the scheduled nature of Watcher as being one of the defining characteristics of this plugin. This behavior is achieved through an extendable architecture which is currently only implemented by a time\/calendar based trigger. In the future, we will extend it to support additional use cases including real-time alerting. For example, a trigger could potentially execute on a file change. Furthermore, triggers could be based on percolation results (i.e. a percolator triggers a watch!). These components can therefore also be complementary. \n"}<br>{"index": {"_id": 930}}<br>{"title":"Kibana 4.2 Beta 1: I Heard You Like Betas","seo_title":"Kibana 4.2 Beta 1","url":"\/blog\/kibana-4-2-beta-1-i-heard-you-like-betas","author":{"name":"Spencer Alger"},"date":"August 31, 2015","category":"News","locales":"","content":" Have you been trying out the brand new\u00a0? Do you want to use Kibana with your test installation? Well, have I got news for you!\u00a0Today we're releasing a beta for your beta,\u00a0Kibana 4.2.0-beta1.This release offers\u00a0support for the first Elasticsearch 2.0 beta along with\u00a0a\u00a0handful of features and\u00a0bug fixes.\u00a0If you are too excited to stick around, go right ahead and\u00a0. If you are interested in what you are downloading however,\u00a0lets take a look at\u00a0some of the new features.Persistent ColorsStarting in the 4.2 beta, generated colors are bound to the data they represent.\u00a0This means that you no longer have to worry about the same color meaning multiple things on a single dashboard, hooray!\u00a0\u2014 Thanks\u00a0! Server StatusIn order to help people get a better idea of why Kibana may not be able to run, we now include a status page which can be accessed at any time, but also shows up automatically when there is a problem. For instance, if the Kibana server loses connectivity with Elasticsearch: Filter using the legendEach visualization's legend is a useful way to see the groups that data falls into, but now it's also a great way to filter a visualization by one of those groups! Just click on any of the labels and a filter will be added to the filter bar at the top of the page. This works across an entire dashboard, but combine it with\u00a0the introduced in 4.1 and your\u00a0filter now\u00a0applies\u00a0to all of\u00a0Kibana.Olson timezone supportOne of the features we are excited about in Elasticsearch 2.0 is the enhanced timezone support in the aggregation.\u00a0Support for\u00a0Olson timezone identifiers allows Elasticsearch to more accurately understand the UTC\u00a0offset of every single event,\u00a0even when\u00a0a\u00a0histogram covers a shift in UTC offset\u00a0like the start of daylight savings time. This\u00a0means that Kibana can better show when events\u00a0happened\u00a0in your local timezone. Structural\u00a0ImprovementsKibana 4.2 also introduces several\u00a0structural improvements\u00a0including: to all of the\u00a0contributors who have helped us pull\u00a0this beta\u00a0together. There are many other features, tweaks, and bug fixes that we couldn't mention here and they wouldn't be possible without you.If you have questions (or want to help answer some)\u00a0please check out the\u00a0\u00a0forums. If you find a bug, please\u00a0file it\u00a0on . Make something great? Tell about your #kibana dashboards on twitter. Happy data hunting! \n"}<br>{"index": {"_id": 931}}<br>{"title":"Where in the World is Elastic? - August 31, 2015","seo_title":"Where in the World is Elastic, August 24 2015","url":"\/blog\/2015-08-31-where-in-the-world-is-elastic","author":{"name":"Livia Froelicher"},"date":"August 31, 2015","category":"","locales":"","content":" Welcome to\u00a0 As we conclude the month of August, we continue to have meetups occurring worldwide.\u00a0Read on to see where we are!Upcoming MeetupsAugust 31: September 2: September 3: That's it for this week.\u00a0Stay tuned for Elastic happenings next week! - The Elastic Team P.S.\u00a0\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats,\u00a0Elasticsearch, Logstash or Kibana\u00a0\u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 932}}<br>{"title":"TTL Documents, Shield and Found","seo_title":"","url":"\/blog\/ttl-documents-shield-and-found","author":{"name":"Christian Strzadala"},"date":"August 28, 2015","category":"Engineering","locales":"","content":" Elasticsearch allows for many types of document mappings. An interesting mapping is the or mapping.\u00a0 This mapping allows us to set a expiry time for a document. Once the time has past, the expired documents are deleted.\u00a0 Note that in the current version of Elasticsearch, is deprecated. This post will look at the current mapping and how you can try to avoid using them. Let's define the mappingLet\u2019s say we are creating an index structure for a store called that has regular specials that end at various time periods. Here is an example mapping with a for a regular document, in this case called POST \/crazy-shop { \"mappings\": { \"special\": { \"properties\": { \"message\": { \"type\": \"string\" } }, \"_ttl\": { \"enabled\": true, \"default\": \"10s\" } } } } The is set to and defaults to . We can test this out by indexing the following document: PUT \/crazy-shop\/special\/1 { \"message\" : \"An awesome new special\" } We can get this document with the following request: GET \/crazy-shop\/special\/1 which will return: { \"_index\": \"crazy-shop\", \"_type\": \"special\", \"_id\": \"1\", \"_version\": 1, \"found\": true, \"_source\": { \"message\": \"An awesome new special\" } } So after 10 seconds, this document should be deleted, right? . How does expiring a document actually work?Elasticsearch has a background system process that will check for all expired documents and add them to a bulk delete request. This process by default runs every 60 seconds. This means that setting the for a document to anything under 60 seconds won\u2019t actually delete\u00a0the document until 60 seconds has past. This interval can be adjusted though, through the setting , so you can adjust this if needed. Delete operations are expensiveDeleting documents doesn\u2019t remove them from the index, but rather marks\u00a0them as and filters\u00a0them out at query time. Large amounts of bulk deletions can result in large Lucene index segments and in turn a large amount of data to handle until segment merges occur and deleted documents are finally removed from the index. Refer to for more information around Elasticsearch and Lucene indexes. With this in mind, our advice is to try and avoid using TTL. The expense that TTL causes Elasticsearch can in most circumstances be avoided using time based indices. The suggested re-implementation is to use a combination of two things: You may think your data model doesn\u2019t allow for time-based indices or there\u2019s some overhead around managing time-based indices. We\u2019ll demonstrate a modified data model below and there are already available for handling time-based indices. Example time based indicesContinuing our example, below is an example that allows for: An alias is also included to use a constant index name. PUT \/_template\/crazy-shop-template { \"order\": 0, \"template\": \"crazy-shop-*\", \"mappings\": { \"special\": { \"properties\": { \"message\": { \"type\": \"string\" }, \"expiry\": { \"type\": \"date\", \"format\": \"yyyy-MM-dd'T'HHmmssZ\" } } } }, \"aliases\": { \"crazy-shop\": {} } } We can add some documents to an index with a date in the index name which will create a new index with the document added to it: PUT \/crazy-shop-2015-08-24\/special\/1 { \"message\" : \"An awesome new special\", \"expiry\" : \"2015-08-24T202000+1000\" } PUT \/crazy-shop-2015-08-24\/special\/2 { \"message\" : \"Another awesome new special\", \"expiry\" : \"2015-08-24T203000+1000\" } Next, we can query the index using a filter for the field with a timestamp, which will filter out documents we don\u2019t need anymore. POST \/crazy-shop\/_search { \"query\": { \"filtered\": { \"query\": { \"match_all\": {} }, \"filter\": { \"range\": { \"expiry\": { \"gte\": \"2015-08-24T202500+1000\" } } } } } } We can delete the daily index manually with the following request: DELETE \/crazy-shop-2015-08-24 Or use tools like to automatically delete indices. Again, deleting the entire index is cheaper than having lots of deleted documents in an index. When time based indices may not workThere may be times when the use of time based indices may not work for your data model. You might require documents with a TTL to be in a relationship which requires all documents to be in the same index. For example, hotel deals that have a relationship and the deals expire at\u00a0various intervals. Deleting the index in this case would remove not only the deals but the hotel documents as well. In these situations, mapped documents are valid but it needs to be reminded that care should be taken of the cluster when large amounts of deleted documents occur. Also remember that is deprecated and that future versions of Elasticsearch may have new implementations of . It would be recommended to avoid using and have your application handle TTL of documents if time-based indicies doesn't work for you. How does Shield affect TTL documents?In the current version of Elasticsearch,\u00a0if Shield is installed, that\u00a0will affect documents with . The issue here is that Shield adds privileges to documents. When Elasticsearch\u2019s background system action is executed to add documents with an expired , the bulk delete operation fails as it doesn\u2019t have the appropriate privileges to delete these documents. The documents therefore are not deleted and stay available in the index. This affect the use of time based indices as Elasticsearch is not handling a background system level deletion of any documents or indices. \n"}<br>{"index": {"_id": 933}}<br>{"title":"Elasticsearch for Apache Hadoop 2.2.0-m1 and 2.1.1","seo_title":"","url":"\/blog\/elasticsearch-for-apache-hadoop-2-2-0-m1","author":{"name":"Costin Leau"},"date":"August 27, 2015","category":"Engineering","locales":"","content":" Hot on the heels of Elasticsearch 2.0.0-beta1 (check it out!), we are pleased to announce the of Elasticsearch for Apache Hadoop, or simply ES-Hadoop, and . ES-Hadoop 2.2.0-m1 This first milestone in the 2.2 branch introduces, among bug fixes, several new features: Want to use the new goodies in Elasticsearch 2.0 in Spark or Hadoop? That\u2019s what ES-Hadoop is here for! Note that compatibility with Elasticsearch 1.x is preserved in ES-Hadoop 2.2.x. At start-up, ES-Hadoop checks whether there\u2019s another version used in the job and properly informs the user. This helps the not-so-uncommon case of multiple versions being picked arbitrarily from different sources (task vs jar vs runtime vs Java classpath). While ES-Hadoop does provide data formatting, it now detects whether one is provided (such as ) and uses that instead allowing richer formatting of s. Future versions might be extended to support the new package in Java 8. Those building the source manually will notice the system has been upgraded to the latest stable version, resulting in some nice speed improvements and simplifications (such as being able to use Java 8 for building the Scala modules). ES-Hadoop 2.1.1 Alongside the milestone, ES-Hadoop 2.1.1 was . It is the latest stable version of ES-Hadoop and contains important bug-fixes and improvements such as: The operations in Elasticsearch Spark have been pushed-down resulting in instant response no matter how big the . Fatal network errors are detected early and reported better, simplifying diagnosis. A previous bug sometimes prevented Pig support from being used across Hadoop versions. This has now been addressed. Feedback ES-Hadoop 2.0.x and 2.1.x users are recommended to upgrade to while those interested in trying out Elasticsearch 2.2.0, should take ES-Hadoop for a spin. Let us know what you think on Twitter (@elastic) or on . You can report any problems on the GitHub . \n"}<br>{"index": {"_id": 934}}<br>{"title":"Improving User Intelligence with the ELK Stack at SCA","seo_title":"Improving User Intelligence with the ELK Stack at SCA","url":"\/blog\/improving-user-intelligence-with-the-elk-stack-at-sca","author":{"name":"Martin Johansson"},"date":"August 27, 2015","category":"User Stories","locales":"de-de","content":" is a leading global hygiene and forest products company, employing around 44,000 people worldwide. The Group (all companies within SCA) develops and produces sustainable, and . Sales are conducted in about 100 countries under .\u00a0Each brand\u00a0each has its own website and its own search.At SCA we use Elasticsearch,\u00a0Logstash, and\u00a0Kibana to record searches, clicks on result documents and user feedback, on both the\u00a0intranet and external sites. We also collect qualitative metrics by asking our public users a question after showing search results: \u201cDid you find what you were looking for?\u201d The user has the option to\u00a0give a thumbs up or down and also write a comment.What is logged?All search parameters and results information is recorded for each search event: the query string, paging, sorting, facets, the number of hits, search response time, the date and time of the search, etc. Clicking a result document also records a multitude of information: the position of the document in the result list, the time it took from search to click and various document metadata (such as URL, source, format, last modified, author, and more). A click event also gets connected with the search event that generated it. This is also the case for feedback events.Each event is written to a log file that is being monitored by Logstash, which then creates a document from each event and pushes them to Elasticsearch where the data is visualized in Kibana.Why?Due to the extent of information that is indexed, we can answer questions from the very simple, such as \u201cWhat are the\u00a0ten most frequent queries during the past week?\u201d and \u201cUsers who click on document X, what do they search for?\u201d to the more complex like \u201cWhat is the distribution of clicked documents\u2019 last modified dates, coming from source S, on Wednesdays?\u00a0The possibilities are almost endless!The answers to these questions allow us to tune the search to meet the needs of the users to an even greater extent and deliver even greater value. Today, we use this analysis for everything from adjusting the relevance model, to adding new facets or removing old ones, or changing the layout of the search and result pages.Experienced value \u2013 more than \u201cjust\u201d logsRecording search and click events are common practice, but at SCA we have extended this to include user feedback, as mentioned above. This increases the value of the statistics even more. It allows an administrator to follow up on\u00a0negative feedback in detail, e.g. by recreating the scenario. It also enables implicitly evaluated trial periods for change requests. If a statistically significant increase in the share of positive feedbacks is observed, then that change made it easier for users to find what they were looking for. We can also find the answer to new questions, such as \u201cWhat\u2019s the feedback from the users who experience zero hits?\u201d and \u201cAre users more likely to find what they are looking for if they use facets?\"And server monitoring as well!Benefits of the ELK Stack What this means for SCA is that they get a search that is ever improving. We, the developers and administrators of the search system, are no longer in the dark regarding what changes actually change things for the better. The direct feedback loop between the users and administrators of the system creates a sense of community, especially when users see that their grievances are being tended to. Users find what they are looking for to a greater and greater extent, saving them time and frustration.ConclusionWe rely heavily on Elasticsearch, Logstash and Kibana as the core of our search capability, and for the insight to continually improve. We're excited to see what the 2.0 versions bring. The challenge is to know what information you are after and create a model that will meet those needs. Getting the ELK platform up and running at SCA was the part of the project that took the least amount of our time, once the logs started streaming out of our systems. \n"}<br>{"index": {"_id": 935}}<br>{"title":"Elasticsearch 2.0.0-beta1 released","seo_title":"Elasticsearch 2.0.0-beta1 released","url":"\/blog\/elasticsearch-2-0-0-beta1-released","author":{"name":"Clinton Gormley"},"date":"August 26, 2015","category":"News","locales":"","content":" Today, we are excited to announce the release of , based on . This release contains over 2,500 pull requests from 469 committers. 850 of the pull requests are completely new to 2.0. : This is a beta release and is intended for testing purposes only. There is no guarantee that\u00a0Elasticsearch 2.0.0-beta1\u00a0will be compatible with\u00a0Elasticsearch 2.0.0 GA. You can . Elasticsearch 2.0.0-beta1 has some cool new changes\u00a0like: Besides the above, there are hundreds of incremental\u00a0changes in both Elasticsearch and Lucene which make Elasticsearch 2.0 safer, better, and easier. Have a look at these blog posts for more information about this release: \n"}<br>{"index": {"_id": 936}}<br>{"title":"Between the Curly Braces: Describe Elasticsearch","seo_title":"What is Elasticsearch? Between the Curly Braces.","url":"\/blog\/describe-elasticsearch","author":{"name":"Haley Eshagh"},"date":"August 25, 2015","category":"User Stories","locales":"","content":" Imagine you\u2019re walking down the street. You\u2019re thinking about query optimization, upgrading your cluster, what you should have for lunch \u2014 you know, the usual. Suddenly, you\u2019re stopped by someone, your average Joe, and he asks, \u201cHey, what is this Elasticsearch thing I keep hearing about?\u201d What would you say? How would you describe Elasticsearch? Before you rack your brain for a good answer, we captured a few responses on video at Elastic{ON}. We weren't sure how people would answer, but, boy, we\u2019re glad we asked. Elasticsearch can be many things to many people. It helps , , , (lunch problem solved!), and more. While Elasticsearch certainly started as a search engine, it\u2019s become more than just that. Elasticsearch helps you connect the proverbial dots and make sense of your data \u2014 whether it\u2019s server logs, mortgage rates, genetic code, or the complete works of Shakespeare. So, now it's your turn. How would you describe Elasticsearch? Give it a go on Twitter (with the added bonus of a 140-character limit) using #elastic. Lastly, we\u2019d like to say thanks to all of the folks who dropped by our recording studio (OK, maybe it was a trailer in a parking lot \u2014 we improvised) at Elastic{ON} to share their stories. We had a fantastic time and look forward to hearing more at an upcoming event. () \n"}<br>{"index": {"_id": 937}}<br>{"title":"Elasticsearch unplugged - Networking changes in 2.0","seo_title":"Elasticsearch unplugged - Networking changes in 2.0","url":"\/blog\/elasticsearch-unplugged","author":{"name":"Clinton Gormley"},"date":"August 25, 2015","category":"Engineering","locales":"","content":" You start Elasticsearch on your laptop. You issue a quick to clear out yesterday\u2019s experiments. Then you notice the plaintive cries issuing from the mouths of your developer colleagues and you wonder what pain they are suffering\u2026Elasticsearch has always been friendly and approachable. Testing out how a multi-node cluster works is as easy as starting up a few instances on your laptop: they auto-discover each other using multicast, form a cluster, and start sharing the load. But at times Elasticsearch has been a bit too friendly. Try starting Elasticsearch on your laptop at a conference, and you could easily find yourself participating in a 100 node cluster.The soon-to-be-released 2.0.0-beta1 comes with some networking changes that make\u00a0Elasticsearch choosier about who it talks to, while still maintaining the easy out-of-the-box developer experience. \n"}<br>{"index": {"_id": 938}}<br>{"title":"This Week in Elasticsearch and Apache Lucene - August 25 2015","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-08-25","author":{"name":"Michael McCandless"},"date":"August 25, 2015","category":"","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsWhy did we remove the Delete by Query API in 2.0? \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 939}}<br>{"title":"Where in the World is Elastic? - August 24, 2015","seo_title":"Where in the World is Elastic, August 24 2015","url":"\/blog\/2015-08-24-where-in-the-world-is-elastic","author":{"name":"Livia Froelicher"},"date":"August 24, 2015","category":"","locales":"","content":" Welcome to\u00a0 It is summer time but still we have a few meetups scheduled this week. Read on to see where we are!Upcoming MeetupsAugust 24: August 26: August 26:\u00a0August 26: August 26: That's it for this week.\u00a0Stay tuned for Elastic happenings next week! - The Elastic Team P.S.\u00a0\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats,\u00a0Elasticsearch, Logstash or Kibana\u00a0\u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 940}}<br>{"title":"Writing Custom Field Formatters for Kibana","seo_title":"","url":"\/blog\/kibana-custom-field-formatters","author":{"name":"Jon Budzenski"},"date":"August 24, 2015","category":"Engineering","locales":"","content":" Kibana 4.1 introduced a new feature called field formatters, giving us the ability to visually convert fields on the fly. \u00a0Field formatters provide a great way to display data in a different way\u00a0without changing how it is stored. \u00a0For a more in depth overview of what field formatters do, you can read a previous blog post\u00a0. The goal for this post is to walk through the steps of creating a new formatter. \u00a0We will start by going over the field formatter API, then implement a basic formatter that will draw attention to the word \"error\", and finally generalize our solution. Getting StartedInstructions on pulling down the Kibana development environment can be found at the . Starting from the Kibana root directory, field formatters are stored in . The resulting folder structure looks like: \/stringify |--type \u00a0\/\/Contains different formatters |--icons |--editors \u00a0\/\/HTML used by the formatter to request or display additional information |--__tests__ |--register.js \/\/Every formatter is registered with the application here In Kibana\u00a04.1, formatters can be found at . If using 4.1, paths in the code samples will need to be updated. Let\u2019s create a new file called in the folder and add some initialization code: define(function (require) { return function HighlightFormatProvider(Private) { var _ = require('lodash'): var FieldFormat = Private(require('ui\/index_patterns\/_field_format\/FieldFormat')): _.class(Highlight).inherits(FieldFormat): function Highlight(params) { Highlight.Super.call(this, params): } Highlight.id = 'highlight': Highlight.title = 'Highlight': Highlight.fieldType = ['string']: Highlight.prototype._convert = { text: _.escape, html: _.escape }: return Highlight: }: }): A class extending FieldFormat is implemented for each field format. \u00a0 is used internally by Kibana to keep track of the formatter and should not conflict with any other formatter id. \u00a0 is the displayed text\u00a0when selecting from a list of formatters, and describes what types of fields this formatter is available for. is where the formatting happens. It has methods for converting both text and html. The text method is used for tooltips, filters, legends, and axis markers. The html method is used for search tables. Both take a field value as input, and return what we want displayed visually. If you want both methods to behave the same, can be assigned as a function instead. Adding code to draw attention to errors looks like: Highlight.prototype._highlight = function (val, replace) { return _.escape(val).replace(\/(error)\/g, replace): }: Highlight.prototype._convert = { text: function(val) { return this._highlight(val, function convertToUpperCase(match) { return match.toUpperCase(): }): }, html: function(val) { return this._highlight(val, '<mark>$&<\/mark>'): } }: Any time a field has the text \"error\", we either wrap it in a mark element or convert it to uppercase depending on whether HTML or text is requested. It's important to use here, we want to avoid HTML injection and cross-site scripting attacks. We also need to register this field formatter with the application. In we add: fieldFormats.register(require('ui\/stringify\/types\/Highlight')): In the future, we (the Kibana team) will be\u00a0working on providing this functionality as a plugin, which will help simplify the registration process. We should now be able to add Highlight as a field formatter on fields with a string type! Testing it on the Discover page shows us it is working: GeneralizeThis works, but what if we want to highlight more than just errors? Instead of making a new field formatter for every input, let\u2019s match against an inputted regular expression. In the editor folder, add a new file called with the following: <div class=\"form-group\"> <label>Pattern<\/label> <input class=\"form-control\" ng-model=\"editor.formatParams.pattern\"\/> <\/div> Back in Highlight.js we need to define as our editor and update our method to use its input field as our pattern to match on. Highlight.editor = require('ui\/stringify\/editors\/highlight.html'): Highlight.prototype._highlight = function (val, replace) { var escapedVal = _.escape(val): var highlightPattern: try { var inputRegex = this.param('pattern').split('\/'): var pattern = inputRegex[0] || inputRegex[1]: var flags = inputRegex[2]: highlightPattern = new RegExp(pattern, flags): } catch(e) { return escapedVal: } return escapedVal.replace(highlightPattern, replace): }: SamplesIt may be beneficial to see how an\u00a0inputted\u00a0pattern\u00a0behaves before applying the\u00a0formatter. There\u2019s a directive that has already been built that will let us see some example conversions as we modify our pattern. We can use this by adding sample field values, and including the directive in our template. In highlight.html, append: <field-format-editor-samples inputs=\"editor.field.format.type.sampleInputs\"><\/field-format-editor-samples> In Highlight.js: Highlight.sampleInputs = [ 'Hello world', 'The quick brown fox jumps over the lazy dog', '112345' ]: The end\u00a0result is: ConclusionThe field formatter API provides an easy way to customize how your fields are displayed. Kibana comes with several built in formatters but in the event that none match your needs, this feature was built in a way to let anyone add their own. If you are planning on adding your own formatters, you can check back here after Kibana 4.2 has been released to be notified of any API changes. \n"}<br>{"index": {"_id": 941}}<br>{"title":"Logstash 1.5.4 and 1.4.5 released","seo_title":"Logstash 1.5.4 and 1.4.5 released","url":"\/blog\/logstash-1-5-4-and-1-4-5-released","author":{"name":"Pier-Hugues Pellerin"},"date":"August 20, 2015","category":"Releases","locales":"","content":" We are announcing the \u00a0of logstash 1.5.4 and 1.4.5 which fixes important security issues. Our recommendation is to upgrade immediately if you are using either of the following features: After the release of 1.5.3, users encountered an issue where Logstash Forwarder was unable to communicate to Logstash instance because of SSL\/TLS certificate validation errors. This has been fixed. Typically used to connect two Logstash instances. In such deployments, one Logstash instance is used to collect logs from a webserver and securely transmit them to a central Logstash instance to perform additional filtering and storing. Security FixesWhen using SSL\/TLS functionality, Lumberjack output from Logstash 1.5.3 and prior versions did not validate certificate presented by the Logstash instance acting as a server. This exposes a man in the middle vulnerability. We have been assigned \u00a0for this issue and have added this vulnerability to our . \u00a0Users of Logstash Forwarder are not affected by this particular vulnerability Enhancements Added the ability to update existing ES documents and support of upsert \u00a0--\u00a0if document doesn't exist, create it (). Thanks to\u00a0\u00a0for contributing this enhancement!\u00a0output { if [use_case] == \"doc_upsert\" { elasticsearch { host => \"elasticsearch\" protocol => \"http\" action => \"update\" document_id => \"%{[uid]}\" doc_as_upsert => true } } else if [use_case] == \"doc_static_upsert\" { elasticsearch { host => \"elasticsearch\" protocol => \"http\" action => \"update\" document_id => \"%{[uid]}\" upsert => '{\"static_field\": \"demo\"}' } } else if [use_case] == \"doc_dynamic_upsert\" { elasticsearch { host => \"elasticsearch\" protocol => \"http\" action => \"update\" document_id => \"%{[uid]}\" upsert => '{\"use_case\": \"%{[use_case]}\", \"dynamic\": { \"fieldC\": \"%{[dynamic_field][fieldC]}\"}}' } } } Bug fixes Below is a list of bug fixes in core and\u00a0plugins. For a full list, please check the . FeedbackPlease \u00a0Logstash 1.5.4 and let us know what you think on Twitter ()\u00a0or on our forum. You can report any problems on the GitHub \u00a0page. \n"}<br>{"index": {"_id": 942}}<br>{"title":"This Week in Elasticsearch and Apache Lucene - August 18 2015","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-08-18","author":{"name":"Alexander Reelsen"},"date":"August 18, 2015","category":"","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsSee how GuideStar, with help from , aggregates, analyzes, & provides data for grantmakers & benefactors: \u2014 GuideStar USA (@GuideStarUSA) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 943}}<br>{"title":"The Delete by Query API Is now a plugin","seo_title":"","url":"\/blog\/core-delete-by-query-is-a-plugin","author":{"name":"Michael McCandless"},"date":"August 18, 2015","category":"Engineering","locales":"","content":" As of Elasticsearch's 2.0.0-beta1 release we have the previous core implementation of the and with a new . Here we explain why we did this and how the plugin's implementation differs from the previous core implementation. If you use the Delete by Query API, after upgrading to 2.0, just install the plugin\u00a0and then\u00a0 : bin\/plugin install delete-by-query Why did we do this? We take the quality of Elasticsearch's core APIs seriously, and the previous\u00a0implementation of Delete by Query had major issues that could not easily be fixed: In contrast, the has a fully safe implementation: it runs to find all ids matching the query, and then uses the to delete them. This implementation is necessarily slower, especially if the query deletes many documents. Be sure to test your application if you delete many documents using this API, and consider switching to a different approach where you can . The\u00a0\u00a0describes more details about the motivation and differences in the new implementation.A minimal Elasticsearch core Switching to a plugin was not an easy decision: many users were able to use the faster core Delete by Query without issue. Still, the danger was always there, and a non-trivial number of users did hit the serious problems above. Furthermore, Elasticsearch's core must remain reliable and lean. Any feature which can be built on top of the other core APIs really does not belong in the core, especially if it's buggy. All features in the core should be ironclad, and Delete by Query, despite its popularity and high performance, simply wasn't.We take resiliency and quality seriously enough to make hard tradeoffs like this one, when necessary.Deleting a Mapping is gone has also because it could lead to index corruption if the same field names were later re-used in a new type but with different mappings. However, you can still delete all documents for a given type using the plugin with a \u00a0against that type,\u00a0or strongly consider changing your approach to use a separate index instead of different types within one index. \n"}<br>{"index": {"_id": 944}}<br>{"title":"How Blueliv Uses the Elastic Stack to Combat Cyber Threats","seo_title":"","url":"\/blog\/how-blueliv-uses-the-elastic-stack-to-combat-cyber-threats","author":{"name":"Jo\u00e3o Alves"},"date":"August 17, 2015","category":"User Stories","locales":"","content":" Why the ELK stack? Most companies that are defending themselves against these attacks use some kind of Security Information and Event Management (SIEM) software that allows them to aggregate and correlate data. This software allows them to set up dashboards in order to quickly visualize the information. Elasticsearch, Logstash, and Kibana are a really great toolsets for our clients: Given these characteristics and how well these tools work seamlessly together, many companies take advantage of these technologies as a SIEM. Therefore, it makes a lot of sense to offer our cyber threat intelligence feeds via a Logstash input plugin that allows users to receive real-time insights about cyber threats in just a couple of minutes. In order to get our data feeds into the ELK stack, we developed a Logstash input plugin that periodically collects them for you, letting you focus on the data analysis and making your company more secure. Logstash output configuration allows us to use different indexes to save different information (for instance, bot IPs and crime servers), which makes the dashboard visualization and creation easier. Another critical characteristic of Elasticsearch (taking into account that we currently analyze and collect information about millions of crime servers and infected IPs) is its stunning performance. It indexes all this data and lets our clients search against it quickly. Protect your network with the ELK stack and Blueliv Every day, millions of people worldwide are affected by cyber attacks. This means that your company's safety and therefore your privileged information may be compromised. With Blueliv Logstash input plugin, you can start to monitor and get insights about cyber threats. Our ELK users will be able to access the Blueliv's global intelligence such as malware distribution domains, C&Cs, phishing campaigns, exploit kits, backdoors, infected IPs, affected operating systems, and more at a glance using Kibana dashboards. To get started, we offer a free API for crime servers that contains a subset of our unique cyber threat intelligence, as well as a 14-day trial of our full-featured feeds. A lot of companies (banks, insurance companies, pharmaceuticals, etc) manage sensitive information about their clients and their own business. For such companies, these information leaks may have a huge impact at the financial and customer level, besides the damage to the company's\u00a0reputation and brand. On the other hand, for companies with hundreds of thousands of employees, distributed across the world, it is really difficult to enforce security policies based on \u201ccommon-sense\u201d.\u00a0Attackers know this very well, and will use social engineering techniques (such as phishing attacks that replicate legitimate websites) or other malware distribution techniques, in order to trick the users and thus obtaining information from the infected user, such as credentials, confidential documents, etc. The need to quickly identify, prevent, or mitigate these\u00a0attacks arises. Blueliv continuously scours and analyses hundreds of sources to provide unique intelligence about verified online crime server conducting malicious activity, infected bot IPs, malware hashes and hacktivism activities. The feeds are offered as an easy to buy solution that provides high-impact results rapidly. The user can understand what attack vectors malicious actors are using, understand potential indicators of compromise (IoC) and deploy mitigation solutions. Although many of the above described companies performed some kind of log analysis, they do not have access to real-time cyber threat insights that would allow them to take action. That is why we launched . If our clients already used the ELK stack for Log analysis it would be easier to install a plugin using the technologies they already know and are used to working with. Taking action against malicious IPs and domains One of our clients had the problem that we stated above. Although they had set-up security policies in their users' machines and other classic security devices, they could not prevent users from inadvertently accessing insecure websites or from downloading insecure attachments from emails. So how could the ELK and Blueliv plugin help with this? Having Blueliv's cyber threat data collected by Logstash and stored in Elasticsearch, our clients could visualise cyber threats in real-time through Kibana and get alerts in order to react in time. For them it was extremely important to visualise these IoCs because it allowed them to take action quickly. Updating the operating systems, blocking IPs and domains were some of the measures that were taken. This was only possible due to the ability to correlate Blueliv's data with their own network logs, using Logstash and Elasticsearch. The correlation went even further: discovering what were the most affected departments and machines. This allowed for the creation of new security policies and the stricter enforcement of current ones. All of this would be a lot harder to discover without Blueliv's data and the correlation and visualisation performed with the ELK stack. You can find out more about plugin and how to use it with the ELK stack here: Future Blueliv cyber threat intelligence data feeds have been available for major SIEMs and via REST API for some months. Currently we are working to bring emerging threats to our cyber threat intelligence platform engine. Our goal is to deliver focused, targeted cyber threat intelligence in a timely manner in order to look our clients take actions and avoid direct and indirect financial harm. With the help of the ELK stack we have been able to get a wider user-base and to deploy features in our cyber threat feeds quicker. Moreover, the learning curve and installation complexity are nearly non-existent, which let users get started with our data without technical support. Overall, we have been pleased with the ELK stack, how it works out-of-the-box and how easy it is to set-up and use a plugin in the Logstash ecosystem. \n"}<br>{"index": {"_id": 945}}<br>{"title":"Where in the World is Elastic? - August 17, 2015","seo_title":"Where in the World is Elastic, August 17 2015","url":"\/blog\/2015-08-17-where-in-the-world-is-elastic","author":{"name":"Livia Froelicher"},"date":"August 17, 2015","category":"","locales":"","content":" Welcome to\u00a0 It is summer time but still we have a few meetups scheduled this week. Read on to see where we are!Upcoming EventsAugust 22-23: - Don't miss talk on on Sunday, August 23 at 10 a.m. &\u00a0check out the Elastic bouncy castle, too!Upcoming MeetupsAugust 19: August 19: August 22:\u00a0August 19: August 20: That's it for this week.\u00a0Stay tuned for Elastic happenings next week! - The Elastic Team P.S.\u00a0\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats,\u00a0Elasticsearch, Logstash or Kibana\u00a0\u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 946}}<br>{"title":"More Signal, Less Noise with Elasticsearch","seo_title":"","url":"\/blog\/more-signal-less-noise-with-elasticsearch","author":{"name":"Wesley Hall"},"date":"August 13, 2015","category":"User Stories","locales":"","content":" By the time you finish reading this sentence, the Signal platform will have received, extracted, analysed, classified and indexed a volume of text equivalent in size to the complete works of Shakespeare. This is a process that continues, in real time, 7 days a week, 365 days a year, allowing users to intelligently strategize and make data-driven decisions. The Importance of Search\u00a0 As a startup, and lacking the resources of the well-known search behemoths, we needed to create the kind of infrastructure that could manage this data and make it available instantly, and we needed to do this on a budget. Since a primary function of our product is search and discovery, what we really needed was a highly-effective, open source text search infrastructure component that could be relied upon to scale up with our increasing data volumes. We found this component in the fantastic Elasticsearch system. The Signal software system is effectively a large scale data processing pipeline that runs sophisticated text analytics routines. As we receive our incoming stream of news articles and blog posts, each is processed through this pipeline, extracting references to important entities such as organisations, people and places. Articles are classified into topics using advanced models built using our machine learning technology. Finally, articles are grouped into clusters of where they described related events or stories. The result of this processing pipeline is large volumes of text (up to 7 million individual articles per day and growing) with associated meta-data describing the meaningful entities and concepts that have been detected by our system. Once this data has been prepared by our pipeline system it is indexed into an Elasticsearch cluster consisting of 15 fairly substantial, cloud-based server instances making it available for search, exploration and discovery by our users. The decision to place Elasticsearch at the centre of our infrastructure was really a matter of coming to the realisation that search is not just a feature of our product: it \u00a0our product. Our entire offering is based around providing users with the ability to locate relevant information. Our system divided neatly between the extraction of this relevant information and the ability to make effective use of it. Why Elasticsearch?\u00a0 Previously, search had been much more of a secondary feature as we focused on the delivery, inbox-style, of the relevant articles to the interested users. The shortcomings of this approach quickly became obvious, however, as we began to consider where our users may want to go next. The feeds themselves offer an excellent jumping off point into further exploration and discovery of the available content but this service was difficult to provide without an effective search system. Up until this point we had been using the AWS cloud search product to provide the search capabilities of our system, but cloud search lacked the advanced features that we needed such as complex aggregation or sophisticated monitoring and control. We needed something with these features and more\u2026 Elasticsearch was an obvious forerunning candidate to provide the infrastructure required for this project. Having worked (albeit briefly) with Elastic CTO Shay Banon as part of an eBay project, I was already aware of the degree of technical competency found in the Elasticsearch software. I knew that Elastic really would mean \u00a0and having confidence in the initial creators is something that takes me a long way when it comes to my technology selection process.\u00a0We began a proof of concept implementation towards the end of 2014, and like many successful PoCs this eventually grew in to our V2 product. Reimagining the\u00a0View on\u00a0Data Reimagining our product as being a multi-faceted search system has changed its nature and how we approach its evolution. We move forward by providing our users with different views and perspectives on their data, all of which are provided by combinations of features found native in the Elasticsearch system. The ability to create visualisations of complex aggregations introduces entirely new ways to look at the world. Better still, by having all of our data available in Elasticsearch, our development and research teams can quickly explore ideas and concepts using tools like Kibana to test the value of a particular approach to data delivery and visualisation. This ability to \u2018mock up\u2019 a technique before taking the time to integrate it into our core product has enabled us to take a far more experimental approach in our development process. Expert Support Engaging Elastic to provide development support for our infrastructure is proving to be one of those decisions\u00a0that we really wish we had made earlier. We have found real value in having access to the core team at Elastic\u00a0to ensure that\u00a0we are using the system effectively. Putting Elasticsearch at the centre of what we are building has proven itself to be one of the best technology decisions that we have made during our growth. It\u2019s truly been a joy to work with and we look forward to finding new and interesting ways to leverage its feature to provide the kind of value that our customers have come to expect of us. \n"}<br>{"index": {"_id": 947}}<br>{"title":"Better Data Makes For A Better World","seo_title":"","url":"\/blog\/better-data-makes-a-better-world","author":{"name":"Daniel Palay"},"date":"August 13, 2015","category":"User Stories","locales":"","content":" There\u2019s a lot of talk in the tech industry of having the next big thing that\u2019s going to change the world. I think we can all agree there are some times where \u2018changing the world\u2019 is an understatement - think about what you would do without your smartphone or access to something like Google, GPS navigation, or even Facebook and Twitter. More often than not though, it\u2019s a mixture of hope and hyperbole and I think the world is starting to catch on - look no further than the current trend of American television commercials (including with Jeff Goldblum) satirizing our industry.\u00a0 But every once in a while, we\u2019re lucky enough to come across an organization where even hyperbole doesn\u2019t do justice for their work.\u00a0 From their Williamsburg, Virginia headquarters, the team at GuideStar (with a little help from the Elastic platform) aggregates, analyzes, and provides data for grant\u00a0makers and benefactors all over the world. Through their free and subscription-based services, GuideStar makes it easier for prospective donors to find reputable charities and nonprofits (like man animal shelters across the United States participating in this weekend\u2019s campaign) to which they could donate their time and money.\u00a0 Even more than that, GuideStar is revolutionizing the way nonprofits can now benchmark their own effectiveness within their area of influence by providing data to customers on how similarly focused nonprofits are making an impact around the world. Using this data, nonprofits are now more able to make critical adjustments on the fly which can translate into instant improvements to operations and effectiveness within their communities. I had the pleasure of meeting Shane Ward - GuideStar\u2019s Data Architect - this past February, and it didn\u2019t take long to see his passion for changing the world come through. Don\u2019t take my word for it though, just let our latest customer spotlight be your guide as Shane narrates you through their daily journey to change the world by leveraging Elasticsearch to provide . \n"}<br>{"index": {"_id": 948}}<br>{"title":"This Week in Elasticsearch and Apache Lucene - August 12 2015","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-08-12","author":{"name":"Michael McCandless"},"date":"August 12, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsSame topic, new expert tips! . presents 'Staying in Control w\/Moving Avgs - Pt 2.' \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 949}}<br>{"title":"Staying in Control with Moving Averages - Part 2","seo_title":"","url":"\/blog\/staying-in-control-with-moving-averages-part-2","author":{"name":"Zachary Tong"},"date":"August 12, 2015","category":"Engineering","locales":"","content":" Last week, using the new pipeline aggregations. \u00a0The demonstration used a very simple dataset, where the trend was very flat, and the spike was very obvious. \u00a0In fact, it was so obvious you could probably catch it with a simple threshold. This week, we'll show how the same control chart can be used in more tricky scenarios, such as constantly increasing linear trends, or cyclic\/seasonal data \n"}<br>{"index": {"_id": 950}}<br>{"title":"Where in the World is Elastic? - August 10, 2015","seo_title":"Where in the World is Elastic, August 10 2015","url":"\/blog\/2015-08-10-where-in-the-world-is-elastic","author":{"name":"Livia Froelicher"},"date":"August 10, 2015","category":"","locales":"","content":" Welcome to\u00a0 It is summer time but still we have a few meetups scheduled this week. Read on to see where we are!Upcoming MeetupsAugust 10: August 12: August 13: August 11: That's it for this week.\u00a0Stay tuned for Elastic happenings next week! - The Elastic Team P.S.\u00a0\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats,\u00a0Elasticsearch, Logstash or Kibana\u00a0\u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 951}}<br>{"title":"Shield 1.3.2 Released","seo_title":"","url":"\/blog\/shield-1-3-2-released","author":{"name":"Jay Modi"},"date":"August 10, 2015","category":"Releases","locales":"","content":" Today, we are pleased to announce the bugfix release of Shield 1.3.2. This Shield release contains several bug fixes, most notably\u00a0fixes for forwarding audit events to remote clusters and ensuring that node startup is not aborted due to a LDAP connection failure. For a full list of fixes, take a look at the\u00a0. We recommend that existing Shield users upgrade.For a new installation, download Shield 1.3.2\u00a0: to upgrade from a prior version of Shield, please follow the . \n"}<br>{"index": {"_id": 952}}<br>{"title":"This Week in Elasticsearch and Apache Lucene - August 04 2015","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-08-04","author":{"name":"Alexander Reelsen"},"date":"August 04, 2015","category":"","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsStaying in Control with Moving Avgs: outlier detection via new pipeline aggs \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 953}}<br>{"title":"Staying in Control with Moving Averages - Part 1","seo_title":"","url":"\/blog\/staying-in-control-with-moving-averages-part-1","author":{"name":"Zachary Tong"},"date":"August 03, 2015","category":"Engineering","locales":"","content":" In manufacturing and business processes, there is a common tool called a . Created in 1920 by Dr. Walter Shewhart, a control chart is used to determine if a process is \"in control\" or \"out of control\". \u00a0 At the time, Dr. Shewhart was working at Bell Labs trying to improve the signal quality of telephone lines. \u00a0Poorly-machined components was a leading cause of signal degradation, so improving manufacturing processes to produce more uniform components was a critical step in improving signal quality. We can graph this and see that the spike (yellow) shoots up past the control limit (green). \u00a0In a real system, this is when you send out an alert or email. \u00a0Or maybe something more drastic, since this is a nuclear reactor we are modeling : ) \n"}<br>{"index": {"_id": 954}}<br>{"title":"Where in the World is Elastic? - August 3, 2015","seo_title":"Where in the World is Elastic, August 3 2015","url":"\/blog\/2015-08-03-where-in-the-world-is-elastic","author":{"name":"Livia Froelicher"},"date":"August 03, 2015","category":"","locales":"","content":" Welcome to\u00a0 Read on for the full overview of this week's events and meetups happening all around the world!\u00a0 Upcoming Events August 1-6: - Join a community speaker for his talk on , Wednesday, August 6, 12:45 p.m. - 3:15 p.m. August 4-5: - say hi to who is attending in the hallway track and ask any question you may have around ELK! August 6-9:\u00a0 - and again, will be present and ready for any questions you may have. Upcoming Meetups August 4: August 5: August 6: August 6: August 4: August 6: That's it for this week.\u00a0Stay tuned for Elastic happenings next week - there's much to come!\u00a0 - The Elastic Team P.S.\u00a0\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats,\u00a0Elasticsearch, Logstash or Kibana\u00a0\u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 955}}<br>{"title":"INSERT INTO LOGSTASH SELECT DATA FROM DATABASE","seo_title":"","url":"\/blog\/logstash-jdbc-input-plugin","author":{"name":"Tal Levy"},"date":"August 03, 2015","category":"Engineering","locales":"","content":" Ever want to search your database entities from Elasticsearch?\u00a0Now you can use Logstash\u00a0to do just that!\u00a0In this blog we introduce the , which has been created to import data from any database that supports the . Below, we show you few examples of using this plugin. Getting StartedInstallationbin\/plugin install logstash-input-jdbc Driver SupportPopular databases like Oracle, Postgresql, and MySQL have compatible JDBC drivers that can be used with this input. This plugin does not come packaged with any of these JDBC drivers out of the box, but is straightforward to download. You can then configure the plugin to use the desired jdbc driver library. The setting and are used to load the library path and the driver's class name. Lets get started with the examples! Example 1: Simple Postgres InputHere is an example of how you get started reading from a local \u00a0database. As a prerequisite,\u00a0\u00a0the Postgresql JDBC drivers to use with the plugin. Setting Up The\u00a0DatabaseBefore we get started, let's create a table called and populate it with some contacts! create table contacts ( After this runs, here are the contents in the database in table form. Logstash ConfigurationWe can go ahead and output all these events to the console with this sample\u00a0Logstash\u00a0configuration: # file: simple-out.conf input { \u00a0\u00a0\u00a0\u00a0jdbc { \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0# Postgres jdbc connection string to our database, mydb \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0jdbc_connection_string => \"jdbc:postgresql:\/\/localhost:5432\/mydb\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0# The user we wish to execute our statement as \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0jdbc_user => \"postgres\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0# The path to our downloaded jdbc driver \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0jdbc_driver_library => \"\/path\/to\/postgresql-9.4-1201.jdbc41.jar\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0# The name of the driver class for Postgresql \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0jdbc_driver_class => \"org.postgresql.Driver\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0# our query \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0statement => \"SELECT * from contacts\" \u00a0\u00a0\u00a0\u00a0} } output { \u00a0\u00a0\u00a0\u00a0stdout { codec => json_lines } } Now we can run Logstash and see the results! Awesome, we read data from Postgresql! Up next,\u00a0we will demonstrate two examples of how you may use this plugin in the context of Elasticsearch. Example 2:\u00a0Synchronizing Data In Your Table To ElasticsearchIn the case that we are using our database as an input source for Elasticsearch, we may\u00a0be interested in keeping our existing documents\u00a0in-sync with our data as the database undergoes updates.\u00a0In this case, we can simply index our rows in Elasticsearch with unique ids such that any\u00a0time we re-index them, they will just update. This way, we prevent Elasticsearch from assigning\u00a0a new ID for each record and generating duplicates! Let's do a quick check to see that \"Sam\" was indexed into Elasticsearch So far we just saw how to use a query to fetch results from a database query, but what if\u00a0we want to update our index with new changes? What if some of our contacts changed emails,\u00a0or we want to update someone's last name? Here is a sequence of changes that we can apply to\u00a0our table and later verify the behavior we want in the resulting Elasticsearch index. Now we can run Logstash with the same configuration. When we do the same query as before, we will\u00a0 notice that our document containing Sam has been updated and is now Using this method, we can re-index our table into Elasticsearch without ending up with duplicates. One thing to note is that we are not able to capture deletes to documents under this scheme. Example 3: MusicBrainz Demo is an open music database containing up-to-date information\u00a0about artists, their works, and everything in-between. You can learn\u00a0more at\u00a0.\u00a0 MusicBrainz graciously\u00a0hosts a biweekly\u00a0data dump of their database . This data is\u00a01.8GB with information about\u00a0around 18\u00a0million tracks How to get the MusicBrainz data You must first run your own mirror of the MusicBrainz database. This can\u00a0be achieved using a tool called . The project's repo has instructions on syncing with the data-dump. Formulating a query to loadNow that we have all of this wealth of music data in an accessible database, we can choose a subset of the data we wish to index into Elasticsearch.\u00a0We may be interested in exploring the data about artists and their releases. Here is a\u00a0SQL query to fetch a few attributes belonging to artists and their releases: Using Logstash to Query The Database and Index Into Elasticsearch In this case, we have such a complex query that we chose to leverage the\u00a0 parameter option.\u00a0 Exploring Data in KibanaOne great feature of migrating a part of the data into Elasticsearch is the ability to generate great insightful visualizations using Kibana. For starters, let's see how many musical releases are introduced year over year! (image:\u00a0Number of releases per year from 1900 to 2010) Seeing general counts is a nice starter, but we can explore much more! For example, these releases have artists, countries, and release types associated with them. In the following Kibana dashboard we can see the 20 artists with the most number of releases associated to them. We can also visualize the differences between album, EP, and singles releases across the various producing countries. We can drill\u00a0into our donut visualization and filter for\u00a0EPs that were produced by artists from the United Kingdom. You may recognize some of these artists, while others may be new to you. Musicbrainz collects data about so many artists, there is always something new to discover! More InformationThis post only begins to explore the integrations and features the JDBC plugin includes. For more information, check out the\u00a0plugin's . We would love your feedback on our : if you think you\u2019ve found a bug in this plugin, please submit an . \n"}<br>{"index": {"_id": 956}}<br>{"title":"How Elasticsearch Helped Orange to Build Out Their Website Search","seo_title":"","url":"\/blog\/how-elasticsearch-helped-orange-to-build-out-their-website-search","author":{"name":"Jean-Pierre Paris"},"date":"July 31, 2015","category":"User Stories","locales":"fr-fr","content":" A web search engine is not a monolithic application. The picture below shows that there are many different types of data that contribute to building a useful and attractive response page such as a newspage (a), \u201cdid you know\u201d section (b), French web documents (blue) with a sub-section of associated articles (red) (c) , videos (d), and the buzz (e). In addition to the web search index, we have developed specialized \u201cvertical engines\u201d for each type of data, like weather, recent films, or sports-related news. Each of these vertical engines are built on a dedicated corpus that is much smaller than the main French web source of documents. a) b) c) d) e) A History of Our Legacy Since its beginning more than 15 years ago, the Orange French search engine \u2014 has evolved by developing its own technology and by integrating open source frameworks. Back in 2013, each vertical engine was built on proprietary solutions or older versions of the Sphinx search engine. Moreover, every single vertical engine ran on its own set of hardware, including redundancy. This was expensive and difficult to manage, but even worse was that the complexity increased every time a new vertical engine, or new feature, had to be deployed. Last, but not least, the job of the team that runs these engines became more and more complex because of the various technologies in use. After living with this complexity for years, we realized that we needed to reduce the number of different technologies and improve our ability to quickly add new features. Finding a New Universal Engine to Power Our Search Platform Selecting a new technology on which to base all of our vertical engines was a difficult, but important choice for us. Different teams have developed the vertical engines, and they each had been working with different search technologies. To encourage them to switch, we had to simplify the interface, and ensure that the technology we selected could meet the many technical requirements, like high availability, high throughput and low latency. During summer 2013, we evaluated both Elasticsearch and Solr. It quite quickly came down to Elasticsearch mainly because of the consistent, comprehensive API and the fact that it was designed from its beginning to be, well, elastic. Elasticity \u2014 horizontal scalability \u2014 was one of the key requirements for our migration. Even though our initial roll-out was starting with a single vertical engine, we were selecting a technology on which all of our future vertical engines and features would be built. As such, the technology had to be able to scale to handle new vertical engines, but it also had to be able to grow along with our user base. The first Elasticsearch cluster went live at the end of 2013, with just 2 indexes and less than one million documents. Today, we have 3 clusters, the biggest having 50 million documents on 20 virtual machines (8CPU, 20GB\u00a0RAM and 100GB\u00a0HDD). The primary size of these indices is 150GB, and we're able to process hundreds of requests per second with latency rates under 200ms, all while running on VMs rather than dedicated hardware. Moving away from our legacy interface was made easy by the Elasticsearch REST JSON interface as JSON parsing and HTTP clients are easy to develop in almost every language. Moreover, Elastic provides client libraries for mainstream languages, which simplifies our interaction with Elasticsearch even more by hiding the low level of JSON parsing and HTTP interactions. Thanks to the simple client libraries, our internal customers are now moving to Elasticsearch for the vertical engines. Because we can rapidly deploy new Elasticsearch indexes and clusters, it is easier than ever for our internal teams to create new vertical engines, new features, and handle more data. Based on our experience so far, we are confident that we can operate Elasticsearch in a demanding environment. We rely heavily on Marvel, the Elasticsearch monitoring tool, to help us keep an eye on the running clusters with a 0 downtime objective for one critical cluster. As of now, when you query the search engine on , most of the results \u2014 whether it's about the latest sport update, a new movie or the recent volcano eruptions in Italy \u2014 you get from the vertical engines are powered by Elasticsearch. What's Next? We are currently experimenting with Elasticsearch for more of our internal tools. For example, we are developing a tool to analyse the readability or \u201cquality\u201d of the 1.2 Billion URLs in our French web database. We use Kibana to create dashboards aggregating URL information for a specific host or domain (see image below).We can then quickly determine whether the URLs are readable and get a sense for the overall quality of the domain or host. We also use Logstash and Kibana to experiment with log aggregation for our live cluster. And I am really excited to discover Packetbeat as it takes me back more than 10 years, when I was working on IP traffic analysis. Our success with Elasticsearch makes us want to experiment more with the entire Elastic platform for internal tools with much more data. Hence, there are definitely more stories to be told in the near future when these experiments run live. So, stay tuned, we'll be back with more Elasticsearch fun\u2026 (as you can see I am already working on it :)) \n"}<br>{"index": {"_id": 957}}<br>{"title":"Stick With It - Pinned Filters in Kibana","seo_title":"","url":"\/blog\/stick-with-it-pinned-filters","author":{"name":"Joe Fleming"},"date":"July 31, 2015","category":"Engineering","locales":"","content":" One of the\u00a0new\u00a0features that was added to Kibana in version\u00a04.1 is something we call . Pinned Filters allows you to craft filters in one part of Kibana and bring those filters with you to all the other parts. It started as an enhancement idea from a user in the IRC channel, and now we can't imagine using Kibana without it.\u00a0Creating Pinned Filters is a simple, 1-click operation. You start by creating some filters, for example, by .Next, you need to decide what filters you'd like to take with you. Once you've decided, simply hover over the filter and click the pin icon, and you'll see a pin\u00a0icon\u00a0show up on the filter. This icon\u00a0lets\u00a0you quickly see\u00a0which filters are pinned. You can click on the pin icon again to un-pin the filter.\u00a0If you've got a lot of filters and you simply want to pin them all, you could spend your time clicking on each one, but there's a faster way. If you click on the \u00a0menu in the filter bar, it will open a menu that allows you manipulate \u00a0of the filters, simply click on .Now that you've got one or\u00a0more pinned filters, when you go to another app, like Visualize, the filters will follow along. It's that simple!Generally, users use filters to tease out interesting records in their data set, and pinned filters let them get more out of that effort. For example, after\u00a0filtering\u00a0down data in a visualization, they can take those filters over to Discover and see the records responsible for that visualization.\u00a0That concludes our crash course in Pinned Filters, now go forth and pin! \n"}<br>{"index": {"_id": 958}}<br>{"title":"Packetbeat on Found","seo_title":"Packetbeat on Found","url":"\/blog\/packetbeat-on-found","author":{"name":"Konrad Beiske"},"date":"July 30, 2015","category":"Engineering","locales":"","content":" This article refers to\u00a0our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. Packetbeat is the tool that lets you ship your network data into Elasticsearch so you can visualize them in Kibana. How Does It Work?Packetbeat taps into the network stack on the machine it's running on, analyzes all the traffic for known protocols and extracts useful information from each packet, before shipping that information into Elasticsearch. Currently it supports HTTP, PostgreSQL, MySQL, Redis and Thrift. Packetbeat is a competitor to Logstash, you say? Well, yes and no. There is some overlap between Packetbeat and Logstash, they both feed data into Elasticsearch, but their use cases are still slightly different. Packetbeat focuses on network traffic while Logstash focuses on logs. Both are capable of extracting metrics and Packetbeat also has a sibling called Filebeat that can consume log files. Filebeat can either feed logs directly into Elasticsearch or forward them to Logstash for centralised preprocessing. InstallingInstalling Packetbeat is very straightforward. Download the package matching your platform from and install it with your package system or simply extract the archive if you opted for one of the or files. ConfiguringOnce Packetbeat is installed, it is time to edit . The Debian and the RPM packages install this file directly to , but the generic packages just leave it in the directory you extracted it to. ShipperThere are three noteworthy properties in this section, , and . The attribute is meant to uniquely identify the server Packetbeat is monitoring and it defaults to the host name. You can safely leave it blank or just give a name that makes sense to you. The attribute allows you to specify tags that will be applied to all data originating from this server. Use it for what makes sense to you, but tags like test, staging, production, database or application are not uncommon. In the end the tags are useful when you want to filter data from different groups of servers. InterfacesA short section, but no less important. This is where you specify how Packetbeat will integrate with the networking stack on the server. At minimum, you should specify which devices to monitor. On my Mac, I used something as simple as this: interfaces: device: en0 The device names are platform specific and you should choose what matches your platform. Run in your terminal for a list of devices. On Macs your Wi-Fi and your ethernet card are usually named either or and Linux and are common. There is also a special name called where Packetbeat will connect with all available devices. Packetbeat supports a few more options in this section, each with different trade-offs that are out of scope for this article, but before deploying into production, have a look at . ProtocolsPacketbeat currently supports monitoring HTTP, PostgreSQL, MySQL, Redis and Thrift. For all protocols there is one mandatory parameter, . For demo purposes, declaring ports and protocols in use is usually sufficient, but in particular for the HTTP protocol there are a few things to be aware of. The parameter allows you to specify form fields in GET or POST requests that should not be indexes. This is important since some fields may contain sensitive data like passwords in clear text. A very common setup is to have a standard HTTP server, like Apache or Nginx in front of your application server and then let this server handle things like SSL termination. One disadvantage of this is that it hides the client IP that request originated from. Luckily, both Apache and Nginx and most other servers you would want to use in such a scenario support adding the client IP in a header on each request. Packetbeat can then be configured with the parameter to extract this information. Terminating SSL before it reaches the application server is also the only way to let Packetbeat monitor services provided over HTTPS. OutputLike Logstash, Packetbeat supports multiple outputs and most frequently people use the Elasticsearch output. In this example I've defined the necessary parameters for connecting to a cluster on Found. Specifically this includes: , , , and . output: elasticsearch: enabled: true host: 20ea7fisk409df2c3b523a2b131d.eu-west-1.aws.found.io port: 9243 save_topology: true protocol: https username: readwrite password: <password> ProcsThis section is optional and it is disabled by default, but on Linux systems it will allow monitoring traffic between processes on the same host. It will also populate the and fields. All that is required is to give the process a name and a grep filter so that Packetbeat can identify the process id. The complete reference for is available in . Running PacketbeatThe Deb and RPM packages include launch scripts so you can launch Packetbeat like any other service in your distribution. For the generic packages you might have to specify the location of , like this: sudo .\/packetbeat -c .\/packetbeat.yml -v for verbose is also useful the first time after a change to . Privileged access (sudo) is also required for sniffing packets. Visualizing The DataPacketbeat feeds data into Elasticsearch in a format that is timestamped and suitable for visualizing with Kibana. You can use either Kibana 3 or 4. Packetbeat does not come with any Kibana dashboards out of the box, but in all likelihood, you most likely want to build your own, a dashboard targeting your data and the questions you have. If you have used Kibana previously, all you really need to know to get started is the index pattern to use and that is: \"[packetbeat-]YYYY.MM.DD\". If you've never used Kibana before, I recommend . There is also a . \n"}<br>{"index": {"_id": 959}}<br>{"title":"Elasticsearch 1.7.1 and 1.6.2 released","seo_title":"","url":"\/blog\/elasticsearch-1-7-1-and-1-6-2-released","author":{"name":"Clinton Gormley"},"date":"July 29, 2015","category":"Releases","locales":"","content":" Today, we are pleased to announce bug fix releases of based on , and . These releases contain a fix for a rarely occurring\u00a0but important bug which can cause data loss. .You can download them and read the full changes list here:The bug in question () can, in very rare circumstances involving multiple simultaneous node failures or restarts, cause all copies of a shard to be deleted from the cluster. This bug was introduced in 1.5.0.This release also contains a fix for CIDR mask conversion for IPv4 addresses, and a bug that prevented Shield users from using the more-like-this API, plus a few more changes whose details can be found in the .Please , try it out, and let us know what you think on Twitter () or on our . You can report any problems on the . \n"}<br>{"index": {"_id": 960}}<br>{"title":"This Week in Elasticsearch and Apache Lucene - July 29 2015","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-07-29","author":{"name":"Leslie Hawthorn"},"date":"July 29, 2015","category":"","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top News \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space , where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 961}}<br>{"title":"Watcher 1.0.1 Released","seo_title":"","url":"\/blog\/watcher-1-0-1-released","author":{"name":"Jay Modi"},"date":"July 29, 2015","category":"Releases","locales":"","content":" Today we are announcing the release of Watcher 1.0.1! This is a bugfix release and we recommend that all users of Watcher upgrade. Read on for more details and download it . bug fixes Watcher 1.0.1 fixes a compatibility issue with Elasticsearch 1.6.1 and 1.7.2, which were earlier today. enhancements now support specifying a time zone to be used when computing the names of the indices. The default is UTC. Previously, the computation was fixed to always use UTC when computing the names of the indices. upgrading Please refer to the in the Watcher documentation. feedback We would love to hear any feedback or questions that you may have in the category of our forums. \n"}<br>{"index": {"_id": 962}}<br>{"title":"HTTP Poller, Opening up a New World for Logstash","seo_title":"","url":"\/blog\/introducing-logstash-http-poller","author":{"name":"Andrew Cholakian"},"date":"July 29, 2015","category":"Engineering","locales":"","content":" I\u2019m pleased to announce the release of a brand new Logstash input: . With this new input you\u2019ll be able to repeatedly poll one or more HTTP endpoints and turn the response into Logstash events. There are a number of practical uses for this plugin, like: The syntax for this plugin is dead simple to boot, as seen in the example below: input { http_poller { # List of urls to hit # URLs can either have a simple format for a get request # Or use more complex HTTP features urls => { some_service => \"http:\/\/localhost:8000\" some_other_service => { method => \"POST\" url => \"http:\/\/localhost:8000\/foo\" } } # Maximum amount of time to wait for a request to complete request_timeout => 30 # How far apart requests should be interval => 60 # Decode the results as JSON codec => \"json\" # Store metadata about the request in this key metadata_target => \"http_poller_metadata\" } } output { stdout { codec => rubydebug } } This request will put the HTTP responses of the polled endpoints into the field and provide metadata like response timing and HTTP response headers in the field. Using HTTP Poller to monitor website statusWe\u2019ll start with a simple example: using HTTP Poller to monitor whether a given URL is up, down, or responding slowly. The following Logstash config will hit a webserver on . If you don\u2019t have one up, you can start one that takes a variable length of time to return a JSON response by running in your console (assuming you have ruby installed and have installed the sinatra gem with ). After that, try running Logstash with the sample config below. The sample config has been heavily annotated to make reading it easy, even for a complete logstash novice. Using the config below, you can generate Kibana charts like the one just underneath this paragraph, showing the ratio of slow to fast requests to your service over time. If you have Elastic's set\u00a0up, you can use that to automatically send you alerts when you receive slow requests as well input { http_poller { urls => { \"localhost\" => \"http:\/\/localhost:8000\" } automatic_retries => 0 # Check the site every 10s interval => 10 # Wait no longer than 8 seconds for the request to complete request_timeout => 8 # Store metadata about the request in this field metadata_target => http_poller_metadata # Tag this request so that we can throttle it in a filter tags => website_healthcheck } } filter { # The poller doesn't set an '@host' field because it may or may not have meaning # In this case we can set it to the 'name' of the host which will be 'localhost' # The name is the key used in the poller's 'url' config if [http_poller_metadata] { mutate { add_field => { \"@host\" => \"%{http_poller_metadata[name]}\" } } } # Classify slow requests if [http_poller_metadata][runtime_seconds] and [http_poller_metadata][runtime_seconds] > 0.5 { mutate { add_tag => \"slow_request\" } } # Classify requests that can't connect or have an unexpected response code if [http_request_failure] or [http_poller_metadata][code] != 200 { # Tag all these events as being bad mutate { add_tag => \"bad_request\" } } if \"bad_request\" in [tags] { # Tag all but the first message every 10m as \"_throttled_poller_alert\" # We will later drop messages tagged as such. throttle { key => \"%{@host}-RequestFailure\" period => 600 before_count => -1 after_count => 1 add_tag => \"throttled_poller_alert\" } # Drop all throttled events if \"throttled_poller_alert\" in [tags] { drop {} } # The SNS output plugin requires special fields to send its messages # This should be fixed soon, but for now we need to set them here # For a more robust and flexible solution (tolerant of logstash restarts) # Logging to elasticsearch and using the Watcher plugin is advised mutate { add_field => { sns_subject => \"%{@host} is not so healthy! %{@tags}\" sns_message => '%{http_request_failure}' codec => json } } } } output { # Catch throttled messages for request failures # If we hit one of these, send the output to stdout # as well as an AWS SNS Topic # UNCOMMENT THIS TO ENABLE SNS SUPPORT #if \"http_request_failure\" in [tags] { # sns { # codec => json # access_key_id => \"YOURKEY\" # secret_access_key => \"YOURSECRET\" # arn => \"arn:aws:sns:us-east-1:773216979769:logstash-test-topic\" # } #} elasticsearch { protocol => http } stdout { codec => rubydebug } } Using HTTP Poller to monitor HAProxy stats and Apache server-status pagesBoth and support stats API endpoints for to get information like the number of open connections. In the following example I\u2019ll show how to setup Logstash to record this information to elasticsearch. The key takeaway here is that you can use the HTTP Poller to monitor the health of HAProxy and Apache with greater insight than you\u2019d get with logs alone. Additionally, you can use it to trigger alerts via AWS SNS topics when those thresholds are passed. Those SNS topics can be configured to send texts or emails to alert an operator. Implementing this requires you to as well as . To make this easier to try out I\u2019ve prepared a script that will launch a set of docker machines with this stuff all setup. To run it you\u2019ll just need bash, docker, and . Try checking out all the code in . After you have the code run , which will launch the docker machines and write out a sample file. After you\u2019ve done that, just run to see it with action. If you hit the haproxy server (whose address will be printed out by buildit) with traffic and load the the file into with , you should see something like the kibana dashboard below. Notice that we can graph such things as HAProxy sessions, the response times of polling requests (which rise as the server is more and more saturated, and which HAProxy services are active. All things that cannot be exposed via plain log data, but can be reached via HTTP polling. If you\u2019d rather not run the examples to see the config used, I\u2019ve reproduced a well commented version of it below: input { # Setup one poller for httpd, we keep these separate to tag them differently http_poller { urls => { \"custom_httpd_t1\" => { url => \"http:\/\/192.168.99.100:8001\/server-status?auto\"} \"custom_httpd_t2\" => { url => \"http:\/\/192.168.99.100:8002\/server-status?auto\"} \"custom_httpd_t3\" => { url => \"http:\/\/192.168.99.100:8003\/server-status?auto\"} } tags => apache_stats codec => plain metadata_target => http_poller_metadata interval => 1 } # Another poller, this time for haproxy http_poller { urls => { ha_proxy_stats => \"http:\/\/statsguy:statspass@192.168.99.100:1936\/: csv\" } tags => haproxy_stats codec => plain metadata_target => http_poller_metadata interval => 1 } # Pull the regular Apache\/HAProxy logs via docker commands # This is a hack for the purposes of this example pipe { command => \"docker logs -f custom_httpd_t1\" tags => [ \"apache\" ] add_field => { \"@host\" => \"custom_httpd_t1\" } } pipe { command => \"docker logs -f custom_httpd_t2\" tags => [ \"apache\" ] add_field => { \"@host\" => \"custom_httpd_t2\" } } pipe { command => \"docker logs -f custom_httpd_t3\" tags => [ \"apache\" ] add_field => { \"@host\" => \"custom_httpd_t3\" } } pipe { command => \"docker logs -f custom_haproxy\" tags => [ \"haproxy\" ] add_field => { \"@host\" => \"custom_haproxy\" } } } filter { if [http_poller_metadata] { # Properly set the '@host' field based on the poller's metadat mutate { add_field => { \"@host\" => \"%{http_poller_metadata[name]}\" } } } # Processed polled apache data if \"apache_stats\" in [tags] { # Apache stats uses inconsistent key names. Make sure all fields are camel cased, no spaces mutate { gsub => [\"message\", \"^Total \", \"Total\"] } # Parse the keys\/values in the apache stats, they're separated by \": ' kv { source => message target => apache_stats field_split => \"\\n\" value_split => \":\\ \" trim => \" \" } # We can make educated guesses that strings with mixes of numbers and dots # are numbers, cast them for better behavior in Elasticsearch\/Kibana ruby { code => \"h=event['apache_stats']: h.each {|k,v| h[k] = v.to_f if v =~ \/\\A-?[0-9\\.]+\\Z\/}\" } } # Process polled HAProxy data if \"haproxy_stats\" in [tags] { split {} # We can't read the haproxy csv header, so we define it statically # This is because we're working line by line, and so have no header context csv { target => \"haproxy_stats\" columns => [ pxname,svname,qcur,qmax,scur,smax,slim,stot,bin,bout,dreq,dresp,ereq,econ,eresp,wretr,wredis,status,weight,act,bck,chkfail,chkdown,lastchg,downtime,qlimit,pid,iid,sid,throttle,lbtot,tracked,type,rate,rate_lim,rate_max,check_status,check_code,check_duration,hrsp_1xx,hrsp_2xx,hrsp_3xx,hrsp_4xx,hrsp_5xx,hrsp_other,hanafail,req_rate,req_rate_max,req_tot,cli_abrt,srv_abrt,comp_in,comp_out,comp_byp,comp_rsp,lastsess,last_chk,last_agt,qtime,ctime,rtime,ttime ] } # Drop the haproxy CSV header, which always has this special value if [haproxy_stats][pxname] == \"# pxname\" { drop{} } # We no longer need the message field as the CSV filter has created separate # fields for data. mutate { remove_field => message } # Same as the cast we did for apache ruby { code => \"h=event['haproxy_stats']: h.each {|k,v| h[k] = v.to_f if v =~ \/\\A-?[0-9\\.]+\\Z\/}\" } } # Process the regular apache logs we captured from the docker pipes if \"apache\" in [tags] { grok { match => [ \"message\", \"%{COMMONAPACHELOG:apache}\" ] } } # We're going to email ourselves on error, but we want to throttle the emails # so we don't get so many. This says only send one every 5 minutes if \"_http_request_failure\" in [tags] { throttle { key => \"%{@host}-RequestFailure\" period => 600 before_count => -1 after_count => 1 add_tag => \"_throttled_poller_alert\" } # Drop all throttled events if \"_throttled_poller_alert\" in [tags] { drop {} } # The SNS output plugin requires special fields to send its messages # This should be fixed soon, but for now we need to set them here mutate { add_field => { sns_subject => \"%{@host} unreachable via HTTP\" sns_message => \"%{http_request_failure}\" } } } } output { # Store everything in the local elasticsearch elasticsearch { protocol => http } # Catch throttled messages for request failures # If we hit one of these, send the output to stdout # as well as an AWS SNS Topic # UNCOMMENT TO ENABLE SNS #if \"_http_request_failure\" in [tags] { # sns { # codec => json # access_key_id => \"YOURKEY\" # secret_access_key => \"YOURSECRET\" # arn => \"arn:aws:sns:us-east-1:773216979769:logstash-test-topic\" # } stdout { codec => rubydebug } } } Using the HTTP Client Mixin in Your Own PluginHTTP Poller is the first plugin to use . If you need to add an HTTP client to a plugin you\u2019re writing consider using the mixin. This mixin will add a bunch of well validated configuration options and sane defaults to your plugin for free. Using it is as simple as adding to the body of your plugin. This will expose a new method in your plugin class, which is an instance of the http client. Manticore is a well written and performant client is based on Apache Commons HTTP. Of note is Manticore\u2019s ability to execute requests asynchronously using thread pools with a simple API Wrapping UpI hope these examples have been useful! If you find any other uses for the http input poller, ! If you think you\u2019ve found a bug in it, please . \n"}<br>{"index": {"_id": 963}}<br>{"title":"Monitoring MongoDB with Packetbeat and Elasticsearch","seo_title":"Monitoring MongoDB with Packetbeat and Elasticsearch","url":"\/blog\/mongodb-monitoring-with-packetbeat-and-elasticsearch","author":{"name":"Tudor Golubenco"},"date":"July 27, 2015","category":"Engineering","locales":"","content":" Since the recently released 1.0.0-beta2 version, Packetbeat can understand the MongoDB wire protocol. This means you can now use Packetbeat and Elasticsearch to monitor the performance of your MongoDB servers. You can play with a live demo of the associated Kibana dashboard . The way Packetbeat works is that it captures the network traffic, correlates the request with the response, and inserts a document into Elasticsearch describing each MongoDB query or operation seen on the wire. You can then use Kibana to discover errors or slow queries and to visualize things like \u201cTop slowest MongoDB queries\u201d, \u201cResponse time percentiles for a particular collection\u201d, or the \u201cNumber of writes with unacknowledged write concern\u201d. But more about these visualizations later, let\u2019s start by giving credit where credit is due. Based on a community contributionThe beauty of having a system like Packetbeat be open source is that anyone can add support for the protocols they need. By making it easy to add new protocols and encouraging community contributions, we\u2019re not only extending Packetbeat\u2019s list of supported protocols faster, but we benefit from having experts in each technology providing insights. The open source nature also means that folks can implement support for niche or proprietary protocols. While we hoped that people will start creating their own protocol modules for Packetbeat, we didn\u2019t expect it to happen this quickly. We don\u2019t have yet a proper developer guide for new protocols and the APIs are scarcely documented and may be inconsistent here and there. But all of\u00a0this didn\u2019t stop to submit the pull request for adding MongoDB support just a few days after we announced that . His pull request was well documented, contained unit and integration tests and even a simple to future protocol module writers. As if he didn\u2019t do enough already, we asked Alban to contribute to this blog post as well. He sent us the following quote: Thank you Alban for your excellent work and for leading the way to more community contributions! Mongo\u2019s wire protocolLet\u2019s do a quick dive in the details of the MongoDB wire protocol, so you get a better understanding of what data Packetbeat captures. It is a fairly friendly protocol to a passive decoder like Packetbeat. Messages and individual fields have lengths, so it is easy to jump over the fields that we don\u2019t understood or we don\u2019t need. There is little contextual state so it is easy to understand what is happening even when capturing only part of the conversion. Also, because a single serialization protocol is used in all messages ( - binary JSON), it was easy for us to leverage an existing Go library to decode them. Namely, we use the BSON implementation from the driver, written by Gustavo Niemeyer. One thing to note is that prior to version 2.6, the write operations didn\u2019t actually require a response from the server. By default, however, the drivers called the GetLastError method to acknowledge that the write was successful.\u00a0 This was , which introduced a new wire protocol for insert, update and delete commands so that a response is always sent from the server and it doesn\u2019t require a second command. Currently Packetbeat only supports the newer version of the protocol, so write commands from versions prior to 2.6 are not captured. We (or you!) can implement this in the future if there is demand. Another interesting aspect is that in a MongoDB cluster the same wire protocol is used between the three server types: mongos, config server and data shards servers. The same protocol is also used for replication between shard nodes. This means you can use Packetbeat for advanced troubleshooting of what is going on inside the cluster! To capture the traffic inside the cluster, you need to install Packetbeat not only on the routing nodes but also on the shard nodes. You likely also need to add port 27019 to the list of MongoDB ports, because this is used by the configuration nodes. Kibana dashboardsAs usual with the protocols we support, we also provide a sample Kibana to highlight some of the visualizations you can build based on the data Packetbeat collects and to give you a good starting point for creating your own dashboard. Let\u2019s see some of the visualizations made possible by this data. MongoDB errorsPacketbeat inspects automatically the response payload to check if it contains error. If it finds any, it sets the status field \u00a0to error Error. This example shows the number of MongoDB errors evolution sliced by both the collection name and operation type. Total time spent per collectionThis example shows the total amount of time spent while querying each collection. This view adds to, for example, a 99th percentile visualization of response times because a high total count could be reached if there are slow queries but also if there are many small queries. Response times and count per collectionThis one plots the 99th response time percentile on the Y axis and the dot size represents the number of queries in the particular time bucket. Different colors represent different collections. Just another way of visualizing performance data which can be helpful in spotting trends. In this screenshot, for example, you can notice the cyclicality of the response times. Number of writes with unacknowledged write concernBy inspecting the request payload and looking for the writeConcern parameter of write operations, we can plot the number of them that have an unacknowledged write concern. As always with Packetbeat and Kibana, you can drill down from this graph and find these exact transactions and who creates them. Top slowest MongoDB queriesLet\u2019s end with a fairly obvious but very useful one: top slowest MongoDB queries by their 99th percentile. Getting started with Packetbeat for MongoDBIf you didn\u2019t try Packetbeat before, we recommend reading and following the guide. By default, Packetbeat doesn\u2019t index payload information to avoid capturing sensitive data by mistake. But you can easily enable payload indexing from the configuration file. Here is an example configuration section showing the main options: protocols: mongodb: ports: [27017, 27019] send_request: true # index the request payload send_response: true # index the response payload max_docs: 10 # maximum number of documents to index per request\/response max_doc_length: 1024 # maximum document size to index Image credit: \n"}<br>{"index": {"_id": 964}}<br>{"title":"Support in the Wild: My Biggest Elasticsearch Problem at Scale","seo_title":"Support in the Wild: My Biggest Elasticsearch Problem at Scale","url":"\/blog\/support-in-the-wild-my-biggest-elasticsearch-problem-at-scale","author":{"name":"Chris Earle"},"date":"July 24, 2015","category":"Engineering","locales":"","content":" As a Support Engineer at Elastic, I come across a lot of different issues from our customers, ranging from development questions surrounding Kibana to helping a user to understand why their Elasticsearch cluster had issues. In this blog post, I want to describe the number one problem that I run into with users running Elasticsearch as they begin to scale their workloads. Without fail, when a user approaches me with issues running Elasticsearch, whether it is a customer or not, I point them to this issue. Java Heap PressureElasticsearch has so many wildly different use cases that I could not write a reasonably short blog post describing what can and cannot consume memory. However, there is one thing that constantly stands out above all of the other concerns that you might have while running an Elasticsearch cluster at scale. For the users that I help, is the problem that is the most likely to cause their cluster's instability. Fielddata is the bane of my existence and it's the most frequent cause of the highest severity issues that I handle with our customers. Understanding FielddataThe inverted index is the magic that makes Elasticsearch queries so fast. This data structure holds a sorted list of all the unique terms that appear in a field, and each term points to the list of documents that contain that term: Term: Docs: 1 2 3 4 5 ---------------------------- brown X X X fox X X quick X X ---------------------------- Search asks the question: What documents contain term in the field? The inverted index is the perfect structure to answer this question: look up the term of interest in the sorted list and you immediately know which documents match your query. Sorting or aggregations, however, need to be able to answer this question: What terms does Document 1 contain in the field? To answer this, we need a data structure that is the opposite of the inverted index: Docs: Terms: ---------------------------- 1 [ brown ] 2 [ quick ] 3 [ brown ] 4 [ brown, fox, quick ] 5 [ fox ] ---------------------------- This is the purpose of fielddata. Fielddata can be generated at query time by reading the inverted index, inverting the term <-> doc data structure, and storing the results in memory. The two major downsides of this approach should be obvious: Because loading fielddata is costly, we try to do it as seldom as possible. Once loaded, we keep it in memory for as long as possible. By default, fielddata is loaded on demand, which means that you will not see it until you are using it. Also, by being loaded per segment, it means that new segments that get created will slowly add to your overall memory usage until the field's fielddata is evicted from memory. Eviction happens in only a few ways: While the first two ways will cause the memory to be evicted, they're not useful in terms of solving the problem because they make the index unusable. Segment merging is happening in the background and it is not a way to clear fielddata. The fourth and fifth ways are unlikely to be a long term solution because they do not prevent fielddata from being reloaded. The sixth option, evicting fielddata when the cache is full, leads to different issues: one request triggers fielddata loading for one field and the next request triggers loading for another, causing the first field to be evicted. This causes memory thrashing and slow garbage collections, and your users suffer from very slow queries while they wait for their fielddata to be loaded. Simply put, once fielddata becomes a problem, then it stays a problem. Why Fielddata is BadAt small scales, you can generally get away with fielddata usage without even realizing that you are using it. In highly controlled environments, you may even enjoy that specific fields are being loaded into memory for theoretically faster access. However, almost without fail, you are bound to run into a problem with it eventually. Whether it's because someone ran a test request on the production system without thinking that it would be a problem (it's just one query, right?), your queries changed to match new data, or you just finally reached a scale where it no longer works: you will eventually run into memory pressure that does not go away. As I noted earlier, fielddata does not go away on its own. In Elasticsearch 1.3 and later, we allow up to 60% of your Java heap's memory to be consumed by fielddata per node. We control this via the , which checks incoming requests for potential fielddata usage and then them if they require more memory than is currently available. Any circuit breaker's purpose is to prevent any bad requests, which means that it never gets the chance to cause a problem (e.g., allocate even more fielddata), but it's important to note that it will not clear any existing fielddata. For example, if a node has 10 GBs of Java heap, then 60% of that is going to be 6 GBs. If a new request requires 1 GB of fielddata to be loaded for that node that is already using 4 GBs of the heap for fielddata, then it will allow it because 4 GB, plus 1 GB, is less than 6 GB. However, if the next request needed 2 GB for yet another field's fielddata, then the entire request would be rejected because the fielddata is exhausted (, which is clearly greater than 6 GB). Note: for versions prior to Elasticsearch 1.3, we allowed an unlimited amount of your Java heap to be consumed by fielddata. Finding Your FielddataFortunately, it's not all bad news. Not only do we have a solution to the problem, but we also provide a way to find and understand problem with it. $ curl -XGET 'localhost:9200\/_cat\/fielddata?v&fields=*' This will provide a list of each node with its fielddata usage. For instance, at startup, my local node is using absolutely no fielddata: id host ip node total iExRFXn1Qw23iRzhwor-Wg Chriss-MBP.home 192.168.1.2 WallE 0b To see it change, it's as simple as sorting, scripting, or aggregating any field. So let's do all three! $ curl -XGET localhost:9200\/test-index\/_search -d '{ \"query\": { \"filtered\": { \"filter\": { \"script\": { \"script\": \"doc[\\\"percentage\\\"].value > 0.5\" } } } }, \"aggs\": { \"max_number\": { \"max\": { \"field\": \"number\" } } }, \"sort\": [ { \"@timestamp\": { \"order\": \"desc\" } } ] }' Although order is irrelevant for this, the first field that will be impacted will be the field that is accessed inside of the scripted filter. The second field used will be the field from the aggregation. Finally, the last field is the field used to sort the filtered results. Taking another look at the command above confirms this: id host ip node total number @timestamp percentage iExRFXn1Qw23iRzhwor-Wg Chriss-MBP.home 192.168.1.2 WallE 49.9kb 24.8kb 24.8kb 192b Use Doc ValuesThe solution to this fielddata problem is to avoid it altogether. Fortunately, you can avoid the use of fielddata by mapping all of your fields to use . Without repeating too much from the guide, doc values offload this burden by writing the fielddata to disk at index time, thereby allowing Elasticsearch to load the values outside of your Java heap as they are needed. By taking the burden out of your heap, you get fast access to the on-disk fielddata through the file system cache, which gives in-memory performance without the cost of garbage collections coming into play. This also frees up a lot of headroom for the Elasticsearch heap so that more operations (e.g., bulk indexing and concurrent searches) can use the heap without placing the node under memory pressure, which leads to garbage collection that will slow it down. You might be asking: How do I enable these doc values? It's as simple as adding this to every field's mapping, analyzed string fields: \"doc_values\" : true Unfortunately, you do this before you index any data. This means that, for any existing index that is not already using doc values, you cannot flip the switch to enable them. You would have to reindex. Updating an Active ClusterNaturally, up to this point, you may be wondering how to remove fielddata from your cluster. The answer depends on your data. Time Based IndicesIf you are using time based indices (e.g., ), such as with logging use cases, then you should update your template(s) to use doc values so that future indices (e.g., tomorrow's) get created with doc values. From there, the problem should take care of itself as indices that use fielddata will age themselves out. If you maintain indices for significant periods of time (e.g., many months), then it may be worth looking into reindexing older indices to take advantage of doc values. Other IndicesFor non-time based indices (e.g., ), the problem gets more complicated because it depends entirely on how you use the indices. However, to avoid using fielddata, then you will have to reindex the data. In Elasticsearch: The Definitive Guide, as a mechanism for transitioning between two indices without impacting clients. Potential Downsides to Doc ValuesUnfortunately, nothing is perfect. From my perspective, the only important downside to doc values is that they cannot be used with analyzed strings. But by default, all strings are mapped as analyzed strings though! That is the exception to the use of doc values. Looking back at the Understanding Fielddata section of this post, it is critical to think about why you might use fielddata with an analyzed string. For regular, unstructured search, you will not use any fielddata. With that in mind, the only time that you should catch yourself using fielddata for analyzed strings is with the . All other uses of fielddata should be avoided by using a version of the string because sorting, aggregating, and scripting against an analyzed string is not going to give you the results you expect. We are currently discussing ways to simplify this issue with the release of Elasticsearch 2.0, such as and , and it is worth taking a look at these issues to see some common pitfalls so that you can avoid them yourself in the mean time! The second issue shows a very good way to take advantage of both analyzed and not analyzed strings by using multifields, thereby allowing you to use each field when it is appropriate. There are other minor issues that I want to list for completeness: Fixing It For GoodWe're not there yet, but Elasticsearch 2.0 is on the horizon and we expect to release the first beta very soon. I cannot wait for this release because it will do away with this issue for any new index by applying by default for every possible field (read: everything that is not an analyzed string!). Elasticsearch 2.0 contains a lot of changes that I am excited to see. Changing doc values to default to is just one major change that I am looking forward too, but continuing the analyzed string discussion from above, there are numerous changes that will simplify your deployment and your life (and mine too!). From my support perspective, such changes range from further improvements to shard recovery, to diff-based cluster state communication. Feel free to read about some of the other changes in and keep an eye out for the release of beta1 in the very near future. Hope That HelpsIt's literally my job to help people to be successful running our products and I have seen a lot. This is truly the number one concern that I have with users running Elasticsearch at scale and I hope that you can catch it before it becomes a problem for you, or fix it now that you are aware of it! Stay tuned to this blog for future announcements regarding Elasticsearch 2.0. And as always, feel free to ,\u00a0visit , and check out our webinars such as\u00a0. \n"}<br>{"index": {"_id": 965}}<br>{"title":"API-ing the US Government: A 540.co Story","seo_title":"","url":"\/blog\/api-ing-us-government-540-co-story","author":{"name":"John O'Brien"},"date":"July 23, 2015","category":"User Stories","locales":"","content":" The US Federal Government is teeming with data\u2026 all types of data. Just in the area of business operations alone, there is , , and being generated by each agency - and while much of this data is publicly available (or becoming increasingly more available as data transparency continues to be a focus of the administration), it resides in various places across the government landscape and is often difficult to access, understand or use.As our government and enterprise clients continue to strive to use data to help them understand their business operations and improve decision making, we are often called upon to build applications, \u201c\u201d or analytic tools to help answer questions, provide visibility and automate data analysis to inform decisions makers.During our engagements, we often found ourselves harvesting the same procurement data, the same budget data, etc. to \u201cpaint different pictures\u201d for clients, especially when a flexible way of asking questions of the data wasn\u2019t readily available. \u00a0We also kept hearing about other teams having to start from scratch on the data harvest phase as well - acting as a barrier to achieving the goals of extracting meaningful information from the data.In a very similar way that the government likes to talk about \u201ccommon operating pictures\u201d (ok, that may actually be more of a DoD term) we began to envision a \u201ccommon operational data\u201d platform that would: Our solution - FedAPILeveraging our knowledge of the domain and data, we cranked up the R&D budget, ordered a few cases of 5 Hour Energy, spun up our AWS servers and hacked out beta, with Elasticsearch acting as the heartbeat and began to build out various harvesters for data we often found being reused, difficult to parse and\/or of high value to our clients and friends. To date, FedAPI currently harvests and exposes: In a nutshell, it was pretty simple because of ElasticsearchElasticsearch provided such a powerful indexing and search capability, that really much of FedAPI is a proxy to an Elasticsearch cluster that calls upon Elasticsearch\u2019s powerful search API endpoint (or what we often call the \u201cmagic wand endpoint\u201d) to respond to requests. We also added a little code to record \u201cevent\u201d records when data changes to allow us to see when data is changing and what has changed - which is often very important to see deltas over time - and have begun to pilot Kibana 4 with to more quickly show the data to our clients to allow them to start to better understand the \u201ccommon operational data\u201d that is ready to use in FedAPI. What\u2019s next?FedAPI now acts as both and a . As a , we often point to FedAPI as an example \/ reference of how to leverage Elasticsearch when clients are looking to modernize how they store and expose data within their architecture. \u00a0A recent example of this can be found in our to DTIC for a new \u201cmaster data repository\u201d earlier this year. As a , we have begun to use FedAPI \u00a0in our application builds as a source of data and other external parties \/ partners have begun to do the same. \u00a0We have also begun to explore doing private, on-prem installs of the platform to help jumpstart internal data indexing efforts. This is forcing us to continue to evolve the APIs, improve documentation, harvest new data and is driving us towards a refactor to make things a little faster (our fault, not Elastic!). Have a problem you want to solve with data?Leveraging what we have learned with FedAPI and Elasticsearch, we know we can add more data and help answer more questions.If you have a data challenge just contact us, we\u2019d love to hack out a solution for you. \n"}<br>{"index": {"_id": 966}}<br>{"title":"This Week in Elasticsearch and Apache Lucene - July 22 2015","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-07-22","author":{"name":"Leslie Hawthorn"},"date":"July 22, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Elasticsearch Core Apache Lucene Watch This Space, where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 967}}<br>{"title":"Logstash 1.5.3 and 1.4.4 released","seo_title":"","url":"\/blog\/logstash-1-5-3-and-1-4-4-released","author":{"name":"Suyog Rao"},"date":"July 22, 2015","category":"Releases","locales":"","content":" We are announcing the of Logstash 1.5.3 and 1.4.4. In addition to fixing defects, these releases address important security vulnerabilities. Our recommendation is to upgrade immediately if you are using either of the following plugins: Security Fixes Lumberjack Input Security Vulnerability Logstash 1.5.2 and prior versions are vulnerable to a SSL\/TLS security issue called the attack. If you are using the Lumberjack input, FREAK allows an attacker to successfully implement a man in the middle attack, intercepting communication between the Logstash Forwarder agent and Logstash server. Both 1.5.3 and 1.4.4 release include a patch which resolves this issue. We have been assigned for this issue and added this vulnerability to our . Elasticsearch Vulnerabilities Logstash 1.5.2 and prior versions were packaged with Elasticsearch releases which are vulnerable to Remote code execution vulnerability () and Directory traversal vulnerability (). These binaries are used in Elasticsearch output specifically when using the and protocol. Both 1.5.3 and 1.4.4 are packaged with Elasticsearch version 1.7.0 which has been to address these vulnerabilities. Note that users of protocol are not vulnerable to these attacks. Bug Fixes Below we highlight some bug fixes and enhancements in this release. For a full list, please check the Feedback Please Logstash 1.5.3 and let us know what you think on Twitter (@elastic) or on our . You can report any problems on the GitHub . \n"}<br>{"index": {"_id": 968}}<br>{"title":"Shield 1.3.1 and 1.2.3 Released","seo_title":"","url":"\/blog\/shield-1-3-1-and-1-2-3-released","author":{"name":"Jay Modi"},"date":"July 21, 2015","category":"Releases","locales":"","content":" We have released Shield 1.3.1 and Shield 1.2.3 today. These are bug fix releases that fix a serialization bug in Shield 1.3.0 and Shield 1.2.2 that prevented rolling upgrades when using message authentication. Read below for all of the details and then download it . Message AuthenticationShield provides support for through the use of a shared system key. In Shield 1.2.2 and 1.3.0, a bug was introduced that caused the message authentication to fail when communicating with nodes running Shield 1.2.1 or earlier. During a rolling upgrade from Shield 1.2.1 to Shield 1.2.2 or 1.3.0, the nodes running the newer version would not be able to join the cluster and would see \u201ctampered signed text\u201d log messages. Upgrading from Shield 1.2.1 or earlierIf you have not upgraded to Shield 1.2.2 or 1.3.0, then you can simply follow the normal and upgrade to Shield 1.2.3 or Shield 1.3.1. Upgrading from Shield 1.2.2 or 1.3.0 The first step is to determine if you are using . If you have not configured the system-key on all nodes, you are not using message authentication: please follow the normal . If you are using the message authentication feature with Shield 1.2.2 or 1.3.0, then a will be necessary. The existing Shield plugin should be uninstalled and the new plugin should be installed on each node while they are stopped as documented in the documentation. FeedbackWe would love to hear any feedback and questions that you may have via the category in our forums. \n"}<br>{"index": {"_id": 969}}<br>{"title":"Where in the World is Elastic? - July 20, 2015","seo_title":"Where in the World is Elastic, July 20 2015","url":"\/blog\/2015-07-20-where-in-the-world-is-elastic","author":{"name":"Livia Froelicher"},"date":"July 20, 2015","category":"","locales":"","content":" Welcome to\u00a0Upcoming EventsJuly 20-24: , Portland, Oregon - Stop by our booth #311 to meet our local team and see live demos.\u00a0July 20-26: - Our own will be giving a talk about Beyond the Basics with Elasticsearch on\u00a0Friday, July 24 at 11\u00a0a.m. Don't miss it!Upcoming MeetupsJuly 21: July 22: July 23:July 23: July 21:July 22: July 22: July 23: That's it for this week.\u00a0Stay tuned for Elastic happenings next week - there's much to come!\u00a0- The Elastic TeamP.S.:\u00a0\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats,\u00a0Elasticsearch, Logstash or Kibana\u00a0\u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 970}}<br>{"title":"Elasticsearch 1.7.0 and 1.6.1 released","seo_title":"","url":"\/blog\/elasticsearch-1-7-0-and-1-6-1-released","author":{"name":"Clinton Gormley"},"date":"July 16, 2015","category":"Releases","locales":"ja-jp","content":" Today, we are pleased to announce the release of based on , and the bugfix release of . These releases contain a security fix and .You can download them and read the full changes list here:The 1.7.0 release will be the last feature release in the 1.x series. All future features will go into Elasticsearch 2.0 or later.Elasticsearch 1.7.0 is a small release, but contains two important security fixes and two important features which will improve cluster stability and recovery: \n"}<br>{"index": {"_id": 971}}<br>{"title":"This Week in Elastic - Better query execution in Elasticsearch 2.0","seo_title":"","url":"\/blog\/this-week-in-elastic-2015-07-16","author":{"name":"Leslie Hawthorn"},"date":"July 16, 2015","category":"","locales":"","content":" Welcome to ! In this weekly round up post, we bring you news on all aspects of the ELK Stack, including updates on Elasticsearch, Logstash and Kibana development, tips and tricks and upcoming events. Getting started w\/Watcher -alerting for ? Join on Jul 21 for live demos, real use cases+more \u2014 elastic (@elastic) Elastic News Useful blog posts, how tos, tutorials\u00a0and articles\u00a0from the wide world of all the ELK stack ecosystem. We just released beta2 of our NEST extension that adds support for GA! \u2014 Martijn Laarman (@Mpdreamz) Support for MongoDB, multiple Elasticsearch nodes and other goodies in the new Packetbeat 1.0.0-beta2 \u2014 Packetbeat (@packetbeat) Slides and VideosIf you're a PHP developer,\u00a0\u00a0just gave a presentation on\u00a0. You can check out the accompanying demo application\u00a0. Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking about the ELK stack\u00a0or hosting a meetup, Australia FranceThe Elastic Paris Meetup will get together on July 29 to talk Fuzzy Name Matching in Elasticsearch. to save your seat. Germany Hong Kong will be speaking at the , coming up July 31 - August 2 in Hong Kong. Stay tuned for more details on his talk! IndiaThe Big Data Analytics on Cloud Meetup group of Hyderabad will get together on August 1 for a Hands on ELK Workshop. to attend.\u00a0 IsraelFor our second Tel Aviv meetup in July, you can hear about Elasticsearch and Fuzzy Matching, Fighting Crime with Elasticsearch and Unstructured Data Analytics and more. to attend this meetup on July 22. Japan\u30bf\u30a4\u30c8\u30eb\u6c7a\u3081\u307e\u3057\u305f\uff08\u4e2d\u8eab\u306f\u307e\u3060\u3060\u3051\u3069\uff09\/ \u3010\u6771\u4eac\u3011\u3010\u5973\u6027\u9650\u5b9a\u3011Java\u3067\u30c7\u30fc\u30bf\u89e3\u6790\u3000\u57fa\u672c\u306e\u30ad\uff01 - Java\u5973\u5b50\u90e8 | Doorkeeper - \u2014 Jun Ohtani (@johtani) \u4eca\u56de\u306f\u3001CTO\u3067\u3042\u308aElasticsearch\u306e\u751f\u307f\u306e\u89aa\u3067\u3042\u308bShay\u304c\u6765\u65e5\u3057\u3066\u30c8\u30fc\u30af\u3057\u307e\u3059\u3002 \/ \u7b2c11\u56deelasticsearch\u52c9\u5f37\u4f1a - \u2014 Jun Ohtani (@johtani) Korea[Elastic Seoul Meetup - \uc5d8\ub77c\uc2a4\ud2f1 \uc11c\uc6b8 \ubc0b\uc5c5] \ubaa8\uc784\uc744 \uc628\uc624\ud504\ubbf9\uc2a4\uc5d0 \uac1c\uc124\ud558\uc600\uc2b5\ub2c8\ub2e4. \ub9ce\uc774 \ucc38\uc11d\ud574\uc8fc\uc138\uc694! \u2014 JongMin Kim \uae40\uc885\ubbfc \ub4dc\ubbf8\ud2b8\ub9ac (@kimjmin) South AfricaThe Elasticsearch South Africa group will convene in Jo'Burg on July 29 for a Gentle Introduction to Elasticsearch. to save your seat. SpainEuroPython 2015 heads to Bilbao this year, featuring two talk from : and . You can learn more about Honza's talks in the : EuroPython runs July 20-26. United Kingdom United States - East United States - West UruguayThe Montevideo Big Data and Data Science Meetup will get together on August 6 for talks on Elasticsearch. to save your seat. Where to Find You \u00a0If you're a regular reader, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to\u00a0 ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in\u00a0training on Elastic's product line,\u00a0we have courses coming up in: \n"}<br>{"index": {"_id": 972}}<br>{"title":"Apache Lucene helps squash JVM bugs","seo_title":"","url":"\/blog\/lucene-jvm-bugs","author":{"name":"Michael McCandless"},"date":"July 16, 2015","category":"Engineering","locales":"","content":" A few weeks ago,\u00a0\u00a0from the\u00a0\u00a0notified us on the Lucene developer's list that\u00a0. This happens every few weeks and is a familiar routine for us by now: we quickly upgraded the Lucene\u00a0\u00a0jobs at both\u00a0\u00a0and\u00a0\u00a0build servers so that Lucene's\u00a0\u00a0would stress the new JDK snapshot. But, we were then suddenly bombarded by all sorts of exotic failures\u00a0! \u00a0dug into the intermittent failures and found that they often happened when the test used Lucene's \"spoon feeding reader\" (). This helpful test-only class wraps any incoming and randomly chops up the incoming large blocks of characters into small randomly sized chunks, much like how you would spoon-feed a baby. Its purpose is to tickle any buffering bugs such as\u00a0. Lucene has also had various exciting buffering bugs in its tokenizers in the past, but this time\u00a0 caught a bug in the JVM, specifically in ! Robert eventually boiled the failing test down to a\u00a0\u00a0which finally\u00a0led to\u00a0. The issue was quickly fixed (thank you!), but\u00a0\u00a0to see just how hairy it is for the JVM to implement the seemingly innocent\u00a0! This is like pulling off the volume knob on your car radio only to discover it has a small nuclear reactor inside. This collaboration between the OpenJDK team and Lucene developers is win\/win: new versions of OpenJDK (and of course\u00a0, nearly the same thing) get more extensive testing before being unleashed to the world and Lucene users gain some confidence that there are no specific Java bugs causing horrible things like silent index corruption such as\u00a0. You can see\u00a0. The Lucene community also\u00a0\u00a0affecting us, and\u00a0\u00a0gave a\u00a0. There is one Oracle developer who really stands out in resolving the scary JVM bugs we discover: on behalf of\u00a0, I'd like to extend a warm thank you to\u00a0. We are perpetually in awe of Vladimir because somehow, with even the most cryptic and difficult Lucene test failures, iterating with\u00a0\u00a0or Robert or Uwe or sometimes all three, Vladimir can stare at heaps and heaps of assembly code created by the hotspot compiler and understand and fix the JVM bugs. We are not sure how he does it but he always does! The silver liningThings have not always been so rosy. This\u00a0\u00a0for\u00a0\u00a0in Oracle's first Java 1.7.0 release caused\u00a0, which\u00a0. But the silver lining in this unfortunate event was the closer collaboration and squashed bugs we see today, not just in\u00a0\u00a0but also\u00a0\u00a0that Rory notifies on new JDK snapshot builds. Still, things can and should be better. Inexplicably,\u00a0. This is insane and self-defeating: why on earth would any serious open-source project want to put false barriers for users to report and iterate on problems? This can only hurt the quality of your software. We have no choice but to work around this commercial silliness by resorting to\u00a0\u00a0emails to OpenJDK team members and lists when our tests find problems, such as\u00a0\u00a0\u00a0on\u00a0, still causing occasional SEGVs in Lucene tests today. Robert\u00a0\u00a0to an email (and\u00a0) to the\u00a0\u00a0instead of opening an issue himself. We are allowed to report incidents at\u00a0, but they\u00a0remain invisible until approved or somehow moved to\u00a0. Dark ages! Second, isolating new JVM bugs is horribly time consuming. For example,\u00a0\u00a0but only Dawid has had time to dig in a bit to try to isolate the bugs to small test cases (more volunteers welcome!). It's spooky that even now (), we\u00a0\u00a0that consistently passes Lucene's tests. The frequent build failure emails to the\u00a0\u00a0for bugs that are not in fact Lucene's cause additional noise and confusion to most readers on that list who don't necessarily\u00a0understand that we are testing early-access Java builds. At times we feel like a strange extension of Oracle's QA team! IBM's J9 JDK joins the funIBM has its own\u00a0, and we used to include it in Lucene's tests rotation, but there were too many JVM bugs, such as this\u00a0, causing test failures. Long ago, we never succeeded in getting IBM's attention to resolve them. But then this\u00a0\u00a0led to a renewed effort, and thanks again to Robert we now have\u00a0. The interactions with J9 developers is even more commercially limited than OpenJDK, since J9 is closed-source and there is not even a public issue tracking system for us to see the progress on issues, let alone open and comment on them. So instead of seeing how things are being fixed, as we could above with the tricky\u00a0\u00a0bug, we see cryptic comments like\u00a0. Still, this is better than nothing, and beggars can't be choosers. I hope that some time soon we can declare that J9 won't crash or corrupt Lucene indices. Overall, it's wonderful that Lucene's\u00a0\u00a0are so effective at finding not only Lucene bugs, but also bugs in the various JVM implementations. We've come a long ways since the\u00a0, and juicy bugs are being discovered and\u00a0squashed. Even so, it's not clear this tenuous process is scalable going forward, with the unnecessary friction in how outside users report issues and the sizable time required to isolate new JVM issues. This is time taken away from, say, building a\u00a0search engine! \n"}<br>{"index": {"_id": 973}}<br>{"title":"Better query execution coming to Elasticsearch 2.0","seo_title":"","url":"\/blog\/better-query-execution-coming-elasticsearch-2-0","author":{"name":"Adrien Grand"},"date":"July 15, 2015","category":"Engineering","locales":"","content":" It\u2019s time to forget everything you knew about queries and filters: Elasticsearch 2.0 will make much better decisions by itself instead of relying on users to formulate an optimized query. This change will be almost invisible at the API level but let\u2019s dive into the internal changes that made it possible. Most changes that are mentioned in this blog post have been done in Lucene 5.0, 5.1 and 5.2 and will be integrated in Elasticsearch 2.0. The query\/filter mergePrevious versions of Elasticsearch used to handle queries and filters as different citizens: you had queries that could match and score, and filters that could only match and were cacheable. In Elasticsearch 2.0, queries and filters are the same internal object, and these objects can be configured to score documents, or to skip scoring. Then the query DSL makes sure to propagate the information correctly: for instance the clause of a query would need to produce scores if the query needs to produce scores too, while a clause would never need to produce scores since it may only be used for filtering documents out. In order to make the query DSL more consistent with this change, : clauses are like clauses except that they do not contribute to the score. This means that the following query: { \u201cfiltered\u201d : { \u201cquery\u201d: { query definition }, \u201cfilter\u201d: { filter definition } } } should now be replaced with { \u201cbool\u201d : { \u201cmust\u201d: { query definition }, \u201cfilter\u201d: { filter definition } } } Note that the query DSL is still backward compatible in spite of this change: if you try to run a query, it will parse as a query internally. However, we would encourage you to migrate to the new syntax as the query will be removed in a future release. While this might look like a minor change, this is actually very useful for us. For instance, we used to have 3 queries\/filters that could perform conjunctions: the query, the filter and the query, and it happens that they all computed conjunctions in a slightly different way. The fact that we only have the query now allows us to perform optimizations in a more robust way, and in particular to leverage two-phase execution efficiently. Two-phase executionThe previous filter API could be consumed in two ways: either using iterators over matching documents, or using an optional random-access API that allowed to check if a particular document matched the filter or not. Everything is good so far, except that the best way to consume a filter depended on which kind of filter you had: for instance the filter was more efficient when using the random-access API while the filter was more efficient using the iterator API. This was quite a nightmare to optimize and was the root cause why the filter on the one hand and the and filters on the other hand performed differently. To fix this issue, Lucene introduced a new two-phase iteration API, which consists of an approximation phase that can quickly iterate over a superset of the matching documents, and a verification phase that can be used to check if a document in this superset actually matches the query. A good example of use of this API is the phrase query: if you search for \u201cquick fox\u201d, a good approximation would be to search for documents that contain both \u201cquick\u201d and \u201cfox\u201d, and then as a verification step we could read positions to see if we can find these terms at consecutive positions. Why is it useful? Imagine that you are searching for \u201cquick fox\u201d and applying a filter as well. The fact that we can dissociate the approximation from the verification phase allows us to first intersect the approximation with the filter, so that we will verify positions on a smaller set of documents. This two-phase iteration pattern also applies to other queries: for instance geo-distance queries can use a bounding box as an approximation and a distance computation as a verification, and filters that only make sense in a random-access fashion such as the filter can return all documents in the index as an approximation and run the script as a verification. A nice side-effect of this change is that , there is no need to pick one depending on the wrapped filters. By the way, we have deprecated the and filters and now encourage you to use instead. Smarter filter cachingOne issue that we often saw in previous Elasticsearch releases is that some queries were slow due to over-caching of filters. Take the term filter as an example: it can directly return iterators that are backed by disk-based postings lists, and these postings lists include skip lists that allow for efficient skipping, which is typically useful for conjunctions. However, if you want to cache the results, you need to consume the postings list entirely and load its content into memory, which means you can\u2019t skip over unnecessary documents quickly anymore. In summary, filters should never be cached if they are not going to be reused, otherwise caching them is wasteful. Elasticsearch changed filter caching to be entirely automatic. The way it works is that Elasticsearch keeps track of the 256 most recently used filters, and only caches those that appear 5 times or more in this history. The assumption is that over caching is more dangerous than under caching, given that uncached filters are already fast. So we would rather make sure they are reused before caching them. Also Elasticsearch does not cache anymore on segments which have less than 10000 documents or 3% of the documents of the index, since such segments are no bottleneck for query execution, on the contrary to the larger segments, and are also likely to be picked for a merge quickly since the merge policy favors small merges. As a consequence of this change, and will be ignored if provided. More efficient filter cacheIn Elasticsearch 1.x, filters are cached using actual bit sets. While bit sets have a nice worst-case of 1 bit per existing document, this is quite wasteful when you have only a couple of bits that are sets out of several millions of existing bits. To improve this situation, Elasticsearch switched to a sparse bit set implementation for its filter cache in 2.0 called . Also large terms filters are now prefix-compressed in order to take less memory in the filter cache. These two changes mean that you will now be able to cache more filters with the same amount of memory that you were giving to previous releases of Elasticsearch. Better execution of multi-term queriesMulti-term queries are a family of queries that match several terms depending on some condition. For instance queries match terms that start with a given sequence of bytes, queries match terms that match a given regular expression, etc. All these queries are executed the same way: we create a bit set, then visit all matching terms and read their postings lists into that bit set. This approach scales well when you have many terms, unlike the query. One drawback however, is that it cannot leverage skipping and needs to visit all matching documents for all terms. In order to improve this, we changed multi-term queries to rewrite to a query when they only\u00a0match a\u00a0few terms in order to be more efficiently intersected with other queries. Improved spansFinally, span queries got some interesting improvements, and in particular now fully leverage the new two-phase iteration infrastructure. Additionally, two new span queries are exposed: and . All of these changes work together to allow Elasticsearch to make better decisions about how to execute your queries optimally. You no longer need to think about whether to use bool vs and, the order of your query clauses, or whether to cache or not. Elasticsearch now does it all for you. \n"}<br>{"index": {"_id": 974}}<br>{"title":"Solving the local data problem with Elasticsearch and Docker Compose","seo_title":"","url":"\/blog\/solving-the-local-data-problem-elasticsearch-docker-compose","author":{"name":"Shelby Switzer"},"date":"July 15, 2015","category":"User Stories","locales":"","content":" Open data at the local government level may seem \u201csmaller\u201d but actually faces bigger challenges than those at the national level. \u00a0While there are increasing efforts to open government data sets nationally, cities, towns, counties, and even states are often left behind. These smaller entities don't have the resources to implement APIs for their data, and community tech groups and developers who want to use this data constantly encounter obstacles ranging from fragmented, non-uniform data to finding (and funding) API hosting and maintenance.But what if we could throw all that data in a box that's easy to open, close, and move around? What if we could bypass traditional solutions requiring infrastructure for hosting and maintenance? Enter Docker and Elasticsearch, and a simple three-layer, API-in-a-box solution that any developer can immediately turn on with . The Need Local brigades of (CfA) meet regularly across the country and even the world to bring together citizens from different backgrounds to improve their community and make government more accessible. This means routinely working with data provided by governments, typically in the form of Excel files, CSVs, other spreadsheets, and even PDFs, all containing interesting data such as government employee salaries or tax digests documenting business registration. These data sets can consist of anywhere between ten rows and a few thousand rows \u2014 what I call \u201csmall data.\u201d Developers working on these projects come from very different backgrounds with varying development environments, and must determine the best way to use this data and make it accessible for not only themselves but for other citizens and projects. The projects typically don\u2019t have funding, so they often can\u2019t be hosted, even though most engineers are familiar with interacting with and building clients for HTTP APIs.In sum, any solution, or set of solutions, to these various projects and their small data needs must: The Solution While Elasticsearch is typically thought of in the context of big data and huge amounts of text, it rose to the top of the list for solutions to working with the small data we encounter in civic hacking. The spreadsheets of data we often work with are incomplete, have only text data types, contain duplicates, and contain fields that no one (not even the government officials who provided the sources) can explain but should probably stick around in case they become useful later. Elasticsearch has a RESTful JSON API that is familiar to most developers and very intuitive to work with. Its powerful functions allow for the easy sorting, de-duping, and searching of data without actually changing or deleting raw data.We can then put a hypermedia API layer over Elasticsearch so that we have a uniform interface for different data sets that is not only consumable by generic hypermedia clients but also exposes the queries that are available for this data. For example, if my data has Name, Lat, Long, and Business Type fields, then a hypermedia API can expose those queries simply through the JSON response for the resource, so that anyone consuming this API knows what\u2019s possible even without documentation.But Elasticsearch and a hypermedia API need hosting just like any other database or server, so how can we use them for a solution that can be simply set up anywhere and not need paid hosting? Enter Docker.With a Docker container for Elasticsearch and another for the hypermedia API, and Docker Compose to link and start them together smoothly, we can create an API experience that is uniform, uses remote data, and has powerful search and data manipulation functionality, all without needing to be hosted anywhere beyond your local laptop.The final process is made up of these four easy steps: With an API-in-a-Box solution using Elasticsearch and Docker, anyone, anywhere, once they have the raw data, only needs to put that data in an accessible place, and then they can spin up a robust, flexible API on top of the data to be able to use it in any application they might want to build. It removes the local data problem from the civic hacking equation. \n"}<br>{"index": {"_id": 975}}<br>{"title":"This Week in Elasticsearch and Apache Lucene - July 15, 2015","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-07-15","author":{"name":"Leslie Hawthorn"},"date":"July 15, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Elasticsearch Core Apache Lucene Watch This Space , where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 976}}<br>{"title":"Where in the World is Elastic? - July 13, 2015","seo_title":"","url":"\/blog\/2015-07-13-where-in-the-world-is-elastic","author":{"name":"Livia Froelicher"},"date":"July 13, 2015","category":"","locales":"","content":" Welcome to\u00a0Check out our events happening this week. It's summer time and at least Europe is calming down a bit. But it's picking up soon again with more events and meetups coming\u00a0as of August\/September.Upcoming EventsJuly 16-17: \u00a0- Meet our team in the hallway or perhaps we'll see you in the open space zone where we made a proposal on the ELK stack.\u00a0Upcoming MeetupsJuly 14: July 14: July 14: July 14: July 15: July 14: July 16: July 13: July 14: That's it for this week.\u00a0Stay tuned for Elastic happenings next week - there's much to come!\u00a0- The Elastic TeamP.S.:\u00a0\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats,\u00a0Elasticsearch, Logstash or Kibana\u00a0\u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 977}}<br>{"title":"Introducing the Logstash HTTP input plugin","seo_title":"","url":"\/blog\/introducing-logstash-input-http-plugin","author":{"name":""},"date":"July 09, 2015","category":"","locales":"","content":" Logstash has been missing a way to receive data through HTTP requests, but not anymore! The \u00a0plugin is now available for everyone! Also, starting with , it is included as one of the default plugins that are distributed with the official release. So what exactly does the logstash-input-http plugin do?When you configure this plugin in the section, it will launch a HTTP server and create events from requests sent to this endpoint. This means you can send notification data to Logstash using webhooks, thereby integrating your existing applications with Logstash\u2019s rich plugin ecosystem! How do I use this plugin?By default it will bind the webserver to all hosts (\"0.0.0.0\") and open the TCP port 8080 but it's possible configure these settings: input { http { host => \"127.0.0.1\" # default: 0.0.0.0 port => 31311 # default: 8080 } } That's all you need! What about security?You can configure basic authentication by setting a username and password. All requests done to Logstash will then have to set the right credentials or receive a 401 response. Only correctly authenticated requests will produce an event inside of Logstash. For SSL, it is necessary to specify the path to a that contains the certificate that clients use to validate the server. Here's an example: input { port => 3332 user => myuser password => \"$tr0ngP4ssWD!\" ssl => on keystore => \"\/tmp\/mykeystore.jks\" keystore_password => \"keystore_pass\" } OK, now show me this plugin in action!Step 1 - starting Logstash with http input: bin\/logstash -e \"input { http { } } output { stdout { codec => rubydebug} }\" Step 2 - That's it! To test it, let's issue two requests: % curl -XPUT 'http:\/\/127.0.0.1:8080\/twitter\/tweet\/1' -d 'hello' % curl -H \"content-type: application\/json\" -XPUT 'http:\/\/127.0.0.1:8080\/twitter\/tweet\/1' -d '{ \"user\" : \"kimchy\", \"post_date\" : \"2009-11-15T14:12:12\", \"message\" : \"trying out Elasticsearch\" }' Result in Logstash: { \"message\" => \"hello\", \"@version\" => \"1\", \"@timestamp\" => \"2015-05-29T14:49:00.392Z\", \"headers\" => { \"content_type\" => \"application\/x-www-form-urlencoded\", \"request_method\" => \"PUT\", \"request_path\" => \"\/twitter\/tweet\/1\", \"request_uri\" => \"\/twitter\/tweet\/1\", \"http_version\" => \"HTTP\/1.1\", \"http_user_agent\" => \"curl\/7.37.1\", \"http_host\" => \"127.0.0.1:8080\", \"http_accept\" => \"*\/*\", \"content_length\" => \"5\" } } { \"user\" => \"kimchy\", \"post_date\" => \"2009-11-15T14:12:12\", \"message\" => \"trying out Elasticsearch\", \"@version\" => \"1\", \"@timestamp\" => \"2015-05-29T14:49:04.105Z\", \"headers\" => { \"content_type\" => \"application\/json\", \"request_method\" => \"PUT\", \"request_path\" => \"\/twitter\/tweet\/1\", \"request_uri\" => \"\/twitter\/tweet\/1\", \"http_version\" => \"HTTP\/1.1\", \"http_user_agent\" => \"curl\/7.37.1\", \"http_host\" => \"127.0.0.1:8080\", \"http_accept\" => \"*\/*\", \"content_length\" => \"110\" } } You can see that in the second request, since the content-type was , the body was deserialized and expanded to the event root (notice the fields \"user\", \"post_date\" and \"message\"). Show me more concrete examples of how to use it!Because, real world examples make everything clearer! Elastic\u00a0Watcher IntegrationIn this section, we\u2019ll show you how to integrate -- the new Elasticsearch plugin for alerting and notification -- with Logstash. notifications to Logstash via this input provides you a powerful toolset to further transform notifications and use Logstash\u2019s rich collection of . Imagine that you have indices with Apache logs, and now we want to get a periodic update of how many requests are resulting in a 404 (Not Found) response. The required steps for this are: Here we go! 1. Installing Watchercd elasticsearch-1.5.2 bin\/plugin -i elasticsearch\/watcher\/latest bin\/plugin -i elasticsearch\/license\/latest bin\/elasticsearch # restart the server 2. Creating a watchThe Watcher plugin for elasticsearch provides an API to create and manipulate scheduled tasks, or \"watches\". A will query the data in the elasticsearch cluster according to its schedule, look for certain scenarios (like the presence of an error event) and execute actions. Examples of are sending an email, writing a document to an index, calling an outside HTTP endpoint, and more.. For this test, I created a simple watch that: This is the resulting JSON document I need to send to Watcher: { \"trigger\" : { \"schedule\" : { \"cron\" : \"0 0\/1 * * * ?\" } }, \"input\" : { \"search\" : { \"request\" : { \"indices\" : [ \"logstash*\" ], \"body\" : { \"query\" : { \"term\": { \"response\": 404 } } } } } }, \"actions\" : { \"my_webhook\" : { \"webhook\" : { \"auth\" : { \"basic\" : { \"username\" : \"guest\", \"password\" : \"guest\" } }, \"method\" : \"POST\", \"host\" : \"127.0.0.1\", \"port\" : 8080, \"path\": \"\/{{ctx.watch_id}}\", \"body\" : \"{{ctx.payload.hits.total}}\" } } } } To install this watch you need to create it in Elasticsearch by executing a PUT request: curl -XPUT 'http:\/\/localhost:9200\/_watcher\/watch\/my-watch' -d @create_webhook.json 3. Logstash setupwget http:\/\/download.elastic.co\/logstash\/logstash\/logstash-1.5.2.tar.gz tar -zxf logstash-1.5.2.tar.gz cd logstash-1.5.2 bin\/logstash -e \"input { http { } } output { stdout { codec => rubydebug} }\" 4. ResultsAfter launching an ingestion process in another terminal, Logstash starts receiving 1 notification per minute in the form of a HTTP POST: % bin\/logstash -e \"input { http { } } output { stdout { codec => rubydebug} }\" Logstash startup completed { \"message\" => \"330\", \"@version\" => \"1\", \"@timestamp\" => \"2015-06-02T12:53:00.037Z\", \"headers\" => { \"content_type\" => \"application\/x-www-form-urlencoded\", \"request_method\" => \"POST\", \"request_path\" => \"\/my-watch\", \"request_uri\" => \"\/my-watch?\", \"http_version\" => \"HTTP\/1.1\", \"http_authorization\" => \"Basic Z3Vlc3Q6Z3Vlc3Q=\", \"http_accept_charset\" => \"UTF-8\", \"http_cache_control\" => \"no-cache\", \"http_pragma\" => \"no-cache\", \"http_user_agent\" => \"Java\/1.8.0_20\", \"http_host\" => \"127.0.0.1:8080\", \"http_accept\" => \"text\/html, image\/gif, image\/jpeg, *: q=.2, *\/*: q=.2\", \"http_connection\" => \"keep-alive\", \"content_length\" => \"12\" } } { \"message\" => \"3103\", \"@version\" => \"1\", \"@timestamp\" => \"2015-06-02T12:54:00.030Z\", \"headers\" => { \"content_type\" => \"application\/x-www-form-urlencoded\", \"request_method\" => \"POST\", \"request_path\" => \"\/my-watch\", \"request_uri\" => \"\/my-watch?\", \"http_version\" => \"HTTP\/1.1\", \"http_authorization\" => \"Basic Z3Vlc3Q6Z3Vlc3Q=\", \"http_accept_charset\" => \"UTF-8\", \"http_cache_control\" => \"no-cache\", \"http_pragma\" => \"no-cache\", \"http_user_agent\" => \"Java\/1.8.0_20\", \"http_host\" => \"127.0.0.1:8080\", \"http_accept\" => \"text\/html, image\/gif, image\/jpeg, *: q=.2, *\/*: q=.2\", \"http_connection\" => \"keep-alive\", \"content_length\" => \"13\" } } { \"message\" => \"6071\", \"@version\" => \"1\", \"@timestamp\" => \"2015-06-02T12:55:00.031Z\", \"headers\" => { \"content_type\" => \"application\/x-www-form-urlencoded\", \"request_method\" => \"POST\", \"request_path\" => \"\/my-watch\", \"request_uri\" => \"\/my-watch?\", \"http_version\" => \"HTTP\/1.1\", \"http_authorization\" => \"Basic Z3Vlc3Q6Z3Vlc3Q=\", \"http_accept_charset\" => \"UTF-8\", \"http_cache_control\" => \"no-cache\", \"http_pragma\" => \"no-cache\", \"http_user_agent\" => \"Java\/1.8.0_20\", \"http_host\" => \"127.0.0.1:8080\", \"http_accept\" => \"text\/html, image\/gif, image\/jpeg, *: q=.2, *\/*: q=.2\", \"http_connection\" => \"keep-alive\", \"content_length\" => \"13\" } } A more complex exampleNow that we know how to trigger notification events from Watcher, we can leverage the plugin ecosystem in Logstash to escalate notifications depending in a certain criteria. This following config will: input { http { } } filter { if [headers][request_path] == \"\/my-watch\" { mutate { convert => [\"message\", \"integer\" ] } } } output { if [headers][request_path] == \"\/my-watch\" { if [message] > 40000 { # way too many, notify pagerduty pagerduty { description => \"%{host} - Apache: Very high number of 404\" details => { \"timestamp\" => \"%{@timestamp}\" \"message\" => \"%{message}\" } service_key => \"apikeyforlogstashservice\" incident_key => \"logstash\/apacheservice\" } } else if [message] > 10000 { # unusual amount, notify devs in hipchat hipchat { from => \"logstash\" room_id => \"dev\" token => \"[api key]\" format => \"Very high number of 404 requests: %{message}\" } } # always update count of 404 in statsd statsd { gauge => [ \"http.status.404\", \"%{message}\" ] } } } That's it! Next is an example using GitHub instead of Watcher as the source of notifications. Receiving updates from GitHubGitHub allows you to receive commit , so let's receive those in Logstash through the HTTP input plugin. The steps I needed to accomplish this were: 1. Logstash setupI created a VM on Amazon with TCP port 9200 open: Then setup and start logstash: wget http:\/\/download.elastic.co\/logstash\/logstash\/logstash-1.5.2.tar.gz tar -zxf logstash-1.5.2.tar.gz cd logstash-1.5.2 bin\/logstash -e \"input { http { port => 9200 } } output { stdout { codec => rubydebug} }\" Why a VM? I needed Logstash to be accessible from the internet, and exposing a port on my home network router was complicated.. 2. Github webhook setupI created a GitHub repo under my account called . There I set up a webhook and pointed it at the VM: 3. Generating eventsLet's generate 1 commit so GitHub will notify Logstash: git clone https:\/\/github.com\/jsvd\/test-repo cd test-repo echo 1 >> a git commit -a -m \"new commit\" git push 4. ResultOn the VM, Logstash received (output shortened for readability, ): $ bin\/logstash -e \"input { http { port => 9200 } } output { stdout { codec => rubydebug} }\" { \"ref\" => \"refs\/heads\/master\", \"before\" => \"22dc008b4a9a612ff3fc55b02fabd551a582e271\", \"after\" => \"9046cd06b307dec789248a72c9f36630decc037a\", \"created\" => false, \"deleted\" => false, \"forced\" => false, \"base_ref\" => nil, \"compare\" => \"https:\/\/github.com\/jsvd\/test-repo\/compare\/22dc008b4a9a...9046cd06b307\", \"commits\" => [ [0] { \"id\" => \"9046cd06b307dec789248a72c9f36630decc037a\", \"distinct\" => true, \"message\" => \"new commit\", \"timestamp\" => \"2015-06-02T14:58:14+01:00\", \"url\" => \"https:\/\/github.com\/jsvd\/test-repo\/commit\/9046cd06b307dec789248a72c9f36630decc037a\", \"author\" => { \"name\" => \"Joao Duarte\", \"email\" => \"XXXXXXXXXXXX\", \"username\" => \"jsvd\" }, \"committer\" => { \"name\" => \"Joao Duarte\", \"email\" => \"XXXXXXXXXXXX\", \"username\" => \"jsvd\" } } ], \"head_commit\" => { \"id\" => \"9046cd06b307dec789248a72c9f36630decc037a\", \"distinct\" => true, \"message\" => \"new commit\", \"timestamp\" => \"2015-06-02T14:58:14+01:00\", \"url\" => \"https:\/\/github.com\/jsvd\/test-repo\/commit\/9046cd06b307dec789248a72c9f36630decc037a\", \"author\" => { \"name\" => \"Joao Duarte\", \"email\" => \"XXXXXXXXXXXX\", \"username\" => \"jsvd\" }, \"committer\" => { \"name\" => \"Joao Duarte\", \"email\" => \"XXXXXXXXXXXX\", \"username\" => \"jsvd\" } } } ConclusionThis input plugin opens up an incredible amount of possible scenarios since a lot of applications use webhooks and know how to export data using HTTP requests. I'm already thinking of a ton of ideas where I can leverage this plugin, how are you going to use it? \n"}<br>{"index": {"_id": 978}}<br>{"title":"This Week in Elastic - July 08, 2015","seo_title":"","url":"\/blog\/this-week-in-elastic-2015-07-08","author":{"name":"Leslie Hawthorn"},"date":"July 08, 2015","category":"","locales":"","content":" Welcome to ! In this weekly round up post, we bring you news on all aspects of the ELK Stack, including updates on Elasticsearch, Logstash and Kibana development, tips and tricks and upcoming events. - hosted - is here. Join us on July 15 for a live webinar, demo, & Q&A. \u2014 elastic (@elastic) Elastic News Useful blog posts, how tos, tutorials\u00a0and articles\u00a0from the wide world of all the ELK stack ecosystem. Gearing up 4 the Tel Aviv meetup.View from the Gigya offices are amazing.Thx for hosting us. \u2014 Boaz Leskes (@bleskes) Slides and VideosAnd you can enjoy on from last week's JDEV Conference .Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking about the ELK stack\u00a0or hosting a meetup, Australia FranceThe Elastic Paris Meetup will get together on July 29 to talk Fuzzy Name Matching in Elasticsearch. to save your seat.Germany Hong Kong will be speaking at the , coming up July 31 - August 2 in Hong Kong. Stay tuned for more details on his talk!IsraelFor our second Tel Aviv meetup in July, you can hear about Elasticsearch and Fuzzy Matching, Fighting Crime with Elasticsearch and Unstructured Data Analytics and more. to attend this meetup on July 22.Japan\u5927\u962a\u3067\u3082\u3084\u308a\u307e\u3059\uff01\u30b9\u30d4\u30fc\u30ab\u30fc\u52df\u96c6\u4e2d\u3067\u3059\uff01\/ Elasticsearch\u52c9\u5f37\u4f1a in \u5927\u962a - elasticsearch\u52c9\u5f37\u4f1a | Doorkeeper - \u2014 Jun Ohtani (@johtani) \u51fa\u5f35Elasticsearch\u52c9\u5f37\u4f1a\u7b2c2\u5f3e\uff01 \/ Elasticsearch\u52c9\u5f37\u4f1a in \u4eac\u90fd - elasticsearch\u52c9\u5f37\u4f1a | Doorkeeper - \u2014 Jun Ohtani (@johtani) South AfricaWe are a proud swag sponsor of the . If you happen to be in Johannesburg on July 11, pop in for knowledge and some cool Elastic goodies. SpainEuroPython 2015 heads to Bilbao this year, featuring two talk from : and . You can learn more about Honza's talks in the : EuroPython runs July 20-26. SwitzerlandThe Elasticsearch Switzerland Meetup group will get together on July 14 to talk Elasticsearch Under the Hood with . to save your seat. United KingdomThe London Elastic Meetup will get together on July 21 for two talks, including on using Kibana 4 to analyze data from the Ministry of Transportation. to save your seat - we're hosting at the Elastic London office!United States - East United States - West Where to Find You \u00a0If you're a regular reader, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to\u00a0 ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 979}}<br>{"title":"Out of this world aggregations","seo_title":"","url":"\/blog\/out-of-this-world-aggregations","author":{"name":"Colin Goodheart-Smithe"},"date":"July 08, 2015","category":"","locales":"","content":" One of the most visible features coming in 2.0 are the Pipeline Aggregations. This is an extension of the current Aggregations framework, to allow additional computations to be performed on top of the results of aggregations. This allows users to ask questions such as \u201cWhat is the maximum average monthly price?\u201d from a date histogram and \u201cHow many new users are signing up each day?\u201d from a date histogram showing total user count each day. Internally these aggregation are run after the other aggregations have completed on the coordinating node. This means Pipeline Aggregators are able to use the final results of their sibling aggregations but are not able to go back to the shards to query the index. The first of these new types are: In this post I will show some of these new aggregations in action. To help demonstrate, I have downloaded spacecraft trajectory data from for the Voyager 1 and Voyager 2 spacecraft. Each document in my index represents the position of one of the spacecraft on a particular day. The data spans from the launch of the Voyager missions in September 1977 to the present day and also includes projected trajectories up to 2020. Below is an example of a document in Elasticsearch: { \"_index\": \"helioweb\", \"_type\": \"voyager1\", \"_id\": \"1977-257\", \"_score\": 1, \"_source\": { \"seLon\": 353.8, \"objectName\": \"voyager1\", \"seLat\": 0.2, \"year\": 1977, \"date\": \"1977-09-14T10:28:25.178Z\", \"radAU\": 1.02, \"dayOfYear\": 257 } } and are the latitude and longitude of the object in the respectively, and is the radial distance of the object from the Sun measured in . In this post we will mainly be concentrating on the , , and fields. So first let\u2019s plot the average radial distance of Voyager 1 over time. This can be done with the existing aggregations by defining the following aggregations: { ... \"aggs\": { \"histo\": { \"date_histogram\": { \"field\": \"date\", \"interval\": \"month\" }, \"aggs\": { \"avg_distance\": { \"avg\": { \"field\": \"radAU\" } } } } } } The graph we get from the results looks pretty uninteresting: Basically all we can find out from this is that since launch Voyager 1 has been travelling further and further away from the Sun. Not exactly surprising for a long distance space probe! But what does Voyager 1\u2019s radial speed over time look like? This isn\u2019t something you can currently do in Elasticsearch. The indexed documents only contain the radial distance of Voyager 1 so its speed cannot be plotted directly. With the new Derivative Aggregation we can take the derivative of that distance to calculate the radial speed each month: { ... \"aggs\": { \"histo\": { \"date_histogram\": { \"field\": \"date\", \"interval\": \"month\" }, \"aggs\": { \"avg_distance\": { \"avg\": { \"field\": \"radAU\" } }, \"speed\": { \"derivative\": { \"buckets_path\": \"avg_distance\" } } } } } } Pipeline aggregations look very similar to the other aggregations in the request, but instead of having a parameter to reference which in the document they will work on, they have a which references which aggregation to use in their calculation. The resulting aggregation tree for the above request looks like this: { ... \"aggregations\": { \"histo\": { \"buckets\": [ { \"key_as_string\": \"1977-09-01T00:00:00.000Z\", \"key\": 241920000000, \"doc_count\": 25, \"avg_distance\": { \"value\": 1.0328 } }, { \"key_as_string\": \"1977-10-01T00:00:00.000Z\", \"key\": 244512000000, \"doc_count\": 31, \"avg_distance\": { \"value\": 1.1867741935483873 }, \"speed\": { \"value\": 0.15397419354838737 } }, \u2026 ] } } } You can see that the Derivative Aggregation has added a new value to the all but the first bucket. The first bucket is left empty as we require two values to compute the derivative, the current value and the previous value. Since there is no previous value for the first bucket, we can\u2019t compute a derivative for it. Plotting the speed against time gives us a much more interesting graph: Here we can see that Voyager 1\u2019s radial speed dropped significantly twice, once around 1979 and once around 1981. Looking at the we can see that these points coincide with the closest approach of Voyager 1 with Jupiter and Saturn. We can actually use the Min Bucket Aggregation to determine which month Voyager 1 was travelling at its slowest radial speed using the following: { ... \"aggs\": { \"histo\": { \"date_histogram\": { \"field\": \"date\", \"interval\": \"month\" }, \"aggs\": { \"avg_distance\": { \"avg\": { \"field\": \"radAU\" } }, \"speed\": { \"derivative\": { \"buckets_path\": \"avg_distance\" } } } }, \"min-speed\": { \"min_bucket\": { \"buckets_path\": \"histo > speed\" } } } } Which returns a new aggregation alongside the histogram showing the minimum value for the slowest radial speed and the bucket keys of the bucket which have this minimum value: { ... \"aggregations\": { \"histo\": { \"buckets\": [ ... ] }, \"min-speed\": { \"value\": 0.10212903225806436, \"keys\": [ \"1979-04-01T00:00:00.000Z\" ] } } } So the slowest radial speed was in April 1979 which matches the Voyager timeline as the closest approach to Jupiter was during March 1979. Previously this would have required the client application to parse all the buckets, keeping track of the minimum value. We can show the radial speed of both Voyager 1 and Voyager 2 in the same response by using the filter aggregation to show the average radial distance of Voyager 1 and Voyager 2 and then use two derivative aggregations, one referencing the Voyager 1 distance and the other referencing the Voyager 2 distance: { \"aggs\": { \"histo\": { \"date_histogram\": { \"field\": \"date\", \"interval\": \"month\" }, \"aggs\": { \"voyager_1\": { \"filter\": { \"term\": { \"objectName\": \"voyager1\" } }, \"aggs\": { \"avg_distance\": { \"avg\": { \"field\": \"radAU\" } } } }, \"voyager_2\": { \"filter\": { \"term\": { \"objectName\": \"voyager2\" } }, \"aggs\": { \"avg_distance\": { \"avg\": { \"field\": \"radAU\" } } } }, \"voyager_1_speed\": { \"derivative\": { \"buckets_path\": \"voyager_1>avg_distance\" } }, \"voyager_2_speed\": { \"derivative\": { \"buckets_path\": \"voyager_2>avg_distance\" } } } } } } Now, the references the metric inside each of the filter aggregations using . We can now plot the radial speed of Voyager 1 (blue line) and Voyager 2 (red line): Again from looking at the we can see that the drops in radial speed of Voyager 2 coincide with its closest encounters with Jupiter, Saturn, Uranus and Neptune. Since pipeline aggregations happen right at the end of the aggregation phase, they can be chained together (hence the name pipeline). So to calculate the radial acceleration of the Voyager 1 spacecraft we can just calculate the derivative of the speed (which we calculated in the previous pipeline aggregation) by adding the following aggregation to the request: { ... \"voyager_1_acceleration\": { \"derivative\": { \"buckets_path\": \"voyager_1_speed\" } } \u2026 } Here, instead of referencing a metric aggregation we are referencing the derivative aggregation . This will add an aggregation called to the response for all but the first 2 buckets (since we need two values for to calculate the acceleration). These are just the first pipeline aggregations. We are currently working to add more pipeline aggregations to and there is a growing list of other ideas for possible pipeline aggregators including one that can be used to filter out buckets which do not meet a specified criteria (using this aggregation you could, for example, ask for only histogram buckets where the average speed is greater than a threshold value). We would also appreciate any feedback you have on the current pipeline aggregations and your suggestions for other pipeline aggregations that we could add in the future. Happy exploring! \n"}<br>{"index": {"_id": 980}}<br>{"title":"This Week in Elasticsearch and Apache Lucene - July 7, 2015","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-07-07","author":{"name":"Leslie Hawthorn"},"date":"July 07, 2015","category":"","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsEverything you want to know about Found\u2019s hosted service - register here: \u2014 Found by Elastic (@foundsays) Elasticsearch Core Apache LuceneWatch This Space , where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 981}}<br>{"title":"Where in the World is Elastic? - July 06, 2015","seo_title":"Where in the World is Elastic, July 6 2015","url":"\/blog\/2015-07-06-where-in-the-world-is-elastic","author":{"name":"Livia Froelicher"},"date":"July 06, 2015","category":"","locales":"","content":" Welcome to\u00a0Check out this weeks events and meetups and join us if one of them is happening near you!Upcoming EventsJuly 8-9:\u00a0 - Come by our booth, talk to the Elastic team and grab a cool piece of swag on the way!July 10-11: - Say hi to who will\u00a0be giving an introduction to Elasticsearch as part of Adrian Carr's talk\u00a0\"Amazing Speed - Elasticsearch for the .NET Developer\" on Friday, July 10,\u00a0at 4:05 p.m.\u00a0Feel free to ask him questions thereafter, he's around for the duration of the\u00a0event.July 7: - Come say hi at the Elastic\/Mimacom booth (#33) to check out cool\u00a0demos and talk all things ELK!July 11:\u00a0\u00a0- Check out community organiser\u00a0Jurgen du Toit's talk on \"StaticElastic: An Elasticsearch and Backbone SPA\"\u00a0at 2 p.m.Upcoming MeetupsJuly 7: July 8: July 8: July 7: July 8: That's it for this week.\u00a0Stay tuned for Elastic happenings next week - there's much to come!\u00a0- The Elastic TeamP.S.:\u00a0\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats,\u00a0Elasticsearch, Logstash or Kibana\u00a0\u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 982}}<br>{"title":"Store compression in Lucene and Elasticsearch","seo_title":"","url":"\/blog\/store-compression-in-lucene-and-elasticsearch","author":{"name":"Adrien Grand"},"date":"July 02, 2015","category":"Engineering","locales":"","content":" Back in 2011 if you asked Lucene to index and store some text content, odds are high that your inverted index would take about 30% of the size the original data while the document store (also called \u201cstored fields\u201d) would take a bit more than 100%. Why more than 100%? Because the document store would just store your documents sequentially on disk without any compression and even add some overhead, for instance separators between fields. If you wanted to add compression, your only option was to compress field values yourself before sending them to Lucene. Unfortunately, compression algorithms don\u2019t like short content much. They prefer longer content where they have more opportunities to identify patterns and take advantage of them for compression. Actually if you compress a short string, it will likely be larger than the original string due to the overhead of the compression container. So if you were indexing structured content, you pretty much had no options for store compression. Lucene 4 and codecsBut then in 2012 perspectives changed after the release of Lucene 4.0. One of the major highlights of Lucene 4.0 was the new codec API, which gives developers a framework that makes experimentation with file formats and backward compatibility easier. The latter point in particular is important: if you want to change the index format, all you need to do is to build a new codec and make it the new default. Since segments register the codec that has been used to write them, old segments would still work by using the read API of the previous codec while new segments would be written using the new codec. This has been a very important change since it allowed us to perform drastic changes of the index format in minor releases in a backward-compatible way. By the way, out of the eleven 4.x Lucene releases, 6 of them changed the index format! In particular in Lucene 4.1, the codec changed in order to automatically compress the document store. It works by grouping documents into blocks of 16KB and then compresses them together using , a lightweight compression algorithm. The benefit of this approach is that it also helps compressing short documents since several documents would be compressed into a single block. However in order to read a single document, you need to decompress the whole block. It generally does not matter as decompressing 16KB for 100 documents with LZ4 is still faster than running a non-trivial query or even just seeking on a spinning disk for these 100 documents. Better compression with DEFLATEThe good news is that we brought even more improvements to the document store in Lucene 5.0. More and more users are indexing huge amounts of data and in such cases the bottleneck is often I\/O, which can be improved by heavier compression. Lucene 5.0 still has the same default codec as Lucene 4.1 but now allows you to use (the compression algorithm behind zip, gzip and png) instead of LZ4, if you would like to have better compression. We know this is something which has been long awaited, especially by our logging users. Opting in for better compression is just a matter of setting the setting to . For instance, the following API call would create an index called that trades stored field performance for better compression: curl -XPUT \u2018localhost:9200\/my_index\u2019 -d \u2018{ \u201csettings\u201d: { \u201cindex.codec\u201d: \u201cbest_compression\u201d } }\u2019 Hot and cold nodesThis new option opens new perspectives when it comes to managing hot and cold data: with time-based indices, it is common that indices become queried less often the older they get since new data tend to be more interesting than old data. In order to remain cost-effective in such cases, a good practice is to leverage elasticsearch to assign new indices to beefy machines with fast CPUs and disks, and old indices to cheaper machines that have plenty of disk space. Now you can also enable better compression on the cold nodes by setting in their file in order to be able to archive more data with the same amount of disk space. The sequence of actions would be the following: Improved merging of stored fieldsAnother change that we brought to Lucene 5 is improved stored field merging. When merging segments together in Lucene 4, we would decompress them entirely and then recompress them into a new segment. While this was not too much of an issue with LZ4, it is with DEFLATE as merges can become CPU-bound because of (de)compression. We fixed it by copying compressed data directly at merge time. This is not as easy as it may sound: the last block of a segment is most of time incomplete (less than 16KB). So by copying compressed data directly, incomplete blocks would accumulate in the index and end up hurting the compression ratio. The way it works is that Lucene keeps track of the number of incomplete blocks and only recompresses when this number exceeds a certain threshold. These Lucene-5 changes I discussed will be available in the upcoming Elasticsearch 2.0 release. I hope you liked this retrospective on the state of store compression in Lucene, see you next time for a new article about Lucene and Elasticsearch internals! \n"}<br>{"index": {"_id": 983}}<br>{"title":"The Logstash Lines \u2014 Logstash Forwarder with Docker, a new input plugin, and more!","seo_title":"","url":"\/blog\/logstash-lines-2015-07-02","author":{"name":"Shaunak Kashyap"},"date":"July 02, 2015","category":"","locales":"","content":" Welcome back to ! In these weekly\u00a0posts, we'll share the latest happenings in the world of Logstash and its ecosystem. Ever wanted to use Logstash Forwarder with Docker? Here is a two-part article series explaining how to do just this: And from our very own , here is part one of a three-part blog\u00a0series on Kafka and Logstash integration:\u00a0 Logstash Core and Plugins That's this week in . Come back next week for more Logstash news! \n"}<br>{"index": {"_id": 984}}<br>{"title":"Curator 3.2.0 Released","seo_title":"","url":"\/blog\/curator-3-2-0-released","author":{"name":"Aaron Mildenstein"},"date":"July 02, 2015","category":"Engineering","locales":"","content":" Curator 3.2.0 is here! \u00a0While this release is an incremental improvement over 3.1.0 and 3.0.0, there are some noteworthy things we just had to let you know about:What\u2019s new?Some of the changes included in 3.2.0 are:Let\u2019s take a look at some of these!Synced Flush SupportWith the release of came a highly anticipated feature: , which allows your cluster to recover more quickly. \u00a0The best part of this feature is that your indices will automatically have the benefits of this feature applied as soon as they go inactive (5 minutes with no indexing). \u00a0However, there may be times when you need to shut down immediately, but want to have your indices recover more quickly via a synced flush. \u00a0If you run into such a scenario, Curator can help:curator seal indices --all-indicesOf course, you can use all of the regular parameters, too!Curator will detect if your cluster is 1.6+ and will automatically perform a synced flush on indices before they are closed.Alias CreationIn all prior versions of Curator, an alias had to already exist in order to add or remove indices to it. \u00a0Now, starting with 3.2.0, if the alias does not exist, Curator will create it with the indices you specify.The --skip-repo-validation FlagBeginning with Elasticsearch 1.4, creating a snapshot repository would result in Elasticsearch testing all nodes to ensure each had read\/write access to the shared filesystem, be it NFS, S3, Azure, HDFS, etc. \u00a0An to manually test write access also came with it. \u00a0This API call is used by Curator as a test before snapshots as a safety check, ensuring that all nodes still have write access to the repository. \u00a0This has helped some users find errors that might have resulted in incomplete or broken snapshots. \u00a0However, some users reported intermittent errors with this validation check, usually as a result of the test timing out for some reason, rather than that the file system was unavailable.Because it is a safety check to ensure availability, it is not recommended that you use the --skip-repo-validation flag unless you are completely certain that all nodes have functional read\/write access to the repository and that the errors are the result of intermittent network timing issues.Experimental: SSL Certificate ValidationThis was a requested feature. \u00a0If you\u2019re using SSL to connect to your Elasticsearch instance (you\u2019re using , for example), if you have signed certificates you may see warnings that your certificate is invalid, even though it valid. \u00a0With the new validation feature, these false-positive warnings should go away. \u00a0In order to use this feature you need to be using Curator 3.2.0 and have the Python module installed. \u00a0This can be installed easily by running:pip install certifiWith the certifi module installed, SSL certificate validation should be automatic. \u00a0This feature is experimental, so please report any issues you may encounter at One more thing\u2026All these features make for a great release. \u00a0But this isn\u2019t all that we have cooked up for you.Package RepositoriesCurator is a Python-based product, which can complicate deployment on servers without installed. \u00a0The call for package-based deployment has been heard, and answered!: If you have already installed Curator by way of , you should continue to use . \u00a0These packages provide Python modules which may otherwise conflict with modules installed via or .We even have (64bit only)! \u00a0These binaries are compiled using the fantastic tool, . \u00a0As a result, you no longer need to have Python installed on Windows to use Curator. \u00a0Unzip the package, and run the Curator exe file in a CMD or PowerShell window.ConclusionWe hope you like the new features, and the availability of packages! \u00a0With the release of packages, and package repositories, Curator is now even easier to obtain and deploy\u2014wherever you may need it.\u00a0 \n"}<br>{"index": {"_id": 985}}<br>{"title":"This Week in Elastic - July 01, 2015","seo_title":"This Week in Elastic: July 1, 2015","url":"\/blog\/this-week-in-elastic-2015-07-01","author":{"name":"Leslie Hawthorn"},"date":"July 01, 2015","category":"","locales":"","content":" Welcome to ! In this weekly round up post, we bring you news on all aspects of the ELK Stack, including updates on Elasticsearch, Logstash and Kibana development, tips and tricks and upcoming events. We\u2019ve made (hosted ) more awesome. Now w\/our new Premium & Standard plans \u2014 elastic (@elastic) Elastic News Useful blog posts, how tos, tutorials\u00a0and articles\u00a0from the wide world of all the ELK stack ecosystem. Slides and Videos \\Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking about the ELK stack\u00a0or hosting a meetup, AustraliaOur team will be in the exhibits hall at , on July 16 & 17. We're also proposing an open space on the ELK Stack, so perhaps we'll see you in the open space zone, too.France Germany IndiaThe Practical Big Data Science Meetup will host a hands on training on the ELK stack for log analysis and monitoring on July 4. to save your seat.Israel Japan\u5927\u962a\u3067\u3082\u3084\u308a\u307e\u3059\uff01\u30b9\u30d4\u30fc\u30ab\u30fc\u52df\u96c6\u4e2d\u3067\u3059\uff01\/ Elasticsearch\u52c9\u5f37\u4f1a in \u5927\u962a - elasticsearch\u52c9\u5f37\u4f1a | Doorkeeper - \u2014 Jun Ohtani (@johtani) \u51fa\u5f35Elasticsearch\u52c9\u5f37\u4f1a\u7b2c2\u5f3e\uff01 \/ Elasticsearch\u52c9\u5f37\u4f1a in \u4eac\u90fd - elasticsearch\u52c9\u5f37\u4f1a | Doorkeeper - \u2014 Jun Ohtani (@johtani) New ZealandThe next meeting of the Elasticsearch ELK NZ meetup is coming to Wellington on July 2. We're still lining up the agenda, but for now to save your seat. PolandJoin in Poznan for . The conference runs July 2-4. South AfricaWe are a proud swag sponsor of the . If you happen to be in Johannesburg on July 11, pop in for knowledge and some cool Elastic goodies. SpainEuroPython 2015 heads to Bilbao this year, featuring two talk from : and . You can learn more about Honza's talks in the : EuroPython runs July 20-26.SwitzerlandThe Elasticsearch Switzerland Meetup group will get together on July 14 to talk Elasticsearch Under the Hood with . to save your seat.UkraineThe L'viv DevOps Meetup will get together on July 4 for their second installment of the CoreOS Fest Conference review, featuring a CoreOS with Kubernetes demo: ElasticSearch Cluster on local machine and AWS. to save your seat. United Kingdom United States - East United States - West Where to Find You \u00a0If you're a regular reader, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to\u00a0 ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 986}}<br>{"title":"We Just Made Found More Awesome","seo_title":"","url":"\/blog\/we-just-made-found-more-awesome","author":{"name":"Shay Banon"},"date":"July 01, 2015","category":"News","locales":"","content":" It has been 4 months since , and they have been wonderful. The teams, now working together, broke ground when it comes to providing the best hosted Elasticsearch (and more) offering out there (even I played a ).All this hard work and unique opportunity to work closely together has resulted in today, when we launch\u00a0. Found Standard, everything that you know and love about Found today with additional features and a \u00a0lower price point, and Found Premium, with SLA-driven support and\u00a0in the future, Shield and Watcher on top of that.Found StandardFound is awesome, with dedicated Elasticsearch clusters, easy scaling, security built in, hourly pay as you go, and much more. We think this is the go-to solution when someone is looking for hosted Elasticsearch, and we want to make sure we make it available and affordable for everybody.Starting today, we have reduced the prices of Found considerably, one can easily get started with hosted Elasticsearch\u00a0for .While reducing the prices is one important step in the right direction, we want to make sure everybody running on Found will have the best experience possible. Together with reducing the prices, we are also happy to announce that Found will come with , and .One of the important features of Found is the ability to choose on how many data centers your cluster will be deployed for high availability. Your data is important, and we want to make sure we can help you make the right choice. To reflect it, our pricing \u00a0your cluster is deployed on.We also, as you probably guessed, love Kibana, and we think Kibana is a groundbreaking way to visualize data in Elasticsearch. Kibana 4, our latest version of Kibana, comes with a server side component, which means it incurs an additional toll in order to provide it as a service. In the same spirit, and thanks to the incredible infrastructure the Found team has built and the close work with the Kibana team, we are also happy to say that any hosted Elasticsearch cluster will get its own \u00a0starting July 15th.Found PremiumWe are also happy to announce that we have taken our subscriptions offering around our open source products and now provide it on top of Found Standard, and we are calling it Found Premium.If you want SLA-based support, compared to forum based support, from the team that built the products, you now have that option. Whether it's a critical event and you need help, or looking for guidance and advice on how to best use our products to anticipate problems, we are here for you.In the near future, as it is part of our subscription offerings, we will also make , our one stop security product for Elasticsearch, and , our alerting product, available for no additional charge to Found Premium customers.It is humbling to see how our teams have worked together to make sure we can make all of this possible, and roll all this wonderful work to you, our users. The future is exciting. I am incredibly proud and we hope you like it \u2013 to learn more and get your questions answered! \n"}<br>{"index": {"_id": 987}}<br>{"title":"This Week in Elasticsearch and Apache Lucene - June 30, 2015","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-06-30","author":{"name":"Leslie Hawthorn"},"date":"June 30, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsHave an upgrade on the horizon? Get some tips on leveling up your cluster from next week: \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space , where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 988}}<br>{"title":"Logstash 1.5.2 released","seo_title":"","url":"\/blog\/logstash-1-5-2-released","author":{"name":"Suyog Rao"},"date":"June 30, 2015","category":"Releases","locales":"","content":" Logstash 1.5.2 is now available for ! This is a bug fix release which resolves an important issue in file input. Check the for full details! http input plugin We are also announcing the availability of a new , which is bundled with 1.5.2. This is a general purpose input for sending data to Logstash through http(s). Interesting use cases, you ask? If your existing applications support webhooks, it's now possible to send actionable data through this input to leverage Logstash's rich plugin ecosystem. For example, your Continuous Integration platform such as Jenkins can push build failure notifications to Logstash and index them in Elasticsearch. At the same time you can page developers for critical build failures using conditionals and the PagerDuty output. Watcher integration More interestingly, using our recently announced product, you can set up notifications triggered from data in your Elasticsearch cluster to be escalated through , notify co-workers on and archived to for long term storage. All this can be accomplished in a single (and simple) Logstash configuration. Watch out for a more detailed blog post about this plugin and its use cases. Bug Fixes Fixed a critical bug where new files added to a directory being watched would cause an error. This issue also happens when wildcards were used to watch files matching a certain pattern (). String interpolation is widely used in LS to create keys combining dynamic values from extracted fields. For example, this is used to create an Elasticsearch index name based on the timestamp of an event. We added an optimization which compiles this interpolation template on first use and caches in-memory for subsequent uses. Our performance testing show about 20% increase in throughput for configs that involve a lot of date processing and use field reference syntax ) This input was not handling backpressure properly from downstream plugins and would not timeout client connections, causing clients to constantly reconnect and eventually cause Logstash to run out of memory. We added a circuit breaker to stop accepting new connections when we detect this situation. Please note that `max_clients` setting introduced in v0.1.9 has been deprecated. This setting temporarily solved the problem by configuring an upper limit to the number of LSF connections (). Please Logstash 1.5.2 and let us know what you think on Twitter () or on our . You can report any problems on the . \n"}<br>{"index": {"_id": 989}}<br>{"title":"Field Formatters in Kibana 4.1","seo_title":"","url":"\/blog\/kibana-4-1-field-formatters","author":{"name":"Shaunak Kashyap"},"date":"June 30, 2015","category":"Engineering","locales":"","content":" One of the new features in Kibana 4.1 that we are \u00a0excited about is field formatters. Field formatters allow you to display your data in Kibana the way you prefer to \u00a0it, regardless of how it is actually \u00a0in Elasticsearch. For instance, if you are storing date\u00a0values in Elasticsearch and\u00a0would like them to be displayed in\u00a0mm\/dd\/yyyy format, you can easily\u00a0do that now, courtesy of field formatters! Here's how you can start formatting your fields in Kibana : Watch the following short screencast as it walks through the steps listed above. In this example, a field with a raw number value representing bytes of some data is being formatted using the Bytes field formatter: But field formatters can be used for more than formatting bytes values. You can create links, insert images (see screenshot below), and much more.Here is an example of using\u00a0http status cats to represent the HTTP status codes from the log files: And here's what it ends up looking like: Go ahead.\u00a0Give it a whirl. \n"}<br>{"index": {"_id": 990}}<br>{"title":"Elasticsearch Logging Secrets","seo_title":"","url":"\/blog\/elasticsearch-logging-secrets","author":{"name":"Andrei Stefan"},"date":"June 30, 2015","category":"","locales":"","content":" Like every other software out there, Elasticsearch provides some insight into what's happening with its internals while running. This is an informative process and can reveal quickly if something bad happened (in the form of an error message), or it can decisively determine the cause of a performance issue or why the cluster is behaving in a way users might not like. The Basics Main Elasticsearch logs are written to file. For this file the default level is INFO, thus being sufficient for a rather moderate amount of information and, at the same time, not create a huge log file. Logging settings are specified in the logging.yml configuration file. While this is a convenient way of having the log settings in a single place, having to modify this file on every node every time you want to change the settings is painful because it requires nodes restart and unnecessary downtime.Good news! Elasticsearch allows you to \u00a0.The same applies to \u00a0the second type of logging that it provides: . These provide a very useful insight into how fast or slow queries\/indexing process\/fetches are performing. The slowlog file will show the query itself, on which shards it ran and how much time it took to complete. For the logs, there is a list of \"levels\" which indicate how granular the logs will be. In the order of granularity from low to high, we have: WARN, INFO, DEBUG, TRACE. Setting the log level to WARN will display only WARN logging messages. On the other hand, setting the level to INFO will display both WARN and INFO logging messages, so this is a \"cumulative\" set of log messages. Similarly, for TRACE every log message in Elasticsearch will be printed in the log files. Setting the level to TRACE will create a considerable amount of chatter. Dynamically changing the root logger level This is not necessarily a tricky task :-), but for completeness sake and to warm up before the following tips&tricks let's first (the one from which all other loggers inherit). You can run a query like the following, while the cluster is running of course: PUT \/_cluster\/settings {\"transient\":{\"logger._root\":\"DEBUG\"}} Very simple and quick. Now you should see some more interesting things in the logs, some messages that weren't available with INFO or WARN levels. Dynamically changing the logger level per Java package Many times it is very useful to see logging messages that are related to a certain part or functionality of Elasticsearch. Increasing the logging level globally in all modules in Elasticsearch would result in a potentially very large log file, so Elasticsearch allows \u00a0. . Let's take, for example, the package . It contains classes that deal with. If you have an issue with nodes joining\/leaving the cluster, or with master election, this would be the package to monitor in your logs: PUT \/_cluster\/settings {\"transient\": {\"logger.discovery.zen\":\"TRACE\"}} You notice in the command that \"logger\" is again present and, yes, it should always be. But, how did we choose \"discovery.zen\". You remember I mentioned above that the logging level can be set per Java package. Well, \"discovery.zen\" is just that, without the already present \"org.elasticsearch\". What if you are interested only in the master node fault detection messages? The Java package containing classes for master fault detection is\u00a0. And the Elasticsearch command\u00a0would be: PUT \/_cluster\/settings {\"transient\": {\"logger.discovery.zen.fd\":\"TRACE\"}} You got the picture. : Slowlog settings at index level You remember that I mentioned , without nodes or cluster restart. This is valid for slow logs, as well. Imagine you have several tens of indices in your cluster and you suspect that one of the older indices is performing poorly. You'd want to investigate this index more closely and monitor the query response times. The first approach would be to and grep the resulting slowlog file for your index name. This will work, indeed, but why having to grep for the desired index name? Instead, : PUT \/test_index\/_settings { \"index\": { \"search.slowlog.level\": \"trace\", \"search.slowlog.threshold.query.trace\": \"100ms\" } } The settings above change the slowlog logging level and the threshold for . In this way you can monitor only the queries for that particular index without the overhead of enabling \"trace\" logging for all indices. Logging inside Groovy scripts Another trick that I found myself using several times to debug Groovy scripts in Elasticsearch is to double check that the script is doing what I believe it's doing.For example, you have an index with documents that hold a timestamp and you want to filter your documents considering a certain week of the year. Using a script this goes like this: { \"query\": { \"filtered\": { \"filter\": { \"script\": { \"script\": \"weeks.contains((int)doc['timestamp'].date.toDateTime().getWeekOfWeekyear())\", \"params\": { \"weeks\": [ 18,19,20 ] }, \"lang\": \"groovy\" } } } } } To check if the correct Groovy method for finding out the week of the year is , this logging can be added to the script, to print in the logs the actual value returned by that method: import org.elasticsearch.common.logging.*: ESLogger logger = ESLoggerFactory.getLogger('myscript'): logger.logger.log(org.apache.log4j.Level.INFO, (int)doc['timestamp'].date.toDateTime().getWeekOfWeekyear()): And the final query becomes: { \"query\": { \"filtered\": { \"filter\": { \"script\": { \"script\": \"import org.elasticsearch.common.logging.*: ESLogger logger=ESLoggerFactory.getLogger('myscript'): logger.logger.log(org.apache.log4j.Level.INFO,(int)doc['timestamp'].date.toDateTime().getWeekOfWeekyear()): values.contains((int)doc['timestamp'].date.toDateTime().getWeekOfWeekyear())\", \"params\": { \"values\": [ 18,19,20 ] }, \"lang\": \"groovy\" } } } } } Deprecation Logging in 2.0 Among many other planned goodies in the 2.0 release of Elasticsearch, we also added a to notify users when they use any settings, features, parameters etc which have been deprecated. \n"}<br>{"index": {"_id": 991}}<br>{"title":"The Great Mapping Refactoring","seo_title":"","url":"\/blog\/great-mapping-refactoring","author":{"name":"Clinton Gormley"},"date":"June 29, 2015","category":"Engineering","locales":"","content":" One of the biggest sources of pain for users of Elasticsearch today is the ambiguity that exists in type and field mappings. This ambiguity can result\u00a0in exceptions at index time, exceptions at query time, incorrect results, results that change from request to request, and even index corruption and data loss. In the quest to make Elasticsearch more solid and predictable, we have made a number of changes to make field and type mappings stricter and more reliable. In most cases, we only enforce the new rules when creating new indices in Elasticsearch v2.0, and we have provided a backwards compatibility layer which will keep your old indices functioning as before. However, in certain cases, such as in the presence of conflicting field mappings as explained below, we are unable to do so.\u00a0 If the data in these indices\u00a0is no longer needed, then you can simply delete the\u00a0indices, otherwise you will need to reindex your data with correct mappings. Changing how mappings work is not a decision that we take lightly. Below I explain the problems that exist today and the solutions that we have implemented. Deleting mappings Finally, it is no longer possible to delete a type mapping (along with the documents of that type). Even after removing a mapping, information about the deleted fields continues to exist at the Lucene level, which can cause index corruption if fields of the same name are added later on. You can either leave mappings as they are or reindex your data into a new index. Preparing for 2.0 \n"}<br>{"index": {"_id": 992}}<br>{"title":"Elasticsearch 2.0.0.beta1 coming soon!","seo_title":"","url":"\/blog\/elasticsearch-2.0.0.beta1-coming-soon","author":{"name":"Clinton Gormley"},"date":"June 29, 2015","category":"News","locales":"de-de,fr-fr,ja-jp","content":" We are gearing up to release which takes advantages of all of the improvements available in . This forthcoming release will deliver a few awesome user facing features such as: Pipeline AggregationsThe ability to run aggregations such as derivatives, moving average, and series arithmetic on the results of other aggregations. This functionality was always do-able on the client-side, but pushing the computation into Elasticsearch makes it easier to build more powerful analytic queries, while simplifying client code considerably. It opens up the potential for predictive analytics and anomaly detection. Query\/Filter mergingFilters are no more. All filters clauses have now become query clauses instead. When used in , they have an effect on relevance scoring and, when used in , they simply exclude documents which don\u2019t match, just like filters do today. This restructuring means that query execution can be automatically optimized to run in the most efficient order possible. For instance, slow queries like phrase and geo queries first execute a fast approximate phase, then trim the results with a slower exact phase. In filter context, frequently used clauses will be cached automatically whenever it makes sense to do so. Configurable store compressionThe setting allows you to choose between the LZ4 compression for speed (), or DEFLATE for reduced index size (). This is particularly useful for logging, where old indices can switch to before being optimized. Blog posts about the above topics will follow shortly. \n"}<br>{"index": {"_id": 993}}<br>{"title":"Where in the World is Elastic? - June 29, 2015","seo_title":"Where in the World is Elastic, June 29, 2015","url":"\/blog\/2015-06-29-where-in-the-world-is-elastic","author":{"name":"Livia Froelicher"},"date":"June 29, 2015","category":"","locales":"","content":" Welcome to\u00a0Summer is almost here (it technically is already :),\u00a0so things may calm down a little bit in event and meetup land. W\u00a0still have some things going on this week, so see whether one of these awesome events\u00a0is happening near you!Upcoming EventsJune 30 - July 3:\u00a0\u00a0- will give at talk about\u00a0 from\u00a011 -11:45 AM\u00a0and will also give a \u00a0\u00a0from 2-5:30 PM\u00a0on\u00a0July 1.July 2 - 4:\u00a0\u00a0- has some knowledge to share around Polyglot persistence\u00a0at 4 PM\u00a0on July 2.Upcoming MeetupsJune 30:\u00a0\u00a0(joint event with Meteor South Bay)June 30: June 30:\u00a0June 30:\u00a0June 30:\u00a0July 2:\u00a0July 1: July 1: July 2: July 4: \u00a0That's it for this week.\u00a0Stay tuned for Elastic happenings next week - there's much to come!\u00a0- The Elastic TeamP.S.:\u00a0\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats,\u00a0Elasticsearch, Logstash or Kibana\u00a0\u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 994}}<br>{"title":"Kibana 4.1.1 Released","seo_title":"","url":"\/blog\/kibana-4-1-1-released","author":{"name":"Spencer Alger"},"date":"June 29, 2015","category":"Engineering","locales":"","content":" Today we are releasing a quick update to Kibana 4.1 which fixes a critical bug preventing server error messages from rendering properly as well as a few other small bugs.Grab the new release here:\u00a0bug fixes \n"}<br>{"index": {"_id": 995}}<br>{"title":"The Logstash Lines \u2014 Stories from the community, performance improvements, and more!","seo_title":"","url":"\/blog\/logstash-lines-2015-06-26","author":{"name":"Shaunak Kashyap"},"date":"June 26, 2015","category":"","locales":"","content":" Welcome back to ! In these weekly\u00a0posts, we'll share the latest happenings in the world of Logstash and its ecosystem. This week, we have a couple of interesting blog posts\u00a0to share from the Logstash\u00a0community:Logstash Core and Plugins That's this week in . Come back next week for more Logstash news! \n"}<br>{"index": {"_id": 996}}<br>{"title":"Watcher 1.0 Goes GA","seo_title":"","url":"\/blog\/watcher-1-0-released","author":{"name":"Uri Boness"},"date":"June 25, 2015","category":"News","locales":"","content":" We are thrilled to announce the first GA release of Watcher 1.0. Watcher was built to play a key role in the Elastic product stack and bring alerting and notification functionality to Elasticsearch. Elasticsearch itself is an amazing system that enables fine grained exploration of data... massive amounts of data. And now with Watcher, much of this data exploration can be automated. Watcher enables you to register to watch your data and act on events of interest. A Watch consists of four main parts - , , and . The following pseudocode describes the roles of these different parts in the watch execution: Trigger fires an event e watch.execute(e) payload = input.load(e) if condition.eval(payload) for each action in actions action.execute(e, payload) Lets look at at how this simple execution model translates to a real-world scenario. In this example, we assume you use Elasticsearch to index and store events. These events can be log entries from various systems that are fed by \u00a0or perhaps network monitoring events fed by . You don't index these events just for the sake of storing them: in most cases, the main reason for indexing them is to gain insight into what exactly goes on in the various systems you are monitoring. Part of this overview is to pick up on misbehaving systems, in which case, you want to do it as close to real time as possible. So lets look at a simple example for a watch that looks for error events and if\/when found, sends a notification to the appropriate stakeholders. Assuming you have Elasticsearch already installed, the first thing you need to do is install Watcher. Watcher is a standard plugin to Elasticsearch and as such, you install it in the same way you install any other plugin: bin\/plugin -i elasticsearch\/license\/latest For Watcher to work, you will also need to install the License plugin, but don't worry, you don't need a license to test watcher and play around with it, a 30 days trial license is automatically installed and opens up Watcher's full functionality. If you would like to extend the trial license, just contact us and we will be happy to extend it. bin\/plugin -i elasticsearch\/watcher\/latest Now that you have Watcher installed, start Elasticsearch and add your first watch: <span class=\"pln\">curl -XPUT 'http:\/\/localhost:9200\/_watcher\/watch\/error_status' {<\/span> \"trigger\"<span class=\"pln\">: {<\/span> \"schedule\"<span class=\"pln\"> : { <\/span>\"interval\"<span class=\"pln\"> : <\/span>\"5m\"<span class=\"pln\"> } },<\/span> \"input\"<span class=\"pln\"> : {<\/span> \"search\"<span class=\"pln\"> : {<\/span> \"request\"<span class=\"pln\"> : {<\/span> \"indices\"<span class=\"pln\"> : [<\/span> \"<events-{now\/d}>\"<span class=\"pln\">,<\/span> \"<events-{now\/d-1d}>\"<span class=\"pln\"> ],<\/span> \"body\"<span class=\"pln\"> : {<\/span> \"query\"<span class=\"pln\"> : {<\/span> \"filtered\"<span class=\"pln\"> : {<\/span> \"query\"<span class=\"pln\"> : { <\/span>\"match\"<span class=\"pln\"> : {<\/span> \"status\"<span class=\"pln\"> :<\/span> \"error\"<span class=\"pln\"> }},<\/span> \"filter\"<span class=\"pln\"> : {<\/span> \"range\"<span class=\"pln\"> : {<\/span> \"_timestamp\"<span class=\"pln\"> : {<\/span> \"from\"<span class=\"pln\"> :<\/span> \"now-5m\" <span class=\"pln\">}}} } } } } } },<\/span> \"condition\"<span class=\"pln\"> : {<\/span> \"compare\" <span class=\"pln\">: { <\/span>\"ctx.payload.hits.total\"<span class=\"pln\"> : { <\/span>\"gt\"<span class=\"pln\"> : 0 }} },<\/span> \"actions\"<span class=\"pln\"> : {<\/span> \"email_admin\"<span class=\"pln\"> : {<\/span> \"email\"<span class=\"pln\"> : {<\/span> \"to\"<span class=\"pln\"> : <\/span>\"admin@domain\"<span class=\"pln\">,<\/span> \"subject\"<span class=\"pln\"> : <\/span>\"Error Events\"<span class=\"pln\">,<\/span> \"priority\"<span class=\"pln\"> : <\/span>\"high\"<span class=\"pln\">,<\/span> \"body\"<span class=\"pln\"> :<\/span> \"Found {{ctx.payload.hits.total}} erroneous events\"<span class=\"pln\"> } } } }<\/span> Once registered, the above watch will be triggered and be executed every 5 minutes. When executed the input searches for events with an error status (note the index name pattern that enables the input to only search the last 2 daily event indices). The condition checks if any errors were found, and if so the configured actions will be executed. In this watch we defined a single action that sends a high priority email to the administrator, indicating the number of errors found. Note that the body (as well as many other fields) supports the template language, enabling you to freely customize its content. As you can see, it's pretty straight forward. Now, lets take a closer look at the different parts that make a watch. TriggerThe trigger determines when a watch will be executed. A may have different implementations with different strategies around the decision whether or not a watch should be executed. Watcher 1.0 ships with the trigger - a time\/calendar based trigger that can be configured to execute the watch periodically (e.g. \"every 5 seconds\", \"every 10 minutes\", \"every 2 days\", etc...) or based on the calendar using cron expressions (e.g. \"on Monday at noon, every second week of the month\"). InputThe input loads data for the watch to work with. There are different input types associated with different sources of data, most notably: and . The search input loads data indexed in Elasticsearch leveraging its full search capabilities, including the full Query DSL and Aggregations. The returned search response (which includes the hits and the computed aggregations) will be loaded as the initial watch execution data. The http input enables loading the initial data from remote web services. This can be a 3rd party system exposing RESTful endpoints or it can be an external Elasticsearch cluster with which you communicate via its REST API. The http input effectively enables you to set up a dedicated \"watching\" cluster that will watch all your other Elasticsearch clusters. An additional value in in this generic http input is that enables accessing all Elasticsearch APIs (beyond search) which means you can actually watch the health of your elasticsearch cluster itself. The data loaded by the watch input loads will be used by the watch condition and actions during their execution. This data is commonly referred to as the watch execution ConditionThe condition determines whether the actions should be executed. This predicate will typically evaluate the payload that was loaded by the input (as described above). For example, when using a search input, the condition can choose to execute the actions if the the number of returned search hits is greater than zero. Watcher supports different types of conditions, most notably: and . The condition simply compares a value in the payload to another value. For example, if the input is used to load Elasticsearch's cluster health, the compare condition may look at the health status and decide to execute the actions if it is \"red\". The condition enables you to utilize the full scripting capabilities in Elasticsearch to define more complex logic around these decisions. ActionsFinally, if the condition is met the actions execute. Again, like all other watch constructs, different types of actions are available. Watcher 1.0 ships with three main action types - , and . The action enables you to notify about the events by sending an email to one or more recipients. We also made sure the email infrastructure in Watcher works well with all major email services out there. The action enables the watch to call a 3rd party system via a webhook. For example, one can call a paging service to notify whoever needs to be notified or automatically open a high priority ticket in your organization's ticketing system. The action simply takes the watch execution payload and indexes it back into Elasticsearch. It can be indexed as is, or can be transformed to another document that will be indexed instead. Watch HistoryWatcher keeps a history of all watch executions in dedicated watch history time based indices. This enables continuous insight on Watcher's runtime and serves as a great tool to explore the behaviour of the registered watches. You can search these indices just like any other index in elasticsearch, run analytics on them and even build Kibana dashboards to help visually monitor Watcher. We have built such a dashboard ourselves that you can use by importing it into Kibana (requires Kibana 4.1 and above). You can also just use this dashboard as a starting point and further customise it as you see fit. What's next?With Watcher 1.0 we focused on building a solid future proof infrastructure that will serve as the foundations for many features and enhancements in the future. We tried to nail down the most basic constructs that make a Watch and as described above provide set of basic implementations to all the Watch constructs. This set of inputs, conditions, actions can go a long way to help you build both the simplest and the most advanced watching tasks. But we certainly won't stop here. In future releases expect to see additional inputs, actions, and perhaps even predefined watches that will be optimized for the most common watching tasks and with that simplifying the way you interact with Watcher. To learn more about watcher, we encourage you to \u00a0it and read the online . We also encourage you to participate in the discussions in our , ask questions, report bugs or simply share your experience with Watcher - we LOVE feedback and we act on it. Enjoy! \n"}<br>{"index": {"_id": 997}}<br>{"title":"Elasticsearch for Apache Hadoop 2.1 GA: Spark, Storm and More","seo_title":"Elasticsearch for Apache Hadoop 2.1 GA: Spark, Storm and More","url":"\/blog\/elasticsearch-for-apache-hadoop-2-1-spark-storm-and-more","author":{"name":"Costin Leau"},"date":"June 24, 2015","category":"News","locales":"","content":" Elasticsearch for Apache Hadoop, affectionately known as ES-Hadoop, enables Hadoop users and data-hungry businesses to enhance their work-flows with a full-blown search and analytics engine, in real-time. We are thrilled to announce the GA\u00a0release of . This\u00a0GA release has been the result of 4 successful Betas: , , , , plus , over the last 10 months. We would like to thank the community and all our users for their valuable feedback during the Beta process. Version 2.1 embraces the emerging, real-time components in the Hadoop ecosystem, (in particular and ), beefs up security support by adding SSL\/TLS transport encryption with both HTTP and PKI authentication, and introduces a YARN module. All while preserving , extending the number of supported Hadoop , and gaining new certifications. Plus, we're still bringing you all this functionality with only a single JAR file to download, no dependencies required. In fact, upgrading to 2.1 is simply a matter of updating the ES-Hadoop JAR. However, to help those with longer release cycles, we have also released , the last maintenance release for the 2.0.x branch. It contains important bug-fixes without introducing any new features. Native Integration with Spark and Spark SQL Since its announcement, Apache Spark has taken the 'Big Data' world by storm. While ES-Hadoop 2.0 provides support for Spark through its Map\/Reduce functionality, 2.1 goes beyond that, providing Java and Scala APIs tightly integrated with Spark Core and Spark SQL. This means one can easily index and analyze data through Elasticsearch in real-time directly from Spark. Simply put,\u00a0through ES-Hadoop, Spark treats Elasticsearch indexes as s (Resilient Distributed Dataset) and s. Furthermore, the connector can take Spark and index it or run SQL queries on top Elasticsearch indexes. In good ol' ES-Hadoop tradition, the developer never has to leave her environment: the same Spark API, conventions and data types work transparently on top of Elasticsearch. import org.elasticsearch.spark._ val sc = new SparkContext(conf) \/\/ collection of data val numbers = Map(\"one\" -> 1, \"two\" -> 2, \"three\" -> 3) val airports = Map(\"arrival\" -> \"Otopeni\", \"SFO\" -> \"San Fran\") sc.makeRDD(Seq(numbers, airports)).saveToEs(\"spark\/docs\") \/\/ case classes case class Trip(departure: String, arrival: String, days: long) val upcomingTrip = Trip(\"OTP\", \"SFO\", 10) val lastWeekTrip = Trip(\"MUC\", \"OTP\", 3) val rdd = sc.makeRDD(Seq(upcomingTrip, lastWeekTrip)) sc.saveToEs(rdd, \"spark\/trips\") Also available in Spark SQL as (or <code>SchemaRDD for those on Spark 1.1-1.2): \/\/ as a DataFrame val df = sqlContext.read().format(\"org.elasticsearch.spark.sql\").load(\"spark\/trips\") df.printSchema() \/\/ root \/\/|-- departure: string (nullable = true) \/\/|-- arrival: string (nullable = true) \/\/|-- days: long (nullable = true) val filter = df.filter(df(\"arrival\").equalTo(\"OTP\").and(df(\"days\").gt(3)) And also in pure SQL: CREATE TEMPORARY TABLE trips USING org.elasticsearch.spark.sql OPTIONS (path \"spark\/trips\") SELECT departure FROM trips WHERE arrival = \"OTP\" and days > 3 The integration is not only elegant and out of the developer's way, but also quite efficient: ES-Hadoop connector pushed down all of Spark SQL queries translating them into , thus effectively executing the queries directly on Elasticsearch and leveraging its lightning fast search capabilities: both of the queries above are translated by the connector at runtime into: { \"query\" : { \"filtered\" : { \"query\" : { \"match_all\" : {} }, \"filter\" : { \"and\" : [{ \"query\" : { \"match\" : { \"arrival\" : \"OTP\" } } }, { \"days\" : { \"gt\" : 3 } } ] } } } } Note that as with all the other integrations, through ES-Hadoop all the reads and writes in the example above are executed in parallel across the index shards, for what we call partition-to-partition architecture. 2.1 supports Spark 1.0 through 1.4, in other words all stable releases currently known, so whatever Spark version is targeted, ES-Hadoop can be used right away. Storm Integration In addition to Apache Spark, ES-Hadoop 2.1 also provides native integration with Apache Storm, exposing Elasticsearch as stream search results or as a `Bolt' indexing Tuples flowing through your topology and making them accessible for analysis immediately. TopologyBuilder builder = new TopologyBuilder(): builder.setBolt(\"esBolt\", new EsBolt(\"twitter\/tweets\")): Executing queries in Elasticsearch for Storm is yet another one-liner: TopologyBuilder builder = new TopologyBuilder(): builder.setSpout(\"es-spout\", new EsSpout(\"twitter\/tweets\", \"?q=nfl*), 5): builder.setBolt(\"bolt\", new PrinterBolt()).shuffleGrouping(\"es-spout\"): Under the covers, ES-Hadoop uses its parallelized infrastructure to map the Spout and Bolt instances across the index shards. Low-latency\/high-performance patterns like micro-batching and tick-tuples are supported to provide excellent throughput out of the box and closely integrate the real-time capabilities of Storm and Elasticsearch. Security enhancements 2.1 introduces official support for cryptographic connections between Elasticsearch and Hadoop clusters through SSL\/TLS, enabling data-sensitive environments to transparently encrypt data at transport level, thus prevent snooping and preserving data confidentiality. Furthermore, in addition to HTTP authentication, 2.1 introduces Public Key Infrastructure (PKI) for encrypting the authentication process as well. Elasticsearch on YARN Another major addition in 2.1 is the introduction of the (aka ES-Yarn) project for running an Elasticsearch cluster within a YARN environment. Similar to the plugin, ES-Yarn is distributed as part of the ES-Hadoop\u00a0project, but is independent and has no dependencies outside YARN itself. With ES-Yarn, one can now provision, start and stop Elasticsearch directly on a YARN cluster. In YARN lingo, es-yarn bootstraps a client that deploys a dedicated in YARN which, on its behalf, creates one container for each Elasticsearch node required. For the user, es-yarn is a straight-forward CLI (Command-Line Interface) for deploying and managing the life cycle of the Elasticsearch cluster within YARN. Simply download and run: $ hadoop jar elasticsearch-yarn-2.1.jar No command specified Usage: -download-es : Downloads Elasticsearch.zip -install : Installs\/Provisions Elasticsearch-YARN into HDFS -install-es : Installs\/Provisions Elasticsearch into HDFS -start : Starts provisioned Elasticsearch in YARN -status : Reports status of Elasticsearch in YARN -stop : Stops Elasticsearch in YARN -help : Prints this help Configuration options can be specified _after_ each command: see the documentation for more information. Enhanced Functionality 2.1 introduces a number of enhancements to existing features such as: Certifications While certifications are not as cool as talking about new features, we know customers love peace of mind as much as we do. We increased the number of supported platforms in 2.1, reaching out to our partners to make sure ES-Hadoop works properly out of the box. We are happy to report that 2.1 is certified with CDH 5.x, HDP 2.x, and MapR 4.x, as well as being Databricks Spark certified. We look forward to your feedback on Elasticsearch Hadoop 2.1 GA! You can find the binaries available on the , the sources on and the new features are\u00a0explained in the . As always, you can file bugs or feature requests on our and ask questions on the or . \n"}<br>{"index": {"_id": 998}}<br>{"title":"This Week in Elastic - June 24, 2015","seo_title":"This Week in Elastic: June 24, 2015","url":"\/blog\/this-week-in-elastic-2015-06-24","author":{"name":"Leslie Hawthorn"},"date":"June 24, 2015","category":"","locales":"","content":" Welcome to ! In this weekly round up post, we bring you news on all aspects of the ELK Stack, including updates on Elasticsearch, Logstash and Kibana development, tips and tricks and upcoming events. for Apache 2.1 GA is here. Now w\/native support for Spark, Storm + more \u2014 elastic (@elastic) Elastic News Useful blog posts, how tos, tutorials\u00a0and articles\u00a0from the wide world of all the ELK stack ecosystem. NEST and .NET 1.6 just released! \u2014 Greg Marzouka (@gregmarzouka) Happy Wednesday. Puppet module 0.9.7 released with bugfixes and hot new features. Grab it at \u2014 Richard pijnenburg (@Richardp82) Slides and Videos Where to find UsCome say hello to at Amsterdam. We have cool swag and hot information for you! \u2014 Shaunak Kashyap (@shaunak) We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking about the ELK stack\u00a0or hosting a meetup, Australia ChileJoin the Lenguajes din\u00e1micos meetup group in Santiago tonight, June 24, to talk Elasticsearch and Ruby. to save your seat. France GermanyJoin our team in the exhibits hall at on July 9. We'll be there to answer all your questions and give you some lovely Elastic goodies. India Israel will visit the Tel Aviv Elastic User Group on July 8 to talk Resiliency and Elasticsearch. to save your seat. KoreaThe next Korea Elasticsearch Study Session will be held on July 1. to attend. The Netherlands returns to the Pakhuis de Zwijger June 24-26. You can visit us at our booth or hear from on her latest DevOps and Culture topic, . Rumor has it that the amazing BBQ will be reprised this year, so miss this one! New ZealandThe next meeting of the Elasticsearch ELK NZ meetup is coming to Wellington on July 2. We're still lining up the agenda, but for now to save your seat. Poland and will attend Devoxx Poland 2015 taking place June 22-25 in Krakow. Don't miss their talk on June 25 at 1:30 PM: . And last but not least, join in Poznan for . The conference runs July 2-4. South AfricaWe are a proud swag sponsor of the . If you happen to be in Johannesburg on July 11, pop in for knowledge and some cool Elastic goodies. Spain UkraineThe L'viv DevOps Meetup will get together on June 27 for CoreOS Fest Conference review, featuring a CoreOS with Kubernetes demo: ElasticSearch Cluster on local machine and AWS. to save your seat. United Kingdom United States - East United States - West Where to Find You \u00a0If you're a regular reader, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to\u00a0 ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 999}}<br>{"title":"Shield 1.3 and 1.2.2 Released","seo_title":"","url":"\/blog\/shield-1-3-and-1-2-2-released","author":{"name":"Jay Modi"},"date":"June 24, 2015","category":"Engineering","locales":"","content":" Today we\u2019re excited to announce Shield 1.3 and Shield 1.2.2! Read below for all of the details and then download it . Shield 1.2.2 is a bugfix release, please refer to the for details on what has been fixed. Shield 1.3 is the latest feature release and is our first release to introduce a new realm! Shield 1.3 also includes a new output for auditing and several other enhancements. Here are the highlights: pki realmThe is the first new realm to be introduced since Shield was released and is a very important realm. We received a lot of feedback from users who wanted to directly authenticate their application servers without storing user credentials. In many of these cases, the PKI realm can be used in place of storing and passing credentials. The PKI realm uses X.509 certificates for authentication and maps the distinguished name (DN) to a user via the . index output for auditingAn index based output for has been added. This output allows indexing of audit events into the current cluster or a . This means that the audit logs can now be searched and analyzed using elasticsearch out of the box. For more details on configuring the index based auditing, please refer to the . Here's an example Kibana dashboard based on the audit data:breaking changesShield 1.3 does contain a few breaking changes, though in most cases, upgrading to Shield 1.3 will not require any additional changes. The first breaking change is that the and hashing algorithms have been removed as options for setting. If you are using either of these, please specify one of the other or remove this setting altogether to fall back on the default, . Additionally, the file now only supports password hashes. The tool has always generated hashes, so as long as this tool is used, there will be no issues when upgrading to Shield 1.3. other changesRefer to the Shield 1.3 for the full list of changes including bug fixes and other enhancements. upgradingPlease refer to the of the Shield documentation. feedbackWe would love to hear any feedback that you may have via the category in our forums. \n"}<br>{"index": {"_id": 1000}}<br>{"title":"This Week in Elasticsearch and Apache Lucene: Faster Analytics through Elasticsearch","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-06-23","author":{"name":"Leslie Hawthorn"},"date":"June 23, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsFaster Analytics through Elasticsearch (written by me) \u2014 Harold Neal (@metacreek) Elasticsearch Core Apache LuceneWatch This Space , where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 1001}}<br>{"title":"Kafka and Logstash 1.5 Integration","seo_title":"","url":"\/blog\/logstash-kafka-intro","author":{"name":"Tal Levy"},"date":"June 23, 2015","category":"Engineering","locales":"","content":" As you may of heard, we added support with Logstash 1.5! What is included? Both input and output plugins! This blog is a first in a series of posts introducing various aspects of the integration between Logstash and Kafka. Today, we\u2019ll go over some of the basics. For documentation on all the options provided you can look at the plugin documentation pages: The Apache Kafka defines Kafka as: \"Kafka is a distributed, partitioned, replicated commit log service.\u00a0It provides the functionality of a messaging system, but with a unique design.\" Why is this useful for Logstash? Kafka is quickly becoming the de-facto data-bus for many organizations and Logstash can help enhance and process the\u00a0messages flowing through Kafka. Another reason may be to leverage Kafka's scalable persistence to act as a message broker for buffering messages between Logstash agents. Here, we will show you how easy it is to set up Logstash to read and write from Kafka. You may follow for launching a local Kafka instance. Once launched, you can go ahead and create a test topic we will use in the examples. # create \"logstash_logs\" topic $ bin\/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic logstash_logs Kafka comes with a simple console producer to help quickly test writing to Kafka. In some ways, it is even easier to use Logstash as a replacement for that tool! We can use the input plugin to allow us to write messages to a specific Kafka topic. $ bin\/logstash -e \"input { stdin {} } output { kafka { topic_id => 'logstash_logs' } }\" Logstash Kafka output plugin uses the official Kafka producer. All of its options are exposed to the plugin. One important option that is important is the which defines acknowledgment semantics around how many Kafka Brokers are required to acknowledge writing each message. By default, this is set to -- this means that the producer never waits for an acknowledgement. This option provides the lowest latency but the weakest durability guarantees. Setting this to , the producer will wait for an acknowledgement from the leader replica. is the safest option, where it waits for an acknowledgement from all replicas that the data has been written. More details surrounding other options can be found in the plugin\u2019s page and also . To verify that our messages are being sent to Kafka, we can now turn on our reading pipe to pull new messages from Kafka and index them into using Logstash's output plugin. $ bin\/logtash -e \"input { kafka { topic_id => 'logstash_logs' } } output { elasticsearch { protocol => http } }\" The Kafka input plugin uses the high-level consumer under the hoods. Each instance of the plugin assigns itself to a specific consumer group (\u201clogstash\u201d by default). This way we leverage the partitioning properties of consuming data from Kafka as is done in the high-level consumer. By leveraging these consumer groups we can simply launch multiple logstash instances to scale the read throughput across the partitions. Kafka implements a consumer rebalancing algorithm to efficiently distribute partitions across newly introduced consumers. Consumer offsets are committed to Kafka and not managed by the plugin. You may want to replay messages -- if that is the case, offsets can be disregarded and you may read from the beginning of a topic by using the configuration option. Storage of consumer offsets is defaulted to Zookeeper. More details surrounding other options can be found in the plugin\u2019s documentation page. Logstash processing pipelines can grow very complex and cpu-intensive as\u00a0more plugins like grok are introduced. By default, Logstash implements a back-pressure mechanism wherein inputs are blocked until the later processing units are free to accept new events. Under this scheme, input events are buffering at the source. This may be a problem for inputs which do not natively support buffering of sent messages, and may create additional resource constraints on inputs like file (e.g. disk usage). Kafka lends itself very nicely to this pipelining strategy because consumers are disconnected from producers, and Kafka is designed to hold a healthy buffer of events to be processed. As data volumes grow, you can add additional Kafka brokers to handle the growing buffer sizes. The diagram above demonstrates an example topology where Logstash agents are collecting local log file events and pushing them to Kafka, and another Logstash agent, in addition to other services can parallelly consume those messages for further processing. In this scenario, Kafka is acting as a message queue for buffering events until upstream processors are available to consume more events. Additionally, as you are buffering your events in Kafka, you may wish to leverage other data storage\/processing tools for secondary processing of your events. For example, you may want to archive your logs to S3 or HDFS as a permanent data store. The current version of the output plugin uses the old 0.8 producer. We have plans to release a newer version of the output plugin utilizing the new 0.8.2 producer. You can learn more about the changes . The new producer contract brings in lots of changes to the API, so the next version of the output plugin will not be backwards compatible with the current version. We plan to release this new producer with Logstash 1.6. You can continue to use the old version by not upgrading at the time of release. In our next blog post in this series, we\u2019ll take a look at using your own serialization with Kafka and we\u2019ll give you an example of how to use Apache Avro as such a serialization. \n"}<br>{"index": {"_id": 1002}}<br>{"title":"The Logstash Lines \u2014 Deep dive into grok, install plugins offline, and more!","seo_title":"","url":"\/blog\/logstash-lines-2015-06-22","author":{"name":"Shaunak Kashyap"},"date":"June 22, 2015","category":"","locales":"","content":" Welcome back to ! In these weekly\u00a0posts, we'll share the latest happenings in the world of Logstash and its ecosystem. This week, gain a deeper understanding of how to use the ever-popular from Greg Medford. Here's his presentation on the topic from\u00a0the just-concluded Monitorama conference in Portland: from Logstash Core and Plugins That's this week in . Come back next week for more Logstash news! \n"}<br>{"index": {"_id": 1003}}<br>{"title":"Where in the World is Elastic: RedHat Summit Boston & DevOps Days Amsterdam","seo_title":"","url":"\/blog\/2015-06-22-where-in-the-world-is-elastic","author":{"name":"Livia Froelicher"},"date":"June 22, 2015","category":"","locales":"","content":" Welcome to\u00a0This week we're visiting\u00a04 continents.\u00a0Read on for the full list of events and meetups below. We hope you'll join us if one is on near you!Upcoming EventsJune 21-25: \u00a0\u00a0- Co-located with Red Hat Summit in Boston, this developer focused\u00a0conference will feature on The Democratization of DevOps. You can at on June 23 at 2:45 PM.June 22-25: , Washington DC: Join our team in the exhibits hall to get your questions answered.\u00a0June 23-26:\u00a0, Boston - Come say hi at our booth to talk all things Elastic and grab a cool piece of swag!June 22-26: - \u00a0will\u00a0give\u00a0a talk on on Tuesday, June 23, 11:50\u00a0AM\u00a0-12:50 PM. and will present on \u00a0on Wednesday, June 24, at 3:10 PM..\u00a0David and Joao will also give a on Thursday, June 25\u00a0from 1:00 p.m. - 5:00 p.m.\u00a0June 24-26:\u00a0 - Don't miss talk on\u00a0, Thursday, June 25 at 12:00p.m. We also have a booth so make sure to stop by!Upcoming MeetupsJune 23: June 24: June 24: June 24: June 25: June 24: \u00a0(Santiago)June 23: June 23: (Moscow)June 24: June 24: June 25: June 25: June 27: June 28: That's it for this week.\u00a0Stay tuned for Elastic happenings next week - there's much to come!\u00a0- The Elastic TeamP.S.:\u00a0\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Beats,\u00a0Elasticsearch, Logstash or Kibana\u00a0\u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 1004}}<br>{"title":"Watcher 1.0 RC1 - Try it Now!","seo_title":"","url":"\/blog\/watcher-1-0-RC1-released","author":{"name":"Uri Boness"},"date":"June 19, 2015","category":"News","locales":"","content":" \n"}<br>{"index": {"_id": 1005}}<br>{"title":"Shield Q&A: How DHL Uses Shield to Secure Mission Critical Logistics Data in Elasticsearch","seo_title":"","url":"\/blog\/shield-q-and-a-how-dhl-uses-shield-to-secure-mission-critical-logistics-data-in-elasticsearch","author":{"name":"Livia Froelicher"},"date":"June 18, 2015","category":"User Stories","locales":"","content":" At Elastic, one of our greatest pleasures is learning and sharing how our customers are utilizing our software to achieve various organizational and personal goals.\u00a0 Earlier this year we released\u00a0\u00a0to make\u00a0it super\u00a0easy for anyone to add security to their Elasticsearch deployment (try it for yourself with\u00a0).\u00a0 Today, we are excited to share how DHL Supply Chain, a global leader in the logistics industry, has experienced success with Shield. DHL Supply Chain offers a variety of supply chain services in over 220 countries, including assembly and packaging, warehousing, and transportation. In order to provide customers visibility across their supply chain, DHL integrates its Warehouse Management and Transportation Management System with its customers\u2019 ERP systems. The messages that pass through DHL LINK, DHL's integration layer, are indexed in Elasticsearch, allowing\u00a0DHL\u2019s customers\u00a0to search through\u00a0multiple terabytes of data to find the latest status of a specific EDI order message using a PO number or other reference to see that it has been sent successfully to the customer (e.g. the status of the EDI message is \u201csent\u201d). \n"}<br>{"index": {"_id": 1006}}<br>{"title":"Elasticsearch for Apache Hadoop 2.1 RC1 is out","seo_title":"","url":"\/blog\/es-hadoop-2-1-rc1-released","author":{"name":"Costin Leau"},"date":"June 17, 2015","category":"News","locales":"","content":" The first release candidate of Elasticsearch for Apache Hadoop (ES-Hadoop) 2.1 is . Exactly 50 days after Beta4, RC1 completes the features scheduled for 2.1, improves the stability of the code and polishes the documentation. The goodies are described below: however we understand if you want to grab the binaries right away from the or . Spark SQL Push Down2.1 RC1 not only supports the just released Spark 1.4 but also introduces support for Spark SQL. That is, through ES-Hadoop, Spark SQL is translated to Elasticsearch so the operations are actually to the storage and thus efficiently executed so that only the needed results are returned back to Spark.\u00a0 For example: SELECT reason FROM trips WHERE id>=1 AND airport=\"OTP\"is translated into: { \"query\" : { \"filtered\" : { \"query\" : { \"match_all\" : {} }, \"filter\" : { \"and\" : [{ \"query\" : { \"match\" : { \"airport\" : \"OTP\" } } }, { \"range\" : { \"gte\" : 1 } } ] } } } } This significantly increases performance and also again minimizes the amount of I\/O, memory and CPU required when working against Elasticsearch. Note that the translation applies even if the user has a query defined (on the for the and can be configured to work on (default) and terms so, whatever the Elasticsearch index configuration, one can get started right away. Moverover in terms of usage, ES-Hadoop not only implements all of Spark SQL API but also the so all of Spark SQL (including table creation, insertion and ) are fully supported: CREATE TABLE esIndex USING org.elasticsearch.spark.sql OPTIONS (path \"spark\/docs\") INSERT OVERWRITE TABLE esIndex SELECT * FROM existingSparkTable \/\/ Spark 1.4 style val df = sqlContext.read.load(\"examples\/src\/main\/resources\/users.parquet\") df.select(\"name\", \"favorite_color\").write.mode(SaveMode.ErrorIfExists) .format(\"org.elasticsearch.spark.sql\").save(\"users\/colors\") Note that the excellent Spark compatibility (1.0-1.4) is . Security improvementsOn the security front, the SSL\/TLS handshake has been improved so that protocol errors are better diagnosed and properly exposed to the user. In addition ES-Hadoop officially supports (Public Key Infrastructure) authentication and, to ease setup, features a dedicated documentation on Security. Also the HDFS snapshots\/restore has been improved to better work in Kerberos environments and the acquisition reworked to minimize the number of client connections within the cluster. Last but not least, the various libraries have been upgraded while maintaining backwards compatibility - this includes upgrading to Apache Storm 0.9.5, Apache Hive 1.2, Apache Pig (0.15 - if you are using it in a Hadoop 1.x environment) and of course, Elasticsearch 1.6 (do upgrade to it). FeedbackLet us know what you think about RC1! We love to hear from you on , or the . ( works too). Cheers, \n"}<br>{"index": {"_id": 1007}}<br>{"title":"Elasticsearch: Powering Real-Time Mobile and Web Analytics for LeadBoxer and Opentracker","seo_title":"","url":"\/blog\/elasticsearch-opentracker-leadboxer","author":{"name":"Leslie Hawthorn"},"date":"June 17, 2015","category":"User Stories","locales":"","content":" is an analytics company focusing on website and mobile app user behavior. Today, our 1000s of clients from webmasters to corporate, financial and governmental institutions have become addicted to seeing exactly who, and how, people are using their online services in real-time, letting them track users, improve client experience, and increase conversion rates. Read on to learn how Opentracker.net and our experiences with Elasticsearch led us to create , a sophisticated\u00a0web and mobile based lead capture and qualification system.In our early stages, like a lot of other companies founded during this period,\u00a0Opentracker\u2019s technology was built around MySQL. While providing a great starting point, MySQL suffered from inherent bottlenecks relative to scaling and structuring big data. As NoSQL solutions began appearing, we explored them and eventually settled on Cassandra, which resolved many of our data maintenance, redundancy, storage, and scaling issues. The one thing it did not provide us with, however, was real-time search. Real-time searches are important because every client has specific insights they want to extract from their data, and they need the flexibility to find exactly what they need to improve their business. Some clients are interested in users from certain locations, so that they can focus their on-boarding efforts by sales region, while others are interested in finding users on conversion pages that pre-qualify the visitors with interest in a specific product or service. Others are looking for users that match a specific lead qualification criteria in order to increase the chance of making sales, allowing sales agents to target potentials more effectively, and make warmer calls. In order to provide this functionality, we experimented with Apache Solr and Elasticsearch solely for the purpose of running real-time searches on both web and mobile app user data. Elasticsearch worked smoothly and presented an easy learning curve, while its schemaless structure allowed our clients to search through high volumes of unstructured data with flexibility, stability, and good response times. After implementing Elasticsearch, we started getting the same request from our B2B users: \"Show me the companies who are visiting, and help me get in touch with them.\" An opportunity presented itself: to develop a new service that could provide intelligence in the process of generating and capturing leads. We branched the technology that targeted the identification of companies, and . LeadBoxer\u2019s value proposition? Identify sales leads from online activity, then qualify the leads based on metrics the client finds important. (You can check out the service at by setting up a trial account.) After implementing Elasticsearch in Opentracker, we realised we could use it to power LeadBoxer\u2019s basic functionality by manipulating the scoring and ordering algorithms. Our guess was that we could utilize the and to help sort and rank leads by importance. At the time, documentation on the subject was limited\u00a0and distributed through many different community channels, so we started to develop our own API to query Elasticsearch in order to create a lead scoring system that could be customized and generated by our customers. We were taking a risk. We thought that\u00a0search engines\u00a0were designed for searching through docs, not qualifying sales leads! The big question was would it work? The short answer, is . We now use Elasticsearch to deliver useful, qualified, and beautifully-designed lead results to sales and marketing teams. Our customers can adjust sliding weights to influence a lead score preference, and the preferences are converted into percentile values. The values are stored and converted to a formula in the API call, which in turn translates the formula to an Elasticsearch query. The Elasticsearch query returns the leads, ranked and prioritised based on the formula. Changing the weighted preferences gives different leads, allowing sales teams to focus on leads that they want to target. So, how do the lead score settings in the LeadBoxer UI translate to values? By using the AngularJS framework, we built a settings page where our users can set their scoring preferences with sliders. The values that are set by these sliders can range from 0 to 20. We decided that our lead score value should be a number between 1-100, 100 being the perfect lead. Because we keep on adding sliders and ways to influence the lead score, we need to make these absolute numbers percentiles. We achieve this by use of a formula: We use boosting\/scoring in different ways to calculate match, criteria and range.\u00a0We defined three different property types that could be used to influence the lead score: These values are then translated into a formula by storing the UI-generated percentiles as URL parameters, e.g. which designates 10 leadscore percentile points to any lead identified via company profile as belonging to the Insurance sector. These API calls are then translated to an Elasticsearch query by processing them via a Java execution code path. For the Elasticsearch client, we are using a transport client. (And you can read more about the here.) We store and index our data by collecting and sending user, session, and event data to our cluster of \u2018log\u2019 servers. In turn, the data is processed and enriched before it is stored to both the index of the Elasticsearch cluster and a Cassandra node. We learned a lot when using all this technology. The information is documented, but we couldn\u2019t find any case studies or examples, leading us at the time to conclude that this powerful technology is underutilised. 20+ million downloads later, though, means lots of people have figured out how useful Elasticsearch can be for their businesses! The best part about Elasticsearch is that it's a search engine that lets you manipulate the ranking\/returns, meaning that you can be your own search engine master, and determine the outcomes with which the results are ranked and therefore presented to the user. Bottom line: using Elasticsearch in this way, you can let the user customise the results, meaning the results from any system-wide search, i.e. the order of results, will be based on custom criteria. For those of you who are fans of the nitty gritty details of our installation, our cluster consists of 4 master\/data nodes with a monitoring node. The cluster is using version 0.90.7 and JVM 1.6 update 25. We're planning an upgrade to Elasticsearch 1.6, so stay tuned for more updates! So, what\u2019s next? We anticipate that with our current setup and development trajectory, utilising Elasticsearch, we are positioned to evolve the way B2B, or even B2C, sales processes are shaped. Similar to an IoT future where only relevant ads and personal offers are displayed, we can present our clients with ready-to-be-picked fruit for sales deals, whereby customers have directly or indirectly indicated they want or need a product or service. Combining all external online (big) data with internal client information and user-behaviour is the key to a perfect sales deal. \n"}<br>{"index": {"_id": 1008}}<br>{"title":"This Week in Elastic: Elasticsearch for Apache Hadoop 2.1 RC1 released","seo_title":"","url":"\/blog\/this-week-in-elastic-2015-06-17","author":{"name":"Leslie Hawthorn"},"date":"June 17, 2015","category":"","locales":"","content":" Welcome to ! In this weekly round up post, we bring you news on all aspects of the ELK Stack, including updates on Elasticsearch, Logstash and Kibana development, tips and tricks and upcoming events. Rivers have been removed in code base. Time to switch to other ETL guys! Try for example! \u2014 David Pilato (@dadoonet) Elastic News Useful blog posts, how tos, tutorials\u00a0and articles\u00a0from the wide world of all the ELK stack ecosystem. Getting started w\/? Join on June 24 for an in-depth webinar & Q&A \u2014 elastic (@elastic) Slides and VideosFor all you Apache Hadoop lovers out there, Elasticsearch <3s MapR-DB An introduction to Elasticsearch for Apache Hadoop from yesterday's Elastic Silicon Valley Meetup Our first ever Developer Hangout: on Logstash and the Path from Open Source Contributor to Full-Time Employee An introduction to Elasticsearch (\u65e5\u672c\u8a9e\u3067) We're a global community, dontcha know. Check out this slide deck in West-Vlaams, a Flemish dialect Where to find Us. and getting ready to show off some \"dazzling dashboards\" at - join us upstairs! \u2014 elastic (@elastic) We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking about the ELK stack\u00a0or hosting a meetup, AustraliaOur team will be in the exhibits hall at , on July 16 & 17. We're also proposing an open space on the ELK Stack, so perhaps we'll see you in the open space zone, too. CanadaJoin and in Toronto on June 23 for an open Q&A session. to join them at the Elasticsearch Toronto Meetup. ChileJoin the Lenguajes din\u00e1micos meetup group in Santiago on June 24 to talk Elasticsearch and Ruby. to save your seat. France GermanyJoin our team at on July 19. They'll be on the show floor to answer all of your questions. India ItalyJoin the community in Reggio Emilia for the FazLab Fest! On this Saturday, June 20 - a full day's talk on the Elastic platform and related technologies. are on meetup.com. The Netherlands Reg now: Netherlands Meetup will get together 17 June w\/ talks from & dev Nik Everett \u2014 Leslie Hawthorn (@lhawthorn) New ZealandThe next meeting of the Elasticsearch ELK NZ meetup is coming to Wellington on June 30. We're still lining up the agenda, but for now to save your seat. Poland and will attend Devoxx Poland 2015 taking place June 22-25 in Krakow. Between the two of them, they'll deliver three talks: And last but not least, join is Poznan for . The conference runs July 2-4. South AfricaWe are a proud swag sponsor of the . If you happen to be in Johannesburg on July 11, pop in for knowledge and some cool Elastic goodies. Spain TaiwanThe Taipei D3.js meetup will convene on June 18,including a lightning talk on Elasticsearch and Kibana. to attend. UkraineThe L'viv DevOps Meetup will get together on June 27 for CoreOS Fest Conference review, featuring a CoreOS with Kubernetes demo: ElasticSearch Cluster on local machine and AWS. to save your seat. United KingdomJoin and for Manchester Geek Nights, where you'll hear about Elasticsearch in Action and Building Entity Centric Indexes. to save your seat. Can't join the meetup? No worries. The fine folks organizing the meetup have set up a livestream. Stay tuned to watch live! United States - East United States - West Where to Find You \u00a0If you're a regular reader, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to\u00a0 ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1009}}<br>{"title":"This Week in Elasticsearch and Apache Lucene: 5.2.1 bugfix release is out","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-06-16","author":{"name":"Leslie Hawthorn"},"date":"June 16, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsGetting started w\/? Join on June 24 for an in-depth webinar & Q&A \u2014 elastic (@elastic) Elasticsearch Core Apache LuceneWatch This Space , where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 1010}}<br>{"title":"Logstash 1.5.1 released","seo_title":"","url":"\/blog\/logstash-1-5-1-released","author":{"name":""},"date":"June 16, 2015","category":"","locales":"","content":" We are pleased to announce the release of Logstash 1.5.1. This is a bug fix release: please check the for details or head to our page.We would like to highlight few of the bug fixes here:FeedbackPlease download Logstash 1.5.1 and let us know what you think on Twitter () or on our . You can report any problems on the . \n"}<br>{"index": {"_id": 1011}}<br>{"title":"Partner Spotlight: Search Technologies Launches Aspire for Elasticsearch","seo_title":"","url":"\/blog\/partner-spotlight-search-technologies-launches-aspire-for-elasticsearch","author":{"name":"John-Henry Gross"},"date":"June 16, 2015","category":"News","locales":"","content":" Today, I am excited to announce that Search Technologies, an Elastic partner has released Aspire for Elasticsearch. Aspire is a content access and processing framework specifically designed for unstructured data. It enables content from a variety of content repositories to be acquired, cleaned, normalized and enriched, as part of Elasticsearch implementations. I encourage you to download , it is free for a 45-day trial.Connectors and SecurityLet\u2019s talk a little bit about how Aspire is being used in conjunction with Elasticsearch. A large management consulting firm needed to connect web content, several large databases, SharePoint 2010, and SharePoint 2013 to index in Elasticsearch. Elastic offers Logstash, which focuses on structured log and event data, not unstructured data like office documents and web content. Aspire for Elasticsearch comes pre-packaged with connectors for files systems, RDB and web content. This enables users to start indexing that content immediately and add such as Box.com, Documentum, Salesforce, etc. as needed. And since Aspire uses a modular framework, these connectors can be licensed and plugged in at any time.\u00a0This management consulting firm needed to retrieve access control lists (ACLs) to maintain document-level security throughout the Elasticsearch application as well as extract metadata and content from SharePoint. Aspire SharePoint connectors support this requirement. Both Aspire and Shield address security concerns, however, it is important to understand the different and complementary roles they play. \u00a0Shield provides the foundation-level of security needed to run Elasticsearch in production - protecting your cluster with a username\/password and providing more advanced features like encryption and role-based access controls. Aspire provides support for document level security, what a user has the rights to see from a query based on the source repositories ACLs.\u00a0The need for content processingBy its nature, unstructured content is prone to be inconsistent with incorrect or missing metadata, poor granularity, extraneous content and erratic term usage. Content processing prior to indexing is critical to the success of search and analytics applications utilizing unstructured data. For example, a large recruiting customer\u2019s Elasticsearch solution required extensive content processing. They had inconsistent date formats along with upper and lower case usage in candidate resumes, causing poor search results.Aspire is used to process the content to normalize the date formats and case usage to solve this challenge. In some cases, multiple resumes come in XML blocks and need to be separated into individual documents. Aspire identifies the individual resumes and is able to capture relevant entities (location, titles, company names, etc.) in resumes based on rules (patterns, capitalization, etc.) to create metadata for later analysis for Elasticsearch. An innovative use of content processing in this solution is using Aspire\u2019s integration with Hadoop to support vector creation for a document matching feature.Learn MoreAspire Enterprise for Elasticsearch, just like Marvel and Shield is initially provided as a time restricted \u201ctry and buy\u201d and can easily be converted to full licensing at any time. This is a full feature offering including:For more details on functionality or to download, go to \n"}<br>{"index": {"_id": 1012}}<br>{"title":"The Logstash Lines \u2014 JDBC input plugin, 1.4.3 release and more!","seo_title":"","url":"\/blog\/logstash-lines-2015-06-15","author":{"name":"Shaunak Kashyap"},"date":"June 15, 2015","category":"","locales":"","content":" Welcome back to ! In these weekly\u00a0posts, we'll share the latest happenings in the world of Logstash and its ecosystem. This week, David Pilato shows us how easy it is\u00a0to use Logstash \u2014 instead of using rivers, which were\u00a0recently\u00a0deprecated\u00a0\u2014 to index tweets into Elasticsearch: New post: Indexing Twitter in with \u2014 David Pilato (@dadoonet) Logstash Core and Plugins That's this week in . Come back next week for more Logstash news! \n"}<br>{"index": {"_id": 1013}}<br>{"title":"Where in the World is Elastic: Big Data Analytics London & GOTO Amsterdam","seo_title":"","url":"\/blog\/2015-06-15-where-in-the-world-is-elastic","author":{"name":"Livia Froelicher"},"date":"June 15, 2015","category":"","locales":"","content":" Welcome to\u00a0We're continuing the summer with many events and meetups worldwide.\u00a0Read on to find out if there is an event happening\u00a0near you:Upcoming EventsJune 15-17: , Portland, Oregon- Logstash team lead will give a lightning demo\u00a0on Wednesday, June 17 at 10:40 AM.June 16:\u00a0, London\u00a0-\u00a0Stop by our booth (#1) in the exhibit hall to talk to our local team and pick up some swag. Also don't miss at 12:30 where will show a cool Kibana 4 demo, plus\u00a0we've got a guest speaker from the Met Office, too!June 18-19: , We've got hot Dutch waffles at our booth (#19\/#20) - make sure you don't leave without having tried one! Also, we have an entire track dedicated to Elasticsearch on Thursday, June 18 with the following talks:Upcoming MeetupsJune 15:\u00a0June 16:\u00a0June 16: June 16: (Richmond, VA)June 16: \u00a0June 17:\u00a0June 17:\u00a0June 18: June 18: June 20:\u00a0June 16: (Roeselare, Belgium)June 17: June 18: June 20: June 20: (Hyderabad, India)That's it for this week.\u00a0Stay tuned for Elastic happenings next week - there's much to come!\u00a0- The Elastic TeamP.S.:\u00a0\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Elasticsearch, Logstash or Kibana\u00a0\u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 1014}}<br>{"title":"This Week in Elastic: First dev hangout & Logstash 1.4.3 released","seo_title":"","url":"\/blog\/this-week-in-elastic-2015-06-10","author":{"name":"Leslie Hawthorn"},"date":"June 10, 2015","category":"","locales":"","content":" Welcome to ! In this weekly round up post, we bring you news on all aspects of the ELK Stack, including updates on Elasticsearch, Logstash and Kibana development, tips and tricks and upcoming events. ICYMI: 's 1st ever dev hangout w\/ Fri, 12 June 11 AM PDT\/8 PM CEST. Watch live: \u2014 Leslie Hawthorn (@lhawthorn) Elastic News Useful blog posts, how tos, tutorials\u00a0and articles\u00a0from the wide world of all the ELK stack ecosystem. I'll talk about Elasticsearch under the hood and speed during the first german webinar next Tuesday at 3pm \u2014 Alexander Reelsen (@spinscale) Slides and Videos Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking about the ELK stack\u00a0or hosting a meetup, AustriaThe .NET Community Austria Meetup will get together on June 11 to talk all about the ELK stack. to save your seat. BelgiumThe PHP wvl group will convene in Roeselare on June 16. The speakers will be presenting on Elasticsearch and Symfony. to save your seat. CanadaJoin our and in Toronto on June 23 for an open Q&A session. to join them at the Elasticsearch Toronto Meetup. FranceYou can see our very own on at Breizhcamp this week, or these awesome speakers on Elasticsearch: Universit\u00e9 Kibana et Elasticsearch : . Analyse de donn\u00e9es temps r\u00e9el avec la suite et Adelean.\u2014 Lucian Precup (@lucianprecup) Plus, we have the 3rd Elastic France meetup coming up in Lyon on June 23. to save your seat. And last but not least, join in Bordeaux. The conference runs June 30-July 3. GermanyIf you'll be attending the on June 12, make sure to say hello to in the hallway track! India \n"}<br>{"index": {"_id": 1015}}<br>{"title":"Elastic Community Health Metrics: Sending Your Devs to Conferences is a Good Thing","seo_title":"","url":"\/blog\/community-health-metrics-part-two","author":{"name":"Sonja Winter"},"date":"June 10, 2015","category":"","locales":"","content":" In conclusion, spreading the word about your company and products by talking at developer-centric conferences boosts subsequent meetup activity in that area. If you want your product to be adopted by the entire world, make sure you send your developers to speak all over the world! \n"}<br>{"index": {"_id": 1016}}<br>{"title":"Kibana 4.1","seo_title":"","url":"\/blog\/kibana-4-1","author":{"name":"Rashid Khan"},"date":"June 10, 2015","category":"Engineering","locales":"","content":" Kibana 4.1 is now available for your data dicing, stat splicing, log munching, chart crunching enjoyment. In addition to a fork load of great new features, we've put a big focus on performance in Kibana 4.1, improving responsiveness across the board and reducing memory consumption by as much as 10x. Kibana 4.1 does more, and does it all more quickly. Can't wait? . Otherwise, dig into the juicy details below. Axis AwesomenessSpikes. You deal with them often. Server load hits the ceiling, prices jump for a moment. Kibana 4.1 brings support for logarithmic axis in the line chart. Logarithmic scales allow you to smooth out those big spikes so that the important details aren't unduly impacted by one big event. Speaking of smooth, we've introduced smoothing to line and area charts. Sure, smooth lines are a lie, but they're your lie and they sure do look good! Bubble chartsBut thats not all we've done with line charts. We've also introduced a new metric dimension for line charts called **dot size**. This new metric lets us define the size of the dots placed on the line based on some other metric. For example, is the bandwidth used to serve large files potentially impacting my ability to handle more users? New aggregationsTo help you utilize those new visualization modes we've built support for more elasticsearch aggregations including and . Map MadnessIn addition to improvements to how we communicate the nature of the map projection, we added the ability to render a heat maps. And because heat maps are built using HTML canvas, instead of SVG, they're super fast, enabling you to crank up the precision of the aggregation. Plus, when you need to drill in, we're added geographic filters. Draw and box and we'll filter your request down to just the region you're interested in. Put a pin in itSpeaking of filters, we're introducing the concept of **pinned filters**. We just can't stop using this feature, I don't know how we lived with out it. Imagine you're on a dashboard and you've filtered the view down to using a combination of filters. Now you want to jump back to discover and dig into the documents, or create a new visualization looking at only that filtered data. With filter pinning you can. Pinning a filter means it sticks with you no matter where you go in the app. So if you create a filter in Discover and pin it, it will still be there when you head over to the Dashboard.\u00a0 And when you're on that dashboard, don't miss that new option when you go to save. If you're a Kibana 3 user you may remember that your time filter was always saved with the dashboard. We've brought that option back in Kibana 4.1: Select and Kibana will return you to right where you left off when you load the dashboard. Field formattingWe've always wanted you to see your data how you want it. While aggregations allow us to compose complex, expressive, visualizations, we wanted to be able to do that same thing with the actual values of fields. Thus, we've introduced field formatters in Kibana 4.1. Now you can continue to index your data just how you'd like it, as numbers, or unformatted strings, and let Kibana do the rest. For example, format numbers as bytes, or URL strings as links. URL formatting even support templates allowing you to use Kibana data to create custom links to other applications. And so much moreThat isn't even close to everything in Kibana 4.1. You'll discover improved functionality around every corner. We've streamlined where we can and reduced unnecessary configuration whenever possible. We've fixed dozens of bugs and added important management features, like importing and exporting schemas, and fine grained timeout configuration. Download Kibana 4.1 and give it a shot! EngageOf course Kibana is a product of your input and insight. We wanted to make it easier for you to stay up to date, try out the latest and great, and contribute to the project. We've begun publishing code to let you ride the knife edge. Have a question? Join us on the new . Have a bug? . Make something great? Tell about your #kibana dashboards on twitter. Happy data hunting! \n"}<br>{"index": {"_id": 1017}}<br>{"title":"Watcher Beta 2 - Fixes, Features, Feedback","seo_title":"","url":"\/blog\/watcher-beta-2","author":{"name":"Uri Boness"},"date":"June 10, 2015","category":"Engineering","locales":"","content":" We're pleased to announce Watcher 1.0.0-Beta2!This release of Watcher includes bug fixes and enhancements to features introduced in Beta1.But we didn\u2019t stop there. Since the release of Beta1, we\u2019ve received wonderful feedback from all of you trying out Watcher. We\u2019re delighted with the activity in the \u00a0and I can honestly say that your questions have helped us improve Watcher in every aspect - functionality, usability and documentation.And yes, we are talking the talk and walking the walk. We took some of your wonderful suggestions and included them in this release. For more details, please read the .Installing Beta2 is as easy as it was installing Beta1. You can use the same beta key you received in the Beta1 registration email, but this time appending \u00a0`-Beta2` to your key:Haven\u2019t registered yet? and try Watcher out! \n"}<br>{"index": {"_id": 1018}}<br>{"title":"Elasticsearch 1.6.0 released","seo_title":"","url":"\/blog\/elasticsearch-1-6-0-released","author":{"name":"Clinton Gormley"},"date":"June 09, 2015","category":"Engineering","locales":"ja-jp","content":" Today, we are pleased to announce the release of , based on . This is the latest stable version of Elasticsearch and is packed with awesome new features: You can read the full changes list and . \n"}<br>{"index": {"_id": 1019}}<br>{"title":"This Week in Elasticsearch and Apache Lucene: Algorithms that power Lucene and Elasticsearch","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-06-09","author":{"name":"Leslie Hawthorn"},"date":"June 09, 2015","category":"","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsVideo of my talk is now online: Algorithms that power Lucene and Elasticsearch \u2014 Adrien Grand (@jpountz) Elasticsearch Core Apache Lucene Watch This Space , where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 1020}}<br>{"title":"Kibana 4.0.3 is available","seo_title":"","url":"\/blog\/kibana-4-0-3","author":{"name":"Rashid Khan"},"date":"June 09, 2015","category":"Engineering","locales":"","content":" Kibana 4.0.3 is now available!\u00a0Can't wait to read the rest?\u00a0\u00a0now. Otherwise read on for details. As you know, we\u2019re constantly working to build new, awesome\u00a0features into Kibana. If you didn\u2019t know that, you should get out the weekly \u00a0series. At the same time we\u2019re building new stuff, we\u2019re\u00a0working to stabilize, secure and enhance the features you already know and love. Today we\u2019re releasing Kibana 4.0.3 with over two dozen fixes and tweaks to make everyday Kibana life better. We also undertook an extensive string sanitization audit and identified a few potential security issues worth fixing. For details see our\u00a0. We strongly encourage everyone to upgrade to Kibana 4.0.3, and to stay tuned to this blog for more in the near future! \n"}<br>{"index": {"_id": 1021}}<br>{"title":"Logstash 1.4.3 released","seo_title":"","url":"\/blog\/logstash-1-4-3-released","author":{"name":"Suyog Rao"},"date":"June 09, 2015","category":"Engineering","locales":"","content":" We are pleased to announce the availability of Logstash 1.4.3. This is a bug fix release for the 1.4 series which fixes a few important security vulnerabilities. Our recommendation is to upgrade to 1.4.3 if you are using either of the following plugins:Elasticsearch 1.1.1 vulnerabilityLogstash 1.4.2 was bundled with Elasticsearch 1.1.1, which is vulnerable to . These binaries are used in Elasticsearch output specifically when using the node protocol. Since a node client joins the Elasticsearch cluster, the attackers could use scripts to execute commands on the host OS using the node client's URL endpoint. With 1.4.3 release, we are packaging Logstash with Elasticsearch 1.5.2 binaries which by default disables the ability to run scripts. This also affects users who are using the configuration option in the Elasticsearch output which starts a local embedded Elasticsearch cluster. This is typically used in development environment and proof of concept deployments. Regardless of this vulnerability, we strongly recommend not using embedded in productionNote that users of transport and http protocol are not vulnerable to this attack.Logstash Forwarder with Lumberjack input\/outputThe combination of Logstash Forwarder and Lumberjack input (and output) was vulnerable to the attack in SSLv3 protocol. We have disabled SSLv3 for this combination and set the minimum version to be TLSv1.0. We have added this vulnerability to our CVE page and are working on filling out the CVE.Thanks to Tray Torrance, Marc Chadwick, and David Arena for reporting this.File output vulnerabilityAn attacker could use the File output plugin with in the path option to traverse paths outside of Logstash directory. This technique could also be used to overwrite any files which can be accessed with permissions associated with Logstash user. This release sandboxes the paths which can be traversed using the configuration. We have also disallowed use of dynamic field references if the path options is pointing to an absolute path.We have added this vulnerability to our and are working on filling out the CVE. We would like to thank Colin Coghill for reporting the issue and working with us on the resolution.Other fixesFixed an issue in Elasticsearch output which was not correctly releasing socket connections. This fix was in the HTTP client library, so any plugins using this should benefit from this resolution ()Please check the or proceed to our page. \n"}<br>{"index": {"_id": 1022}}<br>{"title":"Where in the World is Elastic: Hadoop Summit San Jose & dotScale Paris","seo_title":"","url":"\/blog\/2015-06-08-where-in-the-world-is-elastic","author":{"name":"Livia Froelicher"},"date":"June 08, 2015","category":"","locales":"","content":" Welcome to\u00a0 From San Jose to a mini 'Tour de France' plus\u00a0Poland, we have\u00a0another\u00a0geographical\u00a0roller\u00a0coaster of awesome meetups and conferences coming up. Read on to find out if there is an event happening\u00a0near you: Upcoming Events June 9-11: - Come visit us at our booth (#S1) to meet some of our local developers, and learn more about how to explore your data and get real-time results. June 8: -\u00a0Stop by our booth in the exhibit hall to talk to our local team and pick up some swag. June 10-12: - will be giving a talk on\u00a0\u00a0on Thursday, June 11 at 4:30 p.m. June 11-12: \u00a0- David will be\u00a0on tour in South of France reprising\u00a0his talk on\u00a0,\u00a0Friday,\u00a0June 12, 2:40 p.m. June 12: - Alexander Reelsen will be attending in the hallway track. So if you'd like to talk\u00a0the ELK stack and more, drop him a ! Upcoming Meetups June 8: June 8: June 10: June 11: June 11: June 11: That's it for this week.\u00a0Stay tuned for Elastic happenings next week - there's much to come!\u00a0 - The Elastic Team P.S.:\u00a0 \u00a0if you're interested in hosting a meetup or are giving a talk about Elasticsearch, Logstash or Kibana\u00a0\u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 1023}}<br>{"title":"The Logstash Lines: How to reindex data in Elasticsearch using Logstash","seo_title":"","url":"\/blog\/logstash-lines-2015-06-05","author":{"name":"Shaunak Kashyap"},"date":"June 05, 2015","category":"The Logstash Lines","locales":"","content":" Welcome back to ! In these weekly\u00a0posts, we'll share the latest happenings in the world of Logstash and its ecosystem. This week, our very own David Pilato shows us how to reindex data\u00a0in Elasticsearch using Logstash: New post: Reindex With \u2014 David Pilato (@dadoonet) And here is an awesome presentation from Logstash engineer Jo\u00e3o Duarte, on how you can setup a burglar\u00a0alert system using Logstash! Logstash Core and Plugins That's this week in . Come back next week for more Logstash news! \n"}<br>{"index": {"_id": 1024}}<br>{"title":"Kurrently in Kibana: Performance Tweaks and Big Fixes for 4.1","seo_title":"","url":"\/blog\/kurrently-kibana-2015-06-05","author":{"name":"Robyn Bergeron"},"date":"June 05, 2015","category":"Kurrently in Kibana","locales":"","content":" Welcome to , your source for keeping up with the Kibana project. With information on project releases, work in progress, and learning resources, this weekly update helps you satisfy your around what's been happening in Kibana! dashboard for at Stage 1 \u2014 Tanya Bragin (@tbragin) Kibana 4.1: The QA Train Moves ForwardQA continues on Kibana 4.1. We\u2019ve found a number of issues in IE and Firefox, though fortunately recent discoveries have all been fairly small. You can see what we have left to tackle . Performance TweaksOn the plus side, we\u2019ve sped things up a bit as a side effect of all the aforementioned cross browser testing time: Plus... Lots of Fixes! All eyes on demo! Monitoring tweets! \u2014 Valentina Sipovica (@pvalentinaq) See You Next Week!Did you know? Elasticsearch and Apache Lucene, Logstash and Kibana all have weekly updates published to the Elastic blog. Tune in next week to to stay in the ! \n"}<br>{"index": {"_id": 1025}}<br>{"title":"Norway's Postal Service Moves to Elastic from FAST","seo_title":"","url":"\/blog\/norways-postal-service-moves-to-elastic-from-fast","author":{"name":"S\u00e9bastien Muller"},"date":"June 04, 2015","category":"User Stories","locales":"","content":" \n"}<br>{"index": {"_id": 1026}}<br>{"title":"This Week in Elastic: New discussion forums are live!","seo_title":"","url":"\/blog\/this-week-in-elastic-2015-06-03","author":{"name":"Leslie Hawthorn"},"date":"June 03, 2015","category":"","locales":"","content":" Welcome to ! In this weekly round up post, we bring you news on all aspects of the ELK Stack, including updates on Elasticsearch, Logstash and Kibana development, tips and tricks and upcoming events. Always wanted to ask our devs (almost anything)? Join our Dev Hangouts Series! brings you the scoop \u2014 elastic (@elastic) Elastic News Useful blog posts, how tos, tutorials\u00a0and articles\u00a0from the wide world of all the ELK stack ecosystem. Couldn\u2019t catch our live and Beyond webinar yesterday? Catch & now on demand! \u2014 elastic (@elastic) Slides and VideosPssst! We visited CERN last week to learn about all the ways they're using the ELK stack and for our team to tell the scientists there who didn't know us more about our technology. , featuring the ever amazing and . But wait, there's more! Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking about the ELK stack\u00a0or hosting a meetup, AustriaThe .NET Community Austria Meetup will get together on June 11 to talk all about the ELK stack. to save your seat. CanadaThe Montreal Monitoring Meetup will get together on June 8 to talk about the ELK stack, amongst many other tools. to save your seat. France During 2015, will show us how to add to legacy applications in a blink ! \u2014 RivieraDEV (@RivieraDEV) Universit\u00e9 Kibana et Elasticsearch : . Analyse de donn\u00e9es temps r\u00e9el avec la suite et Adelean.\u2014 Lucian Precup (@lucianprecup) GermanyIf you'll be attending the on June 12, make sure to say hello to in the hallway track!IrelandJoin for an expert level session at NoSQL Matters Dublin on . The conference takes place on June 4. IndiaThe Big Data Analytics on Cloud Meetup in Hyderabad will host a free workshop on Elasticsearch on June 20. to attend the workshop. JapanPlease join all members of Elastic's team in Japan at in Tokyo on June 3-5. We will have a booth in the exhibits hall and will be very happy to answer any questions you may have. The Netherlands Reg now: Netherlands Meetup will get together 17 June w\/ talks from & dev Nik Everett \u2014 Leslie Hawthorn (@lhawthorn) PolandIf you'll be in Katowice, Poland on June 11, join the AWS Poland User Group to talk Elasticsearch on AWS. Register now to save your place. David Pilato and will attend Devoxx Poland 2015 taking place June 22-25 in Krakow. Between the two of them, they'll deliver three talks: SpainThe Madrid Open Analytics Meetup will get together on June 25 to talk big data before your holidays, including Elasticsearch. to join them. (No holiday included, but definitely great knowledge sharing.) United Kingdom South Wales Elasticsearchers: a meetup with a talk by Honza Kr\u00e1l , Elasticsearch developer: All welcome. \u2014 DjangoCon Europe (@DjangoConEurope) United States - East United States - West Where to Find You \u00a0If you're a regular reader, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to\u00a0 ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1027}}<br>{"title":"Introducing (Awesome) Developer Hangouts and our Developer Newsletter","seo_title":"","url":"\/blog\/newsletter-and-hangouts","author":{"name":"Robyn Bergeron"},"date":"June 03, 2015","category":"Engineering","locales":"","content":" Here at Elastic, the fantastic folks on our Developer Relations team are not so different from the amazing people in our community in terms of background. Some of us have been developers, some have been in ops \u2014 and we\u2019ve all felt the pain of trying to keep track of what\u2019s going on with our favorite tools. As open source software users and contributors, we\u2019ve accumulated quite a few list subscriptions over time, and\u2026 well, let\u2019s just say we actually celebrate \u201cMailing List Password Reminder Day\u201d each month with a little bit of a grin. And with so many sources of information coming in \u2014 Twitter, forums, blog posts, you name it \u2014 filtering out what is useful can be a challenge. We know the pain. And we want to make that easier for you \u2014- at least when it comes to Elastic-related content. Which is why the Developer Relations team at Elastic is bringing you two new ways to keep in touch with what\u2019s going on in the Elastic community: a weekly newsletter, with content curated for our dev\u00a0audience, and a weekly, live video hangout session with one of the Elastic Developers. Our goal: to bring you concise, relevant, useful content \u2014 deliver it to you in an easily consumable format \u2014 and to be authentic and fun in doing so. \u00a0(That last part is important \u2014 we never want to sound like we\u2019re, you know, stuffy or annoying.) Delivering AwesomeThe Developer Newsletter will hit your inbox once a week. . (And so is unsubscribing \u2014 but we know you\u2019ll never want to!) Bonus points: When you sign up for this newsletter, *the newsletter is all you will get.* (Unless you specify otherwise at some other point in time with us, that is!) No added advertisements, calls, announcements, or otherwise. Double Bonus Points: The Developer Newsletter is your pass, quite literally, to our new Developer Hangouts. Live Developer Hangouts, Exclusively for Newsletter Subscribers Every week, we\u2019ll be hosting a video hangout with a fabulous guest star from the Elastic engineering team, for approximately half an\u00a0hourish \u2014-- consisting partially of a mini-presentation from our guest star, a bit of Q & A from the host, and plenty of time at the end reserved for an \u201cAsk Me Anything\u201d session \u2014 where you can ask the guest (almost) anything, and get an answer. Want to participate? Access to the live hangout \u00a0is granted exclusively to our newsletter subscribers only \u2014 which means that if you have questions, you\u2019ve got to be on our list. Every week, the developer newsletter will contain all the info you\u2019ll need for the hangout \u2014 including the guest, the topic, your link to participate, and information about connecting via IRC to ask All The Things! Of course, though, we want to give you a little taste, just so you know how awesome our hangouts are \u2014 and this means that our first hangout won\u2019t require newsletter subscription. So be sure to keep your eyes open for information about our first hangout next Friday, June 12, with .\u00a0Aaron\u2019s one of our many awesome developers working on Logstash, and he\u2019ll be talking about how his involvement in\u00a0open source projects\u00a0and passion for contributing\u00a0got him on the track to a full-time job working at Elastic on Logstash.\u00a0As your first host, I\u2019ll be sure to get the scoop on all the things Aaron\u00a0been working on lately, too. But after that? . Sorry, folks! And don\u2019t you worry, folks outside of my UTC -7 time zone: we recognize that Elastic has a community that stretches far beyond the west coast of the United States. We\u2019ll be rotating the days and times of day in which we hang \u2014 so everyone gets an opportunity to attend. So what are you waiting for? Get today \u2014 and get your full-fledged, \u201cfirst edition\u201d newsletter starting next week. \n"}<br>{"index": {"_id": 1028}}<br>{"title":"This Week in Elasticsearch and Apache Lucene: The second release candidate for 5.2.0 is out","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-06-02","author":{"name":"Leslie Hawthorn"},"date":"June 02, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsHow uses + to improve their criminal justice data inventory \u2014 Leslie Hawthorn (@lhawthorn) Elasticsearch Core Apache LuceneWatch This Space , where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 1029}}<br>{"title":"Where in the World is Elastic: MongoDB World & Berlin Buzzwords","seo_title":"","url":"\/blog\/2015-06-01-where-in-the-world-is-elastic","author":{"name":"Livia Froelicher"},"date":"June 01, 2015","category":"","locales":"","content":" Welcome to\u00a0 From Berlin to Tokyo, this week is full with great events and meetups once again!\u00a0Read on to\u00a0find out if we'll be near you:Upcoming EventsJune 1 - June 2: \u00a0- Stop by our booth in the exhibit hall to talk to our local team and pick up some swag.May 31 - June 5: -\u00a0Make sure to\u00a0say hello to Honza Kral in the hallway track.\u00a0Our cool\u00a0meetup featured below takes place on June 4, don't miss it!June 1-3: - We have a full host of Elastic talks coming up:June 3-5: - David Pilato will be giving a\u00a0talk\u00a0on\u00a0 on\u00a0Wednesday, June 3, 12:00 p.m - 12:45 p.m.June 4: - Mark Harwood will give a talk on 11:30 a.m. - 12:15 p.m.June 3-5:\u00a0\u00a0- Don't miss the chance to meet our pretty new team in Japan. We'll be at booth #14 and ready for any Elastic\u00a0questions you may have.\u00a0Upcoming Meetups June 2: June 4 : June 5:\u00a0 June 3: June 4: That's it for this week.\u00a0Stay tuned for Elastic happenings next week - there's much to come!\u00a0 - The Elastic Team P.S.:\u00a0 \u00a0if you're interested in hosting a meetup or are giving a talk about Elasticsearch, Logstash or Kibana\u00a0\u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 1030}}<br>{"title":"The Logstash Lines: Logstash deployment and scaling tips","seo_title":"","url":"\/blog\/logstash-lines-2015-05-29","author":{"name":"Shaunak Kashyap"},"date":"May 29, 2015","category":"The Logstash Lines","locales":"","content":" Welcome back to ! In these weekly\u00a0posts, we'll share the latest happenings in the world of Logstash and its ecosystem. This week,\u00a0 from\u00a0Chartbeat\u00a0has some useful\u00a0Logstash deployment and scaling tips for us: Our very own drops some knowledge on deploying and scaling at Chartbeat: \u2014 Chartbeat (@Chartbeat) Logstash Core and Plugins That's this week in . Come back next week for more Logstash news! \n"}<br>{"index": {"_id": 1031}}<br>{"title":"Kurrently in Kibana: Kibana 4.1 QA time","seo_title":"","url":"\/blog\/kurrently-kibana-2015-05-29","author":{"name":"Robyn Bergeron"},"date":"May 29, 2015","category":"Kurrently in Kibana","locales":"","content":" Welcome to , your source for keeping up with the Kibana project. With information on project releases, work in progress, and learning resources, this weekly update helps you satisfy your around what's been happening in Kibana! tv commercial showing some promising results already! \u2014 jwijgerd (@jwijgerd) Kibana 4.1: QA Time! All of the planned pulls have been merged and we\u2019re into QA. You can track our triaging of QA-identified issues Heat Map Merged The new geo heat map has been merged. You turn it on in the tab of the tile map, along with settings to tune it to just your use case. It brought with it a normalization of the tooltips used on the heat map. At the moment they\u2019re using the geo_point field formatter, which we plan to improve on. This also makes sure that the field formatters are used to display the value of the result of a metric aggregation. Refactored Filter Functions We found some instances in which adding and removing filters could create duplicate history entries. We did some refactoring here and added a bunch of test coverage as well. Merged deb and rpm PackagingThanks to , we now have the ability to create rpm and deb packages for Kibana 4.1. We'll let you know as soon as they hit the repository! Plus This Stuff: We have great news: Packetbeat is joining ! \u2014 Packetbeat (@packetbeat) See You Next Week!Did you know? Elasticsearch and Apache Lucene, Logstash and Kibana all have weekly updates published to the Elastic blog. Tune in next week to to stay on All The Things!. \n"}<br>{"index": {"_id": 1032}}<br>{"title":"Combining Geo Points With the Elasticsearch Percolator","seo_title":"","url":"\/blog\/found-geo-points-and-elasticsearch-percolator","author":{"name":"Jettro Coenradie"},"date":"May 29, 2015","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. Elasticsearch has some very good support for geo locations. You can store locations, use distances to filter and even use distances to group using aggregations. Elasticsearch also has something called geo shapes - no worries, we'll explain later on what they are - to select locations within a certain area. If you combine these geo shapes with filters and something called the percolator, you can create a basic classification system. Curious? Read on to learn about the Elasticsearch percolator and geo support in Elasticsearch. To explain the concepts we use a sample application based on spring boot and angularjs. Before we jump into the technical stuff, we'll talk about the data lifecycle that you need for all data projects. \n"}<br>{"index": {"_id": 1033}}<br>{"title":"This Week in Elastic: Welcome Packetbeat!","seo_title":"","url":"\/blog\/this-week-in-elastic-2015-05-27","author":{"name":"Leslie Hawthorn"},"date":"May 27, 2015","category":"","locales":"","content":" Welcome to ! In this weekly round up post, we bring you news on all aspects of the ELK Stack, including updates on Elasticsearch, Logstash and Kibana development, tips and tricks and upcoming events. Elastic NewsCommunity + one a-mazing data scientist concur: you want to hear each others real world stories. We're here to help! \u2014 Leslie Hawthorn (@lhawthorn) Useful blog posts, how tos, tutorials\u00a0and articles\u00a0from the wide world of all the ELK stack ecosystem. Thought you might like my mention of ELK here: :)\u2014 Samuel Scott (@samueljscott) Slides and Videos Where to find Us (Don't let that tomorrow bit fool you. : ) TOMORROW! is coming to talk about elasticsearch, logstash and kibana. Come get your learn on! \u2014 San Antonio DevOps (@SADevOps) We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking about the ELK stack\u00a0or hosting a meetup, AustriaThe .NET Community Austria Meetup will get together on June 11 to talk all about the ELK stack. to save your seat. France During 2015, will show us how to add to legacy applications in a blink ! \u2014 RivieraDEV (@RivieraDEV) Universit\u00e9 Kibana et Elasticsearch : . Analyse de donn\u00e9es temps r\u00e9el avec la suite et Adelean.\u2014 Lucian Precup (@lucianprecup) GermanyThe Elastic team will be out in force at Berlin Buzzwords, including 3 talks, a booth on the show floor and a special conference meetup. You can for the conference and RSVP for . Buzzwords runs May 31 - June 3. Bonus: meet the newest members of our team, and of Packetbeat fame! IrelandJoin Mark Harwood for an expert level session at NoSQL Matters Dublin on . The conference takes place on June 4. JapanPlease join all members of Elastic's team in Japan at in Tokyo on June 3-5. We will have a booth in the exhibits hall and will be very happy to answer any questions you may have. The Netherlands Technical Expert Aur\u00e9lien Foucret of talks about ElasticSearch at , more info: \u2014 Meet Magento NL (@mm15nl) Reg now: Netherlands Meetup will get together 17 June w\/ talks from & dev Nik Everett \u2014 Leslie Hawthorn (@lhawthorn) Poland David Pilato and will attend Devoxx Poland 2015 taking place June 22-25 in Krakow. Between the two of them, they'll deliver three talks: United Kingdom South Wales Elasticsearchers: a meetup with a talk by Honza Kr\u00e1l , Elasticsearch developer: All welcome. \u2014 DjangoCon Europe (@DjangoConEurope) United States - East United States - West On stage now: Rob Tice, Director at talking about complex modelling of rich text data in \u2014 elastic London (@elastic_london) Where to Find You \u00a0If you're a regular reader, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to\u00a0 ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1034}}<br>{"title":"Welcome Packetbeat, Tudor & Monica","seo_title":"","url":"\/blog\/welcome-packetbeat-tudor-monica","author":{"name":"Shay Banon"},"date":"May 27, 2015","category":"News","locales":"","content":" I have been following Packetbeat for quite some time, being one of those projects I just love. Packetbeat is a lightweight network packet analyzer that parses different protocols (HTTP, MySQL, Postgresql, Redis, Thrift-RPC), extracts the relevant information from them, ships the data to Elasticsearch and uses Kibana to visualize it.\u00a0 It has grown to become quite successful, with a strong following. These type of projects are what make open source such a great platform for innovation. Here at Elastic we are building products like Elasticsearch, Kibana, and Logstash, and a project is born using them in a wonderful new direction. \n"}<br>{"index": {"_id": 1035}}<br>{"title":"A Dive into the Elasticsearch Storage","seo_title":"","url":"\/blog\/found-dive-into-elasticsearch-storage","author":{"name":"Njal Karevoll"},"date":"May 26, 2015","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. In this article we'll investigate the files written to the data directory by various parts of Elasticsearch. We will look at node, index and shard level files and give a short explanation of their contents in order to establish an understanding of the data written to disk by Elasticsearch. \n"}<br>{"index": {"_id": 1036}}<br>{"title":"This Week in Elasticsearch and Apache Lucene: Lucene 5.2.0 is coming","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-05-26","author":{"name":"Alexander Reelsen"},"date":"May 26, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsWe were among the first to use and contribute to \u2026 now, more than 1,500 government websites use \u2014 Taha Kass-Hout (@DrTaha_FDA) Elasticsearch Core Apache LuceneWatch This Space , where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 1037}}<br>{"title":"Elastic Community Health Metrics: Why *You* Should Share Your Stories","seo_title":"","url":"\/blog\/community-health-metrics-part-one","author":{"name":"Sonja Winter"},"date":"May 26, 2015","category":"","locales":"","content":" Hi all! I'm Sonja Winter, a data scientist\/statistician, currently helping Elastic analyze their community data. In my daily work, I use the ELK stack to explore the data I work with, so I am excited to now be getting insights from the ELK stack into the\u00a0data from\u00a0the same community that helped build\u00a0it. This post will be the first in a series of short updates on Elastic\u2019s community development and engagement. Any open source project thrives on the engagement and contributions of their community, and the ELK stack is no different. Therefore, it is important to gain insight into the factors that play a role in engaging and motivating this community. Hosting meetups is a popular method of getting the community together to share knowledge and for the projects\u2019 developers to figure out their users\u2019 praise and pain points. So how do you get more people to register for your meetup events? The analysis I will show you today will demonstrate that getting someone from your community to speak to your community at a meetup event, will result in a higher registrant-to-member ratio.The fine folks at Elastic have been monitoring meetup activity for all events taking place since October 2011. Since then, a total of 649 Elastic related events have been organised and tracked via meetup.com: plus, there are many more user group meetings happening than are reflected on just the meetup.com site. For 138 of these events, we have data on the origin of the speaker of the event, and we know that the event was hosted by an Elastic-focused meetup group.In total, 83 events had community speakers (60.1%) and 55 events had Elastic employee speakers (39.9%):As a proxy for the popularity of an event, I computed the registrants-to-member ratio, which equals the number of registrants to an event divided by the total number of members of that meetup group. A ratio of 1 indicates that all members of the meetup group went to the event. A ratio < 1 indicates that some members of the group went to the event and a ratio > 1 indicates that more people than members of the group went to the event. The box-plot figure below shows that the average registrants-to-member ratio (the thick line in each box) is higher when the speaker is a community member than when the speaker is from Elastic Inc.. More specifically, for a community speaker, the average ratio is 0.69, meaning that for every 1 member, 0.69 members will register for the event (or for every 100 members, 69 will register). For an Elastic speaker, the average ratio is 0.58, meaning that for every 1 member, 0.58 members will register for the event (or for every 100 members, 58 will register). Thus, on average, this data indicates that an event with a community speaker will attract 11 per 100 members more than an event with a Company speaker.To explore whether this difference is also statistically significant, I performed a Poisson regression. Since a Poisson regression is used for count data, I first multiplied the ratio by 100 and rounded to the nearest integer. This number now represents the number of registrants per 100 members. The data is overdispersed (z = 3.85, p < .001: see also the histogram below), meaning that the variance of the data is larger than its mean. You can also see this in the box-plot by looking at the outliers (the dots). Because of this, I chose to perform a negative binomial regression analysis. The results indicate that the difference between a community and company speaker is not statistically significant (Est. = 0.19, 95% CI = -0.17 - 0.53, p = .291). This is not surprising, as the variance around the mean is very large (you can see this in the box-plot by looking at the length of the whiskers [lines] and the dots that indicate very high values). To make the estimate more meaningful, we take its exponent, which results in an incidence rate. For every 1 registrant per 100 members for an event with a company speaker, 1.21 members per 100 members register for an event with a community speaker.Can a statistically non-significant result still be meaningful? I think in this case, it can be. Having, on average, 11 extra registrants per 100 members (an increase of 11%), just by having a speaker from the community instead of from your company, is an easy win in my eyes. \n"}<br>{"index": {"_id": 1038}}<br>{"title":"Elasticsearch and the 2015 Leap Second","seo_title":"","url":"\/blog\/elasticsearch-2015-leap-second","author":{"name":"Antonio Bonuccelli"},"date":"May 26, 2015","category":"Engineering","locales":"","content":" We're approaching that time of the year when a day will actually be longer than a normal day, by just one second.That is what the scientific community refers to as the \u201cLeap Second.\u201dA Leap Second is a one-second adjustment that is occasionally applied to Coordinated Universal Time (UTC) in order to keep its time of day close to the mean solar time, or UT1.The next scheduled occurrence of leap second will be on June 30, 2015 23:59:60 UTC.While the leap second is certainly an interesting subject for discussions among scientists, it has proven to be a big headache for an IT infrastructure.The most recent occurrence of the leap second in 2012 disrupted operations for many major companies, bringing down services by causing high cpu usage on production servers.The main problem actually sits in Linux kernel layer. Most Linux vendors have published guides explaining what you need to do (if anything) to test and prepare for the upcoming leap second:Please refer to your distribution's support channels if it is not listed above and for additional details. Elastic recommends you follow your distribution's recommended guidelines for handling this issue in order to avoid any further complications that may arise from unofficial or ad-hoc fixes.Additionally, some of the major cloud providers have also published their own information which you should read if you are running on one of their platforms: \n"}<br>{"index": {"_id": 1039}}<br>{"title":"The Logstash Lines: Versions 1.5.1 and preview","seo_title":"","url":"\/blog\/logstash-lines-2015-05-22","author":{"name":"Shaunak Kashyap"},"date":"May 22, 2015","category":"The Logstash Lines","locales":"","content":" Welcome back to ! In these weekly\u00a0posts, we'll share the latest happenings in the world of Logstash and its ecosystem. We shipped 1.5.0 last week but the team didn't waste any time getting their work\u00a0organized\u00a0for future versions of Logstash.\u00a0 Epic ticket triage for Logstash complete. ~550 tickets read, ~150 moved or otherwise updated. Whew! \u2014 @jordansissel (@jordansissel) If you are curious, here's what's cooking for versions and . While the Logstash team works their magic, here's some Logstash reading for this week: That's this week in . Come back next week for more Logstash news! \n"}<br>{"index": {"_id": 1040}}<br>{"title":"Kurrently in Kibana: The Road to Releasing 4.1","seo_title":"","url":"\/blog\/kurrently-kibana-2015-05-22","author":{"name":"Robyn Bergeron"},"date":"May 22, 2015","category":"","locales":"","content":" Welcome to , your source for keeping up with the Kibana project. With information on project releases, work in progress, and learning resources, this weekly update is a great way to learn what's been happening in Kibana! Starting to get the hang of . E.g. to dig for place names matched to multiple places & vice versa. \u2014 Rainer Simon (@aboutgeo) Kibana 4.1: The Road to Release Almost all of the major features for Kibana 4.1 have been merged with the exception of heat maps, which are almost there. We snuck in one more thing this past week, but really it was mostly squashing bugs and lots of intensive pull review in preparation for release. Added a pause button for auto refresh Quite simply pauses the auto refresh without the need to expand the time picker and turn it off. Sometimes its the little things, eh? We also added one-click access to the refresh interval selector whenever the time picker is open and switched up how the tabs work for a cleaner, easier to use, design. (Also, I keep thinking \u201cpaws\u201d when I type \u201cpause\u201d because has a house full of kittens and can\u2019t stop posting pictures of those fluffy little balls of pure cuddliness and furniture destruction.) The new server architecture is ready for review In addition to playing with kittens, @simianhacker has been simian hacking hard on a new architecture for the Kibana server that enables a totally awesome plugin architecture that we\u2019ll leverage to take Kibana, and other Elasticsearch-enabled (and enabling!) apps to the next level. Check out the write up over on the . It's like looking into the future! Also, we: Once again is my hero: holds so much promise for usability & query optimization!\u2014 Rashid Khan (@rashidkpc) See You Next Week!Did you know? Elasticsearch and Apache Lucene, Logstash and Kibana all have weekly updates published to the Elastic blog.We'll bring you the newest, mind-blowing stuff in next week's . \n"}<br>{"index": {"_id": 1041}}<br>{"title":"Opower(ing) Energy Efficiency with Elastic","seo_title":"","url":"\/blog\/opowering-energy-efficiency-with-elastic","author":{"name":"Haley Eshagh"},"date":"May 21, 2015","category":"User Stories","locales":"","content":" It\u2019s not every day we think about our energy consumption. Do you know what you paid on your last electricity bill? Or what your thermostat is set to right now? Less often, we think about how to reduce it \u2014 and even then, how to take action. Opower is a company that has made a business out of it. In fact, they\u2019ve helped utility companies help their customers (i.e., you and me, the energy consumer) save over 4 terawatt-hours, roughly the equivalent of taking San Francisco off the power grid for an entire year. So what does Elastic have to do with Opower? Well, a few months back, we were bumbling around the Internets (like you do) looking for cool uses of our software, and came across an from Opower engineer Ben Siemon, describing their use of Elasticsearch. We had to know more. A few phone calls later, Ben and his team invited us for a visit. We packed up our gear, jumped on a plane, and rolled into the Opower offices in Arlington, VA, ready to record. One by one, we got the full story from the developers who work with Elasticsearch every day to build and maintain their internal segmentation tool and UI, Utonium. (, if you're curious.) Utonium puts data and insight into the nontechnical hands of Opower employees who then decide what type of energy advice will have the most impact on given segments of a utility company\u2019s customer population. I won\u2019t go into all of the details (that\u2019s what the video above is for), but will note that throughout the process of filming the Opower team, it was clear that they\u2019re on a mission to make the world a better place. Yes, that sounds clich\u00e9, but it\u2019s honest. Currently, we only have one planet to call home, and we\u2019re limited to the resources it provides. If it\u2019s possible to leverage the power of data to use those resource more wisely, the more power to Opower. So, sit back and relax for a few minutes as Opower shares their Elasticsearch story. And, to all the Opower folks out there, a tip of the hat to you \u2014 keep up the good work. \n"}<br>{"index": {"_id": 1042}}<br>{"title":"This Week in Elastic: Watcher Beta goes public","seo_title":"","url":"\/blog\/this-week-in-elastic-2015-05-20","author":{"name":"Leslie Hawthorn"},"date":"May 20, 2015","category":"","locales":"","content":" Welcome to ! In this weekly round up post, we bring you news on all aspects of the ELK Stack, including updates on Elasticsearch, Logstash and Kibana development, tips and tricks and upcoming events. Proud to have my second PR into Elasticsearch. Minor changes, but the community has been great and makes me want to contribute more\u2014 Nick Canzoneri (@nick_canz) Elastic News Useful blog posts, how tos, tutorials\u00a0and articles\u00a0from the wide world of all the ELK stack ecosystem. Just announced: Beta (alerting for ) goes public. Try it today! \u2014 elastic (@elastic) Slides and Videos Slides from my talk at on Migrating from Hibernate Search to Elasticsearch \u2014 Christian Strzadala (@cstrzadala) Slides from my , Logstash & Kibana talk at last week: \u2014 Robin Moffatt (@rmoff) Where to find Us On tonight at 7 PM: LAX meetup (Venice, CA) on logging AWS Cloudwatch & Cloudtrail data. RSVP now: \u2014 Leslie Hawthorn (@lhawthorn) We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking about the ELK stack\u00a0or hosting a meetup, Algeria will take the stage at Voxxed Days Algiers to present An Introduction to the ELK Stack. This first ever conference takes place May 23, and Samir's talk is on for 2:00 PM. AustriaThe .NET Community Austria Meetup will get together on June 11 to talk all about the ELK stack. to save your seat. Canada France During 2015, will show us how to add to legacy applications in a blink ! \u2014 RivieraDEV (@RivieraDEV) Germany IrelandJoin Mark Harwood for an expert level session at NoSQL Matters Dublin on . The conference takes place on June 4. Israel We've got dueling meetups in Tel-Aviv Yafo on May 26: JapanPlease join all members of Elastic's team in Japan at in Tokyo on June 3-5. We will have a booth in the exhibits hall and will be very happy to answer any questions you may have. The NetherlandsTechnical Expert Aur\u00e9lien Foucret of talks about ElasticSearch at , more info: \u2014 Meet Magento NL (@mm15nl) Poland will take the stage at 6:30 PM on May 26 to talk Beyond the Basics with Elasticsearch at the . The event runs May 25-26 in Warsaw. (PS - We've also heard a rumor that the organizers will be offering Schema-Free beer on Elastic. Raise a glass with Honza if we're right!) Spain Join for the next Elasticsearch Barcelona Meetup on May 21, where you'll learn all about Moving to Production with Elasticsearch: Best Practices. to save your seat. SwedenThe Stockholm Elasticsearch Meetup will get together on May 27 to hear about two use cases. to save your seat. SwitzerlandThe Elasticsearch Zurich Meetup group will convene on May 27 to hear about Elastic's security product, Shield. to attend. United Kingdom South Wales Elasticsearchers: a meetup with a talk by Honza Kr\u00e1l , Elasticsearch developer: All welcome. \u2014 DjangoCon Europe (@DjangoConEurope) United States - East United States - West The Elastic family: Big data search, discovery and analytics (p 20-22) - by Christoffer Vig \u2014 Found by Elastic (@foundsays) Where to Find You \u00a0If you're a regular reader, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to\u00a0 ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1043}}<br>{"title":"Watcher Beta Goes Public! You Know, For Alerting...","seo_title":"","url":"\/blog\/watcher-beta-goes-public-you-know-for-alerting","author":{"name":"Uri Boness"},"date":"May 20, 2015","category":"News","locales":"","content":" Today we\u2019re delighted to release the first public beta of \u2013\u00a0our commercial alerting and notification product. In the same spirit of Shield, Watcher is a standalone plugin for Elasticsearch. Elasticsearch enables you to extract invaluable knowledge and insights from changes in your data, in realtime. But with the fast moving markets we all operate in today, it is not enough. In order for you to stay ahead of the game, you also need to do something with that knowledge \u2013\u00a0take actions that will directly translate to tangible values. And act fast. Act at realtime. This is where Watcher complements Elasticsearch. While with Elasticsearch alone you need to be \u201cproactively proactive\u201d when it comes to analyzing your data, Watcher enables you to be \u201creactively proactive.\u201d Hmm\u2026 what? Yes! With Elasticsearch alone you need to continually be there to run the analytics, interpret the results and act on them. With Watcher that is no longer the case. Watcher will monitor the data for you, act on the changes and\/or notify you about important events \u2013 freeing you up to focus on other important tasks, while letting you stay ahead of the game. Here are a few examples of tasks you can define in Watcher: Watcher was designed to serve all the scenarios above and many more. And we\u2019re very eager to see all the different use cases you use it for. Next, I\u2019ll show how you\u2019d go about using Watcher. But first, if you haven\u2019t registered to the beta program, don\u2019t miss out and .\u00a0Once registered, you will receive the installation instructions by email, and as you will find out, installing Watcher is as easy as installing any other Elasticsearch plugin. How do I work with Watcher?Watcher adds a new set of APIs to Elasticsearch to manage . It\u2019s probably best to explain the concept of a with an example. In this example, suppose you are indexing your web traffic logs in Elasticsearch. Let's first create a index and enable the _timestamp mappings, such that a timestamp will be associated with each log event that we\u2019ll index. PUT logs { \"mappings\" : { \"event\" : { \"_timestamp\" : { \"enabled\" : true } } } } Now that we have the logs index ready, let\u2019s add our first . The immediate thing that comes to mind in this setup is the ability to pick up on errors in your logs as close to realtime as possible. In other words, you would like to watch newly indexed logs and look for any log events with an error status. The following snippet registers a new watch that searches for any errors in the log entries in the last 5 minutes: PUT \/_watcher\/watch\/error_status { \"trigger\" : { \"schedule\" : { \"interval\" : \"5s\" } }, \"input\" : { \"search\" : { \"request\" : { \"indices\" : [ \"logs\" ], \"body\" : { \"query\" : { \"filtered\" : { \"query\" : { \"match\" : { \"status\" : \"error\" }}, \"filter\" : { \"range\" : { \"_timestamp\" : { \"from\" : \"now-5m\" }}} } } } } } } } If you look closer at the watch definition above, you\u2019ll see that we defined this watch with a schedule such that it will be executed every 5 seconds (I chose 5 seconds here just for the sake of the example, a more realistic value would have been 5 or 10 minutes). The input loads data for the watch (what we like to refer to as ). It does that by executing a search request over the index, and looks for events in the last 5 minutes with an status. Once this watch is added to Watcher, the schedule will immediately kick in and start ticking. Every 5 seconds the watch will execute and will search for errors. Although it looks like nothing is happening, in the background Watcher records all these executions in indices. And just like any other indices in Elasticsearch, you can explore them using the normal search API. Executing the following search request will return the last 10 watch executions: GET \/.watch_history*\/_search { \"sort\" : [ { \"execution_result.execution_time\" : \"desc\" } ] } OK\u2026 Searching for errors and then searching the watch history is a good start, but that\u2019s just the beginning. It\u2019s very likely you want to do something with the search results - find out if any errors occurred, and if they did, do something about it. So let\u2019s change our watch to do exactly that: PUT \/_watcher\/watch\/error_status { \"trigger\" : { \"schedule\" : { \"interval\" : \"10s\" } }, \"input\" : { \"search\" : { \"request\" : { \"indices\" : [ \"logs\" ], \"body\" : { \"query\" : { \"filtered\" : { \"query\" : { \"match\" : { \"status\" : \"error\" }}, \"filter\" : { \"range\" : { \"_timestamp\" : { \"from\" : \"now-5m\" }}} } } } } } }, \"condition\" : { \"compare\" : { \"ctx.payload.hits.total\" : { \"gt\" : 0 } } }, \"actions\" : { \"log_event\" : { \"logging\" : { \"text\" : \"found {{ctx.payload.hits.total}} errors in the logs\" } } } } We added two new elements to our watch:\u00a0a and . The condition is a check that is evaluated over the watch payload. In our case, the payload is the search results and the condition checks if any errors were found. When the condition evaluates to , the configured actions are executed. Here we defined a very simple action. This simple action logs text to the standard Elasticsearch logs (use the logging action at development time for testing and debugging). You probably noticed that the logged text is actually a (Mustache) template, which allows us to include the number of hits in the log messages. As you learn more about Watcher you will see that many constructs in Watcher accept templates, making Watcher highly customizable. Even now, after the watch was updated, the action is still not executing. The reason for this is simply because there are no log events with an error status. You can verify that the condition has not been met by simply searching the watch history for a watch record with a \u201cmet\u201d condition that was executed in the last 5 seconds: GET \/.watch_history*\/_search { \"query\" : { \"bool\" : { \"must\" : [ { \"match\" : { \"execution_result.condition.met\" : true }}, { \"range\" : { \"execution_result.execution_time\" : { \"from\" : \"now-5s\"}}} ] } } } Running the above will return no results. Now, let\u2019s put a new event, this time with an error status: POST \/logs\/event { \"status\" : \"error\" } Within 5 seconds, you should see the log message in your Elasticsearch logs. If you search the watch history again, the results of the recent watch executions will be returned: GET \/.watch_history*\/_search { \"query\" : { \"bool\" : { \"must\" : [ { \"match\" : { \"execution_result.condition.met\" : true }}, { \"range\" : { \"execution_result.execution_time\" : { \"from\" : \"now-10s\"}}} ] } } } Congrats! You\u2019ve successfully created your first Watch. What\u2019s in a Watch?By now you probably have a good feeling what a Watch is. Each Watch has its own purpose and lifecycle, and its execution is defined by a well-defined set of constructs: , , and . Each of these constructs represents an abstraction with potentially many different implementations. The goal with Watcher was to build a system that not only naturally integrates with Elasticsearch, but is also extensible and prepared to serve a vast variety of use cases \u2013 from the simplest to the most complex requirements one might have. For the first public release we carefully chose an initial set of constructs that we believe will provide immediate value to you. You can view these constructs as the most basic building blocks for your watches: Where to now?As mentioned, if you haven\u2019t done so yet, you can register \u00a0to get access to the beta program. We highly recommend you read the \u00a0to learn more about Watcher and try it out. We\u2019re very curious to see how you are going to use it and what are you going to use it for, and we would absolutely love to get your feedback. For this we have set up a dedicated \u00a0in our forums. Happy watching! \n"}<br>{"index": {"_id": 1044}}<br>{"title":"This Week in Elasticsearch and Apache Lucene: Hunting Tricky Apache Lucene bugs","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-and-apache-lucene-2015-05-19","author":{"name":"Alexander Reelsen"},"date":"May 19, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsCheck out Mike McCandless\u2019 latest deep dive\u2026\"Hunting Tricky Apache bugs.\" \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene \n"}<br>{"index": {"_id": 1045}}<br>{"title":"How to check Logstash's pulse","seo_title":"","url":"\/blog\/how-to-check-logstashs-pulse","author":{"name":"Aaron Mildenstein"},"date":"May 19, 2015","category":"Engineering","locales":"","content":" Have you ever wondered if Logstash was sending data to your outputs? There's a brand new way to check if Logstash has a \"pulse.\" Introducing the It\u2019s bundled with Logstash 1.5 so you can start using it immediately! Why? Logstash currently has a single pipeline. All events generated by inputs travel through the block, and then out of Logstash through the block.Even if you have multiple outputs and are separating events using conditionals all events pass through this single pipeline. If any one of your outputs backs up, the entire pipeline stops flowing. The heartbeat plugin takes advantage of this to help you know when the flow of events slows, or stops altogether.How?The heartbeat plugin sends a message at a definable interval. Here are the options available for the message configuration parameter:ExamplesBe sure to assign a to your heartbeat events. This will make it possible to conditionally act on these events later on.\"ok\" MessagePerhaps you only want to know that Logstash is still sending messages. Your monitoring system can interpret an \"ok\" received within a time window as an indicator that everything is working. Your monitoring system would be responsible for tracking the time between \"ok\" messages.I can send the default \"ok\" message every 10 seconds like this:input { heartbeat { interval => 10 type => \"heartbeat\" } # ... other input blocks go here } The events would look like this:{\"message\":\"ok\",\"host\":\"example.com\",\"@version\":\"1\",\"@timestamp\":\"2015-03-18T17:05:24.696Z\",\"type\":\"heartbeat\"} {\"message\":\"ok\",\"host\":\"example.com\",\"@version\":\"1\",\"@timestamp\":\"2015-03-18T17:05:34.696Z\",\"type\":\"heartbeat\"} {\"message\":\"ok\",\"host\":\"example.com\",\"@version\":\"1\",\"@timestamp\":\"2015-03-18T17:05:44.695Z\",\"type\":\"heartbeat\"} Epoch timestampPerhaps your monitoring system uses unix timestamps to track event timing (like Zabbix, for example). If so, you can use the epoch timestamp in the clock field to calculate the difference between \"now\" and when Logstash generated the heartbeat event. You can calculate lag in this way. This may be especially useful if you inject the heartbeat before events go into a broker, or buffering system, like Redis, RabbitMQ, or Kafka. If the buffer begins to fill up, the time difference will become immediately apparent. You could use this to track the elapsed time--from event creation, to indexing--for your entire Logstash pipeline.This example will send the epoch timestamp in the field:input { heartbeat { message => \"epoch\" interval => 10 type => \"heartbeat\" } # ... other input blocks go here }The events would look like this:{\"clock\":1426698365,\"host\":\"example.com\",\"@version\":\"1\",\"@timestamp\":\"2015-03-18T17:06:05.360Z\",\"type\":\"heartbeat\"} {\"clock\":1426698375,\"host\":\"example.com\",\"@version\":\"1\",\"@timestamp\":\"2015-03-18T17:06:15.364Z\",\"type\":\"heartbeat\"} {\"clock\":1426698385,\"host\":\"example.com\",\"@version\":\"1\",\"@timestamp\":\"2015-03-18T17:06:25.359Z\",\"type\":\"heartbeat\"} Sequence of numbersThis example makes it easy to immediately check if new events are occurring because the clock will continuously increase.input { heartbeat { message => \"sequence\" interval => 10 type => \"heartbeat\" } # ... other input blocks go here }The events would look like this:{\"clock\":1,\"host\":\"example.com\",\"@version\":\"1\",\"@timestamp\":\"2015-03-18T17:08:13.024Z\",\"type\":\"heartbeat\"} {\"clock\":2,\"host\":\"example.com\",\"@version\":\"1\",\"@timestamp\":\"2015-03-18T17:08:23.027Z\",\"type\":\"heartbeat\"} {\"clock\":3,\"host\":\"example.com\",\"@version\":\"1\",\"@timestamp\":\"2015-03-18T17:08:33.029Z\",\"type\":\"heartbeat\"}OutputNow let's add a conditional to send this to our monitoring system, and to our other outputs:output { if [type] == \"heartbeat\" { # Define the output block for your monitoring system here } else { # ... other output blocks go here } } Of course, if you do want your heartbeat messages to be indexed alongside your log data, you are free to do so.ConclusionThe new heartbeat plugin provides a simple, but effective way to monitor the\u00a0availability of your Logstash instances right now. We have big plans for the future, though. \u00a0Take a look at our !In the future we plan to have a full API, complete with visibility into the pipeline, plugin performance, queue status, event throughput and so much more. \u00a0We are super excited to bring these improvements to you!Happy Logstashing! \n"}<br>{"index": {"_id": 1046}}<br>{"title":"Elasticsearch in Big Data Predictive Analytics at Predikto","seo_title":"","url":"\/blog\/elasticsearch-at-predikto","author":{"name":"Roy Russo"},"date":"May 19, 2015","category":"User Stories","locales":"","content":" Predikto processes large volumes of data for asset-intensive industries in order to predict equipment failure. This information allows customers to pro-actively apply prescriptive maintenance, thereby avoiding downtime. The Predikto Enterprise Platform combines applies advanced data science and machine learning techniques and algorithms for customers across industries such as oil & gas, rail, fleet, manufacturing, and data gathered from the Industrial Internet of Things. It processes large volumes of data from disparate sources in heterogeneous formats, something that Elasticsearch is well-suited to store and query on. Elasticsearch is a key component of the Predikto Enterprise Platform. Horizontal scalability, product maturity, and tooling all factored in the decision to adopt Elasticsearch at Predikto. Mapping Distributed AssetsGeoJSON support is an important feature of Elasticsearch. For example, a railroad company may want to predict asset failure on moving locomotives, train cars, and even train car doors to prevent unnecessary stops that cost millions of dollars annually. Predikto factors the location of the asset (sometimes an actively moving asset like a train or fleet vehicle) and correlates the location with weather forecast data also stored in Elasticsearch, as weather often plays a role in device failure. Since Elasticsearch supports the GeoJSON standard out-of-the-box, it allowed Predikto to standardize sensor and device location data in GeoJSON format as well. Now, correlating latitude and longitude coordinates with weather data is a trivial matter. The other benefit to having all location data standardized with GeoJSON and stored in Elasticsearch was that it made visualization simple. The Predikto user interface includes a large map, allowing users to visualize their assets as they move in real-time and highlight those assets that are likely to fail. Heavy use of the aggregations API enables a clean way to do time-series modeling,especially with features like terms, date_histogram, and top hits APIs. Standardizing the format of geo-location data helped remove the custom transformation of \u00a0location data for the user interface and the predictive analysis process. Integrating Elasticsearch with Spark for big data ETLThere is no widely-adopted standard format for sensor data, although many IoT vendors are working on one. This means that the massive amounts of data flowing in to the Predikto system are in any manner of format, from CSV, TSV, log line, xml, and even some legacy formats that defy logic at first glance. All of this data must be transformed into a standard format in order for our machine learning algorithms and predictive analytics models to process. This is where Apache Spark comes in. Being able to process large batches of data in memory, while reading and writing from and to Elasticsearch using the es-hadoop library maintained by Elastic enabled Predikto to have smooth ETL processes that improved performance from the previous, disk-bound ETL process by a factor of 10. Massaging the original data into the Predikto standard format often requires substantial processing power. In this instance, Elasticsearch, as a primary datasource, is having to perform heavy read operations, and finally, heavy write operations from dozens of Spark workers asynchronously during the ETL process. The last point above helped remove a stumbling-block we ran in to when writing asynchronously from many Spark workers to Amazon S3. Because of S3\u2019s eventual-consistency object store, the Spark master was unable to combine to worker-written file parts, as they were not immediately visible, thus causing the entire Spark process to fail. In the past, we remedied the issue by saving the output to a mounted EBS volume, and then copying the file to S3. This was error-prone and not performant at scale. Instead, we make heavy use of the bulk API to insert documents from Spark workers now in to Elasticsearch. In the end, the Predikto standard format is a which fits nicely with our use of Elasticsearch. Since the format is standardized, so are many of the Elasticsearch mappings, templates, analyzers, and tokenizers. This makes on-boarding new sensor data a trivial manner, thus differentiating us from many of our labor-intensive competitors. Elasticsearch and Predikto\u2019s dynamic reporting dashboardsElasticsearch solved two problems for us with Spark. The Predikto user-interface features a bird\u2019s eye view of customers\u2019 distributed assets using the data stored in Elasticsearch. Location visualization is made possible using LeafletJS, and Elasticsearch. Since LeafletJS and Elasticsearch both support the GeoJSON standard, point and aggregate plotting on the map is a trivial manner, facilitated by the elasticsearch-js SDK. In addition to a mapping view, the Predikto interface allows users to analyze data in a myriad of different ways: plotting time-series data, grouping attributes, and even drilling down into any specific device\u2019s current state, health score, and probability of failure. Dynamic querying capabilities come natural to Elasticsearch, and not having to micro-manage a query plan and design tables in advance allows Predikto ultimate flexibility in designing new features and reports for the user interface. However, it\u2019s important to add that Elasticsearch would likely have not been adopted for use in advanced reporting at Predikto, if it were not for the recently-added aggregations API. Aggregations are a fundamental part of our user interface, as customers are monitoring real-time asset health across hundred or thousands of pieces of equipment. Elasticsearch has proven to be an asset in our microservice-based big data architecture, allowing Predikto to scale smoothly in infrastructure and personnel. The simple and well-documented Elasticsearch APIs have made it easy for us to access to data in different ways and make Elasticsearch a core part of our run-time and reporting software. Scaling Elasticsearch affordably As a startup engineering team, time is at a premium and never our friend. We needed a document store that fit all of the above needs, yet was easy to implement and scale with. We wanted to avoid an anti-pattern: many of the solutions we evaluated, although simple to get started with, would become an anchor as we scaled. Elasticsearch has a great reputation and a variety of large scale deployments that vouch for its ability to scale gracefully. The Elasticsearch AWS plugin helped get us started in avoiding split brain scenarios and in making node discovery a breeze. Now, we host several clusters across several AWS regions - some production, and some for testing and staging new releases. We implemented many of the well known optimization best practices discussed on the Elasticsearch blog and published articles, such as JVM tuning (set ES_MIN_MEM and ES_MAX_MEM equally), enabling mlockall, and adjusting index flushing timing. JVM tuning is an art, better left to experts, but we happen to have plenty of those on hand. Network topology was also somewhere we made adjustments, by employing client nodes to act as load balancers across the cluster. Although much of the Elasticsearch operations are bulk writes, even in the face of peak time usage, the most complex of queries will return in sub-second time. Over time, as we have added more sensor data, our cluster has scaled to several dozen nodes, backed by large EBS volumes mounted on EC2 instances. Adding new nodes to the cluster has proven simple and efficient with Elasticsearch\u2019s autoscaling capability of re-distributing shards across the cluster. This is only the beginning As we build out new features in the reporting dashboards and grow our customer base, our use of Elasticsearch today is only just beginning. We foresee a heavier utilization of Elasticsearch at every level. Operating at sensor-data scale is no easy task, but Elasticsearch removed many of the headaches associated with early-stage scaling of our architecture, and we see it as an integral part of our processes over the next billion documents and thereafter. \n"}<br>{"index": {"_id": 1047}}<br>{"title":"Where in the World is Elastic: Gluecon Colorado & Voxxed Days Algiers","seo_title":"","url":"\/blog\/2015-05-18-where-in-the-world-is-elastic","author":{"name":"Livia Froelicher"},"date":"May 18, 2015","category":"","locales":"","content":" Welcome to\u00a0 We'll be all over the world this week for our meetups and events, from Denver\u00a0to Taiwan.\u00a0Read on to find out if we'll be near you:Upcoming EventsMay 20-21: Stop by our\u00a0booth at\u00a0 in Broomfield, Colorado. Aaron Mildenstein will\u00a0be giving a talk titled on Wednesday, May 20th in Track 2, from 3:45 PM- 4:15 PM, make sure to check it out!May 23: Samir Bennacer will be giving an at from 2:00 PM- 3:00 PM in Hall: Salle Algiers.Upcoming Meetups May 18: May 18: May 19: May 19: May 20: May 20: May 20: May 20: May 20:May 21: May 21: May 18: May 19: That's it for this week.\u00a0Stay tuned for Elastic happenings next week - there's much to come!\u00a0 - The Elastic Team P.S.:\u00a0 \u00a0if you're interested in hosting a meetup or are giving a talk about Elasticsearch, Logstash or Kibana\u00a0\u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 1048}}<br>{"title":"ELK Stack Crossing: Where to find the ELK in OpenStack Summit","seo_title":"","url":"\/blog\/openstack-summit-elk","author":{"name":"Robyn Bergeron"},"date":"May 18, 2015","category":"","locales":"","content":" If you're a fan of the ELK stack and you happen to be in Vancouver, British Columbia this week for the , good things are coming your way! As it so often happens with well-loved open source projects, enthusiastic community members find ways to marry the technologies of the projects they love and make them work together. The OpenStack project community is no exception here, and the numbers of ways in which various pieces of the ELK stack are being incorporated in myriad ways with OpenStack -- either as parts of deployments, incorporated in OpenStack projects, used as part of the OpenStack project infrastructure, and likely other ways I haven't heard about just yet.\u00a0 What does this mean? As an attendee, there are a variety of options this week at the OpenStack summit to learn and discuss how the ELK stack can work with OpenStack. Hooray! And to save you, lovely reader, from having to scroll endlessly through the incredible schedule of amazing content to choose from this week, I've put together your quick guide to finding the ELK love you want to hear about while at Summit. Birds of a Feather As the author of this post, I'll admit that I may be a bit biased: I definitely think you should come to the ELK Stack Birds-of-a-Feather session this week -- because I will be your lovely and gracious host. Titled \"\" -- we'll be gathering in the East building on Wednesday, May 20th, from 3:30 - 4:10pm. Operating in a traditional Birds of a Feather fashion, the content of this session very much depends on your participation!\u00a0 One of the great things about bringing people together at open source conferences is that it enables opportunities for collaboration. And even with\u00a0so many different and useful ways to combine the ELK stack and OpenStack, chances are that if you have an idea in mind, others may be as well. If you're interested in seeing the ELK stack be part of the Murano application catalog, or looking for Heat templates for the ELK stack, or want to figure out the best practices for shipping your logs in an OpenStack deployment, this is the place to be! So: Bring your questions, your ideas, your problems you're trying to solve -- let's bring people together, and make magic happen. Also: If you're looking for Logstash or Elasticsearch stickers.... I hear they'll be making an appearance here. So be sure to swing by. Wednesday, May 20: In addition to the aforementioned BoF, the following sessions are also running on Wednesday, and thankfully, not overlapping with each other (thanks, awesome organizers!): :\u00a01:50 - 2:20pm This session, presented by Michael Factor and Dmitry Sotnikov of IBM's Haifa Research Lab, will be showing how they've used open source tools (including Elasticsearch, Logstash, and Kibana!) to identify performance bottlenecks in Swift. : 5:20 - 6:00pm Andy McCrae\u00a0of the Rackspace Private Cloud team\u00a0will be sharing tips from the operator's point of view\u00a0on making logs useful and accessible, even in an environment with numerous OpenStack\u00a0services running across many hosts -- and examples of how to do it with the ELK stack. Thursday, May 21 : 9:00-10:30am Jordan Callicoat and Christopher Woodward of Rackspace will help you eliminate the late-week conference blues of missing doing actual things on your computer with this interactive workshop. Learn how to deploy the ELK stack in an OpenStack environment, and get some hands-on experience using the Elasticsearch API and Kibana to get information about\u00a0users, instances, and services in your OpenStack deployment.\u00a0 : 9:50-10:30am Gabriel Hurley will be discussing the universe of possibilities around feeding OpenStack data directly into Elasticsearch -- and the types of problems to be solved in doing just that. He'll also be covering how to integrate Elasticsearch into your cloud, sharing example queries, and sharing upcoming challenges in embarking on such a project. Be sure to say hi! With such a great schedule, I know it's hard sometimes to be able to make all the sessions you'd love to attend. If you've got a great OpenStack + ELK Stack story to share, have a question, or just want to say hi, please reach out to me -- I'll be here all week! It's easiest to say hi on Twitter (I'm ), or you're welcome to send me a mail. (No graceful way to write it without being forever spammed, so this is as pretty as it gets: robyn at elastic dot co!)\u00a0 Looking forward to meeting the herd of ELK fans at OpenStack Summit this week! \n"}<br>{"index": {"_id": 1049}}<br>{"title":"Hunting Tricky Apache Lucene Bugs","seo_title":"","url":"\/blog\/lucene-tricky-bugs","author":{"name":"Michael McCandless"},"date":"May 18, 2015","category":"Engineering","locales":"","content":" Recently we tracked down two particularly tricky Lucene backwards compatibility bugs ( and ), serious enough to trigger a . The series of events leading to these bug fixes is quite illustrative, not only in how seriously we take index corruption issues (no matter how rare) but also in how randomized tests and alert us to potential issues and how debugging tricky test failures in healthy open source projects works these days. The story begins with , noticing a spooky-looking test failure in one of , asking me to dig. The test in question, , is a great test: it unpacks old indices from pre-built ZIP files across all prior Elasticsearch releases and then verifies that the latest version of Elasticsearch starts up and searches and indexes against these indices properly. Almost always the test passes, but every so often it would fail, with a scary exception showing the index had somehow become corrupt. The corruption seemed to happen when Lucene 4.10.3 first kissed a 3.x index ('s first commit to the index).Like Lucene, Elasticsearch tests are heavily randomized, but provide a reproducible seed to recreate the failure. Unfortunately, when I ran the test\u00a0with this seed, with the same Java version and JVM options, it\u00a0refused to fail.\u00a0Grrr.This sometimes happens, e.g. if the test relies on how concurrent threads are scheduled, so I fired up a dedicated Python script to \"beast\" the test. The script efficiently runs a single test case over and over, bypassing the normally costly Maven dependency checking and compilation steps and just executing the test directly across multiple JVMs. Still, it would not fail for me, after more than 24 hours of beasting. Why not? Unable to reproduce the failure, but still seeing it occasionally fail in Jenkins, we retrenched. First, multiple developers stared at the , and we uncovered which could possibly explain the failure we were seeing: at least it produced the same exception.\u00a0Excited that we had possibly found the issue, we to track it. But then, on further digging, Elasticsearch was not re-using index shard directories in this test, so that could not explain the failure.\u00a0Still, this was a nice separate bug to uncover and fix and this shows a common pattern in open-source software: a test failure, or a new bug, causes sudden excitement and scrutiny by multiple developers on the code in question, and this often uncovers further issues to fix and the project moves forward.\u00a0We saw a similar pattern with , also fixed in Lucene 4.10.4. Retrenching again, we fell back on looking for any patterns to the 3 or 4 failures we had seen, and one thing we noticed is it was always the 0.20.6 test index (Lucene 3.6.2) that failed, despite other 3.x indices in the test. Why? One unusual thing about that particular test\u00a0index was that it was\u00a0much larger than the others, containing many more segments, which confused me, and I asked about this on the issue. quickly replied, explaining that he had regenerated that one index to make it \"beefier\"\u00a0to better test another issue he had fixed in the past. Perhaps something unique about this index tickled a bug that the other indices didn't? Simon also suggested turning on verbose file deletion logging for this test, a feature to Elasticsearch for precisely this kind of situation. Then we waited for the next failure, which came a couple days later, and it clearly indicated where Lucene was incorrectly deleting the file! Armed with that important information, and then going back and staring at that code some more, we finally isolated the situation that could cause the corruption: it only happens on Lucene 4.x\u2019s first kiss to a 3.x index, if concurrent merges are also running and if the threads are scheduled by the JVM \"just right\". This explains why only the 0.20.6 index would fail: it was the only 3.x index with many segments that needing merging! \u00a0It also explains why the test would not easily reproduce: it relied on the specific timing of concurrent merges. Finally, we were able to make a small dedicated Lucene\u00a0test case\u00a0showing the corruption, and a simple fix for the bug. Because the bug is serious (causes corruption), and there were also plenty of other good bug fixes pending for 4.10.4, we then triggered a new Lucene release, now folded into\u00a0Elasticsearch releases 1.4.5 and 1.5.0. \n"}<br>{"index": {"_id": 1050}}<br>{"title":"Kurrently in Kibana - May 18, 2015","seo_title":"","url":"\/blog\/kurrently-kibana-2015-05-18","author":{"name":"Robyn Bergeron"},"date":"May 18, 2015","category":"Kurrently in Kibana","locales":"","content":" Welcome to , your source for keeping up with the Kibana project. With information on project releases, work in progress, and learning resources, you can on this weekly update to let you know about the\u00a0latest\u00a0Kibana goodness coming your way! Data loaded in via Logstash and analyzed with Kibana. is in ELK stack heaven. \u2014 Michael Rainey (@mRainey) Kibana 4.1: Getting Closer... The team has been\u00a0plugging away at the last few , mostly trying to get some tile map stuff cleaned up so we can merge it. Lately, we: Kibana Forum Just like the other projects here at Elastic, Kibana now has a forum for discussions and questions that was recently launched.\u00a0This awesome new service lets us keep Github for getting work done, while fostering a community of Kibana experts to kick around questions, ideas and solutions in a totally async and persistent fashion. , and enjoy! Elasticsearch Stuff We\u2019re Giddy About: _path. We\u2019ve bandied this idea around for over a year and it's almost ready to use. Pull: Purpose: `path` allows us to specify what data we want from a request in a super granular way. For example, let\u2019s say\u00a0is retrieving unique web requests over time: a\u00a0date_histogram agg, with a cardinality agg inside of it. ``` curl -XGET 'localhost:9200\/logstash-*\/_search\u2019 -d \u2018 { \u201caggs\u201d: { \u201c2\u201d: { \u201cdate_histogram\u201d: { \u201cfield\u201d: \u201c@timestamp\u201d, \u201cinterval\u201d: \u201c30s\u201d, }, \u201caggs\u201d: { \u201c1\u201d: { \u201ccardinality\u201d: { \u201cfield\u201d: \u201crequest\u201d } } } } } } ``` We\u2019re going to get back something like this for every bucket. So, you know, like 1000 of these. ``` { \"key_as_string\" : \"2015-04-25T07:06:30.000Z\u201d, \/\/ We don\u2019t need this \"key\" : 1429945590000, \/\/ Oooo important \"doc_count\" : 6716, \/\/ Nope \"1\" : { \"value\" : 441 \/\/ Yep } }, ``` So this thing was 4 keys, only 2 of which we actually need, and one of them is a big long string. Move enough of those over the wire and it's a whole lot of data. Not to mention the memory considerations of parsing all those and keeping around a big honking object on which we\u2019ll only ever access half the properties. Ok, now let's bring into the fray: ``` curl -XGET 'localhost:9200\/logstash-*\/_search?_path=aggregations.2.buckets.1,aggregations.2.buckets.key -d [All that other stuff from above] ``` We get back a nice clean result with only the stuff we need. ``` { \"key\" : 1429945740000, \"1\" : { \"value\" : 1 } } ``` It's something like a 68% reduction in data moved over the wire. And it's not just the search API -- it applies to every API. If you need to do something like enumerate the hostnames of every node in your cluster, it's more like a 99% reduction. Sweet. My first data visualization in with and . Exchange message's send and received \u2014 Farhaz Hofman (@farhaz) See You Next Week!Did you know?\u00a0Elasticsearch and Apache Lucene, Logstash and Kibana all have weekly updates published to the Elastic blog.\u00a0We'll bring you the newest, stuff in next week's . \n"}<br>{"index": {"_id": 1051}}<br>{"title":"The Logstash Lines: Logstash 1.5 is here!","seo_title":"","url":"\/blog\/logstash-lines-2015-05-15","author":{"name":"Shaunak Kashyap"},"date":"May 15, 2015","category":"The Logstash Lines","locales":"","content":" Welcome back to ! In these weekly\u00a0posts, we'll share the latest happenings in the world of Logstash and its ecosystem. After 500+ commits, 1.5.0 GA is released. Details on integration & more here \u2014 elastic (@elastic) The highlights of this release include: Read more in Many thanks to our\u00a0community contributors and the amazing Logstash team at Elastic. Here are some of their happy faces after the 1.5 release: Logstash remote release party with the team. <3 \u2014 @jordansissel (@jordansissel) That's this week in . Come back next week for more Logstash news! \n"}<br>{"index": {"_id": 1052}}<br>{"title":"Logstash 1.5.0 GA released","seo_title":"","url":"\/blog\/logstash-1-5-0-ga-released","author":{"name":"Suyog Rao"},"date":"May 14, 2015","category":"News","locales":"","content":" We are excited to announce the GA release of Logstash 1.5.0! 500 plus commits and 10 months in the making, this is one of our biggest releases. A big thank you to all our users for the many contributions, feedback, GitHub issues, and for trying out the pre-releases. Jump to our page to get going, or check the for details. HighlightsThe main themes of 1.5.0 are plugin management, performance improvements, and Apache Kafka integration. Here are the highlights: Plugins SeparationLogstash has a rich collection of over 165 plugins (inputs, filters, outputs, and codecs). With 1.5.0, we are taking a step closer to making plugin management even better for our users. We have added infrastructure to easily install, update, and remove plugins on top of Logstash. For example, to install the S3 output plugin: $LS_HOME\/bin\/plugin install logstash-output-s3 This has all the scoop about plugin changes.New pluginsAs we iterated on 1.5.0, the feedback we received for plugin changes was overwhelming. This is evident with the contribution of many new plugins -- Heartbeat input, CouchDB changes input, Slack input, RSS input, JMX input\u00a0just to name a few. Check out it is to create and publish plugins! Performance ImprovementsLogstash 1.5.0 is much faster. Let's highlight two areas where performance has gone way up: In this release, we have increased the throughput of the popular grok filter in some patterns by 100%. Put another way, you can process more data through Logstash when using the grok filter. In our benchmark testing, we compared throughput in 1.5.0 and 1.4.2 by processing 6.9 million entries of Apache Web access log lines using the grok pattern. Throughput in 1.5.0 increased from 34K events per second (eps) to 50K eps. Both tests were run on an eight-core machine with eight worker threads in Logstash. These tests we run with a single grok filter and measured throughput of events processed in the pipeline using a stdin input and stdout output. Please note that overall performance will vary with hardware and Logstash configuration used. We implemented JSON serialization and deserialization using the JrJackson library, which improved the throughput by over 100%. In our previously mentioned performance tests, we sent 500,000 JSON events (1.3KB in size) and measured a throughput increase from 16K eps to 30K eps. With events 45KB in size, throughput increased from 850 eps to 3.5K eps. Improved SecurityWe have improved the security of the Elasticsearch output, input, and filter by adding authentication and transport encryption support. For instance, with the HTTP protocol you can configure SSL\/TLS to enable encryption and HTTP basic authentication to provide a username and password while making requests. These capabilities will enable Logstash to natively integrate with the Elastic's security product. Apache Kafka IntegrationIn scaling Logstash deployments, can be used as an intermediate message buffer to store data between the shipping instances and indexing instances. In 1.5.0, we have added built-in support for the Logstash Kafka input and output plugin that was originally developed by . We added the codec and support to easily plug in your serialization\/deserialization mechanism. All this makes it easy to consume events stored in Kafka, enrich them, and analyze them using Elasticsearch, Logstash, and Kibana. Windows ExperienceThis release made many improvements for running Logstash and plugin-related infrastructure on Windows, which was degraded since the 1.4.2 release. We resolved issues related to initial setup and upgrade, and fixed important bugs in the file input plugin. DocumentationPreviously, Logstash documentation was hosted on , which made it cumbersome to find information when working with the rest of the ELK stack. We have moved documentation for 1.5.0 and all future releases to the Elastic website under the . Fixes\/Enhancements1.5.0 contains a number of important enhancements and bug fixes. A detailed list can be found in the . What's next?Though the team has been focused on 1.5.0 release in the last few months, it hasn't stopped us from plotting the next course for Logstash. We are really excited about the received from the Logstash community survey and can't wait to get started on the Logstash 2.0 . Stay tuned on our progress with our weekly updates! Feedback 1.5.0 today and let us know what you think. We hang out in IRC, so join us in #logstash on Freenode. You can also provide us contributions, suggestions, and feedback through , or ask questions on our . You can also tweet us at \n"}<br>{"index": {"_id": 1053}}<br>{"title":"This Week in Elastic: Watcher, alerting for Elasticsearch, is coming soon","seo_title":"","url":"\/blog\/2015-05-13-this-week-in-elastic","author":{"name":"Leslie Hawthorn"},"date":"May 13, 2015","category":"","locales":"","content":" Welcome to ! In this weekly round up post, we bring you news on all aspects of the ELK Stack, including updates on Elasticsearch, Logstash and Kibana development, tips and tricks and upcoming events. : You know, for Alerting (Coming Soon)...Get details & sign up for the webinar now \u2014 elastic (@elastic) Elastic News Useful blog posts, how tos, tutorials\u00a0and articles\u00a0from the wide world of all the ELK stack ecosystem. New article from one of the Found founders: A Dive into the Elasticsearch Storage \u2014 Found by Elastic (@foundsays) Slides and Videos Where to find Us If you're in Denver & interested in , come hear me on things I wish I'd known as a newbie ES app dev: \u2014 Shaunak Kashyap (@shaunak) We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking about the ELK stack\u00a0or hosting a meetup, Algeria will take the stage at Voxxed Days Algiers to present An Introduction to the ELK Stack. This first ever conference takes place May 23, and Samir's talk is on for 2:00 PM. Australia The Melbourne Search Users Group will meet up on May 19 for a talk from Movideo: Migrating from Hibernate Search to Elasticsearch. to save your seat. We're pretty sure our very own will be joining you, too! Canada Czech Republic Our very own will be on hand for Q&A on Elasticsearch in Prague on May 7. You can RSVP for this talk . France The Elasticsearch France Meetup returns to Paris on May 26. so you know when we open up RSVPs! During 2015, will show us how to add to legacy applications in a blink ! \u2014 RivieraDEV (@RivieraDEV) Germany Israel We've got dueling meetups in Tel-Aviv Yafo on May 26: The Netherlands Johan Guldmyr will host a talk on dCache and the ELK stack at the at 2:20 PM on May 19. The Workshop runs May 18-20 in Amsterdam. Poland will take the stage at 6:30 PM on May 26 to talk Beyond the Basics with Elasticsearch at the . The event runs May 25-26 in Warsaw. Portugal The Merge Lisbon Meetup Group will get together on May 14 to talk about the ELK stack. to hear from our very own Logstash engineering team member . Spain Join for the next Elasticsearch Barcelona Meetup on May 21, where you'll learn all about Moving to Production with Elasticsearch: Best Practices. to save your seat. Turkey Voxxed Days Istanbul is coming up on May 9. Join to learn all about Advanced Search for Your Legacy Application Using Elasticsearch. David at 11:30 AM. United Kingdom For folks in Cardiff, Wales, your welcome to attend our Elasticsearch Meetup hosted at DjangoCon EU. Make sure to pop by the conference to say hello to Honza Kral in the hallway track. runs May 31 - June 5. South Wales Elasticsearchers: a meetup with a talk by Honza Kr\u00e1l , Elasticsearch developer: All welcome. \u2014 DjangoCon Europe (@DjangoConEurope) United States - East United States - West Where to Find You \u00a0If you're a regular reader, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to\u00a0 ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1054}}<br>{"title":"This Week in Elasticsearch and Apache Lucene:Meetup: Scaling Elasticsearch & Autosuggest in Lucene","seo_title":"","url":"\/blog\/2015-05-12-this-week-in-elasticsearch-and-apache-lucene","author":{"name":"Michael McCandless"},"date":"May 12, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top News Polyglot meetup next Wed night two talks \"Scaling Elasticsearch & Autosuggest in Lucene\" \u2014 Tavis Rudd (@tavisrudd) Elasticsearch Core Apache Lucene Watch This Space , where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 1055}}<br>{"title":"Join the Conversation: Discuss.Elastic.Co","seo_title":"","url":"\/blog\/join-the-conversation","author":{"name":"Leslie Hawthorn"},"date":"May 12, 2015","category":"News","locales":"","content":" As we\u2019ve begun to scale up development on three different open source projects, we\u2019ve found mailing lists\u00a0to be a difficult solution for dealing with all of our needs for community support. We\u2019ve had\u00a0multiple mailing lists going,\u00a0one dedicated to Elasticsearch and another to Logstash, plus numerous lists for speakers of languages other than English. We've found these many vectors of entry can be confusing for new folks trying to figure out where to go to ask a question.We\u2019ve also found our lists are becoming noisy in the \u201cgood problem to have\u201d kind of way. As we\u2019ve seen more user adoption, and across such a wide variety of use cases, we\u2019re getting widely different types of questions asked. It can be hard to separate signal from noise on a general list. Plus, not all of our users are comfortable with mailing lists.At Elastic, we love to solve our users' problems. We've found a solution that we hope will work well for all of our community members, so head on over to our discussion forum at . Join the conversation and let us know what you think of the new communication tool. Lover of mailing lists, but not a fan of web forums? No problem! Create a user profile on the forum - you can also do this simply by using your GitHub, Facebook, Twitter or Google Apps credentials, plus plain old sign in with email address - and do a quick one time set up of your preferences for email notifications. Once that's done,\u00a0you can interact with the forums solely via email .Use, share and enjoy. And, of course, and how we can improve your experience! \n"}<br>{"index": {"_id": 1056}}<br>{"title":"Watcher: You Know, For Alerting (Coming Soon)","seo_title":"","url":"\/blog\/watcher-you-know-for-alerting-coming-soon","author":{"name":"Shay Banon"},"date":"May 11, 2015","category":"News","locales":"","content":" With simple REST APIs exposed over HTTP, Elasticsearch is a platform that encourages integration and automation. Whether using the percolator API, direct integration with infrastructure monitoring systems like Nagios, or cron-job scripts that run queries and take action, users have always been able to build notification and alerting systems on top of Elasticsearch.\u00a0As downloads of Elasticsearch have grown and its use cases have matured and expanded, we have heard frequent requests from our users and customers for integrated alerting and notification capabilities with a simple API to help them detect changes and anomalies in their growing, diverse data sets.\u00a0Today, after spending many hours with our customers understanding their needs, and many months designing and coding, we are thrilled to announce . Watcher is a flexible, powerful product that will allow Elasticsearch users to get insights and take action on changes in their data more efficiently across a wide range of use cases. Whether you're , or , the ability to easily push notifications based on changes in your data will be a game changer.\u00a0Like all of our products, Watcher is built using public Elasticsearch extension points. This means you can install it on your existing Elasticsearch cluster and it's easy to get started.\u00a0How It Works: The Anatomy of a \u201cWatch\"Interested in 404 errors? Low disk space? Or want to know the exact moment when social sentiment for your latest campaign takes takes off on Twitter? Just define it as a query using the full power of the Elasticsearch query language, including aggregations.\u00a0Now that Watcher knows what to look for, set a threshold worthy of an alert \u2014 maybe you only care about 404 errors if they occur 50% more frequently than average. To craft more sophisticated conditions, scripting is supported.Choose how often Watcher runs your queries and checks the condition. It's easy to define simple schedules \u2014 run every minute, hour, or day. For more complex scheduling needs, cron syntax is also supported. \u00a0If your conditions are met, Watcher can send a custom email, push data to external systems like PagerDuty via WebHook, or take the results of your query and store them in Elasticsearch.Learn More\u00a0If you would like to learn more, please join us for the , happening on Wednesday, May 20. Uri Boness and Steve Kearns will give a detailed overview, including installation, configuration, and a live demo.\u00a0And when you sign up, you can also opt\u00a0into\u00a0the Watcher beta.\u00a0Lastly, I am happy to announce that Watcher will be free for existing and future subscription customers. We invest heavily in the success of our customers, from insights provided by our developers during production and development support, to our growing family of products, and we couldn't be happier to provide them our latest product at no additional cost.\u00a0 \n"}<br>{"index": {"_id": 1057}}<br>{"title":"Analyzing Weblogs with Elasticsearch in the Cloud, Part 1","seo_title":"","url":"\/blog\/found-analyzing-weblogs-with-elasticsearch","author":{"name":"Christoffer Vig"},"date":"May 11, 2015","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud.Using Logstash and Kibana on Found by ElasticThis is part one of a two post blog series, aiming to demonstrate how to feed logs from IIS into Elasticsearch and Kibana via Logstash, using the hosted services provided by Found by Elastic. This post will deal with setting up the basic functionality and securing connections. will show how to configure Logstash to read from IIS log files, and how to use Kibana 4 to visualize web traffic. \n"}<br>{"index": {"_id": 1058}}<br>{"title":"Analyzing Weblogs with Elasticsearch in the Cloud, Part 2","seo_title":"","url":"\/blog\/found-analyzing-weblogs-with-elasticsearch-part-2","author":{"name":"Christoffer Vig"},"date":"May 11, 2015","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud.Using Logstash and Kibana on Found by ElasticThis is part two in the series about using Elasticsearch, Kibana and Logstash with Found by Elastic. In the , we used Logstash 1.5 and Kibana 4.02 to communicate with Elasticsearch in the cloud. This time we will use Logstash to feed logs from a web search application running on the Microsoft web server IIS (Internet Information Service) into Elasticsearch, and use Kibana to show some nice graphs. \n"}<br>{"index": {"_id": 1059}}<br>{"title":"Where in the World is Elastic: Meetups in Chicago, Berlin, Vienna, and more","seo_title":"","url":"\/blog\/2015-05-11-where-in-the-world-is-elastic","author":{"name":"Livia Froelicher"},"date":"May 11, 2015","category":"","locales":"","content":" Welcome to\u00a0 A calm week on the events side but we have some cool\u00a0meetups coming up this\u00a0week!\u00a0Read on to find out where we'll be:Upcoming Meetups May 12: May 13: May 12: May 12: May 13: \u00a0May 14: That's it for this week.\u00a0Stay tuned for Elastic happenings next week - there's much to come!\u00a0 - The Elastic Team P.S.:\u00a0 \u00a0if you're interested in hosting a meetup or are giving a talk about Elasticsearch, Logstash or Kibana\u00a0\u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 1060}}<br>{"title":"NEST 1.5 Released","seo_title":"","url":"\/blog\/nest-1-5-released","author":{"name":"Martijn Laarman"},"date":"May 08, 2015","category":"Engineering","locales":"","content":" Today we are happy to release NEST\u00a0and Elasticsearch.Net\u00a01.5 which brings us to feature parity with the new features introduced in . A couple weeks later than our usual feature parity release cadance, but the .NET team was on the road in the states, which we'll report on later in this blog post. Put plainly: NEST 1.4.3\u00a0was an Elasticsearch 1.5\u00a0compatibilty release, NEST 1.5\u00a0is a complete feature parity release.\u00a0 The Bad! Before we get the good news show rolling, let's start with the bad that has been fixed in this 1.5\u00a0release. We broke .NET 4.0\u00a0support in our Nuget package meta-data causing folks on .NET 4.0\u00a0not see any update past NEST 1.3.3. \u00a0We are very happy that this is now fixed and folks still on .NET 4.0\u00a0can now upgrade to 1.5! If you had an alternative id configured on your POCO either through or on , the method we constructed to get the id out of your POCO was not cached, causing it to not take advantage of cached reflection. \u00a0 We are happy this is now fixed but upset we had to include a\u00a0section in this blog post to begin with! Inner Hits This feature allows you to get the matching parents, childs or nested objects back separately but in a single search\u00a0request. Imagine for a second that we're indexing royal families. \u00a0Instead of indexing the complete graphs, we'll index Kings, Princes, Dukes, Earls and Barons separately. The mapping for which might look something like this in NEST: var create = this.Client.CreateIndex(\"royalty\", c => c .NumberOfReplicas(0) .NumberOfShards(1) .AddMapping<King>(m => m.MapFromAttributes()) .AddMapping<Prince>(m => m.MapFromAttributes().SetParent<King>()) .AddMapping<Duke>(m => m.MapFromAttributes().SetParent<Prince>()) .AddMapping<Earl>(m => m.MapFromAttributes().SetParent<Duke>()) .AddMapping<Baron>(m => m.MapFromAttributes().SetParent<Earl>()) ): When we are searching for s we'd also like to get back the king he's serving, inner hits allows you to do this! var results = this.Client.Search<Prince>(s => s .Index(\"royalty\") .Query(q => q .HasParent<King>(hp => hp .Query(qq => qq.MatchAll()) .InnerHits() ) ) ): To get back each hit's king (remember a document can only have one parent) you can use the following C# code: foreach(var hit in results.Hits) { var king = hit.InnerHits[\"king\"].Documents<King>().FirstOrDefault(): } Here we specified as part of the query DSL, but you can also specify more deeply nested inner hits structures as part of the request.\u00a0\u00a0Be sure to read the \u00a0for more information. IDocument In order to implement inner hits, we had to support lazy document serialization. Because the inner hits on the response is basically an where can be of any unrelated type, we had to come up with a way to defer deserialization until you, the programmer, can get a hold of the dictionary and know what types you want to get out of it. To solve this, inner hits are mapped to , a special construct that you can call on later to deserialize into the type of your pleasing. The \u00a0earlier is a convenience method on the inner hits meta data object to do so for all the inner hits. A cool side effect is that you can now also use this on using as and defer determening what type to deserialize to in your application code. Variables in suffix expressions Best explained through an example. var sortSuffix = \"raw\": var path = Property.Path<ElasticsearchProject>(p => p.Name.Suffix(sortSuffix)): var resolved = client.Infer.PropertyPath(path): will be now be and so much more... Please see our for all the fixes and new features that went into this release, and as always a shout\u00a0out to everyone who submitted a PR or reported an issue. We can't thank you enough! .NET team US tour The .NET team within Elasticsearch ( \u00a0& )\u00a0spent 8 jam-packed days together doing meetups, trainings and hashing out our roadmap for the rest of the year. .NET Fringe First stop: Portland, Oregon, Where we attended the amazing , a grassroots .NET OSS conference. We are still a bit buzzed by the good vibes we felt at this conference! In addition to attending, we also did a 4 hour training on .NET and Elasticsearch,\u00a0where we reworked our new getting started tutorial project into training format. We are pleased to open up \u00a0for folks to play with \u00a0and provide us with feedback.\u00a0 Please note its still a tad unpolished and we plan to release and blog about it more properly as part of our 2.0 release! While in Portland we also had the pleasure of doing a virtualized meetup at the Mozilla offices where we were being video beemed to the internet and the Mountain View office where some of the meetup group had also assembled.\u00a0 You can watch this presentation New York, New York! After 3 very short days, we flew back to Greg's hometown where we had a couple of days to hash out our plans for the future. In addition to this planning, we did the same talk as we did at Mozilla at the Microsoft Times Square office for the \u00a0meetup group. Thank you again \u00a0for hosting us! Roadmap So what did we hash out in the Big Apple? NEST 2.0 NEST 2.0 will move on to C# 6, we will also develop primarely in Visual Studio 2015 and move on from \/\u00a0based architecture to DNX's \/. With that we will move from , which is an amazing package manager, to . What Paket gave us was Nuget retargeting inside of csproj files and being able to call \u00a0on the command line. Since this is now handled as well by dnu pack, we can move over. With the jump to \u00a0we will also start building for the , which will be Microsoft's foray into a cross-platform CLR. If none of these terms make any sense to you yet, fear not! As a consumer you will still be able to use our DLLs on desktop .NET 4.0 and up as well! We are going to remove the thrift (now deprecated in Elasticsearch itself) and http client connection nuget packages, as they offer no performance benefits and with the move to .NET Core FX\u00a0we'll most likely have to move from to by default.\u00a0 Another huuuge focus of our 2.0 release is a reworking our testing and documentation, merging them into one project where we can leverage \u00a0to do literate programming inside our unit tests. \u00a0This will ensure our documentation will never go stale, and the act of writing unit\/integration tests adds to the documentation in the same vein.\u00a0 Expect good things here! But also expect some breaking changes as we move to 2.0, some of which will come from Elasticsearch itself and others from the client. We'll try to keep it at a minimum and document them extensively! \n"}<br>{"index": {"_id": 1061}}<br>{"title":"Virtualization and Elasticsearch: Best Practices","seo_title":"","url":"\/blog\/how-to-handle-elasticsearch-virtualization","author":{"name":"Gabriel Moskovicz"},"date":"May 08, 2015","category":"Engineering","locales":"","content":" To have a better understanding of the challenges we may deal\u00a0with when using Elasticsearch in a virtualized environment, we need\u00a0to change the focus from\u00a0conventional hardware problems\u00a0to a more complex view. The purpose of this article is to uncover\u00a0some common issues you might experience using Elasticsearch in virtual environments. A Brief History Way before Elasticsearch appeared, the concept of virtualization was taking its place as a first class citizen in computing. Virtualization refers to the act of creating a virtual (not an actual) version of something, including, among others, virtual-computer hardware platforms, operating systems, storage devices, or computer network resources. Virtualization was born in the late 1960s and early 1970s, when IBM created the CP-40\/CMS (Conversational Monitor System)\u00a0as a method of logically dividing the system resources provided by mainframe computers between different applications. Afterwards, the meaning of the term\u00a0broadened to\u00a0what currently is: full virtual machine (VM) implementations and control of processing, network and\u00a0memory,\u00a0all working\u00a0together seamlessly\u00a0in the cloud. Existing Platforms There are various existing platforms to handle Elasticsearch in virtual environments, all of which are different between them. Generally, the three main platforms we see used for Elasticsearch are: Finally, as a different way to handle our Elasticsearch virtualized infrastructure, \u00a0is a hosted and fully managed Elasticsearch Software\u00a0as a Service (SaaS). Found provides a fast, scalable, reliable and easy to operate search service hosted for you in the cloud. The Architecture As an example of how complex a virtualized architecture can be, and all the points we have to understand\u00a0to manage Elasticsearch on a virtual environment, we can take a brief look into VMware's vSphere architecture. VMware vSphere is used to transform entire datacenters into a single\u00a0cloud computer infrastructure, virtualizing and aggregating the main physical hardware resource across multiple systems and providing\u00a0virtual resources to the datacenter. VMware vSphere consists of\u00a0multiple component layers such as: Although the\u00a0architecture is complex, no matter which virtualization solution we use,\u00a0we will have tools that makes it very easy to manage entire datacenter or clusters. Those tools can help us to easily allocate storage and networking to the physical nodes, parcel out resource\u00a0allocation (CPU, memory, disk and network bandwidth) as needed, monitor datacenter status, and more. The tools\u00a0will allow us to configure and setup Elasticsearch in a virtual environment exactly as required\u00a0depending on our needs. Regardless, we need to take care around\u00a0some issues that can crop up\u00a0with CPU, memory and disk utilization. Handling Resources There are various ways to achieve the goal of running\u00a0Elasticsearch in a virtualized environment. Each platform and solution, whether is cloud-based or not, has his own complexity and difficulty for configuring and running. Handling resources is the key area\u00a0for achieving\u00a0success. CPU Every virtualization solution has limits regarding CPU usage. A physical processor core can support up to 32 virtual CPUs (vCPU) in both vSphere 6 and Azure, and 36 vCPU in Amazon EC2. As we increase CPU allocation on cloud providers, we will increase the cost for each instance. Elasticsearch uses Java, so we will need to handle a Java Virtual Machine (JVM) within our virtual environment. A good approach for JVM's is to have a minimum of two CPU's, one to handle garbage collection and JVM administration, and the other to handle the application processing. A good way to handle CPU usage is to monitor CPU utilization inside the VM using . If Elasticsearch is using a lot of \u00a0CPU resources inside the VM, it may be worth considering increasing the number of available vCPUs. Memory As well as CPU limits, there are limits for the amount of RAM we can allocate on a host depending the provider: up to 6 TB on vSphere, 244 GB on Amazon EC2, and 112 GB on Azure. As we increase memory usage, we will generally see\u00a0increase in costs. CPU and disk usage can\u00a0be affected by reaching memory limits. You might want to watch and monitor the Host and VM status with Marvel, to find whether you need to do something in order to decrease memory usage, such\u00a0\u00a0as\u00a0refactoring Elasticsearch queries or increasing\u00a0the amount of memory on the host. Java objects, methods, thread stacks and others, reside in Java heap. The amount of memory given to the heap will ensure us\u00a0good \u2014 or bad \u2014 behavior of our Elasticsearch cluster. When the heap starts to fill, the Java garbage collector will start running. It is a best practice to allocate half of the total amount of memory for the heap. In addition, we have detailed information in our documentation on . Disk Disk utilization is similar on a host and a VM. We need to eliminate\u00a0disk contention as we do in any environment. If a set of disks in the host is being overused, meaning that the average I\/O is close to 100%, we might see an impact in all the virtual environments that are using the same disks.\u00a0Disk resources can also be impacted by \"noisy neighbors\", which are generally larger VMs running on or against the same hardware, thereby consuming resources in negative and surprising ways. your Elasticsearch cluster, or for individual indices as well as entire clusters, is incredibly important!\u00a0By making backups from the VM, we can ensure\u00a0that\u00a0we have a starting\u00a0point to continue from in the case of failure. Creating snapshots or backups from VMs has some cost and may have an impact in the VM response time, so we may also impact\u00a0Elasticsearch's responsiveness by doing such operations. Plus, it is just good practice\u00a0to have a\u00a0Backup and Snapshot policy for your clusters. Elasticsearch disk usage depends on each use case. We recommend doing stress and performance tests on the server in order to understand the amount of disk we need to allocate in order to make the cluster work well. When it comes to\u00a0CPU and Memory, some cloud solutions can become pricey as you increase the disk allocation. Network Configuring the network is usually straight forward. There are plenty of possible configurations depending on which cloud\u00a0provider you choose and what your needs are. You\u00a0can share the network with the host, or create an independent network to use on your VM.\u00a0 You make consider creating a Virtualized Private Network (VPN) to isolate the cluster, as well as to secure it. The Perils of Virtualization In addition to the areas outlined above, there are a few other places where we can run into trouble running Elasticsearch in a virtualized environment. As an example, we can see one of the latest fixed on Ubuntu. A simple bug on the Ubuntu kernel (version 3.13) was causing a failure in the transport connection thread on EC2 when the\u00a0network'\u00a0load increased. Consequently, Elasticsearch indexing, query operations and administrative commands started to fail on EC2 instances running Ubuntu. The problem was caused by a combination of and the maximum transmission unit limit on the network interfaces. The solution was either to update Ubuntu's kernel version and restart the EC2 instance, or disable gather-scatter. Another example is the problem that we might encounter while working in a cluster with limited resources on the VMs and losing\u00a0one of the nodes. Shards that were allocated in that specific node will be relocated to another node, without executing any process to see if the new node contains enough resources to handle the\u00a0new shards. In order to limit this problem, we can use . Forced awareness allows us to\u00a0force allocate new shards in specific zones that we define in the configuration. Finally, as it is too common to have more than one VM within the same hardware, to avoid the risk of losing data in a virtualized environment we can use \u00a0to prevent primary\u00a0and replica\u00a0shards to be located\u00a0on the same hardware, rack or zone. We can then force each replica shard to be allocated in another VM that is not on\u00a0the same hardware as\u00a0the primary one. Conclusion There are many different possibilities for using\u00a0Elasticsearch in a virtualized environment. Choosing which is the best will involve analyzing and deciding on some technical and financial tradeoffs. Consider\u00a0the best choice for your solution: you want to\u00a0have a configuration that allows you to use all the resources available not only effectively, but also efficiently. \n"}<br>{"index": {"_id": 1062}}<br>{"title":"The Logstash : Logstash 1.5 RC4 is hot off the presses!","seo_title":"","url":"\/blog\/2015-05-08-logstash-lines","author":{"name":"Shaunak Kashyap"},"date":"May 08, 2015","category":"The Logstash Lines","locales":"","content":" Welcome back to ! In these weekly\u00a0posts, we'll share the latest happenings in the world of Logstash and its ecosystem. 1.5 RC4 now available with lumberjack input, filter, and other improvements! \u2014 elastic (@elastic) Other Logstash Core Improvements was super excited about the logstash-core gem which is used by the pipeline. This gem encapsulates only the pipeline logic now \u2014 we moved out all the helpers, development dependencies, start-up scripts and such. This simplifies artifact packaging, and fixes issues with flaky dependencies. All good stuff! Wondering how best to scale Logstash? Look no further than this awesome talk by our very own : That's this week in . Come back next week for more Logstash news! \n"}<br>{"index": {"_id": 1063}}<br>{"title":"Kurrently in Kibana: Features of the 4.1 Release","seo_title":"","url":"\/blog\/kurrently-kibana-2015-05-08","author":{"name":"Robyn Bergeron"},"date":"May 08, 2015","category":"Kurrently in Kibana","locales":"","content":" Welcome to , your source for keeping up with the Kibana project. With information on project releases, work in progress, and learning resources, we're betting you'll need a to add up all the things you'll learn each week! Exotic and stealth paramiko based SSH bruteforce from 94.79.33.21\/30 in Russia. Visualization done in Kibana 4: \u2014 Eric Leblond (@Regiteric) Kibana 4.1: Progress, it's progressing! We're making progress on 4.1. There's some pretty and we want to make sure they get the attention and proper review they so rightfully deserve. Here's a couple highlights that have gotten some of that attention this week: Pinned Filters Pinned filters allow you to specify a filter as one of your BFFs. A pinned filter is always there for you, no matter which application you switch to next. From Dashboard back to Discover, they are there, by your side (in your filter bar), filtering your searches. But, unlike your BFF who is, frankly, starting to get a bit irritating and should probably make a few more friends and stop smothering you, pinned filters go away with the click of an icon: Automatic Precision on Maps We've always allowed you to configure your geohash_grid precision, but now Kibana is taking it back. I mean, if you let it. (Please, it'll be worth it!)\u00a0As you zoom in and out on a map Kibana will change the precision automagically for you. In combination with the recently merged pull to only draw that which can be seen, this really jazzes up interactions with maps. A Fun Review of the Kibana 4 Client Side Code Gill Barr took the time to really dig into the Kibana 4 code and give us a kind review. And Many Other Things! 4.1 enables display of images and URLs inline. Love it! \u2014 Robin Moffatt (@rmoff) See You Next Week! As you may have seen, we're now publishing weekly updates on Elasticsearch and Apache Lucene, Logstash and Kibana. We'll bring you the newest, stuff\u00a0in next week's . \n"}<br>{"index": {"_id": 1064}}<br>{"title":"Logstash 1.5.0 RC4 released","seo_title":"","url":"\/blog\/logstash-1-5-0-rc4-released","author":{"name":"Suyog Rao"},"date":"May 07, 2015","category":"Engineering","locales":"","content":" A short post to announce the 4th release candidate for Logstash. This release fixes important bugs which were reported with RC3. Head over to the for the details or RC4!Bug Fixes: FeedbackPlease RC4, try it out, and provide your feedback by opening an , contributing pull requests on GitHub or to us. \n"}<br>{"index": {"_id": 1065}}<br>{"title":"Kibana 4 Video Tutorials, Part 4","seo_title":"","url":"\/blog\/kibana-4-video-tutorials-part-4","author":{"name":"Shaunak Kashyap"},"date":"May 07, 2015","category":"Engineering","locales":"","content":" For our next instalment of\u00a0Kibana 4 video\u00a0series, we bring you a\u00a0tutorial on how to embed\u00a0Kibana 4 visualizations into your webpage.\u00a0 This\u00a0seemingly\u00a0daunting proposition\u00a0is easier than ever with Kibana 4! If you have suggestions for future videos or would like to discuss any other Kibana topic, visit our new Kibana discussion category\u00a0on ! \n"}<br>{"index": {"_id": 1066}}<br>{"title":"This Week in Elastic: Shield versions 1.2.1 and 1.1.1 released","seo_title":"","url":"\/blog\/2015-05-06-this-week-in-elastic","author":{"name":"Leslie Hawthorn"},"date":"May 06, 2015","category":"","locales":"","content":" Welcome to ! In this weekly round up post, we bring you news on all aspects of the ELK Stack, including updates on Elasticsearch, Logstash and Kibana development, tips and tricks and upcoming events. Join us tomorrow as we investigate Scaling w\/ & in a .NET environment \u2014 Jamie Turner (@PCAJamie) Elastic News Useful blog posts, how tos, tutorials\u00a0and articles\u00a0from the wide world of all the ELK stack ecosystem. Cool! 's Polysearch2 is a text-mining system for biomedical research \u2014 Zachary Tong (@ZacharyTong) Slides and Videos Hacking on for Philly's new transit system \u2013 Indego Bike Share \u2014 jamestyack (@jamestyack) Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking about the ELK stack\u00a0or hosting a meetup, Algieria will take the stage at Voxxed Days Algiers to present An Introduction to the ELK Stack. This first ever conference takes place May 23, and Samir's talk is on for 2:00 PM. Australia The Melbourne Search Users Group will meet up on May 19 for a talk from Movideo: Migrating from Hibernate Search to Elasticsearch. to save your seat. We're pretty sure our very own will be joining you, too! Austria The Vienna Elasticsearch Meetup will convene on May 12 to hear from on Elasticsearch Under the Hood. to save your seat. Canada If you're attending the upcoming Open Stack Summit in Vancouver, make sure to catch the session. OpenStack Summit runs May 18-22. Czech Republic Our very own will be on hand for Q&A on Elasticsearch in Prague on May 7. You can RSVP for this talk . Denmark France The Elasticsearch France Meetup returns to Paris on May 26. so you know when we open up RSVPs! During 2015, will show us how to add to legacy applications in a blink ! \u2014 RivieraDEV (@RivieraDEV) Germany Israel We've got dueling meetups in Tel-Aviv Yafo on May 26: The Netherlands Johan Guldmyr will host a talk on dCache and the ELK stack at the at 2:20 PM on May 19. The Workshop runs May 18-20 in Amsterdam. Poland will take the stage at 6:30 PM on May 26 to talk Beyond the Basics with Elasticsearch at the . The event runs May 25-26 in Warsaw. Portugal The Merge Lisbon Meetup Group will get together on May 14 to talk about the ELK stack. to hear from our very own Logstash engineering team member . Spain Join for the next Elasticsearch Barcelona Meetup on May 21, where you'll learn all about Moving to Production with Elasticsearch: Best Practices. to save your seat. Turkey Voxxed Days Istanbul is coming up on May 9. Join to learn all about Advanced Search for Your Legacy Application Using Elasticsearch. David at 11:30 AM. United Kingdom We just announced the meetup around London with our expert ! Wed, May 6, 8pm. \u2014 Livia Froelicher (@LivFroe) For folks in Cardiff, Wales, your welcome to attend our Elasticsearch Meetup hosted at DjangoCon EU. Make sure to pop by the conference to say hello to Honza Kral in the hallway track. runs May 31 - June 5. United States - EastThe DevOps and Automation New Jersey Meetup will get together on May 12 to hear from to save your place.The Elastic Chicago Meetup will convene on May 13 to discuss Performance Tuning for Elasticsearch. to save your place. For folks in Chicago interested in all things .NET, you may also want to on May 20 for an Introduction to the ELK stack.The Detroit Elastic User Group will hold its inaugural meeting on May 27, where Peter Kim will reprise his talk from the DevOps and Automation New Jersey Meetup. to save your seat. United States - WestAttending the ? You can hear from our very own and Tyler Langlois on various topics, from starting your career in open source to all things ELK stack. Plus, we'll have a booth on the show floor so you can get all of your questions answered. Open West runs May 7-9 in Orem, Utah.The Orange County MongoDB Users Group will get together on May 7 to talk Elasticsearch and MongoDB. to save your seat.Does your whale need an ELK buddy? Join the Seattle User Group on May 18 to hear all about using Docker together with the ELK stack. to save your seat.Heading to ? Great, so are we! You can visit us in the exhibits hall to get questions answered throughout the conference, and make sure to check our talk: . Gluecon runs May 20-21 in Broomfield, Colorado.If you're not heading to Gluecon but find yourself in Denver, you can still hear from our awesome Gluecon speaker, our newest Developer Advocate, , and Bitly's engineering team on their Elasticsearch user case. to save your place for the Denver Meetup coming up on May 18!The San Antonio DevOps Meetup will welcome 3 speakers from Elastic on May 27. to hear all about the ELK stack for DevOps, including how we eat our own ELK-food from Elastic's infrastructure team lead.On May 28, the Elasticsearch Dallas Fort Worth Meetup will convene to talk going into Production with Elasticsearch. to save your place.The Kansas City Big Data Meetup will get together for a lunch and learn on Elasticsearch & Data Analysis on May 28. to save your place. Lunch will be provided for attendees. Where to Find You \u00a0If you're a regular reader, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to\u00a0 ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1067}}<br>{"title":"This week in Elasticsearch and Apache Lucene: Elasticsearch and the MarsCuriosity analytics cloud","seo_title":"","url":"\/blog\/2015-05-05-this-week-in-elasticsearch-and-apache-lucene","author":{"name":"Alexander Reelsen"},"date":"May 05, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top News although not mentioned, is the powerhouse behind our analytics cloud\u2026 w00t! \u2014 Matt Lenda (@mattTheLenda) Elasticsearch Core Apache Lucene Watch This Space , where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 1068}}<br>{"title":"Where in the World is Elastic: Elastic{ON}15 & Qcon London","seo_title":"","url":"\/blog\/2015-05-01-where-in-the-world-is-elastic","author":{"name":"Livia Froelicher"},"date":"May 04, 2015","category":"","locales":"","content":" Welcome to\u00a0 Check out our\u00a0shows\u00a0coming up this week featuring tons\u00a0of cool content provided by our own Elastic\u00a0experts. Read on to find out more... Upcoming Events May 4-5: -\u00a0Come say hi at our booth and look out for\u00a0the 5 minute demo session\u00a0by . May 6-9: : Orem, Utah - We have\u00a0four\u00a0talks at this event,\u00a0as well as a table so stop by to meet us! May 5: : Riga, Latvia -\u00a0Ruslan Zavacky will be giving a presentation on all things\u00a0Elasticsearch: \"You know, for Search\".\u00a0\u00a0to save your seat! May 6-7: : London, UK - Our own Hadoop expert Costin Leau will be speaking about\u00a0, Thursday, May 7, 10:55 a.m. - 11:35 a.m. We also have a booth there, so come say hi at booth number 408 and grab one of our brand new stickers! May 6: Comperio Breakfast: Oslo, Norway - This event is hosted by our partner firm Comperio and will take place from 8:30 a.m. to 10:30 a.m..\u00a0Our Solutions Architect\u00a0 \u00a0will be giving an introduction to the ELK stack. Register for free. May 9: : Istanbul, Turkey - will give a talk on ,\u00a011:30 a.m. Upcoming Meetups May 7: May 6: May 6: May 7: That's it for this week.\u00a0Stay tuned for Elastic happenings next week - there's much to come!\u00a0 - The Elastic Team P.S.:\u00a0 \u00a0if you're interested in hosting a meetup or are giving a talk about Elasticsearch, Logstash or Kibana\u00a0\u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 1069}}<br>{"title":"The Logstash Lines: RC4 release coming soon","seo_title":"","url":"\/blog\/2015-05-01-logstash-lines","author":{"name":"Shaunak Kashyap"},"date":"May 01, 2015","category":"The Logstash Lines","locales":"","content":" Welcome back to\u00a0 !\u00a0In these weekly\u00a0posts, we'll share the latest happenings in the world of Logstash and its ecosystem. In case you missed it, we last week, found and are planning an RC4 very soon. Stay tuned! Logstash Core and Plugins From the Community We had presentations from LinkedIn's Tin Le and Elastic's Tal Levy () at a meetup last Wednesday - Talking , , and with \u2014 Kurt Hurtado (@kurtado) And for all you Docker and ELK enthusiasts out there - Automating Docker Logging: ElasticSearch, Logstash, Kibana, and Logspout \u2014 Ben Dixon (@TalkingQuickly) That's this week in . Come back next week for more Logstash news! \n"}<br>{"index": {"_id": 1070}}<br>{"title":"Kurrently in Kibana: Heat Map Visualization in 4.1","seo_title":"","url":"\/blog\/kurrently-kibana-2015-05-01","author":{"name":"Robyn Bergeron"},"date":"May 01, 2015","category":"Kurrently in Kibana","locales":"","content":" Welcome to , your source for keeping up with the Kibana project. With information on project releases, work in progress, and learning resources, we hope you'll find this weekly update to be pretty... ! soo useful to be able to index days\/gigabytes of accesslogs from S3 in mere minutes and immediately usable in Kibana. ftw\u2014 Christian Westman (@westmaaan) Kibana 4.1: Maps, maps, and more maps! This past week the Kibana team decided to tackle the map visualization and make some progress on the outstanding 4.1 issues, as well as finding ways to just make things plain better. You can check out the larger scope of everything planned in the , but here's what we've been we've been up to recently: Heat Map is Close to Merge-able We're still cleaning up some code issues, but the functionality is largely there. We also took the opportunity to improve the tooltip positioning for all of the other maps. The tooltip on the map now works by looking for the closest point, with a margin, and throwing a tooltip on it. This means you no longer need to hover directly over the SVG, a tricky task at high precision levels. Adding Filter Support to the Map The first phase of tile map filters is under review. This allows you to draw a rectangle on the map to form a geo_bounding_box filter. Later phases will allow for drawing circles and polygons. Map filters coming in 4.1. Super useful with 's pinned filter feature. \u2014 Rashid Khan (@rashidkpc) Other Map-related Stuff Progress on Non-Map Things, Too! See You Next Week! As you may have seen, we're now publishing weekly updates on Elasticsearch and Apache Lucene, Logstash and Kibana. We'll bring you the latest and greatest in next week's . \n"}<br>{"index": {"_id": 1071}}<br>{"title":"This Week in Elastic: ICYMI: Elasticsearch 1.5.2 and 1.4.5 were released","seo_title":"","url":"\/blog\/2015-04-29-this-week-in-elastic","author":{"name":"Leslie Hawthorn"},"date":"April 29, 2015","category":"","locales":"","content":" Welcome to ! In this weekly round up post, we bring you news on all aspects of the ELK Stack, including updates on Elasticsearch, Logstash and Kibana development, tips and tricks and upcoming events. Awesome: Maptimize demo, attributes last 1M tweets around the world. \u2014 Christopher Shields (@Cshields2015) Elastic News Useful blog posts, how tos, tutorials\u00a0and articles\u00a0from the wide world of all the ELK stack ecosystem. Just released: for Hadoop 2.1 Beta 4 with new features, improvements, and more \u2014 elastic (@elastic) Just released a new version of DSL, a high-level client. Lot of improvements and new features \u2014 Honza Kr\u00e1l (@HonzaKral) Slides and Videos How to sync transformed data from to using Transporter \u2014 DigitalOcean (@digitalocean) Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking about the ELK stack\u00a0or hosting a meetup, Algieria will take the stage at Voxxed Days Algiers to present An Introduction to the ELK Stack. This first ever conference takes place May 23, and Samir's talk is on for 2:00 PM. Australia The Melbourne Search Users Group will meet up on May 19 for a talk from Movideo: Migrating from Hibernate Search to Elasticsearch. to save your seat. We're pretty sure our very own will be joining you, too! Austria The Vienna Elasticsearch Meetup will convene on May 12 to hear from on Elasticsearch Under the Hood. to save your seat. Canada If you're attending the upcoming Open Stack Summit in Vancouver, make sure to catch the session. OpenStack Summit runs May 18-22. Czech Republic Our very own will be on hand for Q&A on Elasticsearch in Prague on May 7. You can RSVP for this talk . Denmark France The Elasticsearch France Meetup returns to Paris on May 26. so you know when we open up RSVPs! Germany Israel We've got dueling meetups in Tel-Aviv Yafo on May 26: Latvia Ruslan Zavacky will present on all things Elasticsearch at LatCraft's NoSQL and Data event on May 5. to save your seat and get introduce to Elasticsearch! Norway Our partner firm, Comperio Search, will host a breakfast learning session on all things Elasticsearch on May 6. You'll hear from Elastic's Solutions Architect amongst other speakers. Attendance is free of charge, but . Portugal The Merge Lisbon Meetup Group will get together on May 14 to talk about the ELK stack. to hear from our very own Logstash engineering team member . South Africa Elasticsearch Jo'burg meetup 29 April at Elasticsearch is not just for search. Come explore with us! \u2014 Jurgens du Toit (@jrgns) Spain Turkey Voxxed Days Istanbul is coming up on May 9. Join to learn all about Advanced Search for Your Legacy Application Using Elasticsearch. David at 11:30 AM. United Kingdom We just announced the meetup around London with our expert ! Wed, May 6, 8pm. \u2014 Livia Froelicher (@LivFroe) United States - EastThe Detroit Python User Group will convene, , April 29 to talk Python and Elasticsearch.\u00a0\u00a0to attend.The DevOps and Automation New Jersey Meetup will get together on May 12 to hear from to save your place.The Detroit Elastic User Group will hold its inaugural meeting on May 27, where Peter Kim will reprise his talk from the DevOps and Automation New Jersey Meetup. to save your seat. United States - WestJoin the folks from LinkedIn for a meetup on their use of the ELK stack, , April 29, which they are kindly hosting in their Mountain View, California office. of Elastic will also be speaking about Logstash and Apache Kafka. to save your space.Attending the ? You can hear from our very own and Tyler Langlois on various topics, from starting your career in open source to all things ELK stack. Plus, we'll have a booth on the show floor so you can get all of your questions answered. Open West runs May 7-9 in Orem, Utah.The Orange County MongoDB Users Group will get together on May 7 to talk Elasticsearch and MongoDB. to save your seat.Does your whale need an ELK buddy? Join the Seattle User Group on May 18 to hear all about using Docker together with the ELK stack. to save your seat.Heading to ? Great, so are we! You can visit us in the exhibits hall to get questions answered throughout the conference, and make sure to check our talk: . Gluecon runs May 20-21 in Broomfield, Colorado.If you're not heading to Gluecon but find yourself in Denver, you can still hear from our awesome Gluecon speaker, our newest Developer Advocate, , and Bitly's engineering team on their Elasticsearch user case. to save your place for the Denver Meetup coming up on May 18!On May 28, the Elasticsearch Dallas Fort Worth Meetup will convene to talk going into Production with Elasticsearch. to save your place. Just scheduled: next Chicago meetup coming up May 13 featuring speakers from RSVP: \u2014 Leslie Hawthorn (@lhawthorn) Where to Find You \u00a0If you're a regular reader, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to\u00a0 ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1072}}<br>{"title":"Shield 1.2.1 and 1.1.1 Released","seo_title":"Shield 1.2.1 and 1.1.1 Released","url":"\/blog\/shield-1-2-1-and-1-1-1-released","author":{"name":"Jay Modi"},"date":"April 29, 2015","category":"Engineering","locales":"","content":" Today, we are pleased to announce the bugfix releases of Shield 1.2.1 and Shield 1.1.1. For a new installation, download it\u00a0: to upgrade from prior versions of Shield, please follow the\u00a0. These Shield releases contain several bug fixes, most notably a fix that ensures\u00a0\u00a0works properly on clusters secured by Shield. We recommend that existing Shield users upgrade to ensure the health of their clusters. \n"}<br>{"index": {"_id": 1073}}<br>{"title":"This week in Elasticsearch and Apache Lucene: Elasticsearch Core and Lucene tips","seo_title":"","url":"\/blog\/2015-04-28-this-week-in-elasticsearch-and-apache-lucene","author":{"name":"Michael McCandless"},"date":"April 28, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsElasticsearch Core Apache Lucene How to sync transformed data from to using Transporter \u2014 DigitalOcean (@digitalocean) Watch This Space , where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 1074}}<br>{"title":"Elasticsearch Hadoop 2.1.0.Beta4 released","seo_title":"","url":"\/blog\/elasticsearch-hadoop-2-1-0-beta4-released","author":{"name":"Costin Leau"},"date":"April 28, 2015","category":"","locales":"","content":" The 4th Beta of Elasticsearch for Apache Hadoop (aka es-hadoop) has been . This release adds a plethora of new features and enhancements to the connector in various areas: Results returned as JSON Since Beta4, data read from Elasticsearch can be returned in JSON format through property (in a highly efficient manner). This is useful for serialization purposes such as saving information to the disk or sending it over the wire. And as always, the feature is available in all library integrations. Obtain document metadata Additionally, it is now possible to return the for each document, alongside the actual source information. Whether one is interested in an index type or a document version or the remaining time-to-live, this information is now made available without any extra network cost. Inclusion \/ Exclusion of fields On the front, it is now possible to specify what fields to be included or excluded for data about to be written to Elasticsearch. This makes it quite handy not only for doing quick transformation of the data but also specifying document metadata without storing it: # extracting the id from the field called 'uuid' es.mapping.id = uuid # specifying a parent with id '123' es.mapping.parent = <123> # combine include \/ exclude for complete control # include es.mapping.include = u*, foo.* # exclude es.mapping.exclude = *.description Client-node routing For clusters in restrained environments, it is now possible to use the connector through . That is, rather than accessing the cluster data nodes directly, the connector will use the client nodes instead (which do need to have the HTTP(S) port opened) and ask those to do the work on its behave. This will impact parallelism as the connector will not communicate directly with the nodes however, unless a lot of data is read\/written and locality is not of importance, the performance penalty is insignificant. Spark improvements The various libraries have been upgraded and enhanced however by far the most updates were applied to the Spark integration. Spark 1.2 and 1.3 are officially supported in es-hadoop Beta4 - both Core and SQL. Unfortunately, due to some in Spark SQL, Elasticsearch Hadoop provides now two different versions - one for Spark 1.0-1.2 and another for Spark 1.3 (and hopefully higher). Core users can transparently migrate between them however those using Spark SQL need to adapt from to the newly introduced API. Speaking on Spark SQL, the DataSource API is in both styles (Spark SQL 1.2 and 1.3) so one can use the connector in a fully declarative fashion: val dataframe = sql.load(\"spark\/index\", \"org.elasticsearch.spark.sql\") Further more, through the API, the connector is able to understand the Spark SQL operations applied on it and thus it is able to push down to the store through optimizing the queries made. Various enhancements were made such as introducing\u00a0 (to allow metadata to be specified separately for each document, at runtime) and (to return the data in unprocessed, JSON format), out-of-the-box indexing of Scala case classes and JavaBeans and also, providing binaries not just for Scala 2.10 (the default) but also Scala 2.11 (make sure to use the 2_11 suffix). Strata London Next week, Elastic will be attending Strata London. If you're interested in Elasticsearch or the ELK stack, please drop by our booth (#408). Further more, you're cordially invited on Thursday at 10:55 to hear about by yours truly.\u00a0 Also join us for the (please RSVP, seats are limited) on Wednesday, May 6th, in London at the new Elastic office. We look forward to your feedback on \u2013 you can find the binaries are available on the and the new features explained in the . As always, you can on GitHub. \n"}<br>{"index": {"_id": 1075}}<br>{"title":"Elasticsearch 1.5.2 and 1.4.5 Released","seo_title":"Elasticsearch 1.5.2 Released","url":"\/blog\/elasticsearch-1-5-2-and-1-4-5-released","author":{"name":"Clinton Gormley"},"date":"April 27, 2015","category":"Engineering","locales":"","content":" We would like to announce security bugfix releases of and , both based on . You can download them and read the full changes list here: For blog posts about past releases see: You can read about all of the changes that have been made in the \u00a0and\u00a0 release notes, but the security issue is explained below: Directory traversal vulnerability found All Elasticsearch versions prior to 1.5.2 and 1.4.5 are vulnerable to a directory traversal attack that allows an attacker to retrieve files from the server running Elasticsearch. This vulnerability is not present in the initial installation of Elasticsearch. The vulnerability is exposed when a \u201csite plugin\" is installed. Elastic's Marvel plugin and many community-sponsored plugins (e.g. Kopf, BigDesk, Head) are site plugins. Elastic Shield, Licensing, Cloud-AWS, Cloud-GCE, Cloud-Azure, the analysis plugins, and the river plugins are not site plugins. We have been assigned for this issue. Versions 1.5.2 and 1.4.5 have addressed this vulnerability, and we advise all users to upgrade. Users that do not want to upgrade can address the vulnerability in several ways, but these options will break any site plugin: Thanks to John Heasman of DocuSign for reporting this issue. Other notable\u00a0changes Some important changes\u00a0have been back-ported to v1.4.5: Please , try it out, and let us know what you think on Twitter (). You can report any problems on the . \n"}<br>{"index": {"_id": 1076}}<br>{"title":"Where in the World is Elastic: Human Language Technology Conference, VA","seo_title":"","url":"\/blog\/2015-04-27-where-in-the-world-is-elastic","author":{"name":"Livia Froelicher"},"date":"April 27, 2015","category":"","locales":"","content":" Welcome to\u00a0Europe, America and Africa are our three continents for\u00a0this week.Check out all the\u00a0places we are heading to!Upcoming EventsApril 28: - , our Director of Product Management will be giving a talk around\u00a0April 29-30: - will be talking about , April 30, 3:30 p.m. - 4:20 p.m.Upcoming MeetupsApril 29: April 29: April 29: April 30: April 29: That's it for this week.\u00a0Stay tuned for Elastic happenings next week - there's much to come!\u00a0- The Elastic TeamP.S.:\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Elasticsearch, Logstash or Kibana\u00a0\u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 1077}}<br>{"title":"The Logstash Lines: Logstash 1.5.0 RC3 released","seo_title":"","url":"\/blog\/2015-04-24-logstash-lines","author":{"name":"Shaunak Kashyap"},"date":"April 24, 2015","category":"The Logstash Lines","locales":"","content":" Welcome back to !\u00a0In these weekly\u00a0posts, we'll share the latest happenings in the world of Logstash and its ecosystem. More news today! Happy to announce 1.5.0 RC3 is now available w\/performance improvements, bug fixes & more \u2014 elastic (@elastic) Logstash Core Recent fixes for 1.5 RC3 include: \n"}<br>{"index": {"_id": 1078}}<br>{"title":"Elastic{ON} Video of the Week: Scaling Elasticsearch for Production at Verizon: 500 Billion Documents & Counting","seo_title":"","url":"\/blog\/elasticon-video-of-the-week-verizon","author":{"name":"Daniel Palay"},"date":"April 24, 2015","category":"User Stories","locales":"","content":" Bhaskar Karambelkar is a Senior Security Data Scientist on the Security Research Team at Verizon Business, where he works\u00a0on next-generation security research. Over the past three years, Bhaskar and his colleagues have scaled Elasticsearch from simple a log analytics proof of concept, to a\u00a0128-node production system capable of handling up to 20 billion documents a day. Here's Bhaskar's video and some of his reflections from his time as a speaker at Elastic{ON}. To watch Bhaskar's full Elastic{ON} talk, follow this or check out his slides below: You can share or find Bhaskar on Twitter . \n"}<br>{"index": {"_id": 1079}}<br>{"title":"Kurrently in Kibana: 4.1 Feature Preview, Part 2","seo_title":"","url":"\/blog\/kurrently-kibana-2015-04-24","author":{"name":"Robyn Bergeron"},"date":"April 24, 2015","category":"Kurrently in Kibana","locales":"","content":" Welcome to , your source for keeping up with the Kibana project. With information on project releases, work in progress, and learning resources, we hope you'll find this weekly update to be pretty... ! Kibana dashboard demo with and by at \u2014 Lionel Porcheron (@lporcheron) Kibana 4.1: What's the scoop? You can check out the larger scope of everything planned in the , but here's what we've been doing in the past week or so: Separate View Options Tab We're starting to get to the point in some visualizations where you're doing less with the data, and more with your view of the data. Previously we had a section called \u201cview options\" at the bottom of the aggregation builder. We're changing that in 4.1 and adding a new tab called \u201cOptions\" that will let you configure things like map style, dot sizes and other options that aren't directly related to the aggregation you're running. We've also moved a few buttons around in order to undo the effect this change would have on vertical space utilization. Field Formatting Updates We decided that field formatters needed a few more options, like per-field number precision. So we're breaking field configuration out into its own screen. This will have the 1-2 punch effect of both simplifying the field listing screen AND allowing us to have a more powerful interface to field configuration. It's a good thing. (Pull pending)\u00a0 Not Kibana, But Is Amazing\u00a0(Or, the death of timestamped indices) Rashid has\u00a0been whistling and smiling half the day because of .\u00a0Why you ask? This API will allow incredibly fast access to the min and the max of a field without using aggregation. Big Deal,\u00a0you say? Yeah, it's TOTALLY a big deal. Kibana will have instant access to\u00a0the min and max of the timestamp fields of every index. This means instead of needing to generate a list of possible indices with their corresponding time, e.g. the old logstash-YYYY.MM.DD, we'll just look up the indices containing timestamps between X and Y, because it's cheap. This could mean the death of timestamped indices. You just set your pattern in Kibana to logstash-* and we'll handle the optimization. And MOAR! So much more. See You Next Week! As you may have seen, we're now publishing weekly updates on Elasticsearch and Apache Lucene, Logstash and Kibana. We'll bring you the latest and greatest in next week's . \n"}<br>{"index": {"_id": 1080}}<br>{"title":"Logstash User Survey Results","seo_title":"","url":"\/blog\/logstash-user-survey-results","author":{"name":"Tanya Bragin"},"date":"April 23, 2015","category":"News","locales":"","content":" In case you hadn't heard about it, we asked all of our community members to tell us more about how they use Logstash, including praise and pain points. We ran the survey for ~4 weeks and had just shy of 250 respondents! We have been poring over the results and have already learned a lot that will prove to be extremely valuable as we continue to improve Logstash. And today, we're very excited to share the results with you. In this blog post, we'll describe the survey methodology, share our summary of the results, and provide links to the raw results in case anyone is interested in doing more analysis. (And if you do, make sure to !)\u00a0 All charts in this blog are based on survey data analysis and visualization\u00a0using the Elastic stack. Check out the\u00a0\"Raw Result Data\" section at the end of this blog for more information on how to set that up yourself. Response Highlights For those of you that can't wait to find out the juicy bits, here are a few highlights: : All percentage calculations are based of the total number of survey respondents. Since every question was multiselect, percentages do not add up to 100%. Want to read about the rest of results? Interested to see it in charts? Read on! Survey Methodology We ran this survey for about four weeks. It was promoted on the logstash-users mailing list, the Elastic company blog, the Elastic Twitter account, and at the Elastic{ON} conference. In all, we had 242 respondents to the survey, with the majority coming in after the first official blog and Tweet. The survey consisted of 17 questions, which combined multi-select and write-in answers (see survey in \u201cpreview mode\" ). Although all of the questions were optional, most respondents completed almost all of the questions and provided ample write-in feedback. The questions ranged from use case information and environment details to desired future product functionality. The survey was anonymous, unless the participants chose to share their contact information with our Developer Relations team. In addition, by taking the survey, participants agreed to share the anonymized results of the survey with the community. Result Details Without further ado, here are the questions we asked and the answers you gave us. 94% of respondents use Logstash in a log aggregation use case based on Elasticsearch. In addition, 22% also send logs to other systems, and 16% aggregate other time-series data, such as Twitter and call detail records. And the most-interesting-use-case award goes to the author of the following write-in answer: Cool! 74% of respondents are running Logstash in production, 57% in development, and 16% are just trying it out. 78% of respondents deploy Logstash on premise, 22% in AWS, 2% in Azure. Other public cloud providers include Rackspace, Google Compute Engine, and DigitalOcean. OpenStack got some mentions among private cloud technologies. Linux leads as the operating system of choice for Logstash deployments with 93% of respondents. 16% of respondents are running Logstash on Windows and 7% on Mac OS X.\u00a0 Top Linux distributions in use by the survey respondents are Ubuntu (23%), CentOS (18%), RHEL (12%), and Debian (10%). The majority of respondents (55%) reported deployments with <10K events\/sec. However, a significant number are running with 50K events\/sec, 100K events\/sec, 500 events\/sec, and even >1M events\/sec. Most respondents are running between 1 and 10 Logstash servers, with some outliers in the teens and beyond. A couple of users reported several hundred Logstash servers, but we were not sure if those users counted Logstash Agent deployments on endpoints. Methods for getting data into Logstash vary, but various approaches for shipping logs from endpoints (Logstash Forwarder, Logstash Agent, nxlog, log-courier, Beaver) lead when added together. These are followed by following Logstash inputs in this order: file, syslog, TCP, UDP, Log4j, Twitter, Kafka, and S3. 40% of respondents do not use queueing software to buffer data between different stages of Logstash. Out of the rest, 39% use Redis, 10% use RabbitMQ, and 9% use Kafka. Other mentions include Amazon SQS and ZeroMQ. 53% of respondents are managing Logstash instances manually. The rest are using Puppet, Ansible, Chef, and Saltstack, in that order. A few respondents also mentioned using home-grown configuration management tools. 52% of respondents do not currently monitor Logstash health. The rest use custom scripts and 3rd party tools, mostly Nagios.\u00a0 The majority of the respondents that answered this question are interested in all the additional reliability guarantees we listed and suggested some additional ones in the write-in responses. This is great! We're thrilled to see Logstash's evolution to being a mission critical part of your infrastructure. Good news is that data reliability is a big theme in our 2.x . Similarly, many of you are interested in additional performance improvements, among which faster event processing, lower resource usage, faster startup time, and improved Elasticsearch insert performance are at the top. This aligns with high-throughput deployments some of you are running, based on answers to Question 5. Many respondents skipped this question, but out of 72 respondents, almost half are interested in an HDFS plugin. Cassandra, MongoDB, and Oracle also figured pretty high and other write-in answers indicated additional interest in better integration with other SQL and NoSQL datastores. Some of you mentioned intent to contribute plugins to the Logstash ecosystem - we are excited to work with you to integrate your ! We greatly improved the plugin contribution process in Logstash 1.5 and provided more detailed on how to submit your contributions. An overwhelming majority of respondents are interested in Logstash health metrics via an API. All of our suggestions ranked high, and many of you had other great ideas! 35% of those that responded to this question asked to be contacted by us to speak at meetups. You will hear back from one of our Developer Relations folks soon! Based on IP information, the survey enjoyed participation from all parts of the globe, with highest concentration of responses originating in the San Francisco Bay Area, Midwestern United States, and Western Europe.\u00a0\u00a0 We were delighted to get your general comments at the end of the survey. Many of you simply said \u201cthank you\" and \u201cgreat job\", which was very-very much appreciated by the Logstash development team!! We love all of your comments, so it was really hard to select only a couple to share in this blog. You can read the rest of the comments in the raw data file we provide (see below). Who doesn't?!? For those of you that gave us your contact information, we'll be reaching out soon to share stickers and other goodies. Thank you, all! Conclusions We will continue to pore over the results in search of data that will help us develop a better product for you. However, some conclusions are clear: The good news is that many of these themes are already part of our roadmap, which you can read about on the page. Stay tuned for more news and announcements about future developments as we work through this feedback. Raw Result Data You can download result data . As promised, all personally-identifiable information has been removed from these files. We also provide data transformation scripts and configuration files used to load this data into Elasticsearch for analysis. These files were used with Logstash 1.5 RC2, Elasticsearch 1.5, Shield 1.2, and a fork of Kibana 4.0.2 enhanced with percentage data labels (we are tracking an to implement similar functionality in the product in the future). The results pack consists of the following files: Big thanks to all of you that responded and gave us your feedback! If you'd like to be notified the next time we run a user survey on Logstash - or any of Elastic's products - you can sign up . \n"}<br>{"index": {"_id": 1081}}<br>{"title":"Logstash 1.5.0 RC3 released","seo_title":"","url":"\/blog\/logstash-1-5-0-rc3-released","author":{"name":"Suyog Rao"},"date":"April 23, 2015","category":"Engineering","locales":"","content":" We have a new release candidate () for 1.5.0. After RC2 was\u00a0released last month, we got a lot of input from the community. Among them were reports of performance regressions, which has been the central focus of this release. We also fixed important bugs so we decided to provide an update before making 1.5.0 generally available. Check out the for details. The highlights: Performance regression Users reported a drop in throughput performance when compared to 1.4.2. This was especially evident in configurations\u00a0using conditionals in filters and outputs. We tweaked the code generation in these pipeline stages and made it more efficient. has the details including numbers. Shutdown issuesFixed a bug which manifested in Logstash not shutting down gracefully. The root cause for this issue was pipeline not sending the right shutdown signal to the plugins. (, \u00a0) Java Options Added the ability to append extra JVM options while running Logstash. Setting the\u00a0LS_JAVA_OPTS environment variable will add to the default options. This enhancement\u00a0also provides\u00a0the ability to completely replace the JVM options. For example, users may change the GC algorithm if they wish and use their own instead of the out of the box settings. (#\u00a0 Grok Filter regression Fixed an issue where coercion of int and floats in Grok pattern was causing empty fields to be created (in some cases). This was a side effect of the performance fixes made previously\u00a0for the Grok library. () File Input Users mentioned permission issues (with respect to sinceDB) during Logstash shutdown. Fixed this and other corruption issues while writing file position to sinceDB in the Filewatch gem. (, , ) As always, thanks to all our users for the valuable feedback and contributions. We are in the home stretch for releasing 1.5.0. Please download , try it out, and\u00a0send your feedback by opening an \u00a0on GitHub\u00a0or to us.\u00a0 \n"}<br>{"index": {"_id": 1082}}<br>{"title":"This Week in Elastic: The True Story Behind Elasticsearch Storage Requirements","seo_title":"","url":"\/blog\/2015-04-22-this-week-in-elastic","author":{"name":"Leslie Hawthorn"},"date":"April 22, 2015","category":"","locales":"","content":" Welcome to ! In this weekly round up post, we bring you news on all aspects of the ELK Stack, including updates on Elasticsearch, Logstash and Kibana development, tips and tricks and upcoming events. Just analyzing some space data\u2026 no big deal \u2014 Chris Cowan (@simianhacker) Elastic News Useful blog posts, how tos, tutorials\u00a0and articles\u00a0from the wide world of all the ELK stack ecosystem. Hosting meetup at the office tonight. Organizer Amit covers solving problems zero downtime\u2714\ufe0f \u2014 Rangle.io Inc. (@rangleio) Slides and Videos Query DSL: Not Just for Wizards. Webinar on 28\/4, pres. by wizard \u2014 Found by Elastic (@foundsays) Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking about the ELK stack\u00a0or hosting a meetup, Algiers will take the stage at Voxxed Days Algiers to present An Introduction to the ELK Stack. This first ever conference takes place May 23, and Samir's talk is on for 2:00 PM. Australia . and myself will also be at the Sydney on the 23rd, answering all your + + questions \u2014 Mark Walkom (@warkolm) Austria The Vienna Elasticsearch Meetup will convene on May 12 to hear from on Elasticsearch Under the Hood. to save your seat. Canada If you're attending the upcoming Open Stack Summit in Vancouver, make sure to catch the session. OpenStack Summit runs May 18-22. Denmark Germany Hungary The Craft Conference will be held April 22-24 in Budapest. If you're heading to the conference, make sure to catch talk\u00a0. Latvia Ruslan Zavacky will present on all things Elasticsearch at LatCraft's NoSQL and Data event on May 5. to save your seat and get introduce to Elasticsearch! Norway Our partner firm, Comperio Search, will host a breakfast learning session on all things Elasticsearch on May 6. You'll hear from Elastic's Solutions Architect amongst other speakers. Attendance is free of charge, but . Portugal The Merge Lisbon Meetup Group will get together on May 14 to talk about the ELK stack. to hear from our very own Logstash engineering team member . South Africa Elasticsearch Jo'burg meetup 29 April at Elasticsearch is not just for search. Come explore with us! \u2014 Jurgens du Toit (@jrgns) Spain If you're heading to the Spring I\/O Conference in Barcelona, make sure to catch \u00a0talk\u00a0. The conference runs April 29-30. Turkey Voxxed Days Istanbul is coming up on May 9. Join to learn all about Advanced Search for Your Legacy Application Using Elasticsearch. David at 11:30 AM. United Kingdom We just announced the meetup around London with our expert ! Wed, May 6, 8pm. \u2014 Livia Froelicher (@LivFroe) United States - East The Human Language Technology Conference is coming up in Herndon, Virginia on April 28. If you're attending the conference, make sure to see\u00a0\u00a0presentation\u00a0. The Detroit Python User Group will convene on April 29 to talk Python and Elasticsearch.\u00a0\u00a0to attend. United States - West The Los Angeles Elasticsearch Meetup is getting together , April 22. ! The Enterprise Search and Analytics Meetup group in Silicon Valley will get together on April 23 to talk Exploring Real-Time Aggregations and an Introduction to Elasticsearch and the ELK stack. The speakers for the evening will be two Elastic folks, , Software Engineer, and , Solutions Architect. to save your seat. The Dallas Elasticsearch Meetup has been rebooted! Join the next meetup on April 23 for an Introduction to Elasticsearch. to save your seat. Join the folks from LinkedIn for a meetup on their use of the ELK stack on April 29, which they are kindly hosting in their Mountain View, California office. of Elastic will also be speaking about Logstash and Apache Kafka. to save your space. Attending the ? You can hear from our very own and Tyler Langlois on various topics, from starting your career in open source to all things ELK stack. Plus, we'll have a booth on the show floor so you can get all of your questions answered. Open West runs May 7-9 in Orem, Utah. The Orange County MongoDB Users Group will get together on May 7 to talk Elasticsearch and MongoDB. to save your seat. Does your whale need an ELK buddy? Join the Seattle User Group on May 18 to hear all about using Docker together with the ELK stack. to save your seat. Heading to ? Great, so are we! You can visit us in the exhibits hall to get questions answered throughout the conference, and make sure to check our talk: . Gluecon runs May 20-21 in Broomfield, Colorado. Just scheduled: next Chicago meetup coming up May 13 featuring speakers from RSVP: \u2014 Leslie Hawthorn (@lhawthorn) Where to Find You \u00a0If you're a regular reader, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to\u00a0 ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1083}}<br>{"title":"This week in Elasticsearch and Apache Lucene: 5.1.0 is released!","seo_title":"","url":"\/blog\/2015-04-21-this-week-in-elasticsearch-and-apache-lucene","author":{"name":"Alexander Reelsen"},"date":"April 21, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top NewsThe real deal on disk capacity requirements from + : . \u2014 elastic (@elastic) Elasticsearch Core Apache Lucene Watch This Space , where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 1084}}<br>{"title":"Where in the World is Elastic: JAX Mainz & AWS Summit Sydney","seo_title":"","url":"\/blog\/2015-04-20-where-in-the-world-is-elastic","author":{"name":"Livia Froelicher"},"date":"April 20, 2015","category":"","locales":"","content":" Welcome to\u00a0You want the answer? Just read on for the full list of events and meetup happenings this week. We hope to see you at one of these lovely places!Upcoming EventsApril 21-23:\u00a0\u00a0- Say hi to\u00a0\u00a0&\u00a0\u00a0at the Elastic\/Inovex booth for demos and more!April 21-23:\u00a0\u00a0- Don't miss out on talk about\u00a0, Thursday, April 23, 3:45 p.m. - 4:45 p.m.April 22-24:\u00a0\u00a0- Join\u00a0\u00a0for his talk on\u00a0, Thursday, April 23, 11:55 a.m. - 12:40 p.m.April 22:\u00a0 - Say hi to , who will be\u00a0in the hallway track.\u00a0Ask him about all things ELK\u00a0and AWS.April 23: - Our local support\u00a0engineer Mark Walkom will also\u00a0be attending this event\u00a0and happy to speak to you about all things ELK and Puppet.Upcoming MeetupsApril 20: April 21: April 22: April 23:\u00a0April 23: April 20: April 21:\u00a0April 22: April 22: That's it for this week.\u00a0Stay tuned for Elastic happenings next week - there's much to come!\u00a0- The Elastic TeamP.S.:\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Elasticsearch, Logstash or Kibana\u00a0\u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 1085}}<br>{"title":"Kurrently in Kibana: 4.1 Feature Preview, Part 1","seo_title":"","url":"\/blog\/kurrently-kibana-2015-04-17","author":{"name":"Robyn Bergeron"},"date":"April 17, 2015","category":"Kurrently in Kibana","locales":"","content":" Welcome to , your source for keeping up with the Kibana project. With information on project releases, work in progress, and learning resources, we hope you'll find this weekly update to be pretty... ! Working on a year in review (on IRC) blog post, getting to play with some ElasticSearch and Kibana! \u2014 matthewarkin (@matthewarkin) Kibana 4.1: What's the scoop? In the , we shared you all the glorious details about our planning for the 4.2 feature set. Since then, we've been hard at work on the 4.1 release. You can check out the larger scope of everything planned in the , but here's what we've been doing in the past week or so: Import\/Export saved objects definitions. This allows you to export and share definitions of searches, visualizations and dashboards. It also lets you edit the raw JSON schema and import the object. (Pull pending) Add and sort columns from the dashboard. Previously columns and sort were tied to the saved search. If you wanted to change them you had todo so from Discover by re-saving the search with your new columns and sort. This changes allows you to change those parameters on a dashboard-by-dashboard basis, while still sharing the search between them. Field formatter pull request ready for review! A long time ask, this allows the user to apply transformation functions to the view of a field. For example, setting the precision of a number, or displaying it as bytes. Or taking a string and mapping it to a link. Phase 1 will have pre-defined functions, phase 2 will like be our first foray into a defined plugin structure and will allow users to define their own functions and views for fields. (Pull pending) Sorting on scripted fields. We've long been able to display and filter scripted fields. Now you can sort on them too. This means the only place you can't use scripted fields now is in the query bar. (Pull pending) Added an indication of current time. Super useful for folks with delayed data, or data that goes \u201cinto the future\". It draws a faint red line on the chart at \u201cnow\". This was designed in such a way that we can place multiples of these in arbitrary locations in the future, making them useful chart markers at a later time. (Pull pending) Snapshot builds. Snapshot build artifacts are now available for when you're jonesin' for the latest and greatest thing. Get them . And MOAR! So much more. In case you missed it... No joke! Kibana 4.0.2 was released on April 1, with a number of important bug fixes and small updates to make the Kibana 4 experience even better. Check out our for more information. Tutorials: You want 'em, we got 'em. After a bit of a hiatus during what we call \"The Elastic{ON} Period,\" we're now back in business with the newest episode in our WILDLY POPULAR Kibana 4 video tutorial series. In this third installment, we share with you -- giving you the tips you need to be a geographic-point-association pro! (Sorry if that title is a mouthful. Don't worry, though, you'll be awesome nonetheless.) Filed under: Pics, Or It Didn't Happen An anonymous reporter from the Phoenix, Arizona office shares that some of the Kibana team members at Elastic may have been delighted to be assisting in the \"renovations\" of some sections of the building, taking great pride in hitting stuff with hammers. So never fear, dear readers, it appears to be true: even though it seems like they must never stop, the Kibana team does get away from the desk now and then! :) See You Next Week! As you may have seen, we're now publishing weekly updates on Elasticsearch and Apache Lucene, Logstash and Kibana. We'll bring you the latest and greatest in next week's . If you're using , you should try Kibana. Amazing way to visualise the data in Elasticsearch. \u2014 Nicolas Widart (@NicolasWidart) \n"}<br>{"index": {"_id": 1086}}<br>{"title":"The true story behind Elasticsearch storage requirements","seo_title":"","url":"\/blog\/elasticsearch-storage-the-true-story","author":{"name":"Peter Kim"},"date":"April 17, 2015","category":"Engineering","locales":"","content":" UPDATE: The\u00a0\"sequel\" to this blog post\u00a0titled\u00a0\u00a0was posted on September 15, 2015 which runs these tests against the more recent\u00a0Elasticsearch 2.0beta1. Don't forget to read that after getting through this one! Introduction One of our responsibilities as Solutions Architects is to help prospective users of the ELK stack figure out how many and what kind of servers they'll need to buy to support their requirements. Production deployments of the ELK stack vary significantly. Some examples of use cases we've spoken to people about include: You can run a legitimate mission-critical Elasticsearch deployment with just 1 server or 200 servers. You may need the ability to ingest 1 million documents per second and\/or support thousands of simultaneous search queries at sub-second latencies. Or your needs may be significantly more modest because you're just getting the website\/mobile app for your startup off the ground. So in response to the question, \u201cHow much hardware will I need to run Elasticsearch?\", the answer is always, \u201cIt depends.\" For this blog post, we'll focus on one element of hardware sizing: figuring out the amount of disk required. Also, we'll be using log data as our test data set. Indexing logs, many different ways A typical log message can be anywhere between 200 bytes and 2000 bytes or more. This log message can contain various types of data: Even if the raw log message is 500 bytes, the amount of space occupied on disk (in its indexed form in Elasticsearch) may be smaller or larger depending on various factors. The best way to start making rough estimates on how much disk you'll need is to do some testing using representative data. Apparently, there's word going around that the data volume in Elasticsearch experiences significant expansion during the indexing process. While this can be true due to Elasticsearch performing text analysis at index-time, it doesn't have to be true, depending on the types of queries you expect to run and how you configure your indexing accordingly. It's certainly not an \u201call or nothing\" scenario \u2013 you can configure certain text fields to be analyzed and others to not be analyzed, in addition to tune other parameters which can have a significant impact on disk utilization. A common question asked with regards to disk usage is whether Elasticsearch uses compression \u2013 Elasticsearch does utilize compression but does so in a way that minimizes the impact on query latency. One thing to look forward to is that will allow some configurability in compression.\u00a0 To analyze or to not_analyze As mentioned above, the textual analysis performed at index time can have a significant impact on disk space. Text analysis is a key component of full text search because it pre-processes the text to optimize the search user experience at query time. Fields can be configured to be analyzed, not be analyzed, retain both analyzed and non_analyzed versions and also be analyzed in different ways. A great introduction to the analysis process in Elasticsearch can be found in .\u00a0 Are you _all in? The _all field is a field, which by default, contains values of all the fields of a document. This is extremely convenient when the user doesn't know the field(s) in which a value occurs so they can search for text without specifying a field to search against. However, there will be additional storage overhead if all of a document's fields are indexed as a part of the _all field in addition to being indexed in its own field. More information about the _all field can be found here: . Doc values One additional lever that can have a significant impact on disk usage is doc values. Doc values are a way to reduce heap memory usage, which is great news for people running applications that require memory-hungry aggregations and sorting queries. However, enabling doc values results in additional on-disk data structures to be created at index time which result in larger index files. More details can be found here: . Replication Elasticsearch is a distributed system and an assumption in distributed systems design is that hardware will fail. A well-designed distributed system must embrace this assumption and handle failures gracefully. One way in which Elasticsearch ensures resiliency is through the use of replication. Elasticsearch, by default, enables shard-level replication which provides 1 replica copy of each shard located on a different node. Obviously, if you have an additional copy of your data, this is going to double your storage footprint. Other centralized logging solutions do not enable replication by default (or make it very difficult to set up), so when you're comparing an ELK-based solution to an alternative, you should consider whether replication is factored in. Tests using structured data The test log file used for this test is a 67644119 byte log file. It contains 300000 Apache HTTP log entries from a colleague's blog that look something like this: 71.212.224.97 - - [28\/May\/2014:16:27:35 -0500] \"GET \/images\/web\/2009\/banner.png HTTP\/1.1\" 200 52315 \"http:\/\/www.semicomplete.com\/projects\/xdotool\/\" \"Mozilla\/5.0 (Macintosh: Intel Mac OS X 10_8_2) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/32.0.1700.107 Safari\/537.36\" The testing process itself is straight-forward: Assumptions: Here is a summary of the test results: . Tests using semi-structured data The test log file used for this test is a 75037027 byte log file. It contains 100000 Apache HTTP log entries from the file used in the previous tests, enhanced with a text entry at the end, taken from a semi-random selection of questions and answers from a data dump of the serverfault.com web site: . The text has been cleaned up and the entries look something like this: 83.149.9.216 - - [28\/May\/2014:16:13:46 -0500] \"GET \/presentations\/logstash-monitorama-2013\/images\/Dreamhost_logo.svg HTTP\/1.1\" 200 2126 \"http:\/\/semicomplete.com\/presentations\/logstash-monitorama-2013\/\" \"Mozilla\/5.0 (Macintosh: Intel Mac OS X 10_9_1) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/32.0.1700.77 Safari\/537.36\" There's a new initialize-from-LSN method but it was only introduced in 2008. There's no way to do the equivalent in earlier versions, including 2000. Sorry. The testing process and assumptions are the same as the previous tests. Here is a summary of the test results: Analysis of the results As you can see from the tables above, we see expansion\/contraction ratios between 0.553 and 1.118 for structured data and between 0.951 and 1.399 for semi-structured data depending on how you configure the Elasticsearch mapping. It is also clear that highly structured data allows for better compression compared to semi-structured data. For smaller deployments, this won't make a huge difference \u2013 disk is relatively cheap and a 1.5x - 2x difference from the best case to worst case isn't a significant variance. However, if you're planning for a larger deployment, it will certainly be worth having some intentionality in how you configure your mapping. For example, if you're expecting to ingest 5 TB of structured log data per day and store it for 30 days, you're looking at a difference between 83 and 168 TB in total storage needs when comparing the mappings with minimum vs.\u00a0maximum storage needs. Depending on other factors which will help define how much data you can host on each node while maintaining reasonable query performance, this could mean 20-30 extra nodes. And that's not even considering replication. While there are a number of dimensions in which you can make comparisons, I'll focus on a few. Disabling the _all field reduced the expansion factor from 1.118 to 0.870 for structured data and from 1.399 to 1.051 for semi-structured data. This is a significant reduction in storage footprint which is an easy win if your users are familiar with the fields they want to search against. Even if you can't assume your users know what fields to search, you can customize your search application to take what the user perceives as a non-fielded search and construct a multi-field search query behind the scenes. Configuring the mapping to index most or all of the fields as \u201cnot_analyzed\" reduced the expansion factor from 0.870 to 0.754 or 0.709 for structured data. In the log analysis use case, realistically, many, if not, most of the fields don't represent data that makes sense to run textual analysis on. There are a lot of fields you'll certainly want to run aggregate analysis on (e.g. histograms, pie charts, heat maps, etc.) but these don't require text analysis. Finally, the last area of focus is the impact of doc values. Looking at two mappings that are equivalent besides the doc values config, the difference in expansion factor is 1.118 and 0.970 for structured data. Again, the types of queries you'll expect to run will drive whether you want to enable doc values or not. Heavy use of aggregations and sorting will certainly benefit from using doc values. In most scenarios, JVM heap memory is more precious than disk: the tradeoff of slightly higher disk usage for significantly lower JVM heap utilization is one that most people are glad to make. Conclusion There are a lot of misconceptions out there about how much disk space an ELK-based solution requires but hopefully this blog post sheds some light on how the reality is that \u201cit depends\". Also, figuring out how much hardware you need involves much more than just how much disk is required. We'll save those discussions for future blog posts. :) You can find the files supporting this testing on Github here: . UPDATE: And don't forget to which provides an update to the findings above using Elasticsearch 2.0beta1! \n"}<br>{"index": {"_id": 1087}}<br>{"title":"The Logstash Lines: 0-60 in 60\u201d Webinar","seo_title":"","url":"\/blog\/2015-04-16-logstash-lines","author":{"name":"Leslie Hawthorn"},"date":"April 16, 2015","category":"The Logstash Lines","locales":"","content":" Welcome back to !\u00a0In these weekly\u00a0posts, we'll share the latest happenings in the world of Logstash and its ecosystem. Reminder: Join tomorrow (Apr. 16) as he brings you our \u201c: 0-60 in 60\u201d webinar \u2014 elastic (@elastic) Logstash Core nice! full house for my presentation :) \u2014 Colin Surprenant (@colinsurprenant) That's this week's line on Logstash. Stay tuned for RC3! \n"}<br>{"index": {"_id": 1088}}<br>{"title":"How Skroutz uses Elasticsearch to gather insights on user behaviour","seo_title":"","url":"\/blog\/how-skroutz-uses-elasticsearch-to-gather-insights-on-user-behaviour","author":{"name":"Nikos Fertakis"},"date":"April 16, 2015","category":"","locales":"","content":" Skroutz.gr is a Greek price comparison website that enables its users to filter through a variety of\u00a0more than 7.5 million products in more than 1.5 \u00a0thousand shops. The site has been in business \u00a0for almost 10 years and, in the process, has spinned off a sister site in Turkey, Alve.com. Skroutz will expand into the UK market in the near future with the Scrooge.co.uk site. Being one of the top-3 sites in Greece, and with monthly traffic of more than 12 million visits from more than 4 million unique visitors, it is only natural that we would like to learn something about the way our visitors use our platform. Which product categories or product category families (e.g. \u201cTechnology\") are the most popular? How does time of the season affect each product categories' popularity? Which are our users' most favourite products? Which are the top products of any category right now or a year ago? The most popular shops? Can we drill-down into these results to find the most popular product in a particular shop last summer? From another point of view, maybe we would like to gain some insights about how well our search engine is working. For example, which are the most popular searches on our platform and which are the most popular searches in any specific category? We could also try to identify problematic searches by examining those that return zero results, such as which zero-result query is used most often by our users? Is our search engine performing well? Do our users find what they look for in the first results page, or do they paginate endlessly? How much do they use our search filters? We could obviously go on, but at this point it should be painfully obvious that insights of this kind are of great value and can play a crucial role in the short and long-term development of our product. Certainly, all of the above didn't come to us as some kind of epiphany. Lots and lots of work had been done previously to make sense of the mountains of logs that we keep amassing. With the danger of oversimplifying, we can describe the previous approach as a set of task-specific Ruby scripts that would run in regular intervals, then process the most recent logs and persist the results inside time-stamped MongoDB documents. The results of these computations were presented to users in custom dashboards using libraries such as high charts. Much thought was also put into creating the logs that we use as input. These are text files with lines in JSON format that record the subset of the website activity that is of interest to us. Each line corresponds to a specific user action and contains information such as the type of that action (e.g. \u201cproduct view\", \u201csearch\", or \u201cbrowsing\"), a timestamp, the exact URI and also action-specific fields such as category or product ID, search query etc. Unfortunately, our approach had its limitations. Creating a new dashboard required a lot of \u00a0effort because many layers of the system would have to be touched.Usually, the MongoDB collections required a new schema so that query performance would be acceptable, which in turn meant altering existing scripts or creating new ones to convert the input to the required state. This process translated into time spent on designing, implementing and testing those scripts and also beefing up our MongoDB servers so they could handle the increased workload. Years of repeating the above process whenever a need for a new dashboard arose had left us with a system that was unmaintainable and of debatable value. Sure, it did the number crunching correctly, but the actual presentation of the data was subpar, with the information hidden inside huge tables and dense plots. Any requested change could only be performed by the very few developers that were familiar with the systems inner workings, and even they found the task daunting. All in all, we used to spend more time developing the platform than analysing the data it presented. Things like on-demand dashboards, interactive filtering and ad-hoc queries with acceptable response time looked like a far-fetched dream. The old way had served us well enough until then, but it was obvious that we had to approach our internal analytics platform differently. We were already happy Elasticsearch users here at Skroutz. We depend on it for our search engine functionality and have invested time into creating plugins for NLP tasks like . We have followed the evolution of Elasticsearch from a search-specific platform to one whose power can also be leveraged for analytics. The success stories of companies using Elasticsearch for analytics (such as the or ) also played a part in making us want to investigate and experiment with it. What we found was that the functionality added in version 1.0.0 was a huge boost over facets, and support for in version 1.4 also meant that we could use more complex calculations inside our queries. However, there are two features of Elasticsearch that we consider the most important: the fact that every field is indexed means we can perform ad-hoc queries without performance loss, and the improvements on performance in version 1.4 mean that our computations will not be heavily memory-dependent. Another attractive aspect was that Elasticsearch can work seamlessly with two other tools, Logstash (for log monitoring and parsing) and Kibana (for data visualization) - all three comprising what is known as the ELK stack. The ELK stack offers a complete solution that can take our log files, crunch them, and enable us to create beautiful, interactive and real-time dashboards with minimal fuss. The fact that we could just throw a couple of our log files into ELK and quickly experiment with it, then judge whether it suited our needs also played a huge part in us making up our minds. We decided to spend a few days experimenting with it. Setting up a simple ELK installation on a virtual machine was a breeze using the provided Debian packages. We then took a few days worth of logs, pointed Logstash to their location and let it import their contents into Elasticsearch. After that, it was only a matter of waiting for the import to finish and opening Kibana inside our browsers to validate that our intuition about ELK was correct: we could visualize, aggregate and analyze our logs on demand, going into as much detail as we wanted. After deciding on using the ELK stack for our internal analytics platform, we spent a couple of weeks writing down in detail all of its requirements, creating user stories for the dashboards and planning our developing strategy. During that process we realised we would need to log some new fields so we altered our application's code accordingly. For our infrastructure we decided that we would use two nodes each having 8 cores, 32GB of RAM one 50GB SSD and two 600GB spinning disks, to handle our daily stream of about four million events. We would experiment with importing only new logs and after being satisfied with the cluster's stability we would import a year's worth of backlogs. We would also set up to move older indexes into spinning disks so newer ones would stay on the SSDs. We already had UDP multicast emission of our logs set up in our network, so we wrote a simple program that would join that multicast group and write to a file that would be monitored by Logstash. We also needed to create custom mappings for our Elasticsearch documents. We took care to specify all the field types correctly, set their format to \u201cdoc_values\", and to set all string field (apart from that holding the search queries) indexes to \u201cnot_analyzed\". The next step was configuring Logstash. The most important part was using a filter to point to the timestamp field in our logs so it could be parsed and used by Elasticsearch. Beyond that, we created some regular expressions to extract information such as pagination, ordering and filtering from the URI. Those were either added as tags or as new fields in the resulting document, depending on the use case. Finally, we created a series of Kibana dashboards, extracted them into JSON files and put them under version control. This enables teams to co-operate in creating and modifying dashboards using a pull request-based workflow, thus ensuring that all changes are reviewed, tracked and easy to roll back. We consider our project both a big success and a great start. The simple and intuitive Kibana interface has democratized access to data, making it possible for non-technical people to easily navigate their way through a Kibana dashboard and even create custom panels that suit their specific needs. Everything is indexed and no code needs to be written when a need for different statistics arises. We now have a very fast feedback loop in which the impact of a change in the website can be monitored in real-time, opening many possibilities. But this is only the beginning. We intend to heavily utilize and build upon our new analytics platform, taking advantage of the power that Elasticsearch offers. \n"}<br>{"index": {"_id": 1089}}<br>{"title":"This Week in Elastic: Costin Leau discusses Elasticsearch in the Apache Hadoop ecosystem","seo_title":"","url":"\/blog\/2015-04-15-this-week-in-elastic","author":{"name":"Leslie Hawthorn"},"date":"April 15, 2015","category":"","locales":"","content":" Welcome to ! In this weekly round up post, we bring you news on all aspects of the ELK Stack, including updates on Elasticsearch, Logstash and Kibana development, tips and tricks and upcoming events. Looking to get started with ? Join on Apr 16 for our next live webinar: 'Logstash: 0-60 in 60' \u2014 elastic (@elastic) Elastic News Useful blog posts, how tos, tutorials\u00a0and articles\u00a0from the wide world of all the ELK stack ecosystem. writes about how picked search tech while building on \u2014 Rif Kiamil (@rifkiamil) Slides and Videos Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking about the ELK stack\u00a0or hosting a meetup, will be attending tomorrow meetup at our brand new office at Mountain View and doing a Q&A \u2014 Shay Banon (@kimchy) For folks in NYC: please join & for tonight's meetup on & .NET. RSVP: \u2014 Leslie Hawthorn (@lhawthorn) Australia Join us for the April Sydney ELK Meetup on April 22 for some pretty amazing talks on Docker and ELK plus Elasticsearch + Cassandra + Kafka + Spark in a Windows Environment. to save your seat.\u00a0 . and I will be at Sydney on the 22nd. Come say hi and ask us your + on questions! :) \u2014 Mark Walkom (@warkolm) . and myself will also be at the Sydney on the 23rd, answering all your + + questions \u2014 Mark Walkom (@warkolm) Austria The Vienna Elasticsearch Meetup will convene on May 12 to hear from on Elasticsearch Under the Hood. to save your seat. Belgium The EU edition of will be held this year in Brussels April 15-16.\u00a0, lead developer of Elasticsearch for Apache Hadoop, gave\u00a0his presentation Real Insights, Real-time: Bridging Batch and Real-time Systems for Anomaly Detection already today, but you can still say hello to him in the hallway track. Canada Join the Elasticsearch Toronto User Group on April 21 to talk about Zero Downtime for Elasticsearch in Production. to save your seat. Denmark The Copenhagen .NET User Group will get together on May 12 to talk Serilog and Elasticsearch in .NET. to save your seat. France The Toulouse DevOps meetup will get together on April 20 to talk about Transforming Your Logs into Insights with the ELK stack. to save your seat. Germany Hungary The Craft Conference will be held April 22-24 in Budapest. If you're heading to the conference, make sure to catch talk\u00a0. India Oh btw, I'm talking about and Kibana at this Saturday - \u2014 Ninad Pundalik (@ni_nad) The Madras Java User Group will be holding their Developer Day on April 21. The schedule updates are still in progress, but you'll be treated to a talk on Elasticsearch and Kibana as part of the event program. to attend the event, which is free of charge for all attendees. Israel The Java Israel User Group of Tel-Aviv Yafo will convene on April 19 to discuss Real World Data Pipeline Technologies, including Elasticsearch. The meetup is nearly full, so to save one of the few remaining seats. Portugal The Merge Lisbon Meetup Group will get together on May 14 to talk about the ELK stack. to hear from our very own Logstash engineering team member . South Africa Elasticsearch Jo'burg meetup 29 April at Elasticsearch is not just for search. Come explore with us! \u2014 Jurgens du Toit (@jrgns) Spain If you're heading to the Spring I\/O Conference in Barcelona, make sure to catch \u00a0talk\u00a0. The conference runs April 29-30. Thailand First Elasticsearch Meetup in Thailand on Wednesday, April 22, 2015 by Thai Programmer Network Register here ... \u2014 UP1 (@somkiat) Turkey Voxxed Days Istanbul is coming up on May 9. Join to learn all about Advanced Search for Your Legacy Application Using Elasticsearch. David at 11:30 AM. United Kingdom We just announced the meetup around London with our expert ! Wed, May 6, 8pm. \u2014 Livia Froelicher (@LivFroe) United States - East United States - West On Thurs, join & for the 1st ever meetup in Salt Lake City >RSVP now-we're near full \u2014 Leslie Hawthorn (@lhawthorn) Can't reiterate how much I love & for creating package bring to : its FANTASTIC \u2014 Alex Bresler (@abresler) Where to Find You \u00a0If you're a regular reader, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to\u00a0 ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1090}}<br>{"title":"This week in Elasticsearch and Apache Lucene: Lucene 5.1.0 RC2 vote has passed","seo_title":"","url":"\/blog\/2015-04-14-this-week-in-elasticsearch-and-apache-lucene","author":{"name":"Michael McCandless"},"date":"April 14, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Found by Elastic users, we have made version 1.5.1 available for provisioning. \u2014 Found by Elastic (@foundsays) Elasticsearch Core Live from , shows how uses & for analytics \u2014 elastic (@elastic) Apache Lucene Are you wondering what exactly an Apache Lucene codec is? Read all about it here: \u2014 elastic (@elastic) Watch This Space , where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 1091}}<br>{"title":"Elastic{ON} Video of the Week: The ELK & The Eagle: Search & Analytics for the US Government","seo_title":"","url":"\/blog\/elasticon-video-of-the-week-digitalgovsearch","author":{"name":"Daniel Palay"},"date":"April 14, 2015","category":"User Stories","locales":"","content":" Loren Siebert serves as the technical lead for DigitalGov Search, the U.S. General Services Administration's service that powers the search box for 1,500 government websites.\u00a0 From helping the public find necessary paperwork on transactional pages\u00a0like the Internal Revenue Service and the Immigration and Naturalization Service to helping nature lovers find photos of remote national parks on the Department of the Interior's website, Loren's work has helped revolutionize the way that\u00a0everyday Americans are able to access the treasure troves of information contained in the web properties of the US Government. Here's Loren's video and some of his reflections from his time as a speaker at Elastic{ON}.\u00a0 To watch Loren's full Elastic{ON} talk, follow this or check out his slides below: You can share this or find Loren on Twitter .\u00a0 \n"}<br>{"index": {"_id": 1092}}<br>{"title":"Where in the World is Elastic? Do Not Fringe Portland &Hadoop Summit Brussels","seo_title":"","url":"\/blog\/2015-04-13-where-in-the-world-is-elastic","author":{"name":"Livia Froelicher"},"date":"April 13, 2015","category":"","locales":"","content":" Welcome to\u00a0Where are we this week?\u00a0From the US to the\u00a0UK, Spain, Poland, Belgium, Germany, Japan, Denmark, Israel and Australia, we are\u00a0covering the world\u00a0with a bunch of great events\u00a0and meetups!Upcoming EventsApril 12-14: - and will be giving a workshop on \u00a0on Sunday, April 12 from 1 p.m. to 5 p.m.April 13: - Our own puppet expert, ,\u00a0will be attending.\u00a0Make sure to say hi to him\u00a0in the hallway track!\u00a0April 15-16: - will give a talk on\u00a0, Wednesday, April 15, 2:30 p.m. - 3:10 p.m.April 18-19: - is one of\u00a0the great organizers behind this event where people come together\u00a0to talk about all things\u00a0software development. Say hello to him while you're there, and thank him and the other volunteer team for their great work putting the camp together!Upcoming MeetupsApril 13: April 13: April 13: (live streaming\u00a0the Elastic Portland Meetup)April 14: April 15: April 15: April 16: April 13: April 13: April 14: April 13: April 15: April 14: That's it for this week.\u00a0Stay tuned for Elastic happenings next week - there's much to come!\u00a0- The Elastic TeamP.S.:\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Elasticsearch, Logstash or Kibana\u00a0\u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 1093}}<br>{"title":"Pythonic Analytics with Elasticsearch","seo_title":"","url":"\/blog\/pythonic-analytics-with-elasticsearch","author":{"name":"Andrew Montalenti"},"date":"April 10, 2015","category":"","locales":"","content":" works with top media companies across the web to deliver a real-time analytics dashboard for digital storytellers. We also run an API platform for integrating analytics and content recommendations into websites like NewYorker.com and Arstechnica.com. Python is central to everything we do at the company. So, when we evaluate open source technologies, strong Python support is one of the first things we have in mind. Last year, we built a time series engine called which uses Python to its core. To make this time series engine work at massive scale, we had to take advantage of technologies outside of the Python community. Systems like Apache Storm and Apache Kafka caught our eye, but their Python support was lacking. So, we released our own open source modules like (for Storm) and (for Kafka). I am presenting our work on streamparse this year. This work allowed us to continue using Python, even while our real-time data processing backend spread load among hundreds of cores and many nodes. We maintained a design centered around immutability, reliability, and performance, with message volumes exceeding hundreds of thousands per second. Elasticsearch\u2019s killer features for analytics We first came across Elasticsearch about three years ago, because our team was very experienced with Lucene and Solr. We tracked its development over time, but got very excited about Elasticsearch\u2019s direction in 2014. We recently wrote an in-depth post about Lucene internals called . When we first evaluated Elasticsearch, we considered it merely as an alternative platform for full-text search and \u201chosted\u201d Lucene. But, that all changed last year. Two features caught our eye that made Elasticsearch particularly interesting to Parse.ly: and . When we dug into Elasticsearch some more, we also found an extremely Python-friendly platform for document storage and analytics. Aggregations Aggregations were , but have been actively developed over the last year, and now comprise one of the most powerful query engines available. What\u2019s more, aggregations offer one of the most flexible ways to model time series data. For Parse.ly\u2019s use cases, it met the need to arbitrarily filter time series data, while offering ways to group ( bucket), resample ( bucket), and calculate statistics (, metrics). Though learning the aggregation query API is an exercise in , we eventually built our own wrapper for this atop the excellent Python libraries officially available through Elastic, like and . Time-based indices Time-based indices are a data management technique where you group all records together by some time bucket, such as month, day, or hour. Then, you have some job expunge records that are older than a certain . In Elasticsearch, this is so convenient because dropping an old index is a cheap operation \u2013 essentially equivalent to unlinking a few files. In time series or log data use cases, you may only care to keep a trailing 30 days or 6 months of data. Time-based indices help you accomplish this. What\u2019s great about using Elasticsearch\u2019s time-based indices on a Python project is that the Elastic team maintains the module, which is written in Python, has an , and an for quick management operations. Scaling Elasticsearch in production Together with Elasticsearch\u2019s built-in replication and sharding model, Python programmers have a scalable platform atop which to build Pythonic analytics applications. However, Elasticsearch is not a silver bullet for the challenges of analytics over huge data sets. Parse.ly operates a huge Elasticsearch cluster, and our backend processes billions of data points per day to store over 4 billion documents in Elasticsearch. We had to write our own tooling for index versioning, schema management, monitoring, and cluster expansion, along with our own query layer that took advantage of the above Elasticsearch features. Thankfully, our knowledge of Lucene internals also came in handy, as we tweaked things like and to handle our scale of data with less memory and disk pressure. We also had to think hard about things like compressing our data and optimizing our use of the Lucene index format, so that we could take terabytes of raw customer data and store it in hundreds of megabytes of flexible rollups and summaries in Elasticsearch. However, the results of this work is that we have one of the most flexible analytics stores we can imagine, and a data partitioning and sharding scheme that can help us as we grow. Our customers pay us for our beautiful analytics dashboard (written with AngularJS and d3.js) and our rich HTTP\/JSON APIs (powered by Tornado). Elasticsearch helps us meet our customers\u2019 massive query needs, so that we can focus on our core product and business value. It lets us offer a platform at a disruptively low price point for the enterprise web analytics market \u2013 with a total cost of ownership that is often a fraction of a single data analyst\u2019s salary. To the next thousand customers! Our backend cluster is now spread over 50 production nodes, and growing. Those nodes are dedicated to serving hundreds of the web\u2019s highest-traffic sites \u2013 from top news websites like , to culture\/politics destinations like . Operating at this scale is not easy, and required us to master and combine several open source technologies (Kafka, Storm, Redis, Cassandra, Elasticsearch) while also building plenty of tech on our own. Among all of these technologies, Elasticsearch offered one of the best experiences for Python programmers. It allowed our team to meet several important analytics needs in a Pythonic way. We know it is the right technology to help us get to our next thousand customers. We are happy to be Elasticsearch users, and we are excited for what\u2019s to come in Elasticsearch 2.0! \n"}<br>{"index": {"_id": 1094}}<br>{"title":"Elasticsearch 1.5.1 Released","seo_title":"Elasticsearch 1.5.1 Released","url":"\/blog\/elasticsearch-1-5-1-released","author":{"name":"Clinton Gormley"},"date":"April 09, 2015","category":"Engineering","locales":"","content":" Today, we are pleased to announce the bugfix release of , based on . This is the latest stable version of Elasticsearch. You can . This release contains an important bug fix which affects the speed of allocating a shard to a new node. The first phase of shard recovery copies all the segment files from the source node to the target node. During this phase, any index, update, or delete requests are recorded in the transaction log, to be replayed on the target node at the end of recovery. If the shard is very large, this transaction log can accumulate many events which need to be replayed.\u00a0 Previously, merges of new segments were disabled on the target node during recovery. A large transaction log would result in an explosion of small new segments, severely impacting the speed of recovery. Issue changes the behaviour to enable merges on the target shard during recovery. Other notable bug fixes include: Finally, in case you haven't seen it, . Please download , try it out, and let us know what you think on Twitter (). You can report any problems on the . \n"}<br>{"index": {"_id": 1095}}<br>{"title":"This Week in Elastic: Kibana 4 video tutorials are back","seo_title":"","url":"\/blog\/2015-04-09-this-week-in-elastic","author":{"name":"Leslie Hawthorn"},"date":"April 09, 2015","category":"","locales":"","content":" Welcome to ! In this weekly round up post, we bring you news on all aspects of the ELK Stack, including updates on Elasticsearch, Logstash and Kibana development, tips and tricks and upcoming events. Kibana 4 talk by at Elasticsearch Seoul meetup. \u2014 Igor Motov (@imotov) Elastic News Useful blog posts, how tos, tutorials\u00a0and articles\u00a0from the wide world of all the ELK stack ecosystem. 3 new Official Images added to Hub in March: \u2014 Docker (@docker) Slides and Videos Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking about the ELK stack\u00a0or hosting a meetup, First Elasticsearch Meetup in Thailand on Wednesday, April 22, 2015 by Thai Programmer Network Register here ... \u2014 UP1 (@somkiat) Australia Join us for the April Sydney ELK Meetup on April 22 for some pretty amazing talks on Docker and ELK plus Elasticsearch + Cassandra + Kafka + Spark in a Windows Environment. to save your seat.\u00a0 Belgium The EU edition of will be held this year in Brussels April 15-16. You can join , lead developer of Elasticsearch for Apache Hadoop, for his presentation Real Insights, Real-time: Bridging Batch and Real-time Systems for Anomaly Detection, on .\u00a0 Canada Join the Elasticsearch Toronto User Group on April 21 to talk about Zero Downtime for Elasticsearch in Production. to save your seat. Denmark The Aarhus Ruby User Group will get together on April 13 to discuss log aggregation on AWS using the ELK stack. They're also on the look out for additional speakers. You can RSVP and get in touch with the organizers to volunteer to present on their . Germany Hungary The Craft Conference will be held April 22-24 in Budapest. If you're heading to the conference, make sure to catch talk\u00a0. Japan Israel The Fullstack Developers User Group of Tel Aviv-Yafo will meet on April 13 to for a workshop on Elasticsearch Basics and Dev Tools. Doors open at 4 PM. to attend. Poland Join the enterprise search meetup in Warsaw tuesday next week (14th Apr) w\/ & me about all things \u2014 Alexander Reelsen (@spinscale) The Enterprise Search Warsaw Meetup will welcome and \u00a0at their April 14 meeting. Please join them to hear about speed in Elasticsearch and Elasticsearch's Rails integration. to save your seat. Spain United Kingdom United States With talking in Seoul, Korea! \u2014 Nathan Zamecnik (@zagnut) Where to Find You \u00a0If you're a regular reader, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to\u00a0 ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1096}}<br>{"title":"Elastic{On} Video of the Week: Powering Real-Time Search at Microsoft","seo_title":"","url":"\/blog\/elasticon-video-of-the-week-microsoft","author":{"name":"Daniel Palay"},"date":"April 09, 2015","category":"User Stories","locales":"","content":" Pablo Castro has been with Microsoft for 13 years and has envisioned, pitched, coded and built teams for projects like Azure Search, SQL Server, and the .NET Framework. We had the great pleasure of having Pablo speak at our first inaugural Elastic{ON} about how Microsoft is using Elasticsearch across several use cases ranging from powering 24,000 search requests per second on MSN.com, to indexing and analyzing all social signals within Microsoft Dynamics CRM, and offering search capabilities within Microsoft Azure. Here's Pablo's video and some of his reflections from Elastic{ON}.\u00a0 To watch Pablo's full Elastic{ON} talk, or check out his slides below: You can share this or find on Twitter. \n"}<br>{"index": {"_id": 1097}}<br>{"title":"Introducing Taming Search","seo_title":"","url":"\/blog\/introducing-taming-search","author":{"name":"Doug Turnbull"},"date":"April 08, 2015","category":"User Stories","locales":"","content":" It's easy to hit a wall when improving the quality of search results. Search relevance ranking can feel very mystical. Leveraging the features of the search engine to return relevant search results is a challenging art. Improving relevance means crafting relevance ranking for a particular kind of content, for a specific user audience with their own expectations, expertise, and vernacular. For this reason, relevance work is unlike any other technical task. Despite the difficulty, the practice of improving relevance is extremely important. Even search developers like us can lose track of how often we use search -- how quickly it has become the *entire* user experience. As users, we don't organize and browse anymore: we search. We look up contacts and friends, find lawnmower parts on craigslist. We search for music, emails, or movies to watch. Doctors search for the latest techniques at the bedsides of sick patients. Patent examiners search existing patents to identify prior art. Search is eating the world -- sinking its fangs into every application. Given search's increasing ubiquity, improving the quality of answers given by the search engine is a keenly felt need.To address this need, we're writing to teach the practice of search relevance. Search is creeping into so many applications and workflows. The needs of each application -- the very definition of relevance -- changes per user experience, user audience, and content. Yet the practice of improving search relevance has common ground and Taming Search teaches it to you!Taming Search bridges two areas of wisdom. On the one hand, there's academic works like that teaches you the computer science, heuristics, and natural language processing behind building a generally relevant search engine. On the other hand, there are practical books like or that provide an overview of Lucene technologies and their features, but don't delve search relevance in any great depth.To improve the search results of everyday applications, we need to bridge the two areas of wisdom. How can you apply the lessons of Information Retrieval to today's search engines? What practical search lessons aren't captured in academic literature that nobody tells you? What practices do the experts use when improving relevance? How can external, enriching resources like ontologies or machine learning technologies be brought to bear on the problem? answers these questions and more!So if you struggle with poor search results, think relevance scoring is a mystical black box, or just want to gain a deeper appreciation of the seeming magic in the search engine, then Taming Search is the book you've been searching for! Check it out, and please be part of the conversation by participating in .\u00a0Happy Searching! \n"}<br>{"index": {"_id": 1098}}<br>{"title":"What is an Apache Lucene Codec?","seo_title":"","url":"\/blog\/what-is-an-apache-lucene-codec","author":{"name":"Michael McCandless"},"date":"April 08, 2015","category":"Engineering","locales":"","content":" You've likely heard that uses something called a codec to read and write index files. What does that really mean? The codec is a concrete instance of the abstract\u00a0 \u00a0class. Each codec has a unique string name, such as \u201cLucene410\", and implements methods to return a separate class for each part of Lucene's index.\u00a0The codec's name is registered with Java's so you can easily get the instance at any time\u00a0from just\u00a0its name. Whenever Lucene needs to access the index, it does so entirely through the codec APIs. This is a vital core abstraction: it isolates all the other complex logic of searching and indexing from the low-level details of how data structures are stored on disk and in RAM. This was a big step forward for Lucene because it presents a much lower barrier to research and innovation in the index file formats than before when the bit-level encoding details were scattered throughout the code base. Each format exposed by the codec in turn provides reading APIs, used at search-time, and writing APIs, used during indexing.\u00a0The codec is set per segment and every segment is free to use a different codec, though that's uncommon. \u00a0A codec defines these 9 formats: Testing a Codec When you create a codec you don't have to implement all nine of these formats! Rather, you would typically use pre-existing formats for all parts except the one you are testing, and even for that one, you would start with source code from an existing implementation and tweak from there. Often it's information retrieval researchers or Lucene developers who experiment with new codecs, using the pluggable infrastructure to try out new ideas, test performance tradeoffs, etc. Speaking of testing, by default Lucene's test framework randomly picks a codec and formats from what's available in the classpath. This is a very powerful way to ferret out any bugs in our default and experimental codecs since . You can use this for your own codecs too. Perhaps you think you've fully debugged your shiny new high performance postings format and you're ready to submit a patch to Lucene, but before you do that, try running all Lucene's tests with your new format. This is easy: run a top-level . You'll also have to ensure your codec's class files are on ant's classpath.\u00a0If you see any exotic test failures that go away when you stop using your codec, roll your sleeves up and start debugging! Experimental Codecs and Backwards Compatibility For each Lucene release, the default codec (e.g. Lucene50 for the 5.0.0 release) is the only one that is guaranteed to have backwards compatibility through the next major Lucene version. All other codecs and formats are experimental, meaning their format is free to change in incompatible and even undocumented ways on every release. Not only are they free to change, but they frequently do! Lucene uses the codec API to implement backwards compatibility, by keeping all codecs for reading (but not writing!) old indices in the module. If you look in that module you'll see a number of codecs to handle reading each of the major format changes that took place during Lucene's 4.x development. Because experimental formats are inherently unstable, they are not exposed in Elasticsearch, and are instead used by Lucene developers to experiment with new ideas. One particularly exotic experimental codec is , .\u00a0It encodes absolutely everything in plain text files that you can browse with any text editor.\u00a0This is a powerful way to learn what Lucene actually stores in each part of the index: just index a few documents and then go open your index in any text editor! However please do not attempt to use this for anything but the most trivial test indices: it is obviously very space and time consuming, and uses inefficient yet approachable implementations. and store doc values and postings entirely in heap, uncompressed as flat native java arrays. These formats are exceptionally wasteful of RAM! also stores all doc values in heap, but in a more compressed fashion. There are also formats that store the entire terms dictionary as a , versus the default postings format which only stores the terms index in heap and must seek and scan a term block to find a given term. Even though the experimental formats have no backwards compatibility, and are thus not suitable for production use, over time their compelling features tend to find their way into the default format. For example, , which so primary key lookups can save a likely otherwise costly disk seek, is now folded into the default . Similarly, we used to have dedicated formats for compressing stored fields, and this has now been folded into as different compression modes (best compression vs. best speed). Another example is primarily disk-based doc values formats, which used to be an experimental format but are now the default, to reduce heap required for large indices. One important property of all codecs is they must encode into the index everything necessary to instantiate themselves at read-time. They must be \u201cself describing,\" neither requiring nor accepting any further parameters at read time. This means Lucene simply reads the codec's name out of the segments file, retrieves the codec instance using Java's SPI, and then uses that codec instance to access everything. Per-field control for Doc Values and Postings Because the postings and doc values formats are especially important, and there can be substantial variation across fields, these two formats each have a special per-field format whose purpose is to let separate fields within a single segment have different formats. The default uses these per-field formats and has two protected methods that you can override during indexing to decide which field uses which format. Furthermore, the write API for these two formats is particularly flexible. Originally these APIs were similar to where a single pass was \u201cpushed\" down to the format. But this was awkward, especially for formats that needed more than one pass through the data to determine the best encoding. We've since switched to a \u201cpull\" API, somewhat analogous to such that the format implementation is free to sweep multiple times through the doc values or postings in order to improve its encoding. Most users will never need to concern themselves with the implementation details under Lucene's codec APIs, because the default codec works very well in general. But if you are an adventurous and innovative developer eager to explore possible improvements, just know that it is easy to create and plug in your own fun modular codec formats! \n"}<br>{"index": {"_id": 1099}}<br>{"title":"This week in Elasticsearch and Apache Lucene: Lucene 5.1.0 has a release branch","seo_title":"","url":"\/blog\/2015-04-07-this-week-in-elasticsearch-and-apache-lucene","author":{"name":"Alexander Reelsen"},"date":"April 07, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this new weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. With talking in Seoul, Korea! \u2014 Nathan Zamecnik (@zagnut) Elasticsearch Core Elasticsearch Plugin Releases Apache Lucene Watch This Space , where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 1100}}<br>{"title":"Kibana 4 Video Tutorials, Part 3","seo_title":"","url":"\/blog\/kibana-4-video-tutorials-part-3","author":{"name":"Nathan Zamecnik"},"date":"April 07, 2015","category":"Engineering","locales":"","content":" After taking\u00a0a brief hiatus in publishing the Kibana 4 video tutorials\u00a0due to , , and then\u00a0decompressing from all that fun,\u00a0we are starting up again! Following up\u00a0on the\u00a0 and of the\u00a0tutorials, check out this new video on how to\u00a0create tile\u00a0maps in Kibana 4.\u00a0 If you're more into reading than watching movies, you'll also\u00a0be happy to know that\u00a0the\u00a0 \u00a0section of Kibana 4 docs\u00a0has been significantly expanded coinciding with the last week, adding\u00a0reference-style guides for every visualization type. \n"}<br>{"index": {"_id": 1101}}<br>{"title":"Where in the World is Elastic: Pycon Montreal & Devoxx Paris","seo_title":"","url":"\/blog\/2015-04-06-where-in-the-world-is-elastic","author":{"name":"Livia Froelicher"},"date":"April 06, 2015","category":"","locales":"","content":" Welcome to\u00a0We're kicking off April in full swing as we attend and host events worldwide. Check out\u00a0what's coming up next and we hope to see you one of these\u00a0shows!Upcoming EventsApril 8-12: - Honza Kral, Pier-Hugues Pellerin, and Peter Kim will give a \u00a0on Wednesday, April 8, 9 a.m\u00a0-\u00a010:30 a.m. Don't forget to\u00a0stop by our Elastic booth as well from April 9-11\u00a0to get sweet swag and talk to our developers!April 12-14: - and \u00a0are giving an on Sunday, April 12, 1 p.m. - 5 p.m.\u00a0April 8-10: - Join us for some ELK stack fun with\u00a0\u00a0\u00a0and\u00a0\u00a0:- \u00a0Wednesday, April 8, 5:55 p.m. - 6:25 p.m.- around the ELK stack, Thursday, April 9, 7:30 p.m. - 8:30-\u00a0\u00a0on Friday, April 10, 2:25\u00a0p.m.-5:25 p.m.April 11: - Jun Ohtani will be speaking about\u00a0\u00a0at\u00a06 p.m.Upcoming MeetupsApril 11: April 9: April 7: April 8: That's it for this week.\u00a0Stay tuned for Elastic happenings next week - there's much to come!\u00a0- The Elastic TeamP.S.:\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Elasticsearch, Logstash or Kibana\u00a0\u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 1102}}<br>{"title":"This week in Logstash: Final touches on Logstash 1.5","seo_title":"","url":"\/blog\/2015-04-03-this-week-in-logstash","author":{"name":"Aaron Mildenstein"},"date":"April 03, 2015","category":"","locales":"","content":" Welcome back to This Week in Logstash!\u00a0In these posts, we'll share the latest happenings in the world of Logstash and its ecosystem. How To Use and To Centralize Logs in \u2014 Manuel de la Pe\u00f1a (@mdelapenya) \u00a0\u00a0\u00a0Logstash Core Our team is working to put the final touches on Logstash 1.5. Two weeks ago, we released a candidate for 1.5.0 -- thanks to many users who provided feedback and reported issues. We identified and are working to resolve them. I'd like to highlight these issues: Logstash and Kibana live demo at \u2014 Arno \u2107rpenbeck (@javacgn) \u00a0 \u00a0Logstash Ecosystem Testing out pulling oracle db stats and a dashboard of active sessions and current waits. \u2014 krisrice (@krisrice) A in the wild. \u2014 ChristophB (@dalatangi) \n"}<br>{"index": {"_id": 1103}}<br>{"title":"This Week in Elastic: Release of Kibana 4.0.2 & Deprecating Rivers","seo_title":"","url":"\/blog\/2015-04-02-this-week-in-elastic","author":{"name":"Leslie Hawthorn"},"date":"April 02, 2015","category":"","locales":"","content":" Welcome to ! In this weekly round up post, we bring you news on all aspects of the ELK Stack, including updates on Elasticsearch, Logstash and Kibana development, tips and tricks and upcoming events. Elastic News Useful blog posts, how tos, tutorials\u00a0and articles\u00a0from the wide world of all the ELK stack ecosystem. Found customers, you may now provision 1.5.0. Inner hits, shadow replica, resiliency enhancements! \u2014 Found by Elastic (@foundsays) We've revamped the full text search for the Django docs based on , including browser search! \u2014 Jannis Leidel (@jezdez) Slides and Videos Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking about the ELK stack\u00a0or hosting a meetup, That's adorable! \u201cWhile I was cleaning the flat today I took this photo of my ELK cluster chilling! \" \u2014 Hobbsee (@SarahKowalik) Australia Belgium The EU edition of will be held this year in Brussels April 15-16. You can join , lead developer of Elasticsearch for Apache Hadoop, for his presentation Real Insights, Real-time: Bridging Batch and Real-time Systems for Anomaly Detection, on .\u00a0 Canada The Elastic team is proud to sponsor , and , , ,\u00a0 and\u00a0\u00a0look forward to seeing you at our booth on the show floor. We'll be sharing all things ELK Stack for Pythonistas, plus telling you all about how \u00a0can make life better for all you folks looking to integrate Elasticsearch as a Service in your Python applications.\u00a0 Even better, Honza, PH and Peter\u00a0will bring you a 1.5 hour tutorial on , including an introduction to our Python language clients. The tutorial takes place on April 8 from 9 - 10:30 AM, and PyCon runs April 8-16, including conference sessions and sprints, in Montreal. In Toronto instead of Montreal? We've got you covered! Join the Elasticsearch Toronto User Group on April 21 to talk about Zero Downtime for Elasticsearch in Production. to save your seat. Denmark The Aarhus Ruby User Group will get together on April 13 to discuss log aggregation on AWS using the ELK stack. They're also on the look out for additional speakers. You can RSVP and get in touch with the organizers to volunteer to present on their . France Germany Hungary The Craft Conference will be held April 22-24 in Budapest. If you're heading to the conference, make sure to catch talk\u00a0. Japan Korea The Seoul community will hold their next\u00a0Study Session on April 7, with presentations from and from Elastic. Check out the on the event from Jong Min Kim, the Seoul Study Session organizer. Jong Min's post includes details on registering for the Study Session. India The TechNxt user group in Pune will meet on April 4 to talk Application Containers and Measuring Systems Performance. You guessed it, the systems performance talk will feature details on the ELK stack. to attend. Israel The Fullstack Developers User Group of Tel Aviv-Yafo will meet on April 13 to for a workshop on Elasticsearch Basics and Dev Tools. Doors open at 4 PM. to attend. Poland The Enterprise Search Warsaw Meetup will welcome and \u00a0at their April 14 meeting. Please join them to hear about speed in Elasticsearch and Elasticsearch's Rails integration. to save your seat. Spain Sweden The first ever Elastic Meetup in G\u00f6teborg will convene on April 9 at 5 PM to discuss getting started with Elasticsearch and the ELK Stack.\u00a0 \u00a0to save your seat. United Kingdom United States Attending ? Come join me and to for an workshop and rebuild search! \u2014 Martijn Laarman (@Mpdreamz) Where to Find You \u00a0If you're a regular reader, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to\u00a0 ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1104}}<br>{"title":"This week in Elasticsearch and Apache Lucene: Deprecating Rivers feature for Elasticsearch","seo_title":"","url":"\/blog\/2015-04-01-this-week-in-elasticsearch-and-apache-lucene","author":{"name":"Alexander Reelsen"},"date":"April 01, 2015","category":"","locales":"","content":" Welcome to ! With this new weekly series, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. Top News We'll be deprecating our Rivers feature for Elasticsearch. You can read the full details, including recommendations for replacing your own Rivers plugins, in . Attending ? Come join me and to for an workshop and rebuild search! \u2014 Martijn Laarman (@Mpdreamz) Elasticsearch Core Elasticsearch Lyon meetup. 1pb\/s of data collected by large hadron collided. One does not simply store 1pb\/s. \u2014 Pascal Cans \u30c3 (@pcans) Elasticsearch Plugin Releases We had several plugin release in this past week. You can find more information about the updates in\u00a0 And let's not forget the Mapper Attachment plugin, also released as . You can find full details in the \u00a0for each plugin as\u00a0sent to the Elasticsearch User mailing list.\u00a0 Apache Lucene sessions are out! My talk on how we use at Microsoft,including some details: \u2014 Pablo Castro (@pmc) Watch This Space , where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 1105}}<br>{"title":"Kibana 4.0.2 Released","seo_title":"","url":"\/blog\/kibana_4_0_2","author":{"name":"Rashid Khan"},"date":"April 01, 2015","category":"Engineering","locales":"","content":" Small enhancements And a few fixes \n"}<br>{"index": {"_id": 1106}}<br>{"title":"My Year at Elastic","seo_title":"","url":"\/blog\/my-year-at-elastic","author":{"name":"Daniel Palay"},"date":"March 31, 2015","category":"User Stories","locales":"","content":" .textwithvideo {float:left: width:60%: padding-right:20px: } .videowithtext {float:right: width:40%: } @media (max-width: 480px) { .textwithvideo {float:left: width:100%: } .videowithtext {float:left: width:100%: } } One year ago, I stepped into our Los Altos office with a metric ton worth of butterflies in my stomach. Here I was an outsider, with only of six years of political and non-profit work to my name, walking into one of the fastest growing startups in the world. Sure, I'd been around this industry for vast majority of my cognitive life. I grew up in Mountain View, my computer scientist dad worked at Silicon Graphics, then a few startups, and finally at Google. I tried to take after my dad - I even joined Computer Club in Seventh Grade (I'm pretty sure I failed at making a video game in Basic and that was the end of that). From that point forward, I couldn't get into computers or technical tools - instead I always looked to others for tech help: my dad, my three computer scientist roommates, and now my father- and brother-in-law. So what led me to join Elastic (ne\u00e9 Elasticsearch) on March 31, 2014?\u00a0 It would be easy to say the people - I mean how could I argue with the personalities, compassion and backstories of the\u00a0colleagues I have here. There are doctors (medical and academic), published authors, well-known computer programmers and developer relations advocates, legends in sales and operations, and heck, there is even that wicked awesome bald guy who only wears black v-neck t-shirts, Levi's jeans, and Nike shoes. But there were people (maybe not as awesome) in my political and non-profit past. I could say the technology - which is pretty killer. I mean, just check out all the info on our (and while you're there, download the newest versions of everything available). But if you remember, I'm not that strong of a technologist. So why was I here? I could honestly talk about our community-driven success stories until my fingers fell off and I went blue in the face. Each of them is unique and wonderful in their own right, so stay tuned to our blog as we feature more of these stories moving forward and share how Elastic technology is helping play a part along the way. But for now, here is just a quick sample of what I'm talking about: But really, it's the stories that fall under the overarching theme of making society a better place that really get me. There are the nonprofits that use our software ( and GuideStar come to mind): there are the universities - both domestic (including the University of Georgia system) and foreign (KU Leuven for instance) making intranet search easier for their students: and there are even hospitals, including Mayo Clinic and Oklahoma's Integris Health, making sure that their patient care is faster and more efficient. So a year in, why am I here? I've gotten a little more technical (I know how to close an HTML bracket and even know how to poke around Kibana 3 and 4), but more to the point, given how our new office is in Mountain View (actually across the street from where I lived growing up), I'm feeling a little nostalgic, so here it goes: Here's to many more years. \n"}<br>{"index": {"_id": 1107}}<br>{"title":"Deprecating Rivers","seo_title":"","url":"\/blog\/deprecating-rivers","author":{"name":"Shay Banon"},"date":"March 31, 2015","category":"Engineering","locales":"","content":" When I added rivers way back in time in the early days of Elasticsearch, the idea was somewhat novel. One of the first tasks that users do when using Elasticsearch is to get data into Elasticsearch to make it searchable, so why not allow our community to write plugins that can be installed directly on an Elasticsearch cluster\u00a0to pull data into Elasticsearch automatically.The first few rivers implementations were quite successful and very helpful. The CouchDB river was immensely simple and popular (thanks to CouchDB changes API). Others were popular as well, for example, the RabbitMQ one. They did start to slowly show the problematic nature of rivers as well.What was the problem we were witnessing? Cluster stability. You see, by their nature, rivers deal with external systems, and those external systems require external libraries to work with. Those are great to use, but they come with an overhead. Part of it is built in overhead, things like additional memory usage, more sockets, file descriptors and so on. Others, sadly, are bugs.Part of our efforts in the past couple of years has been to improve Elasticsearch resiliency, and we kept seeing, time and time again, that rivers are a big cause for cluster instability, due to their inherent notion of working with external systems and external libraries. When Found joined us a couple of months ago, we found that they see the same thing, with rivers plugins causing most of the cluster instabilities across the thousands of clusters under management.We knew it for some time, and in the spirit of helping users build more resilient systems, we decided to deprecate rivers and ask users to focus on\u00a0getting data to Elasticsearch from \"outside\" the cluster. Rivers are deprecated from 1.5 moving forward. We will probably keep the infrastructure around in 2.0, and only remove them at a later version, to ease the migration.The ease of use in getting data into Elasticsearch is still important though, so where should you go from here?For more than a year, we've had official client libraries for Elasticsearch in most programming languages. It means that hooking into your application and getting data through an existing codebase should be relatively simple. This technique also allows to easily munge the data before it gets to Elasticsearch. A common example is an application that already used an ORM to map the domain model to a database, and hooking and indexing the domain model back to Elasticsearch tends to be simple to implement.Also, Logstash, or similar tools, can be used to ship data into Elasticsearch. For example, some of the rivers Elasticsearch came with are now implemented as Logstash plugins (like the ) in the forthcoming\u00a0Logstash 1.5.I love the community and work that has gone into a vibrant set of river plugins, and the decision to deprecate rivers was not taken lightly. What should you do if you are a river plugin author?Since rivers are relatively self-sufficient, the code can be extracted into a common library that can be used to get data into Elasticsearch. Then, this library can be used in various different places. A simple \"main class\" can be written to allow to execute it as a standalone process.Another option is to move the plugin to be a Logstash input.\u00a0Logstash inputs are very simple to write, and in 1.5 the Logstash team has of writing, maintaining, and discovering plugins super simple.It is a hard decision to take something away, especially with all the effort that has gone into writing those river plugins by the wonderful authors. I deeply apologize for it, and we would love to help out with any questions and ideas on how to move forward adapting them. The issue for it is . \n"}<br>{"index": {"_id": 1108}}<br>{"title":"Where in the World is Elastic: Introducing Elastic{ON}15","seo_title":"","url":"\/blog\/where-in-the-world-is-elastic","author":{"name":"Livia Froelicher"},"date":"March 30, 2015","category":"","locales":"","content":" Welcome to Did you miss this post? If so, very sorry for going quiet for a while! We were\u00a0very busy with\u00a0, our first ever user conference.\u00a0Have you checked out the videos from the conference yet?\u00a0The first wave\u00a0is now available! We've posted the presentation slides from every session and the first batch of videos, including talks from , , , , , , , and .Here is what's coming up next this week in events land:\u00a0Upcoming MeetupsMarch 31: April 2: March 31: April 4: April 4: That's it for this week.\u00a0Stay tuned for Elastic happenings next week - there's much to come!\u00a0- The Elastic TeamP.S.:\u00a0\u00a0if you're interested in hosting a meetup or are giving a talk about Elasticsearch, Logstash or Kibana\u00a0\u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 1109}}<br>{"title":"Kurrently in Kibana: Planning for Kibana 4.2","seo_title":"","url":"\/blog\/kurrently-kibana-2015-03-26","author":{"name":"Rashid Khan"},"date":"March 27, 2015","category":"","locales":"","content":" Like the rest of the Elastic\u00a0engineering team, the Kibana gang gathered for nearly a week of food, fun (a.k.a. beer) and, shockingly, a bit of work too. Let's be honest, not much code got written, and not many pulls were merged, but we did get some important face to face done. Planning for Kibana\u00a04.2 Four dot you say? What happened to Kibana\u00a04.1? It's in progress as we speak. We've been hard at work on Kibana\u00a04.1\u00a0since before Kibana\u00a04.0 GA dropped. If you're interested in Kibana\u00a04.1's key features check out the . That said, we always have our eye on tomorrow to confirm the decisions we make today, so we took the opportunity to nail down the Kibana\u00a04.2 feature set while we were all together in Mountain View, California. So whats up with Kibana 4.2? The big stuff includes: A startup page Kibana currently waits for Elasticsearch to startup before it starts up, however it doesn't make the Kibana web\u00a0server available until the Elasticsearch startup process is done. We think the better bet is to show you what we're waiting on, and why, in the browser. So we're designing a startup status page for Kibana that will be available even when Elasticsearch isn't. Document CSV export We're taking export beyond the chart! Kibana\u00a04.2 will allow for exporting documents from Elasticsearch in a columnized CSV perfect for importing into spread sheets or munging with with command line tools. Authentication We're building a lightweight authentication framework with session support. This will allow for functionality such as logout and timeout, even when paired with HTTP basic auth in Elasticsearch. We plan to build this in an expandable fashion to allow for authenticating against custom services. In the first phase this will be limited to authentication, we plan in the future to allow for permissions on individual dashboards and other stored resources. Log event context extraction When you've finally found that one log you need, you often need to know how it got there. Often you need to see the logs around that log, and Kibana 4.2 will enable that. And oh so much more Want to see it all? Every last thing we're working on for Kibana\u00a04.2.0? Check out the\u00a0Oh, also a\u00a0Zero In addition to planning 4.2, we also planned 4.0.2, our next bug fix release. While there's no major bugs, we're always\u00a0looking to fix the little things. Our prime method of this is the\u00a0end-of-the week party we shamelessly cribbed from the Elasticsearch team called . Every Friday we siege the living day lights out of the easily squash-able bugs, small feature requests and well scoped pull requests so they don't get lost in the noise and get the attention they deserve.And more! What else have we been up to in the last few days? All of this jazz is in the master branch right now. You'll find it all in upcoming releases! Here's a few of the highlights: Bubble charts! This allows for sizing the dots in a line chart according to the result of a metric aggregation, effectively adding another visual dimension. We also enabled the disabling of the connecting lines._timestamp in tables Until a few days ago, _timestamp was available for aggregations but not for viewing. Thats fixed now, along with a bug that could cause changes to the metaFields parameter to be ignored. ACE editor in the object editor We actually intended to have this, but it was excluded from the build. This allows for nicely formatted JSON in the stored object editor. Highlighting for multi-field mappings (e.g., .raw) In previous versions highlighting was not supported for fields that don't actually exist in _source. That's no longer the case, we make a run at highlighting everything possible now, even logstash's .raw fields.Decimals in the range aggregation In some browsers type=number was being treated as only whole numbers. We fixed that. More Next WeekAs you may have seen, we're now publishing weekly updates on Elasticsearch and Apache Lucene, Logstash and Kibana. We'll bring you the latest and greatest in next week's . \n"}<br>{"index": {"_id": 1110}}<br>{"title":"Using Elasticsearch to build a CRM","seo_title":"","url":"\/blog\/using-elasticsearch-to-build-crm","author":{"name":"Jilles van Gurp"},"date":"March 26, 2015","category":"User Stories","locales":"ko-kr","content":" At ,\u00a0we are creating a mobile first CRM that heavily uses Elasticsearch to do all the data heavy lifting and analytics. Mobile first in this case means the primary user experience is running in an environment that is typically not controlled by enterprise IT departments: the user's smartphone, which is the same device that sales people use to communicate with their customers and consequently the ideal place to gather data for CRM purposes.Being on the phone and close to where data is generated enables Inbot to automate CRM data gathering and relieves the user from redundant and tedious data entry tasks. As data enters our system, contextual reports about the sales activity adapt to new incoming data right away. This seamless experience effectively turns what used to be a monthly or quarterly chore for sales representatives into actionable insights generated straight from their sales activity in real-time.Why Elasticsearch?Elasticsearch is a perfect fit for our use case since it provides real-time analytics through aggregations. Aggregations are a game changing feature in our industry and an obviously useful tool for the type of reports that are needed in a CRM product. Few other databases provide this feature and most products that do tend to be specialized data mining products or specialist tools such as Apache Hadoop that are used by data scientists. Elasticsearch aggregations make it possible to get real-time answers to complex questions such as how many of my leads converted in the last quarter, what was the average time from prospect to sale, who sells the most in my team, etc. Additionally, Elasticsearch can store massive amounts of data, and provides very flexible ways of querying and ranking information.Elasticsearch as databaseOver the course of last year, we re-built the Inbot backend on top of Elasticsearch. Prior to this, we had a prototype backend based on MySQL that was struggling in a several areas. When I joined Inbot - early 2014 through acquisition of my location based search company Localstream - the plan initially was to complement the Inbot data platform with a new analytics engine based on Elasticsearch aggregations. However, in May 2014 we decided to re-build the complete backend on top of Elasticsearch and use it as a database as well. From past experience with Localstream, where we used Elasticsearch as a database, and Nokia, where we (ab)used Lucene as a key value store, I already knew that Elasticsearch could easily handle hundreds of millions of small JSON objects, even on very modest servers. At the time, using Elasticsearch as a database was still a somewhat controversial thing to do and the recommended practice was to have a separate datastore and then pump the data from there to Elasticsearch to expose it for search. The reasoning for this was that in case of data loss, you can always simply rebuild your indices from your primary store and everything will be fine. This was also before the infamous was published that brought up\u00a0some resiliency related issues in Elasticsearch.\u00a0The developer team has responded brilliantly to this and as of the latest 1.5.x release most of the issues have been addressed. The upcoming 2.0 release promises to deliver additional resilience related\u00a0enhancements.The reasons we decided to focus on Elasticsearch as a storage layer were very simple: The renewed Inbot platform that was launched November 2014 stores documents that represent contacts, comments, people, teams, customer accounts, deals, conversions, and other business objects in the CRM domain. A typical user will have thousands of contacts, tens or even hundreds of thousands of activities, and hundreds of customers and leads that each have a deal history. All of this data is stored in Elasticsearch in a way that facilitates our reporting and querying needs. Using Elasticsearch for CRMA lot of features in the Inbot app are powered directly by Elasticsearch. A key feature of the app is to highlight contacts and customer accounts that are relevant based on the user's recent activity. This feature is powered using a function score query that we use to rank search results for e.g. a contact search by name. The scoring function relies on an aggregation query that calculates the most relevant contacts for the user based on recent activity. This results in an experience that always emphasizes contacts that are the most relevant to the user. When searching, users can find most people they care about with one or two character searches because people they communicate with less get ranked lower.Most CRM functionality in Inbot is accessible via a commenting feature that is integrated into the application. Users can leave notes on accounts and contacts to each other or for themselves. These notes can contain hashtags, at-tags and other metadata. This provides an easy mechanism for users to group contacts together with a hashtag. Inbot also uses tags to drive the sales pipeline. Users can design their own sales funnel and pick hashtags such as #prospect or # sale that are associated with the right a particular stage. To help users select a deal stage tag or other tags, we use context suggesters when they are searching or leaving notes on contacts. Since all the user's data is stored and indexed straight into Elasticsearch, providing reports and analytics is as simple as running aggregation queries and presenting the results. CRM reports include breaking down activity by team member, deal stage and period. For example, how many deals were closed in January: how many deals moved from the prospect to offer stage: what is the sales forecast for May: etc. are all questions that can be answered from the data Inbot stores in Elasticsearch.FutureInbot has been available in the iOS app store since the beginning of the year. Currently, we are very busy supporting our initial customers and adding more features. We took a big bet on Elasticsearch and this has worked really well for us. The number of users, their contacts, and activities that we have in Elasticsearch is rapidly growing. So, far performance has been as planned and expected. Elasticsearch answers most queries in milliseconds. Typical API requests are handled in well below 50-100ms. Overall, we have been very pleased with Elasticsearch, how well it performs, and how it is evolving. Since we started using it, most releases have included new features or enhancements that we ended up using as well as performance and resilience related enhancements. \n"}<br>{"index": {"_id": 1111}}<br>{"title":"This Week in Elastic: A new format for our blog","seo_title":"","url":"\/blog\/2015-03-25-this-week-in-elastic","author":{"name":"Leslie Hawthorn"},"date":"March 25, 2015","category":"","locales":"","content":" Welcome to ! In this weekly round up post, we bring you news on all aspects of the ELK Stack, including updates on Elasticsearch, Logstash and Kibana development, tips and tricks and upcoming events. What Do You Think? We're experimenting with a new format for our blog, publishing more granular updates on each project weekly. We'll then share a wider overview of the full ELK ecosystem each Wednesday. We'd love to hear what you think, and even better if you have a story to suggest that we share with the community. We welcome your feedback and submissions, so Elastic News Useful blog posts, how tos, tutorials\u00a0and articles\u00a0from the wide world of all the ELK stack ecosystem. module 0.9.3 released! Get your Puppetizing fix at \u2014 Richard pijnenburg (@Richardp82) Elasticsearch \u3092\u4f7f\u3063\u305f\u4f4d\u7f6e\u60c5\u5831\u691c\u7d22 \u2014 \u30af\u30c3\u30af\u30d1\u30c3\u30c9\u958b\u767a\u8005\u30d6\u30ed\u30b0 (@cookpad_tech) Slides and Videos This week, we're delighted to bring you all things Elastic{ON}, our first ever user conference. You can check out all of the slides and videos we currently have online in our , but here are a few of our favorites. Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking about the ELK stack\u00a0or hosting a meetup, Australia \u00a0will visit the Australian Computer Society (ACS) meeting on April 8 to discussing Corralling Logs with ELK. You can\u00a0\u00a0for this session, which is free of charges for ACS Members. Belgium The EU edition of will be held this year in Brussels April 15-16. You can join , lead developer of Elasticsearch for Apache Hadoop, for his presentation Real Insights, Real-time: Bridging Batch and Real-time Systems for Anomaly Detection, on .\u00a0 Canada The Elastic team is proud to sponsor , and , , ,\u00a0 and\u00a0\u00a0look forward to seeing you at our booth on the show floor. We'll be sharing all things ELK Stack for Pythonistas, plus telling you all about how \u00a0can make life better for all you folks looking to integrate Elasticsearch as a Service in your Python applications.\u00a0 Even better, Honza, PH and Peter\u00a0will bring you a 1.5 hour tutorial on , including an introduction to our Python language clients. The tutorial takes place on April 8 from 9 - 10:30 AM, and PyCon runs April 8-16, including conference sessions and sprints, in Montreal. Denmark The Aarhus Ruby User Group will get together on April 13 to discuss log aggregation on AWS using the ELK stack. They're also on the look out for additional speakers. You can RSVP and get in touch with the organizers to volunteer to present on their . France Germany Japan Korea The Seoul community will hold their next\u00a0Study Session on April 7, with presentations from and from Elastic. Check out the on the event from Jong Min Kim, the Seoul Study Session organizer. Jong Min's post includes details on registering for the Study Session. India The TechNxt user group in Pune will meet on April 4 to talk Application Containers and Measuring Systems Performance. You guessed it, the systems performance talk will feature details on the ELK stack. to attend. Italy \u00a0will take the stage at Code Motion Rome to discuss\u00a0. David speaks at 3 PM on March 28, and the conference runs the 25-28. Spain The next\u00a0Elasticsearch Barcelona Meetup will take place on April 13, covering Elasticsearch Applied for Music Monitoring and Elasticsearch: More than Just Search for\u00a0your applications. to save your seat, as this meetup is filling up fast! Sweden The first ever Elastic Meetup in G\u00f6teborg will convene on April 9 at 5 PM to discuss getting started with Elasticsearch and the ELK Stack.\u00a0 \u00a0to save your seat. United States Ever have a need to search, analyze, or visualize your data? Join Rick Haffey to learn how can help. \u2014 LCNUG (@LCNUG) Where to Find You \u00a0If you're a regular reader, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to\u00a0 ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1112}}<br>{"title":"This Week in Elasticsearch and Apache Lucene - March 25, 2015","seo_title":"","url":"\/blog\/30-mar-2015-this-week-in-elasticsearch-and-apache-lucene","author":{"name":"Ryan Ernst"},"date":"March 25, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to ! With this new weekly post, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. We're experimenting with this new format, and we welcome your feedback. Give us a to let us know what you think! Developer All Hands Meeting Last weekend, the Elasticsearch developer team met for an all hands meeting following .\u00a0This was the first time since June of last year that the entire engineering team came together in one place. We're an incredibly distributed team that's doubled in size since then, so coming together to get on the same page, in the same place was, in a word, fantastic. (P.S. .) We took the time to learn about our new friends at , discuss the \u00a0and long term\u00a0future, and just talk shop about the .\u00a0 But we didn't stop there: we discussed our culture, our communication styles, and of course, we also got to know each other better in a way one can only do\u00a0in person: over a beer or two.\u00a0We even spent a night hacking together which produced some . Top News In case you missed it, we released Elasticsearch 1.5.0 on Monday! This is the latest stable version of Elasticsearch. It contains a number of important resiliency enhancements and bug fixes, and we advise all users to upgrade. This release also includes two new experimental features, inner hits and shadow replicas. Read all about the release and these new features in Clinton Gormley's . Elasticsearch: Level Up We'll share the wider world of all Elasticsearch news with you weekly on Wednesdays in our This Week in Elastic post. But we'll always bring you at least one awesome learning resource here weekly too. From our new Found family members: Designing for your , including tips and tricks for scaling up and out. Have a recommended article, blog post or video you think we should feature in this section? ! Elasticsearch CoreElasticsearch Plugin Releases Elastic and Apache Lucene Watch This Space Stay tuned to the blog, where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 1113}}<br>{"title":"This Week in Elasticsearch and Apache Lucene: Developer All Hands meeting","seo_title":"","url":"\/blog\/25-mar-2015-this-week-in-elasticsearch-and-apache-lucene","author":{"name":"Ryan Ernst"},"date":"March 25, 2015","category":"","locales":"","content":" Welcome to ! With this new weekly post, we're bringing you an update on all things Elasticsearch and Apache Lucene at Elastic, including the latest on commits, releases and other learning resources. We're experimenting with this new format, and we welcome your feedback. Give us a to let us know what you think! Developer All Hands Meeting Last weekend, the Elasticsearch developer team met for an all hands meeting following .\u00a0This was the first time since June of last year that the entire engineering team came together in one place. We're an incredibly distributed team that's doubled in size since then, so coming together to get on the same page, in the same place was, in a word, fantastic. (P.S. .) We took the time to learn about our new friends at , discuss the \u00a0and long term\u00a0future, and just talk shop about the .\u00a0 But we didn't stop there: we discussed our culture, our communication styles, and of course, we also got to know each other better in a way one can only do\u00a0in person: over a beer or two.\u00a0We even spent a night hacking together which produced some . Top News In case you missed it, we released Elasticsearch 1.5.0 on Monday! This is the latest stable version of Elasticsearch. It contains a number of important resiliency enhancements and bug fixes, and we advise all users to upgrade. This release also includes two new experimental features, inner hits and shadow replicas. Read all about the release and these new features in Clinton Gormley's . Elasticsearch: Level Up We'll share the wider world of all Elasticsearch news with you weekly on Wednesdays in our This Week in Elastic post. But we'll always bring you at least one awesome learning resource here weekly too. From our new Found family members: Designing for your , including tips and tricks for scaling up and out. Have a recommended article, blog post or video you think we should feature in this section? ! Elasticsearch Core Elasticsearch Plugin Releases Elastic and Apache Lucene Watch This Space Stay tuned to the blog, where we'll share more news on the whole ELK ecosystem including news, learning resources and cool use cases! \n"}<br>{"index": {"_id": 1114}}<br>{"title":"Elastic{ON} Sessions Are Online","seo_title":"","url":"\/blog\/elasticon-sessions-are-online","author":{"name":"Shay Banon"},"date":"March 24, 2015","category":"News","locales":"","content":" With a little more than a week since our inaugural Elastic{ON} conference, I'm extremely excited to release today, which includes the presentation slides from every session\u00a0and a handful of videos, including talks from , , , , the\u00a0, , , , and . Elastic{ON} was all about sharing knowledge, from\u00a0the sessions during it, to the\u00a0Birds of Feather informal gatherings, and the hugely popular \"Ask Me Anything\" booth that was staffed during the whole conference with developers and employees. Sadly, while all the slides are available, we do not have audio for the first day main stage content\u00a0due to technical problems, including our keynote. It's devastating to lose it, and we are thinking on how to fix it, all the way to kung fu movie style dubbing the videos. We hope you enjoy .\u00a0I am especially excited with our opportunity to show some of the amazing use cases of our Elastic products out there, and happy we can share it with all of you today and in the coming days as we process the rest of them. \n"}<br>{"index": {"_id": 1115}}<br>{"title":"Shield 1.1 and 1.2 Released","seo_title":"Shield 1.1 and 1.2 Released","url":"\/blog\/shield-1-1-and-1-2-released","author":{"name":"Jay Modi"},"date":"March 24, 2015","category":"News","locales":"","content":" We're happy to announce Shield 1.0.2, Shield 1.1 and Shield 1.2, download it ! Shield 1.0.2 is a bugfix release, please see the for more information. Shield 1.1 and Shield 1.2 are the first feature releases since the introduction of Shield in late January. We have received important feedback from our users and the new Shield releases address some of the most requested features and improves overall\u00a0performance.\u00a0Without further ado, here are the highlights: elasticsearch 1.5 support Shield 1.1 and 1.2 are identical feature wise: the only difference is the compatible versions of Elasticsearch. Shield 1.1 is the last feature release that will be compatible with Elasticsearch 1.4.2 and newer versions of 1.4.x: Shield 1.2 requires Elasticsearch 1.5.0 or higher. Additionally, the plugin download service has been enhanced so that installing the latest version of Shield will actually download the appropriate version of Shield based on your Elasticsearch version. ldap user search Shield now supports LDAP user search, which connects to the LDAP server as a specific user with search privileges to find users and groups rather than requiring all users to have LDAP search privileges. LDAP user search provides improved flexibility, better performance when authenticating users in a complex directory structure, and is necessary to work in environments that restrict directory search operations. For more information, please see the . anonymous access Shield now supports anonymous access. Anonymous access (requests without user credentials) in Shield can be mapped to specific roles allowing for fine grained control of what actions are permitted for anonymous users. For example, anonymous searches against a specific index can be allowed while still restricting the modification of data in that index to users with proper authorization. Audit logging for anonymous access is also supported. Anonymous access is disabled by default, read for more information. dynamic ip filtering Shield now allows for IP Filtering settings to be configured dynamically via the . You can dynamically disable or enable ip filtering in addition to updating the allowed and denied hosts. This will be very helpful in expanding a locked down cluster as a new node's IP address can be added to the allowed IP addresses without the need to restart nodes in the cluster. A few examples are provided . mapping ldap users to roles Mapping ldap users to roles is now supported in addition to mapping ldap groups to roles. Mapping users to roles is helpful in environments where maintaining specific LDAP groups for elasticsearch access would cause too much overhead. An example mapping of both users and groups to roles can be found in the section. settings filtering Shield now filters out sensitive settings, such as SSL configuration and passwords, by default and provides a mechanism to specify other settings to filter. These settings will no longer appear in the output of the node settings API. Further information can be found in the section. For a complete changelist, please refer to the . upgrading Please refer to the of the Shield documentation. \n"}<br>{"index": {"_id": 1116}}<br>{"title":"Elasticsearch 1.5.0 Released","seo_title":"Elasticsearch 1.5.0 Released","url":"\/blog\/elasticsearch-1-5-0-released","author":{"name":"Clinton Gormley"},"date":"March 23, 2015","category":"Engineering","locales":"","content":" start body \n"}<br>{"index": {"_id": 1117}}<br>{"title":"This Week in Logstash: Notes from the Engineering All-Hands","seo_title":"","url":"\/blog\/2015-03-23-this-week-in-logstash","author":{"name":"Suyog Rao"},"date":"March 23, 2015","category":"","locales":"","content":" Welcome to our new blog series ! In these posts, we'll share the latest happenings in the world of Logstash and its ecosystem. Let's kick off the series with a special this week \u2014 The Engineering All Hands Edition. After wrapping up our 2 weeks ago, all of our engineers convened in our brand new office in Mountain View for a week of discussions and fun activities. We had a packed agenda to discuss development activities across products, engineering culture, community engagement, and unconference style break-out sessions for discussing each project in detail. We even had an engineering wide hackathon! hackathon tonight - harnessing the brainpower of 50+ engineers and building cool stuff \u2014 Kurt Hurtado (@kurtado) At the Logstash break-out session, we discussed the following things: I'd like to provide notes from few of these discussions here: Plugins ecosystem One of the major goals of Logstash 1.5 was to separate plugins to individual entities outside of the core. Plugins today exist as separate repositories in the GitHub organization. It is our hope that these changes will allow for more community involvement. To this end, we discussed the details of how we would make it easier for developers to create more plugins and contribute to existing ones. We are looking into providing per-repository commit rights to original authors and contributors. We would love for developers to submit their plugins to logstash-plugins \u2014 we discussed all the infrastructure we can provide to support this move. Things like continuous integration, auto generation of documentation, and discoverability are some of the benefits of having your plugins hosted in repository. Watch\u00a0for a blog post coming soon to cover all these details. Pipeline semantics In this session, we discussed providing clean pipeline semantics for plugin developers. With plugins separated from the main core of Logstash, we can provide a clean, documented API to the different pipeline stages that is easy to understand and develop for. Our intention is to make it easy to write plugins in any language (like Java, Clojure, Scala, etc.) that runs on the JVM. We want to standardize the pipeline behavior on errors and non-recoverable conditions across the different stages. We discussed providing an abstraction layer to pipeline internals like threads, intra-stage queues, and dead-letter queues which plugin developers can safely use. We brainstormed the idea of rewriting the LogStash::Event object in Java to allow for efficient serialization across JVM languages. Testing infrastructure At Elastic, providing quality software is in the DNA of our engineers. We invest a lot of effort in testing infrastructure across our projects. We discussed how we can bolster Logstash testing to support plugins and add more integration testing. We discussed the use of Docker to bring up external services like Redis and Elasticsearch. This would make setup and teardown easy during integration testing. We discussed RSpec best practices, randomized testing, adding code coverage reports on our Jenkins runs, and so on. We are already tracking throughput performance of Logstash (across releases) using the ELK stack and we would like to expose that to our community. Long term, we would like to expose infrastructure for developers to test their patch against the performance test suite to make sure they don't introduce regressions! Whiteboarding our testing improvements:\u00a0 Dev workflow In this session we discussed our development workflow \u2014 our intention is to document a lightweight process for everyone to use. We want a consistent GitHub experience across all our open source projects, so we are changing Logstash issue and pull request labeling to match Elasticsearch and Kibana labeling, with all the same colors too :). We want to make it easier to navigate through our GitHub issues and pull requests. All our work at Elastic is peer reviewed, and Pull Requests (PR) are no exceptions. We discussed how we can streamline PR reviews and provide quick feedback. We discussed the details of when a PR is ready to be merged. As a strict policy \u2014 no tests, no merge :) For complex features, we require 2 developers to review the code. This has a side benefit of having developers new to an area ramp up on the code internals. Every member of our team enjoys the (a word play on triage), and merge party, so we will continue to spend our Fridays on IRC triaging issues and Pull Requests. Please join us! Documentation improvements Improving documentation is an ongoing theme in all our releases. We discussed documenting in detail the internal architecture, scaling Logstash deployments and production best practices. We want to bring back the Logstash cookbook which was previously maintained by Jordan Sissel. We want to focus on use case driven documentation like \"How do I ship Apache web access logs using syslog to Elasticsearch?\" and so on. More to come It was wonderful to host all our colleagues from different parts of the world in sunny California! If you attended our conference I hope you had a chance to say hi to a few of them \u2014 we love interacting with our users and hearing from you. We have exciting plans for Logstash \u2014 stay tuned for weekly updates as we turn these ideas into reality. \n"}<br>{"index": {"_id": 1118}}<br>{"title":"Curator 3.0 Released","seo_title":"","url":"\/blog\/curator-3-0-released","author":{"name":"Aaron Mildenstein"},"date":"March 20, 2015","category":"Engineering","locales":"","content":" Curator 3.0 is a terrific update! It may not look like much has changed if you have been using a 2.x version, but there have been many improvements! I am pleased to present these changes to you! Why change it?Is\u00a0Curator 2\u00a0working just fine for you? I'm so glad to hear that! You can, of course, continue to use Curator 2. Because I was dissatisfied with the performance of some operations, I decided to fix it. For example, the Elasticsearch API does not require you to delete indices one at a time, but Curator 2 did. I was dissatisfied with the index selection parameters. While I did have some unit testing, Curator was sorely lacking command-line integration testing. Some bugs might have been easily detected with command-line-level integration testing. All of these, and more still, led me to write Curator 3. Installation and Upgrading Install the latest version of Curator with: Curator can be upgraded to the latest version by running: : This is a major release update. Command-lines from Curator version 2 with Curator 3. With some small modifications, though, they should be good to go. Learn more about alternative methods of installation at . What's new? I am so glad you asked! Let's take a brief look at each of these. Updated API In Curator 2, the Curator API did index (or snapshot) selection in many of the methods. This required a staggering amount of command-line options. It also required fairly complex methods. Now with Curator 3, index selection and filtering is handled before any command method--close, delete, optimize,\u00a0etc.\u00a0--is called. The API methods expect to have the list of indices to act on sent to them as a parameter. As of Curator 3.0.1, a build_filter method has been added to assist in building index filters, as with the command-line. Learn more at . Command-line based on Click is an amazing tool to help build sophisticated command-line interfaces. Using Click also allows me to do full integration testing of the software as though I were issuing commands at a command-line. The big change for the command-line in Curator 3 is the additional sub-commands and , for index and snapshot selection, respectively. To see how this works, you can use the flag at each sub-command: curator --help curator show --help curator show indices --help Learn more in the wiki, in and\u00a0. Pipelined index and snapshot selection To continue where the last section left off, the new index selection parameters can work together in ways that Curator 2 could not touch. You can now specify a line like: curator delete indices --older-than 30 --newer-than 60 --time-unit days \\ --timestring '%Y.%m.%d' --prefix logs --suffix prod \\ --exclude logs-2015.02.01-prod --exclude 2015.01.31 \\ --index logs-2015.02.01-dev This line will delete all indices older than 30 days, but newer than 60 days, with logs as a prefix and prod\u00a0as a suffix, exclude the logs indicated by the patterns given, and force-include . Simply put, Curator 2 could not achieve this level of customizability. Curator 3 also comes with an option to allow you to select all indices. However, if you select the delete command with , the Kibana indices of .kibana, kibana-int, and .kibana-marvel will be auto-pruned. If you wish for Curator to delete one or more of these indices,\u00a0you would have to manually include them with the flag. The flag bypasses all other filtering to add the specified index to the list to be operated on. In fact, the flag, if used by itself, will allow you to act on specified indices directly: curator delete indices --index index1 --index index2 --index index3 This allows for operations on individual indices, which previously required the use of curl or direct API calls. The best part of this change is that you can use Curator on non-time-series indices now! Curator is no longer restricted to operating on time-series indices! Learn more in the wiki, in and\u00a0. Simultaneous operations (where allowed) Curator 2 would only do one action at a time. This could make some operations take far longer than was needful. Curator 3 now only acts one-at-a-time when: All other operations are done simultaneously, or in batches. Elasticsearch has a 4K limit for incoming requests (a changeable default). If the list of indices is too big, this could result in an error. To prevent this, Curator will try to automatically compensate for extremely long lists of indices by slicing them\u00a0into smaller batches. For example, 365 indices named logstash-YYYY.MM.dd takes 4 or 5 batches to complete.Improved Python package Because everything is segmented into separate modules in the API or CLI, the package is much cleaner. This is makes adding or reviewing code much, much simpler. New commands Introducing the and commands. With the improved index selection, you can now re-open closed indices in a batch! You can also change the replica count of indices, even when closed! Improved testing While the current tests do not necessarily catch every conceivable test or condition, a lot of effort was made to get complete code coverage--that is to say, every line of code is evaluated at least once. This has already caught several potential bugs before they could make it into a released version! The\u00a0code coverage is currently at 99%! This includes command-line simulating integration testing! For the first time in Curator's history, the CLI is being tested, and this is a great beginning. A separate blog post will be following to discuss this in further detail. Python3 support restored Somewhere around version 2.1, Curator stopped working with Python3. I apologize for this, if it affected you. I made it a top priority to make Curator 3 work with Python3. All tests pass with 99% code coverage in both Python2 and Python3! Conclusion Curator 3 is a leap forward in performance, usability, and reliability. I would love to have your feedback, positive or negative. As always, if you come across any issues, do not hesitate to raise an issue on . \n"}<br>{"index": {"_id": 1119}}<br>{"title":"Using ELK to Keep the Lights On","seo_title":"","url":"\/blog\/using-elk-to-keep-the-lights-on","author":{"name":"John Boere"},"date":"March 19, 2015","category":"User Stories","locales":"","content":" Keeping the lights on is literally what we mean. We're talking about the world's power grid or more generally, electricity. Electricity, like air and water, is something that most of us take for granted. It should always be there, right? And we're OK when it is. Until it isn't, which somehow always happens at the worst time, like during a storm. How am I going to update my Facebook status now? Seriously though, as an electrical engineer it's my job to make sure we always have an abundance of reliable and high quality power. Without it the world would be a very different place. Most people don't think about it like this, but compare it to water. With shortages (droughts) or pollution, we and our food cannot prosper. It's the same with power, low quality will lead to outages and shorten the lifespan of devices. Interestingly enough without power most of us wouldn't even have access to water, as none of the pumps to deliver it would work. However, reliable power is easier said than done, and engineers have been working on improving this technology for over a 100 years now and still continue to do so. And so are we at . While we don't operate a power plant, we help our customers, utility companies, with preventative maintenance and reducing outage restoration times, among other things. Today, the [power]grid is transitioning from being 'dumb' to getting smarter. This smart grid uses technology to detect and react to local changes in usage, using computer-based remote control and automation. A large number of smart devices and sensors capture data points from the grid. Data is being collected from a variety of systems such as Supervisory Control and Data Acquisition (SCADA), Outage Management Systems (OMS), Smart Meters (AMI) just to name a few. Capturing data from this vast amount of equipment results in a lot of data points. And a lot of this data is also recorded over time intervals, allowing for historical and trend analysis. So what we have is a high volume of data that is being captured at (somewhat) high velocity. Ideally, this data would have to be analyzed in real time. But as it stands now, we have a long way to go before we get to that point. In one instance, data from smart meters doesn't work with the outage management system \u2014from the same vendor! The root of the problem is that all this data is in its own data silos, making collaboration much more difficult, both from a technical and organizational perspective. The end result is increased outage times and lower customer service. Instead, what we need is an effective mechanism to search and analyze across all these incompatible datasets, preferably in real time. Hello ELK stack. At Cliffhanger Solutions, we index data in real time from various sources using Elasticsearch and Logstash. Sources include GPS location data from maintenance trucks or from tablets running our app, readings from smart meters and facility data from GIS (geographical information systems). To visualize, search and analyze this data we build a mapping application (called ATLAS web and mobile) in which we also embed Kibana dashboards. Think of it like Google Maps on steroids. Operators can now quickly get answers to questions like: \"Can I safely close this switch and restore power to these 1500 customers?\" or \"A storm is coming in from the South, how fast can I get my bucket trucks to the area where the storm will hit?\". As for preventative maintenance, engineers can seek answers to questions like: \"Transformers from vendor X have a higher than average MTBF (mean time between failures). Find all of them and sort them by installation date, then send them to the work order system for inspection or replacement\". While it might not sound like a big deal, this is actually pretty incredible and this wasn't possible until now without heavy investments in consultants or getting locked in with the few \"one stop shop\" large vendors that offer a 'total solution'. Anecdote: One company noticed that MTBF was higher for (wood) power poles in an area located near a certain park. After a lot of analysis it turned out that dogs like poles. Who would have thought? This resulted in a shortened lifespan for the pole. The easy fix was to coat some tar around the base of the poles. Cliffhanger Solutions is a small company, but the flexibility of Elasticsearch allowed us to focus on creating value for our customers instead of getting stuck in maintaining different systems for different clients. And our clients are getting it as well. For example, we serve a tiny utility on a Caribbean island, with only 1 guy in the IT department. By using ATLAS (+Kibana) out of the box, we built them a dashboard to show them outages on a map, color coded by customer density. This would never have been possible even a few years ago. The ELK stack is pretty incredible at making data searchable even if the source data is not clearly defined. Unlike traditional databases you don't need to know your questions in advance, you can explore and find correlations you didn't even know existed. It reduces a lot of overhead (who needs a DBA?) and ultimately it keeps the light on! Internally, at the Cliffhanger office, we use the ELK stack to monitor the status of our clients' applications. We use it to improve search relevance, performance, find errors and prevent hack attacks. We share this data with our clients. They like this level of transparency and it gives them confidence that their data is safe. So next time you have a power outage, ask yourself why they are not our client yet. Send them our way, so you can keep updating your FB status : ) \n"}<br>{"index": {"_id": 1120}}<br>{"title":"This Week in Elastic: A new name, logo, and welcome Found!","seo_title":"","url":"\/blog\/2015-03-18-this-week-in-elastic","author":{"name":"Leslie Hawthorn"},"date":"March 18, 2015","category":"","locales":"","content":" Welcome to This Week in Elastic! Our company has a new name, a new logo and some new additions to our team: Welcome ! Starting next week, we'll be bringing you all the news you can use about all things ELK Stack, with more regular updates. You can still look forward to our weekly round up on Wednesdays. Hey dude, where's my commits? After an incredible week last week at , our dev team spent the rest of the week in an all hands meeting figuring out better ways for us to collaborate with the community, how to better improve our projects and enjoying each others' company. We'll return to our regularly scheduled update on all commits next week. Elastic{ON} Last week, we wrapped our first ever user conference in San Francisco. We had more than 1300 attendees, over 40 talks, standing room only Birds of a Feather sessions and a really good time! We'll be bringing you slides and videos from the conference in the next few days, but in the interim we figured you'd enjoy these photos from the event. The only thing better than great talks is to have them in an amazing location. Pier 27 provided more than a few gorgeous views to our attendees throughout the conference. During our opening reception and throughout the rest of the conference, members of our technical staff were around to answer attendee questions. Krijn Mossel and Lee Wright on deck for our Ask Me Anything sessions. During the opening keynotes, we announced our new branding and that the Found team has joined Elastic. Steven Schuurman and Shay Banon welcome the team from Found to the Elastic family. Our Birds of a Feather sessions were so popular, we ended up migrating many of them outside to accommodate more participants. Zachary Tong lead the Practical Time Series Analysis BoF Elastic News Useful blog posts, how tos and articles from the wide world of all the ELK stack ecosystem. If you're interested in seeing your tutorials featured in this section, ! ~100 humans have responded so far, more needed! MT Help us define future of , take our user survey: \u2014 Leslie Hawthorn (@lhawthorn) Blogged: Introduction to Analysing #ODI Runtime Data Through #Elasticsearch and #Kibana http:\/\/ritt.md\/odi-kibana \u2014 Robin Moffatt (@rmoff) Slides and Videos Normally we try to put a few slides and videos here for you to enjoy, but this one was so good that we didn't want to distract you with anything else. Logs! Link! Zelda! DevOps! ELK! Many <3s! Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Director of Developer Relations, , know! Australia will visit the Australian Computer Society (ACS) meeting on April 8 to discussing Corralling Logs with ELK. You can for this session, which is free of charges for ACS Members. France Germany Italy will take the stage at Code Motion Rome to discuss . David speaks at 3 PM on March 28, and the conference runs the 25-28. The Netherlands For folks in or near Utrecht, you can for the GOTO Night on Elasticsearch. Attendees will hear from Anne Veling and Jettro Coenradie, including a recap of the Elastic{ON} conference. The GOTO Night is scheduled for March 25 at bol.com's offices. Sweden United Kingdom The March London Elasticsearch Meetup is on for March 24, featuring speakers from Couchbase, OpenTable, and Postcode Anywhere. to save your seat. United States Where to Find You If you're a regular reader, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) Oh yeah, we're also . If you'd like us to find you for employment purposes, just . We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1121}}<br>{"title":"Discovering the Need for an Indexing Strategy in Multi-Tenant Applications","seo_title":"","url":"\/blog\/found-multi-tenancy","author":{"name":"Konrad Beiske"},"date":"March 17, 2015","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. There are many buzzwords that may be applied to Elasticsearch. Multi-tenancy is one. Getting started with a multi-tenant use case can be deceptively easy - there are some pitfalls that will require a little careful design. \n"}<br>{"index": {"_id": 1122}}<br>{"title":"Elastic: For - You Know, More Than Search","seo_title":"","url":"\/blog\/elastic-you-know-for-more-than-search","author":{"name":"Steven Schuurman"},"date":"March 10, 2015","category":"News","locales":"","content":" When Shay, Uri, Simon and I founded Elasticsearch in 2012, we always knew we were signing up to provide more than \"just search\" to the market. That it was going to be successful at this scale, we could have never dreamt up.Three years, five more products, 20 million downloads, 170 employees, and over 17,000 Meetup members later, the future is looking very bright. If I just look at the we have at our first user conference, Elastic{ON}, I feel humbled. There's the Yale Department of Laboratory Medicine talking about how they use Elasticsearch to identify causes and potential cures for cancer, the U.S. Geological Survey uses the ELK Stack to supplement their seismographic data with social media data in order to better assess and react to earthquakes, FICO will show how it uses Elasticsearch to calculate more accurate credit scores, and we've even entered the final frontier, with NASA's Jet Propulsion Lab taking the mainstage on Wednesday morning to tell us how Elasticsearch monitors metrics from the Mars Curiosity rover.All of us at Elasticsearch are blown away each and every day with how developers around the world are putting our products to use. Today, we're about much more than just search. We're obsessed with data, and getting insights out of it. We want our users to query their data, drive analytics and make correlations that couldn't be extracted before, and we've built our products to easily scale along as your data volume grows. We believe we have put a suite of products in place that allows users to extract insights out of their data, that they weren't able to extract before. That alone is more rewarding to us, that many of you will ever know.Mostly driven by the fact that we are now servicing so many more use cases that span way beyond search, we have felt an increasing urge for some time now to rethink our company brand. Elasticsearch is, and will continue to be, the core engine of our product stack, but the company is building and maintaining a suite of solutions that deliver additional functionality beyond Elasticsearch. Because of this, we believe it is time to embrace a new company brand that's as versatile as our products.And on that note, I am extremely excited to be able to introduce you to our very new brand:As a growing number of people, including myself, have been referring to us as \"Elastic\" since the inception of the company anyway, we believe this is actually a very fitting brand name for our us.But there's more.As users have become more familiar with the versatility of the ELK stack, we have seen many organizations deploy multiple ELK clusters supporting as many different use cases. Whereas this is a wonderful evolutionary process, it does create challenges we haven't experienced before. We always felt that there was a good chance that this would happen \u2013 one company running many ELK clusters \u2013 and have therefore always envisioned ourselves creating a revolutionary product in the form of a centralized management infrastructure. An infrastructural layer with the objective to put operations people in control of their ELK landscape across their business.In order to accelerate this next phase of our company beyond search, we've also announced today that we acquired Elasticsearch SaaS provider Found (), whose technology will make it possible to manage multiple clusters: through the SaaS solution, and in the near future, also on premise. Shay gives more details around our teams joining forces in .I'd like to personally thank everyone that's been with us on our journey so far. It's been quite a ride, and it's far from over. For those that want to join us on our adventure, follow us on our new Twitter handle and our brand new website \u2013 we've got a lot more exciting things in store for 2015 and beyond! \n"}<br>{"index": {"_id": 1123}}<br>{"title":"Welcome Found","seo_title":"","url":"\/blog\/welcome-found","author":{"name":"Shay Banon"},"date":"March 10, 2015","category":"News","locales":"","content":" Since the early days of Elasticsearch, we knew search was a versatile platform that caters to many different use cases. Since its early start, and even more so since a company was founded around it, we've been investing in making this a reality. We didn't stop with just Elasticsearch. Over the past couple years, we developed language clients for many popular programming languages. We embraced and developed Kibana to bring us closer to our users when it comes to visualizing and exploring data. Logstash allows users to reach into to the vast amount of time series data they have, process it, and centralize it in Elasticsearch. Elasticsearch for Apache Hadoop allows users to integrate Elasticsearch natively with Hadoop and its vast ecosystem. As you can see, we've been busy. But, we never lost sight of one of our biggest ambitions when we started it all. See, if our belief was true and search enables so many different use cases, it's inevitable that organizations will start using our products across their entire organization, either on premise, or in the cloud. Once this adoption curve hits an organization, we wanted to provide the option to run something we called \"CloudES,\" providing \"Elasticsearch as a Service\" functionality in a single, simple product, both on premise and in the cloud. Yet, there is another reason for this \"CloudES\" product that started to manifest over the past few years. People were not just running multiple Elasticsearch clusters and looking for a way to consolidate them, they were also, at the same time, trying to solve their use case by providing our technology as a service to their entire internal organization. Logging as a Service is the prime example here, as our technology is so advanced to be the only one in the market to really be able to tackle such a problem. We realized that \"CloudES\" would be instrumental for helping companies achieve this ambitious goal as well. While we were busy, one company caught our eyes for some time now, Found ( ). For the past few years, Found has been busy building the best \"Elasticsearch as a Service\" out there. They have built a service that is extremely simple to use, with a very strong technical foundation. Moreover, they have been great educators about Elasticsearch with their Foundation community space and . When we met and started to deep dive into the technical architecture of Found, I was immediately impressed. Found has been providing Elasticsearch as a Service the right way, where each user has their own cluster. But one can't just stop there, and Found has been using Linux containers for some time now to make sure clusters can be easily be packed on beefy machines \u2013 critical when using AWS. But that's not where the technical challenges stop for such a service, and Found has addressed each and every one. The service has a scalable proxy architecture to properly direct traffic of users to their respective clusters, a smart manager that can allocate clusters and instances across a vast array of host machines, all while providing top notch security and privacy. There are many more features implemented in Found, including periodic snapshots, cluster upgrades, and support for multiple Elasticsearch versions. We all thought it was pretty impressive. Once we started to talk about our vision for such a service was when everything just clicked. Found has been thinking and experimenting with taking all that they have built, packaging it up, and allowing users to install it on premise, enabling them to provide Elasticsearch as a Service. This was just spot on when it came to our original vision around CloudES. Couple that with the fact the team is a perfect match to how we work at Elastic, and this opportunity to join forces was just too good to miss out on. I am proud to announce that Elastic has acquired Found, with the whole Found team joining us. We are now light years ahead in bringing our original vision to fruition, and you can see how this is just another good reason for our . about the Found team's thoughts around the subject, and we have created an specifically addressing common questions around it. \n"}<br>{"index": {"_id": 1124}}<br>{"title":"Kibana 4 Video Tutorials, Part 2","seo_title":"","url":"\/blog\/kibana-4-video-tutorials-part-2","author":{"name":"Morgan Goeller"},"date":"March 06, 2015","category":"Engineering","locales":"","content":" Following up on the sweetness in , we are back for more videos on how to make the most of Kibana. Of course, if you like text you can use the for Kibana 4. However, if you like videos, we've got 'em. The first video goes through Data Discovery, a new addition to Kibana 4: \u00a0 Next, we dig into the nitty-gritty details of the Bar Chart: \u00a0 Finally, we look at the Line Chart: \u00a0 Enjoy! \n"}<br>{"index": {"_id": 1125}}<br>{"title":"Logstash 1.5.0 RC2 Released","seo_title":"","url":"\/blog\/logstash-1-5-0-rc2-released","author":{"name":"Suyog Rao"},"date":"March 06, 2015","category":"Engineering","locales":"","content":" We are pleased to announce a bug fix update to . Yesterday we and soon discovered a few issues which warranted a quick bug fix release. You can jump to the directly or check the for updates. Bug Fixes Elasticsearch output Logstash would not start when used with the \u201cnode\u201d and \u201ctransport\u201d protocol option of the elasticsearch-output plugin. The \u201chttp\u201d protocol was not affected by this bug (). Lumberjack input When used with Lumberjack input, Logstash would not start because it was using an old version of the Lumberjack gem. We fixed the issue by publishing a new version (0.0.22) of the Lumberjack gem and updated Logstash to package it (). Again, thanks to our users for reporting these issues. We are constantly evolving our continuous integration platform and we will make necessary additions to catch these issues, so they don\u2019t happen in the future. Please and let us know what you think! You can use our twitter handle () or head to our repository if you find any issues. \n"}<br>{"index": {"_id": 1126}}<br>{"title":"Logstash-Forwarder 0.4.0 Released","seo_title":"","url":"\/blog\/logstash-forwarder-0-4-0-released","author":{"name":"Jordan Sissel"},"date":"March 05, 2015","category":"Engineering","locales":"","content":" I am happy to announce that is now available! This is mostly a maintenance release, but before we talk about that, I want to first address some of the history and problems this project has had.It's been too long since the last release of this project, and for that, I am sorry. We didn't adequately focus on improvements to the forwarder. This neglect got bad, and even lead me to delete what I thought was a broken package repository only to find it was in use by many folks. Sorry about that. As humans, we sometimes make mistakes. Do things, mess up, try to do better next time!In the meantime, we want to provide a stable and happy experience with the logstash-forwarder, while we . Logstash-forwarder 0.4.0 is one such stability release, so what's new in it?Features new since the last release: Bug fixes: Note: This release works well with and has fixes that work with lumberjack input.You can see the detailed here.Please logstash-forwarder 0.4.0 and let us know what you think on . If you'd like to see what we have in store for the future of logstash-forwarder, visit our . \n"}<br>{"index": {"_id": 1127}}<br>{"title":"Announcing Logstash 1.5.0 RC1","seo_title":"","url":"\/blog\/announcing-logstash-1-5-0-release-candidate","author":{"name":"Suyog Rao"},"date":"March 05, 2015","category":"Engineering","locales":"","content":" We are announcing the first candidate for the release of Logstash 1.5.0. You can download Logstash and review the associated . As we mentioned in the release of , the main areas of focus for 1.5.0 were , performance improvements, and integration. Thanks to all our users who reported their experiences with the beta1 release. We made a number of fixes and improvements since then: we would like to highlight few of them here. [UPDATE] Known Issues If you are using the \u201cnode\" or \u201ctransport\" protocol with the Elasticsearch output, follow these steps to set up your output with Logstash 1.5.0 RC1 (): <code>% bin\/plugin uninstall logstash-output-elasticsearch ... % bin\/plugin install logstash-output-elasticsearch ... CouchDB Input We added a brand new plugin to stream events from the API of CouchDB. With this input, any future changes will automatically be streamed as well, making it easy to synchronize your CouchDB data to any target destination. Check out the reference for more information! We will be packaging CouchDB input in the Logstash release package, so it'll be ready to use as soon as you upgrade! Retries in Elasticsearch Output We made the Elasticsearch output more resilient to transient errors in Elasticsearch. Previously, partial failures from the bulk indexing functionality were not handled properly. With this fix, we added the ability to capture failed requests from Elasticsearch and retry them. Error codes like 429 (too many requests) will now be retried by default for 3 times. The number of retries and the interval between consecutive retries can be configured. () Heartbeat Input Plugin We created a new input plugin for generating heartbeat messages at periodic intervals. Use this to monitor Logstash \u2014 you can measure the latency of the pipeline using these heartbeat events, and also check for availability. For more information and configuration, check the . Improved S3 Input and Output We made a number of important fixes to the S3 input and output plugin. Among them: Windows Support We have made great improvements for running Logstash and plugin related infrastructure on Windows, which was degraded since the 1.4.2 release. Users can now install, upgrade, and remove individual plugins on Windows at any time. We also resolved issues related to initial setup, upgrade and file input plugin: Other fixes Documentation Updates We continue to enhance our reference documentation. Since beta1, we added a comprehensive guide for writing and publishing plugins. Check this to add an input plugin: you can also find resources for developing other plugins in the same location. Update from beta1 Since releasing beta1 we made internal changes to the way we install and load plugin gems using the Bundler framework. Unfortunately with this change, we cannot upgrade plugins installed during beta1 to the RC1 version. It is strongly recommended to go with a clean install of LS 1.5.0 RC1. Moving forward, you should be able to upgrade the RC1 package to GA release without any issues. It is worth emphasizing that any Logstash configuration created in beta1 and RC1 can be moved safely to the final 1.5.0 release. Check it out! We are closing on the final few issues before we can release Logstash 1.5.0. As always, we would love your feedback on this release. Please it and let us know what you think. You can open and provide feedback on twitter (). Beyond 1.5 We already started planning beyond 1.5, and to make our efforts easier to follow, we published the with the themes of the next major release. We would love for you to help us in the release planning process by taking the ! \n"}<br>{"index": {"_id": 1128}}<br>{"title":"Marvel 1.3.1 Released","seo_title":"","url":"\/blog\/marvel-1-3-1-released","author":{"name":"Boaz Leskes"},"date":"March 05, 2015","category":"Engineering","locales":"","content":" Today, we are happy to announce the release of . This is a bug fix release focusing on improving agent resiliency and fixing minor issues discovered since the release of , our security product. Although this release doesn\u2019t add many new features, we recommend upgrading at the first opportunity. To upgrade, you must install the latest Marvel plugin on all of your Elasticsearch nodes. As with any other Java plugin, you will need to restart each node (one by one) in order for the newer version of Marvel to become active. The upgrade process is described in more detail in the .Here is a complete list of all the goodness that went into this release:Agent Monitoring UI Sense As always, we welcome all feedback so we can continue improving Elasticsearch Marvel. Please send questions, praise, or pains to the or find us on . \n"}<br>{"index": {"_id": 1129}}<br>{"title":"This Week in Elasticsearch - March 04, 2015","seo_title":"","url":"\/blog\/2015-03-04-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"March 04, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. just restarting elasticsearch over and over as an excuse to google marvel characters \u2014 Michael Dewar (@mikedewar) Elasticsearch core Geohashing Barcelona checkins during using and via \u2014 Outliers Collective (@outliers_es) In apache lucene this past week Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack \u2013 that's Elasticsearch plus Logstash and Kibana \u2013 including plugin and driver releases. Oh the places I'll go. MT : The roadmap is now easier to view, comment, & contribute to! \u2014 logstash (@logstash) Slides & VideosAn introduction to Elasticsearch and the ELK Stack. Lots of material, but well worth a gander for users who are just getting started.For lovers of Django and Elasticsearch, this recent presentation from the Berlin Django User Group is for you!Excellent introduction to application logging using LogstashBetter Decisions Through Data Using the ELK Stack (auf Deutsch) Building unlimited scalable ELK stack on AWS by Asaf Yigal at Elasticsearch Boston meetup \u2014 Igor Motov (@imotov) Where to find UsWe\u2019d love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you\u2019re speaking or hosting a meetup, let our Director of Developer Relations, , know!France Germany India The next Delhi Elasticsearch Meetup will take place on March 14, covering what's new in the ELK stack. to save your place. Italy will take the stage at Code Motion Rome to discuss . David speaks at 3 PM on March 28, and the conference runs the 25-28. The Netherlands For folks in or near Utrecht, you can for the GOTO Night on Elasticsearch. Attendees will hear from Anne Veling and Jettro Coenradie, including a recap of the Elastic{ON} conference. The GOTO Night is scheduled for March 25 at bol.com's offices. The track is complete feat 's Nik Everett & Peter Vulgaris! \u2014 GOTO Amsterdam (@GOTOamst) South Africa The inaugural Capetown Elasticsearch Meetup will convene on March 5 to talk shop and plan for the future of the group. to let the organizers know you plan to attend. Sweden The 8th Elasticsearch Stockholm Meetup is coming up on March 25. will cover data analysis using Kibana 4. We're still searching for a second speaker, so please do get in touch if you're interested in presenting. You can also to save your seat. United Kingdom Elasticsearch will be out in force at QCon London, which returns to the Queen Elizabeth II Conference Center this year. You can visit us at Booth 12 on the show floor. QCon runs March 2-6. And for folks looking for ELK stack goodness in Bristol, you can join the local Java Meetup on March 10 to hear about using Elasticsearch & Kibana alongside Apache Storm. to save your seat. Not planning to come to QCon London, but hoping to hear more about the ELK stack? The March London Elasticsearch Meetup is on for March 24, featuring speakers from Couchbase, OpenTable, and Postcode Anywhere. to save your seat. United States If you're heading to , you can visit our team in Booth 334 to hear all about , , and more! \u2014 Leslie Hawthorn (@lhawthorn) Where to Find You If you're a regular reader of This Week in Elasticsearch, a.k.a TWIES, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) Oh yeah, we're also . If you'd like us to find you for employment purposes, just . We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1130}}<br>{"title":"Kibana 4.0.1 Released","seo_title":"","url":"\/blog\/kibana-4-0-1-released","author":{"name":"Rashid Khan"},"date":"March 04, 2015","category":"Engineering","locales":"","content":" Today we make available the first update to Kibana 4 incorporating a number of important usability and stability fixes.Grab the new release here: For more information on Kibana 4 see the original release blog post: Upgrades and Polling for ElasticsearchKibana 4.0.1 improves on the upgrade process in 2 ways in an attempt to make both upgrades to Kibana and to Elasticsearch more seamless. bug fixesIn addition to the two big items above we also fixed a variety of other issues, including: \n"}<br>{"index": {"_id": 1131}}<br>{"title":"High-Level Logstash Roadmap is Published","seo_title":"","url":"\/blog\/high-level-logstash-roadmap-is-published","author":{"name":"Tanya Bragin"},"date":"March 03, 2015","category":"News","locales":"","content":" At Elasticsearch, we are committed to doing things the open source way. To us, \u201copen\" does not only mean open source software development, but also open and transparent communication about the roadmap. We have always used GitHub to develop our open source projects, and each one of these projects already tracks a number of roadmap features as GitHub issues (see the , , , and issues for more information). While GitHub is great for sharing the details of our work, it can be difficult to get an overview of the immediate roadmap from a long issues list. To make it easier for everyone to consume, we decided to distill the Logstash roadmap issues into major themes and added these to the . We also included pointers to additional resources, if you want to get involved. We started with the because we are particularly excited to share with you what we are planning for Logstash 2.0. However, this is just the beginning! If you like where this is headed, our intent is to do the same for Elasticsearch, Kibana, and ES-Hadoop projects. We invite you to comment on the roadmap page on the and let us know if this information is helpful or if there is anything you'd like us to add or amend. As always, we welcome feature requests, bug reports, and pull requests on . \n"}<br>{"index": {"_id": 1132}}<br>{"title":"Where in the World is Elasticsearch? - March 02, 2015","seo_title":"","url":"\/blog\/where-in-the-world-is-elasticsearch-11","author":{"name":"Livia Froelicher"},"date":"March 02, 2015","category":"","locales":"","content":" It's hard to believe, but the 1 week countdown has started! We are kicking off our first ever user conference, , next week, starting on March 9 in San Francisco! Feel free to share your excitement with us on Twitter using hashtag #elasticon. Hopefully we'll see you there! Until then we have a few more things going on in event land: Upcoming Events March 4-6: \u2013 Don't miss our guest session about how to monitor trends in society before they become issues. The guest session will be held on Tuesday, March 4 at 10:20 AM in the Rutherford room on the 4th floor. We will also hang out at Booth 12, so come say hi and grab some Elasticsearch sweets from our sweet stall! Upcoming MeetupsNorth America March 2: Europe March 3: March 3: March 4: Africa March 5: That's it for this week. Stay tuned for an Elastic{ON} special next week! - The Elasticsearch Team P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch \u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 1133}}<br>{"title":"Behind the Antlers: Life Lessons from the Elastic{ON} CFP","seo_title":"","url":"\/blog\/behind-the-antlers-life-lessons-from-the-elasticon-cfp","author":{"name":"Daniel Palay"},"date":"February 27, 2015","category":"News","locales":"","content":" Thanks for making my job difficult. No, seriously \u2013 I mean it. Thank you for making my job nearly impossible. Sounds strange to hear, no? Let me tell you why I really am grateful for all of you fine humans. When I was handed the job of curating all the responses to our call for papers, I really didn't know what to expect. I was 4 months into my new role here heading up our case study and community engagement programs, so I knew we had some amazing stories out there. I'd heard the whispers out of Rochester, MN, where Elasticsearch has been helping some of the world's best doctors revolutionize how data could help save lives. I'd talked with financial executives who gushed about how their work with the ELK stack had allowed their entire team to form a more complete understanding of their customers, driving overall engagement and increasing company revenue. And, I had even seen how our software was front and center during some recent emergency events, helping to let the public know when and where it was safe to travel. I could go on for more than three sentences, but why spoil all of our upcoming case studies? I knew that there were some great stories out there, but I was certainly not prepared for what was going to happen when November came around and we opened up the application process for the ELK in the Wild track at Elastic{ON}15. From that point until the moment we closed submissions on January 18, we received 142 proposals. These submissions came from 5 continents, countless industry verticals, and covered so many different use cases that I could hardly do them all justice by listing them out here. Suffice it to say, when I sat down on January 19, I finally figured out what it was like to hate your job, but love it all at the same time. I mean, how could I figure out which 11 of these proposed sessions merited selection over the rest. I read and re-read every single submission. I tried to find the special points in all of them (Did it have a positive effect on society? Was it a big name that would draw people to the session? Or did I just nerd out when I read the abstract?). There were submissions from companies whose services I use every day and some that I had never heard of. There were simple search use cases, and some use cases that even the most seasoned Elasticsearch employee hadn't thought of. You folks made me dread getting up in the morning, because I had no idea how I could choose. How could I say that one person's story was better than the next? Well, thanks to several internal meetings, a multitude of confectionary therapy sessions, and our hard working events team finding more space for us to hold a few more talks, we found ourselves with our final agenda \u2013 which you can see here. We have a and one that I'm proud to stand by. That said, I couldn't find a spot for everyone and that realization truly made my job terrible for a while. But then I remembered, the best part of our community is that whether it's at our first Elastic{ON} or on a webinar or at a meetup down the road, there will always be people \u2013 especially me (seriously, I'll be there with bells on) \u2013 wanting to hear the story of how you are changing the world one cluster at a time. Thank you for making my life difficult \u2013 the pleasure was all mine. \n"}<br>{"index": {"_id": 1134}}<br>{"title":"Kibana 4 Video Tutorials, Part 1","seo_title":"","url":"\/blog\/kibana-4-video-tutorials-part-1","author":{"name":"Tanya Bragin"},"date":"February 27, 2015","category":"Engineering","locales":"","content":" With the much-anticipated release of Kibana 4, we were thinking about how to help users get up to speed quickly with the new feature set. As a first step, we wrote up comprehensive for Kibana 4, which is a great reference. However, we felt that the power and ease-of-use of the new interface was best conveyed in a series of short video tutorials, ranging from a high-level overview to panel-by-panel recommendations on how to migrate visualizations from Kibana 3 to Kibana 4. Today, we publish the first four of these videos, with more to come! The first video introduces you to Kibana 4 navigation at a very high-level. Whether you are coming over from Kibana 3 or just starting with Kibana, this one is worth while to check out. \u00a0 The second video walks you through how to build a specific visualization in Kibana 4, in this case a pie chart. \u00a0 The third video shows how you can re-create Kibana 3 \"hits\" panels in Kibana 4. \u00a0 The fourth video shows how you can re-create Kibana 3 \"terms\" panels in Kibana 4. \u00a0 And we're always on the lookout for a good Kibana story. Send us yours to . \n"}<br>{"index": {"_id": 1135}}<br>{"title":"Highlights from Southern California Linux Expo","seo_title":"","url":"\/blog\/highlights-from-scale","author":{"name":"Robyn Bergeron"},"date":"February 25, 2015","category":"News","locales":"","content":" On the road again! I spent this past weekend at the , also known as SCALE. This was the 13th year of this conference, and my 5th year of attending. SCALE is the largest community-organized and operated conference in the United States, with approximately 3,000 people in attendance this year. While I suspect a large portion of that audience is from the southern California area, there were attendees and speakers present from all over the world for 4 days of talks, trainings, learning, and fun. Lucky Number Booth 13! Come meet and from at \u2014 Garick Chan (@ilovegarick) As with most conferences, there was an expo hall, which is where , , , and spent the majority of our time talking to folks either coming by the booth, or visiting other open source projects at their booths. Kurt and Suyog had a demo going on our table, capturing the Twitter stream for the conference (#SCALE13x), which caught many folks' eyes. (Including those of , who is in charge of social media for the SCALE conference: not surprisingly, he was the most prolific tweeter at the event.) Of course, as a conference with its roots in the Linux community, there were many Linux enthusiasts present, as well as many folks who have careers in systems administration. For many of these attendees, there was familiarity with Logstash, but not necessarily with the rest of the ELK stack. But in seeing the demo we had going, many were curious about other ways Elasticsearch and Kibana could be combined with their existing Logstash instances for more sysadmin-focused purposes. Kurt and Suyog pulled together a demo for an Apache web server logging case using the , which I think definitely was more relatable for many of the attendees. Demoing the cool, new Kibana 4 at booth \/w \u2014 Suyog Rao (@suyograo) Another highlight of the conference for us was the Elasticsearch Birds of a Feather (BoF) session, in the prime-time slot of 7pm on Friday night. With 60+ people in attendance over the course of the hour, Suyog and Kurt gave an overview of the ELK stack, handled questions, and encouraged sharing of stories like pros! Wrapping up the evening we were fortunate enough to have a ticket to to give away, and with some attendees hailing from the northern part of California and thus easily able to attend, we drew names out of a hat for the lucky winner. Thanks to everyone who came to the BoF at ! \u2014 elasticsearch (@elasticsearch) Speaking of Elastic{On} \u2014 this will be my next major event to which I'm travelling. This is our first user conference, coming up soon on March 9 \u2013 11 in San Francisco, California. I'm looking forward to meeting many of you there! \n"}<br>{"index": {"_id": 1136}}<br>{"title":"This Week in Elasticsearch - February 25, 2015","seo_title":"","url":"\/blog\/2015-02-25-this-week-in-elasticsearch","author":{"name":"Luca Cavanna"},"date":"February 25, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Elasticsearch core Using to visualize and analyze our costs. CFO is happy, prefers it even to \u2014 Alexander Leschinsky (@glsystemhaus) In apache lucene this past week Versions 1.4.3 and 1.4.4 released for the client. Now with special support for Grails 2.x! \u2014 Chris Earle (@pickypg) Elasticsearch EcosystemHere\u2019s some more information about what is happening in the ecosystem we are maintaining around the ELK stack \u2013 that\u2019s Elasticsearch plus Logstash and Kibana \u2013 including plugin and driver releases. Excellent introduction to Elasticsearch: what it does, fundamental concepts, and how to make it do useful things for you out of the box An introduction to Logstash and its ecosystem. Pablo Figue\u2019s presentation from last week\u2019s Elasticsearch Berlin User Group meeting From the January London Elasticsearch Meetup \n"}<br>{"index": {"_id": 1137}}<br>{"title":"Kibana 4 & Civic Hacking: Investigating Campaign Contributions","seo_title":"","url":"\/blog\/kibana-4-and-civic-hacking-investigating-campaign-contributions","author":{"name":"Peter Kim"},"date":"February 23, 2015","category":"Engineering","locales":"","content":" It's a great time to be a civic hacker. We're seeing increased transparency from local and national governments through more data sets released to the public every day around subjects such as traffic accidents, adverse drug reactions, financial aid applications for higher education loans, restaurant inspections and even public restroom locations. Now, anyone can access this data, analyze it and build apps that promote the common good. Yay for civic hacking! The United States Federal Election Commission publishes campaign contributions data to its website (www.fec.gov), covering elections for President, Senate and House of Representatives. As stated on fec.gov: Providing this information to the public is critical to ensuring the integrity of the election process. So now that the FEC has provided us with the raw data, what can we do with it? If you don't consider yourself a Data Scientist who knows how to analyze data in R or create pretty D3.js-based visualizations like the New York Times, you probably feel stuck at this point. Fortunately, the ELK stack makes it possible to perform rich, visual, interactive data analysis with very little coding. I'll describe data loading steps in a separate post but for now, I'll provide a glimpse at some of the data visualizations possible with Kibana 4. Discover In Kibana 4, you typically start on the Discover tab. This is where you get a high-level view of the data set, immediately seeing the distribution of data over time, a list of the fields that structure your documents, and the contents of some documents in your index. In the screenshot above, we're looking at almost 2.1 million records representing campaign contributions from individuals to political committees during the 2013-2014 election cycle. We can see a clear trend in the number of contributions increasing over the election cycle, with a few interesting spikes at seemingly random points. The column on the left side lists all of the fields contained in the data set. This is extremely helpful in giving us context for the questions we might want to ask of the data. For example, since we now know our data set potentially contains fields such as \u201cname\", \u201ccity\", \u201cstate\", \u201ctransactionAmount\" and \u201ctransactionDate\", we can start building a list of questions we'll want to ask of the data: The list of fields can also be helpful in identifying holes in the data set which may prevent you from getting answers to the questions you want to ask. For example, the file representing these individual contributions does not contain clear information about the committee receiving contributions or the candidate associated with the committee (technically, individual contributions go to a committee associated with a candidate). The raw data file simply contains the cryptic IDs of the committees and associated candidates. This makes it difficult for me to ask a question like \u201cWhat are the names of the top 10 committees receiving contributions?\" Identifying these gaps using the Discover interface can lead us to decide we need to load additional data to make this application more useful. Visualize Once we've identified some questions we might want to ask, we can start building visualizations based on some of the attributes in the data set. Let's take one of the questions we brainstormed above as an example. Here's a pie chart representing the top 10 states from which individual campaign contributions are made, measured by the sum value of contributions: Not a lot of surprises here, as the pie chart shows California, New York, Texas, Florida and Illinois (the five most populous states in the US) amongst the top sources of contributions. DC's position at the #3 spot is interesting and worth investigating\u2009\u2014\u2009even though DC would be the third least populous state if it was a state, perhaps its role as the seat of the federal government naturally draws residents who are more likely to be politically engaged. The pie chart was easy to create: If you've got some experience with data visualization, you might have been thinking \u201cThis guy is a total hack. A pie chart is the wrong visualization to use for this type of data representation.\" And you're right (well, hopefully not about the \u201ctotal hack\" part). There's some distortion of the data here because using a pie chart gives the viewer the misperception that all of the slices add up to 100% of the total data, which in this case, makes it look like contributions from California comprise a quarter of all campaign contributions. You can change the \u201csize\" parameter to '51' so that the sum of the slices adds up to the actual total, but as you can see here, this makes the visualization less pretty: An alternative is to use a different visualization, perhaps a Vertical Bar Chart. The input parameters to creating the Vertical Bar Chart probably look familiar to you. They're exactly the same as the parameters used to create the Pie Chart because the underlying query used to drive the visualization is exactly the same. We're just visualizing it differently here, hopefully with a lower probability of misinterpretation. Dashboard Creating visualizations is fun but at some point, you'll want to package these together onto a nice Dashboard where you can perform some aggregate analysis, gain interesting insights across multiple, disparate fields of data, and share these findings with others. The actual process of adding visualizations to dashboards is straight-forward. Once you've created a number of visualizations you'd want to place on a dashboard together, you can click the Add Visualization icon in the upper right corner of the Dashboard tab and start adding visualizations! Before you start going nuts creating visualizations and dashboards, it would be worthwhile to identify a naming convention to use when saving those elements. For example, prefixing your saved objects with the name of the Elasticsearch index and\/or type is one idea. At some point, you might have a dashboard that looks something like this: Explore Let's walk through two potential data discovery scenarios: one focused on a particular Super PAC and another looking at campaign contributions from your home town. Who's behind these PACs? Political Action Committees, or PACs as they're commonly called, aren't a new thing. The first PAC was created in 1947 in response to a part of the Taft-Hartley Act that prohibited labor unions or corporations from spending money to influence federal elections. Super PACs were made possible by two Supreme Court decisions in 2010 that declared PACs that did not make contributions to candidates, parties, or other PACs could accept unlimited contributions from individuals, unions, and corporations (both for profit and not-for-profit) for the purpose of making independent expenditures. [ ] Super PACs have been the source of much controversy and debate because prior to the existence of Super PACs, there were clear restrictions on the amount of money that could be contributed towards elections. In this screenshot above, we see a high-level view of the contributions, and in particular, the top committees receiving contributions, committee types (e.g. Super PAC, PAC, Party, etc.) and interest group categories (e.g. Corporation, Labor Organization, etc.). I can probably guess what a lot of these committees represent but some of these are less obvious\u2009\u2014\u2009e.g. \u201cACTBLUE\" and \u201cNEXTGEN CLIMATE ACTION COMMITTEE\". Over $77 million contributed to a single vaguely-named committee is worth taking a closer look at. You can filter the data set simply by clicking on that element in the data table: After clicking \u201cNEXTGEN CLIMATE ACTION COMMITTEE\", Kibana refreshes all of the other charts and tables to only show the relevant data for the contributions to this committee. We immediately discover some interesting insights: The vast majority of the contributions to \u201cNEXTGEN CLIMATE ACTION COMMITTEE\" are by people: When you drill down further by clicking on \u201cFAHR, LLC\", it's obvious all of these contributions are from the same person: Prior to drilling down by the employer, we noticed there were only 56 contribution transactions for \u201cNEXTGEN CLIMATE ACTION COMMITTEE\". Just from a few clicks, we've discovered that this Super PAC predominantly consists of contributions from 1 person and a few others, who we presume are likely friends, associates, or have something beyond a superficial relationship. The contributor base for the other large PAC, \u201cACTBLUE\", is quite different. There are far more transactions making up the contributions to this PAC (154,448 vs 56 for NextGen) and the contribution sources are far more geographically distributed: One of the more interesting analytics functions provided by Elasticsearch is the significant terms aggregation. You can use significant terms for use cases such as fraud detection, anomaly detection, recommendations, and more. There's a great introduction to it on the Elasticsearch blog: . With the campaign contribution data set, one example of using significant terms is to identify statistically unique characteristics of a particular query state. For example, it's very common to see contributors with an Occupation of \u201cAttorney\", \u201cRetired\", \u201cLawyer\" across many of the PACs. As a result, just getting a list of the top Occupations for any particular PAC may not disclose useful information about the types of people who contribute to that PAC. Using the statistical terms aggregation, as done on the table on the far right, exposes the Occupations that are uniquely common for ActBlue, such as \u201cProfessor\", \u201cSelf\" and \u201cWriter\": We can filter the data by another PAC, the Democratic National Committee, and discover the occupations that are uniquely common for that PAC: Even though we started this exploration process not knowing anything about these PACs, it's triggered many more questions that I want to follow up on: The beautiful thing about this process is that in addition to helping provide some of the answers to these questions, using the ELK stack helps formulate questions that you didn't even know you wanted to ask! Who are people in my home town giving money to? Warning: Depending on the size of your hometown, your findings here may lead to awkward interactions with your neighbors.\u00a0 All contributions over $200 are required by law to be disclosed to the public so while it might be awkward seeing your neighbor's information here, data about campaign contributions is public information and the public has a legal right to know. You can quickly drill down the data set to state and city and get some insightful information about who in your town is making contributions and to whom. With only 449 transactions from Hoboken, New Jersey, it wouldn't be time consuming to sift through each record one by one. However, if you had to analyze 70,850 contribution records from New York City, there's a clear benefit from being able to do so with the interactive user experience that the ELK stack provides: Back to my hometown of Hoboken, New Jersey, just from making a few clicks, you can start building a list of the top contributors to the campaigns for the local House and Senate seats. I've always been curious why people would contribute money to non-competitive races, which Cory Booker (won with 56% of the vote) and Albio Sires (won with 77.3% of the vote) were involved in. Maybe it's just a matter of wanting to support a friend but a cynic might keep an eye on any potential attempts to return the favor. Conclusion We've just grazed the surface of what's possible when using the ELK stack to explore the FEC campaign contributions data set. Hopefully this exercise has also expanded your vision for use of the ELK stack and apply these same data discovery principles to any type of data whether that's highly structured data (e.g. transaction data), unstructured data (e.g. plain-text documents), or a combination of the two. Individuals, non-profits, government organizations and private companies from startups to large corporations are using the ELK stack to get real-time insights on data sets varying in size from a few megabytes to a few petabytes, and with the release of Kibana 4, this becomes even easier and more powerful. Appendix A. How to get ELK with this data set running on your laptop If you don't already have the ELK stack with the latest versions of each piece of the stack, you can download it and follow the installation instructions on that page. You don't actually need Logstash to get this up and running but if you wanted to tweak the Logstash configs and re-load the raw data yourself, it'd definitely be worthwhile installing it. Restoring the Elasticsearch index snapshot After downloading and installing the ELK stack, you'll need to download the index snapshot file for the campaign contributions data which can be obtained here (FYI it's a 1.4GB file: we take no responsibility for this download eating up your monthly mobile tethering quota): Create a folder somewhere on your local drive called \u201csnapshots\" and uncompress the .tar.gz file into that directory. For example: mkdir -p ~\/elk\/snapshots cp ~\/Downloads\/snapshot_demo_usfec.tar.gz ~\/elk\/snapshots cd ~\/elk\/snapshots tar xf snapshot_demo_usfec.tar.gz Once you have Elasticsearch running, restoring the index is a two-step process: 1) Register a file system repository for the snapshot (change the value of the \u201clocation\" parameter below to the location of your usfec snapshot directory): curl -XPUT 'http:\/\/localhost:9200\/_snapshot\/usfec' -d '{ \"type\": \"fs\", \"settings\": { \"location\": \"\/tmp\/snapshots\/usfec\", \"compress\": true, \"max_snapshot_bytes_per_sec\": \"1000mb\", \"max_restore_bytes_per_sec\": \"1000mb\" } }' 2) Call the Restore API endpoint to start restoring the index data into your Elasticsearch instance: curl -XPOST \"localhost:9200\/_snapshot\/usfec\/1\/_restore\" At this point, go . When your delicious cup of single-origin, direct trade coffee has finished brewing, you can check to see if the restore operation is complete by calling the cat recovery API: curl -XGET 'localhost:9200\/_cat\/recovery?v' Or get a count of the documents in the expected indexes: curl -XGET localhost:9200\/usfec*\/_count -d '{ \"query\": { \"match_all\": {} } }' which should return a count of approximately 4250251. Pointing Kibana 4 to an Elasticsearch index The first time you go to Kibana at localhost:5601, it'll ask you to define an \u201cindex pattern\": Since the Elasticsearch cluster may contain numerous indexes, you need to tell Kibana which index contains the data you want to build visualizations and dashboards against. In this case, the campaign contribution snapshot contained four indexes, so when you ran your index restore operation, it should have created four new indexes in your Elasticsearch instance: You can type in one of these index names into the input field, select a time-field (in our indexes, it will be '@timestamp'), then click Create: In the examples in this blog post, we've exclusively looked at the individual contributions data but there's certainly a wealth of data to explore in the other three indexes. You could even set up an index pattern in Kibana to point to all four indexes and try to correlate data between data sets! Go to the Discover tab, select a more suitable time frame (set an Absolute \u201cFrom\" date of about 2012-12-18), and go exploring! Appendix B. Supporting Links Numerous resources for analyzing campaign finance data. Thanks for providing a more detailed data dictionary for the FEC data! Logstash config, index template, Python script for denormalizing data and creating JSON, etc. \n"}<br>{"index": {"_id": 1138}}<br>{"title":"Where in the World is Elasticsearch? - February 23, 2015","seo_title":"","url":"\/blog\/where-in-the-world-is-elasticsearch-10","author":{"name":"Livia Froelicher"},"date":"February 23, 2015","category":"","locales":"","content":" A bit over 2 weeks until we are off to our first ever user conference in San Francisco, March 9-11- ! Feel free to share your excitement with us on twitter using #elasticon. Hopefully we'll see you there!We are all pretty busy getting the last things organised and ready until then, however, we've got a few meetups on the list for this week nevertheless.Upcoming MeetupsEuropeFebruary 24: February 24: North AmericaFebruary 24: AsiaFebruary 24: February 25: That's it for this week. Stay tuned for Elasticsearch happenings next week \u2013 there's much to come! - The Elasticsearch TeamP.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch \u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 1139}}<br>{"title":"How Elasticsearch Made Us Faster \u2013 Literally","seo_title":"","url":"\/blog\/how-elasticsearch-made-us-faster-literally","author":{"name":"Leslie Hawthorn"},"date":"February 20, 2015","category":"User Stories","locales":"","content":" At , our work focuses on e-procurement. In a nutshell, e-procurement is online shopping for employees on behalf of their company, plus integrating this purchasing process with various business systems. Of course, we're using Elasticsearch extensively in this setup, e.g. when searching for products, but also for analytics. But some of us at Meplato have another passion: racing. For many years, we've toured race tracks and attended various track days and trainings. So, finally, some of us decided to get our official licenses and take part in a professional race series, the . The VLN is a series of 10 races over 4-6 hours, all taking place at the , a 21 km race track in Germany. At the VLN, you typically see about 200 cars on the track, ranging from Porsche 911s to Ferrari 458s and Opel OPCs, all racing at the same time and at (very) different speeds. Obviously, overtaking is not the exception, but the rule here. So what does this all have to do with Elasticsearch? Let me explain. In our first races, we found that we were slower than our competitors in similar cars. So what do good engineers do? First, they gather data. Second, they analyze it. And that's exactly what we did, using Elasticsearch. What we obviously needed was data about location and speed. While you can get a ton of data from a race car (worth a separate article), we found that getting data from only our car didn't solve the problem. After all, we only have data from one car, and we need data from the competitors as well. So we came up with a different solution. Virtually every team in the VLN uses an iOS application called to track the location of their car: remember, it's a 21 km track. I've even heard that the Race Control Center uses it. (And kudos to the team at for such an awesome app!) The app tracks the exact location of every car on the track and streams it over the internet. While GPS-over-IP is not as exact as GPS data from the cars themselves, it's available for every car and, as it turns out, good enough for us to solve our problem. So, we wrote a proxy to record data on the wire and stored it in Elasticsearch. Looking at the data, we found that not only is the latitude and longitude of every car provided, but also its speed, steering wheel position, and some other metrics. Nice. Next, we hacked up a program to analyze the recorded data. We used to prepare a list of sectors for the track. Then, we used the geo-queries and geo-filters of Elasticsearch to find entry and exit times for each car in every sector. Given enough laps, that gave us a good estimate of where we lost time. We even tracked time loss down to individual corners of the track. Then, we generated a nice PDF of the results. One evening after the race, we figured that with all this data at hand, we could just replay the whole race. So, some of us sat down and, with the help of , came up with this: While we extracted the data for this replay, we could have easily done this in real-time with Elasticsearch. All in all, we had a lot of fun at the N\u00fcrburgring. Not only did we learn a lot about racing and cars but also about how technology, and Elasticsearch in particular, can help us to solve problems. And we finally made it to the podium two times. Happy racing! \n"}<br>{"index": {"_id": 1140}}<br>{"title":"Kibana, Aggregation Execution Order, and You","seo_title":"","url":"\/blog\/kibana-aggregation-execution-order-and-you","author":{"name":"Rashid Khan"},"date":"February 20, 2015","category":"Engineering","locales":"","content":" By now you may have spotted those crafty little arrow buttons in the screen of Kibana 4 and said \u201cHey, what are you doing over there? And what are you up to?\". Well, those buttons control the . This concept defines how Elasticsearch goes about analyzing your data, and how Kibana displays the result. Let's define a common scenario: . Easy enough right? Well yes, but your demand is ambiguous and your goals are unclear. What defines the \u201cmost active users\"? Let's set more parameters: . Now we're getting closer, but there are two ways we can interpret all that: Top 5 users in each week, for a year In this screenshot, we run the date histogram first, followed by asking for the top 5 users. This creates a bucket for each week of the year. Within each of those weeks, we find the top 5 users. Because that top 5 could be, and is in this case, different from week-to-week, you see far more than 5 users in the legend. Further, if we look at the aggregation request in the shaded section, we can see the date histogram is requested first, with the terms aggregation within the date histogram. The result is that we see weeks in which some user has an outsized activity, even if they haven't been active in any other portion of the year. This lets us spot outliers in any given week. Top 5 users for the year, and their weekly activity Now, we click the up arrow to move the terms aggregation above the date histogram. We now calculate the top 5 users over the entire year, then create a date histogram for each. This results in just 5 legend values. However, we now see the users that are consistently very active instead of the spikey outliers. Go forth and aggregate So there you go: those arrows matter. Aggregation execution order applies to almost every chart in Kibana and significantly influences both what you see on the chart, as well as the conclusions you can draw from the data. And finally, if you think you have a good Kibana success story, we'd love to hear it. Give us a shout at or and we'll help share your successes with the world! \n"}<br>{"index": {"_id": 1141}}<br>{"title":"Kibana 4. Literally.","seo_title":"","url":"\/blog\/kibana-4-literally","author":{"name":"Rashid Khan"},"date":"February 19, 2015","category":"News","locales":"ko-kr","content":" Kibana 4 is now, literally, figuratively, conceptually, spiritually, and deliciously production ready. Ok, it was ready a week ago, but we wanted to make absolutely sure that we were totally happy with it. And we are, and we want to share the happiness that is Kibana 4.0.0 GA with you. Gratuitous screenshots and backstory below. If you're just too excited for all of that, we've devised a two-step plan: If you haven't already, you will need to upgrade your cluster to If you're upgrading from Kibana 4 RC1, you'll need to migrate your config. The back story Kibana has always been a tool for solving problems. Why am I getting paged at 2am every night? When did that code get pushed to production? Did it break something as a result? Well, we solved all of those. Globally, for years, not a single person has been paged at 2am. I know, right? As the answers get easier, the questions get harder. The easy wins were easy. Now, let's solve the hard problems, the problems three layers deep. Let's solve the problems that require analyzing multiple dimensions, multiple fields, and multiple data sources. Kibana 4 is us, working together, to solve the hardest problems in the least amount of time, and with the least hassle. We took everything we learned from Kibana 3 and applied it to Kibana 4. Why settle for one thousand points on a map, when we could have one billion? Why settle for one field on a chart? Or one chart in a panel? Why just one index on a dashboard? Let's generate 5 scenarios, comparing data across 2 fields and put them all on a dashboard with data from 3 indexes. Yeah. Let's do that, then let's go get ice cream. With sprinkles. The plot Like ice cream, problems come in many flavors. To that end, we've divided Kibana up neapolitan style, except we left out that flavor you don't like. If you're a long-term Kibana user, you'll feel right at home on the first tab . This allows you to quickly iterate on searches, find records, and keep solving the easy problems that are quickly corrected by finding that one line that tells the whole story. When things get more complex than simple search can account for, it's time to make magic with charts and graphs. Dive into the tab to break down data with the power of Elasticsearch aggregations. exposes the multi-dimensional nature of data and lets you build charts, tables and maps that quickly answer the kind of questions you never would have known to ask before. The question you might have asked first was \u201cWhy was the site slow last week?\", but the question revealed by the data is \u201cWhy did the average file size of requests made from Tokyo spike on Christmas day?\" Finally, bring it all together on the . Put it on the big screen and say: \u201cThere's your answer and here's a link for later. Also, I embedded it in the wiki, mailed you a csv export of the data, ate some ice cream and wrote the first chapter of my autobiography. Now get me more ice cream, I earned it.\" For a more in-depth look at each tab, check out the blog post. To be continued\u2026 It's probably time for a nap right? Nope. Kibana 4.1 is already in the works and we have big plans for the future. Much effort went into making the underpinnings of Kibana 4 stable and sensible, giving us a platform to build the future of Elasticsearch applications upon. The entire thing was designed to be extended. For example, visualizations were built to be, well, built upon. Open source is more than a GitHub account to us, it's our commitment to creating a structure that enables everyone to build new amazing things. Watch space for articles on building your own Kibana visualizations and creating your own applications that work with Elasticsearch. Want a sneak peek? Check out Spencer Alger's talk at . We wouldn't be here without you, and we're not going anywhere without your help, so please, ping us on with issues, suggestions, and contributions. Or, if you love IRC like we do, join us in #kibana on Freenode. Extra credit Want the whole Kibana 4 story as it happened? Check out the previous blog posts from the Kibana 4 beta series: And finally, if you think you have a good Kibana success story, we'd love to hear it. Give us a shout at stories@elastic.co or and we'll see how we can share your successes with the world! \n"}<br>{"index": {"_id": 1142}}<br>{"title":"Elasticsearch 1.4.4 and 1.3.9 Released","seo_title":"","url":"\/blog\/elasticsearch-1-4-4-and-1-3-9-released","author":{"name":"Kevin Kluge"},"date":"February 19, 2015","category":"Engineering","locales":"","content":" Today, we released Elasticsearch 1.4.4 and 1.3.9. This is a small bug fix release, mainly including a packaging fix for our RPM and DEB packages if you are using Lucene expression scripts . You can . fixes The 1.4.3 RPM and DEB packages were for Antlr and ASM. These dependencies are required to use Lucene expression scripts with Elasticsearch. Since the for Groovy, we expect a lot more people will be using expressions scripts, so we quickly released 1.4.4. The release also fixes a few bugs around cluster pending tasks. And it fixes a bug where a negative interval on date histograms could cause an . The as well as the list out all the changes. feedback As always, we would love to hear from you. Please let us know what you think on Twitter via or by filing an . \n"}<br>{"index": {"_id": 1143}}<br>{"title":"This Week in Elasticsearch - February 18, 2015","seo_title":"","url":"\/blog\/2015-02-18-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"February 18, 2015","category":"","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.It's ready! 4 RC1 is freshly baked. Get the skinny on all the features or just jump right in. \u2014 elasticsearch (@elasticsearch) Elasticsearch core In Apache Lucene this Past Week log analysis in and . 30 minutes from concept to dashboard: great tools to work with. \u2014 Robin Moffatt (@rmoff) Elasticsearch EcosystemHere\u2019s some more information about what is happening in the ecosystem we are maintaining around the ELK stack \u2013 that\u2019s Elasticsearch plus Logstash and Kibana \u2013 including plugin and driver releases. Slides & VideosJoe Jasinski shows how he uses Django, Elasticsearch, and Haystack for searching the contents of his website to the Chicago Python User Group.The MongoDB meetup group in Delhi recently heard from Bharvi Dixit about some use cases for MongoDB with Elasticsearch.The Elasticsearch meetup in London had some fantastic presentations at their last gathering.Where to Find UsWe'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Director of Developer Relations, , know!AustriaThe Vienna Elasticsearch Users Group will get together on March 4 to talk Elasticsearch at Cloud Foundry and more. to let the organizers know you\u2019re attending.GermanyWant to know more and happen to be in Berlin next 24\/02, join me () for an all night on logs! \u2014 Pere Urb\u00f3n-Bayes (@purbon) IndiaThe Configuration Management Magic Meetup will convene on February 21 in Bangalore. Among the many talks on offer, you can hear all about Log Analysis using Elasticsearch, Kibana and Fluentd. to save your seat.IsraelThe Tel Aviv-Yafo ELK meetup group will be talking How to Use ELK to Analyze Logs from a Large Production AWS Environment on February 24. You can to attend.Speaker Update: Peter Vulgaris from speaks in the track at : \u2014 GOTO Amsterdam (@GOTOamst) South AfricaThe inaugural Capetown Elasticsearch Meetup will convene on March 5 to talk shop and plan for the future of the group. to let the organizers know you plan to attend.TaiwanThe Agile Code Camp team are convening a developer and designer hack day on February 23, and attendees will be developing with Elasticsearch. to attend the full day event.United KingdomElasticsearch will be out in force at QCon London, which returns to the Queen Elizabeth II Conference Center this year. You can visit us at our booth on the show floor, plus we\u2019ll be having one of our engineers take the stage for the main program. Those details are in the works, but in the meantime you can take a look at . He\u2019ll be sharing the story of how Elasticsearch and other technologies are powering the Norwegian Roads Authority\u2019s brand new system to provide real-time traffic information to travelers throughout Norway.United StatesIf you\u2019re at Strata in San Jose this week, don\u2019t forget to join , creator of Elasticsearch for Apache Hadoop, at the conference. He\u2019ll present on on Friday, Feb 20 at 11:30 AM.Coming up in San Francisco next month, you can join the SF MySQL Meetup to hear all about using MySQL and the ELK stack for audit logging. The user group will get together on March 11, but the event is filling up quickly. Register now to save your seat.And for our friends beyond Silicon Valley: It's ready! 4 RC1 is freshly baked. Get the skinny on all the features or just jump right in. \u2014 elasticsearch (@elasticsearch) Where to Find You If you\u2019re a regular reader of This Week in Elasticsearch, a.k.a TWIES, you\u2019re thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That\u2019s awesome, because we\u2019d like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we\u2019ve made it even easier for you to get support for your meetup!Head on over to ! (And we\u2019ll still totally send you swag if you\u2019re giving a talk on anything ELKy at a conference.)Oh yeah, we're also . If you'd like us to find you for employment purposes, just . We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head.TrainingsIf you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1144}}<br>{"title":"Frame of Reference and Roaring Bitmaps","seo_title":"","url":"\/blog\/frame-of-reference-and-roaring-bitmaps","author":{"name":"Adrien Grand"},"date":"February 17, 2015","category":"Engineering","locales":"","content":" Postings listsWhile it may surprise you if you are new to search engine internals, one of the most important building blocks of a search engine is the ability to efficiently compress and quickly decode sorted lists of integers. Why is this useful? As you may know, Elasticsearch shards, , split the data that they store into segments which are regularly merged together. Inside each segment, documents are given an identifier between 0 and the number of documents in the segment (up to 2-1). This is conceptually like an index in an array: it is stored nowhere but is enough to identity an item. Segments store data about documents sequentially, and a doc ID is the index of a document in a segment. So the first document in a segment would have a doc ID of 0, the second 1, etc. until the last document, which has a doc ID equal to the total number of documents in the segment minus one.Why are these doc IDs useful? An inverted index needs to map terms to the list of documents that contain this term, called a , and these doc IDs that we just discussed are a perfect fit since they can be compressed efficiently.Frame Of ReferenceIn order to be able to compute intersections and unions efficiently, we require that these postings lists are sorted. A nice side-effect of this decision is that postings lists can be compressed with delta-encoding.For instance, if your postings list is , the list of deltas would be . What is interesting to note here is that all deltas are between 0 and 255, so you only need one byte per value. This is the technique that Lucene is using in order to encode your inverted index on disk: postings lists are split into blocks of 256 doc IDs and then each block is compressed separately using delta-encoding and bit packing: Lucene computes the maximum number of bits required to store deltas in a block, adds this information to the block header, and then encodes all deltas of the block using this number of bits. This encoding technique is known as (FOR) in the literature and has been used .Here is an example with a block size of 3 (instead of 256 in practice):The same abstraction is used at search time: queries and filters return a sorted iterator over the list of documents that they match. In the case of term queries and filters, implementation is very simple, we just need to return an iterator over a postings list from the inverted index. Other queries are more sophisticated. For instance, a disjunction would need to merge postings lists for and on the fly. But in the end, it is still using the same abstraction.Roaring bitmapsThis leads us to a second place where Lucene needs to encode sorted lists of integers: the filter cache. Filter caching is a popular technique which can speed up the execution of frequently-used filters. It is a simple cache that maps (filter, segment) pairs to the list of doc IDs that they match. But constraints are different from the inverted index: For these reasons, the best encoding techniques are not necessarily the same for an inverted index and for cached filters.So what should we use here? Clearly the most important requirement is to have something fast: if your cached filter is slower than executing the filter again, it is not only consuming memory but also making your queries slower. The more sophisticated an encoding is, the more likely it is to slow down encoding and decoding because of the increased CPU usage, so let's look at the simple options that we have to encode a sorted list of integers:Option 1: integer arrayProbably the simplest option: doc IDs are stored in an array. This makes iteration very simple, however compression is really bad. This encoding technique requires 4 bytes per entry, which makes dense filters very memory-consuming. If you have a segment that contains 100M documents, and a filter which matches most documents, caching a single filter on this segment requires roughly 400MB of memory. Ideally we should have something more memory-efficient on dense sets.Option 2: bitmapDense sets of integers are a great use-case for bitmaps. A bitmap is an array where each entry takes only one bit, so they only have two possible values: 0 or 1. In order to know whether docID is contained in a bitmap, you need to read the value at index . 0 would mean that the set does not contain this docID while 1 would mean that the set contains this docID. Iteration requires to count consecutive zeros, which is actually very fast since CPUs have dedicated instructions for that. If we compare to option 1, memory usage is much better on dense filters since we would now only need 100M bits = 12.5MB. But now we have an issue with sparse sets: while we needed 4 bytes per match with our first option, we now need 12.5MB of memory, no matter how many matches there are.For a very long time, Lucene has been using such bitmaps in order to cache filters into memory. In Lucene 5 however, we switched to Daniel Lemire's . See for more background.Option 3: roaring bitmapsRoaring bitmaps aim at taking the best of both worlds that we just described. It starts by splitting the postings list into blocks depending on the 16 highest bits. Which means that for example, the first block would encode values between 0 and 65535, the second block between 65536 and 131071, etc. Then in each block we encode independently the 16 lowest bits: if it has less than 4096 values, an array will be used, otherwise a bitmap. Something important to notice at this stage is that while we used to need 4 bytes per value with the array encoding described above, here the arrays only need to store 2 bytes per value since the block ID implicitely gives us the 16 highest bits.Why does it use 4096 as a threshold? Simply because above this number of documents in a block, a bitmap becomes more memory-efficient than an array:This is what makes roaring bitmaps interesting: they are based on two fast encoding techniques that have very different compression characteristics and dynamically decide which to use based on memory-efficiency.Roaring bit maps have lots of features, but there are really only two of them that interest us in the context of Lucene: ComparisonLet's compare several implementations to see why we decided on using roaring bitmaps for filter caching. Here are the various implementations that we are comparing: The benchmark code is available at In all the charts that will be presented, we use bitmap as a reference implementation since it had been used for years in Lucene. The y-axis uses a logarithmic scale in base 2: a value of 0 means that it is as fast as a bitmap, 1 means 2x faster, etc. The x-axis uses a logarithmic scale in base 10 which represents the density of the doc id set. For instance a value of -2 means that 10=1% of documents are contained in the set.Iteration performanceHere we are measuring iteration performance, which is essentially about the performance that you would get when wrapping the filter in a constant-score query. The int[] array constantly beats other implementations by a factor of 2. What is even more interesting to notice is that the bitmap is much slower than other implementations in the sparse case, which means that you should not use it to cache filters as it could be even slower than reading from disk again.Skip performanceThis time we are measuring skipping, which is used when you intersect a filter with another query. The number in parenthesis is the number of documents that we are trying to skip over (no matter whether they match or not) on every iteration. Basically skipping over N documents would occur when intersecting with a query that matches roughly 1\/Nth of all your documents. You may wonder how the different implementations can do it efficiently, here is the answer: Even though the bitmap is still much slower than other implementations on sparse sets, it is also the fastest implementation on dense sets. The performance of other implementations compared to bitmaps degrades when density increases with roaring bitmaps having the most graceful performance degradation.You might wonder what explains the little jump that we can observe on very high densities on roaring bitmaps. The explanation is that our roaring bitmap implementation inverses its encoding when the set becomes very dense: instead of storing doc IDs which are contained in the set, it stores those that are missing. This makes skipping a bit slower but also helps with memory usage and can typically be useful for filter caching if you have some filters of the form \u201call except X\".Memory footprintThe less memory a cached filter uses, the more filters we will be able to cache, which makes good compression appealing. Here we can see that roaring bitmaps are almost always better than both the int[] array and a bitmap. The only exception is the very sparse case (less than 0.05% of documents contained in the set) where the memory overhead of each block makes roaring bitmaps less efficient than simple arrays.Also the int[] array performs poorly on dense sets by requiring about 32x more memory than a bitmap or a roaring bitmap.For this benchmark, we used a uniform distribution of documents. While this does not matter for the int[] and bitmap encodings, this is actually the worst-case for roaring bitmaps, so we could expect them to perform even better on more realistic data.Note: \u201cfor\" is absent from this benchmark as it is fully disk-based and does not require any memory at all.Build timeOne final yet important factor to consider for filter caching is the amount of time it takes to build a cache entry. And again roaring bitmaps are appealing by being either the fastest implementation (when density is between 0.01% and 1%) or very close to the fastest implementation (int[] array when the density is < 0.01%, and bitmap when density is > 1%).ConclusionThere is no particular implementation which is constantly better than all others. However some implementations were disqualified because they performed poorly in some particular cases: Even though roaring bitmaps are rarely the fastest implementation, they are never a bad choice.Another important conclusion from this comparison is that even though postings lists from the inverted index are stored on disk instead of memory, they remain very fast. The nextDoc benchmark (and to some extent the advance one too) showed that they are even competitive with an in-memory implementation. This means that the filter cache should only be used on slow filters in order to be efficient, and probably not on fast filters such as term filters.Finally, Lucene today always uses the same implementation for all filters. We might make it more efficient in the future, for instance by using a different implementation depending on the density of the doc id set that we have to cache (patches welcome!). \n"}<br>{"index": {"_id": 1145}}<br>{"title":"Where in the World is Elasticsearch? - February 16, 2015","seo_title":"","url":"\/blog\/where-in-the-world-is-elasticsearch-9","author":{"name":"Livia Froelicher"},"date":"February 16, 2015","category":"","locales":"","content":" As promised last week, we are back with a bunch of events in our US home base, California! Check out the events we are at this week, plus meetups happening around Elasticsearch and the ELK stack. Even more exciting, the count down is {ON}, with less than a month to go to our first ever user conference in San Francisco March 9-11 \u2013 ! Upcoming EventsNorth America February 17-20: \u2013 Don't miss our tutorial given by Logstash creator, , and team member Tal Levy on Wednesday, February 18, 1:30 p.m.-5:00 p.m. , or talk: , Friday, February 20, 11:30 a.m.-12:10 p.m. February 19-22: \u2013 Developer Relations team member will give a talk titled on Saturday, February 21, 4:30 p.m.-5:30 p.m. in Room Los Angeles B February 19-20: \u2013 Make sure you say hi to who will be walking around in the hallway ready to talk all things #ELKstack with you! Upcoming MeetupsNorth America February 18: February 19: Europe February 18: Asia February 18: February 21: That's it for this week. Stay tuned for Elasticsearch happenings next week \u2013 there's much to come! - The Elasticsearch Team P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch \u2013 we can offer support and send you swag! \n"}<br>{"index": {"_id": 1146}}<br>{"title":"Uses of Elasticsearch, and Things to Learn","seo_title":"","url":"\/blog\/found-uses-of-elasticsearch","author":{"name":"Alex Brasetvik"},"date":"February 15, 2015","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud.Elasticsearch is used for a lot of different use cases: \"classical\" full text search, analytics store, auto completer, spell checker, alerting engine, and as a general purpose document store. This article gives a brief overview of different common uses and important things to consider, with pointers to where you can learn more about them. \n"}<br>{"index": {"_id": 1147}}<br>{"title":"Highlights from Configuration Management Camp & AnsibleFest London","seo_title":"","url":"\/blog\/highlights-cfgmgmtcamp-ansiblefest","author":{"name":"Robyn Bergeron"},"date":"February 13, 2015","category":"News","locales":"","content":" As a Developer Advocate for Elasticsearch, I'm incredibly fortunate to be able to travel the world and speak with members of the Elasticsearch, Logstash, and Kibana communities. And whether I'm on the road or talking to folks in my hometown, the versatility of the ELK stack means that I get to see and hear about the myriad ways people are putting it to work. One of the synergies I consistently see lies with the ELK stack and DevOps-practicing organizations. While I'm a firm believer in the notion that DevOps is not \u201cachieved\" simply by adopting a particular set of tools, and instead is rooted deeply in organizational culture \u2014 I do think that the ELK stack, in part or in whole, enables IT departments to deliver increasing value to their organizations. Enabling the ability to explore and correlate data, whether you're in marketing or keeping the website up and running, drives the continuous improvement that is embraced by innovative organizations. More importantly, I often hear that the adoption of the ELK stack is occurring on both the Dev and the Ops sides of organizations \u2014 often with Elasticsearch and Kibana for developers, and Logstash for operations teams \u2014 and that the shared love is a common ground that brings people together. Our stack helps initiate a crucial part of the DevOps journey: having conversations. My latest journey was one that had me off to Europe for a handful of events, including and , both events that are largely targeted at folks on the Ops side of the house, but cater to the developer audience as well. Config Management Camp This was my second year attending this event, which is held right after FOSDEM in Ghent, a lovely city 30 minutes train ride from Brussels. Despite the name, the audience and speakers for this event are definitely interested in the bigger picture of the tech world, and this theme came out often as speakers presented on several topics \u201cbeyond\" configuration management. The event was divided between a main track, which included keynote speakers each day, and separate tracks dedicated to various project communities, including Ansible, Chef, Puppet, and SaltStack. I was delighted to see Jez Humble keynote, as a talk he gave several years ago became my \u201ca-ha!\" moment in understanding DevOps. Closing out the event was , the VP of Engineering at Kickstarter, who gave a talk about the . Best of all, when asked about his recommendations for a monitoring tool, James said \u2013 you guessed it \u2013 the ELK stack was one of his key recommended pieces to the puzzle. AnsibleFest Two days and one pleasant train ride later, I was in London for AnsibleFest, where Elasticsearch was a sponsor. AnsibleFest is largely focused on users of Ansible sharing their advice, stories, and successes, with just the right blend of technical content and inspirational \u201cbig picture\" coming through.Having attended an Ansible meetup in the past, where I met numerous folks who also used the ELK stack, I suspected that there would be a similar alignment at this event in London. The steady stream of people coming to our table confirmed that I was correct. The discussions often touched on the \u201cbringing people together\" theme: both Ansible and the ELK stack were useful to both developers and operators \u2014 and more pertinently, both were simple enough to learn and use, enabling users to start getting results quickly. Not surprisingly, people like to just get things done, and I'm glad to see that we're helping to make that happen. And if that wasn't enough to put a smile on my face (though it was!) \u2014 I was delighted to see Elasticsearch and the ELK stack mentioned in a number of presentations at the event. Seeing presenters from companies like Rackspace mentioning the ELK stack as part of their toolchain, and BigStep talking about how Ansible automates the deployment of their Elasticsearch application, certainly validated for me that the ELK stack communities are continuing to make software that people love. And that, my friends, makes me love my job a bit more every day. . talking about app w\/, deployed with \u2014 robyn bergeron (@robynbergeron) \n"}<br>{"index": {"_id": 1148}}<br>{"title":"Shield 1.0.1 Released","seo_title":"","url":"\/blog\/shield-1-0-1-released","author":{"name":"Kevin Kluge"},"date":"February 13, 2015","category":"Engineering","locales":"","content":" We're happy to announce the release of Shield 1.0.1!This is a bug fix release. We recommend that all users of Shield 1.0.0 upgrade to Shield 1.0.1. This version of Shield is certified to work with Elasticsearch 1.4.2 and 1.4.3.FixesMost importantly, this release fixes an issue where Shield 1.0.0 was incompatible with Elasticsearch 1.4.3. Even if you're currently using Elasticsearch 1.4.2, we recommend upgrading to Shield 1.0.1. This will protect you from encountering this incompatibility when you upgrade to Elasticsearch 1.4.3 or later in the future.We also fixed a bug with parsing the roles to users mapping. In some cases, Shield would not allow the user to receive privileges from all the roles it was a member of.EnhancementsKibana 4 has been evolving, and you may have seen yesterday(!). We have updated the default roles available with Shield to work with new features added to Kibana 4 RC1.We have also added a changelog to the documentation.UpgradingTo upgrade, just uninstall the current Shield and install Shield 1.0.1. Your configuration will be preserved. You can do this with a rolling upgrade of Elasticsearch.For each node, after you have stopped it, runbin\/plugin -r shield bin\/plugin -i elasticsearch\/shield\/latestThen restart the node. Larger deployments should follow the steps in the in order to ensure the recovery is as quick as possible.On upgrade, your current config files will keep their names and content. The config files provided by Shield 1.0.1 will be added with a \u201c.new\" extension. If you are a Kibana 4 user or might become one, you'll want to copy the role additions for the Kibana user, found in roles.yml.new, to roles.yml. \n"}<br>{"index": {"_id": 1149}}<br>{"title":"Kibana 4 RC1 is Freshly Baked","seo_title":"","url":"\/blog\/kibana-4-rc1-is-now-available","author":{"name":"Rashid Khan"},"date":"February 12, 2015","category":"Engineering","locales":"","content":" The first release candidate of Kibana 4 is ready to colorize, stackify, bar-a-tize, and pie-u-late. You may notice the second letter of the greek alphabet is conspicuously absent in the title. Yep, this isn\u2019t a beta. What does that mean for you? It means we\u2019ve sanded down the rough edges and shined up the whole shebang! It also means improved stability, performance, and yes, some fun new features too. The good stuff is below, but if you want to jump right in then upgrade to Elasticsearch 1.4.3 and grab the new build over on the right away. A couple tips Multi series charts Kibana 4 now supports multiple metric aggregations on each chart. For example, displaying the minimum, maximum and average of a field, or multiple totally unrelated fields, on a single plot. We\u2019ve also added the much requested percentiles aggregation as well as a view of standard deviation. Partial bucket indication You may have noticed in many analytics engines everything always seems to be trending down at the last point. This behavior is usually due to the last bar not being \u201cfull\u201d. For example, a daily bar chart, in which today isn\u2019t over yet. Kibana now shows you how much time is left in the day by subtly shading the chart to indicate that more data may be forthcoming when working with time based series. Document tables on the dashboard In addition to saved visualizations, Kibana can now show saved searches on the dashboard. Add them in the same way you would add a visualization, but take note of that \u201cSearches\u201d tab. Kibana will load your saved search, along with its columns and sort order into a table on the dashboard. Markdown widget and table filtering Tired of answering the question: \u201cWhat does this line here mean?\u201d The markdown widget allows you to add helpful informational panels to complex dashboards. Plus, the data table visualization now supports the same click-to-filter functionality that every other panel supports. Filtering on Scripted fields Beta 3 disallowed filtering on scripts. RC1 enables filtering on scripts via completely transparent support for Elasticsearch\u2019s script filter. Click to filter on scripted field values just like you would anywhere else. Kibana 4 RC1 also switches over to from Groovy due to the release of Elasticsearch 1.4.3. While Lucene expressions only support numeric values and functions for now, we\u2019re working hard to bring in support for strings, dates, and more. Auto-refresh Auto refresh is back! And it uses the same federated request system for simultaneous panel updates that Kibana uses everywhere else. And, of course, it works everywhere, including Discover, Visualize, and Dashboard. NodeJS backend We\u2019ve switched away from the Java (aka jRuby) based backend to a new, faster, more compatible, NodeJS-based backend. No need to worry, we package up the right version of NodeJS with the Kibana distribution and with no more Java dependency setup is even easier. The start process is still exactly the same: .\/bin\/kibana, except startup is nearly instant! The flip side is that you will need to download the right package for your operation system. As an entirely unrelated compensation for the operating system specific distribution, we\u2019ve dropped in SSL support totally gratis, both from the browser and to Elasticsearch. And more Order now and we\u2019ll throw in a set of steak knives. No, not really, but we will throw in formatted CSV exports, improved negative number handling, and a slick new style! Who knows what else we\u2019ve hidden in there? Something? Nothing? The only way you\u2019ll find out is by downloading it: so go, go now! Go before someone else downloads it all and there\u2019s nothing left for you! As always, we love hearing from you on IRC (#kibana on irc.freenode.net), , or with issues, suggestions, and contributions. \n"}<br>{"index": {"_id": 1150}}<br>{"title":"This Week in Elasticsearch - February 11, 2015","seo_title":"","url":"\/blog\/2015-02-11-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"February 11, 2015","category":"","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Groovy scripting vulnerability. See the blog and download Elasticsearch v1.4.3 \/ v1.3.8 \u2014 elasticsearch (@elasticsearch) Elasticsearch Core wow! \u201c: is now powering our data analytics platform. Welcome to Mars, \u2026 \" \u2014 Shay Banon (@kimchy) In Apache Lucene This Past Week 90-170% indexing throughput boost with new Elasticsearch-php core. Informal test, but encouraging results so far! \u2014 Zachary Tong (@ZacharyTong) Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Slides & Videos on the how and why of building Elasticsearch's API Spotify's engineering team share their Elasticsearch Use Cases at the recent Stockholm Meetup Alexander Reelsen's quick introduction to Elasticsearch's percolator, showcasing the potential of performing document enrichment before indexing Where to Find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Director of Developer Relations, , know! Austria Germany Want to know more and happen to be in Berlin next 24\/02, join me () for an all night on logs! \u2014 Pere Urb\u00f3n-Bayes (@purbon) India The Configuration Management Magic Meetup will convene on February 21 in Bangalore. Among the many talks on offer, you can hear all about Log Analysis using Elasticsearch, Kibana and Fluentd. to save your seat. Israel The Tel Aviv-Yafo ELK meetup group will be talking How to Use ELK to Analyze Logs from a Large Production AWS Environment on February 24. You can to attend. Japan Registration is already full for the next Elasticsearch Japan Study Session in Tokyo, but you can . The user group will get together on February 13 at 7:30 PM. Speaker Update: Peter Vulgaris from speaks in the track at : \u2014 GOTO Amsterdam (@GOTOamst) Norway The NDC Meetup Group in Oslo will get together on Feb 18 to talk Data Exploration with Elasticsearch. to save your place. South Africa The inaugural Capetown Elasticsearch Meetup will convene on March 5 to talk shop and plan for the future of the group. to let the organizers know you plan to attend. Taiwan The Agile Code Camp team are convening a developer and designer hack day on February 23, and attendees will be developing with Elasticsearch. to attend the full day event. United Kingdom Elasticsearch will be out in force at QCon London, which returns to the Queen Elizabeth II Conference Center this year. You can visit us at our booth on the show floor, plus we'll be having one of our engineers take the stage for the main program. Those details are in the works, but in the meantime you can take a look at . He'll be sharing the story of how Elasticsearch and other technologies are powering the Norwegian Roads Authority's brand new system to provide real-time traffic information to travelers throughout Norway. United States Heading to in San Jose? We've got several activites planned for around the conference. Check them out - you don't have to be attending Strata to enjoy some of the fun! Coming up in San Francisco next month, you can join the SF MySQL Meetup to hear all about using MySQL and the ELK stack for audit logging. The user group will get together on March 11, but the event is filling up quickly. to save your seat. And for our friends beyond Silicon Valley: mentors attendees at the recent Django Girls Brno workshop Where to Find You If you're a regular reader of This Week in Elasticsearch, a.k.a TWIES, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1151}}<br>{"title":"Running Groovy Scripts without Dynamic Scripting","seo_title":"","url":"\/blog\/running-groovy-scripts-without-dynamic-scripting","author":{"name":"Chris Earle"},"date":"February 11, 2015","category":"Engineering","locales":"","content":" \n"}<br>{"index": {"_id": 1152}}<br>{"title":"Elasticsearch 1.4.3 and 1.3.8 Released","seo_title":"","url":"\/blog\/elasticsearch-1-4-3-and-1-3-8-released","author":{"name":"Clinton Gormley"},"date":"February 11, 2015","category":"Engineering","locales":"","content":" Today, we have released the and bug fix release of\u00a0, based on , and . You can download them and read the full changes list here: For blog posts about past releases see: You can read about all of the changes that have been made in the and the , but the security issue is explained below:Groovy scripting vulnerability foundElasticsearch versions 1.3.0-1.3.7 and 1.4.0-1.4.2 have a vulnerability in the Groovy scripting engine. The vulnerability allows an attacker to construct Groovy scripts that escape the sandbox and execute shell commands as the user running the Elasticsearch Java VM.We have been assigned CVE-2015-1427 for this issue.Versions 1.3.8 and 1.4.3 disable sandboxing for Groovy by default. As a consequence, .If you are running a vulnerable version, you should either upgrade to v1.3.8 or v1.4.3, or disable dynamic Groovy scripts by adding this setting to all nodes in the cluster:script.groovy.sandbox.enabled: falseThis will turn off the Groovy sandbox, thus preventing dynamic Groovy scripts from being accepted inline as part of a request or from being retrieved from the special index.In the meantime, you can still use Groovy scripts by saving them as files in the directory on every data node. See for more information about how to do this. \n"}<br>{"index": {"_id": 1153}}<br>{"title":"Where in the World is Elasticsearch? - February 09, 2015","seo_title":"","url":"\/blog\/where-in-the-world-is-elasticsearch-8","author":{"name":"Livia Froelicher"},"date":"February 09, 2015","category":"","locales":"","content":" It's another week full of meetups all around the world, and we wouldn't have it any other way. We are taking a short break this week from conferences and other events to get ready for what's coming thereafter: Strata+Hadoop World San Jose, SCALE13x, and SXSW15. Upcoming MeetupsNorth America February 10: February 11: Europe February 11: February 12: Asia February 11: February 13: That's it for this week. Stay tuned for Elasticsearch happenings next week - there's much to come! - The Elasticsearch Team P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag! \n"}<br>{"index": {"_id": 1154}}<br>{"title":"Spotting Bad Actors: What Your Logs Can Tell You about Protecting Your Business","seo_title":"","url":"\/blog\/spotting-bad-actors-what-your-logs-can-tell-you-about-protecting-your-business","author":{"name":"Mark Harwood"},"date":"February 06, 2015","category":"","locales":"","content":" In this blog post, we'll use Elasticsearch's aggregations to analyze web server log files, with the goal of discovering how to block unwelcome visitors to a site. This is a responsibility every webmaster has, and the fundamental choice is to either: It may be more convenient for a webmaster to block a whole range of IP addresses grouped under a single subnet.However, this may be being over-zealous as there may be a wealth of well-behaved visitors who are now blocked along with the bad guys. How do webmasters understand the mix of good vs bad traffic at each level to make a good business decision? Elasticsearch to the rescue! We'll explore how the runs Elasticsearch queries to find sources of bad behavior and uses a \"Sankey\" flow diagram (see below) to illustrate the size and concentrations of risk at various points in a site's traffic flow. Setting up the example To follow along with this demonstration, you will first need to install the netrisk plugin running the following command in your elasticsearch (1.4.0 or later) home directory: All being well, the plugin should be installed. Before we can use it, however, we must provide some data with the appropriate configuration. We'll examine the details of the required index mapping later, but, for now, you can index some anonymized test data by running the shell script in this directory: This will create an index called \"mylogs\" with some data from real log records which contain an anonymized IP address and an HTTP response code. Finally you can launch the plugin using the URL Running the example The example data has a limited set of attributes we can use to identify risky traffic. We only have HTTP response status codes, but these are sufficient to find some bad behaviour in this data. The 200\/300 range of HTTP response codes represents typical site traffic, whereas the 400\/500 ranges represent failures, e.g. attempts to access non-existent pages. The query to single out those requests in our data is as follows: The netrisk plugin uses the standard Lucene query parser (the same one used by Kibana), so your query could use ORs to look for other features in your data that might suggest risky traffic, e.g. requests missing a UserAgent. Our query does not need to be to be too certain in determining what is \"bad\" - we just need to suggest a sense of what have a bad smell about it and then the aggregations framework will do the rest in finding sources with high concentrations of this type of content, undiluted by anything else. If we run the above search, the Sankey diagram should appear showing trails of the riskier traffic flowing into our website. Various pieces of information are summarized in the diagram: You'll notice that the lines in the diagram tend to change from red to green as they move from left to right through various stages of subnet. This is because on the left hand side of the diagram each node is typically representing smaller numbers of users who are dedicated to bad behavior. Each stage to the right represents a subnet covering a larger number of users who will typically dilute the good\/bad mix with added volumes of well-behaved users who make up the normal access patterns. However, some subnets may represent entire countries where the mix of traffic stays in the red because your site may not have any relevance to that region, and the only people interested in visiting your site from there are miscreants. How does it work? Preparing the data This analysis relies on having statistics about the frequencies of both IP addresses and subnets encoded in the index. To do this analysis, we can't just index each IP address as a single string: we must break it up into multiple tokens (e.g. the IPv4 address 186.28.25.186 is indexed as tokens 186.28.25.186, 186.28.25, 186.28 and 186). This is done using the following mapping definition: curl -XPOST \"http:\/\/localhost:9200\/mylogs\" -d ' { \"settings\": { \"analysis\": { \"analyzer\": { \"ip4_analyzer\": { \"tokenizer\": \"ip4_hierarchy\" } }, \"tokenizer\": { \"ip4_hierarchy\" : { \"type\" : <strong>\"PathHierarchy\"<\/strong>, \"delimiter\" : \".\" } } } }, \"mappings\": { \"log\": { \"properties\": { \"remote_host\": { \"type\": \"string\", \"index\": \"not_analyzed\", \"fields\": { \"subs\": { \"type\": \"string\", \"index_analyzer\": \"ip4_analyzer\", \"search_analyzer\": \"keyword\" } } } } } } } This gives us the power to quickly look up the number of logged events at 4 levels of hierarchy for each IP address. For IPv6 addresses, the delimiter used would be a \":\" and some additional logic would be required to deal with the \"::\" syntax that is shorthand for zeroes. The queries behind the netrisk tool The netrisk tool takes your choice of query which identifies \"bad\" (or perhaps more accurately, \"potentially bad\") and uses an aggregation called the \"significant_terms\" aggregation to examine which IP addresses or subnets are disproportionately represented in the set of bad requests. We here at Elasticsearch call this the \"uncommonly common\". The template looks like this: curl -XGET \"http:\/\/localhost:9200\/anonlogs\/_search?search_type=count\" -d' { \"query\": { \"query_string\": { \"query\": \"status:[400 TO 599]\" } }, \"aggs\": { \"sigIps\": { \"significant_terms\": { \"field\": \"remote_host.subs\", \"size\": 50, \"shard_size\": 50000, \"gnd\": {} } } } }' This query will pick the 50 highest-risk IP addresses or subnets in your index. The points of interest here are: This single query will do the bulk of the analysis and provide us with the main offenders in our system but we need to address some potential inaccuracies before inviting webmasters to block a particular subnet or IP address. What if our \"bad\" query identified some matches for an IP address on one shard but failed to match a single record in another shard holding a multitude of only \"good\" records? If the IP was a dynamic one and was reallocated, it is plausible that when using time-based indices that this sort of discrepancy between shards might happen. The shard with only good records would fail to return any stats on this benign behaviour as part of the initial risk assessment. To verify our stats a subsequent query is required to gather all of the stats from all of the shards for our assumed high-risk selections. The query to do this looks as follows: { \"query\":{ \"terms\":{\"remote_host.subs\":[\"256.52\",\"186.34.56\" ...]} }, \"aggs\": { \"ips\" : { \"filters\" : { \"filters\" : { \"256.52\":{ \"term\" : { \"remote_host.subs\" : \"256.52\" }}, \"186.34.56\":{ \"term\" : { \"remote_host.subs\" : \"186.34.56\" }} ... } }, \"aggs\": { \"badTraffic\": { \"filter\": { \"query\":{\"query_string\": {\"query\": \"status:[400 TO 599]\"} } } }, \"uniqueIps\": { \"cardinality\": { \"field\":\"remote_host\" } } } } } } For each of the perceived high-risk IPs\/subnets we create a bucket and for ALL shards count: Using the above we can now accurately color and size the selected nodes in our diagram. Conclusion Tracking behaviors of entities like IP addresses across multiple log records and shards is a tough computation problem. The analysis performed by this plugin is at the upper end of what you might attempt at scale using a typical time-based index of log records. Below are some examples of even more challenging forms of behavioral analysis: To attempt these forms of analysis at scale, we need to fuse related log records into summaries of an entity's behavior over time. Thankfully, there is a way of doing this and it is the subject of the \"entity-centric indexing\" talk I will be giving at If you are coming to Elastic{ON}, come join in on the fun on the . If not, stay tuned for updates on on when videos of the session may be ready. Either way, have a great weekend and may your logs be ever in your favor. \n"}<br>{"index": {"_id": 1155}}<br>{"title":"This Week in Elasticsearch - February 04, 2015","seo_title":"","url":"\/blog\/2015-02-04-this-week-in-elasticsearch","author":{"name":"Luca Cavanna"},"date":"February 04, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Elasticsearch Core Check out the Q&A w\/ Britta Weber at Fyber's Elasticsearch UG () meetup. \u2014 Fyber (@Fyber) In Apache Lucene This Past Week Realtime updates from PostgreSQL to Elasticsearch - Atlassian Developers \u2014 Found (@foundsays) Elasticsearch EcosystemHere's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Blogged: One Tip a Day: Using Dynamic Templates To Avoid Rigorous Mappings \u2014 Itamar Syn-Hershko (@synhershko) Slides & VideosAll the talks from last Friday's p Talks, including Q&A with (Hint: Elasticsearch & Robots!)Capacity Planning and Custom Setups Suitable for Large Elasticsearch DeploymentsBetter Decisions Through Better Data (auf Deutsch)OH: In the last 12 hours, we have taken in 12GB of sensor data in \u2014 Chris Matthieu (@chrismatthieu) Where to Find UsWe'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Director of Developer Relations, , know!AustriaThe Vienna Ruby Users Group will get convene on Feb 12, with talks on Logstash, Jekyll and Octopress. You can to save your seat.Germany IsraelThe Tel Aviv-Yafo ELK meetup group will be talking How to Use ELK to Analyze Logs from a Large Production AWS Environment on February 24. These folks are looking for space to meet, so you can host get in touch with the organizers. You can now while they're finding a location.JapanRegistration is already full for the next Elasticsearch Japan Study Session in Tokyo, but you can . The user group will get together on February 13 at 7:30 PM.NorwayThe NDC Meetup Group in Oslo will get together on Feb 18 to talk Data Exploration with Elasticsearch. to save your place.TaiwanThe Agile Code Camp team are convening a developer and designer hack day on February 23, and attendees will be developing with Elasticsearch. to attend the full day event. United KingdomIf you're a star in the Ansible Galaxy, you're no doubt attending AnsibleFest London on Feb 5. Stop by and say hello to and at our table in the exhibits area! Our Developer Advocate, , will also be hanging out in the hallway track if you'd like to say hello!United States Heading to in San Jose? We've got several activites planned for around the conference. Check them out - you don't have to be attending Strata to enjoy some of the fun! And for our friends beyond Silicon Valley: Where to Find You If you're a regular reader of This Week in Elasticsearch, a.k.a TWIES, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup!Head on over to ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.)Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head.TrainingsIf you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1156}}<br>{"title":"Elasticsearch Puppet Module 0.9.0 Released","seo_title":"","url":"\/blog\/elasticsearch-puppet-module-0-9-0-released","author":{"name":"Richard Pijnenburg"},"date":"February 02, 2015","category":"Engineering","locales":"","content":" I'm very happy to announce the latest release of our Elasticsearch Puppet module, version 0.9.0Since its creation two years ago, the Elasticsearch Puppet module has grown to be one of the most widely used modules and was included in the inaugural class of modules.New FeaturesAs with every release, we have a lot of new and exciting things in the module. One of these is support for out of the box for defining instances and plugins.We also added different custom facts to expose interesting information about the running Elasticsearch instances. These custom facts can be used together with other applications like Mcollective.An example output of these custom facts:ChangesWe added support for OpenSuse 13.x and enabled Puppet 3.7 testing.\u00a0Along the way, we added several internal changes which will help improve the stability of the project.\u00a0One of these changes is using the official module to manage the java installation. This replaces our custom class with a wonderfully, well-tested module from Puppet Labs.FixesThanks to the feedback from both the community and customers, we fixed several bugs. It is worth mentioning few important fixes here: RoadmapThe Elasticsearch puppet module will continue to evolve in the future, with different needs and requirements. With this release, we are paving the road for future changes without breaking expectations for your environments.In the next major release, we are planning on using . We are also working to extend support for different Operating systems such as SLES, Windows and many more.As always, if you find any bugs or have questions, enhancements, please reach out to us on the Github page, or on our page. \n"}<br>{"index": {"_id": 1157}}<br>{"title":"Where in the World Is Elasticsearch? - February 02, 2015","seo_title":"","url":"\/blog\/where-in-the-world-is-elasticsearch-7","author":{"name":"Livia Froelicher"},"date":"February 02, 2015","category":"","locales":"","content":" Did you enjoy any of the Elasticsearch events last week? We hope so! We are continuing our event and meetup journey this week and heading over to Belgium, London, San Francisco, Cupertino (CA), Stockholm, Munich and Taipei. Check out all the details so you don't miss out. Upcoming EventsEurope February 2 - 3: - & will see you in the hallway track between talks, plus don't miss Robyn's panel on Provisioning Infrastructure as Code. February 5: - and will be hanging around our booth in the exhibit area, so please go say hi! Our developer advocate Robyn Bergeron will also be around. Pssst: you will also get a chance to win one of our limited edition (signed) Elasticsearch books. Upcoming MeetupsNorth America February 4: February 5: Europe February 2: February 5: Asia February 4: That's it for this week. Stay tuned for Elasticsearch happenings next week - there's much to come! - The Elasticsearch Team P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag! \n"}<br>{"index": {"_id": 1158}}<br>{"title":"Lucene's Handling of Deleted Documents","seo_title":"","url":"\/blog\/lucenes-handling-of-deleted-documents","author":{"name":"Michael McCandless"},"date":"January 30, 2015","category":"Engineering","locales":"","content":" When a document is deleted or updated (= delete + add), simply marks a bit in a per-segment bitset to record that the document is deleted. All subsequent searches simply skip any deleted documents. It is not until that the bytes consumed by deleted documents are reclaimed. Likewise, any terms that occur only in deleted documents (ghost terms) are not removed until merge. This approach is necessary because it would otherwise be far too costly to update Lucene's write-once index data structures and aggregate statistics for every document deletion, but it has some implications: Merging Reclaims Deleted Documents Lucene's default merge policy, , already prefers merges that would reclaim more deleted documents, other factors being equal. Over time this means segments with more deletions will be targeted for merging. While it does have a tunable setting () to control how aggressively it targets deletions, it is dangerous to increase this too much otherwise it could select poor (costly) merge choices, dwarfing any gains from slightly fewer deleted documents. I was curious how effective its defaults are in practice, so I ran a simple worst-case indexing test. First, I built an initial index with 100 M added documents (no deletions) derived from English export. Then I updated that index by forever randomly replacing an existing document (never adding a new document), so that every add also incurs a deletion. There was no pattern to the updates, such as favoring replacing older or newer documents. This is unrealistic, but it is a good worst case test because the deletes accumulate uniformly, in proportion to each segment's size. In real usage, certain segments (old or new) would accumulate deletions at a faster rate and thus be more quickly selected for merging. I measured the percentage of deleted (but not yet merged away) documents over time, computed as (where is constant at 100 M in my test). The graph below shows an initial startup transient, when the percentage quickly rise from 0% to 45% at which point a couple of large merges complete and bring it back down. After that the deletions percentage hovers between 35% and 60%, with a sawtooth shape showing a sudden drop whenever varying sized merges finish. It looks somewhat like the stock market! A maximum sized segment (default: 5 GB) will only be eligible for merging once it accumulates 50% deletions. If this is too slow for your usage, try decreasing that maximum (): this will result in a somewhat larger segment count, but the reclaiming should happen more quickly, especially when there is a pattern to the deletions. How Do Deleted Documents Affect Search Performance? Because deleted documents remain in the index, they must still be decoded from the postings lists and then skipped during searching, so there is added search cost. To test how much, I ran a search performance test for varying queries using the 100 M document index with no deletions as the baseline, and the same index with 50% deleted documents (i.e., 150 M documents with 50M deleted). Both indices were single-segment. Here are the results: The bad news is there is clearly a non-trivial performance cost to deleted documents, and this is something we can work to reduce over time (patches welcome!). The good news is the cost is typically quite a bit lower than the percentage deletes (50% in this test) because these documents are filtered out at a low level before any of the costly query matchers and scorers see them. The more costly queries (Phrase, Span) tend to see the lowest impact, which is also good because it is the slow queries that determine node capacity for most applications. How About Expunge Deletes? Elasticsearch's , which in turn calls Lucene's method. While this will forcefully reclaim space from deleted documents, this operation is very costly: under the hood, it forces merging of any segments that have more than 10% (by default) deletions. Use it sparingly: it is better to let Lucene's natural merging handle reclaiming deletions. However, if you have an index which receives only deletions (never an added or updated document) then beware that Lucene in this case currently fails to kick off any merges. This is a that has been fixed, and will be fixed in Lucene 5.0 and Elasticsearch 2.0. In the meantime, this is an appropriate time to periodically expunge deletes! Time-Based Indices Elasticsearch for each added document, which means after that time has passed, the document is automatically deleted. This is very useful for certain applications, but it will cause heavy deletions over time. One simple optimization Lucene uses, that may help in such use cases, is to simply drop a segment once it has accumulated 100% deleted documents, without waiting for it to be merged away. The optimization is somewhat fragile since it only applies when all documents in the segment were deleted, but it is very effective since it is obviously extremely fast and happens before merging. Unfortunately, because picks out of order merges, it reduces how frequently the optimization can apply in time-to-live indices. If you need to further improve indexing performance with time-to-live documents consider using time-based indices instead, such as one index per day or per week: dropping an entire index is quite a bit more efficient than having Lucene remove a subset of documents. If you are concerned about the loss of granularity with this approach, just add a filter to the request to remove the oldest results from the oldest index. If you are curious about how many deleted documents are in your shards, use the to find out. Just don't read too much into it. Overall, besides perhaps decreasing the maximum segment size, it is best to leave Lucene's defaults as-is and not fret too much about when deletes are reclaimed. \n"}<br>{"index": {"_id": 1159}}<br>{"title":"Numeric Aggregations: An Exploration of UK Housing Data","seo_title":"","url":"\/blog\/numeric-aggregations-an-exploration-of-uk-housing-data","author":{"name":"Colin Goodheart-Smithe"},"date":"January 29, 2015","category":"","locales":"","content":" The Elasticsearch aggregations series continues! In the previous blog posts, we discovered , and . Today, we will explore some of the aggregations available for numeric data. Since this is a developer-focused series, we suggest you follow along at \/blog\/numeric-aggregations-an-exploration-of-uk-housing-datahome, so that you can play with the data and the various code examples that we show. For this article, we are going to use . This dataset includes details of every house sale in the UK for 2014. To follow along with this blog you will need Elasticsearch version 1.3.0 or later. To follow along, you'll need to restore a Snapshot into your local cluster. The snapshot is about 200MB, and it may take some time depending on your connection: # Register the land registry Repository PUT \/_snapshot\/demo_uk_landregistry_data { \"type\": \"url\", \"settings\": { \"url\": \"http:\/\/data.elasticsearch.org\/blogs\/data\/snapshots\/demo_uk_landregistry_data\/demo_uk_landregistry_data\" } } # (Optional) Inspect the repository to view available snapshots GET \/_snapshot\/demo_uk_landregistry_data\/_all # Restore the snapshot into your cluster POST \/_snapshot\/demo_uk_landregistry_data\/demo_uk_landregistry_data\/_restore # Watch the download progress. GET \/housesales\/_recovery Once your cluster has finished restoring the Snapshot, let's perform a simple search to see what the data holds: GET housesales\/_search { \"_shards\": {...}, \"hits\": { \"total\": 646386, \"max_score\": 1, \"hits\": [ { \"_index\": \"housesales\", \"_type\": \"housesale\", \"_id\": \"AUsHjsE4-ULRehTiURN7\", \"_score\": 1, \"_source\": { \"town\": \"DUNSTABLE\", \"status\": \"A\", \"location\": { \"lat\": 51.882769709, \"lon\": -0.513041822 }, \"district\": \"CENTRAL BEDFORDSHIRE\", \"locality\": \"\", \"price\": 140000, \"housetype\": \"Terraced\", \"oldnew\": \"N\", \"county\": \"CENTRAL BEDFORDSHIRE\", \"duration\": \"Freehold\", \"street\": \"GREAT NORTHERN ROAD\", \"postcode\": \"LU54BN\", \"date\": \"2014-06-19 00:00\", \"paon\": \"43\", \"saon\": \"\" } }, ... ] } } Each document in our index represents an individual property sale in the UK and contains various metadata about the sale such as the price paid, the date of the sale, whether the sale was freehold or leasehold, and various information indicating the location of the property. There are around 650,000 documents in the index so there should be plenty of data to use to identify interesting trends. Let's start our investigation by looking at the dataset as a whole: GET housesales\/_search?search_type=count { \"aggs\": { \"house_price_stats\": { \"stats\": { \"field\": \"price\" } } } } Here, we are simply asking for some basic statistics about the price of sales as a whole. This gives us the following response: { ... \"hits\": { \"total\": 646386, \"max_score\": 0, \"hits\": [] }, \"aggregations\": { \"house_price_stats\": { \"count\": 646386, \"min\": 7000, \"max\": 50000000, \"avg\": 257876.91169053785, \"sum\": 166688025440 } } } So, Elasticsearch has reported back the count (the number of sales) and the minimum, maximum, average (mean), and sum of the sales. We could do the same thing by using the min, max, avg, sum, and value_count aggregations, but the stats aggregation provides a convenient way to return all this information together. We can see from the above response that property sales in the UK in 2014 totalled over \u00a3166 billion (over $250 billion), with a mean average sale of around \u00a3260,000 ($390,000). But this aggregation doesn't tell us much about the distribution of house prices. How much are the few very expensive houses pulling up the mean average value. To answer this we can use the percentiles aggregation. GET housesales\/_search?search_type=count { \"aggs\": { \"house_price_stats\": { \"stats\": { \"field\": \"price\" } }, \"house_price_percentiles\": { \"percentiles\": { \"field\": \"price\", \"percents\": [ 50 ] } } } } So now we have added a new aggregation called 'house_price_percentiles' to our previous request and we are using it to ask for the maximum value of a sale that would fit into the first 50% of our sales data (also known as the 50th percentile or the median value). Although this would be quite useful on its own, before we run the request, let's add some other percentiles to our request GET housesales\/_search?search_type=count { \"aggs\": { \"house_price_stats\": { \"stats\": { \"field\": \"price\" } }, \"house_price_percentiles\": { \"percentiles\": { \"field\": \"price\", \"percents\": [ 1, 25, 50, 75, 99 ] } } } } Now, we are asking for values for not only the 50th percentile but also the 1st, 25th, 75th and 99th percentiles. When we run this request we get back the following: { ... \"aggregations\": { \"house_price_percentiles\": { \"values\": { \"1.0\": 45000.204685714285, \"25.0\": 126873.78905788704, \"50.0\": 188892.36462063208, \"75.0\": 290076.7973567194, \"99.0\": 1296500.8114525543 } }, \"house_price_stats\": { \"count\": 646386, \"min\": 7000, \"max\": 50000000, \"avg\": 257876.91169053785, \"sum\": 166688025440 } } } This shows us that the median sale value is only ~\u00a3189,000, and the mean value is actually closer to the 75th percentile than the median, showing that there are a small number of sales at the top end of the price scale which significantly skew the mean average sale value. So we know that the mean average sale value is much higher than the median sale value, but what percentage of houses were sold for lower than the mean average value? To answer this question we could keep adding percentiles to our above request until we get a result close to the mean value, but this feels a lot like shooting in the dark'. Luckily there is an aggregation which does the reverse of the percentiles aggregation, the percentile ranks aggregation. We can now ask the percentile ranks aggregation to calculate the percentile which represents our mean sale value in our dataset. GET housesales\/_search?search_type=count { \"aggs\": { \"house_price_percentile_ranks\": { \"percentile_ranks\": { \"field\": \"price\", \"values\": [ 257876 ] } } } } Which gives us the following response: { ... \"aggregations\": { \"house_price_percentile_ranks\": { \"values\": { \"257876.0\": 69.8520536775868 } } } } We can see now that roughly two thirds of houses are sold under the mean average sale value. Aside: UK Stamp Duty In the UK every property sale above \u00a3125,000 is subject to a tax paid by the buyer, which is called the stamp duty land tax. The amount you pay is determined by the purchase amount and is divided into bands. If the value of the purchase is greater than the threshold for a band, you have to pay the bands percentage of the entire value of the property. The bands for 2014 were as follows: So for the maximum sale in our dataset which was \u00a350,000,000 the stamp duty tax would be: \u00a350,000,000 * 0.07 = \u00a33,500,000 Using the percentile ranks aggregation we can determine what percentage of UK house sales in 2014 were affected by each stamp duty threshold. GET housesales\/_search?search_type=count { \"aggs\": { \"house_price_percentile_ranks\": { \"percentile_ranks\": { \"field\": \"price\", \"values\": [ 125000, 250000, 500000, 1000000, 2000000 ] } } } } which produces the following result: { ... \"aggregations\": { \"house_price_percentile_ranks\": { \"values\": { \"125000.0\": 24.08112180647477, \"250000.0\": 68.51649014675442, \"500000.0\": 92.08539398815546, \"1000000.0\": 98.36604199119392, \"2000000.0\": 99.6443848633277 } } } } Almost a quarter of all house sales in the UK in 2014 did not have to pay any stamp duty and over two thirds of sales had to pay either no stamp duty or at the 1% rate. Now that we've looked at the dataset as a whole, let's try to work out how these findings change in different counties of the UK. For example, which is the most expensive county in terms of house prices? Here we can make use of a very useful feature in the terms aggregation, the ability to sort the returned buckets by a sub-metric aggregation. First, lets start with a naive approach to answering this question, by asking for the top 5 UK counties sorted by the maximum sale price in descending order: GET housesales\/_search?search_type=count { \"aggs\": { \"counties\": { \"terms\": { \"field\": \"county.raw\", \"size\": 5, \"order\": { \"house_price_stats[max]\": \"desc\" } }, \"aggs\": { \"house_price_stats\": { \"stats\": { \"field\": \"price\" } }, \"house_price_percentiles\": { \"percentiles\": { \"field\": \"price\", \"percents\": [ 1, 25, 50, 75, 99 ] } }, \"stamp_duty_bands\": { \"percentile_ranks\": { \"field\": \"price\", \"values\": [ 125000, 250000, 500000, 1000000, 2000000 ] } } } } } } This request uses components we've already encountered: terms, percentiles, etc. But you'll notice something new about the terms aggregation: the order clause. This is used to indicate that we want the buckets returned from the aggregation ordered by something other than descending document count. In this instance, we want to order the county terms by the value of the 'max' field in the 'house_price_stats' aggregation and take the top 5 buckets (as stated by the 'size' parameter). The result is the statistics for the 5 counties with the highest maximum sales in 2014. { ... \"aggregations\": { \"counties\": { \"doc_count_error_upper_bound\": -1, \"sum_other_doc_count\": 511421, \"buckets\": [ { \"key\": \"GREATER LONDON\", \"doc_count\": 84256, \"house_price_percentiles\": { \"values\": { \"1.0\": 110000.00000000001, \"25.0\": 250000, \"50.0\": 361328.9936144069, \"75.0\": 556307.7822199536, \"99.0\": 3076310.5196182355 } }, \"house_price_stats\": { \"count\": 84256, \"min\": 50881, \"max\": 50000000, \"avg\": 525786.4564660083, \"sum\": 44300663676 } }, { \"key\": \"KENT\", \"doc_count\": 19843, \"house_price_percentiles\": { \"values\": { \"1.0\": 65000, \"25.0\": 160081.13354497356, \"50.0\": 214969.56200753682, \"75.0\": 294245.9144186047, \"99.0\": 993350.5076923068 } }, \"house_price_stats\": { \"count\": 19843, \"min\": 26250, \"max\": 49595000, \"avg\": 261625.75774832434, \"sum\": 5191439911 } }, { \"key\": \"SURREY\", \"doc_count\": 16168, \"house_price_percentiles\": { \"values\": { \"1.0\": 97835, \"25.0\": 249709.7963936475, \"50.0\": 341767.1243912337, \"75.0\": 516881.80511538463, \"99.0\": 1990000 } }, \"house_price_stats\": { \"count\": 16168, \"min\": 12000, \"max\": 12500000, \"avg\": 448801.1140524493, \"sum\": 7256216412 } }, { \"key\": \"OXFORDSHIRE\", \"doc_count\": 7944, \"house_price_percentiles\": { \"values\": { \"1.0\": 90620, \"25.0\": 212276.70833333334, \"50.0\": 274681.9068736142, \"75.0\": 380306.0258838384, \"99.0\": 1392833.3333333284 } }, \"house_price_stats\": { \"count\": 7944, \"min\": 38750, \"max\": 10000000, \"avg\": 345101.6182024169, \"sum\": 2741487255 } }, { \"key\": \"BUCKINGHAMSHIRE\", \"doc_count\": 6754, \"house_price_percentiles\": { \"values\": { \"1.0\": 96000, \"25.0\": 210044.27898321193, \"50.0\": 302701.05212355213, \"75.0\": 471529.1039576365, \"99.0\": 1639470.0000000005 } }, \"house_price_stats\": { \"count\": 6754, \"min\": 36000, \"max\": 7075000, \"avg\": 395626.3212910868, \"sum\": 2672060174 } } ] } } } So it looks like Greater London is the most expensive place to live. However, the problem with sorting the data this way is that although Greater London certainly had the highest priced sale in 2014, it doesn't tell us anything about the other house sales. That one sale is likely to skew the data a lot in favour of the Greater London area. So Greater London certainly has the most expensive address sold in the UK in 2014 but as a county as a whole, is it really at the top of the list? To answer this we could sort the terms aggregation by the mean average, but, as we discussed previously, this can be (and from our previous findings, is) skewed heavily by the high-end sales. A better metric here might be the median value. This will essentially tell us at what price the 'middle' sale for 2014 was for each county. To do this, we sort the terms aggregation based on the 50th percentile of that term, rather than the max: GET housesales\/_search?search_type=count { \"aggs\": { \"counties\": { \"terms\": { \"field\": \"county.raw\", \"size\": 5, \"order\": { \"house_price_percentiles[50]\": \"desc\" } }, \"aggs\": { \"house_price_stats\": { \"stats\": { \"field\": \"price\" } }, \"house_price_percentiles\": { \"percentiles\": { \"field\": \"price\", \"percents\": [ 1, 25, 50, 75, 99 ] } }, \"stamp_duty_bands\": { \"percentile_ranks\": { \"field\": \"price\", \"values\": [ 125000, 250000, 500000, 1000000, 2000000 ] } } } } } } Now we can see the order of the counties changes quite a bit: { ... \"aggregations\": { \"counties\": { \"doc_count_error_upper_bound\": -1, \"sum_other_doc_count\": 535352, \"buckets\": [ { \"key\": \"WINDSOR AND MAIDENHEAD\", \"doc_count\": 1774, \"house_price_percentiles\": { \"values\": { \"1.0\": 131387.5, \"25.0\": 283679.3706293706, \"50.0\": 375076.70454545453, \"75.0\": 535702.1296296297, \"99.0\": 2251350 } }, \"house_price_stats\": { \"count\": 1774, \"min\": 46250, \"max\": 5300000, \"avg\": 479086.5941375423, \"sum\": 849899618 }, \"stamp_duty_bands\": { \"values\": { \"125000.0\": 0.9582863585118376, \"250000.0\": 18.207440811724915, \"500000.0\": 72.71709605768585, \"1000000.0\": 95.03945885005636, \"2000000.0\": 98.81623506200113 } } }, { \"key\": \"GREATER LONDON\", \"doc_count\": 84256, \"house_price_percentiles\": { \"values\": { \"1.0\": 110000, \"25.0\": 250000, \"50.0\": 361150.5580953402, \"75.0\": 556310.594361639, \"99.0\": 3076195.800751876 } }, \"house_price_stats\": { \"count\": 84256, \"min\": 50881, \"max\": 50000000, \"avg\": 525786.4564660083, \"sum\": 44300663676 }, \"stamp_duty_bands\": { \"values\": { \"125000.0\": 2.0224078997341435, \"250000.0\": 26.231959741739463, \"500000.0\": 70.54815638375172, \"1000000.0\": 91.68715171319795, \"2000000.0\": 97.83517054664898 } } }, { \"key\": \"SURREY\", \"doc_count\": 16168, \"house_price_percentiles\": { \"values\": { \"1.0\": 97890, \"25.0\": 249780.1736677116, \"50.0\": 341882.1553970223, \"75.0\": 516708.2499209361, \"99.0\": 1990000 } }, \"house_price_stats\": { \"count\": 16168, \"min\": 12000, \"max\": 12500000, \"avg\": 448801.1140524493, \"sum\": 7256216412 }, \"stamp_duty_bands\": { \"values\": { \"125000.0\": 2.3070262246412665, \"250000.0\": 28.315190499752596, \"500000.0\": 73.96239802319863, \"1000000.0\": 94.69347101341646, \"2000000.0\": 99.078426521524 } } }, { \"key\": \"WOKINGHAM\", \"doc_count\": 2082, \"house_price_percentiles\": { \"values\": { \"1.0\": 107715, \"25.0\": 248710.41666666663, \"50.0\": 320477.2727272727, \"75.0\": 429986.1764705882, \"99.0\": 1176840.000000002 } }, \"house_price_stats\": { \"count\": 2082, \"min\": 45000, \"max\": 3300000, \"avg\": 366122.4620557157, \"sum\": 762266966 }, \"stamp_duty_bands\": { \"values\": { \"125000.0\": 2.2574447646493754, \"250000.0\": 28.914505283381363, \"500000.0\": 85.01440922190201, \"1000000.0\": 98.52605667627282, \"2000000.0\": 99.82118676434847 } } }, { \"key\": \"BUCKINGHAMSHIRE\", \"doc_count\": 6754, \"house_price_percentiles\": { \"values\": { \"1.0\": 96000, \"25.0\": 210042.35757575755, \"50.0\": 301217.14015928353, \"75.0\": 471271.60837438423, \"99.0\": 1639470.0000000005 } }, \"house_price_stats\": { \"count\": 6754, \"min\": 36000, \"max\": 7075000, \"avg\": 395626.3212910868, \"sum\": 2672060174 }, \"stamp_duty_bands\": { \"values\": { \"125000.0\": 3.849570624814924, \"250000.0\": 39.19159016878886, \"500000.0\": 78.51659370525427, \"1000000.0\": 96.06172164854438, \"2000000.0\": 99.55581877405982 } } } ] } } } Now, Greater London and Surrey are still in the top 5, but have changed position. Most notably, Windsor and Maidenhead has got to the top of the list where it hadn't made the top 5 previously. The median value is higher than Greater London suggesting that although London has more expensive properties than Windsor and Maidenhead, it does not have as high a concentration of expensive housing. We can also see that where the national data suggested that about a quarter of house sales are not subject to stamp duty tax, in Windsor and Maidenhead less than 1% of house sales avoid the tax. Conclusion In this article we have explored how numeric aggregations can be used to explore a dataset. We have seen how the stats aggregation can be used to gain a rudimentary understanding of the data, and how this can be furthered by combining it with the percentiles and percentile ranks aggregations. \n"}<br>{"index": {"_id": 1160}}<br>{"title":"This Week in Elasticsearch - January 28, 2015","seo_title":"","url":"\/blog\/2015-01-28this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"January 28, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Elasticsearch Core In Apache Lucene this Past Week . presenting at Montreal meetup! \u2014 Colin Surprenant (@colinsurprenant) Elasticsearch EcosystemHere's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Slides & VideosTaylor Lovett shares how Elasticsearch can make WordPress search sing\u00a0introduces the ELK stackPour nos amis francophone par David PilatoBritta Weber speaks about , and at . \u2014 Fyber (@Fyber) Where to Find UsWe'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Director of Developer Relations, , know!Belgium Germany IsraelThe Tel Aviv-Yafo ELK meetup group will be talking How to Use ELK to Analyze Logs from a Large Production AWS Environment on February 24. These folks are looking for space to meet, so you can host get in touch with the organizers. You can now while they're finding a location.JapanRegistration is already full for the next Elasticsearch Japan Study Session in Tokyo, but you can . The user group will get together on February 13 at 7:30 PM.NorwayJoin the NDC Meetup in Oslo on Feb 18 and hear talk about Data Exploration with \u2014 Found (@foundsays) SwedenJust announced: Stockolm Meetup for on 2 Feb. Many thanks to for hosting & speaking! \u2014 Leslie Hawthorn (@lhawthorn) Taiwan United Kingdom United States Where to Find You If you're a regular reader of This Week in Elasticsearch, a.k.a TWIES, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup!Head on over to ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.)Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head.TrainingsIf you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1161}}<br>{"title":"NEST 1.4 Released","seo_title":"","url":"\/blog\/nest-1-4-released","author":{"name":"Martijn Laarman"},"date":"January 28, 2015","category":"Engineering","locales":"","content":" The .NET team within Elasticsearch is happy to announce that NEST and Elasticsearch.NET 1.4 The big theme for this release was parity. After we released , we went through all the PR\u2019s that made it into and created tickets for them in our own GitHib issues. Within 2 weeks, all of them were closed! This means that you can now use the new , and aggregations, or call the . Check out the for the full list. Stability fixes Rather than releasing before Christmas, we focused on closing as many of the lingering open tickets and stability fixes as possible. We also heard from many of our users that our default connect timeout of was a little too stringent on cloud platforms. Our default timeout is now and when using . Better shield support NEST 1.3 fully supports all the moving parts of Shield, but we found a bug in our that would reintroduce newly found nodes as and not . If you are planning to use shield and , upgrading to is highly recommended. We also added a greater default connect timeout when using , which is now set to . We found that connecting locally over is typically fast enough, but when using remote nodes you need some more leeway built in. Configuring ids in code An , long ignored, has finally made it in! NEST by default infers \u2018s on objects when they are not passed explicitly by looking at the property of your object. Previously the only way to override this behavior was through the attribute: [ElasticType(IdProperty=\"AlternateId\"] This change introduced an alternative way to configure id properties, via code: var settings = new ConnectionSettings() .MapIdPropertyFor(o => o.AlternateId): Observe on backups and restores Much like , that coordinates several long running\/sequential calls and exposes them as an , we now offer a similar experience for backup and restore: var interval = TimeSpan.FromMilliseconds(100): var restoreObservable = this.Client.RestoreObservable(interval, r => r .Repository(_repositoryName) .Snapshot(_snapshotName) .RenamePattern(d + \"_(.+)\") .RenameReplacement(d + \"_restored_$1\") .Index(_indexName) .IgnoreUnavailable(true)): In this example we will return an that you can subscribe allowing you to monitor restore progress and be notified when it completes (or fails). Many many thanks to who volunteered to implement this new feature. .NET 4.5 builds in our NuGet package. We included specific builds of our DLLs in our NuGet package so that you can now use and on applications that target the desktop CLR (). Support for the Core CLR () is high on our wishlist but since it might mean some breaking changes it won\u2019t be available until we release . Our builds now also have enabled with the help from . See for details on how to set it up. Community feedback Every release blog post we touch on how much we appreciate your contributions, but we really really do! We are pleasantly surprised at the number of you who are on the bleeding edge builds and help us spot errors before they are even released. deserves a special mention here for helping us catch an edge case aggregation parser bug in our bleeding edge builds by providing one of the best , allowing us to fix the bug within hours. As always many of our have been provided by the community, thank you! If you are developing a .NET application with NEST and you need a fix that has not been released on NuGet yet, remember you can always get our bleeding edge builds from . Keep in mind, these builds have been unit tested but have not gone through the rigorous integration testing that we do for our NuGet releases against Elasticsearch release. What\u2019s next? We are going to focus on our branch making it the default branch on GitHub as well. will go into maintenance mode, keeping track with Elasticsearch updates and releases. Our current status-quo means we have 5 different unit\/integration tests projects, we have been spiking a unique approach to unify all our testing and documentation needs using Roslyn with something we\u2019ve dubbed . Much of our efforts in 2.0 will be to re-architect our testing infrastructure. support will dictate much of our rewrite. The most intrusive issue being that is longer available, so we will move to as our default implementation. We have no plans to drop support though! Another huge part that we hope to tackle in 2.0 is to formalize Elasticsearch\u2019s request and responses and hopefully be able to generate our domain and JSON serialization for optimal performance. As always, please don\u2019t hesitate to submit your questions\/suggestions\/issues to either or . \n"}<br>{"index": {"_id": 1162}}<br>{"title":"Shield: Redefining What You Can Do with ELK","seo_title":"","url":"\/blog\/shield-redefining-can-elk","author":{"name":"Steven Schuurman"},"date":"January 27, 2015","category":"News","locales":"","content":" When we originally built Elasticsearch, we architected it to serve as a powerful search engine that could easily scale across a distributed environment and be used to both search and analyze any type of data \u2014 essentially serve as the backbone for a business to centralize, explore, and extract insights out of any data they want. When we released the software four years ago, however, using a search engine to also perform operational and even business analytics was a completely foreign, somewhat extreme idea \u2014 so we let our users make this discovery on their own. Fast forward to nearly 20 million downloads later and 4x customer growth in 2014, businesses worldwide continue to implement Elasticsearch, Logstash, and Kibana for an endless variety of use cases. Adoption started with end user-facing sites like , , and implementing us for search, then moved to businesses like , , and TomTom utilizing Elasticsearch for log analysis. Over the past year, we've started to see ELK stack usage align with our initial vision of powering custom analytics use cases \u2014 many that have far exceeded our wildest dreams. built its own analytics tool on top of Elasticsearch to make sure it publishes and presents the right news content on its site at the best time of day, not only leveraging data to make sure its content gets maximum exposure but also to guide its editorial strategy by evaluating which content its audience reads. uses our software to analyze patient data. Financial services firms analyze trade data with Elasticsearch to help advise their clients on investment decisions. Criminal investigative units put forensics data in Elasticsearch to help solve crimes. The list goes on \u2026. Needless to say, businesses continue to put more and more data into the ELK stack to extract insights. In order to meet customer demand to utilize ELK across even more of their business, we're extremely excited to introduce , a security and administrative plugin to the ELK stack that makes it easier for our customers to do even more things with their most valuable asset: their data. Shield's introduction today follows a successful beta with a handful of our users and customers. Some of the new capabilities Shield provides that let businesses do even more with the ELK stack include: Shield is available starting today as part of our Development, Gold, and Platinum subscriptions (which means it's *free* for existing customers!). Those interested in checking it out can download a free 30-day trial at . We couldn't be more excited about the next evolution of both our software stack as well as our business, and hope our users are, too. \n"}<br>{"index": {"_id": 1163}}<br>{"title":"You Know, for Security: Shield Goes GA","seo_title":"","url":"\/blog\/you-know-for-security-shield-goes-ga","author":{"name":"Uri Boness"},"date":"January 27, 2015","category":"Engineering","locales":"","content":" Today we are pleased to announce \u2014 the first release of our security plugin for Elasticsearch. While we announced the coming of Shield back in November, today is when the security functionality for Elasticsearch completes the transition that started with a general wish, moved to concrete ideas and execution plan, and is now a reality. While it has always been possible to secure Elasticsearch clusters by deploying them within well-secured environments, we continuously received requests from customers and users to have a more integrated solution. We started exploring what such a product would look like, spending a lot of time making sure we truly understood the security needs of our customers and users. The result is Shield \u2014 a commercial Elasticsearch plugin that enables securing Elasticsearch clusters. And we are pleased to include it as part of all our Development, Gold, and Platinum subscriptions at no additional cost. This first release is focused on infrastructure and foundational functionality. We went to great lengths preparing Elasticsearch itself for security, not just on its extensibility side, but also carefully rethinking how the data flows in it. We\u2019ve built a foundation that not only delivers immediate tangible value when it comes to securing Elasticsearch clusters, but also enables us to extend its functionality incrementally and rapidly over time. Features Shield 1.0 focuses on the following five aspects: Authentication Security at large is all about identity (e.g., Who called this API?, What service connected to our system?, etc.). At any given time in the lifetime of a service, one could associate a subject (a.k.a ) with any of the currently running sub-\/processes. Having this association mandates that the users will be identified just before any of the sub-\/processes start running. The process of identifying the users is called Authentication and it is triggered for every API call in Elasticsearch. There are many different authentication methods, each requires the user to provide different types of credentials by which they\u2019ll be identified (a.k.a. ). In Shield 1.0 we kept it simple and require the authentication token to be in the form of a . (That said, Shield\u2019s authentication infrastructure is built to easily extend this and support other authentication tokens in the future.) Receiving the user credentials is not enough, next we need to verify and authenticate them. In Shield, this is the responsibility of realms. A realm can be seen as an authentication provider\/service that can either resolve and verify the relevant user, or reject the authentication token due to incorrect credentials or simply because the user is unknown. Shield\u2019s authentication mechanism enables you to configure multiple realms and chain them together where one realm can serve as a fallback to another. In Shield 1.0 we support three realm types: The realm in the elasticsearch.yml configuration file in the following manner: shield.authc realms: esuser: type: esusers order: 0 ldap: type: ldap order: 1 url: ldaps:\/\/url\/to\/ldap1\/server ldap_fallback: type: ldap order: 2 url: ldaps:\/\/url\/to\/ldap2\/server As mentioned above, the realms are consulted one at a time in a chain. The per-realm order setting determines the order in which they will be consulted. NOTE: Shield comes with a command-line tool to manage the users stored in the esusers files. Authorization Authorization is the process of granting or denying a user access to a protected resource. Modern systems use the role-based access control (a.k.a RBAC) model to determine user permissions. In this model, each user is associated with a set of roles, where each role defines a set of permissions. This enables sophisticated configuration where permissions can be shared across functional groups. For example, we may define the following roles: Having that, from the finance department may have both employee and finance roles, granting her access to company directory and all financial data. Since the authorization process requires the user to be associated with the incoming request, it\u2019s only natural for this process to execute directly after the authentication phase. Shield defines two types of protected resources \u2014 cluster and indices \u2014 which cover and protect all API calls in Elasticsearch. Furthermore, it enables defining the available roles and their associated permissions on both. Once defined, roles may be assigned to users or mapped to LDAP\/AD groups. The roles are defined in a dedicated configuration file. Here is an example of such configuration: admin: cluster: all indices: '*' : all monitor: cluster: monitor indices: '*': monitor employee: indices: 'company_directory' : read sales: indices: 'opportunities' : read, write 'accounts' : read, write finance: indices: 'expenses' : read, write 'purchases' : read, write In the example above, we defined five roles: The definitions above use , , and as \u201cnamed\u201d privileges, as we often like to refer to them. These are predefined, high-level privileges that group multiple low-level Elasticsearch actions under a single name (e.g., the privilege groups and operations). While for most cases these high-level named privileges will suffice, we also enable finer-grained access control by explicitly specifying the actions granted for a specific role, as shown in the example below: hr: indices: 'company_directory' : indices:data\/write\/index, indices:data\/write\/update The authentication realms we\u2019ve discussed above are responsible for resolving the roles associated with each user. With the internal esusers realm, the roles can be assigned to users (and modified) using the provided esusers command-line tool. With and , we enable mapping LDAP\/AD groups to Shield roles. Having both authentication and authorization in place, we can now grant or deny user requests depending on their nature (action\/operation types) and the user\u2019s privileges. Encrypted Communication While authorization protects the data in Elasticsearch from a functional perspective (granting access to an operation to only permitted users), sending the data unencrypted from the client to the Elasticsearch cluster and between the nodes in the cluster, is dangerous. Third parties \u201clistening\u201d or sniffing the wire can potentially view and modify the data on the fly, or emulate other users and thus compromise the cluster as a whole. Shield 1.0 enables securing all communication channels in Elasticsearch. Whether these are the channels between the nodes within the cluster, or those that are opened to the clients. This is done with the introduction of SSL\/TLS communication. When SSL is enabled Shield will replace the transport services of Elasticsearch with ones that \u201ctalk\u201d SSL\/TLS. This can be done separately on the internal node-to-node communication channels and on the HTTP transport that is opened to serve the REST APIs. SSL\/TLS in Shield is based on the standard Java\u2122 support and is based on keystores and truststores. Configuring SSL\/TLS involves importing certificates into the keystore of every node. It is possible to use Certificate Authority (CA) signed certificates and their authorization\/validation will be done on the trusted CAs. This requires all trust stores to know about all trusted CAs. When new nodes are added to the cluster, all that is required is to sign their certificates with one of the trusted CAs, without the need to update all the keystores\/truststores on all other nodes in the cluster. You can read more about about securing the communication channels and how one can configure SSL\/TLS in the Shield in Node-to-Node Authentication It is also possible (and highly recommended) to configure the SSL transports to perform node authentication, making sure that only the permitted nodes can connect to the cluster. This can be done by setting to . When set, during the SSL handshake between the node, the connected node will request a client certificate from the connecting node and verify it. If verification fails, the SSL handshake fails and the connection is denied. SSL Client Authentication Requiring node authentication on the transport level poses an interesting question. How will Elasticsearch behave when using a Transport Client to connect to the cluster? Since the Transport Client uses the same channels as the other nodes in the cluster, a node cannot typically differentiate between another node trying to connect to it and a client when the connection is established. One could claim, that the simplest solution here is to simply issue certificates to the Transport Clients as well. While that will solve the authentication challenge, it also introduces another one: (potentially malicious) Transport Clients will be able to emulate nodes in the cluster. And we don\u2019t want that, do we?! Luckily, there\u2019s a clear path to an elegant solution here: transport profiles. Introduced in Elasticsearch 1.4, transport profiles enables you to define multiple network channels for the transport layer (each binding to different host\/port). Shield extends this support by enabling the configuration of different SSL settings per profile. It also enables you to clearly distinguish between a client profile type to a node type. With this in place, one can set up two profiles \u2014 one dedicated for the clients (one that doesn\u2019t require SSL client authentication) and another one dedicated for nodes (one that requires SSL client authentication). With this settings, there\u2019s no need to issue certificates for the clients, and Shield will also ensure that requests coming through the client profile will be limited to those that clients are allowed to execute (i.e., public API requests). IP Filtering While this doesn\u2019t directly fall under the \u201cauthentication\u201d category, it is related. Shield ships with its own IP filtering mechanism that enables setting a list of \u201callowed\u201d and \u201cdenied\u201d IPs, from which requests can be made. These filtering rules can be configured on multiple levels \u2013 globally on the transport channels, on the transport profile level, and globally on the HTTP channels. The following snippet shows an example of such settings (within the elasticsearch.yml configuration file): shield: transport.filter: allow: - '127.0.0.1' - '2001:0db8:1234:0000:0000:8a2e:0370:73 deny: - '10.0.0.0\/8' - '2001:0db8:1234::\/48' - '*.google.com' http.filter: allow: [ '10.0.0.0\/8' ] deny: [ '127.0.0.1' ] transport.profiles: client: shield.filter.deny: [ '_all' ] As you can see above, the IP rules support both IPv4 and IPv6, CIDR masks, hostnames, and wildcards. Also note that while this functionality can typically be added by configuring the IP tables of the hosting OS, keeping it in Shield significantly simplifies these settings and removes yet another moving part in the overall deployment. (See more about .) Audit Trail Being an essential part of any secured system, audit trails enable tracking of important events occurring in Elasticsearch. Persisting these events provides evidence for important activities in the Elasticsearch cluster and primarily serves as a diagnostic tool when investigating potentially suspicious\/malicious events. In Shield 1.0.0, audit trails are persisted in audit\/access logs that are separate from the standard Elasticsearch logs. They have a well-defined and consistent structure that makes it easy to both read and parse, and emit several types of events. It is also possible to configure the level of the information that is emitted for each event by simply configuring the logging level. Here is a list of the events that may be logged: To learn more about audit trails in Shield, . So\u2026 What\u2019s next? As mentioned in the introduction, this is just the beginning. There are many features we\u2019d like to add to Shield, and now that we have the solid infrastructure built, the next version of Shield will focus on adding these features. Some of these features include (and not limited to): Shield is the second commercial product offered by our company (after ), yet it\u2019s available for everyone to download and evaluate on development environments. You install it just like you install any other plugin in Elasticsearch (see ). Once installed, you\u2019ll automatically be issued a 30-day trial license with which you can test it. If you need more time, you\u2019re invited to contact us at and enquire for an extended trial license. As with every product we have, your feedback is highly appreciated. If you have any questions regarding Shield\u2019s commercial offering, its functionality, future roadmap, or any other security related topic, \n"}<br>{"index": {"_id": 1164}}<br>{"title":"Where in the World Is Elasticsearch? - January 26, 2015","seo_title":"","url":"\/blog\/where-in-the-world-is-elasticsearch-6","author":{"name":"Livia Froelicher"},"date":"January 26, 2015","category":"","locales":"","content":" After a full month of meetup activity around the world, we're excited to end January with a few more opportunities to talk the ELK stack with our community members. Here's what's on the itinerary in short: Belgium, Germany, Taiwan, United Arab Emirates, the United Kingdom and the United States. We hope to see you at one of these wonderful places! Upcoming EventsEurope January 26-30: - Join for his talk on Thursday, 29, 11:00 a.m. - 11:45 a.m. Alex will discuss . January 29-30: - will be attending talks and would love to talk all things Elasticsearch & the ELK stack with you in the hallway track while sipping a coffee (sponsored by Elasticsearch :)). Make sure to say hello! January 31 - February 1: - Visit us in the on Saturday, January 31, which will include a talk from on . Also, don't miss out on excellent presentation , Sunday, February 1, 3:30 p.m. - 4:15 p.m. Last but not least, you can visit , , and the rest of the Elasticsearch crew at our table in the exhibits hall, Building K, Level 2. Stop by for some awesome knowledge sharing and swag! Upcoming MeetupsNorth America January 29: Europe January 27: January 27: January 29: January 29: January 30: - Pre-FOSDEM Special Edition Asia January 27: January 29: That's it for this week. Stay tuned for Elasticsearch happenings next week - there's much to come! - The Elasticsearch Team P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag! \n"}<br>{"index": {"_id": 1165}}<br>{"title":"Intro to Aggregations pt. 2: Sub-Aggregations","seo_title":"","url":"\/blog\/intro-to-aggregations-pt-2-sub-aggregations","author":{"name":"Zachary Tong"},"date":"January 22, 2015","category":"Engineering","locales":"","content":" \n"}<br>{"index": {"_id": 1166}}<br>{"title":"This Week in Elasticsearch - January 21, 2015","seo_title":"","url":"\/blog\/2015-01-21-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"January 21, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core In Apache Lucene this Past Week Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. \"Cloud years are functionally equivalent to dog years\": ICYMI How we built ElasticSearch cluster on \u2014 Mingle (@thatsmingle) I have to say does a lot of things right! Moving NEST over was a pretty smooth experience \u2014 Martijn Laarman (@Mpdreamz) Slides & Videos introduces the ELK stack at the recent linux.conf.au conference Phil Wills from TheGuardian.com on how they've scaled to 1M unique browser per month using Elasticsearch & Scala Levi Reich from Thomson Reuters on their Elasticsearch use case, and our very own introduces the ELK stack Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Director of Developer Relations, , know! Q&A with speakers and team at meetup! \u2014 Ryan Roemer (@ryan_roemer) Australia and will be visiting the Melbourne Search Users Group tomorrow. You'll hear from them on an Introduction to the ELK stack and how to contribute to the ELK community. Mark Wallis from Lexer will also be presenting, discussing Search Interfaces and User Experience. You can still for this Jan 21 meetup. Belgium France The 12th Elasticsearch Paris Meetup is on in Paris tomorrow night, but we're currently sold out. You can still . We'll let folks know if spaces open up tomorrow. Germany United Arab Emirates The Hadoop User Group is gathering in Dubai on January 27 for a meetup. Elasticsearch's own will be joining via video conference to give a presentation titled \"Make Sense of your (BIG) data!\" today to save your spot. United Kingdom United States on and right now at \u2014 elasticsearch Vienna (@elasticvienna) Where to Find You If you're a regular reader of This Week in Elasticsearch, a.k.a TWIES, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1167}}<br>{"title":"Understanding the Memory Pressure Indicator","seo_title":"","url":"\/blog\/found-understanding-memory-pressure-indicator","author":{"name":"Konrad Beiske"},"date":"January 21, 2015","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud.We all know memory is critical to Elasticsearch, but when should you add more? In the console we've included a memory pressure indicator so that you can easily check where your cluster is at in terms of memory usage and capacity. For those familiar with how the JVM garbage collector works: \"The indicator uses the fill percentage of the old generation pool\". In this article I will cover the basics of the old pool and why we chose that as the indicator. \n"}<br>{"index": {"_id": 1168}}<br>{"title":"Scaling Trackjs with Elasticsearch for Fun and Profit","seo_title":"","url":"\/blog\/scaling-trackjs-with-elasticsearch-for-fun-and-profit","author":{"name":"Leslie Hawthorn"},"date":"January 20, 2015","category":"User Stories","locales":"","content":" JavaScript errors are not great, and rarely do they provide you with enough information to identify what went wrong. TrackJS, a JavaScript error reporting service for modern web applications, helps solve this problem. Similar to an airplane's black box, TrackJS captures events from the application, user, and network leading up to the error, so you can recreate and fix the problem. If you're building a JavaScript app, this is an essential tool. In the spirit of knowledge sharing, we wanted to tell our Elasticsearch story. Like many others out there, TrackJS is a small company scaling quickly, and open source solutions can play a critical role in growing your organization without breaking the bank. TrackJS uses Elasticsearch to provide real-time JavaScript error reporting analytics to our customers. It underpins our backend and allows us to slice and dice client-side errors. We've encountered a number of scaling issues as we've grown, and have gained hard-won knowledge in the process. We don't have an unlimited budget \u2014 the answer for us is not always \u201cadd a bigger box.\" This post is a raw look at how our business has grown to process over 200 million error events per month on a limited budget \u2014 and still provide a great user experience. But before you dive in, we invite you to get an in-depth look at how we use Elasticsearch in an . We'll give you the inside scoop on what happened when we hit #1 on HackerNews. (And if you'd like to get even more out of the session, we invite you to grab a free trial of of our software at .) In the Beginning TrackJS started simple, with an application server and database server. The database was a traditional RDBMS with a normalized schema and proper referential integrity. Our application performs many aggregate counts. To do aggregates in SQL inevitably means a GROUP BY, which often equates to a table scan. This negatively impacts performance, and once we hit a few million errors stored, we couldn't afford a large enough box to process things in any reasonable timeframe. We tried removing foreign keys, tweaking the indexes, denormalizing everything, and in the end, we concluded it was the wrong tool for the job. We wanted near real-time analytics, and SQL wasn't going to give it to us. The Right Tool for the Job We auditioned several NoSQL databases to replace our relational database. The test was simple: perform several aggregate counts over one million errors on a single core VM with 1.5GB of RAM, and see who does it best. It was meager hardware, but we were curious to see how various tools would perform. We will not name names here, but many challengers came up short. (One even experienced catastrophic data loss.) When using only the defaults on Windows machines, Elasticsearch was able to handle the challenge without breaking a sweat. Running on Azure TrackJS is primarily hosted on Microsoft Azure. We host our Elasticsearch cluster on a few virtual machines in a single Azure Cloud Service. Azure gives us load balancing out of the box. It does not support multicast, so we explicitly turn it off in our Elasticsearch config and instead rely on the unicast hosts list. Originally, our web tier was not on the same virtual network as our Elasticsearch cluster. Azure exposed a public IP\/hostname so it wasn't a big deal (or so we thought). We started experiencing random connectivity issues, but only when connecting to Elasticsearch from our web tier. After lots of diagnostics, we believe it's related to the load balancer\/NAT our web tier went through. Today, we connect directly between internal IPs and the system is much more stable. Index Per Customer Next, we had to figure out how to index our error data. Elasticsearch gives you lots of options, which can be overwhelming. We really didn't know what we were doing, or know how to organize documents, so we went with the simplest thing we could think of: assign one index per customer. At the time we were using a three node (Windows) cluster. Each node was two cores and 3.5GB of RAM. Each customer index was three shards with one replica. This meant that the data for each customer was spread over all the nodes, and to serve a query for a customer, each node had to be involved. When we hit 800 customers the amount of overhead for each index, coupled with the number of shards spread over that many nodes, started causing problems. We saw random disconnects and timeouts as the boxes wouldn't respond to pings in a timely fashion. CPU was always pegged, and it was impossible to do multiple index queries. More money and larger hardware could have solved the problem for us, but we had some fundamental data organization issues we needed to address. Elasticsearch 1.0 and Backup When we first started using Elasticsearch there was no good solution for backup. Many people use Elasticsearch as a projection of some other canonical data store which does have backup capability. We didn't have that situation: Elasticsearch was it. Being ex-enterprise guys we knew we couldn't just \u201cwing it,\" so we made our own. We hand-rolled a system that shoved a serialized version of our error data into cloud storage should the need to restore ever arise. Once Elasticsearch 1.0 came out with snapshot capability, we jumped on it and continue use it to this day. We backup to Amazon S3 and restore to our dev environment just to make sure it's all working. So far we've had great success. We believe it's possible to use Elasticsearch as your primary data store and still provide excellent retention and uptime guarantees. Alias Per Customer TIP: Use Aliases. Even with a single index you think you'll never have to change. Each workload is different so there's no \u201cbest\" way to organize your data in Elasticsearch. However, in our case it was apparent that we had too many customers and not enough money to pull off the index-per-customer approach. Our next idea was to put all of the error data into a single index and create an alias for each customer. It worked and continues to be the approach we use today. We still have a three-node cluster, but upgraded our machines to run Linux and each node now has 14GB of RAM. Our single error index consists of 50 shards. We intentionally oversharded the index so we can add additional nodes for scaling at-will. Each customer has their own alias. The alias consists of a term filter (by customer ID) as well as a routing value (also the customer ID). This means that each customer's data is located on a single shard. To serve a search request the cluster need only contact one node, and one shard within that node, to craft a response. This also ensures we get accurate count data for each aggregation. This strategy is working well, though some cracks in the foundation are appearing. We currently run a delete-by-query to truncate customer's data as it reaches the end of our retention period. This will occasionally cause stop-the-world garbage collection (GC) pauses and drop a node for a time. In addition, we're starting to see our field data cache sizes creep up as we ingest more (and varied) errors and aggregate them. Finally, we are worried about so-called \u201chot shards\" \u2014 shards that were randomly assigned heavy-use customers and are much larger than other shards. There is no easy way to rebalance those at the moment. The Future: Index Per Day To address the GC pauses we're planning on migrating to an index-per-day strategy with customer aliases pointing at several indices at once (based on their retention period). This will let us delete data (drop an entire index) without putting memory pressure on the JVM. Creating a new index per day also lets us more easily change our type mappings. Currently if we want to change existing mappings we have to reindex all the data. With a new index each day we'll be able to evolve our mappings as necessary. We've also upgraded to 1.4.1 from 1.0.1, which should give us quite a few aggregate performance optimizations and cluster stability enhancements. So far it's been a huge improvement. Doc Values To address the field data cache increases we're beginning our experiments with doc values. By default, when doing aggregations, Elasticsearch pulls the field data in memory. This is an expensive operation and, in our case, the greatest driver of hardware cost. An alternative exists that pre-computes the field data at index time: doc values. With the release of Elasticsearch 1.4.1, doc values have been tuned for performance, and are approaching the speed of the field data cache. We're hopeful this will let us continue to scale without breaking the bank. Elasticsearch has been central to our growth and success, and underpins a lot of what we hope to do in the future. We look forward to continuing to work together. P.S. Don't forget to for more in-depth technical discussion about our story and insight into how small teams can make a big impact with Elasticsearch. And grab and start finding and fixing your production JavaScript bugs. \n"}<br>{"index": {"_id": 1169}}<br>{"title":"Where in the World Is Elasticsearch? - January 19, 2015","seo_title":"","url":"\/blog\/where-in-the-world-is-elasticsearch-5","author":{"name":"Livia Froelicher"},"date":"January 19, 2015","category":"","locales":"","content":" Hello Elasticsearch Community! We have got a full host of meetups ahead of us this week. Check out where we are! Upcoming MeetupsNorth America January 19: January 20: Europe January 20: January 22: January 22: Australia January 22: There's more to come next week, plus we are heading to FOSDEM! - The Elasticsearch Team P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag! \n"}<br>{"index": {"_id": 1170}}<br>{"title":"This Week in Elasticsearch - January 14, 2015","seo_title":"","url":"\/blog\/2015-01-14-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"January 14, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Elasticsearch core In Apache Lucene this past week analyzing my ~14k emails of the last 8 years with and Kibana \u2014 Florian Purchess (@florianpurchess) Elasticsearch EcosystemHere's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Slides & VideosGaspar Mu\u00f1oz and Santiago Mola spoke at the Madrid Elasticsearch meetup on December 15. The video from their talk -- On-the-fly ETL con EFK: ElasticSearch, Flume y Kibana -- is now available, en espa\u00f1ol!At one the December gathering of the Elasticsearch London MeetUp group, - CTO & Co-founder at Orchestrate.io - shared some great real-world lessons in his talk Where to find UsWe'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Director of Developer Relations, , know!AustriaThe Vienna Elasticsearch user group will be doing a joint meetup with the Vienna DB meetup group on Tuesday, January 20 (in Vienna, of course!). Karel Minarik and Martijn van Groningen of Elasticsearch will both be presenting. Save your spot and !BelgiumIf you're headed out to (Europe's largest gathering of open source developers!) in Brussels at the end of January, be sure to squeeze time into your schedule for the BeLux (Belgium \/ Luxembourg) Elasticsearch user group on Friday, January 30. Can't make it? Catch us at the Elasticsearch booth, or visit the Open Source Search devroom track at FOSDEM. GermanyOur partner Intrafind is organizing an \"Elasticsearch Expert Talk\" on January 28 in Munich starting at 1pm. You can register using . The Search Meetup Karlsruhe group will be gathering on January 29 for a presentation from Nico Heid on the ELK stack. Check out their for more information and to register for the event.New Zealand and will both be speaking at (also known as LCA) in Auckland. This fantastic event is happening now, and runs through January 16, and is definitely worth attending!The NetherlandsCome to the CRI Service Kennissessie in Houten on January 15 to learn about enterprise logging with Elasticsearch, rsyslog, Docker, and Kibana. Save your place by today.United Arab EmiratesThe Hadoop User Group is gathering in Dubai on January 27 for a meetup. Elasticsearch's own will be joining via video conference to give a presentation titled \"Make Sense of your (BIG) data!\" today to save your spot.United KingdomIf you couldn't decide between the Bath Ruby Battlebot event and the upcoming Elasticsearch meetup, we've got great news: The Elasticsearch meetup has changed dates, so now you can attend both! for this meetup in Bath, now on January 22. There is still a remaining speaking slot, too, so be sure to let the organizer know if you're interested. United StatesThe South Shore .NET user group in Plymouth, Massachusetts, is getting together on January 29 for a presentation on Elasticsearch for data mining. This meetup will be covering Elasticsearch basics and a few other areas, and have you ready to add Elasticsearch to your data analysis toolkit. to save your spot!Tons of folks in SysAdmin Mini Conf to hear on The : Corralling Your Logs \u2014 Leslie Hawthorn (@lhawthorn) Where to Find You If you're a regular reader of This Week in Elasticsearch, a.k.a TWIES, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup!Head on over to ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.)Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head.TrainingIf you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1171}}<br>{"title":"Intro to Aggregations","seo_title":"","url":"\/blog\/intro-to-aggregations","author":{"name":"Zachary Tong"},"date":"January 13, 2015","category":"Engineering","locales":"","content":" global wrapper \n"}<br>{"index": {"_id": 1172}}<br>{"title":"Interfacing with Elasticsearch: Picking a Client","seo_title":"","url":"\/blog\/found-interfacing-elasticsearch-picking-client","author":{"name":"Njal Karevoll"},"date":"January 14, 2015","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. When starting using Elasticsearch, it's easy to get confused about all the different ways to connect to Elasticsearch and why one of them should be preferred over the other. In this article we'll provide an overview of the different client types available and give some pointers on when one should be chosen over another. \n"}<br>{"index": {"_id": 1173}}<br>{"title":"Google Cloud Platform Delivers Real-Time Search with Click-to-Deploy Elasticsearch ","seo_title":"","url":"\/blog\/google-cloud-platform-delivers-real-time-search-with-click-to-deploy-elasticsearch","author":{"name":"David Pilato"},"date":"January 12, 2015","category":"News","locales":"","content":" From the beginning, one of the goals of Elasticsearch was to\u00a0We've achieved another milestone on that mission with that Elasticsearch (plus Marvel!) is available as a click-to-deploy install on Google Compute Engine (GCE). This means that Elasticsearch can be automatically provisioned on GCE in minutes, giving businesses powerful search and immediate insights into the workloads they're running on Google's infrastructure \u2014 from full-text application search to analytics for operational insights. To give it a spin, head on over to .It's been a big year for us in terms of being selected by a variety of key infrastructure players as the search and analytics engine they recommend to their customers. Over the summer, our became certified on , making Elasticsearch compatible across all Apache-based Hadoop distributions thanks to previous partnerships with and . as the underlying full-text search engine for its newly released Azure Search, and we also announced a to provide real-time search and analytics to its Unified Computing System customers. We couldn't be more thrilled, and humbled, that industry leaders like these, along with thousand of businesses worldwide (like Target, Mayo Clinic, Facebook, GitHub, Netflix, Verizon, and PayPal), continue to benefit from our software for mission-critical use cases. We look forward to continuing to help them mine and extract value from their most valuable asset: their data.P.S. We also love a good story. Are you using Elasticsearch on GCE? Tell us about it via or on . \n"}<br>{"index": {"_id": 1174}}<br>{"title":"Where in the World is Elasticsearch? - January 12, 2015","seo_title":"","url":"\/blog\/where-in-the-world-is-elasticsearch-4","author":{"name":"Livia Froelicher"},"date":"January 12, 2015","category":"","locales":"","content":" The new year is still very young but we are already busy again with lots of meetups and events going on. Check them out! Upcoming EventsAustralia January 12-16: - we'll have 2 sessions at this conference: I. will talk about on Tuesday, January 13 from 4:10-4:35 p.m. II. will drop some knowledge about on Wednesday, January 14 from 2:15-3:00 p.m. Upcoming MeetupsNorth America January 14: January 14: January 14: January 15: Europe January 12: January 14: January 15: January 15: Australia January 12: Asia January 13: - The Elasticsearch Team P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag! \n"}<br>{"index": {"_id": 1175}}<br>{"title":"This Week in Elasticsearch - January 07, 2015","seo_title":"","url":"\/blog\/2015-01-07-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"January 07, 2015","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core are so fast these days! \u2014 Simon Bahuchet (@UncleGarf) Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Slides & Videos Bhaskar Karambelkar of Verizon shared his tips on scaling Elasticsearch for production-scale data at the Washington, D.C. meetup on December 11. From the Elasticsearch meetup in Madrid, Spain on December 15: On-the-fly ETL con EFK: Elasticsearch, Flume, Kibana (en espa\u00f1ol), by Gaspar Mu\u00f1oz and Santiago Mola. Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Director of Developer Relations, , know! Belgium If you're headed out to (Europe's largest gathering of open source developers!) in Brussels at the end of January, be sure to squeeze time into your schedule for the BeLux (Belgium \/ Luxembourg) Elasticsearch user group on Friday, January 30. Can't make it? Catch us at the Elasticsearch booth, or visit the Open Source Search devroom track at FOSDEM. Germany will talk about systems on January 13 in Berlin. Very limited space, so please register. Israel The first-ever in Tel Aviv-Yafo will be happening on Tuesday, January 13, and they're kicking off with a great topic: an overview of the Kibana 4 Beta and real-life use cases. Get today! New Zealand and will both be speaking at (also known as LCA) in Auckland. This fantastic event runs January 12 - 16, and is definitely worth attending! And accompanying ,\u00a0we'll be having our first-ever in Auckland on January 12. The schedule is still being finalized, but \u00a0to save your spot. Spain Just a few days away - our own \u00a0will be joining the Barcelona Meetup on January 8 to share his presentation, . to save your place - it's filling up quickly! The Netherlands Come to the CRI Service Kennissessie in Houten on January 15 to learn about enterprise logging with Elasticsearch, rsyslog, Docker, and Kibana. Save your place by today. United Arab Emirates The Hadoop User Group is gathering in Dubai on January 27 for a meetup. Elasticsearch's own will be joining via video conference to give a presentation titled \"Make Sense of your (BIG) data!\" today to save your spot. United States The Codemash conference in Sandusky, Ohio, will have Itamar Syn-Hershko speaking on making distributed search and analytics on big data . Register to join this session on January 8! If you're in Arizona, come to the Elasticsearch meetup at the GoDaddy offices in Scottsdale on Wednesday, January 14 for a great lineup of talks, including a Q & A session with Elasticsearch CTO Shay Banon. Get registered for what is sure to be a great meetup! The South Shore .NET user group in Plymouth, Massachusetts, is getting together on January 29 for a presentation on Elasticsearch for data mining. This meetup will be covering Elasticsearch basics and a few other areas, and have you ready to add Elasticsearch to your data analysis toolkit. to save your spot! Finally, the Washington, D.C. Elasticsearch meetup group will have an \"Unconference\" meetup on January 14. Not sure what an unconference is? In short, it's a conference format where rather than having a structured schedule of talks decided in advance, the schedule is decided onsite, by the attendees themselves - which ensures that the content presented is of value and interest to the people who show up. Intrigued? for this specially planned meetup - we're sure you'll have a great time! Awesome holidays with my lovely . It really went wild : ) \u2014 Bharvi Dixit (@d_bharvi) Where to Find You If you're a regular reader of This Week in Elasticsearch, a.k.a TWIES, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1176}}<br>{"title":"Where in the World is Elasticsearch? - January 05, 2015","seo_title":"","url":"\/blog\/where-in-the-world-is-elasticsearch-3","author":{"name":"Livia Froelicher"},"date":"January 05, 2015","category":"","locales":"","content":" We're excited to kick off 2015 by announcing our winners of the #ElksInTheWild\u00a0holiday photo contest! Congrats to both of our winners, and thanks for participating. You can expect an Elasticsearch surprise in the next few weeks! Awesome holidays with my lovely . It really went wild : ) \u2014 Bharvi Dixit (@d_bharvi) are so fast these days! \u2014 Simon Bahuchet (@UncleGarf) Here's what's going on in the Elasticsearch event-land this week. We hope to meet you at one of these places, and watch for more happenings in your area later this month! Upcoming Meetups North America January 8: South America January 7: Europe January 8: Asia January 10: - The Elasticsearch Team P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag! \n"}<br>{"index": {"_id": 1177}}<br>{"title":"Full-Text Search is an Input-Oriented Task","seo_title":"","url":"\/blog\/found-full-text-search-is-an-input-oriented-task","author":{"name":"Florian Gilcher"},"date":"December 24, 2014","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud.Full-text search is an interesting field for backend developers: it requires raw technical knowledge, knowledge about the input languages and lots of feedback gathering on the usability side. In this article, I'd like to give you a rough overview of the challenges in each area and inform you about basic solutions for them. \n"}<br>{"index": {"_id": 1178}}<br>{"title":"It\u2019s Time! Elastic{ON}15 Registration Is Finally Open!","seo_title":"","url":"\/blog\/its-time-elasticon15-registration-is-finally-open","author":{"name":"Shay Banon"},"date":"December 18, 2014","category":"News","locales":"","content":" It's official: Registration for . Almost a month ago, I gave you an early look at what to expect from our first Elasticsearch user conference happening March 9-11 at Pier 27 in San Francisco, CA. Since then, we've seen a huge, positive response to Elasticsearch hosting this exciting event. The whole company has come together to plan a truly inspiring couple of days, and I'm happy to share even more details with you today about what's to come. First, I can imagine everyone wants to know who is speaking and what topics we will cover. We have put together a preliminary , which outlines a variety of sessions that fall into three main tracks: ELK in the Wild, Developer, and Demo Theater. is entirely dedicated to hearing from you, the user. Many of you out there submitted to speak during this track and share how you're leveraging Elasticsearch, Logstash, and Kibana to do great things. As we've been reviewing the abstracts, we have to say, we'll never get tired of hearing about the amazing work our users are doing. is your opportunity to hear from the people behind the projects you know and love. They will cover a number of themes and give you insight into what you can expect to see in the future. I am super excited about our speaker lineup: Clinton Gormley, Isabel Drost-Fromm, Jordan Sissel, Rashid Khan, Costin Leau, Robert Muir, Boaz Leskes, Spencer Alger, and the list goes on! is our time to work together and learn together. Throughout this track, members of the Elasticsearch team will walk you through live demos of our products. Leslie Hawthorn will be opening this track with a talk about the community. Need I say more? I also want to point out our - and they want to hear from you! So when we aren't on stage speaking, we'll be there to hang out between sessions. You can find us wandering the halls, at our Ask Me Anything stations, as well as hanging out in the developer lounge where we'll host conversations around specific topics and have lightning talks. The is on the Elastic{ON} website. We'll be updating and adding to it in the weeks to come\u2026maybe your name will be on it!? It's been mesmerizing to watch Elasticsearch grow. Elastic{ON} definitely marks a milestone for the company and the products, and we'd love for you to be part of the continuing journey this coming March. (Also, the events team kindly reminded me that space is limited and is sure to fill up fast, so on the Elastic{ON} website ASAP!) \n"}<br>{"index": {"_id": 1179}}<br>{"title":"This Week in Elasticsearch - December 17, 2014","seo_title":"","url":"\/blog\/2014-12-17-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"December 17, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Looks like my North American friends are all hanging out together. I wonder what mischief is afoot \u2014 logstash (@logstash) Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Slides & Videos on DIY Aggregations for Elasticsearch From the December Search Meetup Munich: provides an introduction to Elasticsearch and explores the gotchas of Distributed Systems From the December London Elasticsearch Meetup: The Guardian on how they use Elasticsearch for 100s of searches per second How Logmatic.io uses Elasticsearch in their SaaS log analysis tool (en fran\u00e7ais) Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Director of Developer Relations, , know! Germany For folks in or around Bonn on December 18, the Bonn ELK Meetup group will be holding their inaugural meetup. to save your place. Israel The first-ever in Tel Aviv-Yafo will be happening on Tuesday, January 13, and they're kicking off with a great topic: an overview of the Kibana 4 Beta and real-life use cases. Get today! New Zealand and will both be speaking at (also known as LCA) in Auckland. This fantastic event runs January 12 - 16, and is definitely worth attending! And accompanying ,\u00a0we'll be having our first-ever in Auckland on January 12. The schedule is still being finalized, but \u00a0to save your spot. Spain Our own \u00a0will be joining the Barcelona Meetup on January 8 to share his presentation, . to save your place. The Netherlands Come to the CRI Service Kennissessie in Houten on January 15 to learn about enterprise logging with Elasticsearch, rsyslog, Docker, and Kibana. Save your place by today. United States The Codemash conference in Sandusky, Ohio, will have Itamar Syn-Hershko speaking on making distributed search and analytics on big data . Register to join this session on January 8! and just ready for (flume, ES, Kibana) \u2014 Stratio (@StratioBD) Where to Find You If you're a regular reader of This Week in Elasticsearch, a.k.a TWIES, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1180}}<br>{"title":"Marvel 1.3.0 Released","seo_title":"","url":"\/blog\/marvel-1-3-0-released","author":{"name":"Boaz Leskes"},"date":"December 17, 2014","category":"News","locales":"","content":" Today, we are happy to announce the release of . A lot has happened in Elasticsearch (including the release of Elasticsearch 1.4) since the previous release of Marvel. This version adds monitoring for these new features, e.g. query cache and the new circuit breakers. On top of that, Sense's knowledge base was extended to include the latest API. We also added HTTPs support, preparing Marvel for the up-and-coming release of , our security product. To upgrade, you must install the latest Marvel plugin on all of your Elasticsearch nodes. As with any other Java plugin, you will need to restart each node (one by one) in order for the newer version of Marvel to become active. The upgrade process is described in more detail in the . To conclude, here is complete list of all the goodness that went into this release: Agent Monitoring UI Sense As always, we welcome all feedback so we can continue improving Elasticsearch Marvel. Please send questions, praise, or pains to the or find us on . \n"}<br>{"index": {"_id": 1181}}<br>{"title":"Kibana 4 Beta 3: Now More Filtery","seo_title":"","url":"\/blog\/kibana-4-beta-3-now-more-filtery","author":{"name":"Rashid Khan"},"date":"December 16, 2014","category":"Engineering","locales":"fr-fr","content":" Kibana 4 Beta 3 is out! Along with the usual smattering of small fixes come a few knockout headliners. Once again, we offer you the choice to dive right in by grabbing it here: . However, we suggest you check out the remainder of this post for the feature-by-feature breakdown. Ooo, break it down now! Dance! Interactive Charts and Dashboards Filters are back on the dashboard, and now available in single visualizations too! Bars, points, and pie slices are all clickable and create toggleable filters. We also added some functions to operate on all filters, so you can toggle back and forth between sets with a single click. Scripted Fields Kibana now includes support for Elasticsearch scripting! Not only can you write scripts, you can name them and access them like fields anywhere in the application. Create a scripted field and it becomes part of the documents you view in Kibana as if it was always there. The only catch is that since the script isn't technically part of the Elasticsearch index, you can not search scripted fields. You can, however, use scripts to combine several fields, or perform math on number fields, and then drop the result into a visualization. To help get you started, we've added a handy link in the scripted fields screen titled \u201cCreate a few examples from your date fields.\" Find it by heading to the Settings tab's \u201cIndex\" section. Select or create an index pattern and click the \u201cScripted Fields\" tab. Once you've done that, you'll find yourself with a few new numeric fields available for use in aggregations. For example, we can look at the 24 hours that make up the day, and get the total hits for all of them across 30 days: Highlighting and a New Format for _source JSON is great. We all love JSON. Who doesn't love JSON? XML, that's who, but that's beside the point. JSON can be a bit of a jumble to look at full time, so we've taken to nicely formatting it. The raw JSON for the event is, of course, always available by expanding the record's row and clicking over to the JSON tab. Oh, and while we were at it, we threw in highlighting, too. Kibana will now automatically highlight matching fields, and even march them to the front of the line: Hit Links Maybe you noticed that little in the screenshot above? You might not need to share a visualization or a search, you simply need someone to see just one important hit. Now, it's easy! Metric Visualization Sometimes you don't need a chart a document! You just need that , on a dashboard, right now. And here it is: Ok, there it is! Enjoy! As always, ping us on with issues, suggestions and contributions. Or, if you love IRC like we do, join us in #kibana on Freenode. \n"}<br>{"index": {"_id": 1182}}<br>{"title":"Elasticsearch 1.4.2 and 1.3.7 Released - December 16, 2014","seo_title":"","url":"\/blog\/elasticsearch-1-4-2-released","author":{"name":"Clinton Gormley"},"date":"December 16, 2014","category":"Engineering","locales":"","content":" Today, we are happy to announce the bug fix release of\u00a0 , based on , and the bug fix release of . You can download them and read the full changes list here: For blog posts about past releases see: You can read about all of the changes that have been made in the and the , but we highlight some of the more important changes below: \n"}<br>{"index": {"_id": 1183}}<br>{"title":"Exciting Logstash Plugin Ecosystem Changes","seo_title":"","url":"\/blog\/plugin-ecosystem-changes","author":{"name":"Jordan Sissel"},"date":"December 12, 2014","category":"Engineering","locales":"","content":" With the release of Logstash 1.5.0 Beta 1 (), we are changing the way plugins are installed, maintained, and published. We have taken the feedback from our loverly users and community over time and our goal is to make it easier to use and develop plugins. This project is only the beginning \u2014 we will be iterating on this idea to provide a one-stop solution to discover and share a community of plugins! In this blog we would like to explain our reasons behind this decision, take you through the new workflow and future roadmap we have in mind. There\u2019s a plugin for that! Logstash has a rich collection of plugins (inputs, filters, outputs, and codecs) which are both developed by Elasticsearch and contributed to by the community. One of the core strengths of Logstash is the availability of these plugins and ease of adding new ones to extend behavior. Today, there are over 165 plugins in the ecosystem which are split across two projects: New Plugin Ecosystem Changes the plugins will now be separated out from Logstash core into their own self-contained packages using rubygems. We chose rubygems because of its powerful and standard way to package and distribute libraries with dependencies. Plus, we will be leveraging the platform for publishing and discovery. We have also added infrastructure to easily install, update, and remove plugins on top of Logstash. The project will slowly cease to exist \u2014 all plugins will have a single home. Reasons to move to the Plugin Ecosystem Having a large set of plugins exposes unique challenges in distribution and publishing. Some of the pain points which inspired us to make these change were: The Details: Source Code Location Logstash source code will continue to exist in its current GitHub but will not have any code or tests source related to plugins. Having this separation allows us to focus on core as well as to iterate quickly on individual plugins, which will improve the overall quality of Logstash project. The source code for all plugins will be located in a new GitHub organization and each plugin will exist as individual repositories under it. At first blush, this may seem hard to maintain, but it provides clear isolation for tests, issues and dependencies. Our aim is to automate testing, documentation, and gem publishing and provide additional tooling to ease this move. However, it is not necessary for developers to host their plugin source under this organization \u2014 it is only necessary to publish it to to make it available to our community. Workflow Below we describe the interaction\/workflow with the new plugin ecosystem from various perspectives: Logstash Users: Users will download the Logstash binary similar to previous releases. Logstash 1.5.0 will ship with the same set of plugins packaged with 1.4.2 to ease the migration to the new system. Additionally, users will be able to install and upgrade any Logstash plugin after the initial deployment. script will be used for all plugin lifecycle interaction Most of the plugins will have their gems uploaded to . For example, if the user has to install the Apache Kafka plugin - , using a file location: Documentation Even though the plugins are separated, documentation for all plugins will be in one central Logstash Plugin Developers: Plugin developers and authors will be able to publish plugins for the Logstash ecosystem. Plugins will be able to declare external dependencies on gems and\/or java libraries. More importantly, developers will be able to release improvements to plugins outside of the release cadence of Logstash. Rubygems technology was chosen for the packaging system, dependency management, and hosting facility. Developers familiar with publishing regular Ruby gems will be able to easily publish Logstash plugins. Elasticsearch provides and maintains the tooling to aid developers with these functions. Developing and testing locally JRuby is the only prerequisites for developing the plugin. Providing a patch to a plugin is like before. For example, to patch : Versioning Version information is maintained in the of the respective plugins. For example, for the Apache Kafka output, the gemspec is . Versioning should follow rules and is maintained by the developer of the plugin outside of the Logstash versioning system. When Logstash 1.5.0 is released, plugins with milestone 1 will have version 1.0.0: plugins with milestone 2 will have version 2.0.0. Publishing When the developer is happy with the changes and wish to publish the plugins, the version number is changed at . When all tests pass, Elasticsearch will manually publish the plugin to rubygems.org. If the tests fail, the gem is not published. Longer term we will be moving to automated publishing of the plugins. Since these changes are new, we would like to understand more about it and improve our testing infrastructure for plugins before we are able to provide automated publishing. Issues Issues should be opened against respective github repositories for each plugin. Logstash core repo will continue to be the home for issues that are pertaining to core pipeline and common functionality. Documentation Plugin documentation is generated from the source code itself, so each plugin\u2019s documentation is contained in its own repository. Elasticsearch will provide the infrastructure to generate and consolidate the documentation for all plugins in to a centralised location under . Migration All new pull requests and issues need to be opened against the respective plugins under the github organisation. Fear not, existing pull requests does not need to be migrated to by developers. Logstash team will be merging existing PR\u2019s targeted to Logstash core repo into their respective plugins repo by doing this: Issues currently open against Logstash repo will be moved to their respective plugins. Logstash team will be automating this process using the github.com API. So, rest assured, we will migrate existing issues against the individual plugins. Future Roadmap While it is a first step, these changes provides a solid foundation for us to make the ecosystem even better for our users and developers. Short term, we will be adding infrastructure for developers to provide automatic testing feedback on pull requests. We will continue to provide more tools to bootstrap and manage plugin repositories. Longer term, we would like to provide a community portal for discovering and publishing all Logstash plugins. This idea is similar to the works of Puppet Forge and AWS marketplace. We just released , which has support for the new ecosystem. Please try it out and let us know what you think about these changes. Your feedback (on or ) is valuable to us!! \n"}<br>{"index": {"_id": 1184}}<br>{"title":"Logstash 1.5.0.Beta1 Released","seo_title":"","url":"\/blog\/logstash-1-5-0-beta1-released","author":{"name":"Suyog Rao"},"date":"December 11, 2014","category":"Engineering","locales":"","content":" global wrapper \n"}<br>{"index": {"_id": 1185}}<br>{"title":"This Week in Elasticsearch - December 10, 2014","seo_title":"","url":"\/blog\/2014-12-10-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"December 10, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Elasticsearch Core Ever tried running multiple instances of Elasticsearch on a single host? explains how we do it. \u2014 Etsy Engineering (@codeascraft) Elasticsearch EcosystemHere's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. \/\/ <!--[CDATA[<br \/--> <span id=\"mce_marker\" data-mce-type=\"bookmark\"><\/span><span id=\"__caret\">_<\/span><br> \/\/ ]]&gt: \u00a0Slides & Videos at last week's Elasticsearch meetup in Chicago, presenting \"Extending your logs: Why not make your logs do the legwork?\"Greg DeKoenigsberg, VP of Community at Ansible, was also caught on video at last week's meetup in Chicago, walking the audience through the steps for how he set up Elasticsearch + Logstash with Ansible for his very own analytics purposes.Where to Find UsWe'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Director of Developer Relations, , know!FranceThe Elasticsearch France Meetup will return to Paris for Meetup #11 on December 17. This meetup always fills quickly, so to save your place.GermanyNext meetup at munich office will have talks about Elasticsearch & search quality at 15th Dec \u2014 Alexander Reelsen (@spinscale) And, for folks in or around Bonn on December 18, the Bonn ELK Meetup group will be holding their inaugural meetup. Register now to save your place.Spain15\/12\/14: On-the-fly ETL con EFK: , Flume y | \u2014 Adesis Netlife (@adesis) Additionally, our own \u00a0will be joining the Barcelona Meetup on January 8 to share his presentation titled, \"Make sense of your data with Elasticsearch.\" to save your place.United States Where to Find You If you're a regular reader of This Week in Elasticsearch, a.k.a TWIES, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup!Head on over to ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.)Packed room for the first meetup in Lyon! \u2014 Tanguy Leroux (@tlrx) Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head.TrainingsIf you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1186}}<br>{"title":"Nest and Elasticsearch.Net 1.3","seo_title":"","url":"\/blog\/nest-and-elasticsearch-net-1-3","author":{"name":"Greg Marzouka"},"date":"December 09, 2014","category":"Engineering","locales":"","content":" Last week, we released NEST and Elasticsearch.NET 1.3, while not one of our most action-packed releases, during its postmortem we realized there were quite a few important features and fixes that warranted a blog post! New Security Features: You may have heard that Elasticsearch is coming out with a new security product, . Shield offers a rich set of features for securing your Elasticsearch cluster, and we took the initiative to make sure NEST and Elasticsearch.NET will have full support for Shield when it\u2019s officially released. Prior to 1.3, basic authentication credentials could only be specified on the URI like so: var uri = new Uri(\"http:\/\/username:password@localhost:9200\"): var settings = new ConnectionSettings(uri): This isn\u2019t the best way to manage credentials in your application, and more importantly it doesn\u2019t allow you to specify different credentials per request. Now you can specify basic authentication credentials for all requests at the global level as follows: var uri = new Uri(\"http:\/\/localhost:9200\"): var settings = new ConnectionSettings(uri): .SetBasicAuthentication(\"user\", \"password\"): Or per request, overriding any credentials set at the global level: var response = client.Search<MyClass>(s => s .MatchAll() .RequestConfiguration(rc => rc .BasicAuthentication(\"anotheruser\", \"password\") ) ): The client is thread-safe, so you can use a single client, in which case, passing a per request configuration is the only way to pass state local to the request. Instantiating a client each time is also supported. In this case each client instance could hold a different object with their own set of basic authorization credentials. Do note that if you new a client each time (or your IoC does), they all should use the same instance. Now that an is a valid response from Elasticsearch, we had to make some modifications to our connection pooling retry logic in order to fail as quickly as possible on responses, and not retry the request on other nodes. New Property Name Mapping API: Prior to 1.3, expressions (e.g ) could only be controlled using the attribute, or the shotgun which happens too late in the pipeline to know which property on what type it actually is. Therefore, we introduced a third approach to override what a strongly typed expression resolves to: settings.MapPropertiesFor<MyClass>(props => props .Rename(p => p.Foo, \"bar\") ): This allows you to refer to the property using the expression in any of the API calls, but resolving the property name to before being sent to Elasticsearch. Additionally, before 1.3, the only way to exclude properties from being mapped was to use or Json.NET\u2019s attribute on the property. Now with this new API, you can also ignore properties in code: settings.MapPropertiesFor<MyClass>(props => props .Rename(p => p.Foo, \"bar\") .Ignore(p => p.Bar) ): Other New Features: We received an influx of pull requests from our community, so a special thank you to everyone who contributed to this release! Just some of the new features added in 1.3\u2026 See the for the complete list of changes. what\u2019s next? brings a ton of new APIs and aggregations. We plan on mapping all of them in our 1.4 release of NEST and Elasticsearch.NET. For a list of all the features that are currently planned, just filter by the on our GitHub issues page. This list is constantly growing, so please feel free to add to it, or let us know if we\u2019re missing anything. It\u2019s an exciting time to be a .NET developer! If you\u2019ve been keeping up with the latest news, then you know that .NET is now open source and Microsoft is cooking up some awesomeness with , an exciting alternative, leaner stack to develop .NET applications on. Starting with NEST 1.4 we will include a proper .NET 4.5 build that works on and up. We are also exploring adding support for the new cross platform core CLR () in , though support for this is not a blocker for a 1.4 release of NEST. That\u2019s all from the .NET corner at Elasticsearch. As always, please don\u2019t hesitate to submit your questions\/suggestions\/issues to either or . \n"}<br>{"index": {"_id": 1187}}<br>{"title":"Where in the World is Elasticsearch? #elksinthewild Holiday Special!","seo_title":"","url":"\/blog\/where-in-the-world-is-elasticsearch-elksinthewild-holiday-special","author":{"name":"Livia Froelicher"},"date":"December 08, 2014","category":"","locales":"","content":" You may remember our <#ElksInTheWild> summer competition that we did right before the summer break. We had so much fun seeing all these <#ElksInTheWild>, we thought we should do it again! Instructions are outlined below - and remember - the best picture wins! Here's what's going on in the Elasticsearch event land before the holidays. We hope to meet you at one of these places. Upcoming Meetups North America December 9: December 9: December 9: December 11: Europe December 9: December 10: December 15: December 15: December 17: December 18: Asia December 13: That's it for now and until we meet again in 2015. Stay tuned for a lot more to come in the new year. We'll be starting our world travels again and discovering new places, too! - The Elasticsearch Team P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag! \n"}<br>{"index": {"_id": 1188}}<br>{"title":"This Week in Elasticsearch - December 03, 2014","seo_title":"","url":"\/blog\/2014-12-03-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"December 03, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Pre-registration for is closing soon. Get your name {ON} the list before it's too late. See you in March! \u2014 elasticsearch (@elasticsearch) Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. We just released NEST 1.3.0 .net client to ! See whats new here: \u2014 Martijn Laarman (@Mpdreamz) How is enabling scientists worldwide to better share & collaborate on the next frontier of discoveries? \u2014 elasticsearch (@elasticsearch) Slides & Videos on Lucene 5 at our latest Washington, DC Elasticsearch Meetup Short and sweet: Demo of Weave to tie together Elasticsearch, Docker, and Apache Spark From the latest London Elasticsearch Meetup From this week's Women Who Code Austin sessions on Item Based Search with Elasticsearch (en fran\u00e7ais) Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Director of Developer Relations, , know! France Germany Next meetup at munich office will have talks about Elasticsearch & search quality at 15th Dec \u2014 Alexander Reelsen (@spinscale) And, for folks in or around Bonn on December 18, the Bonn ELK Meetup group will be holding their inaugural meetup. to save your place. The Netherlands Elasticsearch NL meetup schedule for Dec 9th: Sinterklaas\/X-Mas\/H\u00ad\u00adanukkah drinks RSVP on \u2014 Boaz Leskes (@bleskes) Spain No te pierdas On-the-fly ETL con EFK: , Flume y [15\/12\/2014] | Telef\u00f3nica Flagship Store \u2014 Adesis Netlife (@adesis) United Kingdom The London Elasticsearch Meetup will convene on December 10 at 6:30 PM. This one always fills up quickly, so to save your place. United States In NYC? will Intro you to the stack, using local car traffic data, at Dec 9th meetup \u2014 Leslie Hawthorn (@lhawthorn) PDX folks join & to learn about , 's SIEM platform & Shield on Dec 9th \u2014 Leslie Hawthorn (@lhawthorn) Where to Find You If you're a regular reader of This Week in Elasticsearch, a.k.a TWIES, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) \" speed is inverted indexing\" talk cc \u2014 Women Who Code ATX (@wwcodeatx) Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Training If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1189}}<br>{"title":"Where in the World Is Elasticsearch? - December 01, 2014","seo_title":"","url":"\/blog\/where-in-the-world-is-elasticsearch-2","author":{"name":"Livia Froelicher"},"date":"December 01, 2014","category":"","locales":"","content":" It's December and Christmas is getting closer. But there are still a few things happening in the world of Elasticsearch. Check them out! Here's just a sneak peek from last weeks where talked about the company culture at Elasticsearch. Fire side chat with at TLV about company culture \u2014 Boaz Leskes (@bleskes) Upcoming EventsEurope November 30-December 1: (Israel) - Join talking about TODAY 11:00 a.m. - 11:40 a.m. Upcoming MeetupsNorth America December 2: December 2: December 4: Europe December 2: December 3: December 4: That's it for this week. Stay tuned for a Christmas special next week! ...and just a few final words from from last weeks : Admin guide for by \u2014 Filip Zr\u016fst (@frzng) P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag! \n"}<br>{"index": {"_id": 1190}}<br>{"title":"Making Elasticsearch Groovy-er","seo_title":"","url":"\/blog\/making-elasticsearch-groovy-er","author":{"name":"Chris Earle"},"date":"November 26, 2014","category":"Engineering","locales":"","content":" The Groovy community has been asking for us to ensure it\u2019s an officially supported language once again, and we\u2019ve been listening. With the recent release of , we are also excited to announce the release of the official Elasticsearch Groovy client (1.4.1), which is fully compatible with Elasticsearch 1.4.1. Starting today, the Groovy client becomes an officially supported client hosted on . The old, long-defunct Groovy client has been completely rewritten for this release in order to guarantee 100% Java client compatiblity. Unlike before, any feature that exists in the Java client is now guaranteed to exist in the Groovy client. New Features The More You Know The new and improved Groovy client does away with the old, Groovy-friendly variants of Java client objects in favor of using . Groovy extension modules provide the excellent ability to add new methods to existing classes and the Groovy client takes full advantage of them. Thanks to the use of the extension modules, Java client examples are 100% compatible with the Groovy client, which means that any Groovy project can transition to using the Groovy client where when it is convenient without having to make hard decisions about features. Naturally, any new Groovy code can be written to take full advantage of the new client immediately. What does 100% compatibility mean? Having 100% compatibility means that you can will use the same code as the Java client, often with added Groovy-isms as opposed to custom-written Groovy equivalents (ye olde will be missed \u2026 but hopefully forgotten). From development of the Groovy client\u2019s perspective, this means that there is less code to write and test, and superior usability. And, from your perspective, it hopefully means less new code to learn and no worrying about missing any functionality as future versions are released. \/\/ No Groovy imports! import org.elasticsearch.action.search.SearchResponse import org.elasticsearch.client.Client import static org.elasticsearch.node.NodeBuilder.nodeBuilder \/\/ Create a client node using a mix of the Java NodeBuilder and Groovy extensions Client client = nodeBuilder().client(true).settings { cluster { name = \"my-cluster-name\" } arbitrary { setting = \"arbitraryValue\" } }.node().client \/\/ Perform a search on your cluster using a Closure! SearchResponse response = client.search { indices \"index1\", \"index2\" types \"type1\", \"type2\" source { query { match_all { } } } }.actionGet() Making Life Groovy-er As with earlier incarnations of the Groovy client, support for treating a Groovy as data \u2014 instead of as a block of code \u2014 is a core concept. This allows you to do things that are sometimes verbose when using the Java client by using a Groovy . In your Java code, you might see something akin to: import static org.elasticsearch.common.xcontent.XContentFactory.*: XContentBuilder builder = jsonBuilder() .startObject() .field(\"user\", \"kimchy\") .field(\"postDate\", new Date()) .field(\"message\", \"trying out Elasticsearch\") .endObject() String json = builder.string() However, if you start to use the Groovy client, then you could replace this with an equivalent : String json = { user = \"kimchy\" postDate = new Date() message = \"trying out Elasticsearch\" }.asJsonString() No code . Just Groovy magic! And thanks to this feature, the Groovy client makes full use of passing a into your Elasticsearch requests as well: import org.elasticsearch.action.ListenableActionFuture def username = \"kimchy\" ListenableActionFuture<IndexResponse> responseFuture = client.index { index \"my-index\" type \"my-type\" id \"my-id\" source { user = username postDate = new Date() message = \"Trying out Elasticsearch Groovy\" nested { nested_object { some_int = 123 some_double = 4.56 some_object_list = [{ key = \"Closures\" }, { key = \"Beats\" }, { key = \"Bears\" }] } favorites = Integer.MAX_VALUE } } } This enables very powerful flows for submitting requests to your Elasticsearch cluster(s) by allowing you to use a instead of a or to pass around request bodies because the full flexibility of each is expanded to be handled as data. It creates some of the easiest to read and reuse conversion code around (and no one\u2019s ever going to keep it down). Finding Most of the flexibility added by the Groovy client comes from extension methods applied to the class itself and the internal usages of it. Other than the convenient-for-debugging , you can easily convert your into a using (this kind of thing is done for you in the Groovy client\u2019s methods that accept a ): Map<String, Object> map = { user = \"kimchy\" postDate = new Date() nested { value = 1.23 } }.asMap() Feedback The release of the Groovy client was because of user comments and requests. If you have a future feature request or find a bug, please let us know by opening an or if you just want to leave us some good ol\u2019 fashion, 140-character feedback, find us on Twitter ()! \n"}<br>{"index": {"_id": 1191}}<br>{"title":"Elasticsearch 1.4.1 and 1.3.6 Released","seo_title":"","url":"\/blog\/elasticsearch-1-4-1-released","author":{"name":"Clinton Gormley"},"date":"November 26, 2014","category":"Engineering","locales":"","content":" Today, we are happy to announce the bug fix release of\u00a0, based on , and the bug fix release of . You can download them and read the full changes list here: For blog posts about past releases see: You can read about all of the changes that have been made in the and the , but we highlight some of the more important changes below: \n"}<br>{"index": {"_id": 1192}}<br>{"title":"This Week in Elasticsearch - November 26, 2014","seo_title":"","url":"\/blog\/2014-11-26-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"November 26, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Elasticsearch Core ICYMI: - our 1st user conference - is coming to SF March 9-11, 2015. Save your spot today. \u2014 elasticsearch (@elasticsearch) Elasticsearch EcosystemHere's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. How does manage, monitor, & innovate a video content website w\/500k visitors? See how the helps\u2026 \u2014 elasticsearch (@elasticsearch) Slides & VideosThe slides from my capacity planning talk @ the Elasticsearch Meetup in Tel Aviv are online on .Until the next time\u2026 \u2014 Boaz Leskes (@bleskes) Slides for my talk at about are out! Have fun :) \u2014 David Pilato (@dadoonet) Slides from our last Elasticsearch NL meetup are online. ING: , RIPE: \u2014 Boaz Leskes (@bleskes) Where to Find UsWe'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Director of Developer Relations, , know!Czech RepublicOur very own and will speak at the next Elasticsearch CZ Meetup, taking place in Prague tomorrow, November 27 from 7-10 PM. to save your place. France Germany:, Karlsruhe, Nov. 26-28: Patrick Peschlow on .Next tuesday I'll talk about performance (OS\/JVM\/Application) with Elasticsearch at the Software Performance Meetup \u2014 Alexander Reelsen (@spinscale) : And for folks in or around Bonn on December 18, the Bonn ELK Meetup group will be holding their inaugural meetup. to save your place.IndiaAttention Delhi! We have our 1st meetup coming up this week! 29 Nov, 2pm . Sign up now! \u2014 Livia Froelicher (@LivFroe) ItalyJoin at CodeMotion Milan, November 26-29. David will teach you all about .IsraelFresh from his performance at CodeMotion Milan, the intrepid will be reprising his staring role in at CodeMotion TelAviv on Monday, December 1.United Kingdom United States Don't miss the next Chicago meetup hosted here at Vodori on 12\/2 from 6-8pm \u2014 vodori, inc. (@vodori) Where to Find You If you're a regular reader of This Week in Elasticsearch, a.k.a TWIES, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup!Head on over to ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.)Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head.TrainingsIf you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1193}}<br>{"title":"White Paper: Testing Automation for Distributed Applications","seo_title":"","url":"\/blog\/white-paper-testing-automation-for-distributed-applications","author":{"name":"Leslie Hawthorn"},"date":"November 25, 2014","category":"Engineering","locales":"","content":" Over the last few weeks, published a series of blog posts about how we go about testing and quality assurance (QA) for Elasticsearch. From continuous integration to the various levels of testing to performing randomized test runs, the importance of testing and QA for Elasticsearch cannot be understated. In addition to these great articles, Isabel has also authored a for those who'd like to go even more in-depth. Get . Get testing. And enjoy! \n"}<br>{"index": {"_id": 1194}}<br>{"title":"Elasticsearch Upgrade Guide as Seen by the Client","seo_title":"","url":"\/blog\/found-elasticsearch-upgrade-guide","author":{"name":"Konrad Beiske"},"date":"November 26, 2014","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud.Upgrading a system is one thing. Usually it involves taking a backup, doing the upgrade and then verifying everything is OK. Upgrading a system that your software depends on can be quite a different experience. In particular when the task is long overdue. \n"}<br>{"index": {"_id": 1195}}<br>{"title":"Where in the World Is Elasticsearch? - November 24, 2014","seo_title":"","url":"\/blog\/where-in-the-world-is-elasticsearch","author":{"name":"Livia Froelicher"},"date":"November 24, 2014","category":"","locales":"","content":" After a great couple of days at in Barcelona where we gave away a limited edition of the first Elasticsearch book with and the authors - & - signatures, we are now ready for another week full of various Elasticsearch events! THE book signed by & the authors! RT this tweet & you are in for a win at BCN! \u2014 elasticsearch (@elasticsearch) Upcoming Events Europe November 26-28: (Germany) - will be there to show some shiny Kibana demos and Patrick Peschlow will give a talk on . November 28-29: (Italy) - will teach you all about . Friday, November 28, 2:00 p.m. Upcoming Meetups North America November 29: Europe November 24: November 24: November 27: Asia November 29: That's it for this week. Stay tuned for Elasticsearch happenings next week! It may calm down a bit during Christmas time and especially in the US we wish you a very Happy Thanksgiving! - The Elasticsearch Team P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag! \n"}<br>{"index": {"_id": 1196}}<br>{"title":"It\u2019s {ON}: Announcing Our First User Conference - Elastic{ON}15","seo_title":"","url":"\/blog\/its-on-announcing-our-first-user-conference-elasticon15","author":{"name":"Shay Banon"},"date":"November 20, 2014","category":"News","locales":"","content":" It's been a little over two years since we formed a company around Elasticsearch, and the engagement with our community, users, and customers has taken on a life of its own. There are now around the globe, hundreds of conferences featuring our products, and a growing list of events where our own developers engage audiences in the Elasticsearch story. It's clear we hit a nerve. Over and over, we kept hearing one question: \u201cWhen will Elasticsearch get a conference of its own?\" We listened, and I am happy to announce the first Elasticsearch conference, , is happening March 9 through 11, 2015 in San Francisco, California. The conference details are unfolding as we speak, but there are a few things we already have planned that I want to share with you. First, Elastic{ON} will be centered around and the ecosystem of products surrounding it, including Apache Lucene, , , the various , , , and . Part of what makes Elasticsearch tick is the close communication we have with our users. To that extent, we're doing a few things to make sure the conference is run the same way. What does this mean for you? It means that *all* the developers at our company (that's right, every single one of them) will be attending the conference \u2014 and they want to hear from you. Elastic{ON} will feature a dedicated track that gives you a unique opportunity to talk with our engineers about all the work they currently do and plan to do. Afterwards, we're coordinating an Elasticsearch dev all hands meeting where we'll discuss your feedback and apply it to future products and events. The second aspect of the conference is hearing you, the user, speak about how you use our platform. I am lucky enough to be able to travel the world and talk to users and customers frequently, and am continuously amazed by how our products are being put to use. We plan to create a platform for our users, customers, and contributors in the community to talk about their use cases and successes. Elastic{ON} will be a great way to meet and talk with other users in your space and share knowledge. Please, if you're interested, don't hesitate to at the conference. We will also have a hands-on track with our developers, who will go through some high-level overviews and technical deep dives of our various products. Or you can drop by our \"Agents of Elasticsearch\" station to ask any questions that are on your mind. Bottom line: Elastic{ON} is all about you! And obviously, we plan to have a lot of fun while we're together. I am super excited about the conference, and I hope you are as well. I would love to personally welcome each and every one of you to join us: it's going to be great. (And make sure to to save your spot \u2013 my events team keeps reminding me that registration will fill up fast!) \n"}<br>{"index": {"_id": 1197}}<br>{"title":"This Week in Elasticsearch - November 19, 2014","seo_title":"","url":"\/blog\/2014-11-1-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"November 19, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Thurs. Barcelona meetup: reg now for Q&A w\/ \u2014 Leslie Hawthorn (@lhawthorn) Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Congratulations to the Chocolatey Team on their successful Kickstarter! We're proud to have contributed. We are celebrating .NET going OSS by backing \u2014 Martijn Laarman (@Mpdreamz) Elastically Searching w00t! 1.2 terabytes of event data 1.7 billion event documents \u2014 David Pilato (@dadoonet) Slides & Videos Our very own , creator of Logstash, brings you an intro to ELK Christine Flood on Shenandoah and how the project uses Elasticsearch Our very own David Pilato on Elasticsearch and Drupal (en fran\u00e7ais) \u30a2\u30c3\u30d7\u3057\u307e\u3057\u305f\u3002 \"niconico\u306e\u691c\u7d22\u3092\u652f\u3048\u308bElasticsearch\" \u2014 shoito (@shoito) Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Director of Developer Relations, , know! Canada I'll be talking about , and at -- ELK != Plain 'Ol Syslog - More info: \u2014 Jason Kendall (@coolacid) Czech Republic Our very own and will speak at the next Elasticsearch CZ Meetup, taking place in Prague on November 27. to save your place. France Germany We have a number of upcoming events in Germany: India The first ever Elasticsearch Delhi meetup is coming up on November 29. to save your place and to hear about several real world Elasticsearch use cases. The organizers are looking for additional speakers, so don't hesitate to contact them to volunteer! Israel and will both take the stage at DevOps Days Tel Aviv, which takes place November 23-24. Shay will hold a fireside chat on Dev, Ops and Culture, and Boaz will lead a workshop on the ELK stack. Not heading to DevOps Days? No worries! We've got a meetup planned for November 23. You can to attend. Italy Join at CodeMotion Milan, November 26-29. David will teach you all about . Spain Heading to Strata Barcelona? Great, so are we! You can hear from Shay Banon - - and Costin Leau - - plus visit us on the show floor. We are going to have special gifts on hand too, so make sure to stop by to say hello. Even if you're not planning to attend Strata, we have other great talks on offer in Barcelona on November 20. You can for our Special Strata Meetup. And, just because we can't have enough awesome things happening in Barcelona in one week, you can also hear from at the NoSQL Matters Conference on November 22. Clinton will deep dive into ! Call Madrid home instead of Barca? Awesome, we've got you covered! David Pilato will teach you all about at Codemotion Madrid on Friday, November 21 at 12:15 PM. Not attending Codemotion Madrid? There's also a meetup scheduled for November 24, where you can hear all about your fellow users' experiences with Elasticsearch. to save your place. United Kingdom United States On tonight: join the Gainesville LUG to hear all about the . Doors open at 6 PM. Reg now: \u2014 Leslie Hawthorn (@lhawthorn) Don't miss the next Chicago meetup hosted here at Vodori on 12\/2 from 6-8pm \u2014 vodori, inc. (@vodori) Where to Find You If you're a regular reader of This Week in Elasticsearch, a.k.a TWIES, you're thinking of skipping this section. You may even be thinking to yourself, yes of course I will drop a note on Twitter when I am giving a talk on all things ELK. That's awesome, because we'd like to showcase every meetup, conference presentation and workshop on Elasticsearch, Logstash, and Kibana happening worldwide. And now, we've made it even easier for you to get support for your meetup! Head on over to ! (And we'll still totally send you swag if you're giving a talk on anything ELKy at a conference.) Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Training If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1198}}<br>{"title":"The People Behind the Projects: More than a Bug","seo_title":"","url":"\/blog\/people-behind-projects-more-than-a-bug","author":{"name":"Marty Messer"},"date":"November 17, 2014","category":"Engineering","locales":"","content":" \u2014 When I join a company, it's typically at the stage of growth where the vision is so focused, the work pressure is so intense, and the product release schedule is so tight that the welcome note from the dev team has always been one of relief: \u201cThank god, you're here!\" Developers typically don't like dealing with support or the operational issues of integration. They like product development. However, at Elasticsearch, the situation was different. The developers loved customer interaction, and enjoyed dealing with support, and I had to gently hug it away from them. Enterprise software is a complicated and multidisciplinary field. In the Customer Care department at Elasticsearch, we have teams of support-focused engineers working alongside the developers of the product, and, boy, will our developers do anything for a customer. The precedents for this value system have been role-modeled and emulated since the founding of this company. Being involved in Customer Care also makes developers more aware of the operational aspects of building the platform. This customer-centricity brings us closer, and this fact is apparent in our customer surveys. Our customer survey response rates are 30 percent, three times the industry standards. People want to tell us how they are feeling. And this is a testament not only to the effectiveness of our Customer Care process, but also to the excellence of our recruiting. It's about the people we are bringing in who make all the difference. Earlier this year, we started working with an EdTech company with a 100 million users. They use Elasticsearch to let their users search across more than 2 billion terms to find the most relevant learning material. They were having some operational performance issues, and so we started having a conversation with them. As we started peeling off the layers, we realized they were using an operating system that no other customer was using, and this selection was causing the operational performance issues (and this is with Elasticsearch, which has been downloaded over 10 million times!). When you start calling people's choice of operating systems into question, they can get prickly. Selecting an operating system is like a religious choice. It's like saying, \u201cYour baby's ugly.\" But we knew we needed to have a conversation, and so we laid out a list of scientific reasons for why the operating system was a reason for concern. But instead of a formal presentation that could have come across as condescending, we ended up having a simple conversation. And the tech lead at the company told me, \u201cYou know, we have never really liked this system, and we have sort of been looking for a reason to migrate. This is going to be it.\" So then we were able to offer a more optimal set of operating systems as options, and have a more consultative conversation about the next steps regarding the choice of architecture and analytics. At the end of that conversation, I felt good that I had succeeded in setting his expectations higher than what he had himself thought possible. We talked about building standalone clusters. We then went on to build a parallel infrastructure to AB test and to demonstrate the effectiveness of our recommended operating system. The conversation went beyond what our client team expected of us. For me to confidently set expectations higher than what the customer anticipated is so rare in the world of support. It's way more than just dealing with a bug here. The act of seeking support poses a burden to one's self-image. Complicated technical issues aren't always fun. People come to us because something isn't working. But our team practices a form of intellectual honesty, of being aware that we may know Elasticsearch best, but the customer team knows their business and their technical domain inside out. At the end, we share the same goal, and the goal is to have the best, the most stable Elasticsearch installation possible in every use case. Psychologist Daniel Kahneman argues in Thinking, Fast and Slow that people remember the end of the experience, not the experience itself. I think that's very relevant in the context of support. It really matters how we leave a customer feeling when we are done. \n"}<br>{"index": {"_id": 1199}}<br>{"title":"Elasticsearch on YARN and SSL Support in Elasticsearch Hadoop","seo_title":"","url":"\/blog\/elasticsearch-yarn-and-ssl","author":{"name":"Costin Leau"},"date":"November 17, 2014","category":"Engineering","locales":"","content":" I am happy to announce Elasticsearch for Apache Hadoop 2.1.Beta3 has just been . We are introducing two new features: SSL connectivity and enhanced HTTP authentication and dedicated support for running Elasticsearch on YARN. Elasticsearch on YARN With 2.1.Beta3, we introduce the (aka es-yarn) project for running an Elasticsearch cluster within a YARN environment. Similar to the plugin, es-yarn is distributed as part of the Elasticsearch for Apache Hadoop (aka es-hadoop) project, but is and has no dependencies outside YARN itself. With es-yarn, one can now provision, start and stop Elasticsearch directly on a YARN cluster. In YARN lingo, es-yarn bootstraps a client that deploys a dedicated in YARN which, on its behalf, creates one container for each Elasticsearch node required. For the user, es-yarn is a straight-forward CLI (Command-Line Interface) for deploying and managing the life cycle of the Elasticsearch cluster within YARN. To wit, simply and run: $ hadoop jar elasticsearch-yarn-2.1.Beta3.jar No command specified Usage: -download-es : Downloads Elasticsearch.zip -install : Installs\/Provisions Elasticsearch-YARN into HDFS -install-es : Installs\/Provisions Elasticsearch into HDFS -start : Starts provisioned Elasticsearch in YARN -status : Reports status of Elasticsearch in YARN -stop : Stops Elasticsearch in YARN -help : Prints this help Configuration options can be specified _after_ each command: see the documentation for more information. Each command should be self-explanatory. Typically one would: Download Elasticsearch You can do this yourself. However, out of the box, es-yarn can do this for you: $ hadoop jar elasticsearch-yarn-2.1.Beta3.jar -download-es Downloading Elasticsearch 1.4.0 Downloading ...........................................................................DONE Provision Elasticsearch and Elasticsearch on YARN in HDFS To start a YARN application, YARN needs to get access to the needed artifacts from HDFS. es-yarn can provision HDFS on your behalf: $ hadoop jar elasticsearch-yarn-2.1.Beta3.jar -install-es Uploaded \/opt\/es-yarn\/downloads\/elasticsearch-2.1.Beta3.zip to HDFS at hdfs:\/\/127.0.0.1:50463\/apps\/elasticsearch\/elasticsearch-2.1.Beta3.zip $ hadoop jar elasticsearch-yarn-2.1.Beta3.jar -install Uploaded opt\/es-yarn\/elasticsearch-yarn-2.1.Beta3.jar to HDFS at hdfs:\/\/127.0.0.1:50463\/apps\/elasticsearch\/elasticsearch-yarn-2.1.Beta3.jar Start Elasticsearch on YARN $ hadoop jar elasticsearch-yarn-2.1.Beta3.jar -start Launched a 1 node Elasticsearch-YARN cluster [application_1415921358606_0001@http:\/\/hadoop:8088\/proxy\/application_1415921358606_0001\/] at Fri Nov 14 21:11:39 EET 2014 and voila: Want to run multiple nodes? Just tell es-yarn so: $ hadoop jar elasticsearch-yarn-2.1.Beta3.jar -start containers=2 Launched a 2 node Elasticsearch-YARN cluster [application_1415921359403_0001@http:\/\/hadoop:8088\/proxy\/application_1415921359403_0001\/] at Fri Nov 14 21:24:53 EET 2014 Stop the cluster When you are done, shutdown the cluster like this: $ hadoop jar elasticsearch-yarn-2.1.Beta3.jar -stop Stopped Elasticsearch-YARN cluster with id application_1415921358606_0001 It\u2019s that simple! SSL and HTTP authentication es-hadoop uses REST over HTTP to communicate with Elastisearch. Release 2.1.Beta3 introduces official support for basic HTTP authentication allowing Hadoop jobs running against a restricted Elasticsearch cluster to identify themselves accordingly. While es-hadoop has supported authentication through its options, with 2.1.Beta3 it is graduated to an individual component and thus can be used within or outside the context of a proxy configuration. Further more, the new 2.1 Beta release introduces support for cryptographic connections between Elasticsearch and your Hadoop cluster. Thus data-sensitive environments can encrypt the data at transport level to prevent snooping and preserve data confidentiality. Note that while self-signed certificates are supported (though are disabled by default) for development, for production environments we recommend using a proper authority to create your certificates. Strata Barcelona If you happen to be in Barcelona next week and are interested in Elasticsearch, we'd love to talk to you! We are headed to Strata Barcelona and we\u2019ll be giving two presentations, plus you can always stop by our booth (P5). Yours truly is presenting on and Shay, the man himself, is on . Further more on Friday evening, you can get your copy by Clinton and Zack! Also, join us for the (please RSVP \u2013 seats are limited) on Thursday, Nov. 20th at CCIB. We look forward to your on Elasticsearch Hadoop 2.1.Beta3 \u2013 \u2013 you can find the binaries are available on the and the new features explained in the . As always, you can on GitHub. \n"}<br>{"index": {"_id": 1200}}<br>{"title":"Where in the World Is Elasticsearch? - November 17, 2014","seo_title":"","url":"\/blog\/world-elasticsearch-25","author":{"name":"Livia Froelicher"},"date":"November 17, 2014","category":"","locales":"","content":" Just a small highlight from last week before we start the deep dive into this week's happenings: Over 100 Elasticsearch fans came to the 10th edition of our meetup in Paris. It is just heart warming to have such a great crowd in one room. Thanks to for hosting tonights meetup in Paris witch . It was a truly great crowd! \u2014 Livia Froelicher (@LivFroe) This week we'll be visiting various cities in Canada, Germany, Hungary, Israel, Spain, The Netherlands, UK and the US. Hopefully we'll see you there! Upcoming Events North America November 18: , Broomfield (CO) - Stop by our booth for some swag, and check out talk about on Tuesday, November 18 from 5:15 p.m. - 5:30 p.m. November 22: , Toronto - will give a talk titled \u201cElasticsearch\/Logstash\/Kibana: Not plain ol syslog\" from 4:30 p.m.- 5:00 p.m. Europe November 17-21: (Hungary) - will be giving two talks : Contributing to Apache Projects in a Nutshell \u2013 November 17 at 2:40 p.m. : how to find out whether the search box you offer your users is helping \u2013 November 19 at 10:40 a.m. November 18-20: (Germany) - on . Thursday, November 20, 9:30 a.m. - 10:30 a.m. November 19-21: (Spain) - Hear from about , Friday, November 21 at 11:50 a.m. \u2013 and talking about , Thursday, November 20 at 5:45 p.m. Plus visit us on the show floor at booth Nr. P5. November 20: (Germany) - on . November 21-22: (Spain) - David Pilato will teach you all about , Friday, November 21 at 12:15 p.m. November 21: (UK) - will deep dive into the \"Ins and Outs of the ELK Stack\" at 3:10 p.m. November 22: (Spain) - will speak about at 11:45 a.m. November 23-24 - (Israel) - Shay Banon will hold a fireside chat on DevOps and Culture on Sunday, November 23 at 10:30 a.m. and will lead a workshop on the ELK stack on Sunday, November 23 at 3:30 p.m. Upcoming Meetups North America November 20: Europe November 17: November 20: That's it for this week. Stay tuned for Elasticsearch happenings next week - there's much to come! - The Elasticsearch Team P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag! \n"}<br>{"index": {"_id": 1201}}<br>{"title":"This Week in Elasticsearch - November 12, 2014","seo_title":"","url":"\/blog\/2014-11-12-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"November 12, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Working on Search at ... Our total searches in the cluster is > 14,000,000,000. Yes, that's BILLION. Holy crap. \u2014 David Haney (@haneycodes) Elasticsearch core NEST 1.2.3 now available . Compatibility issues with ES 1.4 have been addressed. \u2014 Greg Marzouka (@gregmarzouka) Elasticsearch EcosystemHere's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases.Introducing Raigad - An Elasticsearch Sidecar \u2014 NetflixOSS (@NetflixOSS) Our very own has written an article in NDC magazine about \u2014 Aleksander Stensby (@astensby) Slides & VideosPresented by at last week's \u00d8redev 2014 ConferencePresented by at last week's San Francisco Cloud Mafia MeetupPresented by at last week's JMahgreb 2014 ConferenceWhere to find UsWe'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Director of Developer Relations, , know!Headed to in DC? Join the team for a meetup tomorrow to hear from & others \u2014 elasticsearch (@elasticsearch) CanadaI'll be talking about , and at -- ELK != Plain 'Ol Syslog - More info: \u2014 Jason Kendall (@coolacid) Czech RepublicOur very own and will speak at the next Elasticsearch CZ Meetup, taking place in Prague on November 27. to save your place. Denmark will keynote the in Copenhagen. Stay tuned for more schedule details, but Simon will cover Randomized Testing during his presentation, a.k.a. \"evil tests.\" The conference takes place on November 14, 2014.France GermanyWe have a number of upcoming events in Germany: Hungary will be giving two talks at ApacheCon Europe: ApacheCon Europe is on November 17-21, 2014 in Budapest.Israel and will both take the stage at DevOps Days Tel Aviv, which takes place November 23-24. Shay will hold a fireside chat on Dev, Ops and Culture, and Boaz will lead a workshop on the ELK stack.Not heading to DevOps Days? No worries! We've got a meetup planned for November 23. You can to attend.ItalyJoin at CodeMotion Milan, November 26-29. David will teach you all about . Japan The NetherlandsNext Elasticsearch NL meetup is scheduled. Mark the date: November 17. Talks by ING and RIPE. See you there! RSVP: \u2014 Boaz Leskes (@bleskes) RomaniaNew meetup on *tonight*! Bucharest Big Data user group will talk Analytics using Hadoop & \u2014 Leslie Hawthorn (@lhawthorn) SpainHeading to Strata Barcelona? Great, so are we! You can hear from Shay Banon - - and Costin Leau - - plus visit us on the show floor. We are going to have special gifts on hand too, so make sure to stop by to say hello. Even if you're not planning to attend Strata, we have other great talks on offer in Barcelona on November 20. You can for our Special Strata Meetup.And, just because we can't have enough awesome things happening in Barcelona in one week, you can also hear from at the NoSQL Matters Conference on November 22. Clinton will deep dive into ! Call Madrid home instead of Barca? Awesome, we've got you covered!David Pilato will teach you all about at Codemotion Madrid on Friday, November 21 at 12:15 PM. Not attending Codemotion Madrid? There's also a meetup scheduled for November 24, where you can hear all about your fellow users' experiences with Elasticsearch. to save your place.United Kingdom United States Meetup November in Philadelphia: Building an educational content search application using \u2014 jamestyack (@jamestyack) PDX friends, will demo 4 at the November 13 meetup + what's new in the ELK stack! \u2014 Leslie Hawthorn (@lhawthorn) Where to Find YouOur Director of Developer Relations, Leslie Hawthorn, is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, .Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head.TrainingsIf you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1202}}<br>{"title":"Document Processing and Elasticsearch","seo_title":"","url":"\/blog\/found-document-processing","author":{"name":"Njal Karevoll"},"date":"November 12, 2014","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud.An OverviewRaw documents from the source database or server may need some extra processing before being indexed in Elasticsearch. In this article, we consider a few different options for this processing. \n"}<br>{"index": {"_id": 1203}}<br>{"title":"Kibana 4 Beta 2: Get It Now","seo_title":"","url":"\/blog\/kibana-4-beta-2-get-now","author":{"name":"Rashid Khan"},"date":"November 11, 2014","category":"Engineering","locales":"ja-jp","content":" Eeeeeeeee! It's here! Kibana 4 Beta 2 is ready to be poked, prodded, and otherwise fiddled with by you, your friends, and your exceptionally intelligent pets. We look forward to your feedback. If you just can't wait to get started, , otherwise read on for the good stuff. Along with dozens of small tweaks and fixes, here are some of the fun new things to look out for in this release of Kibana: Map Support Maps are back and they are more powerful than ever! The new tile map visualization makes use of Elasticsearch's awesomely powerful to display geographic data, such as visualizing relative response times: Visualization Options In Beta 1, bar charts were always stacked. In Kibana 4 Beta 2, we've added options that allow you to modify how visualizations display their data. For example, by grouping bars: Or displaying bars as percentages: Area Charts Beta 2 brings back area charts, both stacked and unstacked: Advanced Parameters We aim to support as many Elasticsearch features as possible, but sometimes we just haven't gotten to that one aggregation option you really need right now. For that option, we've introduced a JSON input which allows you to specify additional aggregation parameters to send with your request. For example, maybe you want to pass in a agg, or increase the in a cardinality agg. In this case, we pass a script as an advanced parameter, taking the log of the of the field and placing it on the X-axis: Data Tables Sometimes you want a flashy chart, and sometimes you just want the numbers. The data table visualization makes that desire a reality: Hey! Where Did My Dashboards Go? The internal Kibana index changed from to . We recommend you move your documents (e.g., dashboards, settings, visualizations) from the old index to the new one. However you can also simply set in kibana.yml. What Are We Working on Now? Check out our path to Kibana 4 GA on our . As always, we welcome feedback\/bugs\/fixes on \n"}<br>{"index": {"_id": 1204}}<br>{"title":"The People Behind the Projects: The Swiss Army Knife","seo_title":"","url":"\/blog\/people-behind-projects-swiss-army-knife","author":{"name":"Aaron Mildenstein"},"date":"November 10, 2014","category":"Engineering","locales":"","content":" \u2014 I encountered my first computer in elementary school in Provo, Utah. It was the early 1980s, and the future was in the school library. I learned a tiny bit of BASIC and loaded games from a cassette drive onto a Commodore PET computer. A few years later, it was the Commodore VIC-20. When I started the sixth grade, I transferred to a school funded by the World Institute for Computer Aided Training (WICAT) where various subjects were taught or were enhanced by software running on computer terminals connected to a mini-computer. It was there that I received my first programming lessons in UCSD Pascal. Though I did not yet know it, by then, the die was cast. It wasn\u2019t all by design, though. I wanted stuff and we weren\u2019t well-off. So I would go to thrift stores, find broken electronics, take them apart, and fix them. I fixed my first television at the age of twelve. The repairman had examined the TV and said, \u201cWell, X, Y, and Z have to be replaced.\u201d So I looked up the parts, went to an electronics store to buy them, replaced a couple of parts, soldered some new parts, turned on the television, and it came on. I learned to gain understanding and knowledge by taking things apart and, where possible, repairing and reassembling them. My dad taught me to do the same with cars. When we needed a car, he would go buy a car that was in disrepair and we would fix it so that we could have a car for less money. My own journey with computer science continued on to college, but I didn\u2019t complete a degree. I met the girl who became my wife, and we got married soon after. I started working and never ended up going back to school. After saving up some money, I quit my job and became immersed in Linux for three months. That\u2019s all I did\u2014all day, everyday. From there, I branched out to employment as a software tester and then moved to systems administration. That\u2019s when I started scripting and learning Perl and Python. A few years ago, I was working at Alcatel-Lucent where we were trying to create a centralized logging platform to better monitor the conditions of our servers and applications. We investigated Splunk, but the sticker shock was supreme, because we were generating an enormous volume of logs per day. We tried to make our own centralized logging system, and that was too painful, slow, and buggy. We gave up on that project, and our logging needs went unmet for a few more years. While vacationing in the summer of 2011, I heard mention of Logstash in a user-group email, and within weeks, I was testing Logstash and Elasticsearch at work. I loved how helpful everyone was in the IRC chat rooms. The company gave me the go-ahead to architect a four-node cluster of Elasticsearch, Logstash, and version one of Kibana, making me one of the first enterprise users of the ELK stack who worked on tracking problems with logs. During those days, I wrote a script called Logstash Index Cleaner to help delete old indexes. This script has evolved through many iterations and is now the Elasticsearch Curator project, for managing time-series indices. When Logstash was formally incorporated into Elasticsearch, I also joined the company. It\u2019s exhilarating to be in an environment where somebody who didn\u2019t graduate from college but who has the passion to learn this information can debate and contribute to the development of the product alongside team members with PhDs. The focus here is a desire for the technology to be furthered, a desire to make open source as a model succeed. Recently, I have been supporting one of the leading telecom companies in their development of a log management system that captures and summarizes over a terabyte of logs a day. They have over 45 nodes in production for a Security Event and Threat Analysis (SETA) reporting tool that tracks the security of all customer-facing devices. The tool ensures that the data that the company\u2019s customers share remain confidential. We are currently in the design phase, and therefore I was able to share my knowledge of cluster design, about making the cluster more robust, how to scale the system, what are the ideal number of master nodes, what is the appropriate distribution of shards, how to speed up the ingestion rate, how to best search for X using aggregations. It\u2019s helpful to talk about these design nuances because Elasticsearch isn\u2019t prescriptive. It does not try to limit what a person can do. There isn\u2019t just one way to do things. You can use it as just a plain search engine. You can aggregate data based on geographic location. You can analyze time-series data. It\u2019s like a Swiss army knife. Restaurant apps use it to search for restaurants \u201cnear me.\u201d Businesses use it to allow customers to search for a product, and that\u2019s Elasticsearch. You go to Loggly that\u2019s storing log data and conducting time-series analyses, and that\u2019s Elasticsearch. Because there are so many ways to configure and use the open Elasticsearch architecture, we are discovering that having a conversation in the early stages of a customer deployment allows for a smoother production lifecycle. \n"}<br>{"index": {"_id": 1205}}<br>{"title":"ELK + Cisco UCS turn massive data into massive insights","seo_title":"","url":"\/blog\/elk-cisco-ucs-turn-massive-data-massive-insights","author":{"name":""},"date":"November 10, 2014","category":"","locales":"","content":" We announced a partnership today - - that we\u2019re all really excited about at Elasticsearch. This is an important partnership to us because Cisco is a leader in data center infrastructure, and we are joining forces to bring businesses that leverage Cisco\u2019s Unified Computing System (UCS) Platform the ability to gain real-time search and analytics, and in turn, insights, out of their data with the Elasticsearch ELK stack. Elasticsearch is in the business of providing real-time insight into data - whether structured or unstructured, human- or machine-generated: we bring a search-based architecture to data analytics. By combining the ELK stack with Cisco UCS, organizations benefit by having a turnkey underlying infrastructure solution that provides them with real-time search and analytics for a variety of applications, from log analysis, to structured, semi-structured, or unstructured searches, as well as as a web-backend for custom applications that use search-based analytics as a core functionality. Together, Elasticsearch and Cisco provide access to a flexible and powerful infrastructure for scalable ELK deployments that increase business and IT agility, reduce total cost of ownership, and deliver exceptional ROI. We\u2019ve already been doing some major deployments with Cisco in the area of financial service, telecom, and retail industries. And, the Cisco Open Security Operations Center (OpenSOC) project uses Elasticsearch and UCS for data-driven security discoveries, providing a unified platform for ingesting, storing and analyzing security logs. Today, we are releasing our joint reference architecture to deploy optimized Elasticsearch and UCS deployments. The reference architecture allows one to identify the right UCS configuration based on use case (like log analytics), retention policies (how long you want to keep the data), etc. Stay tuned for further developments between Elasticsearch and Cisco, but in the meantime: \n"}<br>{"index": {"_id": 1206}}<br>{"title":"Where in the World Is Elasticsearch? - November 10, 2014","seo_title":"","url":"\/blog\/world-elasticsearch-24","author":{"name":"Livia Froelicher"},"date":"November 10, 2014","category":"","locales":"","content":" Last week we were at where talked about all the nice things you can do with your logs using the ELK stack and held the closing keynote where she made the audience laugh with her talk about \"The Human Element in Development\". great talk by on how easy it is to do powerful log queries using \u2014 Courtney Hemphill (@chemphill) Full room at the final keynote by ! Come and join us now at Hall 1! \u2014 Livia Froelicher (@LivFroe) This week we'll be visiting various cities in Belgium, Denmark, France, Germany, Japan, the UK and the US. Hopefully we'll see you there! Upcoming Events Europe November 10-12: - will be onsite with our partner codecentric to present some great Kibana 4 demos. November 10-14: - will host an . Monday, November 10 at 9:30 a.m. November 13: - Come say hi at our booth Number 15 and we'll show you all the great things you can do with the ELK stack. We'll also have a guest speaker, Dan Leong from Daily Mail, who will be talking about . 10:40 a.m. - 10:55 a.m. November 14: - will be giving a keynote on \"Randomized Testing - Maximise Probability for Reliable Software\". The time is still not online, but make sure to check the website the day before! November 14: - David Pilato will be presenting on \"Elasticsearch and Drupal\" at 2 p.m. Asia November 15: - will be presenting and talking about including some demos. Upcoming Meetups North America November 12: November 13: November 13: Europe November 13: That's it for this week. Stay tuned for Elasticsearch happenings next week - there's much to come! - The Elasticsearch Team P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag! \n"}<br>{"index": {"_id": 1207}}<br>{"title":"This Week in Elasticsearch - November 05, 2014","seo_title":"","url":"\/blog\/2014-11-05-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"November 05, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Elasticsearch core Elasticsearch EcosystemHere's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Slides & VideosWhere to find UsWe'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Director of Developer Relations, , know!Belgium will host a at Devoxx Belgium 2014. David's workshop kicks off on Monday, November 10th at 9:30 AM, and the conference runs from November 10-14 in Antwerp.CanadaI'll be talking about , and at -- ELK != Plain 'Ol Syslog - More info: \u2014 Jason Kendall (@coolacid) Denmark will keynote the in Copenhagen. Stay tuned for more schedule details, but Simon will cover Randomized Testing during his presentation, a.k.a. \"evil tests.\" The conference takes place on November 14, 2014.France GermanyFor folks in Berlin, we'll have a booth at the GOTO Berlin conference, plus two awesome talks from Elasticsearchers: Join us at the Kosmos Event Center on November 6th and 7th for !And, we have a few of other great events coming up in Germany: Hungary will be giving two talks at ApacheCon Europe: ApacheCon Europe is on November 17-21, 2014 in Budapest.IrelandOur CEO, , will be speaking at the Web Summit conference. You can hear from Steven on Friday, November 6th on . Web Summit is on in Dublin November 4-6th.Israel and will both take the stage at DevOps Days Tel Aviv, which takes place November 23-24th. Shay will hold a fireside chat on Dev, Ops and Culture, and Boaz will lead a workshop on the ELK stack.Not heading to DevOps Days? No worries! We've got a meetup planned for November 23rd. You can to attend.ItalyJoin at CodeMotion Milan, November 26-29th. David will teach you all about . Japan The NetherlandsNext Elasticsearch NL meetup is scheduled. Mark the date: 17\/\/11. Talks by ING and RIPE. See you there! RSVP: \u2014 Boaz Leskes (@bleskes) RomaniaNew meetup on *tonight*! Bucharest Big Data user group will talk Analytics using Hadoop & \u2014 Leslie Hawthorn (@lhawthorn) SpainHeading to Strata Barcelona? Great, so are we! You can hear from Shay Banon - - and Costin Leau - - plus visit us on the show floor. We are going to have special gifts on hand too, so make sure to stop by to say hello. Even if you're not planning to attend Strata, we have other great talks on offer in Barcelona on November 20th. You can for our Special Strata Meetup.And, just because we can't have enough awesome things happening in Barcelona in one week, you can also hear from at the NoSQL Matters Conference on November 22nd. Clinton will deep dive into ! Call Madrid home instead of Barca? Awesome, we've got you covered!David Pilato will teach you all about at Codemotion Madrid on Friday, November 21st at 12:15 PM. Not attending Codemotion Madrid? There's also a meetup scheduled for November 24th, where you can hear all about your fellow users' experiences with Elasticsearch. to save your place.SwedenHonza Kral will be speaking at the \u00d8redev conference in Malm\u00f6 on . The conference runs Nov. 4-7th, and Honza takes the stage on Nov. 6th at 5:40 PM. While Honza is visiting Sweden, we figured it would be a great time to host a meetup in Malm\u00f6. Please join us Friday, November 7th to hear from Honza on How to Make Sense of Your Big Data using Elasticsearch. to save your place.United KingdomThe Elasticsearch team will be at the conference in London on November 13th and we are honored to have the UK's own present how .United StatesDC friends, go see at Enterprise Search & Discovery conf tomorrow Lots of goodness on offer \u2014 Leslie Hawthorn (@lhawthorn) Meetup November in Philadelphia: Building an educational content search application using \u2014 jamestyack (@jamestyack) PDX friends, will demo 4 at the Nov. 13th meetup + what's new in the ELK stack! \u2014 Leslie Hawthorn (@lhawthorn) Where to Find YouOur Director of Developer Relations, Leslie Hawthorn, is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, .Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head.TrainingsIf you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1208}}<br>{"title":"Elasticsearch 1.4.0 And 1.3.5 Released","seo_title":"","url":"\/blog\/elasticsearch-1-4-0-released","author":{"name":"Clinton Gormley"},"date":"November 05, 2014","category":"Engineering","locales":"","content":" Today, we are happy to announce the release of\u00a0, based on , and of bug fix release . You can download them and read the full changes list here: For blog posts about past releases in the 1.3 branch, see: , , , , . As we said with the Beta1 release, the major theme of 1.4.0 is : making Elasticsearch more stable and reliable than ever before, with better memory management, improved discovery algorithms, and better detection of corrupted data. Some highlights from the Beta1 release include: Please read the for more details. You can read about all of the changes that have gone into 1.4.0 since Beta1 in the , but there are two major changes which deserve to be highlighted: \n"}<br>{"index": {"_id": 1209}}<br>{"title":"Shield: You Know, For Security","seo_title":"","url":"\/blog\/shield-know-security-coming-soon","author":{"name":"Shay Banon"},"date":"November 04, 2014","category":"Engineering","locales":"","content":" Since the early days of Elasticsearch, one could secure Elasticsearch using external systems. For example, since Elasticsearch APIs are exposed through REST over HTTP, users secure it using or firewalls. With the explosive adoption of Elasticsearch and the ELK stack, our customers and users started to ask us for a more integrated security solution with advanced features that are not implemented using external systems. After spending a lot of time with our customers, some of them with very demanding security requirements, we started to work on a security product within Elasticsearch, which we named Shield. (Any Marvel fans out there sensing a theme? :) ) Over the last few months, I have been traveling all over the world talking to customers and users at meetups, and every time I mentioned Shield, people got very excited. For this reason, we thought it made sense to publicly announce that we are working on a security product, explain what it is, and that we are expecting to release it by the end of the year. Shield, in the same spirit of , is built on top of Elasticsearch public extensions points, and is easily installed as a plugin to add security features to any existing Elasticsearch installation. It does not require a different distribution of Elasticsearch, and relies heavily on the open public APIs Elasticsearch already exposes. Shield itself provides four main feature themes: Role-Based Access Control Set granular cluster, index, and alias-level permissions for each user of your Elasticsearch cluster. For example, allow the marketing department to freely search and analyze social media data with read-only permissions, while preventing access to sensitive financial data. Authentication System Support Shield integrates with LDAP-based authentication systems as well as Active Directory, so your users don't need to remember yet another password. We also provide a native authentication system, for those who want to manage all access within Elasticsearch. Encrypted Communications Node-to-node encryption protects your data from intruders. With certificate-based SSL\/TLS encryption and secure client communications with HTTPS, Shield keeps data traveling over the wire protected. Audit Logging Ensure compliance and keep a pulse on security-related activity happening in your Elasticsearch deployment: record login failures and attempts to access unauthorized information. Recently, we successfully launched a beta with a select group of customers who are putting each aspect of Shield to the test. We are excited to take what we learn and fold that valuable knowledge back into the finished product for everyone to use. Finally, I am very happy to announce that Shield will be free for existing and future . Our customers already enjoy the relationship they built with our developers when it comes to supporting them through their development and production deployments, as well as the huge investment we make in developing the products themselves, and we are thrilled to provide them, at no additional cost, the option to use Shield. We think Shield will develop into a one-stop shop when it comes to securing the ELK stack, satisfying even the most demanding security requirements. We are very excited to make this available to our customers, and I hope you are as well. as the release date draws near.... \n"}<br>{"index": {"_id": 1210}}<br>{"title":"The People Behind the Projects: for the Commons","seo_title":"","url":"\/blog\/people-behind-projects-commons","author":{"name":"Andrew Selden"},"date":"November 03, 2014","category":"Engineering","locales":"","content":" -- I meandered some in the early years. I had no idea what I wanted to do in college, but my parents always told my brother and I that we needed to get a Liberal Arts education. They actively encouraged us from being practical. I dabbled in philosophy, history, and political science before settling on Russian Language and Literature as a major. After college, I started working at the Bioinformatics Lab at UPenn. This was in the early days of what came to be called \u201cbig data\". There was no Hadoop. No Elasticsearch. None of the great tools we have today to manage massive data sets. We had to cobble together large Linux clusters using Perl, NFS, and a smattering of other technologies. We'd get these large grants from the National Science Foundation to perform analytics on various genomes. Today you would just rent space in the cloud, but 12 years ago there was no cloud. It's so interesting to see how the state of the industry has evolved. A lot of the computational techniques we were struggling to build a decade ago are now mainstream in just about every tech startup. I simultaneously got my Masters in Computer Science taking courses part-time alongside work. After all, who wants to get out of school with student debt? After finishing graduate school, I moved to the Bay Area and ended up as a search engineer for a large media surveillance company. We crawled the web, pulling in content in over 30 different languages to analyze and create competitive intelligence for our clients. We were very successful and built a great product, but I always felt that the software tools were too hard to use. Then I discovered Elasticsearch. The technology probably wasn't even a year old when we introduced Elasticsearch into our company. But even in its earliest days it was so clearly superior to everything else. Clustering just worked. Search just worked. It was a breath of fresh air to have a tool I didn't have to fight to get working. It's been amazing to watch the evolution in how customers use Elasticsearch, from a purely search-oriented technology into a full-fledged analytics engine. Elasticsearch comes at the problem from the perspective of a search engine. Most big data products come at the problem from the perspective of putting files on disks, scanning them from start to end. That approach is very linear, whereas Elasticsearch wants to find that relevant needle in the haystack in milliseconds. Easy to get data in. Easy to get data out. For instance, you give the data to Hadoop. It will take that data and store it on disk. Later, if you want to analyze the data, it will allow you to launch a number of parallel processes, each of which scan a part of the file. They take apart and scan the file from start to finish. It's linear within chunks. You give it data and it puts the bits on disks. With Elasticsearch, the moment you give us data, we don't just take it and store it on disk. We do deep analysis on it. We construct data structures and put those on disk. The data structures are organized in such a way that you can do extremely fast lookups. If I want to search for the word \u201cDostoevsky\" in a set of billions of documents, I don't have to sit idly while the system scans everything for hours. I just have to lookup \u201cDostoevsky.\" It's one hop. The preprocessing was completed at the time of ingestion. Search engines and information retrieval algorithms are a well-understood problem,whereas parallel processing data analytics is still new arena -- and the ELK stack is ahead of the curve here. For example, say you're Walmart with thousands of retail outlets, and you're selling five types of electronics across thousands of stores. You want the min-maxes and averages per store for every electronic. You also want to find the most effective salespeople across your network. Those questions were traditionally answered over the course of weeks or months by using SQL on an Oracle analytics engine. With Elasticsearch's aggregations, we can assemble such business analytics within seconds because of the pre- and parallel processing. I joined Elasticsearch last year, and one of the first customers I supported was my former media surveillance company. I spent a day onsite there. From that point on, we've had calls every two weeks. We had a live dubugging call recently between five guys at the company and two of our engineers, Robert Muir and Mike McCandless. Robert and Mike are the top contributors to Lucene. They are search experts. Everyone learns so much in these conversations. In our support conversations, there have been technical wins, but really it's been also about human relationships.The conversation reminded me of this book that I've loved called For Common Things. It's a manifesto by Jedediah Purdy for civic responsibility and against this prevailing culture of cynical irony that seems to be ever-present. Civic responsibility at Elasticsearch is apparent when the team comes together to make a customer successful. \n"}<br>{"index": {"_id": 1211}}<br>{"title":"Where in the World Is Elasticsearch? - November 03, 2014","seo_title":"","url":"\/blog\/world-elasticsearch-23","author":{"name":"Livia Froelicher"},"date":"November 03, 2014","category":"","locales":"","content":" Last week we were at to demo some Kibana 4 dashboards and give out USB ELKs to attendees. At Ghent? Meet our booth crew w' & and learn all things ! \u2014 elasticsearch (@elasticsearch) has the cutest swag! Thank you :) \u2014 Krzysztof Wilczynski (@kwilczynski) This week we'll be visiting various cities in Denmark, Germany, Ireland, Morocco, Sweden and in the US. Hopefully we'll see you there! Upcoming Events North America November 5-7: - will be part of a panel discussion about on Thursday, November 6 from 10:45 a.m. - 11:45 a.m. Online registration is now closed but you can still register onsite by completing . Europe November 4-7: - Join in his session on . Thursday, November 6 from 5:40 p.m. - 6:20 p.m. November 5-7: - Check out talk about , Thursday, November 6 from 10:20 a.m. - 11:10 a.m. And don't forget to attend the closing keynote by awesome : , Friday, November 7 from 5:00 p.m. - 5:50 p.m. November 5: - Honza Kral will present \u201cAnalyzing and Searching Data using Elasticsearch\" and the Registration is free of charge, but you'll need to . Africa November 4-6: - Don't miss . Tuesday, November 4 from 10:00 a.m. - 12:00 p.m. Upcoming Meetups North America November 5: November 6: Europe November 5: November 6: November 7: That's it for this week, and stay tuned for Elasticsearch happenings next week. There's much to come! - The Elasticsearch Team P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag! \n"}<br>{"index": {"_id": 1212}}<br>{"title":"This Week in Elasticsearch - October 29, 2014","seo_title":"","url":"\/blog\/2014-10-29-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"October 29, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Elasticsearch Core Revealing the Uncommonly Common with Elasticsearch Webcast Oct 30 9am PT\/ 12pm ET \u2014 O'Reilly Strata (@strataconf) Elasticsearch EcosystemHere's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. . talking about Kibana 3, 4 & at Tempe meetup. All things ELK-y. \u2014 robyn bergeron (@robynbergeron) Slides & VideosThanks SO much all who saw the meetup on replication tonight! Slides here (see comments): \u2014 sunnygleason (@sunnygleason) And from the oldies but goodies files, you Kevin Kluge and Steve Mayzak's talk from OSCON 2014, where they show you how to monitor data from a drone using ELK. You'll also learn how to literally crash your demo, plus fun stuff for all fans of the Internet of Things. Check it out!Where to Find UsWe'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Director of Developer Relations, , know!Belgium will host a at Devoxx Belgium 2014. David's workshop kicks off on Monday, November 10th at 9:30 AM, and the conference runs from November 10-14th in Antwerp.CanadaI'll be talking about , and at -- ELK != Plain 'Ol Syslog - More info: \u2014 Jason Kendall (@coolacid) Denmark France GermanyFor folks in Berlin, we'll have a booth at the GOTO Berlin conference, plus two awesome talks from Elasticsearchers: Join us at the Kosmos Event Center on November 6th and 7th for !And, we have a few of other great events coming up in Germany: Hungary will be giving two talks at ApacheCon Europe: ApacheCon Europe is on November 17-21, 2014 in Budapest.IrelandOur CEO, , will be speaking at the Web Summit conference. You can hear from Steven on Friday, November 6th on . Web Summit is on in Dublin November 4-6th.ItalyTomorrow, October 30th, we'll be working with - the official Zimbra event in Italy (organized by Seacom) - to help show the ELK stack as a Zimbra log analyzer. You may also with to join us that evening at 5:30 PM for the second , including talks and networking.Japan The NetherlandsING on IT tour. Proud to host Meetup Events. Elastic Search next. Mon 17\/11 press center AMP Amsterdam \u2014 Rob van Elburg (@RAVanElburg) Poland will speak at PolyConf 2014 on Elasticsearch's language clients, Bridging the gap: . Honza takes the stage at 5:30 PM tomorrow night, October 30th, and the conference runs the 30th-31st in Poznan.SwedenHonza Kral will be speaking at the \u00d8redev conference in Malm\u00f6 on . The conference runs Nov. 4-7th, and Honza takes the stage on Nov. 6th at 5:40 PM. While Honza is visiting Sweden, we figured it would be a great time to host a meetup in Malm\u00f6. Please join us Friday, November 7th to hear from Honza on How to Make Sense of Your Big Data using Elasticsearch. to save your place, and, even better, if you're interested in sharing your story at the meetup! United KingdomThe Elasticsearch team will be at the conference in London on November 13th and we are honored to have the UK's own present how .United States Where to Find YouOur Director of Developer Relations, Leslie Hawthorn, is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, .Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head.TrainingsIf you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1213}}<br>{"title":"The People Behind the Projects: DNA","seo_title":"","url":"\/blog\/people-behind-projects-dna","author":{"name":"Suyog Rao"},"date":"October 27, 2014","category":"Engineering","locales":"","content":" I had been exposed to the world of engineering at a very early age. My father was a mechanical engineer and always had a methodical approach to solving issues. If a toilet at home wasn\u2019t working, he would try to evaluate the root cause of the problem rather than searching for a quick fix. He always had a calm and logical response: \u201cThis doesn\u2019t work, let\u2019s figure out why.\u201d As a twelve-year-old, I found this practical approach pretty impressive. At university, I worked on a bioinformatics research project where we tried to figure out the causal relationship between certain patterns of DNA and diseases in humans. If we clustered those DNA patterns together, we could identify which diseases each pattern correlated with. It was in this lab that my appreciation for computer science and its application to solving problems in the real world began. I was first introduced to the ELK stack when I was at Loggly. When I started exploring the different versions of the Elasticsearch code, I realized that it hasn\u2019t changed a lot since 2010 when Shay Banon wrote the first version. Unlike other software systems, there hasn\u2019t been a drastic architectural change and things aren\u2019t constantly being written and rewritten. Elasticsearch had this foresight: \u201cData will grow exponentially. Machines can be rented. Therefore, let us build a search mechanism that can scale.\u201d The elastic\u2014that is, the scale\u2014part of Elasticsearch is incredible. Many people are able to create search algorithms, but the elasticity of the company gives it a major competitive advantage. If such foresight is part of the DNA of the company, I wanted to be there. So here I am. One of my favorite features of Elasticsearch is called \u201callocation awareness.\u201d We created this when we realized that \u201cnot all data are created equal.\u201d It allows you to assign a higher-end machine to certain indices that need more computing power, and older, less frequented data to a low-end machine. We still have access to the old data, but it\u2019s of fading relevance. One of my recent memories of helping a customer was from a mobile analytics company that uses Elasticsearch to gather data about in-app experience, user session information, and API usage. They were migrating from using a NoSQL product to Elasticsearch for providing these real-time analytics and had gone live the previous week. When I received the support call, one of the nodes in their cluster was experiencing high CPU load and the memory usage was very high. Using Marvel, we narrowed the problem to a special use case of theirs where they were doing frequent updates to documents using scripts, which was adding high load on the primary shards. Once I realized this was the root cause of the problem, I wrote a script to balance the primary shards equally across their four machines. So, instead of allowing 80 percent of one CPU to get loaded, we could have CPUs on other machines sharing the workload. The new script allowed us to distribute jobs evenly across all the machines. And now that their urgent request has been addressed, we are taking corrective measures to make sure that this code is scripted in for other similar use cases. I love the quick feedback loop from customers to products, which benefits everyone. It\u2019s all very gratifying. \n"}<br>{"index": {"_id": 1214}}<br>{"title":"Where in the World Is Elasticsearch? - October 27, 2014","seo_title":"","url":"\/blog\/world-elasticsearch-22","author":{"name":"Livia Froelicher"},"date":"October 27, 2014","category":"","locales":"","content":" While our ELKs are starting to conquer the world, we are doing the same with conferences and meetups. :) This week you can find us in Florence (IT), Ghent (BE), Los Angeles (US), Poznan (PL) and San Francisco (US). Come join us for a session to learn even more about Elasticsearch. I've a new friend watching my logs! Tx ! \/Cc \u2014 Xavier Mertens (@xme) Upcoming Events Europe October 27-28: . Stop by our booth to see live demos, talk to our Solutions Architect, and learn about all things Elasticsearch! October 30-31: . Join for his session on . Thursday, October 30 5:30 p.m. - 6:00 p.m. (CET) October 30: . Our partner Seacom will be talking about Elasticsearch, 11:30 a.m. - 12:30 p.m. (CET). Upcoming Meetups North America October 29: October 30: Europe October 28: October 30: That's it for this week, and stay tuned for Elasticsearch happenings next week. There's much to come! - The Elasticsearch Team P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag! \n"}<br>{"index": {"_id": 1215}}<br>{"title":"This Week in Elasticsearch - October 22, 2014","seo_title":"","url":"\/blog\/2014-10-22-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"October 22, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. All new to Elasticsearch? Dive right in with Dr. Myagmar's overview. Elasticsearch core \": Interactive analysis of 14 years of crime data using , , . \" \u2014 Will Button (@wfbutton) Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. I'll be a hosting an Oct 30th webcast featuring : Anomaly Detection with \u2014 Ben Lorica (@bigdata) Slides & Videos ElasticSearch\u5165\u9580 [embedded in ] \u2014 ymizushi (@ymizushi) Slides for my talk at are available at :) \u2014 David Pilato (@dadoonet) Yann Cluchey, the stalwart organizer of the Elasticsearch London Meetup, deep dives on GfK's architecture and their ELK stack use case Need a quick review of our latest webinar? Look no further! \n"}<br>{"index": {"_id": 1216}}<br>{"title":"Use ELK to Visualise Security Data: IPTables and KippoSSH Honeypot","seo_title":"","url":"\/blog\/use-elk-display-security-datasources-iptables-kippo-honeypot","author":{"name":"Antonio Bonuccelli"},"date":"October 21, 2014","category":"Engineering","locales":"","content":" Among the countless possible use cases where ELK can help save the day, displaying security-relevant data is certainly a very interesting one.\u00a0In this blog post, using a virtual machine sitting on the cloud, we're going to show how to quickly set up a clustered instance of Elasticsearch to visualise firewall and honeypot datasources, namely IPtables and KippoSSH, focusing on the ELK-relevant configuration bits. KippoSSH is a medium interaction honeypot capable of recording plenty of information about the attacker, including interactive TTY sessions recordings: for the purpose of this blog post, we'll leave that latter piece of info aside, and focus on making sense of some brute force data. Starting from the live raw data, we have logs containing: These look like: #iptables elk@debianVM:~$ tail -3 \/var\/log\/kern.log Sep 24 13:52:06 debianVM kernel: iptables denied: IN=eth0 OUT= MAC=f2:3c:91:73:6c:71:84:78:ac:0d:8f:41:08:00 SRC=184.95.32.162 DST=85.159.211.137 LEN=48 TOS=0x00 PREC=0x00 TTL=110 ID=6886 PROTO=TCP SPT=37377 DPT=3306 Sep 24 13:52:44 debianVM kernel: iptables denied: IN=eth0 OUT= MAC=f2:3c:91:73:6c:71:84:78:ac:0d:8f:41:08:00 SRC=122.143.247.8 DST=85.159.211.137 LEN=40 TOS=0x00 PREC=0x00 TTL=107 ID=54661 PROTO=TCP SPT=6000 DPT=1433 Sep 24 13:55:22 debianVM kernel: iptables denied: IN=eth0 OUT= MAC=f2:3c:91:73:6c:71:84:78:ac:0d:8f:41:08:00 SRC=50.63.43.162 DST=85.159.211.137 LEN=44 TOS=0x00 PREC=0x00 TTL=57 ID=55765 PROTO=TCP SPT=80 DPT=5568 #kippo SSH elk@debianVM:~$ egrep 'New connection' -A10 \/opt\/kippo\/kippo-master\/log\/kippo.log | tail -11 2014-09-24 15:00:51+0100 [kippo.core.honeypot.HoneyPotSSHFactory] New connection: 221.146.74.146:49609 (85.159.211.137:2222) [session: 660] 2014-09-24 15:00:51+0100 [HoneyPotTransport,660,221.146.74.146] Remote SSH version: SSH-2.0-libssh2_1.4.1 2014-09-24 15:00:51+0100 [HoneyPotTransport,660,221.146.74.146] kex alg, key alg: diffie-hellman-group1-sha1 ssh-rsa 2014-09-24 15:00:51+0100 [HoneyPotTransport,660,221.146.74.146] outgoing: aes128-ctr hmac-sha1 none 2014-09-24 15:00:51+0100 [HoneyPotTransport,660,221.146.74.146] incoming: aes128-ctr hmac-sha1 none 2014-09-24 15:00:52+0100 [HoneyPotTransport,660,221.146.74.146] NEW KEYS 2014-09-24 15:00:52+0100 [HoneyPotTransport,660,221.146.74.146] starting service ssh-userauth 2014-09-24 15:00:53+0100 [SSHService ssh-userauth on HoneyPotTransport,660,221.146.74.146] root trying auth password 2014-09-24 15:00:53+0100 [SSHService ssh-userauth on HoneyPotTransport,660,221.146.74.146] login attempt [root\/123456] failed 2014-09-24 15:00:54+0100 [-] root failed auth password 2014-09-24 15:00:54+0100 [-] unauthorized login: Lots of interesting information that can be extracted from the above data. Event collection and processing: Logstash Logstash is an awesome piece of software and the first layer of the ELK stack, where the journey of an event begins. Starting from the raw data, we want to be able to: So we want to extract fields of interest like source IP, destination port, target usernames and passwords to name the obvious ones. For sake of brevity, we will go specifically after only two log entries here, one from IPTables: Sep 24 15:42:03 debianVM kernel: iptables denied: IN=eth0 OUT= MAC=f2:3c:91:73:6c:71:84:78:ac:0d:8f:41:08:00 SRC=184.95.32.162 DST=85.159.211.137 LEN=48 TOS=0x00 PREC=0x00 TTL=110 ID=6886 PROTO=TCP SPT=37377 DPT=3306 and one from KippoSSH: 2014-09-24 15:00:53+0100 [SSHService ssh-userauth on HoneyPotTransport,660,221.146.74.146] login attempt [root\/123456] failed We'll need to tell Logstash where the logs are located and what to do with them, below is our logstash config file (). Notice the three different sections : #input section, what data do we want to collect input { file { type => \"linux-syslog\" path => \"\/var\/log\/kern.log\" } file { type => \"honey-kippo\" path => \"\/opt\/kippo\/kippo-master\/log\/kippo.log\" } } #filter section, what to do with the data, process it , enrich it... filter { if [type] == \"linux-syslog\" { grok { #for linux-syslog type events use Grok definition below #to match the messages and extract fields of interest match => [ \"message\", \"%{IPTABLES_DENIED}\"] } date { #use the field timestamp to match event time and #populate @timestamp field (used by Elasticsearch) match => [ \"timestamp\", \"MMM dd HH:mm:ss\"] timezone => \"Europe\/London\" } } else if [type] == \"honey-kippo\" { grok { #like above, but using three separate #Grok definitions (see Grok definitions later) match => [ \"message\", \"%{KIPPO_TIMESTAMP}\\+\\d+\\s%{KIPPO_BODY_SSHSERVICE}\\s%{KIPPO_MSG_LOGIN}\" ] } date { match => [ \"timestamp\", \"YYYY-MM-dd HH:mm:ss\" ] timezone => \"Europe\/London\" } } } geoip { #enrich both event types with geo fields based on the #src_ip field for analytics and drawing pretty maps source => \"src_ip\" } } #output section, where do we send the data output { #events failing to match Grok definitions will be #automatically tagged with '_grokparsefailure' #in this case we want to send only events where #field extraction will be happening correctly if \"_grokparsefailure\" not in [tags] { if [type] == \"linux-syslog\" { elasticsearch { embedded => false cluster => \"joinus\" host => \"127.0.0.1\" bind_host => \"127.0.0.1\" index => \"logstash-os\" index_type => \"linux-syslog\" } } else if [type] == \"honey-kippo\" { elasticsearch { embedded => false cluster => \"joinus\" host => \"127.0.0.1\" bind_host => \"127.0.0.1\" index => \"logstash-honey\" index_type => \"kippo\" } } } else { #let's print to logstash standard output #events not captured by our Grok definitions stdout { codec => rubydebug } } } Notice in the above output section that the index names both start with logstash-*. This is in order to leverage logstash-* , which will allow us to make use of both an 'analyzed' and '' versions of the fields, in order to be able to correctly draw our dashboards.See more on this aspect Now let's take a closer look at the Grok definitions we will be using. We can get our raw data recognised and parsed by adding the 4 lines below to a pattern file in $LOGSTASH_HOME\/patterns: IPTABLES_DENIED %{SYSLOGTIMESTAMP:timestamp} %{HOSTNAME:_host} kernel: iptables denied: IN=(?<in>eth0) OUT= MAC=(?<mac_addr>\\\\S+) SRC=%{IP:src_ip} DST=%{IP:dst_ip} LEN=\\\\d+ TOS=0x\\\\d+ PREC=0x\\\\d+ TTL=\\\\d+ ID=\\\\d+(?:\\\\sDF)? PROTO=(?<proto>\\\\S+) SPT=(?<src_port>\\\\d+) DPT=(?<dst_port>\\\\d+)(?:\\\\sWINDOW=\\\\d+)?(?:\\\\sRES=0x\\\\d+)?(?:\\\\s[ACKSYNFIRT]{3})+(?:\\\\sURGP=\\\\d)? KIPPO_TIMESTAMP (?<timestamp>\\\\d{4}-\\\\d{2}-\\\\d{2} \\\\d{2}:\\\\d{2}:\\\\d{2}) KIPPO_BODY_SSHSERVICE \\\\[SSHService ssh-userauth on HoneyPotTransport,\\\\d+,%{IP:src_ip>}\\\\] KIPPO_MSG_LOGIN login\\\\sattempt\\\\s\\\\[(?<src_user>\\\\S+)\/(?<src_pwd>\\\\S+)\\\\]\\\\s(?<outcome>succeeded|failed) Here we are just telling Grok to be aware of these new definitions that we have referenced in Logstash main config file earlier.\u00a0Grok will match the event types we have configured and use the regular expression above to extract our fields of interest. You can see that some definitions are based on already existing patterns - for e.g. IPTABLES_DENIED reuses Grok patterns SYSLOGTIMESTAMP, HOSTNAME and IP. This is one of the key strengths of Grok, aimed at making a better use of your time, other than writing and re-writing regex after regex. Using good online regex tools can help speed up on this task. is a great tool you can rely on to construct and debug Grok patterns. Some other resources worth mentioning for pure regex testing are , . See Grok Debugger in action below: Now we're good to index as much data as we like (and our hardware can handle), so we will move to the next layer on the ELK stack. Store the data and make it searchable: Elasticsearch Setting up an Elasticsearch cluster is straightforward. In this demo we setup 2 elasticsearch nodes on a single host. You could also do this in production, if you have enough capacity on a single machine in some specific scenarios. See for more details. We\u00a0could leave default settings and get started by: and these instance would just talk to each other like good old friends using multicast zen discovery and form a cluster with no configuration needed! As we'd like to have a bit more control over the cluster behaviour we proceed to amend some defaults for each of the 2 nodes.For example we set node 1 to use: #Set a name for each node, for readability and manageability node.name: \"node-1\" #Disable multicast discovery, you never know what happens in a network you don't own discovery.zen.ping.multicast.enabled: false #Configure an initial list of master nodes in the cluster, we know who we are discovery.zen.ping.unicast.hosts: [\"localhost:9301\"] #Set a cluster name, elasticsearch is a nice name though, we like here to set our own cluster.name: joinus And that is it! Cluster 'joinus' is ready to accept data and make it searchable, resilient and all the magic Elasticsearch will do for us. Let's just say \"hi,how are you?\" to our cluster elk@debianVM:~$ curl -XGET 'localhost:9200\/_cluster\/health?pretty' { \"cluster_name\" : \"joinus\", \"status\" : \"green\", \"timed_out\" : false, \"number_of_nodes\" : 2, \"number_of_data_nodes\" : 2, \"active_primary_shards\" : 100, \"active_shards\" : 200, \"relocating_shards\" : 0, \"initializing_shards\" : 0, \"unassigned_shards\" : 0 } You know, looks good! We can now create two indexes in our Elasticsearch cluster by issuing: $ curl -XPUT 'localhost:9200\/logstash-os?pretty' and $ curl -XPUT 'localhost:9200\/logstash-honey?pretty' For each of these requests, we will receive the below answer, saying index creation was successful: { \"acknowledged\" : true } We could also tell Elasticsearch explicitly how to interpret our fields (is this an integer or a date or a string), but for this simple demo we're happy to let Elasticsearch automatically determine the field types. Open my eyes, show me what you've got: Kibana While we impatiently await to go GA let's use Kibana 3 to plot some data. We have now left this running for a while to allow the bad guys to feed us with some events and make our dashboards nice and pretty. Once Kibana is we are greeted with If we go and have a look at the sample dashboard, we see Notice our document types are showing up in 'Document Types' panel. Contextually on the left handside we also have a list of available searchable field: Now that we have validated the data looks good, we can go ahead and start building our first dashboard from scratch! Let's go one step back, and choose option 3, 'Blank Dashboard', and let's set a title for our new dashboard And point it towards the index 'logstash-os' where we are storing IPTables events (by default '_all' indexes are set to be queried) Then let's add a row to our empty 'Denied Connections' dashboard. Finally let's add our first panel and choose panel type 'Terms' to show some nice aggregations Notice that as you type your first char in Field form, Kibana will show you all the possible field matching the string as you type it. We have also here available fields named with extension .raw , this is because we are leveraging logstash index mapping template for having 'not_analyzed' fields. We choose now 'src_ip' for this panel and let's set up some more options, we want to see the top 20 IPs, sorted by count, using bars as the visualization format. Just hit 'Save' Et voil\u00e0\u00a0! You know, Kibana rocks! Reiterate the above and have fun! We have now plenty of data to leverage, manipulate and visualise from many different angles. We can ask all the questions we want, just add a few queries to slice your data as you please, each panel can display all or a selection of the queries. Then we can plot beautiful charts giving us lots of insight on the bad guys trying to access our host: Likewise, for our KippoSSH honeypot data You can click on any dashboard, drilldown and start your investigations: just ask the questions, ELK will give you the answers - easy peasy!\" \n"}<br>{"index": {"_id": 1217}}<br>{"title":"Where in the World Is Elasticsearch? - October 20, 2014","seo_title":"","url":"\/blog\/world-elasticsearch-21","author":{"name":"Livia Froelicher"},"date":"October 20, 2014","category":"","locales":"","content":" This week you'll find us in Beijing, Geneva, Michigan, Milan, Minneapolis, Paris, Phoenix, Raleigh and Seattle. Before we tell you all about this week's events, check out this Kibana dashboard from last week's Leeds DevOps Meetup - you can analyze everything you want, even \u201cThe Walking Dead\" tweets. :) The Walking Dead tweet analysis for tonight, I think Carol was a popular term... \u2014 Steve Elliott (@Tegud) We also had a great time this week in New York at , educating attendees how they can provide real-time insight into their Hadoop data. The team is ready for Day 2 at . Come see us @ Booth P1 & get your on \u2014 elasticsearch (@elasticsearch) Upcoming Events North America October 22-23: - don't miss talking about Wednesday, October 22 at 2:15 p.m. (ET) Europe October 20: IBM's event, - our partner Seacom will be educating folks about Elasticsearch on IBM Power8 systems. Event starts at 9:30 a.m. (CET). To learn more and sign up, click . October 23-24: . will give a . Thursday 23, 9:30 a.m. - 1:30 p.m. (CET) October 23-24: . Hear David Pilato talk about . Friday 24, 2:45 p.m. - 3:30 p.m. (CET) Upcoming Meetups North America October 21: October 22: October 23: October 23: Asia October 25: That's it for this week, and stay tuned for Elasticsearch happenings next week. There's much to come! - The Elasticsearch Team P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag! \n"}<br>{"index": {"_id": 1218}}<br>{"title":"Elasticsearch Testing and QA: Increasing Coverage by Randomizing Test Runs","seo_title":"","url":"\/blog\/elasticsearch-testing-qa-increasing-coverage-randomizing-test-runs","author":{"name":"Isabel Drost-Fromm"},"date":"October 17, 2014","category":"Engineering","locales":"","content":" When writing tests, developers tend to have a certain picture of how the code is supposed to work in their mind. Based on that picture they craft tests, ideally checking not only the but also boundary conditions and error cases. Often, though, our perception of what the code should be doing is not in line with what is actually going on. Here's one famous example code snippet that shows unexpected behavior: In Java, there is no integer value defined that would be large enough to represent the absolute value of Integer.MIN_VALUE: as a result, the . Apart from such \"surprising\" behavior, developer inexperience with the problem domain can lead to overlooking otherwise obvious test cases. For example, engineers inexperienced with geographic coordinates might overlook double checking whether their code works at the North\/South pole or at the date line leading to problems in production systems. One approach to find issues in programs used by the security industry is to feed the program under test with all sorts of expected and in particular unexpected or even invalid random input. This particular technique is known as or fuzzing. The term was initially coined by Richard Hamlet in 1994 as one type of black box testing. In the recent past, though, it's become increasingly popular to use the same concept for white box testing by replacing hard coded test values with some automated way of generating valid input data: When using pseudo-random input - based on pre-defined constraints - checking the test result for correctness can be done in multiple ways: Several years ago the Lucene community added support for to their unit test suite. In contrast to other approaches, the idea here is to not only use random input into the program under test, but also create randomized runtime environments. When initializing each test run with a new set of randomly chosen input parameters, it also makes sense to re-run one particular test multiple times, each time with a new set of input parameters. When running tests on a developer's workstation, the number of re-runs should be limited to decrease testing time: Overly long running test suites often aren't executed by the developers after making changes. When running on a continuous integration server, though, the number of iterations can easily be increased to 50 or 100 to cover more ground, especially if the test itself is cheap in terms of runtime. A simple randomization example that runs 100 iterations and is based on a list of length 10 to 100, filled with random short numbers would look like this: 01 @Test 02 @Repeat (iterations = 100) 03 public void testSorting { 04 int length = randomIntBetween(10, 100): 05 short[] list = new short[length]: 06 for (int i = 0: i < length: i++) { 07 list[i] = randomShort(): 08 } 09 short[] result = Arrays.sort(list): 10 assertTrue(isSorted(result)): 11 } Line 02 defines the number of iterations to run. Each run is initialized with a different test seed leading to different values being generated in the test. On failure, this test seed is provided to the user to allow for reproducing (and fixing) what went wrong deterministically. Line 04 defines the length of our array to be a random value between a maximum and minimum boundary. The max and min values can be omitted to generate just any integer value. Line 07 uses this notation to generate short values. This example only shows a very limited - but already powerful - subset of the functionality provided by the carrotsearch randomized testing framework that is the basis for randomized testing in both Apache Lucene and Elasticsearch. Other types of input parameters that can be generated include, but are not limited to, random String generation (limited to Unicode or ASCII characters only) and input data of every primitive data type available in Java. The framework also checks for threads lingering around after test execution completed. In addition to initializing tests with a specific number of iterations, it is possible to also make sure one specific test seed is checked once on each run. This way fixed tests can always be included in each test run to avoid regressions. For more extensive examples see the . Randomization at the Java Testing Level Not only does Elasticsearch use the randomization framework above to make unit tests more interesting, it also helps our integration tests go one step further. In our , we saw how to write an Elasticsearch integration test. What was not - and could not be - shown in the example, but happens in the background, is that the cluster configuration used to pull up an integration test cluster isn't static. Instead, basic configuration options like the number of master and data nodes, number of replicas, transport to use etc. are randomized on each run. Again, an exact configuration can be reproduced deterministically by initializing the test in question with a specific test seed, e.g. on test failure. If you are using the you will not only benefit from a great number of helper methods for cluster startup, search request creation and search result checking. The same kind of randomization on cluster bootup will also be applied in your test setup. Randomization at the Continuous Integration Level Our continuous integration deployment sounds pretty much standard. There are multiple Jenkins managed jobs checking the software works on all supported hardware configurations, operating systems and JDK versions. Hardware platforms range from small EC2 instances to rather beefy bare metal machines . Operating systems include various Linux flavors as well as Windows versions. The trick lies in the details: on each run, a supported JDK is chosen at random, and so are the JVM configuration options. The Elasticsearch server configuration itself is randomized. JDK choice can be biased towards specific JDK versions. We work closely with the Lucene community to make sure we are using - and recommending to users - JDK versions that are known to work well and avoid bugs. As a result, our tests are biased towards those versions. By simply biasing test runs towards specific versions, we make sure that time and resources to test Elasticsearch can be distributed according to how often the underlying platforms are being used in the wild. Impact of Randomization on Development Culture With automated testing and continuous integration in place, it has become common advice to make sure your tests are always green before checking in. There's even a that turns the goal of having a working build into a game heavily penalizing build breakage. When introducing randomization to any project, over time, the space searched for problematic code increases over time. Parts of the code that are complex tend to cause tests to become flaky - adding noise instead of signal. In addition, pieces of your software that put the underlying platform - in our use case: Apache Lucene and Elasticsearch JVM - under pressure are bound to reveal bugs in that platform over time. Is this a bad thing? Of course not. As Mike puts it, \".\" However it is paramount to establish a development culture where even complex issues, that only rarely cause the build to break, are fixed quickly, especially if they impact real world user deployments. Often believing the issues uncovered are merely false positives that cannot occur in production leads to finding lots of \"this should never happen\" exception messages in log files. Double - or better triple - check your conclusion that it's noise. If it is noise, make sure to disable the test configuration in question to get the build back to stable state. Don't do so, and your development teams will slow down in reacting to test failures, or just ignore them entirely. \n"}<br>{"index": {"_id": 1219}}<br>{"title":"This Week in Elasticsearch - October 15, 2014","seo_title":"","url":"\/blog\/2014-10-15-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"October 15, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Elasticsearch Core I'll be a hosting an Oct 30th webcast featuring : Anomaly Detection with \u2014 Ben Lorica (@bigdata) Elasticsearch EcosystemHere's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Slides & VideosHere are the slides for my \"Application Logging in the 21st century\" talk I just gave at today: \u2014 Tim Bunce (@timbunce) on the Elasticsearch Language ClientsMy slides about data visualisation and D3.js from the EUROPEN 2014 conference are here: \u2014 Karel Mina\u0159\u00edk (@karmiq) Where to Find UsWe'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Director of Developer Relations, , know!BelgiumWe're a proud sponsor of the 5th anniversary of , held in its original hometown of Ghent. Elasticsearch will have a booth at the conference, so stop by and say hello to and between sessions. We'll be at DevOps Days October 27-28th. Canada will regale all with tales of the ELK stack at the next Montreal Elasticsearch Meetup. You can join Colin this Thursday, Oct. 16th at 6:30 PM. to save your spot.ChinaZeng Yong, aka Medcl, is one of our most active community members in China. He has an upcoming talk on all things Elasticsearch: at QCon Shanghai on October 17, 2014.Medcl is also busy convening the 3rd annual Elasticsearch Users Conference in China for October 25th. You can find out .France GermanyIf you happen to be in Karlsruhe on October 16th, you can catch Patrick Peschlow on Elasticsearch Performance in a Nutshell at the Search Meetup Karlsruhe. , and the meetup will begin at 7:15 PM.For folks in Berlin, we'll have a booth at the GOTO Berlin conference, plus two awesome talks from Elasticsearchers: Join us at the Kosmos Event Center on November 6th and 7th for !IndiaThe Hyderabad Scalability Meetup group is hosting a getting started with Elasticsearch hackathon on October 18th. to save your place, looks like space is limited!Italy Poland SwedenHonza Kral will be speaking at the \u00d8redev conference in Malm\u00f6 on . The conference runs Nov. 4-7th, and Honza takes the stage on Nov. 6th at 5:40 PM. Switzerland will return to Soft-Shake in Geneva once again this year. He will speak on Advanced Search for Your Legacy Application in the Big Data Track. Soft-Shake takes place on October 23-24th, and David will speak in Slot 5 on Thursday.United Kingdom United States Where to Find YouOur Director of Developer Relations, Leslie Hawthorn, is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, .Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head.TrainingsIf you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1220}}<br>{"title":"Little Logstash Lessons - Part I: Using grok and mutate to type your data","seo_title":"","url":"\/blog\/little-logstash-lessons-part-using-grok-mutate-type-data","author":{"name":"Aaron Mildenstein"},"date":"October 14, 2014","category":"Engineering","locales":"de-de","content":" \n"}<br>{"index": {"_id": 1221}}<br>{"title":"Elasticsearch from the Top Down","seo_title":"","url":"\/blog\/found-elasticsearch-top-down","author":{"name":"Alex Brasetvik"},"date":"October 15, 2014","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. The previous article in this series, Elasticsearch from the Bottom Up, covered essential data structures within a single shard. In this article, we will look at the distributed nature of Elasticsearch. \n"}<br>{"index": {"_id": 1222}}<br>{"title":"Where in the World Is Elasticsearch? - October 13, 2014","seo_title":"","url":"\/blog\/world-elasticsearch-20","author":{"name":"Livia Froelicher"},"date":"October 13, 2014","category":"","locales":"","content":" Last week ended with a great conference in Hamburg, . gave an introduction to the ELK stack with 250 attendees. We also had speaking about \u201cWhen Search boxes don't work \u2013 How to best ensure the quality of your search application\". Upcoming EventsNorth America Oct. 15th-17th: - Stop by our booth (P1) to see live demos, talk to our Solutions Architects, and learn about how Elasticsearch works with Hadoop. Europe Oct. 13th-15th: - Join in the panel discussion about . Wednesday, 2:30-3:20pm. Oct. 16th-19th: - Listen to talking about Polyglot Persistence. You can catch Honza's keynote address this Thursday at 7:00 PM. Oct. 17th: - Don't miss out on talk on which is scheduled for 2:00pm-2:50pm. Upcoming MeetupsNorth America Oct. 14th: : You'll be treated to three use case talks: on Elasticsearch in Production, Real-Time Geo-Replication and Custom Tokenization. Oct. 15th: at Twitter. Hear talks from our very own , and speakers from Concurrent, and Found AS. Seats are all spoken for, but you can still sign up to be added to the waitlist. Oct. 16th: : Join to hear about the full ELK stack, plus a talk on migrating Elasticsearch production clusters. Europe Oct. 14th: ELK use case presentation at the Oct. 16th: \u201cElasticsearch Performance in a Nutshell\" at the Asia Oct. 18th: Elasticsearch Workshop at the That's it for this week, and stay tuned for Elasticsearch happenings next week. There's much to come! - The Elasticsearch Team P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag! \n"}<br>{"index": {"_id": 1223}}<br>{"title":"Kibana 4 Beta 1.1: Pointy Needles Blunted","seo_title":"","url":"\/blog\/kibana-4-beta-1-1-pointy-needles-blunted","author":{"name":"Rashid Khan"},"date":"October 10, 2014","category":"Engineering","locales":"","content":" The response to Kibana 4 Beta 1 has been amazing! The overwhelmingly positive reactions have been incredible. The whole team is extremely thankful for the bevy of comments and contributions that have been pouring in. We've found some particularly pointy needles in the haystack that we decided should be addressed right away, thus we bring you Kibana 4 Beta 1.1 . This is software. It we do our best to make things great, but this should not be used in production. You can get Kibana 4 Beta 1.1 . Get it now, enjoy it, and be sure to give us your . \n"}<br>{"index": {"_id": 1224}}<br>{"title":"Elasticsearch Testing & QA: Testing Levels of Elasticsearch","seo_title":"","url":"\/blog\/elasticsearch-testing-qa-testing-levels-elasticsearch","author":{"name":"Isabel Drost-Fromm"},"date":"October 09, 2014","category":"Engineering","locales":"","content":" \"Works on my machine\" is a phrase that became famous for software projects lacking automated testing infrastructure. Even today, when most checks are done automatically on an integration test server, it's still crucial to be able to reproduce bugs and test features on your local box. Ideally, those should be the same tests that are being run by the CI environment (or some stripped down version thereof). Testing Layers Elasticsearch tests check the code base from multiple perspectives. Traditional unit tests are the usual check that core algorithm implementations are correct and all methods behave the way they should. One level up, integration tests run against a locally running cluster, making sure all pieces of the application work nicely together and can be interacted with through the Java Client API. REST tests make sure all REST endpoints work according to their specification. Backwards compatibility tests are a special case that were introduced recently. Instead of running some test against a cluster containing nodes of only one Elasticsearch version, a previous release can be downloaded, installed and started. Tests then run against a mixed node cluster making sure that everything works as expected and is compatible between releases. Testing the Elasticsearch Java Layer Elasticsearch attacks testing from a bunch of different angles. Java code is tested on more than on the unit test level: the Java Client API is also checked by integration tests that pull up complete Elasticsearch clusters to run requests against. Essentially, the goal for integration tests (based on the class ElasticsearchIntegrationTest) is to make sure Java API calls work against a full running cluster. It is cheap to pull up an example Elasticsearch cluster in terms of CPU power and memory needed, even on an ordinary laptop. When extending the above test class, it also becomes simple in terms of development overhead. The cluster is pulled up for you and reused between tests unless you specify something else in the test's ClusterScope annotation. Looking at an example integration test, let's walk through the most important annotations and features that makes writing Elasticsearch integration tests so trivial: 01 \/\/ make sure all tests in the test suite run on a separate test cluster as we will modify the 02 \/\/ cluster configuration 03 @ElasticsearchIntegrationTest.ClusterScope(scope = ElasticsearchIntegrationTest.Scope.SUITE) 04 public class TemplateQueryTest extends ElasticsearchIntegrationTest { 05 06 @Before 07 public void setup() throws IOException { 08 \/\/ create an index, make sure it is ready for indexing and add documents to it 09 createIndex(\"test\"): 10 ensureGreen(\"test\"): 11 12 index(\"test\", \"testtype\", \"1\", jsonBuilder().startObject().field(\"text\", \"value1\").endObject()): 13 index(\"test\", \"testtype\", \"2\", jsonBuilder().startObject().field(\"text\", \"value2\").endObject()): 14 refresh(): 15 } 16 17 \/\/ for our test we want to make sure the config path of the cluster actually points 18 \/\/ to the test resources that we provide - this is the cluster modification referred 19 \/\/ to earlier 20 @Override 21 public Settings nodeSettings(int nodeOrdinal) { 22 return settingsBuilder().put(super.nodeSettings(nodeOrdinal)) 23 .put(\"path.conf\", this.getResource(\"config\").getPath()).build(): 24 } 25 26 @Test 27 public void testTemplateInBody() throws IOException { 28 Map<String, Object> vars = new HashMap<>(): 29 vars.put(\"template\", \"all\"): 30 31 TemplateQueryBuilder builder = new TemplateQueryBuilder( 32 \"{\\\"match_{{template}}\\\": {}}\\\"\", vars): 33 34 \/\/ the search client to use in the test comes pre-configured as part of the 35 \/\/ integration test 36 SearchResponse sr = client().prepareSearch().setQuery(builder) 37 .execute().actionGet(): 38 39 \/\/ specific assertions make checks very simple 40 assertHitCount(sr, 2): 41 } In our example, line 03 defines the cluster scope of that test to be only for the test suite. This makes sense if you change the cluster configuration, e.g. hard setting a specific configuration option like we do here in line 22 for the configuration path of the cluster. Starting in line 06, the setup method simply sets up an index, makes sure it is green before modifying it and adds a couple of test documents to it. As shown in line 36, the client to use is available as part of the integration test, all pre-configured and ready to use. So are helper assertions like the one in line 40 that make it easy to check the state of results. In addition to regular integration tests, Elasticsearch also tests backwards compatibility for those versions that should be backwards compatible. Essentially this is achieved in a similar way to how integration tests work. A cluster is started for the test, and the release to check backwards compatibility against is downloaded and installed. Then, for each test, a random number of nodes from the comparison release is added to the test cluster and requests are then executed against this mixed node cluster. This way, we can automatically verify that changes do not break backwards compatibility where they shouldn't, and at the per commit level if needed. Testing the REST Layer The Elasticsearch REST API is defined in . Based on this spec, tests can be defined declaratively in YAML. The snippet below defines, in a concise way, a test to check the templating based search query. Line 01 to 04 defines the query to execute. Based on the specification for search requests, this snippet can automatically be turned into a valid GET URL and request body. 01 - do: 02 search_template: 03 body: { \"template\" : { \"query\": { \"term\": { \"text\": { \"value\": \"{{template}}\" } } } }, 04 \"params\": { \"template\": \"value1\" } } 05 06 - match: { hits.total: 1 } Line 06 then defines the expected result. In this case only the number of hits returned is being checked. Code Checks Built into Each Compile Run Tests aren't the only way code quality is ensured within Elasticsearch. On each Maven build, we check for the usage of \"forbidden Java APIs.\" In case there are known faster versions of the same API functionality, the slower API call is detected in the code base, causing the build to fail. Another example would be calls that send output to STDOUT (like calls to System.out.println that are usually a sign of forgotten debug statements), instead of using the logging framework to communicate messages. Also there are certain functions that are downright dangerous to use if one cares about compatibility across systems (think using the default charset of the machine the code is running on instead of explicitly defining which charset is supposed to be used). For releases, checks are even more restrictive. During development broken tests can be disabled and marked with the special annotation \"AwaitsFix.\" In the case of cutting a release, the AwaitsFix broken tests will fail the build, telling the release manager that there is still functionality that is not yet working. In our final installment of this series, we'll cover Elasticsearch's randomized testing framework. \n"}<br>{"index": {"_id": 1225}}<br>{"title":"This Week in Elasticsearch - October 08, 2014","seo_title":"","url":"\/blog\/2014-10-08-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"October 08, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Elasticsearch core So happy to be tweeting 4 screenshots. are awesome \u2014 Rashid Khan (@rashidkpc) Elasticsearch EcosystemHere's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Happy to announce that for Apache Hadoop 2.1 is now certified on Cloudera 5, including support for Apache Spark! \u2014 Cloudera Connect (@ClouderaConnect) Slides & VideosThis week, we're bringing you a whole whack of Elasticsearch love from last week's DrupalCon Amsterdam! Not a Drupalista? No problem - these videos are great for all lovers of things PHP and folks interested in learning how to scale the ELK stack for centralized logging and monitoring. Where to find UsWe'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Director of Developer Relations, , know!BelgiumWe're a proud sponsor of the 5th anniversary of , held in its original hometown of Ghent. Elasticsearch will have a booth at the conference, so stop by and say hello to and between sessions. We'll be at DevOps Days October 27-28th. ChinaZeng Yong, aka Medcl, is one of our most active community members in China. He has two upcoming talks on all things Elasticsearch: Medcl is also busy convening the 3rd annual Elasticsearch Users Conference in China for October 25th. You can find out .France GermanyThe code.talks conference is back in Hamburg this year on October 9th and 10th, though with a new name. (We had a great time there last year when this conference was known simply as Developer Conference EU.) will be speaking once again, along with . Here's all the Elasticsearch and ELK stack information on offer at : The week after code.talks, will be heading LinuxCon Europe in Dusseldorf, where she'll speak on the panel Empowering Your Corporate Open Source Software Developers. The panel takes place on Wednesday, October 15th at 2:30 PM, and the conference runs October 13-15th at Congress Centre Dusseldorf.And, if you happen to be in Karlsruhe on October 16th, you can catch Patrick Peschlow on Elasticsearch Performance in a Nutshell at the Search Meetup Karlsruhe. , and the meetup will begin at 7:15 PM.IndiaThe Hyderabad Scalability Meetup group is hosting a getting started with Elasticsearch hackathon on October 18th. to save your place, looks like space is limited!Poland SwedenHonza Kral will be speaking at the \u00d8redev conference in Malm\u00f6 on . The conference runs Nov. 4-7th, and Honza takes the stage on Nov. 6th at 5:40 PM. Switzerland will return to Soft-Shake in Geneva once again this year. He will speak on Advanced Search for Your Legacy Application in the Big Data Track. Soft-Shake takes place on October 23-24th, and David will speak in Slot 5 on Thursday.United KingdomThe Leeds DevOps meetup group will convene on Oct. 14th for their one year anniversary meeting! Along with the celebration, you can also enjoy a use case talk from the fine folks at LateRooms on how they use the ELK stack to grapple with millions of lines of log data. You can still !United States Where to Find YouOur Director of Developer Relations, Leslie Hawthorn, is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, .Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head.TrainingIf you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1226}}<br>{"title":"Elasticsearch Hadoop 2.0.2 and 2.1.Beta2 Released","seo_title":"","url":"\/blog\/elasticsearch-hadoop-2-0-2-and-2-1-beta2","author":{"name":"Costin Leau"},"date":"October 08, 2014","category":"News","locales":"","content":" I am pleased to announce Elasticsearch for Apache Hadoop releases and . (If you haven't been following our story so far, is our connector that serves up real-time search & analytics for your Hadoop deployments.) 2.0.2 is the latest release containing several bug fixes and is recommended upgrade for all existing users. 2.1.Beta2 is the second from the development branch bringing a number of new features and improvements besides the typical bug fixes, adding and support. Spark SQL Support 2.1 Beta2 extends our Spark support through integration. One can save s to Elasticsearch or materialize them based on indices or queries (effectively creating ). For example, finding out the \u201cSmith\"s is a one liner: import org.apache.spark.sql.SQLContext import org.elasticsearch.spark.sql._ ... val people = sqlContext.esRDD(\"spark\/people\",\"?q=Smith\") \/\/ check the associated schema println(people.schema) \/\/ root \/\/ |-- name: string (nullable = true) \/\/ |-- surname: string (nullable = true) \/\/ |-- age: long (nullable = true) The data and its associated schema are loaded through the returned and through Spark SQL, and can be further interrogated through SQL. Writing to Elasticsearch looks strikingly similar, as any can be indexed. For this example, let's use the Java support: import org.apache.spark.sql.api.java.*: import org.elasticsearch.spark.sql.java.api.JavaEsSparkSQL: JavaSchemaRDD people = JavaSQLContext.parquetFile(\"people.dat\") \/\/ filter data using SQL people.registerTempTable(\"people\"): JavaSchemRDD teenagers = sqlContext.sql(\"SELECT name FROM people WHERE age >= 13 AND age <= 19\") \/\/ index it to Elastic JavaEsSparkSQL.saveToEs(teenagers, \"spark\/teens\"): Again, it's just a one liner to save the data to Elasticsearch. In addition to the Spark SQL support, the Spark module has had several improvements: the existing s have been enhanced to s and the code base has been upgraded to Spark 1.1 while with Spark 1.0. CDH 5.1 Certified Happy to announce that for Apache Hadoop 2.1 is now certified on Cloudera 5, including support for Apache Spark! \u2014 Cloudera Connect (@ClouderaConnect) Speaking of Spark, we are glad to report that es-hadoop is now officially certified for CDH 5.1 (in addition to ) this time the category. We are tracking our releases to Hadoop's releases to make sure our product evolves in step with its ecosystem, giving our users peace of mind knowing that es-hadoop will simply work out of the box. Apache Storm Integration 2.1 Beta2 makes a first class citizen. (And, by the way, congrats to the Storm team for to a top level project) in the Apache incubator. es-hadoop brings real-time search and analytics to Storm's stream data processing platform through dedicated native and implementation to ingest data and fan-out queries from and to Storm topologies. To index data to Elasticsearch simply use : TopologyBuilder builder = new TopologyBuilder(): builder.setBolt(\"esBolt\", new EsBolt(\"twitter\/tweets\")): Executing queries in Elasticsearch for Storm is yet another one-liner: TopologyBuilder builder = new TopologyBuilder(): builder.setSpout(\"es-spout\", new EsSpout(\"twitter\/tweets\", \"?q=nfl*), 5): builder.setBolt(\"bolt\", new PrinterBolt()).shuffleGrouping(\"es-spout\"): That's it! Under the covers, es-hadoop uses its parallelized infrastructure to the and instances across the index shards for what we call . Low-latency\/high-performance patterns like and are supported to provide excellent through-put out of the box and closely integrate the real-time capabilities of Storm and Elasticsearch. Elasticsearch 1.4 Repository Support Elasticsearch 1.4 Beta 1 was released bringing significant enhancements especially in resilience area. Among them, the snapshot and restore infrastructure has been , with the new version supported by 2.1 Beta 2. (For Elasticsearch 1.0 \u2013 1.3 please use es-hadoop 2.0.x.) Elasticsearch Comes to NYC If you happen to be in NYC next week and are interested in Elasticsearch, we'd love to talk to you! Join us for the \u00a0(please RSVP \u2013 seats are limited) on Oct 15th at Twitter or if you are attending please pass by our booth. Many thanks to Twitter for hosting us! We look forward to your on 2.1.Beta2 \u2013 you can find the binaries are available on the and the new features explained in the . As always, you can on GitHub. \n"}<br>{"index": {"_id": 1227}}<br>{"title":"Playing HTTP Tricks with Nginx","seo_title":"","url":"\/blog\/playing-http-tricks-nginx","author":{"name":"Karel Mina\u0159\u00edk"},"date":"October 07, 2014","category":"Engineering","locales":"de-de","content":" One of the defining features of Elasticsearch is that it\u2019s exposed as a (loosely) RESTful service over HTTP.The benefits are easy to spell out, of course: the API is familiar and predictable to all web developers. It\u2019s easy to use with \u201cbare hands\u201d\ufffd via the command, or in the browser. It\u2019s easy to write API wrappers in various programming languages.Nevertheless, the importance of the HTTP-based nature of Elasticsearch is rooted deeper: in the way it fits into the existing paradigm of software development and architecture.HTTP As an Architectural ParadigmThe typical modern software or information system is quite frequently a collection of loosely coupled services, communicating over network: typically, via HTTP. Design-wise, the important aspect of this approach is that you can always \u201crip apart\u201d the chain of services, and insert another component, which adds or changes functionality, into the \u201cstack\ufffd.\u201d In the old days, this has been traditionally called \u201cmiddleware,\u201d but it resurfaced in context of RESTful web services, for example as , used notably in the .HTTP is particularly well suited for such architectures, because its perceived shortcomings (lack of state, text-based representation, URI-centric semantics, \u2026) turn into an advantage: neither \u201cmiddleware\u201d\ufffd has to accommodate for something specific in the \u201cchain\u201d, and just passes along status codes, headers, and bodies. In this sense, HTTP is \u2013 it doesn\u2019t matter, for example, if you fetch an image from the original web server or a cache on a different continent. It\u2019s still the same \u201cresource\ufffd.\u201d is a prime example of this aspect of HTTP, presented already in Roy Fielding\u2019s on RESTful architectures. (For a thorough information on the subject, see Ryan Tomayko\u2019s and Mark Nottingham\u2019s .)Technically, the cache operates as a here \u2013 it \u201cstands for\u201d some other component in the stack.But proxies can do so much more. A good example is authentication and authorization: a proxy can intercept requests to a service, perform authentication and\/or authorization routines, and either allow or deny access to the client.This type of proxy is usually called a . The name makes sense when you consider that a traditional proxy \u201cforwards\u201d traffic from a network to the network (the internet), which is reversed here, because the \u201creverse\u201d proxy forwards requests from the internet to a \u201clocal\u201d backend. Such a proxy could be implemented in a programming language like Java or Go, or with a framework like Node.js. Alternatively, we could use a configurable webserver like Nginx.Nginx is an open source web server, originally writen by Igor Sysoev, focused on high performance, and low memory footprint. (For a detailed technical overview, see the relevant chapter of the book.)Nginx has been designed with a proxy role in mind from the start, and supports many related configuration directives an options. It is fairly common to run Nginx as a load balancer in front of Ruby on Rails of Django applications. Many large PHP applications even running to accelerate serving static content and scale the application. Most parts of this article assume a , but the advanced parts rely on the .To run Nginx as a \u201c100% transparent\u201d\ufffd proxy for Elasticsearch, we need a very minimal configuration:http { server { listen 8080: location \/ { proxy_pass http:\/\/localhost:9200: } } } When we execute a request to , we\u2019ll get a response from Elasticsearch running on port 9200.This proxy is of course quite useless \u2014 it just hands over data between the client and Elasticsearch: though astute readers might have guessed that it adds something to the \u201cstack,\u201d namely the logging of every request.Use CasesIn this article, we\u2019ll go through some of the more interesting use cases for Nginx as a reverse proxy for Elasticsearch.Persistent HTTP ConnectionsLet\u2019s start with a very simple example: using Nginx as a proxy which keeps persistent (\u201ckeep-alive\u201d\ufffd) connections to Elasticsearch. Why we would like to do it? The primary reason would be to relieve Elasticsearch of the stress from opening and closing a connection for each request when using a client without support for persistent connections. Elasticsearch has many more responsibilities than just handling the networking, and opening\/closing connections wastes valuable time and resources (such as open files limit).The full configuration is available, like all examples in this article, in .events { worker_connections 1024: } http { upstream elasticsearch { server 127.0.0.1:9200: keepalive 15: } server { listen 8080: location \/ { proxy_pass http:\/\/elasticsearch: proxy_http_version 1.1: proxy_set_header Connection \"Keep-Alive\": proxy_set_header Proxy-Connection \"Keep-Alive\": } } } Let\u2019s launch Nginx with this configuration:$ nginx -p $PWD\/nginx\/ -c $PWD\/nginx_keep_alive.conf When you execute a request directly to Elasticsearch, you\u2019ll notice that the number of opened connections is increasing all the time:$ curl 'localhost:9200\/_nodes\/stats\/http?pretty' | grep total_opened # \"total_opened\" : 13 $ curl 'localhost:9200\/_nodes\/stats\/http?pretty' | grep total_opened # \"total_opened\" : 14 # ... But it\u2019s a completely different story when using Nginx \u2014 the number of opened connections stays the same:$ curl 'localhost:8080\/_nodes\/stats\/http?pretty' | grep total_opened # \"total_opened\" : 15 $ curl 'localhost:9200\/_nodes\/stats\/http?pretty' | grep total_opened # \"total_opened\" : 15 # ... Simple Load BalancerWith a very small change to the configuration, we can use it to pass requests to multiple Elasticsearch nodes, and use Nginx as a light-weight load balancer:events { worker_connections 1024: } http { upstream elasticsearch { server 127.0.0.1:9200: server 127.0.0.1:9201: server 127.0.0.1:9202: keepalive 15: } server { listen 8080: location \/ { proxy_pass http:\/\/elasticsearch: proxy_http_version 1.1: proxy_set_header Connection \"Keep-Alive\": proxy_set_header Proxy-Connection \"Keep-Alive\": } } } As you can see, we\u2019ve added two additional nodes in the directive. Nginx will now automatically distribute requests, in a round-robin fashion, across these servers, spreading the load on the Elasticsearch cluster evenly across the nodes:$ curl localhost:8080 | grep name # \"name\" : \"Silver Fox\", $ curl localhost:8080 | grep name # \"name\" : \"G-Force\", $ curl localhost:8080 | grep name # \"name\" : \"Helleyes\", $ curl localhost:8080 | grep name # \"name\" : \"Silver Fox\", # ... This is a desirable behaviour, because it prevents hitting a single \u201chot\u201d\ufffd node, which has to perform the regular node duties also route all the traffic and perform all the other associated actions. To change the configuration, we just need to update the list of servers in the directive, and send Nginx a signal.For more information about Nginx\u2019s load balancing features, including different balancing strategies, setting \u201cweights\u201d for different nodes, health checking and live monitoring, please see the article.(Note, that the can perform such load balancing by themselves, with the ability to automatically reload list of nodes in the cluster, retrying a request on another node, etc.)Basic AuthenticationLet\u2019s focus on another functionality: authentication and authorization. By default, Elasticsearch doesn\u2019t prevent any unauthorized access, because it\u2019s not designed to be running as an open service. When you\u2019d allow open access to port 9200, you\u2019d be vulnerable to data theft, loss and even to .The usual way of protecting your Elasticsearch cluster to is to restrict the access via VPN, firewall rules, AWS\u2019s security groups, etc. What if you want or need to connect to the cluster from the outside, though, authenticating by an username and password?Well, if we consider the proxy concept, as outlined above, that could work, right? We just need to intercept requests to Elasticsearch, authorize the client, and allow or deny access. Since Nginx supports out-of-the-box, it\u2019s absolutely trivial to do it:events { worker_connections 1024: } http { upstream elasticsearch { server 127.0.0.1:9200: } server { listen 8080: auth_basic \"Protected Elasticsearch\": auth_basic_user_file passwords: location \/ { proxy_pass http:\/\/elasticsearch: proxy_redirect off: } } } We can generate the passwords file with , for example with :$ printf \"john:$(openssl passwd -crypt s3cr3t)n\" > passwords Let\u2019s run Nginx with this configuration (don\u2019t forget to shutdown the Nginx process first):$ nginx -p $PWD\/nginx\/ -c $PWD\/nginx_http_auth_basic.conf When we attempt to access the proxy without proper credentials, the request will be denied:$ curl -i localhost:8080 # HTTP\/1.1 401 Unauthorized # ... With proper credentials, though, the access is allowed:$ curl -i john:s3cr3t@localhost:8080 # HTTP\/1.1 200 OK # ... We can now restrict access to the 9200 port to local network (eg. with firewall rules), leaving only the 8080 port open to the outside. Any client accessing Elasticsearch has to know the correct credentials.Simple AuthorizationHaving a secure way for accessing the cluster from the outside is certainly great, but you might have noticed that there\u2019s no granularity when it comes to authorization \u2013 once allowed access, the client can do whatever it wants in the cluster: change or delete the data, inspect internal statistics, even .A very simple way of authorizing the access would be to flat out deny requests to certain endpoints, so they\u2019re allowed only from a client running on the local machine or network. We can change the location directive a little bit:location \/ { if ($request_filename ~ _shutdown) { return 403: break: } proxy_pass http:\/\/elasticsearch: proxy_redirect off: } Let\u2019s shutdown Nginx and run it with the new configuration:$ nginx -p $PWD\/nginx\/ -c $PWD\/nginx_http_auth_deny_path.conf When we attempt a request to the shutdown API now, it will be denied even with correct credentials:$ curl -i -X POST john:s3cr3t@localhost:8080\/_cluster\/nodes\/_shutdown # HTTP\/1.1 403 Forbidden # .... We can also flip the approach \u2013 let\u2019s allow only certain endpoints, such as the administrative APIs, and deny access to anything else. We\u2019ll distinguish between them by two separate directives:events { worker_connections 1024: } http { upstream elasticsearch { server 127.0.0.1:9200: } server { listen 8080: auth_basic \"Protected Elasticsearch\": auth_basic_user_file passwords: location ~* ^(\/_cluster|\/_nodes) { proxy_pass http:\/\/elasticsearch: proxy_redirect off: } location \/ { return 403: break: } } } Authenticated requests to and APIs will be allowed, but anything else will be denied:$ curl -i john:s3cr3t@localhost:8080\/ HTTP\/1.1 403 Forbidden # ... $ curl -i john:s3cr3t@localhost:8080\/_cluster\/health # HTTP\/1.1 200 OK # ... $ curl -i john:s3cr3t@localhost:8080\/_nodes\/stats HTTP\/1.1 200 OK # ... Selective AuthorizationLet\u2019s have a look at another authorization use case: we want to protect the Elasticsearch cluster with basic authentication, but still allow a HEAD request to \u2013 called \u201cping\u201d in the , e.g. for monitoring purposes.This might sound like an easy thing to do, but in fact, it\u2019s not a trivial thing to do in an Nginx configuration: we need to combine for a rule like that (request URL and method), and Nginx\u2019s statement doesn\u2019t allow that. (Nginx even considers the statement .)So, what should we do? As it happens, we can creatively use two central pieces of Nginx configuration syntax: variables and custom error codes:events { worker_connections 1024: } http { upstream elasticsearch { server 127.0.0.1:9200: } server { listen 8080: location \/ { error_page 590 = @elasticsearch: error_page 595 = @protected_elasticsearch: set $ok 0: if ($request_uri ~ ^\/$) { set $ok \"${ok}1\": } if ($request_method = HEAD) { set $ok \"${ok}2\": } if ($ok = 012) { return 590: } return 595: } location @elasticsearch { proxy_pass http:\/\/elasticsearch: proxy_redirect off: } location @protected_elasticsearch { auth_basic \"Protected Elasticsearch\": auth_basic_user_file passwords: proxy_pass http:\/\/elasticsearch: proxy_redirect off: } } } First, we define two custom status \u201cerror\u201d codes: , for accessing Elasticsearch without credentials, and , for accessing it with basic authentication, just as we did up to this point. We use Nginx\u2019s \u201cnamed locations\u201d\ufffd feature to distinguish between these two \u2013 both point to the same cluster, but one of them requires authentication.Then we set up a variable , which has a default value of . When the incoming request URL matches (ie. the path is empty), we append to it. When it\u2019s performed via the method as well, we append . Clearly, when both of those conditions are satisfied, the resulting value of is .And that\u2019s exactly what we check in the last . In that case, we return the status code \u2014 in other words, we allow the request to go through to Elasticsearch. In any other case, we require authentication:$ curl -i -X HEAD localhost:8080 # HTTP\/1.1 200 OK # ... $ curl -i localhost:8080 # HTTP\/1.1 401 Unauthorized # ... $ curl -i john:s3cr3t@localhost:8080 # HTTP\/1.1 200 OK # ... Multiple Roles for AuthorizationUp until now, we had a pretty simple authorization scheme. What if we need a wider scheme, based on roles, though? Something like: We will use a different approach here \u2014 we\u2019ll create a separate virtual server for each role:events { worker_connections 1024: } http { upstream elasticsearch { server 127.0.0.1:9200: } # Allow HEAD \/ for all # server { listen 8080: location \/ { return 401: } location = \/ { if ($request_method !~ \"HEAD\") { return 403: break: } proxy_pass http:\/\/elasticsearch: proxy_redirect off: } } # Allow access to \/_search and \/_analyze for authenticated \"users\" # server { listen 8081: auth_basic \"Elasticsearch Users\": auth_basic_user_file users: location \/ { return 403: } location ~* ^(\/_search|\/_analyze) { proxy_pass http:\/\/elasticsearch: proxy_redirect off: } } # Allow access to anything for authenticated \"admins\" # server { listen 8082: auth_basic \"Elasticsearch Admins\": auth_basic_user_file admins: location \/ { proxy_pass http:\/\/elasticsearch: proxy_redirect off: } } } We\u2019ll generate the credentials with the command again:$ printf \"user:$(openssl passwd -crypt user)n\" > users $ printf \"admin:$(openssl passwd -crypt admin)n\" > admins Now, everybody can \u201cping\u201d the cluster, but nothing else:$ curl -i -X HEAD localhost:8080 # HTTP\/1.1 200 OK $ curl -i -X GET localhost:8080 # HTTP\/1.1 403 Forbidden Authenticated can access the search and analyze APIs, but nothing else:$ curl -i localhost:8081\/_search # HTTP\/1.1 401 Unauthorized # ... $ curl -i user:user@localhost:8081\/_search # HTTP\/1.1 200 OK # ... $ curl -i user:user@localhost:8081\/_analyze?text=Test # HTTP\/1.1 200 OK # ... $ curl -i user:user@localhost:8081\/_cluster\/health # HTTP\/1.1 403 Forbidden # ... Authenticated , of course, can access any API:$ curl -i admin:admin@localhost:8082\/_search # HTTP\/1.1 200 OK # ... $ curl -i admin:admin@localhost:8082\/_cluster\/health # HTTP\/1.1 200 OK # ... As you\u2019ve might have noticed, each role is accessing the proxy on a different port: that is the price we have to pay with this solution. On the other hand, it should be quite easy to configure any application for a scheme like this, for instance using different , connected to different URLs. (We could have used the directive instead, to distinguish between different servers, and run all servers on the same port, instead.)Access Control List with LuaWe have been able to support reasonably complex, non-\u201dHello World\u201d\ufffd scenarios with Nginx as a proxy for Elasticsearch so far. On the other hand, even the last example is pretty simple, and supporting a more complex, fine-grained authorization scheme would be unwieldy \u2013 imagine all those possible blocks\u2026So, what if we need to support a much more complex set of rules, such as allowing not only certain endpoints for certain roles, but also only certain methods for them, and we would like to store the information in a more familiar format.In the next configuration, we\u2019ll use the Lua module for Nginx to be able to express the rules and code more expressively. We\u2019ll use the package provided by the project, which bundles not only Lua, but also a JSON parser, a Redis library, and many other useful Lua modules with Nginx: please see the at the OpenResty site. On a Mac, you can use the :$ brew install https:\/\/raw.githubusercontent.com\/Homebrew\/homebrew-nginx\/master\/openresty.rb The OpenResty bundle turns Nginx into a full-featured web application server, allowing to rewrite locations by Lua code, using external databases, manipulating responses on the fly, making HTTP , and much more. In our example, we\u2019ll use the directive in concert with the regular HTTP basic authentication to allow or deny the client.The Nginx configuration itself is fairly simple:error_log logs\/lua.log notice: events { worker_connections 1024: } http { upstream elasticsearch { server 127.0.0.1:9200: } server { listen 8080: location \/ { auth_basic \"Protected Elasticsearch\": auth_basic_user_file passwords: access_by_lua_file '..\/authorize.lua': proxy_pass http:\/\/elasticsearch: proxy_redirect off: } } } The Lua code is of course a bit more complicated \u2013 consult the for full source with comments, debug logging, etc:-- authorization rules local restrictions = { all = { [\"^\/$\"] = { \"HEAD\" } }, user = { [\"^\/$\"] = { \"GET\" }, [\"^\/?[^\/]*\/?[^\/]*\/_search\"] = { \"GET\", \"POST\" }, [\"^\/?[^\/]*\/?[^\/]*\/_msearch\"] = { \"GET\", \"POST\" }, [\"^\/?[^\/]*\/?[^\/]*\/_validate\/query\"] = { \"GET\", \"POST\" }, [\"\/_aliases\"] = { \"GET\" }, [\"\/_cluster.*\"] = { \"GET\" } }, admin = { [\"^\/?[^\/]*\/?[^\/]*\/_bulk\"] = { \"GET\", \"POST\" }, [\"^\/?[^\/]*\/?[^\/]*\/_refresh\"] = { \"GET\", \"POST\" }, [\"^\/?[^\/]*\/?[^\/]*\/?[^\/]*\/_create\"] = { \"GET\", \"POST\" }, [\"^\/?[^\/]*\/?[^\/]*\/?[^\/]*\/_update\"] = { \"GET\", \"POST\" }, [\"^\/?[^\/]*\/?[^\/]*\/?.*\"] = { \"GET\", \"POST\", \"PUT\", \"DELETE\" }, [\"^\/?[^\/]*\/?[^\/]*$\"] = { \"GET\", \"POST\", \"PUT\", \"DELETE\" }, [\"\/_aliases\"] = { \"GET\", \"POST\" } } } -- get authenticated user as role local role = ngx.var.remote_user -- exit 403 when no matching role has been found if restrictions[role] == nil then ngx.header.content_type = 'text\/plain' ngx.status = 403 ngx.say(\"403 Forbidden: You don't have access to this resource.\") return ngx.exit(403) end -- get URL local uri = ngx.var.uri -- get method local method = ngx.req.get_method() local allowed = false for path, methods in pairs(restrictions[role]) do -- path matched rules? local p = string.match(uri, path) local m = nil -- method matched rules? for _, _method in pairs(methods) do m = m and m or string.match(method, _method) end if p and m then allowed = true end end if not allowed then ngx.header.content_type = 'text\/plain' ngx.log(ngx.WARN, \"Role [\"..role..\"] not allowed to access the resource [\"..method..\" \"..uri..\"]\") ngx.status = 403 ngx.say(\"403 Forbidden: You don't have access to this resource.\") return ngx.exit(403) end As you can see, we\u2019re storing the list of roles as a Lua table, with a nested table for each role. An incoming request method and URL are matched against regular expression patterns, and if they match, the request is allowed:$ curl -i -X HEAD 'http:\/\/localhost:8080' # HTTP\/1.1 401 Unauthorized # ... $ curl -i -X HEAD 'http:\/\/all:all@localhost:8080' # HTTP\/1.1 200 OK # ... $ curl -i -X GET 'http:\/\/all:all@localhost:8080' # HTTP\/1.1 403 Forbidden # ... $ curl -i -X GET 'http:\/\/user:user@localhost:8080' # HTTP\/1.1 200 OK # ... $ curl -i -X POST 'http:\/\/user:user@localhost:8080\/myindex\/mytype\/1' -d '{\"title\" : \"Test\"}' # HTTP\/1.1 403 Forbidden # ... $ curl -i -X DELETE 'http:\/\/user:user@localhost:8080\/myindex\/' # HTTP\/1.1 403 Forbidden # ... $ curl -i -X POST 'http:\/\/admin:admin@localhost:8080\/myindex\/mytype\/1' -d '{\"title\" : \"Test\"}' # HTTP\/1.1 200 OK # ... $ curl -i -X DELETE 'http:\/\/admin:admin@localhost:8080\/myindex\/' # HTTP\/1.1 200 OK # ... Of course, the restrictions table could be much more complicated, the authentication could be provided by an Oauth token instead of HTTP basic authentication, etc., but the authorization mechanics would be the same.ConclusionIn this article, we\u2019ve made great use of the fact that Elasticsearch is a service exposed via HTTP \u2013 we\u2019ve added amount of \ufffd to Elasticsearch, without extending or modifiying the software itself in any way.We\u2019ve seen how HTTP fits very well conceptually into the current paradigm of designing software architectures as independent, decoupled services, and how Nginx can be used as a high-performing, customizable proxy. Happy proxying! \n"}<br>{"index": {"_id": 1228}}<br>{"title":"Kibana 4 Beta 1 Released","seo_title":"","url":"\/blog\/kibana-4-beta-1-released","author":{"name":"Rashid Khan"},"date":"October 06, 2014","category":"News","locales":"","content":" We\u2019re pretty darn happy, to share the future of Kibana, and the first beta release of Kibana 4 with you today. This is software. It we do our best to make things great, but this should not be used in production. I want it now! Gimmie! Get it , see the for the new (easier!) installation procedure. That said, you really should read the rest, there\u2019s some great tips down there. Welcome to Kibana 4 We\u2019re taking the long road with Kibana 4: You can expect to see several beta releases, each with new features, visualizations and enhancements. We combed over feedback, mailing lists, IRC and the Github issues to compile the features that made it into Beta 1, and we think we hit a lot of the biggies. We\u2019re already hard at work on Beta 2 and we\u2019re happy to share our roadmap with you, simply checkout the tagged issues in Github. As always, your feedback is crucial in making sure we get it right. In addition to your feedback we took a step back to consider how people look at data, and further, how they solve real problems. We found that one question will lead to others and those questions will lead to yet more. If you attended Monitorama, or any of a handful of Elasticsearch meet ups, you may have already seen the Kibana 4 proof of concept demo that allowed you to progressively create ever more complex charts. Kibana 4 takes that PoC and expands it to dozens of new features that allow you to compose questions, get answers, and solve problems like never before. That level of composability can be found throughout Kibana 4 in the way aggregations, searching, visualizations and dashboards fit together. To simplify and streamline composition we\u2019ve broken out Kibana 4 into three distinct interfaces, all working together, each adept at answering a unique set of questions. A familiar face If you\u2019re a long term Kibana user you will recognize and feel right at home in the Discover tab. Discover functions much like a traditional search interface with a list of documents and a timeline of events. Type in a search, hit enter and let Kibana dig through your Elasticsearch index. Speaking of indices, a quick drop down allows you to quickly switch between indices while you search. If you want to switch back, click your browser\u2019s back button and you\u2019re there. Don\u2019t like your new search terms? The old ones are a back button click away, or available in the history of the search field. And speaking of searches, feel free to type either Lucene Query String syntax or, an oft requested feature, into that search box. We know JSON can be tricky to type out, so whether you use Lucene Query Strings, or JSON, we\u2019ll validate the syntax for you before shipping it off to Elasticsearch. And that holds true no matter where you type a query in Kibana 4. Those queries can also be saved for later. Importantly, queries are no longer bound to the dashboard, they can be recalled in Discover, or even tied to a visualization which is later put on a dashboard. Plus, the , no matter what screen you\u2019re on, so linking to queries is super easy. I\u2019m here for the charts The Visualize tab of Kibana 4 is the culmination of that long-in-the-tooth proof of concept I talked about earlier. Kibana 4 brings the power of Elasticsearch\u2019s nested aggregations to the click of a mouse. Maybe I want to know what countries are hitting my site, when they\u2019re doing so and whether or not they are authenticated. I can ask that question, and see how the answers relate to each other all within a single request on a single canvas: While Kibana 3 could only show time on the histogram panel, and terms on bar chart, Kibana 4 can make use of multiple . These include both bucket and metric aggregations, including the much anticipated (aka unique count) aggregation, and support for more is on the way. We had to build an entirely new visualization framework to deal with the complexity of aggregations. Right now there are three supported types: Bar charts, line charts and sunburst charts. Fear not! More are on the way! You can expect new visualization with every beta release of Kibana 4. Sunburst charts are like a multi-level pie chart. In theory they have infinite rings. Bar charts are now for more than time. Here we show file size ranges broken down by file extension. By now you may have noticed that little gray bar at the bottom of every visualization. Click it to see the data that backs the chart, and, by popular demand, for analysis elsewhere. You can also see both the elasticsearch request, and the elasticsearch response here, as well as how long the request took to process. Visualizations can be interactively searched, allowing you to modify your query as you build the chart. They can also be tied to a saved query that was created in the Discover tab. This allows you to tie one query to multiple visualizations and update a single query if you need to update the search parameters. For example, if you had several charts that deal with images you may have a query that says png OR jpg saved as \"Images\". If you start supporting animated gifs, you need only update your \u201cImages\u201d and save it for the changes to apply to any chart that is tied to the \u201cImages\u201d query. Show me more charts! Of course, you can still create amazing dashboards, but now they\u2019re even easier to create and maintain. Gone are the cluttered config dialogs. Any panel added to a dashboard can be created in the Visualize screen, saved, and reused multiple times. Much like one saved query can live on many visualizations, one saved visualization can live on multiple dashboards. If you need to update a visualization you can do it in one place, and your changes will be applied to every dashboard applicable. Further, while queries and visualizations are bound to a selected index, dashboards are not! That means you can have data from say, your users index, right next to data about your web traffic. Sales data can live next to marketing research and that can live next to the logs from your weather station, all on the same screen! And so much more We can\u2019t fit it all in a blog post, so go grab the beta and give it a shot: . If you\u2019re coming from Kibana 3 we\u2019ve put together a short FAQ that we\u2019ll be expanding on as needed: . As always, we want your feedback, we used it every single day while building Kibana 4 and we\u2019ll continue to use it every day as we make Kibana better, faster and easier. \n"}<br>{"index": {"_id": 1229}}<br>{"title":"Where in the World Is Elasticsearch? - October 06, 2014","seo_title":"","url":"\/blog\/world-elasticsearch-19","author":{"name":"Livia Froelicher"},"date":"October 06, 2014","category":"","locales":"","content":" Last week we attended Goto Aarhus where Yann Cluchey talked about the Elasticsearch use case at Cogenta. Great talk and a lot of interested folks. Check out the slides . A great turnout for Yann from talking about using \u2014 Gary Harvey (@Gshtrifork) Furthermore was on in Amsterdam - our 2nd home town. Here's a small flashback and twitter highlight of the week! How elastic is ? It's unbelievable elastic :) \u2014 Frontkom (@frontkom) So here's what's on the list for next week: Chicago - Paris - Madrid - Stockholm - Oslo - Hamburg. Read on for more! Upcoming Events North America Oct. 7th-8th: - stop by our table to pick up swag, and visit with our midwest territory manager , and Solutions Architect . Europe Oct. 7th: - will give a short talk with our partner Alterway about the and will later also present . will give an overview of the . Oct. 9th-10th: - don't miss out on our two Elasticsearch talks: 1. will give an , Thursday 9th October, 1pm. 2. will talk about , Friday 10th October, 3pm. Furthermore we have lovely and at our booth, so go say hello to them and grab a cool piece o' swag. Upcoming Meetups Europe Oct. 7th: Oct. 7th: Oct. 7th: That's it for this week, and stay tuned for Elasticsearch happenings next week. There's lots to come! - The Elasticsearch Team P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag! \n"}<br>{"index": {"_id": 1230}}<br>{"title":"Elasticsearch Testing & QA: Elasticsearch Continuous Integration","seo_title":"","url":"\/blog\/elasticsearch-testing-qa-elasticsearch-continuous-integration","author":{"name":"Isabel Drost-Fromm"},"date":"October 02, 2014","category":"Engineering","locales":"","content":" Writing tests is a crucial part of developing new features for and fixing bugs in Elasticsearch. In order to make creating these tests as easy as possible, we use a couple of techniques to help developers. Many of these are available to our downstream users as well. Elasticsearch CI Elasticsearch regularly goes through quite a few test cycles, including after each new commit and triggered on a continuous basis. After check in, the Elasticsearch code base goes through a set of automated tests (to a large extent inspired by what is run for Apache Lucene itself). On each commit, a smoke test verifies the system can be built at all, and whether basic functionality (connecting to the resulting search server, installing plugins, etc.) are possible. Builds that pass this initial sanity check are examined further. The Java Unit and Integration test suites are executed, and afterwards backwards compatibility (where applicable) is verified. Finally, the REST tests are checked. In addition to these checks, we run all Java level checks on a continuous basis on several hardware configurations and operating systems. All jobs are Jenkins managed. The key to reducing manual configuration overhead in our setting is an aggressive automation strategy. For the cloud in particular, it pays quickly to have dedicated scripts for initializing all instance types needed for testing. In our case this includes being able to spin up clusters of any topology to test various ingestion scenarios. In the remaining two blog posts, we will first walk you through the various types of tests that we run to ensure Elasticsearch works as expected. Later in the series, we'll show how we use test randomization to increase test coverage not only at the Java level but also to optimize time and hardware resources needed to check our code base on a large set of deployment configurations including but not limited to testing against various JDK versions.\" \n"}<br>{"index": {"_id": 1231}}<br>{"title":"Elasticsearch 1.4.0.Beta1 released","seo_title":"","url":"\/blog\/elasticsearch-1-4-0-beta-released","author":{"name":"Clinton Gormley"},"date":"October 01, 2014","category":"Engineering","locales":"","content":" <!--<br \/> div.itemizedlist { margin-top: -15px}<br \/> --> Today, we are happy to announce the release of\u00a0, based on . You can download them and read the full changes list here: . The theme of 1.4.0 is : making Elasticsearch more stable and reliable than ever before. It is easy to be reliable when everything functions as it should. The difficult part comes when the unexpected happens: nodes run out of memory, their performance is degraded by slow garbage collections or heavy I\/O, networks fail or transmit data erratically. This Beta release includes three major efforts to improve resiliency: Distributed systems are complex. We have an extensive test suite which creates random scenarios to try to simulate conditions that we could never imagine, but we recognise that there are an infinite number of edge cases. The changes in 1.4.0.Beta1 include all of the improvements that we have made thus far. We ask you to test these changes out in the real world and to . { \"@context\": \"http:\/\/schema.org\", \"@type\": \"Organization\", \"name\" : \"Elastic\", \"url\": \"https:\/\/www.elastic.co\/\", \"logo\": \"https:\/\/www.elastic.co\/static\/images\/elastic-logo-200.png\", \"sameAs\" : [ \"https:\/\/www.facebook.com\/elastic.co\", \"https:\/\/twitter.com\/elastic\", \"https:\/\/plus.google.com\/105178019064686397293\", \"https:\/\/www.youtube.com\/user\/elasticsearch\", \"https:\/\/www.linkedin.com\/company\/elasticsearch\" ], \"potentialAction\": { \"@type\": \"SearchAction\", \"target\": \"https:\/\/www.elastic.co\/search?q={query_string}\", \"query-input\": \"required name=query_string\" } } START Parse.ly Include: Standard (function(s, p, d) { var h=d.location.protocol, i=p+\"-\"+s, e=d.getElementById(i), r=d.getElementById(p+\"-root\"), u=h===\"https:\"?\"d1z2jf7jlzjs58.cloudfront.net\" :\"static.\"+p+\".com\": if (e) return: e = d.createElement(s): e.id = i: e.async = true: e.src = h+\"\/\/\"+u+\"\/p.js\": r.appendChild(e): })(\"script\", \"parsely\", document): END Parse.ly Include: Standard \n"}<br>{"index": {"_id": 1232}}<br>{"title":"This Week in Elasticsearch - October 01, 2014","seo_title":"","url":"\/blog\/2014-10-01-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"October 01, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Elasticsearch Core Full house at last night's DevOps Amsterdam Meetup: DrupalCon & ELK Stack StyleElasticsearch EcosystemHere's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. . and talking about at for meetup. \u2014 David Pilato (@dadoonet) Slides & VideosA great lessons learned story from Etsy, including how they're using Elasticsearch & Logstash in their new architectureAn incredibly in-depth use case shared at last week's Elasticsearch Netherlands Meetup. Thanks again for hosting us, Bol.com!An end to end tutorial on the ELK stack, including you can use as you watch Elasticsearch Aggregations Webineri Tamamland\u0131 (Video) \u2014 kodcu.com (@kodcucom) Where to Find UsWe'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Director of Developer Relations, , know!AustriaThe Vienna Elasticsearch User Group will convene tomorrow on October 2nd at 7 PM. This next meetup will focus on Elasticsearch use cases. You can to attend.BelgiumWe're a proud sponsor of the 5th anniversary of , held in its original hometown of Ghent. Elasticsearch will have a booth at the conference, so stop by and say hello to between sessions. We'll be at DevOps Days October 27-28th. ChinaZeng Yong, aka Medcl, is one of our most active community members in China. He has two upcoming talks on all things Elasticsearch: France GermanyThe code.talks conference is back in Hamburg this year on October 9th and 10th, though with a new name. (We had a great time there last year when this conference was known simply as Developer Conference EU.) will be speaking once again, along with . Here's all the Elasticsearch and ELK stack information on offer at code.talks: The week after code.talks, will be heading LinuxCon Europe in Dusseldorf, where she'll speak on the panel . The panel takes place on Wednesday, October 15th at 2:30 PM, and the conference runs October 13-15th at Congress Centre Dusseldorf.And, if you happen to be in Karlsruhe on October 16th, you can catch Patrick Peschlow on Elasticsearch Performance in a Nutshell at the Search Meetup Karlsruhe. , and the meetup will begin at 7:15 PM.Japan: Jun Ohtani will attend the in Tokyo. Jun will present on the ELK stack and why he works for Elasticsearch. Global Hack Day takes place October 3rd-5th. The NetherlandsNikolay Ignatov and Welin Welchev from Propeople will present on for Drupal. Join them on Thursday at 10:45 AM to learn all about the Elasticsearch Connector module!NorwayThe next Elasticsearch Oslo Meetup is on for October 7th at 6 PM. to save your seat. We'll get back to you with more details as soon as the meeting agenda is finalized.Poland SpainThe first ever Elasticsearch Meetup in Madrid has been scheduled! The meetup will take place on October 7th from 7:00 - 8:30 PM. Our very own will cover all things Elasticsearch. You can to save your place.SwedenTwo of our developers, and , will be visiting Sweden on October 7th. Starting at 7:00 PM, we'll convene our sixth Elasticsearch Stockholm Meetup, featuring a demo of our new high-level Python library elasticsearch-dsl and an overview of circuit breaker. You can to save your place.Switzerland will return to Soft-Shake in Geneva once again this year. He will speak on Advanced Search for Your Legacy Application in the Big Data Track. Soft-Shake takes place on October 23-24th, and David will speak in Slot 5 on Thursday.New meetup: Minneapolis on Oct. 22nd, 6:30 PM. Join us to hear ' use case. Details & reg at \u2014 Leslie Hawthorn (@lhawthorn) United States Where to Find YouOur Director of Developer Relations, Leslie Hawthorn, is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, .Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head.TrainingsIf you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1233}}<br>{"title":"Six Ways to Crash Elasticsearch","seo_title":"","url":"\/blog\/found-crash-elasticsearch","author":{"name":"Konrad Beiske"},"date":"September 30, 2014","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. As much as we love Elasticsearch, at Found we've seen customers crash their clusters in numerous ways. Mostly due to simple misunderstandings and usually the fixes are fairly straightforward. In our quest to enlighten new adopters and entertain the experienced users of Elasticsearch, we'd like to share this list of pitfalls. \n"}<br>{"index": {"_id": 1234}}<br>{"title":"Elasticsearch 1.3.4 released","seo_title":"","url":"\/blog\/elasticsearch-1-3-4-released","author":{"name":"Clinton Gormley"},"date":"September 30, 2014","category":"Engineering","locales":"","content":" Today, we are happy to announce the bugfix release of\u00a0, based on . You can download it and read the full changes list here: . Elasticsearch 1.3.4 is the latest stable release. Users of Elasticsearch 1.3.3 who have 100 or more shards per node should upgrade. For blog posts about past releases in the 1.3 branch, see: , , , . Elasticsearch 1.3.3 included a change to the management threadpool (used, amongst other things, to collect node and index statistics) to make it a fixed pool with a queue size limited to 100. The change was added to prevent a queue explosion in the case of slow statistics collection, which was experienced by some of our bigger users. Usually, collecting statistics is very fast, but a bug introduced in a previous release slowed down the file system check enough to cause a notable delay on nodes with many shards. Unfortunately, limiting the size of the management thread pool means that stats calls can fail on nodes with more than 100 shards, because the queue fills up. This release reverts the change to the management thread pool, and in a future release we will look at other ways of handling this scenario. Please , try it out, and let us know what you think on Twitter (). You can report any problems on the . \n"}<br>{"index": {"_id": 1235}}<br>{"title":"Elasticsearch 1.3.3 released","seo_title":"","url":"\/blog\/elasticsearch-1-3-3-released","author":{"name":"Clinton Gormley"},"date":"September 29, 2014","category":"Engineering","locales":"","content":" Today, we are happy to announce the bugfix release of\u00a0, based on . You can download it and read the full changes list here: . Elasticsearch 1.3.3 is the latest stable release and we recommend that all users upgrade. Some of the highlights of this release include: { \"@context\": \"http:\/\/schema.org\", \"@type\": \"Organization\", \"name\" : \"Elastic\", \"url\": \"https:\/\/www.elastic.co\/\", \"logo\": \"https:\/\/www.elastic.co\/static\/images\/elastic-logo-200.png\", \"sameAs\" : [ \"https:\/\/www.facebook.com\/elastic.co\", \"https:\/\/twitter.com\/elastic\", \"https:\/\/plus.google.com\/105178019064686397293\", \"https:\/\/www.youtube.com\/user\/elasticsearch\", \"https:\/\/www.linkedin.com\/company\/elasticsearch\" ], \"potentialAction\": { \"@type\": \"SearchAction\", \"target\": \"https:\/\/www.elastic.co\/search?q={query_string}\", \"query-input\": \"required name=query_string\" } } START Parse.ly Include: Standard (function(s, p, d) { var h=d.location.protocol, i=p+\"-\"+s, e=d.getElementById(i), r=d.getElementById(p+\"-root\"), u=h===\"https:\"?\"d1z2jf7jlzjs58.cloudfront.net\" :\"static.\"+p+\".com\": if (e) return: e = d.createElement(s): e.id = i: e.async = true: e.src = h+\"\/\/\"+u+\"\/p.js\": r.appendChild(e): })(\"script\", \"parsely\", document): END Parse.ly Include: Standard \n"}<br>{"index": {"_id": 1236}}<br>{"title":"Where in the World Is Elasticsearch? - September 29, 2014","seo_title":"","url":"\/blog\/world-elasticsearch-18","author":{"name":"Livia Froelicher"},"date":"September 29, 2014","category":"","locales":"","content":" We had a fantastic meetup premiere in Utrecht last week with 140 people attending. Thanks again to bol.com for hosting us and to R. Toma for giving a talk on \u201cScaling an ELK stack @bol.com\", it was a pleasure to be there! The are already available, too! Tonight's NL Meetup. Largest ever, first outside of Amsterdam and group up to 500 members. Woot! \u2014 Leslie Hawthorn (@lhawthorn) gave a talk last week on at PuppetConf 2014 where attendees were happy to conclude the outstanding conference with #hugops. Stay tuned to see the full recording, and thanks to our friends at Puppet for having us! Glad to see the final slide of the conf is . \u2014 Nick Lewis (@nick_lewis) This week we are once again covering the world with different events. From Aarhus to Stockholm via Bellevue and Tokyo to Vienna. Enjoy! Upcoming Events Europe Sept. 29th-30th: Goto Aarhus (Denmark) - join us for this interesting guest speaking session where Yann Cluchey is presenting how . Tuesday 30th September, 1:20pm-2:10pm. Tokyo Oct. 3rd: . Meet for a talk about the ELK stack. Upcoming Meetups North America Oct. 2nd: Europe Oct. 1st: Oct. 2nd: That's it for this week, and stay tuned for Elasticsearch happenings next week. There's lots to come! - The Elasticsearch Team P.S.: Contact us if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag! \n"}<br>{"index": {"_id": 1237}}<br>{"title":"How to write a Logstash input plugin","seo_title":"","url":"\/blog\/write-logstash-input-plugin","author":{"name":"Aaron Mildenstein"},"date":"September 26, 2014","category":"Engineering","locales":"","content":" Logstash is an event processing pipeline, which features a rich ecosystem of plugins, allowing users to push data in, manipulate it, and then send it to various backends. While there is a multitude of plugins currently available for Logstash, perhaps, the one that fits your exact needs has yet to be created. That\u2019s where you come in\u2026To that end, this tutorial is to help walk you through the process of building your own. We\u2019re going to use the source code from the plugin to go through the process of creating an input plugin for Logstash. This tutorial expects a certain amount of Ruby knowledge, but, hopefully, you will find it fairly easy to follow. Anatomy of an input plugin For this example, we\u2019ll be using the . While this is a basic plugin, the design principles and requirements apply to any input plugin. This document will refer to the source code by line (with links to the relevant block) and will show inline examples. Clicking the links will take you to highlighted parts of the code. It seems like a small thing, but please don\u2019t omit adding to the top of your input plugin. Logstash depends on things being in UTF-8, so we put this here to tell the Ruby interpreter that we\u2019re going to be using the UTF-8 encoding. A Logstash input plugin requires some parent classes that can be referenced through the indicated statements. The following statements are mandatory: You may also need the require statement if your plugin is going to obtain the local hostname by way of a call Of course, the plugin you build may depend on other code, or even gems. Just put them here along with these Logstash dependencies. Here, we\u2019ll cover many subsections one by one. : Where the action is How do I make my own plugin from this? Since you now have a good overview of how a plugin is built, and what the flow looks like, you should be able to envision your path to a plugin that does what you want. Most of what you will want to do will be in the method, or, at least, will be accessed from the method. You can write other methods, include other required gems or code, and basically get your plugin to do anything you want so long as you: Testing Write unit and integration tests to ensure that your plugin behaves as expected. Tests for existing plugins are in the Logstash code in the path in the input, codec, filter, and output directories. These files provide excellent examples from which to derive your own tests. If you would like to submit your plugin to the greater Logstash community, please be sure to include tests! A few examples of input plugin tests (ranging from simple to more complex) are: Summary This is a simple example of how you could write your own Logstash input plugin. Your final product can be as simple or as complex as your needs require. Once you find how easy it can be to write your own input plugin, you are empowered to make Logstash work for you in new and exciting ways! And once you get your new plugins working, we\u2019d love to hear about them? Just drop us a line on so we can share in your awesomeness. Happy Logstashing! \n"}<br>{"index": {"_id": 1238}}<br>{"title":"Elasticsearch Curator Version 2.0 Released ","seo_title":"","url":"\/blog\/elasticsearch-curator-version-2-0-released","author":{"name":"Aaron Mildenstein"},"date":"September 25, 2014","category":"Engineering","locales":"","content":" I am pleased to announce the immediate availability of Curator 2.0! Curator is our tool that helps your curate, or manage, your time-series indices. What's changed? So many new features were being added to Curator that it's monolithic nature was getting in the way of its future progress. As a result, Curator 2.0 now separates the from the . Because there have been some changes in the command-line flags, be sure to test with the flag. The Elasticsearch Curator Python API As the API has been separated, it is now simple to write your own scripts using the same methods that Curator uses. These methods are documented thoroughly . The Curator Script In order to preserve reverse compatibility as much as possible, installing Curator in the recommended way () continues to install an that allows Curator to be invoked with the same command. will work exactly as it did before! New Features The changes to the Elasticsearch Curator Python API aren't the only new features! Snapshots Snapshot functionality has been completely reworked to allow multiple indices per snapshot, incremental snapshots, named snapshots, and the ability to capture indices in a snapshot. Accordingly, when you wish to delete snapshots older than a given time period, Curator will now use the time the snapshot was created (as stored in the snapshot metadata) to determine its age. Prefixes and suffixes and wildcards\u2026Oh, my! In addition to prefixes, Curator now allows you to use suffixes and wildcards to determine the index pattern it should look for. Additionally, prefixes and suffixes can be empty, allowing your index name to be just a date. Curator now expects your indices to match a pattern of + + . Both and support wildcards, and can be empty. Delay after optimize I love getting feature requests and bug reports from the community. was to introduce a delay after an optimize. This delay allows your Elasticsearch cluster to quiesce before continuing with the next optimize call. Conclusion The new changes in Curator are awesome! I look forward to hearing about new ways you are using the Elasticsearch Curator API. If you run into trouble or find something we missed, please log an issue on our page. If you love Curator, please tell us about it! We love tweets with #elasticsearch in them! Curator is growing and maturing into a bigger, better project with each new release! Thanks for reading, and Happy Curating! \n"}<br>{"index": {"_id": 1239}}<br>{"title":"This Week in Elasticsearch - September 24, 2014","seo_title":"","url":"\/blog\/2014-09-24this-week-in-elasticsearch","author":{"name":"Ryan Ernst"},"date":"September 24, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch Core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. RT : Big news: is here & we're honored to be part of the inaugural module class \u2014 Puppet Labs (@puppetlabs) We celebrated our largest ever Elasticsearch Netherlands Meetup with Bol.com on Monday. Many thanks to them for hosting, and to Renzo for sharing their very detailed use case! \n"}<br>{"index": {"_id": 1240}}<br>{"title":"Celebrating Our Success: News from PuppetConf 2014","seo_title":"","url":"\/blog\/celebrating-success-news-puppetconf-2014","author":{"name":"Richard Pijnenburg"},"date":"September 23, 2014","category":"User Stories","locales":"","content":" I first began developing the Elasticsearch Puppet module at a previous employer, where I was already a huge fan of both technologies. I loved working with Puppet because it was so easy to use: its configuration language is very descriptive, making it simple to understand what you\u2019re doing under the hood. I\u2019d really enjoyed my experiments with Logstash and Elasticsearch, and started whipping up Puppet modules for both of them in my spare time, hoping to see both deployed at my workplace. These efforts led to me joining Elasticsearch to work on the Puppet modules full-time, and the rest, as they say, is history. Today, I have a great news to add to that story. If you\u2019re attending PuppetConf 2014, you\u2019ve probably heard about the brand new . I\u2019m really extremely honored and excited to share that the Elasticsearch Puppet module was selected as one of the very first modules to be Puppet Approved! The team at Puppet Labs has created the Puppet Approved program to make it easier for customers to choose modules for specific automation tasks and quickly deploy them to production. Puppet Approved modules are recommended by Puppet Labs, and meet its standards for quality composition, reliable operation, and active development. In true open source fashion, the Elasticsearch Puppet module was a personal side project turned dream job. I\u2019m thrilled to see that so many members of the Puppet community find the Elasticsearch Puppet module useful. Happy Puppetizing! \n"}<br>{"index": {"_id": 1241}}<br>{"title":"Where in the World Is Elasticsearch? - September 22, 2014","seo_title":"","url":"\/blog\/world-elasticsearch-17","author":{"name":"Livia Froelicher"},"date":"September 22, 2014","category":"","locales":"","content":" We're kicking off with a great event in our home town, San Francisco, and continue with some cool meetups on all things Elasticsearch all over Europe and in a completely new country. Curious? Read on for all the details. Upcoming Events North America Sept. 22nd: Puppet Conference San Francisco - come listen to who will be speaking on , on Wednesday from 5:10pm-6:00pm, located in Salon 7-9. If you're lucky you can still get a discount! PuppetConf is next week! WEEEE. 35% discount if you want it: \u2014 @jordansissel (@jordansissel) Upcoming Meetups Europe Sept. 22nd: Sept. 24th: Sept. 25th: Sept. 26th: Want to come hack on next week? Join us in Cambridge at free food, wifi & coffee! \u2014 Charlie Hull (@FlaxSearch) Asia Sept. 27th: That's it for this week, and stay tuned for Elasticsearch happenings next week. - The Elasticsearch Team P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag. \n"}<br>{"index": {"_id": 1242}}<br>{"title":"The Top Hits Aggregation","seo_title":"","url":"\/blog\/top-hits-aggregation","author":{"name":""},"date":"September 18, 2014","category":"Engineering","locales":"","content":" \n"}<br>{"index": {"_id": 1243}}<br>{"title":"This Week in Elasticsearch - September 17, 2014","seo_title":"","url":"\/blog\/2014-09-17-this-week-in-elasticsearch","author":{"name":"Ryan Ernst"},"date":"September 17, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Elasticsearch core Elasticsearch EcosystemHere's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases.Average UK house prices 2014. elasticsearch GeoHashGrid + Percentiles agg at work. \u2014 Mark Harwood (@elasticmark) Slides & Videos introduces the Elasticsearch .NET clientsAll things Laravel and ElasticsearchWhere to find UsWe'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Director of Developer Relations, , know! & on the ELK Stack at last week's API WorldAustriaThe Vienna Elasticsearch User Group will convene on October 2nd at 7 PM. This next meetup will focus on Elasticsearch use cases. You can .DenmarkYann Cluchey, the awesome human who organizes the Elasticsearch London User Group, will take the stage at GOTO Aarhus on Tuesday, September 30th to share his company's Elasticsearch use case. Join Yann at 1:20 PM to hear all about . GOTO Aarhus runs September 29-30th.France GermanyThe code.talks conference is back in Hamburg this year on October 9th and 10th, though with a new name. (We had a great time there last year when this conference was known simply as Developer Conference EU.) will be speaking once again, along with .Here's all the Elasticsearch and ELK stack information on offer at code.talks: The week after code.talks, Leslie Hawthorn will be heading LinuxCon Europe in Dusseldorf, where she'll speak on the panel . The panel takes place on Wednesday, October 15th at 2:30 PM, and the conference runs October 13-15th at Congress Centre Dusseldorf.The NetherlandsYou can join us next Monday, September 22nd for our first ever Elasticsearch Netherlands Meetup in Utrecht! The fine folks at Bol.com will share all about how they use the ELK stack and have scaled it out to easily process a daily volume of 300M log events and 185 GB of data. to attend.Can't join us in person? No problem. Thanks to our friends at Bol, the event will be livestreamed.Save the date & watch this space: next NL meetup will be livestreamed at (22 Sept, starting @ 19 CEST) \u2014 Leslie Hawthorn (@lhawthorn) We're also super excited that this year's will be in our hometown of Amsterdam on Sept. 29th - Oct. 3rd. will be out and about in the hallway track, so make sure to say hello to her! There are also some great talks on all things Elasticsearch and the ELK stack on offer from these Drupalistas: NorwayThe next Elasticsearch Oslo Meetup is on for October 7th at 6 PM. to save your seat. We'll get back to you with more details as soon as the meeting agenda is finalized.SerbiaPatrick Peschlow from our partner firm codecentric AG will take the stage at the 2nd Annual Coding Serbia Conference on September 25th. Join him at 8:00 PM to learn how you can go from .SpainThe first ever Elasticsearch Meetup in Madrid has been scheduled! The meetup will take place on October 7th from 7:00 - 8:30 PM. Our very own will cover all things Elasticsearch. You can to save your place.SwedenThe fifth Elasticsearch Stockholm Meetup is on for October 1st at 5:30 PM. The agenda will be posted shortly, but in the meantime to ensure there's a seat for you.United KingdomPlease join the folks from the Enterprise Search Cambridge group for a full day Elasticsearch hackathon on September 26th! You can to attend.United States Where to Find YouOur Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, .Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head.TrainingsIf you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1244}}<br>{"title":"NEST and Elasticsearch.NET 1.1 released!","seo_title":"","url":"\/blog\/nest-elasticsearch-net-1-1-released","author":{"name":"Martijn Laarman"},"date":"September 16, 2014","category":"Engineering","locales":"","content":" It's been a while since we released the of the NEST & .NET clients for Elasticsearch. In the meantime, we've done two releases, as most of our efforts have focused on getting out the door.And, here you have it - all that's new in NEST and Elasticsearch.NET.Map all the APIs!We are very pleased to announce that we now support the API's that are exposed in Elasticsearch 1.3.2! And NEST now also supports of the .The only APIs still missing from NEST are the Search Template related APIs. While we are pretty far in spiking a nice way to support mustache templates using C#, we decided to let it bake a while longer instead of rushing it into this 1.1 release.We've also exposed the internal on the NEST and Elasticsearch.NET clients so that you can hit any URL while still taking advantage of the cluster failover and built-in response handling. This new feature will come in handy when calling Elasticsearch plugin APIs.Map all the aggregations!We've added support for the following aggregations: Loads of miscellaneous improvementsWe've also improved our API coverage for existing APIs in tons of places and fixed several bugs. Please have a look at our complete changelog .We have to give a special shoutout to who sent a total of 8 pull requests improved our multifield mapping API in a backwards compatible fashion. Thanks to Patric's work, the multifield mapping API more closely resembles the new way of mapping properties.Future plansWhile we are very pleased to release 1.1, we can not sit still while our colleagues working on Elasticsearch are moving at such an incredible pace. The list of will be our main focus for the 1.2 release. We'll also be going over all the existing APIs in a very rigorous manner to see if there are features that have been updated that we've missed.As always please don't hesitate to submit your questions\/suggestions\/issues to either or . \n"}<br>{"index": {"_id": 1245}}<br>{"title":"Scripting with Elasticsearch","seo_title":"","url":"\/blog\/found-scripting-elasticsearch","author":{"name":"Njal Karevoll"},"date":"September 16, 2014","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud.Scripting is an important part of the toolbox of any Elasticsearch user, and enables evaluating custom expressions that may be used to synthesize fields or provide customized scoring. In this post we take a brief look at the upcoming changes to the scripting module and the different scripting languages available to use today. In a recent about scripting, Elasticsearch outlined some coming changes to its scripting support. The two important takeaways from that post is that the sandboxing story of scripts will be improved and that the default scripting language will be changed from MVEL to Groovy. Let\u2019s take a look at the current official scripting languages. \n"}<br>{"index": {"_id": 1246}}<br>{"title":"Where in the World Is Elasticsearch? - September 15, 2014","seo_title":"","url":"\/blog\/world-elasticsearch-16","author":{"name":"Livia Froelicher"},"date":"September 15, 2014","category":"","locales":"","content":" You can guess yourself from the map. Not good at Geography? Well then, read on to find out what exciting places we'll be visiting... ...but before you do that, here's our favorite tweets from last week's events: 1. with on files, data structures and their usage in Elasticsearch: Once again, rocking another meetup at hosted by \u2014 George P. Stathis (@gstathis) 2. with and his live streaming session on : will now talk about how get your information actionable \u2014 Findwise (@Findwise) Upcoming EventsEurope Sept. 19th: JUG Summer Camp 2014, La Rochelle, France - come say hi to and listen to his talk on , 16:15-17:15. Upcoming MeetupsNorth America Sept. 15th: Sept. 18th: Asia Sept. 16th: That's it for this week, and stay tuned for Elasticsearch happenings next week. We've got big things coming up in San Francisco and we'll have a our first ever Dutch Elasticsearch meetup happening in Utrecht! - The Elasticsearch Team P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag! \n"}<br>{"index": {"_id": 1247}}<br>{"title":"ZooKeeper - The King of Coordination","seo_title":"","url":"\/blog\/found-zookeeper-king-of-coordination","author":{"name":"Konrad Beiske"},"date":"September 14, 2014","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud.Let's explore Apache ZooKeeper, a distributed coordination service for distributed systems. Needless to say, there are plenty of use cases! At Found, for example, we use ZooKeeper extensively for discovery, resource allocation, leader election and high priority notifications. In this article, we'll introduce you to this King of Coordination and look closely at how we use ZooKeeper at Found. \n"}<br>{"index": {"_id": 1248}}<br>{"title":"#BYODemos: New York City Traffic Incidents","seo_title":"","url":"\/blog\/byodemos-new-york-city-traffic-incidents","author":{"name":"Dimitri Marx"},"date":"September 12, 2014","category":"User Stories","locales":"","content":" For the introduction of Elasticsearch #BYODemo environment, please check out our announcement .Background This status quo is unacceptable. The City of New York must no longer regard traffic crashes as mere \u2018accidents,\u2019 but rather as preventable incidents that can be systematically addressed. No level of fatality on city streets is inevitable or acceptable. This Vision Zero Action Plan is the City\u2019s foundation for ending traffic deaths and injuries on our streets. The City will use every tool at its disposal to improve the safety of our streets.\u201d From NYC.gov\u2019s Before making major public policy decisions based on anecdotal information that may cost significant taxpayer money based on anecdotal information, are there tools available to analyze data to identify patterns and trends then drill down into details in motor vehicle collisions? Can we get answers to questions such as: In less than an hour, we can set up Logstash, Elasticsearch, and Kibana (ELK) to start asking these questions. With our search capabilities, powerful APIs, and visualizations, it\u2019s possible to calculate totals, counts, averages and have a very interactive experience with your data. And if you don\u2019t know what to ask, you can use aggregations to discover aspects and anomalies of the data.Getting startedAfter following , you should see the following dashboard in your browser.By clicking on the rows , several stats panels will be opened, displaying statistics for deaths and injuries at a glance.The row accommodates a hits panel displaying the varying reasons lives are lost in combination with an automobile accident.In the row you will find the same for injuries.We have setup a number of different panels to show the many different ways you can visualize and interact with the data in Kibana. We encourage you to expand each row and learn more about the data and how to visualize it in Kibana.Discovering the uncommonly commonBy clicking the row , a histogram for all accident types over the time will be displayed.There are several spikes indicating some unusual behavior in our data. But which events and accident types are responsible for these? Can we find the reason among our all-time top 5 accident types? Let us open the row and see if we can answer this question.By looking at the the top 5 accident types: , , , , in the histogram it becomes clear that these events are not necessarily the major factors for most of the spikes. How can we find out what the top contributing factors for these time periods are?Let us zoom into the time around March 1, 2013 on the histogram (just span a rectangle with the mouse around the spike).Now let us see the top accidents types for the selected time range. In doing so, we can refer to the terms panel in the row .There is a change of order. Suddenly, a new accident type is appearing among the top 5 \u2013 . Is this the accident type responsible for the spike in accidents reported? If yes, we would see some correlation of spikes between all events and this particular accident type. To confirm this, we are going to modify the histogram . By clicking on the cog symbol in the top right corner, a setting dialog will be displayed.Please open the tab called and activate by clicking on it. Now click on the Save button. The histogram should look like this.The correlation of all events and accidents of the type at the February 9, 2013 looks like this.Let\u2019s have a look at this eye-catching behavior. After selecting the time frame around this spike and removing all events query, we get something like this.Since we are looking at the query for , we assume that the reason for this unusual event is due to some changed weather conditions.By doing some research, we discover that on February 9, 2013, the storm unofficially called or \u201cBlizzard of 2013\u201d developed strong activity over NYC and other parts of the East Coast. It was snowing, freezing cold, and streets got slippery, no wonder there was a spike in accidents caused by slippery pavement! Image of the the nor\u2019easter on February, 2013 (source: )By the way: Are there places that are more dangerous than others?Let\u2019s see if there are any areas of NYC that are more likely to have slippery streets (on the January 21st, 2014 \u2013 another date with a spike in activity). The pie chart suggests that the most accidents happened in Queens followed by Manhattan, Brooklyn, the Bronx, and Staten Island.Let us have a closer look at Queens by clicking on the corresponding part of the pie chart and analyze the distribution of the accidents on the map . The map suggests that all events are almost evenly distributed across Queens and the limited slice of the data we\u2019re looking at prevents us from making any clear conclusions on specific danger areas.We can broaden our analysis by expanding the search and removing all filters to look at the entire data set for Queens. Now, some locations in Queens indicate multiple accidents. In the example below, we can observe seven accidents at the junction of Queens Blvd. and Skillman Avenue. With this information, the city may want to consider implementing safety measures at that particular location.Understanding where and why fatal accidents occurIt is in the interest of every modern city to make roads safer. One way to achieve this goal is to understand why and where accidents happen.Let us have a look at the overall statistics for deaths over all accidents types. By clicking at the row , some stats panels will be displayed exhibiting the number of killed people by category.Let us now analyze geographic distribution of accidents with deadly outcome. For doing so, we will modify the query . Please unpin the query.After unpinning, an input field will be displayed.In the input field, an arbitrary query can be entered and issued. To restrict the dataset to the events with a deadly outcome, please enter .Let us go back to to the pie chart . It should look like this, suggesting that the most accidents with deadly outcome happen to be in Brooklyn followed by Queens, Manhattan, Bronx and Staten Island.Let us check the distribution on a map and see if there are any \u201chot spots\u201d.It looks like that the accidents are evenly distributed and there is no particular hot spot. Another observation you can make by zooming into the map, is that the many accidents happen on a road junction. Checking the contribution factors and if ignoring the numbers for unspecified events, it it gets evident that is the top contribution factor followed by and .By the way, is among the all-time top three factors for all accidents. It seems that NYC needs to address this issue in particular.SummaryIt is said that a picture is worth a thousand words. We believe this is true. That is the one of the reasons why we\u2019re proud of what the ELK stack (Elasticsearch, Logstash, Kibana) can do.This New York City traffic incidents demo is the first of a series of demos we hope to publish in the coming months to show how easy it is to perform meaningful analysis on data using Elasticsearch, Logstash and Kibana. In this post, we presented you with some ideas on how to get started with experimenting with this data set, but we encourage you to explore further \u2014 brainstorm to generate interesting questions you want to ask of the data and experiment with the various features in Kibana to start getting answers to those questions. If you find anything interesting or have feedback you\u2019d like to share with us, we\u2019d love to hear it either via or on \u2013 just make sure to use the hashtag #BYODemos.This blog and associated demo was a collaborative effort and certainly would not have been possible with out help from my colleagues , , and Christian Dahlqvist. \n"}<br>{"index": {"_id": 1249}}<br>{"title":"BYOD (Bring Your Own Demo)","seo_title":"","url":"\/blog\/bring-your-own-demo","author":{"name":"Steve Mayzak"},"date":"September 10, 2014","category":"News","locales":"","content":" There are so many great examples of community members using the powers of Elasticsearch, Logstash, and Kibana (the ELK stack) to get meaningful insights from data. From companies: The list goes on and on. At Elasticsearch, we're continually inspired and amazed at the creative ways companies are using our software stack to extract meaningful value from their data. It should come as no surprise that we also work hard on finding insights in many publicly available data sets in order to put our products to the test. Unfortunately, as of yet, we haven\u2019t had a great collaborative way to share this work with the community and for you to share with each other. That changes now!Start Your EnginesWe are delighted to announce a new repository in GitHub under \u00a0where we will begin sharing easy-to-use demos of the ELK stack for everyone to enjoy, enhance, and contribute back with the goal of greater education. These demos will include all Logstash configs, plus Kibana dashboards and custom settings in Elasticsearch to make them a great, real-world starting point for those of you looking to kickstart an internal project. We aren\u2019t going to limit this repo to just us, though. If you have come across a great public dataset and want to contribute a demo to the repo, please do. You can also post an issue in the repo with a link and description of a dataset you would like to see turned into a demo eventually. While we probably won\u2019t be able to get to all of them, we promise to do our best!Under the HoodWith the goal of making your demo-playing experience as pain-free as possible, we have come up with a simple process and structure. We will adhere to this structure for all the demos we create and ask that you do the same. That said, if you have suggestions for improvement, we're ready and eager to listen via email at or .The FrameworkFirst, we wanted the 'getting started process' to be as simple and quick as possible. Second, we wanted the demos to run in a self-contained environment. With this in mind, we\u2019ve decided to combine Vagrant, Virtual Box, and Puppet, with Snapshots (a feature we introduced in Elasticsearch 1.0) to help you download, install, configure, and run the full ELK stack. Every time we release a demo, we will accompany it with a blog post with instructions and details about the insights we gained from it. The instructions will also be part of the .: If you'd rather not setup a VM and understand how to restore a snapshot using our REST API, by all means, clone the repo and just restore the snapshot. In that case, there's no need for Vagrant or Virtual Box. If you decide to go this route, please do it in a fresh install of Elasticsearch rather than an existing one to keep things simple. We don't want to overwrite anything you've already been working on.As of now, we\u2019ve tested this on a lot of Mac\/Linux laptops and a bit on Windows, so if you have issues with your particular OS, please let us know and we will get things fixed or, if need be, make recommendations on alternatives. For Windows in particular, the first demo we publish will have specific instructions so keep an eye out for those.Feel Free to Take the wheelWe hope you enjoy this new project and please don't hesitate to contribute your own hard work for everyone else to benefit from and build upon. \n"}<br>{"index": {"_id": 1250}}<br>{"title":"This week in Elasticsearch - September 10, 2014","seo_title":"","url":"\/blog\/2014-09-10-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"September 10, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core awesome presentation with real life use case demo by at \u2014 Colin Surprenant (@colinsurprenant) Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. All set for the meetup tonight \u2014 Boaz Leskes (@bleskes) Slides & Videos At last night's Elasticsearch Boston Meetup, EverTrue shared their use case All things Elasticsearch & Python from last week's An Introduction to Elasticsearch and Kibana (\u65e5\u672c\u8a9e\u3067) From last week's DevOps Ireland Meetup: Making sense of your data using the ELK stack Thursday, September 11th from 10:00 - 17:00 CEST \n"}<br>{"index": {"_id": 1251}}<br>{"title":"Where in the World Is Elasticsearch? - September 08, 2014","seo_title":"","url":"\/blog\/world-elasticsearch-15","author":{"name":"Livia Froelicher"},"date":"September 08, 2014","category":"","locales":"","content":" In short: Boston, Copenhagen, Florida, Oslo and San Francisco! :) Wanna know what's going on in all these cities? Read on for the full overview (but before that, we would love to share a few impressions from last week's happenings): 1. with and All things and by ! \u2014 Livia Froelicher (@LivFroe) Search terms related to \"gun\" - produced by significant terms + graphing aggs on entity-centric index. \u2014 Mark Harwood (@elasticmark) 2. with getting ready for the Irish crowd All set for the meetup tonight \u2014 Boaz Leskes (@bleskes) Upcoming Events North America Sept. 11th-13th: , join for his keynote session on , Saturday 13th, 17:20-18:30 . Also on Saturday at 15:40 is session, which is an . Europe Sept. 9th-11th: , attend workshop , Tuesday 9th, 13:30-17:30. Sept. 11th: , sign up and listen to talking about , Conference runs from 10:00-17:00. Upcoming Meetups North America Sept. 9th: Sept. 9th: Europe Sept. 8th: - Casual style That's it for this week, and stay tuned for Elasticsearch happenings next week. - The Elasticsearch Team P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag! \n"}<br>{"index": {"_id": 1252}}<br>{"title":"Performance Considerations for Elasticsearch Indexing","seo_title":"","url":"\/blog\/performance-considerations-elasticsearch-indexing","author":{"name":"Michael McCandless"},"date":"September 03, 2014","category":"Engineering","locales":"de-de,fr-fr,ja-jp,ko-kr","content":" Elasticsearch users have delightfully diverse use cases, ranging from appending tiny log-line documents to indexing Web-scale collections of large documents, and maximizing indexing throughput is often a common and important goal. While we try hard to set good general defaults for \"typical\" applications, you can quickly improve your indexing performance by following a few simple best practices, described here. To begin with, do not use a very large java heap if you can help it: set it only as large as is necessary (ideally no more than half of the machine's RAM) to hold the overall maximum working set size for your usage of Elasticsearch. This leaves the remaining (hopefully sizable) RAM for the OS to manage for IO caching. Make sure the OS is not . Upgrade to the most recent Elasticsearch release (): numerous indexing related issues have been fixed in recent releases. Before delving into the details, a caveat: remember that all the information here is up-to-date as of today (), but as Elasticsearch is a fast moving target, this information may no longer be accurate when you, future Googler, come across it. If you are unsure, just . is especially useful when tuning your cluster for indexing throughput: as you iterate on each setting described here you can easily visualize the impact of each change on your cluster's behavior. Client side Always use the , which indexes multiple documents in one request, and experiment with the right number of documents to send with each bulk request. The optimal size depends on many factors, but try to err in the direction of too few rather than too many documents. Use concurrent bulk requests with client-side threads or separate asynchronous requests. Before you conclude indexing is too slow, be sure you are really making full use of your cluster's hardware: use tools like , and to confirm you are saturating either CPU or IO across all nodes. If you are not then you need more concurrent requests, but if you hit from the java client, or HTTP response from REST requests, then you are sending too many concurrent requests. If you are using , you can see the rejection counts under the section of the . It is usually not a good idea to increase the bulk thread pool size (defaults to the number of cores) as that will likely decrease overall indexing throughput: it is better to decrease client-side concurrency or add more nodes instead. Since the settings we discuss here are focused on maximizing indexing throughput for a single shard, it is best to first test just a single node, with a single shard and no replicas, to measure what a single Lucene index is capable of on your documents, and iterate on tuning that, before scaling it out to the entire cluster. This can also give you a baseline to roughly estimate how many nodes you will need in the full cluster to meet your indexing throughput requirements. Once you have a single shard working well, you can take full advantage of Elasticsearch's scalability and multiple nodes in your cluster by increasing the shard count and replica count. Before drawing any conclusions, be sure to measure performance of the full cluster over a fairly long time (say 60 minutes), so your test covers the full lifecycle including events like large merges, GC cycles, shard movements, exceeding the OS's IO cache, possibly unexpected swapping, etc. Storage devices Unsurprisingly, the storage devices that hold the index have a huge impact on indexing performance: Segments and merging Under the hood, newly indexed documents are first held in RAM by Lucene's . Periodically, when the RAM buffer is full, or when Elasticsearch triggers a flush or refresh, these documents are written to new on-disk segments. Eventually there are too many segments, and they are merged according to the . This process cascades: the merged segments produce a larger segment, and after enough small merges, those larger segments are also merged. of how this works. Merges, especially large ones, can take a very long time to run. This is normally fine, because such merges are also rare, so the amortized cost remains low. But if merging cannot keep up with indexing then Elasticsearch will (as of 1.2) to prevent serious problems when there are far too many segments in the index. If you see INFO level log messages saying or you see segment counts growing and growing in then you know merges are falling behind. Marvel plots the segment count under the section of the , and it should grow at a very slow logarithmic rate, perhaps showing a saw-tooth pattern as large merges complete: Why would merges fall behind? By default, Elasticsearch limits the allowed aggregate bytes written across all merges to a paltry 20 MB\/sec. For spinning disks, this ensures that merging will not saturate the typical drive's IO capacity, allowing concurrent searching to still perform well. But if you are not searching during your indexing, search performance is less important to you than indexing throughput or your index is on SSDs, you should disable merge throttling entirely by setting to : see for details. Note that prior to 1.2, there was a nasty bug that . Upgrade! If you are unfortunately still using spinning disks, which do not handle concurrent IO nearly as well as SSDs, then you should set to 1. Otherwise, the default value (which favors SSDs) will allow too many merges to run at once. Do not call on an index that is still being actively updated, since it is a very costly operation (it merges all segments). However, if you are done adding documents to a given index, it is a good idea to optimize it at that point, since that will reduce resources required during searching. For example, if you are using time-based indices where each day's worth of logs is added to a new index, once that day has passed, it is a good idea to optimize the index, especially if nodes will hold many days worth of indices. Here are some further settings to tune: Index buffer size If your node is doing only heavy indexing, be sure is large enough to give at most ~512 MB indexing buffer per active shard (beyond that indexing performance does not typically improve). Elasticsearch takes that setting (a percentage of the java heap or an absolute byte-size), and divides it equally among the currently active shards on the node : larger values means Lucene writes larger initial segments which reduces future merge pressure. The default is which is often plenty: for example, if you have 5 active shards on a node, and your heap is 25 GB, then each shard gets 1\/5th of 10% of 25 GB = 512 MB (already the maximum). After dedicated heavy indexing, lower this setting back to its default (currently ) so search-time data structures have plenty of RAM to use. Note that this is not yet a dynamic setting: there is an . The number of bytes currently in use by the index buffer was added to the in 1.3.0. You can see it by looking at the value. This is not yet plotted in Marvel and will be added in the coming version, but you can add a chart yourself (Marvel still collects the data). Coming in 1.4.0, the also shows exactly how much RAM buffer was allocated to each active shard as . To see these values per-shard for a given index, use the : this will return the stats per shard as well as the totals across all shards. Use auto id or pick a good id If you do not care what your documents have, : this case (as of 1.2) to save an ID and version lookup per document, and you can see the performance difference in Elasticsearch's (compare the and lines). If you do have your own ids, try to if that is under your control, and upgrade to at least 1.3.2 since there were to id lookup. Just remember that java's is the worst choice for an id because it has no predictability or pattern on how ids are assigned to segments, causing a in the worst case. You can see the difference in indexing rate as reported by when using : versus using fully random UUIDs: Coming in 1.4.0, we have switched Elasticsearch's auto-generated IDs . If you are curious about the low-level operations Lucene is doing on your index, try (available in 1.2). This produces very verbose output but can be helpful to understand what is happening at the Lucene level. The output is very low-level: provides a much better real-time graphical view on what is happening to the index. Scaling out Remember, we focused here on tuning performance for a single shard (Lucene index) but once you are happy with that, where Elasticsearch really shines is in easily scaling out your indexing and searching across a full cluster of machines. So be sure to increase your shard count again (the default is currently 5), which buys you concurrency across machines, a larger maximum index size, and lower latency when searching. Also remember to increase your replicas to at least 1 so you have redundancy to hardware failures. Finally, if you are still having trouble, , e.g. through the . Maybe there is an exciting bug to fix (patches are always welcome!). \n"}<br>{"index": {"_id": 1253}}<br>{"title":"This Week in Elasticsearch - September 03, 2014","seo_title":"","url":"\/blog\/2014-09-03-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"September 03, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch Core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. If you use Elasticsearch with Laravel, I've got a package (beta) that integrates ES types with Laravel models: \u2014 Adam Fairholm (@adamfairholm) L'usine logicielle de Voyages-SNCF. Avec du dedans :) \u2014 David Pilato (@dadoonet) Slides & Videos Great overview of the ELK stack for logging & data visualization For all you PaaS lovers out there, check out how to use the ELK stack on OpenShift Origin Great exploration of using the ELK stack and other tools to monitor your infrastructure \n"}<br>{"index": {"_id": 1254}}<br>{"title":"This Week in Elasticsearch - August 27, 2014","seo_title":"","url":"\/blog\/2014-08-27-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"August 27, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Elasticsearch core In case you've missed the webinar, the recording is available here: Enjoy! \u2014 Costin Leau (@costinl) Elasticsearch EcosystemHere's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Definitive Guide goes to the printers Sept 1. Get 50% off now at \u2014 Clinton Gormley (@clintongormley) Slides & VideosNew to Elasticsearch? Rick Winfrey introduces you to its features, with great getting started code examples in Ruby. Thanks Rick! treats us to walk through of the options of determining search quality & how Elasticsearch can help you in your questRafael Lopes on all things Elasticsearch, AWS & High Availability at the recent Elasticsearch Brasil Meetup . But we can't claim credit for this one. \n"}<br>{"index": {"_id": 1255}}<br>{"title":"Using the Percolator for Geo Tagging","seo_title":"","url":"\/blog\/using-percolator-geo-tagging","author":{"name":"Alexander Reelsen"},"date":"August 26, 2014","category":"Engineering","locales":"","content":" \n"}<br>{"index": {"_id": 1256}}<br>{"title":"Elasticsearch Training Comes to India","seo_title":"","url":"\/blog\/elasticsearch-training-comes-to-india","author":{"name":"Justin Hoffman"},"date":"August 26, 2014","category":"","locales":"","content":" We feel very lucky that thousands of businesses worldwide continue to adopt Elasticsearch, Logstash and Kibana for uses that start as simple as full-text search, all the way up to performing powerful, real-time analytics for log analysis, fraud detection, digital forensics among a plethora of other use cases. In order to set up their implementations for success and resolve known issues faster, we support our users by offering subscriptions to get direct access to our engineers for guidance on topics such as security considerations, proper architecting, sizing, performance optimization and integrations. But the first step in this process actually starts with training. Our training courses go over the ins and outs of our technology including the ELK stack, helping attendees understand the basics of distributed search application development and the various use cases our products can help with. Today, we\u2019re thrilled to announce we will be bringing our training courses to India thanks to our new partnership with SpringPeople. SpringPeople is a leader in corporate training within India for high-end and emerging technologies. They currently work with market leaders like EMC, MuleSoft, Typesafe and VMware - and we\u2019re thrilled to join the ranks. The first Core Elasticsearch course will be held on 24\/25 September and ELK Workshop on 26 September. Secure your spot today - they go quick! - at . \n"}<br>{"index": {"_id": 1257}}<br>{"title":"Where in the World Is Elasticsearch? - August 25, 2014","seo_title":"","url":"\/blog\/world-elasticsearch-14","author":{"name":"Livia Froelicher"},"date":"August 25, 2014","category":"","locales":"","content":" Last week we came back from summer break and kicked it off with a great talk about \u201cElasticsearch Architectures in the Wild\" at the in Kansas. . dropping some serious knowledge about ELK at the meetup \u2014 DevOps Kansas City (@DevOpsKC) The next couple of weeks are calming down a bit so we are gearing up for what's to come in the next couple of months. Little teaser: The Nordics and Florida. :) Stay tuned and read on for this and next week's events, hopefully one is happening in a city near you! Upcoming Events Europe Sept. 4th: , listen to talking about . Upcoming Meetups Europe Aug. 26th: Sept. 3rd: That's it for this week, and stay tuned for Elasticsearch happenings in two weeks. - The Elasticsearch Team P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag! \n"}<br>{"index": {"_id": 1258}}<br>{"title":"This week in Elasticsearch - August 20, 2014","seo_title":"","url":"\/blog\/2014-08-20-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"August 20, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Slides & Videos Jeffrey Sogolov on the ELK Stack (and how it can save you millions of dollars!) Our very own Alex Ksikes on multimedia search, matching procedures and a little bit of Apache Lucene on the side gives you all the news you can use on the latest features in Elasticsearch Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Community Manager, , know! Germany If you're heading to on August 23rd & 24th, we're happy to bring you bouncy castle & ball pool love this year. And make sure to see on . United Kingdom Please join the folks from the Enterprise Search Cambridge group for a full day Elasticsearch hackathon! You can to attend. United States Where to Find You Our Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1259}}<br>{"title":"Optimizing Elasticsearch Searches","seo_title":"Optimizing Elasticsearch Searches","url":"\/blog\/found-optimizing-elasticsearch-searches","author":{"name":"Alex Brasetvik"},"date":"August 19, 2014","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. Simple Suggestions for Speedier Searches Elasticsearch can query, filter and aggregate in many ways. Often there are several ways to solve the same problem \u2013 and possibly with very different performance characteristics. This article will cover some important optimizations that can buy you a lot of performance. \n"}<br>{"index": {"_id": 1260}}<br>{"title":"Where in the World Is Elasticsearch? - August 18, 2014","seo_title":"","url":"\/blog\/world-elasticsearch-13","author":{"name":"Livia Froelicher"},"date":"August 18, 2014","category":"","locales":"","content":" Elasticsearchers are back, fully tanked up with sun and energy, and ready for some conferences and meetups this week. We hope you all had a lovely summer break, too! Before we get to the events, we would first like to congratulate our #ELKsintheWild competition winner, . For those who missed the competition, here's a short recap: everybody in possession of one of our cute plushy ELKs could take part by taking a picture during the summer holidays and sharing it via Twitter tagging #ELKsintheWild. The best picture wins an Elasticsearch surprise. Thank you Ricky for participating and sharing that very sweet Tweet with us. Expect an Elasticsearch package in your mailbox soon! :) Thank you ! My Elks arrived and have met the monkeys and are ready for adventures \u2014 Ricky Moorhouse (@rickymoorhouse) Now check out our events and meetups taking place next week, hopefully one is happening in a city near you. Upcoming Events North America Aug. 20th-22nd: , come by and listen to speaking on a panel about or sign up for her workshop on . Europe Aug. 23rd-24th: , meet at our small booth over lunch time and visit her talk about on Sunday 24th, 10am @ room HS1. Upcoming Meetups North America Aug. 20th: South America Aug. 19th: That's it for this week, and stay tuned for Elasticsearch happenings next week. - The Elasticsearch Team P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag! \n"}<br>{"index": {"_id": 1261}}<br>{"title":"Getting Started with LIRE and Elasticsearch","seo_title":"","url":"\/blog\/found-getting-started-with-lire-and-elasticsearch","author":{"name":"Konrad Beiske"},"date":"August 15, 2014","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. Search for Images Using ImagesLIRE (Lucene Image REtrieval) is a plugin for Lucene to index and search images. A cool and quirky feature that sets it apart is that it does content based retrieval, a fancy word for saying that you use images in your search query and it retrieves similar images from the index. In order to use LIRE with Elasticsearch, we need to make Elasticsearch aware of the new data type and the query that is provided by LIRE. Luckily there is a plugin for Elasticsearch that does just that. \n"}<br>{"index": {"_id": 1262}}<br>{"title":"Elasticsearch Hadoop 2.0.1 and 2.1.Beta1 Released","seo_title":"","url":"\/blog\/es-hadoop-2-0-1-and-2-1-beta1","author":{"name":"Costin Leau"},"date":"August 14, 2014","category":"Engineering","locales":"","content":" I am happy to announce Elasticsearch for Apache Hadoop releases and 2.0.1 is the latest release, that fixes several bugs, improves compatibility across various Hadoop distributions and also tracks the latest library updates. 2.1.Beta1 is the first release from the development branch focused mainly on the , in the Hadoop ecosystem: in particular Beta1 provides integration with Apache Spark support Elasticsearch for Apache Hadoop 2.0 added , through its Map\/Reduce functionality. Beta1 goes that, providing a dedicated Spark (or Resilient Distributed Dataset) for Elasticsearch, for both Java and Scala. Thus, one can easily execute searches in Elasticsearch and transparently feed the results back to Spark for transformation. For example, using the artists example from the , counting the performers starting with \u201cme\u201d is a one-liner: import org.elasticsearch.spark._ val sc = new SparkContext(new SparkConf()) val number = sc.esRDD(\"radio\/artists\", \"?me*\").count() Dedicated Java and Scala APIs In Beta1, with the introduction of the Spark module, Elasticsearch for Apache Hadoop has grown beyond Java and is also using as a language (as Apache Spark itself is written in Scala). As such, one will find the typical Scala patterns (like \u2013 gotta love the name) in place as well as support for and objects as returned by the . However, Java users are not forgotten, the Spark module provides a dedicated for Java which returns <code>java.util collections and proper JDK types \u2013 the equivalent of its Scala brethren, but for Java. Since the infrastructure is the same, one will get the same end result regardless of the which API is used. In fact, the two APIs are fully compatible and one can even use both in the same application, at the same time. To wit, here\u2019s an example of the Java RDD leveraging Java 8 lambda expressions for conciseness, to filter some entries (please ignore the fact one and do the filtering directly through Elasticsearch): import org.elasticsearch.spark.java.api.JavaEsSpark: JavaSparkContext jsc = ... JavaRDD<Map<String, Object>> esRDD = JavaEsSpark.esRDD(jsc, \"radio\/artists\", \"?me*\"): JavaRDD<Map<String, Object>> filtered = esRDD.filter( m -> m.values().stream().filter(v -> v.contains(\"mega\"))): Notice how the returned collection is used as is, without any conversion of any sort. Index arbitrary s to Elasticsearch In a similar vein, through the Spark module can be saved to Elasticsearch as long as its structure maps to a document (one can easily transform the data or plug her own serializer if needed): val game = Map(\"media_type\"->\"game\",\"title\" -> \"FF VI\",\"year\" -> \"1994\") val book = Map(\"media_type\" -> \"book\",\"title\" -> \"A Clash of Kings\",\"year\" -> \"1999\") val cd = Map(\"media_type\" -> \"music\",\"title\" -> \"Surfing With The Alien\") val sc = new SparkContext(...) sc.makeRDD(Seq(game, book, cd)).saveToEs(\"my-collection\/{media-type}\") The attentive user may have noticed the pattern usage in the index definition \u2013 the Spark module supports all the functionality of es-hadoop such as above, writing of , scripting or customizing the . In fact, all the options are supported as the underlying code-base is the same \u2013 whether you are using Java, Scala or the Map\/Reduce layer. Modular design \u2013 pick only what you need While part of Elasticsearch for Apache Hadoop, the Spark module is self-contained and can be used either itself or alongside the , <code>Hive, and <code>Cascading integrations. One can use it in or against a YARN cluster. We cannot wait to get your on 2.1.Beta1 \u2013 you can find it in the and the new features explained in the . And by the way, if you are interested in data exploration, search, and identifying anomalies in real-time on your Hadoop data, you are warmly invited to our upcoming webinar hosted by yours truly, next week, on Wednesday, August 20th. The webinar will showcase some of the ways in which Elasticsearch for Apache Hadoop can help. Please . \n"}<br>{"index": {"_id": 1263}}<br>{"title":"This Week in Elasticsearch - August 13, 2014","seo_title":"","url":"\/blog\/2014-08-13-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"August 13, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch Core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Slides & Videos Are you a Pythonista? Then you are really going to want to watch our resident Python expert in this presentation from the recent in Berlin. Did Honza's talk not quite satiate your weekly need for all things Python? Don't worry, we've got this special presentation from community member at EuroPython last month that will hopefully do the trick. A ToDo List: 1) Visit Booth 202: 2) Pick up cool leather notebook: 3) Watch demo \u2014 elasticsearch (@elasticsearch) Where to Find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Community Manager, , know! Germany If you're heading to on August 23rd & 24th, we're happy to bring you bouncy castle love this year. And make sure to see on . United States Heading to Chicago for LinuxCon and Cloud Open North America? Say hello to , and Empowering Your Corporate Open Source Software Developers. Where to Find You Our Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1264}}<br>{"title":"Elasticsearch 1.3.2 and 1.2.4 Released","seo_title":"","url":"\/blog\/elasticsearch-1-3-2-released","author":{"name":"Clinton Gormley"},"date":"August 13, 2014","category":"Engineering","locales":"","content":" Today, we are happy to announce bugfix releases\u00a0 and\u00a0\u00a0.\u00a0You can download them and read the full list of changes here: These two releases fix a rare bug in the compression of data transferred between nodes (). \u00a0We recommend that everyone upgrades.Communication between Elasticsearch nodes is compressed using LZF to reduce the amount of data transferred across the network. A small number of byte sequences can produce a hash collision which, when combined with a bug in the that we use, results in data corruption.We noticed this bug thanks to a recent checksum change in 1.3.0, which is part of the work we are doing to make Elasticsearch as resilient as possible. While we have always added checksums to files that we write, we did not check that files transferred across the network had the same checksum as the original. This added check resulted in an exception for one of our users when trying to recover a replica shard from the primary: one segment was being corrupted during transfer, which altered the checksum.We managed to create a test case, find the bug, and submit a pull request to the author of the compression library, who reacted very promptly and released a new version with the bugfix.The sequence of events needed to trigger this bug occurs rarely. It may be responsible for the occasional case of corruption that we have seen reported, but which has remained unexplained. \u00a0We advise users to upgrade, but in the meantime you can avoid this bug completely by disabling compression with the following request:curl -XPUT \"http:\/\/localhost:9200\/_cluster\/settings\" -d' { \"persistent\": { \"indices.recovery.compress\": false } }'Please download\u00a0, try it out, and let us know what you think on Twitter (). You can report any problems on the\u00a0. \n"}<br>{"index": {"_id": 1265}}<br>{"title":"All about Scripting","seo_title":"","url":"\/blog\/scripting","author":{"name":"Lee Hinman"},"date":"August 07, 2014","category":"Engineering","locales":"","content":" With the release of 1.3 and moving forward, we are making some big changes to the scripting infrastructure in Elasticsearch. In this blog post we\u2019ll cover the major changes that we\u2019re making, some of the upcoming changes to scripting, and some of the new ways to work with scripting in ES! Dynamic scripting disabled One of the first (and most noticable) changes that has impacted scripting is in the Elasticsearch 1.2 release. We recently released a blog post titled about the security implications of this. Please take a look for more information about how dynamic scripting was changed after the 1.2 release. Groovy and the sandbox Starting with version 1.3, we have decided to add a sandboxed version of Groovy to the Elasticsearch scripting languages, with plans to transition all scripts from MVEL to Groovy in the long run. The reason for this is threefold: The last point leads back to dynamic scripting. In 1.2.0 we disabled dynamic scripting for non-sandboxed languages. However, since Groovy can be sandboxed, we can still allow dynamic scripts to be sent with each request. What do we mean by sandboxing? First sandboxing does NOT address or prevent DOS (Denial Of Service) attack scripts, it is only intended to prevent scripts from accessing parts of the operating system or internals of Elasticsearch they are not intended to access. A malicious script can still be run with an infinite loop, exhausting system resources by sending it many times. If you would like to disable the sandbox (thus causing scripts sent dynamically as strings with requests to be denied), you can disable it by adding to your configuration in Elasticsearch 1.3 or later. Be sure to check out the different sandboxing configuration parameters in the , as well as more information about disabling the sandbox, or enabling dynamic scripting for Elasticsearch overall. In the 1.3 release of Elasticsearch, MVEL is still the default language. We are planning to transition away from MVEL to Groovy as the default language for the 1.4 release. You will be able to transition your scripts from MVEL to Groovy by specifying in the scripts, or changing the default scripting language for all scripts to Groovy by adding to elasticsearch.yml. You can then transition each MVEL script individually to Groovy. When upgrading to Elasticsearch 1.4, MVEL will be removed entirely as a scripting language. If you want to continue using MVEL as a scripting language you will need to install the plugin. While testing, however, we found that the Groovy and MVEL languages were so similar that MVEL scripts needed very minimal changes, if any, to work with Groovy. Why not Javascript? One question that we anticipate getting is why not use Javascript for the scripting language? After all, Javascript is becoming a very popular language. There are a few reasons we decided to go with Groovy instead of Javascript. First, Groovy was faster than Javascript (using Rhino) in our tests, and Nashorn has poor support for concurrent execution of scripts. Additionally, the syntactic difference between Groovy and Javascript is very small for simple scripts, so there should be little difficulty understanding scripts. With the release of 1.3 however, we do have an additional scripting language available for use: Lucene Expressions. Lucene Expressions Lucene Expressions provide a mechanism for dynamically evaluating a single Javascript numeric statement, per document. Its primary purpose is to provide easy scoring adjustment, without writing custom Java code, but the framework allows execution with any per document use case. Each expression is compiled to Java bytecode, to achieve \u201cnative code\u201d-like performance. Integrating expressions as a new scripting language was an easy fit. The new \u201cexpression\u201d lang for scripts can be used for virtually all current uses of query scripts in ES: , , sort scripts and numeric aggregation scripts. And did we mention they are fast? Initial benchmarks show speeds many times faster than Groovy scripts, and even slightly faster than native scripts! As with any feature, gaining great performance comes with a cost. In this case it is the limitations that expression scripts impose: You can read more about expressions (and what functions and operators are available) in the documentation, and how to use them in Elasticsearch in the . An alternative to scripting Before signing off, we would like to talk a little bit about another scripting alternative for a commonly used case. Sometimes you may want to influence the score of a document based on a field inside the document. Think the popularity of a restaurant, or the star-rating of a hotel. One way to do this is to use a script as was shown in the first example. However, there is an easier and faster way of influencing the score based on a document\u2019s field\u2019s value \u2013 the function in the query. Whereas before you would specify: POST \/imdb\/_search?pretty { \"query\": { \"function_score\": { \"query\": {\"match_all\": {}}, \"functions\": [ { \"script_score\": { \"script\": \"log(n * doc['popularity'].value)\", \"params\": { \"n\": 1.5 } } } ] } } } Instead, you can now use: POST \/imdb\/_search?pretty { \"query\": { \"function_score\": { \"query\": {\"match_all\": {}}, \"functions\": [ { \"field_value_factor\": { \"field\": \"popularity\", \"factor\": 1.5, \"modifier\": \"log\" } } ] } } } This not only requires no scripting, but is faster because the execution can use native paths instead of compiling and executing an MVEL or Groovy script. Keep the function in mind as a faster alternative to scripting! \n"}<br>{"index": {"_id": 1266}}<br>{"title":"This Week in Elasticsearch - August 06, 2014","seo_title":"","url":"\/blog\/2014-08-06-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"August 06, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Elasticsearch core You too can start a six node ElasticSearch cluster in under 10 minutes! \u2014 Megabyte Mike (@megabytemike) Elasticsearch EcosystemHere's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Total plotted in \/. US has 5x more than closest rival. pic2 by Top 10 Country Population. \u2014 Bhaskar Karambelkar (@bhaskar_vk) Slides & Videos Where to find UsWe'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Community Manager, , know!GermanyIf you're heading to on August 23rd & 24th, we're happy to bring you bouncy castle love this year. And make sure to see on .PolandThe Warsaw Java Users Group is holding a Microservices Hackathon on August 9th from 10 AM to 10 PM. You can spend those twelve hours hacking on the ELK stack and a variety of other tools. to attend.United StatesHeading to Chicago for LinuxCon and Cloud Open North America? Say hello to , and Empowering Your Corporate Open Source Software Developers.Where to Find YouOur Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, .Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head.TrainingIf you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1267}}<br>{"title":"This Week in Elasticsearch - July 30, 2014","seo_title":"","url":"\/blog\/2014-07-30-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"July 30, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.EC2! DDoS! Cloud! Elasticsearch!If you've been reading the news, you've been seeing those words together quite a bit for the past few days. Don't panic! (And bring your towel.) .tl: dr: Elasticsearch core logstash is just a way to get people hooked on using ElasticSearch for everything, I think. Well played, \u2014 Michael Pearson (@mipearson) Elasticsearch EcosystemHere's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Slides & VideosLearn how Elasticsearch powers the Building Performance Database, helping folks understand their building's energy footprint All about AOL's Network Forensics tool Moloch, powered by Elasticsearch Rotem Hermon, the organizer of the Elasticsearch Tel Aviv meetup, on serendip.me How Clairvoyant uses the ELK stack for log analysis \n"}<br>{"index": {"_id": 1268}}<br>{"title":"Where in the World Is Elasticsearch? - July 28, 2014","seo_title":"","url":"\/blog\/world-elasticsearch-12","author":{"name":"Livia Froelicher"},"date":"July 28, 2014","category":"","locales":"","content":" The summer heat is kicking in (even in normally chilly Amsterdam) and us Elasticsearchers need a little break. Hence, we decided to combine the next three weeks of events into one blog post and start-off again in mid August (the 18th to be exact). We'll also announce our winner(s) of the #ElksInTheWild holiday competition then - so be sure to take some holiday pictures with your plush ELK and share your photos with us on Twitter. What's this #ElksInTheWild thingy about? If you missed our last blog post here's the \u201chow-to\" guide: In case you lovely humans are around, here is what's on the calendar for the next three weeks: Upcoming Events North America Jul 31st - Aug 1st: - say hi to Aug 7th - 10th: - say hi to Aug 11th - 14th: - stop by our booth (we're there all week!) and see session on Thursday at 9:25am Europe Aug 1st - 3rd: - say hallo to and Upcoming Meetups North America Jul 31st: Europe Jul 28th: Aug 4th: Aug 9th: That's it for now. Stay tuned for more Elasticsearch happenings after our summer break. P.S.: if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag! \n"}<br>{"index": {"_id": 1269}}<br>{"title":"Elasticsearch 1.3.1 Released","seo_title":"","url":"\/blog\/elasticsearch-1-3-1-released","author":{"name":"Clinton Gormley"},"date":"July 28, 2014","category":"Engineering","locales":"","content":" Today, we are happy to announce the bugfix release of , based on Lucene 4.9. You can download it and read the full changes list here:\u00a0.This release fixes a backwards compatibility bug () in index recovery. This bug and upgrading to Elasticsearch 1.3.1 will fix the problem.\u00a0It will affect any user who tries to upgrade to version 1.3.0, whose indices still include segments which were written to in any of these versions of Elasticsearch: The bug \u00a0prevents the recovery of replicas for these older indices. \u00a0An index that has segments from these versions, and has replicas enabled, will reach status yellow, but never green. \u00a0The exceptions in the logs will look like this: IllegalArgumentException[No enum constant org.apache.lucene.util.Version.x.x.x]Certain versions of Lucene are missing constants which represent minor Lucene versions, and incorrect version numbers have been recorded in some segments. \u00a0 has been opened to address this issue in Lucene.\u00a0This issue should have been caught by our backwards compatibility tests, but was missed because of the missing constant in Lucene. \u00a0The test suite will be improved to cover that eventuality in the future.This release also fixes a few minor aggregation bugs, which are listed in the\u00a0.Please download , try it out, and let us know what you think . You can report any problems on the . \n"}<br>{"index": {"_id": 1270}}<br>{"title":"Curator 1.2.0 Released","seo_title":"","url":"\/blog\/curator-1-2-0-released","author":{"name":"Aaron Mildenstein"},"date":"July 24, 2014","category":"Engineering","locales":"","content":" Greetings! Even though it has only been a few weeks since was released, we're rolling out another new version. Introducing Curator v1.2.0! New features These changes are documented thoroughly in the Updates Date patterns and In previous releases of Curator, the date was calculated by separating the elements of the index name using a separator character. This design decision was simple for use with the Logstash indices the program was originally designed to manage. Since then, however, Curator has matured into a time-series index manager, and that has meant different index naming schemas. There is still a need to do date math calculations by interval, and so the option remains, though now you can also specify as the time unit. The default options should still work out of the box as they did previously. They are as follows: What this means, is that if you specify as your time unit, and do not specify a , the default will be , which is \"Year.Month.Day.Hour\" expressed in . Similarly, if you were to specify as your time unit, and allowed Curator to provide the default it would be . Where this feature now provides value is with indices with no separator character between date elements. For example, if I had daily indices like you could for indices older than 2 days with a command like this: Note that the default time unit is in this example. Hourly indices\u2014like could be managed in similar fashion: Replacing If you were using a custom separator character with a previous version of Curator, your change should be relatively simple. If your old command was for an index like , your command would have used . Now, your command will look like this: Just put your separator string in between the year (), month (), and day () identifiers! This also means that you can now do what was previously impossible in Curator: mixed separator characters. Now you could process indices like with a like . Learn more about in the . Feedback Many of these features came about because of user comments and requests. If you have a feature request or find a bug, ! We also love shout-outs on Twitter. Our twitter handle is @elasticsearch Happy Curating! \n"}<br>{"index": {"_id": 1271}}<br>{"title":"This Week in Elasticsearch - July 23, 2014","seo_title":"","url":"\/blog\/2014-07-23-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"July 23, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Alright, we are ready for tonight! Swing by booth P18 for some awesome demos! \u2014 cariG (@cariG) Elasticsearch Core Turns out 10 stickers is worth 1 bacon maple . \u2014 Kimberly Lembo (@kimlembo) Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Slides & Videos Where to Find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Community Manager, , know! Germany Israel Poland The Warsaw Java Users Group is holding a Microservices Hackathon on August 9th from 10 AM to 10 PM. You can spend those twelve hours hacking on the ELK stack and a variety of other tools. to attend. United States Where to Find You Our Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1272}}<br>{"title":"Elasticsearch 1.3.0 And 1.2.3 Released","seo_title":"","url":"\/blog\/elasticsearch-1-3-0-released","author":{"name":"Clinton Gormley"},"date":"July 23, 2014","category":"Engineering","locales":"","content":" Today, we are happy to announce the release of\u00a0, based on, along with a bugfix release of . You can download them and read the full changes list here: Elasticsearch 1.3.0 is the latest stable release. It is chock full of new features, performance and stability improvements, and bugfixes. \u00a0We recommend upgrading, especially for users with high indexing or aggregation loads. The full change log is available in the\u00a0, but we will highlight the most important changes below: Security Elasticsearch previously allowed any request to return its response in a format. \u00a0While very useful, this meant that any web page you view could send requests to any Elasticsearch instance which you have access to. \u00a0 (BREAKING:) but can be enabled if you so choose (). Scripting In the 1.2 branch, we disabled dynamic scripting by default. This was a good decision from a security standpoint, but made it more difficult to use scripting with Elasticsearch. \u00a0This release adds a number of awesome scripting features which give you the best of both worlds: Aggregations Aggregations keep on getting better and better. We have added three new aggregations: Besides these new features, aggregation performance and memory usage have also received a lot of love: Indexing Elasticsearch is used for a range of very different use cases, such as large document search, centralised logging, and high performance analytics. Document size and indexing rate varies dramatically between these use cases, so it is important that Elasticsearch is able to adapt dynamically. \u00a0We are closer to an auto-regulating system than ever before, thanks to changes that have been made in recent releases and to the following: At Elasticsearch we like good defaults. \u00a0We don't want our users to have to twiddle many confusing knobs in the hope that one particular combination might deliver what they need: It should just work. With the above changes, we have reduced the number of settings that you know about to just three: Suggesters We have a new in-house suggesters expert, so expect a number of improvements to suggesters in the near future. To start off with, we have added \u00a0the much requested ability to limit \"did-you-mean\" phrase suggestions to phrases that actually exist in the index (). Mapping The new \u00a0feature\u00a0adds the ability to use scripting to transform\u00a0the source document on-the-fly during indexing (). This doesn't change the field that is stored on disk, but it changes how the field is indexed. Mapping has also seen some significant performance improvements: Disk, files and I\/O The slowest component of any modern server is the disk. \u00a0Small improvements to I\/O and disk usage can make a big difference to the performance of the system overall. \u00a0With this in mind, we have made the following changes: Resiliency With a complex asynchronous distributed system like Elasticsearch, there are always complicated corner cases which can impact the stability of a system. \u00a0You can read about the many low-level improvements and bugfixes that have been added in this release . These resiliency improvements are part of an ongoing effort to make Elasticsearch rock solid. \n"}<br>{"index": {"_id": 1273}}<br>{"title":"Where in the World Is Elasticsearch - July 21, 2014","seo_title":"","url":"\/blog\/world-elasticsearch-11","author":{"name":"Livia Froelicher"},"date":"July 21, 2014","category":"","locales":"","content":" Last week our three hackers , and were on a mission to discover the tech side of Japan. Igor and Honza also held a talk at their first ever Elasticsearch meetup in Tokyo. hacking, yet lost in translation, with and \u2014 Shay Banon (@kimchy) Tokyo meetup has started. has the floor \u2014 Igor Motov (@imotov) Little ELK didn't quite get to travel that far but the German folks at the Java Forum in Stuttgart loved him and even ranked him Number One among all conference freebies at the Java Forum Stuttgart. Sweet! F\u00fcr mich das Giveaway des Tages : -) :-) \u2014 Achim L. (@achiml75) Now, check out what's on the Elasticsearch calendar for this week (teaser: we have one session where we'll teach you how to monitor your drone project with Elasticsearch!): Upcoming Events North America - , and are all speaking. Be sure to check out their sessions and stop by our booth (P18) to say hello. Europe - Honza Kr\u00e1l speaking - Honza Kr\u00e1l speaking Upcoming Meetups North America Europe Oceania If you are one of the lucky ones on holiday traveling somewhere around the world, here are 2 holiday tips: You have a plushy ELK? Take it with you, take a fun holiday picture and about it using the #ELKsIntheWild hashtag. Our top 3 will get some awesome swag sent over, so the competition is on! Bored on your sun chair? Just scan through our and have a look at one or the other cool video on there. :) That's it for this week, and stay tuned for Elasticsearch happenings next week. We hope to see you at one of our events. PS: if you're interested in hosting a meetup or are giving a talk about Elasticsearch - we can offer support and send you swag! \n"}<br>{"index": {"_id": 1274}}<br>{"title":"Elasticsearch.NET & NEST 1.0 GA Released","seo_title":"","url":"\/blog\/nest-elasticsearch-1-0-ga","author":{"name":"Martijn Laarman"},"date":"July 18, 2014","category":"Engineering","locales":"","content":" Last week, we released the to the nuget.org unstable feed. Today, we are happy to announce the general availability of 1.0 in the nuget stable channel! No more separate *.Signed packages All the assemblies are strong name signed by default. While we personally feel strong naming is up there with the invention of null as big mistakes, we can't escape the fact that it's a reality for some of our customers. In , if you strong name your application or library, you can only use libraries that are also strongly named. If you do not, you are free to use signed and unsigned assemblies. The choice whether to strong name or not therefore comes down to servicing the most people. We already see that great libraries like that take a dependency on NEST are signed themselves. Breaking Changes So we promised no breaking changes between the RC and GA, but sharply observed that our mapping of the Update API and updates inside the Bulk API were inconsistent and together . This also has consequences for some of the other API's where you can pass an CLR Object to infer to id on. This used to be called but has been renamed to the more descriptive . To make up for the breaking changes between the RC and GA, we released a little bit earlier! Connection Pooling Since the RC, we have improved the exception messages it throws to be as verbose as possible. Pings and sniffs exceptions are clearly distinguishable. The addresses of all the nodes that failed are now also visible in the exception message itself. Exceptions For the RC, we wrote a ton of unit tests throwing exceptions in deliberate places to be sure that exceptions that bubble out of the client are consistent: when using connection pooling, and the actual exception when not regardless whether a synchronous or asynchronous method is called. We've added unit tests for these exceptions and wrote a ton of integration tests for timeouts and other connection related exceptions. Better GeoShape mapping Previously, NEST only allowed for a Coordinates object of type for shapes which only worked for a sub set of the GeoJSON objects that Elasticsearch supports. \u00a0Rather than one GeoShape descriptor for all shape types, NEST now exposes a separate descriptor for each, accepting the correct coordinates structure for that type. CLS-Compliant? We're proud to announce that NEST is now CLS-Compliant! Read more about what that means . What's Next? If you have any issues, comments, or ideas, please don't forget to report them on our . \n"}<br>{"index": {"_id": 1275}}<br>{"title":"Why I joined elasticsearch - July 17, 2014","seo_title":"","url":"\/blog\/joined-elasticsearch-2","author":{"name":"Aaron Katz"},"date":"July 17, 2014","category":"News","locales":"","content":" Twelve years ago, as the dust from the dot-com implosion settled, I joined a one-product, one-hundred person startup that was on a mission to reinvent the enterprise software industry. We accomplished this by developing products that were easy-to-use, easy-to-deploy, community-driven, and engineered around a simple yet fundamental principle that had somehow been lost by traditional software vendors during the melee of the dot-com frenzy: vendor success is a derivative of customer success. Focus on the latter and the former will follow. That company was and, after working there for more than a decade I have decided to close one incredible chapter and start the next. Here, at a glance, is why I joined Elasticsearch and why I believe it will emerge as the next great enterprise software company. First and foremost, extracting business value from data will be the number one priority for enterprises across all industries within the next five years. Right now people talk about big data, analytics, predictive computing, artificial intelligence and many other data-focused disciplines. I predict that a term will emerge to capture this sector of the technology industry in the same way that \u201ccloud computing\u201d captured software-as-a-service, utility computing, file sharing, storage, web services, application hosting, etc. The seemingly endless use cases the Elasticsearch ELK stack addresses uniquely positions the company to help define this rapidly evolving category. Secondly, open source is here to stay and, like social networking and mobility, still has so much room to mature and grow. The Elasticsearch ELK stack, and all of its core products - Elasticsearch, Logstash and Kibana - started independently as passion projects before a company was built around them. It is this evangelical, community-led approach to technology development that will write the future of enterprise software. Thirdly, platforms that deliver insight from unprecedented volumes of data in milliseconds will dominate the space. They scale massively, are simple to deploy, and can be implemented at a fraction of the cost of traditional methods. These platforms will emerge as the new standard. Elasticsearch offers this today, as evidenced by the 10M total downloads to date, and I have not seen this type of viral growth in enterprise software in the last decade. And lastly, I fundamentally believe, having spent a significant part of my career living or working in Asia Pacific, Europe, or Latin America, that the long-term winners in our industry are those who approach international and emerging markets with the same intensity as they do mature markets. Elasticsearch shares this belief more so than any other company I have encountered at such an early stage. If you want to be a part of this energy, growth, and innovation, head on over to . You can drop us a line at , or you can contact me directly at . \n"}<br>{"index": {"_id": 1276}}<br>{"title":"This week in Elasticsearch - July 16, 2014","seo_title":"","url":"\/blog\/2014-07-16-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"July 16, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. presents at last week's Elasticsearch Korea Study Session Photo credit: JongMin Kim Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. amazing turnout to the elasticsearch at Tokyo \u2014 Shay Banon (@kimchy) Slides & Videos LivingSocial shares their use case Alexander Mols' slides from the recent Dutch PHP Conference Learn how Yieldbot uses Kafka together with new Elasticsearch features like doc values at Devoxx UK 2014 Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Community Manager, , know! Germany Israel Italy The very first Elasticsearch Italy Meetup has been scheduled for July 16th! Please join us to hear from on . You'll also be treated to a case study talk on how uses Elasticsearch in its Threat Management System for Breach Detection, Intelligence & Response. Doors open at 6:00 PM, and . Japan \u9996\u90fd\u5927\u30677\/17\u5348\u5f8c \u3055\u3093\u3068 \u3055\u3093\u306belasticsearch\u5165\u9580\u3068\u30af\u30c3\u30af\u30d1\u30c3\u30c9\u306b\u304a\u3051\u308b\u30b5\u30fc\u30d3\u30b9\u958b\u767a\u306b\u3064\u3044\u3066\u30c8\u30fc\u30af\u3057\u3066\u3044\u305f\u3060\u304d\u307e\u3059\u3002\u53c2\u52a0\u8cbb\u7121\u6599\u3001\u7533\u3057\u8fbc\u307f\u4e0d\u8981\u3067\u3059\u306e\u3067\u3001\u304a\u6c17\u8efd\u306b\u3069\u3046\u305e\uff01 \u2014 Mamoru Komachi (@mamoruk) New Zealand The Auckland JVM Users Group will rebooting their meetup series, with their newest offering focused on Elasticsearch. You can join them on Tuesday, July 22nd at 6:00 PM, and . Poland The Warsaw Java Users Group is holding a Microservices Hackathon on August 9th from 10 AM to 10 PM. You can spend those twelve hours hacking on the ELK stack and a variety of other tools. to attend. United Kingdom The London VoiP User Group will get together on July 22nd at 6:30 PM. These folks are in search of a venue, so if you're excited to hear about Eye-candy from CDRs with the ELK stack, and help these good folks find a place to meetup. United States Where to Find You Our Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1277}}<br>{"title":"Streamlining Maintenance of Our Puppet Modules","seo_title":"","url":"\/blog\/streamlining-maintenance-puppet-modules","author":{"name":"Richard Pijnenburg"},"date":"July 14, 2014","category":"Engineering","locales":"","content":" Since the beginning, we've tried to support all current and historic releases of Puppet. We're big fans of Puppet - just like many of our users - so we went broad in our version support. We wanted to ensure the best possible experience for as many folks as possible. At the time of writing this post, we're testing against 9 different versions of Puppet, both vanilla and Puppet Enterprise. We have a great testing infrastructure to do this work for us. However, long term maintenance to support all these versions, with even more great bits to come, is proving to be more challenging. Moving forward After pondering the challenges and tradeoffs, we've decided to shrink the versions we test against and officially support. Puppet is developed and released at quite a fast pace - one of the reasons we love it - so we'll make sure our modules always keep up with Puppet's latest releases. Specifically, we'll support the latest version of vanilla Puppet, plus the prior four releases. For Puppet Enterprise, we will support the latest two releases. What this means for you Moving forward, we will support the following: Puppet Open Source: 3.2.x to 3.6.x Puppet Enterprise: 3.1.x and 3.2.x If you're running an older version, our Puppet modules should still keep right on working for you. However, with this change we cannot guarantee that will always be the case. We'd recommend to ensure compatibility, and because why not get the latest bits? \n"}<br>{"index": {"_id": 1278}}<br>{"title":"Where in the World Is Elasticsearch - July 14, 2014","seo_title":"","url":"\/blog\/world-elasticsearch-10","author":{"name":"Livia Froelicher"},"date":"July 14, 2014","category":"","locales":"","content":" Last week was awesome! We had some great presentations around the world by our own developers and happy Elasticsearch users like . Seoul meetup starting with talking about data structures used in elasticsearch. \u2014 Honza Kr\u00e1l (@HonzaKral) Philly meetup, presents. Thanks for providing an awesome space. \u2014 jamestyack (@jamestyack) This week we are very excited to check out some brand new places - hello, Bath and Milan! - and accompany on his way to Tokyo for the 5th Elasticsearch Study Session! flying to Tokyo today for our first training, excited, first time at Tokyo + see first hand our amazing community \u2014 Shay Banon (@kimchy) Events & Conferences Berlin Are you on your way to EuroPython or perhaps you are already in Berlin and are looking for weekend plans? , happening in Berlin on July 19th and 20th, is your place to go if you are all passionate about documentation systems, tech writing theory, and information delivery. will be giving a talk about on Sunday July 20th at 2:30pm. We're happy to provide you the post-conference meetup drinks. And remember, we're . Portland If you are all in for , join us at in Portland from July 20th until 24th. We're looking forward to our visit to PDX, especially because we get to see all you lovely people. But since OSCON isn't for a few more days make sure to stay tuned here, as we'll get into all the juicy OSCON details (where to find us - Booth P18, when to hear us, what swag we'll have, etc.) in next week's post. Stuttgart is a one day conference covering all things Java. , will be attending along with . Make sure to say hello at booth number 20 between sessions. The conference takes place on July 17th at the Culture & Convention Centre Liederhalle. Tokyo As part of a public educational course at the Tokyo Metropolitan University, , will give an Introduction to Elasticsearch on July 17th. Want to join us? . Meetups Bath Neil Andrassy, CTO at , organizes our first in the South West of England on July 14th in Bath. Neil will kick this thing off by explaining a little more about how . In the area? Join and sign up . Berlin It is a busy tech week in Berlin and we are trying to make people not busier but happier with an ELK Hackathon. Led by Florian Gilcher, organizer of the , the Hackathon is happening on July 15th from 10am-6pm. There is limited space, so if you fancy some hacking before heading to the , please sign up . Cincinnati Feel like meeting up for an evening of fun with the user group? Their upcoming meetup on July 16th will cover some of the most popular 'Free and Open Source Software' (FOSS) tools used to monitor various aspects of your computer environment. Tools covered will include the ELK stack. Milan Our partner is hosting our first ever meetup in Milan on July 16th. Yay. , , and will be onsite. Luca will be talking about followed by a case study presentation from about . Paris The in France is gathering in Paris on July 15th and Olivier Dolbeau will give a short introduction to ELK. Doors open at 7:30pm. Spaces are limited so make sure you register. Tokyo After Seoul, Elasticsearch descends on Tokyo this week. And it's not 'just' your garden variety meetup in the wild. Our own crew with Shay Banon, Honza Kral, and Jun Ohtani are going to be there. So don't miss the chance to meet them all on July 14th and hear Igor and Honza talk about all things Elasticsearch. Sign up . \n"}<br>{"index": {"_id": 1279}}<br>{"title":"The Summer of Elasticsearch in Berlin","seo_title":"","url":"\/blog\/summer-elasticsearch-berlin","author":{"name":"Livia Froelicher"},"date":"July 11, 2014","category":"News","locales":"","content":" The Elasticsearch community in Berlin has been busy with all sorts of events over the past few weeks - and there is much more to come! In case you haven\u2019t been following the news at lately or you haven\u2019t joined our - yet :) - here\u2019s a brief summary of past and future activities. Elasticsearch Hackfest On May 28th, we held an Elasticsearch Hackfest, organised and coached by Asquera and Elasticsearch as part of Berlin Buzzwords\u2019 Hackathon day. Around 60 people got together to learn more about Elasticsearch and work on cool projects. The teams worked on small, fun to build apps that sent users notifications using the Percolator, made movie recommendations based on other movies you like using Elasticsearch or helped German newbies to determine a word gender with Logstash. The Elasticsearch Hackfest was great for developers new to Elasticsearch, as they got to learn in a more hands-on environment. For more seasoned Elasticsearch users, it was a great chance to play around with all the newest bits and to chat with other members of the community and with the Elasticsearch team members. Most of the European Union-based employees of Elasticsearch journeyed to Berlin for Buzzwords and joined the hackathon - thanks for being so helpful and accessible! Today's hackathon. Thanks for all! \u2014 Leslie Hawthorn (@lhawthorn) Elasticsearch User Group The Berlin Elasticsearch User Group, organised by Asquera, takes place the last Tuesday of every month. While we changed our May meeting to a hackfest, we went back to our regular schedule at the end of June. And we\u2019ll see you in July, as well! In June, we continued our tradition of hosting a beginners workshop and a more advanced talk. This time, Jilles Van Gurp told us about how they take advantage of the ELK stack (Elasticsearch + Logstash + Kibana) at his company, Linko. \u00a0 \n"}<br>{"index": {"_id": 1280}}<br>{"title":"Elasticsearch.Net & Nest 1.0 Release Candidate","seo_title":"","url":"\/blog\/elasticsearch-net-nest-1-0-release-candidate-now-available","author":{"name":"Martijn Laarman"},"date":"July 10, 2014","category":"Engineering","locales":"","content":" After a very successful period, we are pleased to announce the availability of the release candidate for the Elasticsearch .NET clients. So what does release candidate mean for you exactly? Just like the beta, the RC is being released on the nuget unstable channel. However, we\u2019ve now committed our public API as released in this RC. No breaking changes will be introduced between this RC release and the final 1.0 release forthcoming on the nuget stable feed. We\u2019re pushing for a 1.0 stable release 10 days after this release candidate. We\u2019ll spend these 10 days ramping up the documentation for NEST and Elasticsearch.NET and responding to bugs discovered in the RC. As with all of our .NET releases, we\u2019ve tested this RC against version of Elasticsearch 1.0 and up, including the latest 1.2.2 release. In addition to our automated testing, we\u2019ve also spent time upgrading some of our customers\u2019 existing applications to the new . The firsthand experience and feedback on the state of the new client from these real world scenarios has been incredibly helpful in improving from . Wait, wait \u2013 2 clients? Quick recap on our story so far\u2026 Starting with 1.0, we made a conscious decision to split out the bare metal low level moving parts from into . The low level client does not come with design choices around types, so you can inject your own routines for serialization, connection handling and connection pooling handling. This change makes a great choice for interfacing to small libraries such as logging adapters, as the low level client is completely dependency free. If you are writing more involved applications, we recommend since it is strongly typed around 90% of the Elasticsearch universe. If you are using and need to drop down to the low client, you can always do by simply calling into property. uses internally, allowing you to inject your own moving parts as you see fit. Breaking changes This list is by no means exhaustive, but in our work converting existing applications using the release we\u2019ve found these to be the main breaking changes you might run into when upgrading to the : If you find others, please ! Whats new As always, we\u2019d like to thank the community first and foremost. The amount of feedback coming in from GitHub issues and Stack Overflow has been absolutely stellar. All of this continuous feedback means we\u2019ve been able to address many quirks and bugs that the beta1 release introduced, plus add new functionality for the deepest places where the Elasticsearch and .NET universes intersect. New hire I\u2019m very pleased to be able announce the team at Elasticsearch Inc has doubled in size with the hiring of . Greg is based in Jersey City, New Jersey, so the team now spans two continents! Ok, so technically Greg is not a new feature or bug fix of the , but he\u2019s been instrumental in getting the RC out the door. Welcome Greg! Object Initializer Syntax The big new feature of the RC is the object initializer syntax. When I first started to write NEST, I wrote it for me and the Elasticsearch projects I was doing at that time. I really like the fluent syntax, but not all NEST users feel the same way. With this release, we hope to get the fluent syntax haters back on board! So what does this mean in practice? Lets consider an example: var response = this._client.CreateIndex(c => c .Index(\"new-index-name\") .Settings(s => s .Add(\"index.settings\", \"value\") ) .AddMapping<object>(m => m .Type(\"my_root_object\") .Properties(p => p .String(sm => sm.Name(\"my_field\").Analyzer(\"default\")) ) ) ): var request = new CreateIndexRequest(\"new-index-name\") { IndexSettings = new IndexSettings { Settings = new Dictionary<string, object> { {\"index.settings\", \"value\"} }, Mappings = new List<RootObjectMapping> { { new RootObjectMapping { Name = \"my_root_object\", Properties = new Dictionary<PropertyNameMarker, IElasticType> { {\"my_field\", new StringMapping() { Analyzer = \"default\" } } } }} } } }: var response = this._client.CreateIndex(request): In most cases, the fluent syntax is more terse, but the object initializer syntax has the following benefits: The choice is now yours! We\u2019ve enabled this on the API endpoints mapped by NEST. Object initlizer query syntax A special mention should go to show that the new syntax extends also in to Query DSL csharp QueryContainer query = new TermQuery() { Field = Property.Path<ElasticsearchProject>(p=>p.Name), Value = \"value\" } && new PrefixQuery() { Field = \"prefix_field\", Value = \"prefi\", Rewrite = RewriteMultiTerm.ConstantScoreBoolean }: var request = new CountRequest() { AllowNoIndices = true, ExpandWildcards = ExpandWildcards.Closed, MinScore = 0.6, Query = query }: Deserialize query \/ dsl visitor Since we\u2019ve separated the internal state of the descriptors to specialized interfaces, both syntaxes are now assertable. It also opens interesting use cases such as . It also means that you can deserialize strings into NEST query objects as is shown by . Fields() One of the biggest problems people in the .NET world face when upgrading to Elasticsearch 1.0, is that when specifying fields they are always returned as arrays. While the fully supported the new situation, the NEST API became very verbose. We\u2019ve simplified the API, making it more readable. The also had a bug in the view into your that would return an array of nulls if you specified . Thanks to for reporting it! We now offer a specialized view into your field selections using and improved the syntax around getting you field values. See for the updated syntax. Metrics support With the new connection pooling \/ cluster failover support in the client, a single call might be doing multiple calls in the background. Starting with this RC, every response in and will return a object. This object lists the total time all the requests took, (de)serialization time and an individual metric record for each request that the client performed. This change gives you insights into what nodes were pinged, sniffed, and on which nodes the call was actually done. Metrics is enabled by default under DEBUG builds, but you can turn it on explicitely by calling on . Connection pooling \/ cluster failover The was the first release that included support for connection pooling and cluster failover. Sadly, that version orphaned exceptions into making it hard to see what the actual exception was even if you did not even use a connection pool! Thanks to for identifying and . A is something you should now only see if you are using connectionpooling and all the attempts resulted in an actual network exception or an HTTP 503. Elasticsearch server exceptions By default, NEST never throws an exception if it gets a response from Elasticsearch. While we\u2019ve always exposed the status code and raw response, we now also support a property on all the responses. This property gives more information about the Elasticsearch server exception that occurred, e.g. IndexMissingException, SearchParseException, etc. If you wish to throw on these kinds of exceptions, you can instruct the client by specifying on . In this case a special is thrown. The throw\/not throw behaviour is quite similar to .NET vs . The older always throws on anything not in the 200 range, where as the new does not. Continuous builds We\u2019ve also set up continuous bleeding edge builds of the client on . If a commit on our branch passes all our unit tests, myget will build and graciously host a bleeding edge version of the client. Even if we do plan to release often after the big 1.0 release, if you need to use a fix that went in to rather then 2 weeks later, it\u2019s all yours! Changelog As always the level of community feedback never ceases to amaze us. The only lists those that resulted in fixes or new features but the influx of general questions from and is wonderful to see. Many thanks to all of you for your contributions \u2013 you\u2019ll see many familiar names thanked there! Moving forward As stated, we will take a 10 day period to solidify the , after which we will push into the nuget stable channel. As always we are actively looking for feedback so please don\u2019t hesitate to what you think! Stay tuned for our announcement in a few days time that Elasticsearch .Net & NEST are in GA! \n"}<br>{"index": {"_id": 1281}}<br>{"title":"This Week in Elasticsearch - July 09, 2014","seo_title":"","url":"\/blog\/2014-07-09-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"July 09, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch Core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. For all you Pythonistas out there ... I just released new version of client (1.1.0) - \u2014 Honza Kr\u00e1l (@HonzaKral) Bonjour, powered by ES : ) \u2014 Jean-Yves Stervinou (@jy) The Magic Zapper team uses Elasticsearch to help find relevant TV content for you, all from your mobile phone \"remote control.\" Slides & Videos Heading to our EU hometown for DrupalCon Amsterdam? Check out on Elasticsearch and Drupal before you arrive! From the oldies but goodies files: Igor Motov on Ongoing Resiliency Improvements in Elasticsearch Love Scala and Elasticsearch? Hear from the folks at Sports195 about their custom Scala libraries that make Elasticsearch sing. Learn all about how PSA Peugeot Citro\u00ebn uses the ELK Stack (en fran\u00e7ais) Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Community Manager, , know! Australia \"Search: A Journey of Delivery on a Budget\" from & - July 10 \u2014 \u24dc\u24e1 \u24dc\u24de\u24dd\u24d3\u24de (@s_mcleod) Germany Israel The Second Elasticsearch Tel Aviv Meetup will convene on July 28th, focusing on real world use cases. The agenda is now finalized and you can hear from three different companies on how they use Elasticsearch. You can . Italy The very first Elasticsearch Italy Meetup has been scheduled for July 16th! Please join us to hear from on What's New in Elasticsearch. You'll also be treated to a case study talk on how Lutech uses Elasticsearch in its Threat Management System for Breach Detection, Intelligence & Response. Doors open at 6:00 PM, and . Japan The will convene on July 14th at 6:30 PM. Register now to get a chance to hear from our core developers and . Even cooler, our CTO will be attending this meetup, so register now to save your place! Korea The will convene in Seoul on July 10th at 7 PM. Register now to get a chance to hear from our core developers and . New Zealand The Auckland JVM Users Group will rebooting their meetup series, with their newest offering focused on Elasticsearch. You can join them on Tuesday, July 22nd at 6:00 PM, and . Spain Clinton Gormley will be speaking on Scaling Real-Time Search and Analytics with Elasticsearch at on July 10th. Clint takes the stage at 9:15 AM. United Kingdom Meeting up in Portlandia, OSCON style Join us for an focused BOF session, July 23rd at 7pm at OSCON - details are here \u2014 stevemayzak (@smayzak) United States Where to Find You Our Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana, and Logstash than where you rest your head. The price of support is dirt cheap compared to the value that their stack represents so I'll be a happy (paying) customer ... \u2014 Henrik Johansen (@HenrikJohansen) We think you're pretty nifty too, Henrik! If you're interested, here's where to . Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1282}}<br>{"title":"Elasticsearch 1.2.2 released","seo_title":"","url":"\/blog\/elasticsearch-1-2-2-released","author":{"name":"Clinton Gormley"},"date":"July 09, 2014","category":"Engineering","locales":"","content":" <!--<br \/> div.itemizedlist { margin-top: -15px}<br \/> --> Today, we are happy to announce the bugfix release of , based on Lucene 4.8.1. You can download it and read the full changes list here:\u00a0. Elasticsearch 1.2.2 is the latest stable release. Windows users and users with heavy indexing requirements should upgrade. The full change log is available in the , but we will highlight the three most important ones below: \n"}<br>{"index": {"_id": 1283}}<br>{"title":"Scripting and Security","seo_title":"","url":"\/blog\/scripting-security","author":{"name":"Lee Hinman"},"date":"July 09, 2014","category":"Engineering","locales":"","content":" \n"}<br>{"index": {"_id": 1284}}<br>{"title":"Elasticsearch Plugin Types","seo_title":"","url":"\/blog\/found-elasticsearch-plugin-types","author":{"name":"Njal Karevoll"},"date":"July 09, 2014","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. In order to write a great plugin, we need to have an overview of the different plugin types and scopes Elasticsearch has made available to us. This article gives a rundown of these and also some tips on how to write a 'well behaved' plugin. \n"}<br>{"index": {"_id": 1285}}<br>{"title":"Quick Tips: regex filter buckets","seo_title":"","url":"\/blog\/quick-tips-regex-filter-buckets","author":{"name":"Zachary Tong"},"date":"July 08, 2014","category":"Engineering","locales":"","content":" A while ago on Twitter, someone was asking if aggregations could be used to categorize data based on irregular product codes. They were combining data from several legacy systems, so the product codes were erratic and not internally consistent. There were two classes of product codes: The goal was to determine how many of each type existed, and how many were missing certain meta-data tags. Many people are stumped by situations like this, since it is initially unclear how to categorize two groups of product codes that are only related to each other by the structural format of their ID. Option 1: Pre-parse with Grok and Logstash The best solution is to deal with inconsistencies like this at the input level. For example, you can build a to identify the two different patterns and tag them appropriately. Once tagged, it is trivial to do aggregations on the structured document data. If a new pattern occurs in your data that doesn\u2019t match the pattern, Logstash will emit a tag. This has the benefit of improving search results, since only properly tagged documents will be visible to search. You can go back and fix\/reindex the \u201cbroken\u201d data at your lesiure and iteratively improve your search results through better-tagged data. Option 2: Regex to the rescue But things are not always this simple. What if you just indexed 10TB of data and realized you forgot to include appropriate pre-parsing? Re-indexing would be a pain, or potentially impossible. We need a solution that operates on your existing data. The key is to use a regular expression and filter buckets. A will hold all documents matching its filtering criteria. If we place a inside the bucket, we can find all product IDs matching a certain pattern. Once documents have been sorted into one of the filter buckets, we can apply other bucketing and metrics to derive statistics. Let\u2019s take a look at a very simple example. First we index some data with mixed product codes: PUT \/test\/data\/_bulk {\"index\":{}} {\"product_code\" : \"AB123\"} {\"index\":{}} {\"product_code\" : \"XY345\"} {\"index\":{}} {\"product_code\" : \"AZ987\"} {\"index\":{}} {\"product_code\" : \"ZZ192\"} {\"index\":{}} {\"product_code\" : \"A99999\"} {\"index\":{}} {\"product_code\" : \"A12345\"} {\"index\":{}} {\"product_code\" : \"A98765\"} {\"index\":{}} {\"some_other_field\" : \"xyz\"} {\"index\":{}} {\"some_other_field\" : \"123\"} Then we can run a very simple aggregation to sort out the various codes: GET \/test\/data\/_search?search_type=count { \"aggs\" :{ \"total_count\" : { \"global\" : {} }, \"XX999\" : { \"filter\" : { \"regexp\":{ \"product_code\" : \"[a-z]{2}[0-9]{3}\" } } }, \"X99999\" : { \"filter\" : { \"regexp\":{ \"product_code\" : \"[a-z]{1}[0-9]{5}\" } } }, \"no_format\" : { \"missing\" : { \"field\" : \"product_code\" } } } } This query will give a document count for each product code matching the two regex patterns. The bucket, which will get , will show all documents that don\u2019t have any product code at all. From this base, it is easy to add extra metrics, such as the average price of each product, or the average number sold each day for the last month, etc. The takeaway tip The key to this tip is the bucket. This bucket accepts Elasticsearch filter, which means you can construct the same kind of complex filtering operations which you already use in search requests. And because these are filters, they enjoy all the performance benefits inherent to filters. Starting in Elasticsearch version 1.3.0, you will also have access to the (note the plural). Although functionally equivalent to using multiple filter buckets, the simplifies the syntax for applying multiple filters at the same time. So next time you need to aggregate some statistics, but are stumped by the irregular or inconsistent nature of your data, remember the bucket (and the upcoming bucket). \n"}<br>{"index": {"_id": 1286}}<br>{"title":"Where in the World is Elasticsearch? - July 07, 2015","seo_title":"","url":"\/blog\/world-elasticsearch-9","author":{"name":"Livia Froelicher"},"date":"July 07, 2014","category":"","locales":"","content":" The week before last week all Elasticsearch ELKs were in the wild (or at the beach) in Amsterdam at our #ESAllHands meeting... on the speed lane! \u2014 Dimitri Marx (@MarxDimitri) ...This week we are back with some awesome events and meetups happening in Barcelona, Cologne, Montreal, Paris, Philadelphia, Seoul and Tel Aviv!Mimacom and Elasticsearch are on the road in Bar\u00e7a! Our local Elasticsearcher will be giving a talk on on Thursday July 10th at the . Are you in the area and don\u2019t want to miss out on interesting tech talk and coffee? Then sign up .Want to learn how to work with public, conversational, real-time data? Make sure to head down to the . Our own will present a workshop together with Sylvain Carle on . July 9th, 1pm, sign up .If you feel like some great talks on all things Elasticsearch you should read on. On Wednesday July 9th, our German partner is hosting their 2nd meetup and we are lucky to be part of it! will kick it off with a talk about and will bring it home with a more specific look into . now!We are pleased to announce our on Monday 7th July where two great speakers will present their use cases within two very different business industries. S\u00e9bastien Capillier will talk about how is monitoring their logs with Elasticsearch and Kibana and Alexandre Fricker will present their Logstash, Redis, Elasticsearch, Kibana and Marvel ecosystem and explain how has been using it for different use cases. Amusez-vous!Our 2nd Philadelphia meetup on July 9th is almost here! Last time folks made an introduction to Elasticsearch and the new features in 1.0.x. This time you will hear an interesting use case story about how uses Elasticsearch on both and . There are still some free spots left, make sure you .Thanks to the lovely , we have our next , scheduled for July 10th complete with Elasticsearchers from all over the world. If you are in the Seoul area you should make sure to say hi to and as it is rather seldom to meet them and hear them talk that far East. :)The in Tel Aviv is going to host a day of education on Applied Cloud Computing with the Google Cloud Platform. Among the list of great talks around how to apply these great features to everyday tasks of developers and DevOps folks will speak about and will also show a demo.That's it for this week, we look forward to meeting you at one of these exciting places!And remember, if you\u2019re giving a talk, hosting a meetup or otherwise sharing the Elasticsearch love, . We\u2019d love to feature your knowledge sharing bits here! \n"}<br>{"index": {"_id": 1287}}<br>{"title":"This week in Elasticsearch - July 02, 2014","seo_title":"","url":"\/blog\/2014-07-02-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"July 02, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Full house at last week's ELK Stack open space session at DevOps Days Silicon Valley Photo credit: Ilan Rabinovitch Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. OpenTable <3s Elasticsearch LOL our logging ElasticSearch cluster has just reached 1 Billion documents :) \u2014 Paul Stack (@stack72) Slides & Videos Costin Leau's Presentation from the recent Hadoop Summit North America 2014 explains the significant terms aggregation, a feature that allows to users to identify terms that are relevant to a particular set of documents Jean Baptiste Favre shares details on Blablacar's system architecture and how they use the ELK stack (en fran\u00e7ais) Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Community Manager, , know! France The 8th Elasticsearch France Meetup will take place in Paris on July 7th at Coworkshop. Space is very much limited, so take a look and to save your place. Germany Israel Italy The very first Elasticsearch Italy Meetup has been scheduled for July 16th! Please join us to hear from on What's New in Elasticsearch. You'll also be treated to a case study talk on how Lutech uses Elasticsearch in its Threat Management System for Breach Detection, Intelligence & Response. Doors open at 6:00 PM, and . Japan The will convene on July 14th at 6:30 PM. Register now to get a chance to hear from our core developers and . Even cooler, our CTO will be attending this meetup, so register now to save your place! Korea The will convene in Seoul on July 10th at 7 PM. Register now to get a chance to hear from our core developers and . New Zealand The Auckland JVM Users Group will rebooting their meetup series, with their newest offering focused on Elasticsearch. You can join them on Tuesday, July 22nd at 6:00 PM, and . Spain Clinton Gormley will be speaking on Scaling Real-Time Search and Analytics with Elasticsearch at on July 10th. Clint takes the stage at 9:15 AM. United Kingdom United States Where to Find You Our Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1288}}<br>{"title":"Where in the World is Elasticsearch? #ESAllHands edition","seo_title":"","url":"\/blog\/world-elasticsearch-esallhands-edition","author":{"name":"Daniel Palay"},"date":"June 26, 2014","category":"","locales":"","content":" It's been quite the week at Elasticsearch, as all of our employees descend on our EU HQ for a week of hands on collaboration.We're just about to wrap up our meetings. But as the saying goes, the journey is more important than the final destination. To that end, we had our staff tweet their journey using #ESAllHands all week and collected many of them below. If you missed us around the world, don't worry, our merry band of Elasticsearchers will be back in a town near you soon. Until then, we you! \/\/ app:<br> \/\/ res:<br> window.s = window.s || {}: <br> s[\"api_url\"] = \"\/\/private-api.storify.com\/v1\": <br> s[\"base_url\"] = \"\/\/storify.com\": <br> s[\"env\"] = \"production\": <br> s[\"git\"] = \"f450393f\": <br> s[\"namespace\"] = \"storifyapp\": <br> s[\"protocol\"] = \"https\": <p>window.s = window.s || {}: <br> s.user = window.s.user || {}: <br> s.user[\"username\"] = \"Elasticsearch\": <br> s.user[\"canEdit\"] = true: <\/p> <p>window.s = window.s || {}: <br> s.story = window.s.story || {}: <br> s.story[\"sid\"] = \"53aaa3a17cced80a64000133\": <br> s.story[\"slug\"] = \"esallhands\": <br> s.story[\"permalink\"] = \"http:\/\/storify.com\/Elasticsearch\/esallhands\": <br> s.story[\"title\"] = \"#ESAllHands\": <br> s.story[\"date\"] = {\"created\":\"2014-06-25T10:25:37.942Z\", \"modified\":\"2014-06-26T11:28:02.049Z\", \"published\":\"2014-06-26T11:28:02.049Z\"}: <br> s.story[\"stats\"] = {\"popularity\":0, \"views\":26, \"likes\":0, \"comments\":0, \"elementComments\":0, \"embeds\":[{\"clicks\":0, \"views\":15, \"href\":\"https:\/\/storify.com\/dpalay\/esallhands\", \"domain\":\"storify.com\"}, {\"clicks\":0, \"views\":11, \"href\":\"http:\/\/www.elasticsearch.org\/?p=79357&amp: preview=true\", \"domain\":\"elasticsearch.org\"}], \"elements\":{\"text\":11, \"quote\":4, \"image\":26, \"video\":0, \"link\":0, \"other\":0}, \"clicks\":0}: <br> s.story[\"canEdit\"] = true: <br> s.story[\"liked\"] = false: <br> s.story[\"not_indexed\"] = false: <br> s.story[\"author\"] = {\"username\":\"Elasticsearch\", \"name\":\"Elasticsearch\", \"options\":{\"infinite_scroll\":false, \"hide_stats\":false, \"allow_embedding\":true, \"comments\":true, \"related_stories\":true, \"ga\":false}, \"style\":{\"fonts\":{\"title\":\"Georgia, Times\", \"body\":\"Helvetica, Arial\"}, \"colors\":{\"text\":\"#666\", \"link\":\"#3676c4\", \"background\":\"#fff\"}, \"typekit\":{\"fonts\":[]}}, \"ga_tracker\":undefined, \"features_enabled\":{\"custom_embed_style\":false, \"private_stories\":false, \"html_for_seo\":false, \"no_advertising\":false, \"business_options\":false, \"headerless_embed\":false, \"pdf\":false, \"realtime_updates\":false, \"storylock\":false, \"maxEditors\":0}}: <\/p> \n"}<br>{"index": {"_id": 1289}}<br>{"title":"This week in Elasticsearch - June 26, 2014","seo_title":"","url":"\/blog\/2014-06-24-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"June 26, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. : The Age of by via \u2014 Timo Batista (@TimoBatista) Slides & Videos Introduces Elasticsearch and Kibana gives a high level overview of using the ELK stack at ScaleConf 2014 C\u00e9dric Hourcade shares Daily Motion's use case on an Overview of Using the ELK stack (auf Deutsch) Mr. ( ) shares a moment with our travel buddy . Almost time for \u2014 Daniel Palay (@danielpalay) Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Community Manager,, know! France The 8th Elasticsearch France Meetup will take place in Paris on July 7th at Coworkshop. Space is very much limited, so take a look and to save your place. Israel Japan The will convene on July 14th at 6:30 PM. Register now to get a chance to hear from our core developers and . Korea The will convene in Seoul on July 10th at 7 PM. Register now to get a chance to hear from our core developers and . The Netherlands Spain Clinton Gormley will be speaking on Scaling Real-Time Search and Analytics with Elasticsearch at on July 10th. Clint takes the stage at 9:15 AM. United Kingdom If you're in or around Bath on July 14th, the South-West Elasticsearch Community will convene to talk about how you're using Elasticsearch. You can , which will kick off at 7 PM. United States Where to Find You Our Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1290}}<br>{"title":"Java Clients for Elasticsearch","seo_title":"","url":"\/blog\/found-java-clients-for-elasticsearch","author":{"name":"Florian Hopf"},"date":"June 24, 2014","category":"","locales":"","content":" One of the important aspects of Elasticsearch is that it is programming language independent. All of the APIs for indexing, searching and monitoring can be accessed using HTTP and JSON so it can be integrated in any language that has those capabilities. Nevertheless Java, the language Elasticsearch and Lucene are implemented in, is very dominant. In this post I would like to show you some of the options for integrating Elasticsearch with a Java application. \n"}<br>{"index": {"_id": 1291}}<br>{"title":"Logstash 1.4.2 released, vulnerability fixed","seo_title":"","url":"\/blog\/logstash-1-4-2","author":{"name":"Kevin Kluge"},"date":"June 24, 2014","category":"","locales":"","content":" We released Logstash 1.4.2 today. This is a bug fix release that includes an important fix for a security vulnerability that was present in previous versions of Logstash. We recommend that users of Logstash's zabbix or nagios_nsca outputs upgrade immediately. Deployments that do not use the zabbix or the nagios_nsca outputs are not vulnerable and do not need to upgrade for this reason. the vulnerability The vulnerability impacts deployments that use the either the zabbix or the nagios_nsca outputs. In these cases, an attacker with an ability to send crafted events to any source of data for Logstash could execute operating system commands with the permissions of the Logstash process. Deployments that do not use the zabbix or the nagios_nsca outputs are not vulnerable and do not need to upgrade for this reason. We have added this vulnerability to our and are working on filling out the CVE. We would like to thank Jan Karwowski and Danila Borisiuk for reporting the issue and working with us on the resolution. remediations An upgrade to Logstash 1.4.2 will address the issue. This is our recommended path. Some deployments may be able to remove the zabbix and nagios_nsca outputs from their configuration. This is a viable option to remediate until an upgrade can be performed. We have also released a patch for the 1.3.x series of Logstash releases. This patch can be applied to address the vulnerability. This patch is available as an option to upgrade to 1.4.2. If you apply the patch, you do not need to upgrade to 1.4.2 to fix the vulnerability. In order to apply the patch for the 1.3.x series, do the following on each Logstash host. \u00a0This example uses 1.3.3, but you can also use these steps for 1.3.0 - 1.3.2. # mkdir -p \/tmp\/logstash-patch\/logstash\/outputs # wget -O \/tmp\/logstash-patch\/logstash\/outputs\/zabbix.rb https:\/\/github.com\/elasticsearch\/logstash-contrib\/raw\/v1.4.2\/lib\/logstash\/outputs\/zabbix.rb # wget -O \/tmp\/logstash-patch\/logstash\/outputs\/nagios_nsca.rb https:\/\/github.com\/elasticsearch\/logstash\/raw\/v1.4.2\/lib\/logstash\/outputs\/nagios_nsca.rb # jar uf logstash-1.3.3-flatjar.jar -C \/tmp\/logstash-patch\/ logstash\/outputs\/zabbix.rb -C \/tmp\/logstash-patch\/ logstash\/outputs\/nagios_nsca.rb other fixes The 1.4.2 release includes a number of other fixes. For Logstash core: And for logstash-contrib: You can read the full , or jump right to the page. \n"}<br>{"index": {"_id": 1292}}<br>{"title":"Elasticsearch Hadoop certified for Cloudera CDH5","seo_title":"","url":"\/blog\/elasticseach-hadoop-certified-cloudera-cdh5","author":{"name":"Costin Leau"},"date":"June 19, 2014","category":"News","locales":"","content":" I am happy to announce that has been . Since the beginning, (es-hadoop) has been tested against the popular CDH distribution and, during the few last months, we have been working closely with Cloudera to complete the process. With this certification in place, we can offer users complete peace of mind that Elasticsearch is thoroughly tested and validated against the CDH environment. Adding to our existing partnerships with and , es-hadoop users can rest assured that whatever they use, we at Elasticsearch are fully committed to supporting it. We are delighted to see es-hadoop used in production by businesses in a variety of fields, from social recommendations to financial services, multi-national media companies to global telecoms. Organizations in each of these industries leverage es-hadoop to gather insight and perform analytics on massive volumes of data, and we\u2019re proud we can help them achieve their analysis goals in real-time. We\u2019ll continue to expand on es-hadoop\u2019s feature set to bring Elasticsearch\u2019s rich experience to users of CDH 5 and all other flavors of Hadoop. We know your business is hungry for data, and we\u2019re proud to serve up the best possible search and analytics experience. But don\u2019t take our word for it - and let us know what you think! If you are interested in data exploration, search and identifying anomalies in real-time on your Hadoop data, you are warmly invited to an upcoming webinar by yours truly on Wednesday August 20th, which will showcase the above through Elasticsearch for Apache Hadoop. \n"}<br>{"index": {"_id": 1293}}<br>{"title":"This Week in Elasticsearch - June 18, 2014","seo_title":"","url":"\/blog\/2014-06-18-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"June 18, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. explains Elasticsearch in just 90 seconds .... Elasticsearch Core on all things Elasticsearch from the recent Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. The `Elasticsearch::Persistence::Model` has been released to Rubygems. Details here: \u2014 Karel Mina\u0159\u00edk (@karmiq) Got plans on July 2nd? Join & 1500+ of your fellow enthusiasts for our biggest webinar yet \u2014 elasticsearch (@elasticsearch) Slides & Videos Michael Kaisser on Geospatial Analysis of Social Media posts with Elasticsearch from Berlin Buzzwords 2014 Just published my slides about (add advanced search to your legacy app): \u2014 David Pilato (@dadoonet) Matthew Britt from the University of Michigan showcases how to better handle HPC logs using Logstash From June's Elasticsearch London Meetup With excellent and useful information for non-hipsters, too! Jens Kohl's overview of the Elasticsearch PHP client Itamar Syn-Hershko shares the Ultimate Guide to Elasticsearch plugins at Berlin Buzzwords 2014 \n"}<br>{"index": {"_id": 1294}}<br>{"title":"Elasticsearch Puppet module 0.4.0 released","seo_title":"","url":"\/blog\/elasticsearch-puppet-module-0-4-0-released","author":{"name":"Richard Pijnenburg"},"date":"June 18, 2014","category":"Engineering","locales":"","content":" \n"}<br>{"index": {"_id": 1295}}<br>{"title":"Where in the World is Elasticsearch? - June 16, 2014","seo_title":"","url":"\/blog\/world-elasticsearch-8","author":{"name":"Daniel Palay"},"date":"June 16, 2014","category":"","locales":"","content":" Quick answer: In Amsterdam, London and Paris. But wait, you actually want the details...keep reading and we\u2019ll drop all location knowledge you want (and maybe even more : -)). Amsterdam We\u2019ve got a busy week in our hometown of Amsterdam with sessions at two fantastic international conferences. Join us at from June 19th - 21st at the . Thanks to popular demand, two of our awesome engineers and will be hosting a workshop on on Thursday, June 19th. Additionally, our much-loved and heralded Community Manager, , will present her talk at 10:30 AM on Saturday, June 21st. As always, the whole crew welcomes you to swing by and say hi at the Elasticsearch table. Come and share your stories with us, hear about what\u2019s going on and pick up some fun swag to boot! On June 19th & 20th in the heart of the city, we\u2019ll have a team at . Our CTO, , will treat the crowd to a . Shay will also join from to tell the story of When you\u2019re not in sessions, grab a coffee and follow the scent of delicious warm Dutch syrup waffles which we\u2019ll be baking fresh at our booth. If you\u2019re feeling healthy - and please don\u2019t, stroopwaffles are amazing! - we\u2019ll have cool swag up for grabs too. London Elasticsearch will be on stage during at the first ever at the London EXCEL on June 17th. Our own will be telling you all about how to Mark\u2019s talk is at 16:00 in the Big Data & Analytics theatre. Can\u2019t make Mark\u2019s talk, but have a need to quench your Elasticsearch thirst whilst in London? The has got you covered as they will be hosting a special meetup on June 18th starting at 17:00 at The Marketplace. We\u2019ll have lightning talks from Elasticsearch users Cogenta and Betfair and we\u2019ll follow those with networking drinks until 18.30. Paris If you\u2019re a fan of Drupal, don\u2019t miss out on the session where our own will speak at the on June 18th at . Doors open at 18:45. Where in the world is Elasticsearch next week? It\u2019s going to be a quiet week on the conference and meet up front for us as the whole company will be converging on our HQ in Amsterdam for our annual all hands gathering. For those already in or surreptitiously visiting Amsterdam, we\u2019ll be on Friday, June 27th at 18:00 in . You\u2019ll have the chance to schmooze and kvetch with tons of our team members while enjoying delicious snacks and drinks. Want to join us? . And remember, if you\u2019re giving a talk, hosting a meetup or otherwise sharing the Elasticsearch love, . We\u2019d love to feature your knowledge sharing bits here! \n"}<br>{"index": {"_id": 1296}}<br>{"title":"Elasticsearch 1.2: Adding Context to Suggestions","seo_title":"","url":"\/blog\/elasticsearch-1-2-adding-context-suggestions","author":{"name":"Alexander Reelsen"},"date":"June 13, 2014","category":"Engineering","locales":"","content":" The need for speed If you have not yet read the introductory blog post about the completion suggester, why we built it, and what makes it so fast, you should do so ! Speed is nothing without control One of the most requested requirements for the suggester was the possibility to apply filters to the suggestions. As the query being executed for a completion suggest request is not a real search request the data structure being accessed differs, applying filters was not as simple as one would hope. We spent some time thinking about this problem, and came up with a solution we call context suggestions. The name describes the difference between this one and other suggesters: users want to get suggestions back, but in the scope of a context. What can a scope include? Like with many things in Elasticsearch, there are endless possibilities. You, the person using your data, will know best what the correct scope is. However, we wanted to show you a couple of examples of scoping a suggestion. Filtering by fields The first possibility is to filter by fields. One common use case is when you want to return suggestions only for a certain type. The mapping would look like this: DELETE \/posts PUT \/posts PUT \/posts\/article\/_mapping { \"article\" : { \"properties\" : { \"suggest_field\": { \"type\": \"completion\", \"context\": { \"type\": { \"type\": \"category\", \"path\": \"_type\" } } } } } } PUT \/posts\/teaser\/_mapping { \"teaser\" : { \"properties\" : { \"suggest_field\": { \"type\": \"completion\", \"context\": { \"type\": { \"type\": \"category\", \"path\": \"_type\" } } } } } } Now index two documents: PUT \/posts\/article\/1 { \"suggest_field\" : { \"input\" : [ \"Medicine - Better than homeopathy?\" ] } } PUT posts\/teaser\/2 { \"suggest_field\" : { \"input\" : [ \"Music - can it help plants to grow?\" ] } } Now a suggestion needs to contain context information: POST \/posts\/_suggest?pretty' { \"suggest\" : { \"text\" : \"m\", \"completion\" : { \"field\" : \"suggest_field\", \"size\": 10, \"context\": { \"type\": \"article\" } } } } Because the suggester is using the type as its context, only the first suggestion (\u201cMedicine \u2013 Better than homeopathy?\u201d) will be returned by the suggester. The second suggestion is ignored because it is a different type than . A very common use case for this example would be an e-commerce shop: imagine you have selected a category and want to return products which are inside of the selected product category. Using geo locations Another interesting use case is to take geo locations into account. Imagine you are retrieving suggestions for restaurants: you probably want to suggest restaurants near the user. Ideally, we would filter the suggestions to include only those which are around 2km from the users\u2019 location. This means that you need to supply location information on query and index time. Let us take care of the mapping first: DELETE \/venues PUT \/venues PUT \/venues\/poi\/_mapping { \"poi\" : { \"properties\" : { \"suggest_field\": { \"type\": \"completion\", \"context\": { \"location\": { \"type\": \"geo\", \"precision\" : \"500m\" } } } } } } The next step is to index a document, which contains location information in the suggest field: PUT \/venues\/poi\/1 { \"suggest_field\": { \"input\": [\"The Shed\", \"shed\"], \"context\": { \"location\": { \"lat\": 51.9481442, \"lon\": -5.1817516 } } } } And now, all of a sudden, you can get suggestions back which only apply to a certain area: POST \/venues\/_suggest { \"suggest\" : { \"text\" : \"s\", \"completion\" : { \"field\" : \"suggest_field\", \"context\": { \"location\": { \"value\": { \"lat\": 51.938119, \"lon\": -5.174051 } } } } } } Combining several suggesters So after understanding this principle, your next step would be to answer the question: . Even though this seems more tricky, the great part about the context suggester is the possibility of using several suggesters sequentially. You can create a completion field mapping, which needs a field and a geo location in order to return suggestions. So, let us create a new index with a new field mapping that contains two contexts. There are just two in this example, but you can have arbitrarily many contexts! DELETE \/venues PUT \/venues PUT \/venues\/poi\/_mapping { \"poi\" : { \"properties\" : { \"suggest_field\": { \"type\": \"completion\", \"context\": { \"type\": { \"type\": \"category\", \"path\": \"type\" }, \"location\": { \"type\": \"geo\", \"precision\" : \"500m\" } } } } } } Next, index a new point of interest of type restaurant: PUT \/venues\/poi\/1 { \"suggest_field\": { \"input\": [\"The Shed\", \"shed\"], \"output\" : \"The Shed - fresh sea food\", \"context\": { \"location\": { \"lat\": 51.9481442, \"lon\": -5.1817516 } } }, \"type\" : \"restaurant\" } > And now, use the context and the context to find suggestions for restaurants in that area: POST \/venues\/_suggest { \"suggest\" : { \"text\" : \"s\", \"completion\" : { \"field\" : \"suggest_field\", \"context\": { \"type\" :\"restaurant\", \"location\": { \"value\": { \"lat\": 51.938119, \"lon\": -5.174051 } } } } } } Internally, Elasticsearch is creating two prefix graphs (remember the cute graph in the ?) in addition to the usual suggestion graph. The first one is for the type field and the second for the location. The location is a , and you may be wondering how can this be a graph? The solution is simple: the geo point is converted into a geohash first \u2013 which is a string \u2013 and then a graph is created from the geohashes. This principle is also the reason why you can have an unlimited amount of such graphs, as you just create a graph with more prefix graphs. For example, the category id in your ecommerce site\u2019s page, or the location and the type of a restaurant, or the type of point of interest you wanted to visit, etc etc. More documentation We intentionally left out a couple of possible mapping options in this quick introduction, which you might want to read up on in the We are very interested into what use cases you might bring this functionality in and would love to hear back from you about this highly requested feature. what you think! \n"}<br>{"index": {"_id": 1297}}<br>{"title":"Elasticsearch Curator -- Version 1.1.0 Released","seo_title":"","url":"\/blog\/elasticsearch-curator-version-1-1-0-released","author":{"name":"Aaron Mildenstein"},"date":"June 13, 2014","category":"Engineering","locales":"","content":" \n"}<br>{"index": {"_id": 1298}}<br>{"title":"Logstash on OpenShift","seo_title":"","url":"\/blog\/found-logstash-openshift","author":{"name":"Alex Brasetvik"},"date":"June 13, 2014","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. Get started analyzing your logs on OpenShift. While OpenShift lets you tail the logs of your apps, the Elasticsearch\/Logstash\/Kibana trinity gives you a very flexible and powerful toolchain to visualize and analyze these logs. This article explains how to make a Logstash cartridge on OpenShift. The cartridge feeds your logs into Elasticsearch where you can use the Kibana visualization engine to follow trends, detect anomalies and inspect incidents in your environment. \n"}<br>{"index": {"_id": 1299}}<br>{"title":"This Week in Elasticsearch - June 11, 2014","seo_title":"","url":"\/blog\/2014-06-11-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"June 11, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Slides & Videos slides from last week's Hadoop Summit. Video Coming Soon! at Berlin Buzzwords 2014: Elasticsearch's Query Domain Specific Language (DSL) - Not Just for Wizards! Talking about how we use Scala and at \u2014 Skot Mahr (@lazyvalue) on Elasticsearch's Percolator at Berlin Buzzwords 2014 on Apache Lucene 4 from Berlin Buzzwords 2014 . at talking about ELK in a DevOps environment for tonight's San Francisco meetup. \u2014 elasticsearch (@elasticsearch) Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Community Manager,, know! Austria The has scheduled their first meetup for Thursday, June 12th. Please join us at 7 PM to hear from on What's New in Elasticsearch. France If you're a fan of Drupal and Elasticsearch, please join on June 18th at the . Doors open at 6:45 PM. Israel The is hosting a workshop on Applied Cloud Computing with Google Cloud Platform at Google Tel Aviv. Topics will include BigQuery with Logstash as Application Log Analysis Platform. The workshop runs from 9:30-13:30 on July 7th. The Netherlands We've got not one but awesome conferences going on in Amsterdam the week of June 16th: Plus, we're hosting at 6:00 PM in Amsterdam. You'll have the chance to meet tons of our core developers, as the whole company will be visiting our EU HQ that week for our annual all hands gathering. Romania will speak at on Big data real time search and analytics. Topconf Bucharest runs from June 10-13th and Costin will speak at 3:20 PM on June 12th. United Kingdom United States Where to Find You Our Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana, and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1300}}<br>{"title":"Marvel 1.2.1 Released","seo_title":"","url":"\/blog\/marvel-1-2-1-released","author":{"name":"Boaz Leskes"},"date":"June 09, 2014","category":"Engineering","locales":"","content":" Today, we are happy to announce the release of . This is a bug fix release, fixing a data shipping issue in the new information which can affect large clusters. We recommend you upgrade if you are experiencing problems with the new Shard Allocation dashboard and\/or if you are seeing the following error in one of your Elasticsearch node's logs:[2014-06-05 10:47:48,683][ERROR][marvel.agent] [Bandit] exporter [es_exporter] has thrown an exception: java.lang.IllegalStateException: array not available at org.elasticsearch.common.bytes.PagedBytesReference.array(PagedBytesReference.java:289) at org.elasticsearch.marvel.agent.exporter.ESExporter.addXContentRendererToConnection(ESExporter.java:209) To upgrade, you must install the latest Marvel plugin on all your ES nodes. As with any other Java plugin, you will need to restart nodes (one by one) in order for the version to become active. This is described in more details on the Marvel .As always, we welcome all feedback so we can continue improving Elasticsearch Marvel. Please send questions, praise or pains to the . \n"}<br>{"index": {"_id": 1301}}<br>{"title":"Where in the World is Elasticsearch? - June 07, 2014","seo_title":"","url":"\/blog\/world-elasticsearch-7","author":{"name":"Livia Froelicher"},"date":"June 07, 2014","category":"","locales":"","content":" Welcome to this week\u2019s ! Several members of our core developer team are speaking at conferences in Bucharest and London and we\u2019ve got meetups from Paris to San Francisco. Read on to find where you can hear all about the ELK stack and Elasticsearch awesomeness! A snapshot of last week\u2019s Bay Area Search group meetup in San Jose - on all things Elasticsearch. Topconf Bucharest This international brand of Software conference takes place June 10-13. Don\u2019t miss presentation, , on Thursday, June 12 at 15:20 in Room Asia. If you have any questions about Big Data\/Hadoop architecture, Real-time search in distributed systems or Data visualization, make sure to say hi to Costin during the conference. Devoxx UK Running June 12-13, Devoxx UK offers a packed schedule including presentations and hands-on labs delivered by industry veterans, mavericks and rising stars, both UK- and internationally- based. Our own will be giving a on on Thursday, June 12 in Room 1 from 16:00-16:50. Meetups Norway Comperio will host a\u00a0\u00a0on June 11 at 8:30 with various talks and case studies on search and analytics matters.\u00a0\u00a0will talk about \"How to combine Elasticsearch, Logstash and Kibana to get new real-time analysis of almost all types of structured and unstructured data sources\". Mark's session begins at 10:00 @\u00a0The Thief in Tjuvholmen. Paris The will be hosting an evening of fun @ Dailymotion on Tuesday June 10. The French connection, David Pilato, and will be getting together for some Elasticsearch talks at 19:30. There are only 2 spots left, so make sure to secure your seat if you are in the area! San Fransisco and will be talking all things ELK stack at the From a general overview to best practices for configuring your ELK cluster, Kurt and Gaurav will educate you how the ELK stack provides the perfect tool set for collaboration across teams, not just for Devs and Ops, but for ALL your colleagues. Doors open at 6:30. Vienna The\u00a0\u00a0has announced that its first Elasticsearch meetup will be taking place on Thursday, June 12 starting at 19:00.\u00a0will be covering all the shiny new features in Elasticsearch 1.0. Don\u2019t miss it! Whittier - SoCal Whittier, Southern California - not the most well-known spot on earth. But wait! and are in the area and would love to speak to you and answer any questions you may have. Meet them on Tuesday June 10 for a couple of beers, some snacks and probably a few pizzookies at at 6:00. RSVP on the meetup page. Lots of great stuff on the docket for this upcoming week. Remember, if you\u2019re giving a talk, hosting a meetup or otherwise sharing the Elasticsearch and ELK stack love, . We\u2019d love to feature your knowledge sharing bits here! And with that all the Elasticsearch fans at Puppet Camp DC wave thank you and see you soon! \n"}<br>{"index": {"_id": 1302}}<br>{"title":"Berlin Buzzwords Fever","seo_title":"","url":"\/blog\/berlin-buzzwords-fever","author":{"name":"Livia Froelicher"},"date":"June 06, 2014","category":"Engineering","locales":"","content":" Last week was all about - the EU startup hub's most exciting conference on storing, processing and searching large amounts of digital data. Over 600 attendees from every continent save Antarctica, with visitors from Chile, India, Korea, South Africa and the US. Among these, a total of 15 Elasticsearchers were onsite to share the love and spread knowledge about our products and contributions to the open source community. Take a minute to watch \u00a0 on Apache Lucene 4: The fantastic Kulturbrauerei \u2013 an old beer brewery \u2013 was once more the perfect atmosphere for some great and inspiring discussions in the expo hall. And people really loved our swag. Thanks a lot Elasticsearch for protecting me from bad architecture nightmare :) \u2014 Lo\u00efc Bertron (@loicbertron) ,\u00a0,,and\u00a0rocked their sessions without leaving any seats empty. (We'll be featuring all of our employees talks from Buzzwords in our weekly blog newsletter, .) (photo source: ) Berlin Buzzwords wasn't just about talks. As a gold sponsor Elasticsearch had the chance to provide a fun chill & play area with a cool foosball table, comfy outdoor recliners and a green powered DIY smoothie bike. Here's taking a ride: The search for hydration continues!@kimchy cycles his way to a smoothie \u2014 sejal korenromp (@sejiek) After two days of conference talks and social gatherings, it was time for a deep-dive into the Elasticsearch code. The Elasticsearch hackathon was a great round off of the entire event. Hosted by , we had a great facility to make this event truly amazing. Thanks again to the , especially brand new community manager Cristina Santamarina, and all other sponsors who contributed to this hackathon! Florian and Felix will be sharing a write up of the hackathon with us next week. Today's hackathon. Thanks for all! \u2014 Leslie Hawthorn (@lhawthorn) Finally, a BIG thank to Newthinking (especially) for their fantastic organization before and throughout the whole conference. It was a pleasure to be part of it and discover a bunch of new glowing Elasticsearch & ELK stack users! \n"}<br>{"index": {"_id": 1303}}<br>{"title":"A tool to help with routing issues from Elasticsearch 1.2.0","seo_title":"","url":"\/blog\/tool-help-routing-issues-elasticsearch-1-2-0","author":{"name":"Kevin Kluge"},"date":"June 06, 2014","category":"Engineering","locales":"","content":" \n"}<br>{"index": {"_id": 1304}}<br>{"title":"Our Series C Financing: Sharing the Fruit of Our Labors","seo_title":"","url":"\/blog\/series-c-financing-sharing-fruit-labors","author":{"name":"Shay Banon"},"date":"June 05, 2014","category":"News","locales":"","content":" You may have already , but in case you missed it, Elasticsearch just closed a $70M funding round led by NEA Ventures. Needless to say, we\u2019re very excited about what this means for the future of Elasticsearch and the ELK stack. We hope that you\u2019ll join us in celebrating today! So, what do we plan to do with our new found venture capital? More of the same, and even more. We\u2019ll continue to make the ELK stack open source and ever improving. Always. We\u2019ll continue adding more commercial offerings to our product line. We\u2019ll continue hiring great employees. And we\u2019ll keep . At times like these, anyone would find themselves reflecting on what they\u2019ve built. Just over four years ago, I created Elasticsearch with the vision of building a system architected for scale and the cloud. A few years later, I was fortunate to be joined by Steven, Simon and Uri so we could build a company around the Elasticsearch project. Today, we employ nearly one hundred people in 9 countries and provide an end to end, full stack, search, analytics, logging and data visualization engine. It\u2019s been a humbling ride! In particular, though, I am proud of our open source foundations and how our work empowers the community to innovate. When you look at major community users like Mozilla and Wikipedia, it\u2019s incredible to know that our open source products support their missions. Not only are we helping our customers at major financial institutions to and newsrooms to to their reader engagement analytics. But our creations also support global access to free knowledge and the creation of an open, innovative internet. All while making sure that big companies can keep their systems up and running, and to you. We\u2019re thrilled we can share the successes we\u2019ve enjoyed with all of you today. You keep telling us what you need from the ELK stack, and we\u2019ll keep making great products for our customers and community! (The apple photo is courtesy of . The apples were designed with love by nature and our marketing team in Amsterdam.) \n"}<br>{"index": {"_id": 1305}}<br>{"title":"Elasticsearch Raises $70M in Series C from NEA","seo_title":"","url":"\/blog\/elasticsearch-raises-70m-series-c-nea","author":{"name":"Steven Schuurman"},"date":"June 05, 2014","category":"News","locales":"","content":" With unbelievable pride, I'd like to announce that we just closed another amazing round of financing. In this Series C round, which was led by New Enterprise Associates (NEA) with contributions from Benchmark Capital and Index Ventures, we raised $70M. NEA General Partners Scott Sandell and Harry Weller led NEA's investment in Elasticsearch. Harry will be joining our Board of Directors, and you can look forward to his thoughts on our round later today.Over the course of three rounds of financing, Elasticsearch has raised a grand total of $104M since we started seeking capital just 18 months ago.The last year and a half has been an amazing adventure, and quite frankly I only feel like we're just about to shift into the highest gear. With some of the highest caliber customers already on board, from Facebook to The Guardian, our products are powering some of the world's most sophisticated search and analytics engines. In addition to our most well-known use case, businesses are now commonly using our logging solution. Bloomberg uses the Elasticsearch ELK stack to centralize 1.5B log lines\/day, generated across 1,000s of production machines. The ability to centralize them in one place to troubleshoot any potential issues saves their 2,000 programmers an immense amount of time and hassle.Even better, we've built a world-class team to fuel our product development and commercial activities. We've benefited greatly from the support from our board members Rod Johnson, Peter Fenton and Mike Volpi in our search for new business and talent. The experience these guys bring to the table is invaluable to us, as we're moving quickly to respond to the immense market demand for the ELK stack. As we'll only be expanding our efforts from here, we chose to go with an investment firm with deep open source and enterprise software experience at scale. One that could help us grow aggressively and propel our products offerings forward. Of all the top-tier Venture Capital firms out there, we believe the team at NEA stands out as the one best positioned to help us execute against our plans during this phase of extremely rapid growth. We are nothing short of humbled by the fact that after having signed up Benchmark and Index, we get to work with this third team of wonderfully talented people. Together, Benchmark, Index and NEA are some of the best investment firms and people in open source.The company will be using the additional funds to continue to expanding our investment in our open source products, whilst also expanding our commercial presence across the globe. Elasticsearch's dual headquarters in Los Altos, California and Amsterdam, The Netherlands house about half of our global team. We have regional offices in Berlin, London and Phoenix, but they aren't the only places employees call home. We also have developers in Canada, the Czech Republic, France, Spain, Romania and states across the US. To facilitate our growth and remain close to our user base, we make our company's distributed nature work to our advantage. If you want to know more, check out I did with FAST company.Elasticsearch has always been a wonderful place to work. We offer our people - in all disciplines - the chance to work in an open and vibrant culture and learn from some of the best and brightest in our industry. With these additional funds, we're looking to continue our track record of hiring the best talent our industry has to offer. If you're interested in helping us build the world's next great software company, take a peek at . We're incredibly excited about what the future holds. My thanks to all of our investors, and a huge thanks to all of our employees worldwide. We wouldn't be able to share today's news without all of your hard work, passion and dedication to a simple and beautiful customer experience! \n"}<br>{"index": {"_id": 1306}}<br>{"title":"This Week in Elasticsearch - June 04, 2014","seo_title":"","url":"\/blog\/2014-06-04-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"June 04, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Wait, a realtime patch and vulnerability dashboard using elasticsearch and kibana? Why yes! (note: still beta) \u2014 Michael Henry (@neoCrimeLabs) Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. MT : Standing room only for 's talk on for real-time analytics \u2014 Paige Roberts (@RobertsPaige) Slides & Videos One of the best talks Scoring for human beings by . Get the video when it's out ! \u2014 Lucian Precup (@lucianprecup) You got it, Lucian! on Scoring for Human Beings at Berlin Buzzwords 2014 on Elasticsearch Aggregations at Berlin Buzzwords 2014 on Two Use Cases for Scaling Data with Elasticsearch at Berlin Buzzwords 2014 Where to find Us We'd love to feature all the great Elasticsearch, Logstash, and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Community Manager,, know! RT \"\u201c: Impressive presentations tonight about by \"\" \u2014 Brussels DataScience (@DataScienceBe) Austria The has scheduled their first meetup for Thursday, June 12th. Please join us at 7 PM to hear from on What's New in Elasticsearch. France Israel The is hosting a workshop on Applied Cloud Computing with Google Cloud Platform at Google Tel Aviv. Topics will include BigQuery with Logstash as Application Log Analysis Platform. The workshop runs from 9:30-13:30 on July 7th. The Netherlands We've got not one but awesome conferences going on in Amsterdam the week of June 16th: Norway Romania will speak at on Big data real time search and analytics. Topconf Bucharest runs from June 10-13th and Costin will speak at 3:20 PM on June 12th. New Zealand The in Auckland will get together on June 7th to talk Getting Control of Your Logs. Lots of Logstash love on offer. Switzerland Alexander Reelsen and will be speaking at the on June 7th. Alex will discuss What's new in Elasticsearch and Britta will cover the Significant Terms Aggregation. Doors open at 7 PM. United Kingdom United States Where to Find You Our Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana, and Logstash than where you rest your head. Trainings Attending training, and learning a lot of new things from the experts. Great product and training. \u2014 Trent Swanson (@trentmswanson) Thanks, Trent! Glad it was useful for you. :) If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1307}}<br>{"title":"Marvel 1.2 Released","seo_title":"","url":"\/blog\/marvel-1-2-released","author":{"name":"Chris Earle"},"date":"June 04, 2014","category":"Engineering","locales":"","content":" Today, we are excited to announce the release of Elasticsearch Marvel 1.2. With this upgrade, we are bringing some amazing new features to our Marvel users. These features include the shard allocation dashboard, improved navigation and customization, and updates to the Sense knowledge base to bring it up to date with the latest Elasticsearch 1.2.1 release. As always the new release works with Elasticsearch version 0.90.9 and up. Shard Allocation Dashboard We\u2019ve added a new dashboard for visualizing the shard allocation of the cluster for nodes and indices. With this dashboard you can now see how the cluster is allocated and how the indices are distributed among the nodes. You can also go back in time to see how your cluster has changed over the past few minutes, hours and beyond. This feature should be a big help for diagnosing why your cluster went red at 3 am. And here is a demo video showing off the new features\u2026 \u00a0 Improved Navigation and Customization In previous versions, saving a dashboard would detach it from the Marvel dashboard list and place it into a completely different drop-down \u2013 similar to how Kibana works. We felt like this was impacting the user experience, and wanted to make saving customizations a much smoother experience. With this in mind, we refactored the top navigation to simplify things. We\u2019ve replaced the default Kibana dashboard drop down with a single save button that allows the user to customize their dashboards and replace the defaults. When the user customizes the \u201cOverview\u201d dashboard and saves it, the Marvel navigation will then use the customized saved version from that point on. Updates to Sense to include Elasticsearch 1.2 Features To keep up with Elasticsearch\u2019s new features we\u2019ve upgraded Marvel\u2019s knowledge base to include the latest APIs from Elasticsearch 1.2. The updated APIs include the new percentiles, significant terms, and cardinality aggregations. The following endpoints additions are also included: , <code>_cat\/segments, , <code>_count, and . Upgrade Instructions To upgrade, you must install the latest Marvel plugin on all your Elasticsearch nodes. As with any other Java plugin, you will need to restart nodes (one by one) in order for the version to become active. Please refer to the documentation for . For a complete change list, see . We welcome all feedback so we can continue improving Elasticsearch Marvel. Please send questions, praise or pains to the . \n"}<br>{"index": {"_id": 1308}}<br>{"title":"Elasticsearch 1.2.1 Released","seo_title":"","url":"\/blog\/elasticsearch-1-2-1-released","author":{"name":"Kevin Kluge"},"date":"June 03, 2014","category":"Engineering","locales":"","content":" We released today. This is a bug fix release that includes the fix for a severe bug in Elasticsearch 1.2.0. We recommend that anyone using version 1.2.0 upgrade immediately to this 1.2.1 release. We removed the 1.2.0 release from our download site and repositories due to the severity of the bug. A Fix for Document Routing and Duplicate Documents There was\u00a0\u00a0in Elasticsearch 1.2.0 that could have a number of bad side effects on the cluster. Possible side effects include: The 1.2.1 release fixes this bug. The bug fix will restore access via get to the documents that were indexed prior to the upgrade to 1.2.0. An upgrade to 1.2.1 will not correct duplicate documents. Also, an upgrade to 1.2.1 will break access via get to documents that were indexed since the upgrade to 1.2.0. \u00a0We are investigating what tools we can create to help with the diagnosis and correction of these problems. We will post an update as soon as possible with this information. Other Fixes Elasticsearch 1.2.1 also fixes a\u00a0. We found that the\u00a0\u00a0was too conservative and could prevent memory requests that should have been allowed. We have effectively disabled this new circuit breaker for 1.2.1. The fielddata circuit breaker continues to work as it has in previous releases. There is also a\u00a0. A mapping that contained the parameter \u00a0in the root type would produce a MapperParsingException. For example: PUT test1 { \"mappings\": { \"type_name\": { \"include_in_all\": false, \"properties\": {} } } } would trigger the bug, effectively removing this feature from 1.2.0. If such a mapping is present when upgrading to 1.2.0, then the mapping for this index can be corrupted once a document with a new field is indexed. 1.2.1 restores the correct behavior of\u00a0. Conclusion Users with Elasticsearch 1.2.0 should immediately upgrade to 1.2.1. We will be working to see what tools we can create to help users that have experienced problems from 1.2.0 and we will update on our progress soon. Please\u00a0\u00a0and let us know what you think. You can report any issues on our\u00a0. \n"}<br>{"index": {"_id": 1309}}<br>{"title":"Hello from Hadoop Summit! ","seo_title":"","url":"\/blog\/hello-hadoop-summit","author":{"name":"Leslie Hawthorn"},"date":"June 03, 2014","category":"News","locales":"","content":" Greetings and good morning, San Jose! If you're attending , we want to make sure that you know where to find us, and what we have on.We'll have tons of folks from our team to chat with you about all things Elasticsearch and Apache Hadoop, plus how the ELK Stack can give you massive insights into your data in real-time. We have an expo table and we're at your service!We're even more excited to invite you to join session today. Costin is the lead developer of Elasticsearch for Apache Hadoop, and his talk will cover using Elasticsearch, Hadoop and Storm. Join Costin at 4:35 PM today in the Future of Hadoop track!Costin will explore using Apache Hadoop as a data platform, Apache Storm for real-time computation, data ingestion and orchestration and Elasticsearch for performing advanced real-time searches. The session will also have a particular focus on the architectural challenges of bridging batch and real-time systems and how to overcome them, keeping a close eye on performance and scalability.We're looking forward to seeing everyone here at the San Jose Convention Center, and we'll be there throughout the conference. See you soon! \n"}<br>{"index": {"_id": 1310}}<br>{"title":"Where in the World is Elasticsearch? - June 02, 2014","seo_title":"","url":"\/blog\/world-elasticsearch-6","author":{"name":"Leslie Hawthorn"},"date":"June 02, 2014","category":"","locales":"","content":" Welcome to this week's ! Several members of our core developer team are speaking at conferences throughout the EU, and we've got meetups on from Belgium to Zurich. Read on to find where you can hear about all things ELK Stack, and a special chance to do live Q&A with our CTO, . From last week's Berlin Buzzwords' Adventures - Adrien Grand on Elasticsearch Aggregations Norwegian Developers Conference NDC Oslo will welcome more than 1600 attendees this week, covering topics from Cloud to User Experience. Our very own , creator of NEST, will teach you all about implementing search and provide a tour of Apache Lucene under the hood. Martijn's presentation, , on Friday, June 6th at 15:00 in Room 6. If you have any questions on .Net and Elasticsearch, make sure to say hi to Martijn during the conference! PyCon Russia Bringing together lovers of all things Python in Russia, this annual 2 day conference takes place June 2-3rd near Yekaterinburg. If you're joining us for the festivities, please plan to attend presentation on exploring your data, . Honza will take the stage in the main room at 14:10 on Day 2 of the conference. Don't forget to say hello in the hallway track - Honza is our go to guy for all things Python and Elasticsearch! Topconf Bucharest Topconf's vision is to be the conference series that inspires attendees with information on how to optimize business critical IT systems and to take future IT technologies and put them to the best possible use for customers. , the creator of Elasticsearch for Apache Hadoop, will present on . His session will focus on big data through the lens of the Hadoop platform and teach you how Map\/Reduce, Hive, Pig or Cascading jobs can leverage a search engine to significantly speed up execution and enhance their capabilities. You can catch Costin's talk at 15:20 in the Asia room on Thursday, June 12th. Costin will also be at the conference in the hallway track if you want to talk about how to make your life with Hadoop better! Mimacom Days Zurich Our partner Mimacom to give attendees the opportunity to network and hear about the latest cutting-edge technologies that can drive their businesses' success. This Wednesday, you can hear from , Elasticsearch core developer, on Elasticsearch - Beyond Full-Text Search. Alex's talk starts at 9:45, directly after the conference's opening remarks. Alex will be at Mimacom Days Zurich throughout the day, so make sure to say hello and ask him about all things JVM, concurrency, scalability and Elasticsearch! You can get your Elasticsearch hackfest on this week with the BigBoards Garage Meetup group in Aarschot. Meetups San Jose There are several great talks happening at meetups worldwide this week, but we're particularly excited to let folks know that Shay Banon, creator of Elasticsearch, will be holding a live Q&A session at this week's ! Join Shay and a bunch of our core developers at eBay's San Jose campus tomorrow, June 3rd. Doors open at 6:30 PM. Thanks to the Bay Area Search Meetup and eBay for hosting us! Aarschot, Belgium The will be hosting an evening of fun and hacking on Logstash & Kibana on Tuesday night. Everyone will be getting together at 19:30 for the festivities. what cool things you build during the meetup! Austin The will be hosting an introduction to various technologies, including Logstash, Docker, OpenStack and more. Doors open at 7:00 PM on Wednesday, and this meetup promises to be a great teaser for all the great content on offer at the upcoming Texas Linux Fest. (Psst: you can get an from Aaron Mildenstein, Logstash Core Developer, at TLF!) Breizh, France The Breizh JUG will welcome our very own , to talk about all things Elasticsearch this Thursday. Amongst other topics, David will cover how Elasticsearch can make your life far easier than using plain old SQL queries. Doors open at 18:00. London The is getting together this Wednesday 93 Feet East. In addition to our fabulous venue, there will be three presentations on Elasticsearch use cases, from OpenTable to Elasticsearch on bare metal hardware. Following the talks, there will be Q&A with Elasticsearch core developers and . Doors open at 18:30, and attendee spots are filling fast. to make sure you get a spot on the guest list! New York Karen Sun and the team from Sports195 will discuss their use of Elasticsearch, plus provide a deep dive into their internal Scala Elasticsearch library which wraps the Java API. Following Sports195's talk, you'll be treated to a live Q&A with two visiting Elasticsearchers, and . Doors open at 6:30 PM at ThoughtWorks' offices on Madison Avenue. Many thanks to ThoughtWorks for hosting us! Zurich Please join us on Thursday to hear from two Elasticsearch core developers, and . Alex will be sharing all about what's new in Elasticsearch, including an overview of new features the rationale behind the development process. Britta will deep dive into the Significant Terms aggregation, so if you're interested in finding out how to use Elasticsearch to find the uncommonly common, e.g. fraud and anomaly detection, don't miss this meetup! Doors open at 19:00 at Centralway HQ. Many thanks to Centralway for hosting us! Lots of great stuff on this week. Remember, if you\u2019re giving a talk, hosting a meetup or otherwise sharing the Elasticsearch love, . We\u2019d love to feature your knowledge sharing bits here! Last but not least, we've got some exciting news from Elasticsearch land coming to you this week, so the best is tuned into this blog. More to come! \n"}<br>{"index": {"_id": 1311}}<br>{"title":"Extending the Scripts Module","seo_title":"","url":"\/blog\/found-extending-the-scripting-module","author":{"name":"Konrad Beiske"},"date":"May 30, 2014","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. How to Add Another Scripting Language You can use this post as a starting point to make a language plugin for any scripting engine that implements the JSR-223 interfaces. \n"}<br>{"index": {"_id": 1312}}<br>{"title":"Openstack Elastic-recheck: Powered by the Elk Stack","seo_title":"","url":"\/blog\/openstack-elastic-recheck-powered-elk-stack","author":{"name":"Leslie Hawthorn"},"date":"May 29, 2014","category":"User Stories","locales":"","content":" Sean Dague at the recent OpenStack Summit in Atlanta on Every day, the OpenStack project runs hundreds of patches through its continuous integration system to assure code consistency, functionality and smooth integration with other projects in the OpenStack ecosystem. This process works exceptionally well for a majority of patches, but as with any system pushing so much data through development infrastructure, there are times when there are failures unrelated to the patches being tested. It may be that a VM goes down unexpectedly during a test, an external resource is unavailable (nameserver, package repository, etc), a service unrelated to the test locks up or one of many race conditions or other transient bugs pops up. Gatekeeper Graph Showing VMs Used over the Course of a Day Historically, the team worked to track these issues in bug reports, which developers could submit and then search through at to see if their failed change was tied to one of these types of \u201ctransient\u201d bugs. This process was largely manual and only gave limited data about the frequency and types of patches these bugs were occurring on. It was also difficult to determine whether a \u201cnew\u201d bug was only impacting your change, whether it had been going on for some time without being reported or whether the bug had simply gone away. There was also no automated way of notifying a developer that their change had encountered a known bug: they had to check the rechecks page themselves. Old Manual Rechecks Page When a developer ran into one of these bugs, they would then rerun the tests with a comment referencing the bug in our code review system. Enter Elasticsearch Back at the OpenStack Summit in the fall of 2012, Clark Boylan and Sean Dague came up with some ideas around a more automated solution, using Elasticsearch to address many of the issues with the manual process so that developers could be automatically notified if their change hit a known bug. In 2013, Clark began implementing an Elasticsearch + Logstash + Kibana (the ELK stack) solution for the OpenStack infrastructure. The stable setup he finally came up with is fully open source and documented at . Over that summer, Sean created some sample code to talk to the web service. Joe Gordon and Matthew Treinish then turned the sample code into in September of 2013, when stress on the project infrastructure hit a high point and manual rechecks were common. With now in place, contributors can: Format for this change is , so for , a file called with data from the bug would be created containing: query: > message:\"SSHTimeout: Connection to the\" AND message:\"via SSH timed out.\" AND tags:\"console.html\" AND NOT build_name:\"check-tempest-dsvm-neutron-heat-slow\" (You can see live files here: .) Just like everything else in the OpenStack ecosystem, this patch is then reviewed by peers and then merged into the system to be used. From there, the page is automatically generated with all bugs included as queries in . The page includes frequency graphs and links to resources for each bug: . Home Page Automatic responses are then fed into our code review system from when a patch hits a known bug, e.g.: Automatic Response to Code Review from Now, when known failures are encountered, subsequent developers running into the same issue are automatically notified and can take the appropriate action immediately without having to search through the bug tracker. This innovation has been a boon for our developers, who can now move along more efficiently with development instead of getting stuck on transient bugs. Overview of Flow by Sean Dague By using the ELK stack and , we have given members of our community tools that allow them to: You can find out more about here: Thanks to Clark Boylan, Joe Gordon and Sean Dague for reviewing this article, and to Matt Riedemann and Matthew Treinish who keep reviews for this project coming along as additional core reviewers. \n"}<br>{"index": {"_id": 1313}}<br>{"title":"This Week in Elasticsearch - May 28, 2014","seo_title":"","url":"\/blog\/2014-05-28-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"May 28, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Today's hackathon. Thanks for all! \u2014 Leslie Hawthorn (@lhawthorn) Elasticsearch Ecosystem Here\u2019s some more information about what is happening in the ecosystem we are maintaining around the ELK stack \u2013 that\u2019s Elasticsearch plus Logstash and Kibana \u2013 including plugin and driver releases. Introduces Kibana at last week\u2019s Slides & Videos We\u2019re got a bunch of slide & video love from Berlin Buzzwords and beyond! \n"}<br>{"index": {"_id": 1314}}<br>{"title":"Elasticsearch for Apache Hadoop 2.0 GA Released","seo_title":"","url":"\/blog\/es-hadoop-2-0-g","author":{"name":"Costin Leau"},"date":"May 27, 2014","category":"Engineering","locales":"","content":" I am elated to of Elasticsearch for Apache Hadoop 2.0 GA. Elasticsearch for Apache Hadoop, affectionately known as es-hadoop, enables Hadoop users and data-hungry businesses to enhance their workflows with a full-blown search and analytics engine, in real-time. es-hadoop is open source and works across different Hadoop, Cascading, Apache Hive and Apache Pig versions and across multiple Hadoop , whether vanilla Apache Hadoop, Cloudera CDH, Hortonworks HDP, MapR or Pivotal. No dependencies, all the functionality. Native Integration with Hadoop Using Elasticsearch with Hadoop has never been easier. Thanks to our deep API integration, interacting with Elasticsearch is similar to interacting with HDFS resources, whatever the environment used, from plain Map\/Reduce, to Cascading plans, Pig scripts and Hive queries. For each environment, es-hadoop provides a interface that one can use to read, write and query Elasticsearch transparently: the dedicated Map\/Reduce \/, Cascading \/, Hive \/ and Pig \/tions take care of the heavy lifting so you do not have to fiddle with data conversion or network communicating with Elasticsearch. If your data happens to be JSON that's fine by us: es-hadoop supports that too. Pure Map\/Reduce model Most importantly, the Map\/Reduce model in Hadoop is mapped on top of your Elasticsearch cluster: by leveraging Elasticsearch distributed architecture es-hadoop operation scales out, being executed in parallel across the target shards. In other words, whenever a write or a read is issued, es-hadoop will dynamically determine the number of shards used for the target index and, for each one, use a dedicated task to push\/pull the data in parallel, enabling the operation to scale out with the data. Moreover, es-hadoop has full insight into the data topology used underneath so it can run its tasks with the data, a great performance boost in deployments where Elasticsearch and Hadoop clusters run side by side. Portability Elasticsearch Hadoop is actively tested against various Hadoop distributions (such as vanilla Hadoop, CDH, HDP, MapR, Pivotal). Whether you are using Hadoop 1.x or 2.x, the so-called old () or the new () API, vanilla Hadoop or a certain distribution, we invest heavily in ensuring that es-hadoop works reliably no matter your Hadoop environment. Operational Ease es-hadoop provides a single binary (~350 KB jar) for its entire feature set, and those interested in saving a few KBs can use the jars. Without any dependencies, each jar can be used as is, easily embedded inside Hadoop jobs or provisioned throughout the cluster. At runtime, the firewall-friendly HTTP\/REST protocol is used while HTTP and SOCKS proxies (with or without authentication) being supported for those running in locked down networks. Production-ready, at Scale We are happy to report that es-hadoop is being used in multiple data-intensive environments: in a recent example, a large financial institute that stores all of their raw access logs in Hadoop \u2013 billions of documents \u2013 has been using es-hadoop to index the data into Elasticsearch and then visualize it using Kibana. This approach allowed the customer to have near real-time visibility into their data through Kibana, yet also run batch oriented jobs over all their raw data when needed. By combining Hadoop and Elasticsearch, organizations gain a scalable, distributed platform that enables fast search and data discovery across tremendous amounts of information. And through es-hadoop, this is easier than ever. But don't take our word for it, es-hadoop 2.0 GA, try it out and what you think! \n"}<br>{"index": {"_id": 1315}}<br>{"title":"Where in the World is Elasticsearch: Berlin Buzzwords Edition","seo_title":"","url":"\/blog\/world-elasticsearch-berlin-buzzworks-edition","author":{"name":"Leslie Hawthorn"},"date":"May 26, 2014","category":"","locales":"","content":" Welcome to the latest edition of . For this week, the answer is largely \"at \"! If you're joining us in Berlin, there's a full docket of Elasticsearch content on offer at the conference. If you're not, no worries - the conference organizers will be taping and publishing all of these sessions for your later enjoyment and edification. Plus, we've got Bulgaria Web Summit at the end of the week and plenty of meetup goodness worldwide. Sit back, relax, and enjoy the shows! Berlin Buzzwords Now in its 5th edition, Berlin Buzzwords brings together experts in all of our favorite buzzwords: cloud, search, storage, scale and beyond. The conference runs from May 25-26th in Berlin at Kulturbraurei, capping off with hackathons running in various locations throughout the city on Wednesday, the 27th. When you're not attending sessions, you can visit us anytime at the Elasticsearch stand in the Palais Building, where we can offer you knowledge, swag and delicious smoothies! All things Elasticsearch at Buzzwords: Monday, May 25th Tuesday, May 27th Wednesday, May 28th The fine folks at the Elasticsearch User Group Berlin have once again organized an Elasticsearch Hackathon for Buzzwords! We're nearly at capacity, so if you are interested in attending so we can try to find a place for you. Thanks again to for organizing! Bulgaria Web Summit The Bulgaria Web Summit is an all day event on Saturday, May 31st with a number of great talks on offer. If you're attending, make sure to stop by session at 16:45 on Explore your data. Honza promises us 60% code & console commands, no slides, all how Elasticsearch helps you make sense of your data. Meetups From Belgium to Washington, D.C, here's where to get your Elasticsearch Meetup on this week: Monday, May 25th Tuesday, May 26th Wednesday, May 27th And that's a wrap for this week. Remember, if you're giving a talk, hosting a meetup or otherwise sharing the Elasticsearch love, . We'd love to feature your knowledge sharing bits here! \n"}<br>{"index": {"_id": 1316}}<br>{"title":"Elasticsearch Teams up with MIT Sloan for Data Analytics Hackathon","seo_title":"","url":"\/blog\/elasticsearch-teams-mit-sloan-data-analytics-hackathon","author":{"name":"Sejal Korenromp"},"date":"May 23, 2014","category":"News","locales":"","content":" Following from the success and popularity of the we participated in late 2013, last week we sponsored the for our latest offering to Elasticsearch aficionados. More than 50 software engineers, business students and other open source software enthusiasts signed up to participate, and on a Saturday to boot! The full day's festivities included access to a huge storage and computing cluster, and everyone was set free to create something awesome using Elasticsearch. <p> <img class=\"alignnone\" alt=\"\" src=\"https:\/\/lh4.googleusercontent.com\/yeI6ABiqGMWK6t-LfGLTVZEPd2AVGoRQ5VXV5kmYhhAA97CaU5CMHcQ2yRqi8QWrrzmAIw0CUnkuIAcVZt2ChuvC2Yoxw_RdiEcX4vshwADqcBL_aLnFzWIMN-3bpS1WQg\" width=\"624px: \" height=\"181px: \" style=\"margin: 10px: \" > <\/p> <p class=\"blog-img-caption\"> <a href=\"http:\/\/twitter.com\/imotov\">Igor Motov<\/a> teaches the crowd about all things ELK Stack <\/p> With no time to lose, we kick started the session with and , two of our software engineers. They gave an overview of the , followed by an in-depth tutorial to get new users up to speed with the search engine's features and implementation. Even those never exposed to these technologies were wowed, especially by Kibana and how its simplicity and beauty provides a powerful data visualization solution. Binh Ly in action: Kibana, Simple & Beautiful The participants then split into 5 teams, and from that moment on it was heads down hacking time. Whilst the teams were diving into real world data sets \u2013 including Tweets, Wikipedia and datasets \u2013 our expert duo were at hand to answer questions, help troubleshoot, and advise and inspire along the way. No hackathon is complete without an element of competition, so with a prize incentive up for grabs, the teams were unstoppable. The five finalists came up with some incredibly cool hacks, including: Chris had the idea of taking ebooks from , extracting content and metadata, indexing it into Elasticsearch and providing a single search box that allows you to easily search through all the texts. Project Gutenburg contains 45K ebooks and a public domain API. He used Python to index the content into Elasticsearch and Node.js to build a search webpage. He was also thinking of eventually allowing multiple users to do collaborative annotations on each ebook. This team looked at sentiment analysis for a number of food chains: Burger King, McDonald's, Subway and Chipotle. Using Twitter mentions, they looked for these brand names and associated sentiment words. e.g. \u201clike\" or \u201cdislike\" terms such as \u201cawesome,\" \u201cgreat,\" \u201cbest,\" \u201cme gusto,\" \u201cfun,\" \u201cworst,\" \u201cbad,\" etc. Based on their counts and ratios, they determined that Burger King had the most positive sentiment, and Chipotle had the most negative sentiment. Invaluable data for the next snack attack you might have, really. <p> <img class=\"alignnone\" alt=\"\" src=\"https:\/\/lh6.googleusercontent.com\/G4EGElp5xqq7yf0aD5gD2nLllS0GEGJqUu00WT1p6J-fpdaJSJghZHYXRmVOmpt9zGm8EYpRP9maFtED5vnZy-erxKuKsfX8NkrqDZeLUOtHshsE4fWlyxHWHdc68Y48og\" width=\"533px: \" height=\"249px: \" style=\"margin: 12px: \" > <\/p> <p class=\"blog-img-caption\"> Happy hacking! <\/p> Theja had the idea of taking data on papers submitted to the conference, extracting metadata and PDF content, indexing it into Elasticsearch and making it searchable. Currently, only very few pieces of metadata (e.g. title and author) are searchable online, so making the body\/content of these papers searchable benefits research by making discovery of these papers much easier. He used Python to do all the processing and indexing, standardizing the data all into a common schema (e.g. paper ID, filename\/url, keywords, authors, body, etc.). Theja then used Kibana to dig into his newly generated dataset, as well as perform some interesting aggregations. He came up with some interesting discoveries, such as what nationalities are the most common amongst paper submitters, the most common topics that are in the body of each paper, etc. Siddharth's idea was to provide the ability to dynamically search on any topic\/brand in Twitter stream and dynamically perform sentiment analysis on Tweets. This sentiment analyzer could be used to search for movies and see how people rate\u00a0a movie on Twitter. He also described how he could extend this to other ideas like machine learning and correlation. For example, sentiment on a specific product could be correlated to a company's stock price performance. Since they had no prior Elasticsearch experience, this team decided to use Kibana, exploring Wikipedia data for a correlation between a person's profession and their chances of success. They also dived into the TMDB dataset with some analysis on movies by different characteristics such as cost, running time, revenue, language, country etc. Using Kibana's panel overviews, they were able to visualize their data finding\u00a0relationships and\u00a0correlations\u00a0among these characteristics. For example, they demonstrated how cost was correlated to runtime and revenue. Home stretch! And the winner is \u2026 All in all, it was a tough competition, and every team had great ideas for ways in which to analyze their data sets with the ELK stack. This time the 1st prize went to Titka and Jacek for their exploration of Statistics on Movies and Wikipedia \u2013 well done to you both. For folks who didn't walk away with Amazon gift cards, the fine folks at O'Reilly Media donated a number of titles on data science from their quite impressive catalog. (Thanks again, !) Thanks once again to the crew at the MIT Sloan Data Analytics Club, especially Lior Belenki, for organizing and supporting this initiative. A huge shout out of love to our developers Igor and Binh for helping spread the knowledge of the ELK stack amongst all our attendees. And, of course, thanks to the for hosting what turned out to be yet another great community activity around Elasticsearch! \n"}<br>{"index": {"_id": 1317}}<br>{"title":"Elasticsearch 1.2.0 and 1.1.2 released","seo_title":"","url":"\/blog\/elasticsearch-1-2-0-released","author":{"name":"Clinton Gormley"},"date":"May 22, 2014","category":"Engineering","locales":"","content":" Today, we are happy to announce the release of , based on Lucene 4.8.1, along with a bug fix release . You can download them and read the full change lists here: Elasticsearch 1.2.0 is a bumper release, containing over 300 new features, enhancements, and bug fixes. You can see the full changes list in the , but we will highlight some of the important ones below: Breaking changes While there are a few more breaking changes than just those listed here, most of those probably won\u2019t affect you. The following, however, are very important: Java 7 required Elasticsearch now requires Java 7 and will no longer work with Java 6. We recommend using Oracle\u2019s JDK 7u55 or JDK 7u25. Avoid any of the updates in-between as they contain a nasty bug which can cause index corruption. Dynamic scripting disabled by default Elasticsearch allows the use of scripts in several APIs: document updates, searches and aggregations. can be loaded from disk (static scripts) or specified directly within a request (dynamic scripts). Unfortunately MVEL, the current default scripting language, does not support sandboxing, meaning that a dynamic script can be used to do pretty much anything that the user can do. While it has been possible to disable dynamic scripting for a long time, we\u2019ve decided to change the default to disable dynamic scripting out of the box. See . Watch this space for a blog post giving more details about the future of scripting in Elasticsearch. Field data and filter caches The JVM heap has to be shared by a number of competing resources such as field data, filter caching, index buffering, aggregations, etc. Field data in particular can be greedy and, in the past, has caused a number of users to experience OOM conditions. We added the to try to prevent these OOMs. Initially we set the default circuit breaker limit to 80% of the heap size, but that appears to have been too generous. We have now changed the default circuit breaker limit to of the JVM heap, and the filter cache to of the heap. Some Logstash users and other users of time-based indices might find that queries that worked correctly the day before have now suddenly stopped working. The reason for this failure is that the field data cache is full of old data which is no longer being used, so the circuit breaker is refusing to load more field data. This can be worked around either by or by setting the (which is unbounded by default) to a value like of the heap. We hope to have a better answer for this in the next release. Gateways removed The shared filesystem, S3 and HDFS gateways have been deprecated for a long time, and they have finally been removed. The functionality should be used instead. New features and enhancements The improvements in this release are heavily focussed on performance and resource usage, specifically during indexing and aggregating. Indexing and merging We tend to think of indexing and merging as separate functions, but really they are very closely related. The indexing process takes the docs in the indexing buffer and writes them to disk as a small segment. Having too many segments slows down indexing and searching, so the merge process merges smaller segments into bigger segments in the background. There is a balance between the size of new segments and the speed at which your changes become searchable. Very large merges can swamp the I\/O on a node, slowing down other functions like search. To control this we have merge throttling, which slows down the merge speed to 20 MB\/s by default. However, it is quite possible that the indexing rate is so high that merges just can\u2019t keep up, leading to an explosion of segments. This hurts indexing and searching. To improve the interplay of all of these factors, we have: Of course, it is difficult to provide good defaults both for users with spinning disks and users with SSD. If you have spinning disks, you may consider dropping from its default value of to . If you are just indexing, without searching, you may want to disable completely by setting to . On top of these changes, we have improved indexing performance for the typical logging use case: Aggregations Aggregations are awesome. Now we\u2019re making them awesomely fast, and less memory hungry while we\u2019re about it: We\u2019ve also added some new functionality to aggregations: Other new features Context Suggester The is very popular, but the number one feature request has been to allow it to perform filtering. Unfortunately, the reason it is so fast is that it does not rely on the usual search infrastructure at all, meaning that adding our normal filters would just slow it down. The new builds on the completion suggester by allowing you to specify \u201ccontexts\u201d, which can be the value(s) of a field or a geo-location. For instance, you could use contexts for music suggester like , , , and a song may be both and . Watch this space for a blog post explaining the context suggester in detail. Improved deep scrolling Previously, it was only possible to retrieve large numbers of documents from a search request by using , which returns results unordered. The has been improved to keep track of the last document returned from every shard, meaning that deep scrolling of sorted docs is now almost as efficient as . Field value factor Using a field like to boost individual documents is so popular, that we decided to add a bit of sugar to the . Instead of having to use a script like: You can now do: A handy side benefit of this change is that the will still work when dynamic scripting is disabled. Conclusion We hope you are as excited about these new features as we are. Please download , try them out, and let us know what you think . You can report any problems on the . \n"}<br>{"index": {"_id": 1318}}<br>{"title":"This Week in Elasticsearch - May 21, 2014","seo_title":"","url":"\/blog\/2014-05-21-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"May 21, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Elasticsearch Core NOC Display with switching Tabs, powered by , and some jQuery to parse JSON Output \u2014 Andri Steiner (@andristeiner) Elasticsearch EcosystemHere's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. . is a happy customer RT speaking about at . \u2014 Grant Gochnauer (@GrantGochnauer) \n"}<br>{"index": {"_id": 1319}}<br>{"title":"Quick Tips: Negative Connotation Filter","seo_title":"","url":"\/blog\/quick-tips-negative-connotation-filter","author":{"name":"Zachary Tong"},"date":"May 20, 2014","category":"Engineering","locales":"","content":" global wrapper \n"}<br>{"index": {"_id": 1320}}<br>{"title":"Where in the World is Elasticsearch? - May 19, 2014","seo_title":"","url":"\/blog\/world-elasticsearch-5","author":{"name":"Leslie Hawthorn"},"date":"May 19, 2014","category":"","locales":"","content":" Welcome to our weekly news bite about where you can find all sorts of Elasticsearch & ELK stack goodness. This week, will get you ready for the wide world of Elasticsearch and Kibana, while will teach you how to love your logs with Logstash - the L in the Elasticsearch ELK stack - and Elasticsearch & Kibana.DatabeatGood morning, San Francisco! Headed to today and tomorrow? Make sure to say hello to our resident Elasticsearchians, and as you wend your way through The Grand Hyatt Union Square. And block your calendar now for 3:10 PM today, as you won't want to miss Graham Tackley, Director of News and Architecture at The Guardian, on User Behavior Analytics Frameworks to Drive Revenue. Solutions LinuxThe team putting on are at it again, bringing you the edition of the conference this week on May 20th and 21st in Paris. Join David Pilato on Wednesday, May 20th at 11:40 AM in Salle Monet for a one hour workshop, including a feature overview of Elasticsearch and an introduction to Kibana. You can also visit our team throughout the conference in Booth A18. Come on over and say \"Bonjour!\"GOTO ChicagoWith this on offer, we just had to go, too. Join us at on May 20th and 21st at the Drake Hotel. We'll have and other folks from Elasticsearch Inc there to answer all of your questions and to offer you some cool ELK toy goodness. Plus, we've got a meetup on in Chicago !You can visit Binh and the rest of the Elasticsearch team at Booth #2. GlueconGluecon 2014 kicks off on Tuesday, May 20th with a pre-conference camp, CampDevOps @ Gluecon. Even if you're not joining us for Gluecon on May 21st & 22nd, you can still attend CampDevOps. Just !For those who will be attending Gluecon in Broomfield, Colorado, plan to hear from the creator of Logstash, Jordan Sissel. Jordan will be covering Love Your Logs with Elasticsearch ELK at 11:05 AM in Breakout Room #2, directly after the conference opening keynotes on Wednesday.Jordan and other stalwart folks from the Elasticsearch team will be hanging out at the Elasticsearch table, T8, when not presenting. Visit us to get some cool Loggy and Elasticsearch stickers!BreizhCampDavid Pilato will conclude his Elasticsearch love powered tour of France this week in Rennes at . The conference runs from May 21-23rd, with David leading a hands on Elasticsearch and Kibana workshop at 10:30 AM on Thursday. Make sure to attend David's workshop and chat with him during the breaks about all things ELK stack! If that's not enough Elasticsearch goodness for you, J\u00e9r\u00f4me Mainaud will cover Five Ingredients to Spice up Your Elasticsearch experience on Thursday evening. Bonjour, J\u00e9r\u00f4me! Nous sommes impatients de vous rencontrer \u00e0 BreizhCamp!Polyglot VancouverThe fine folks at the Polyglot Unconference in Vancouver, BC, Canada are hosting their annual event on May 23-25th. The conference kicks off with Ganesh Swami presenting a half day workshop on .MeetupsSince you are not Dr. Who and are therefore likely without a Tardis, you may not be able to join us for all these conferences. But we have lots of great meetups happening this week. Please join us in a city near you for more informal get togethers, including refreshments and tasty talk treats!San FranciscoOkay, so we took this one out of alphabetical order, but that's because we're welcoming a speaker from overseas. Please join us tomorrow, Tuesday, May 20th to hear from Graham Tackley, Director of Architecture at The Guardian News and Media. Graham will discuss how to build an analytics platform that allowed everyone in The Guardian's newsroom to deep dive into reader engagement - all in real-time. But wait, there's more! Kirsten Stewart from Desk.com will present on the challenges, complexities, and triumphs Desk has experienced giving their users a near real-time experience using various tools and configurations of Elasticsearch. We're at capacity now, but there's still . If you cannot join us in person, we'll be taping the talks, so stay tuned to this blog for updates.ChicagoThe day after the conference program for GOTO Chicago concludes, the fine folks at ADP Dealer Services will be hosting the 4th Elasticsearch Chicago Meetup. Attendees will hear from Binh Ly on an Introduction to Kibana, and from on Improving Resiliency in Elasticsearch.Doors open at 6 PM in Thursday, May 22nd. , as space is limited. We'll fill your brain, feed your belly and you'll probably walk out with some cool Elasticsearch gear.MiamiThe Miami JVM Users Group will get together on Thursday, May 22nd and cover an . Doors open at 7:00 PM.SydneyMark Walkom, the lovely organizer of the group, will don his SAGE-AU User Group speaker hat and treat folks to a talk on . Please join Mark and company at 6:00 PM on Tuesday, May 20th at Google's Sydney offices. Logstash stickers on us!Headed off to Berlin....Next week, the Elasticsearch team in Europe will be out in force at . We'll get you a full itinerary for all things Elasticsearch at Buzzwords next Monday, but for the moment go ahead and on May 28th. It'll be great!We'll see you next week's exciting installment of \n"}<br>{"index": {"_id": 1321}}<br>{"title":"Kibana 3.1 is out!","seo_title":"","url":"\/blog\/kibana-3-1","author":{"name":"Rashid Khan"},"date":"May 15, 2014","category":"Engineering","locales":"","content":" Kibana 3.1 has been tagged and released! In addition to the usual smattering of bug fixes and small tweaks we have added a few fun features we\u2019d love to share with you.Extended statisticsThe stats panel has been expanded to include all eight statistics Elasticsearch makes available. Of course all can be toggled, and sorted.A stats button in the tableIn addition to the terms button, we\u2019ve added a stats button to create an adhoc stats panel. The button is type aware: it only appears for numeric fields.Drag it to the dashboardIn addition to the new stats button in the table, both the terms and stats panels in the table can be dragged directly onto the dashboard by grabbing their move icon. This means no more going through the menus if all you need is a quick panel, just drag it from the table onto your existing dashboard. After you\u2019ve dragged it to the dashboard, grab the right edge of the panel and drag to resize!Help us out!Have a great idea for a feature? Find a bug and want to fix it? Head over to the . Have some really great ideas? And the passion and skills to implement them? We\u2019re working on the next generation of Kibana right now, \n"}<br>{"index": {"_id": 1322}}<br>{"title":"This Week in Elasticsearch - May 14, 2014","seo_title":"","url":"\/blog\/2014-05-14-week-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"May 14, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch Core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Slides & Videos Where to Find Us We'd love to feature all the great Elasticsearch, Logstash and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Community Manager, , know! Australia The wonderful Mark Walkom, Community Organizer of the Elasticsearch Sydney Meetup, will discuss How to on May 20th. Join Mark at Google Sydney for the May SAGE-AU Meetup at 6 PM. Austria The has scheduled their first meetup for Thursday, June 12th. Please join us at 7 PM to hear from on What's New in Elasticsearch. Bulgaria will discuss how to Explore Your Data using Elasticsearch at the . The conference takes place on May 31st in Sofia. Canada The fine folks at the Polyglot Unconference in Vancouver, BC are hosting their annual event on May 23-25th. The conference kicks off with Ganesh Swami presenting a on Getting Started with Elasticsearch. France Germany Norway will be speaking on from text to full-text search at the conference. The show runs from June 2-6th. Poland The Torun JUG will get together on May 28th at 6 PM to talk about , with a spotlight on Elasticsearch. Romania will speak at on Big data real time search and analytics. Topconf Bucharest runs from June 10-13th and Costin will speak at 3:20 PM on June 12th. Russia will speak at . The schedule is still being finalized, but mark your calendars for June 2nd and 3rd. If you're heading to PyCon Ru, make sure to say hello to Honza! Spain has been invited to speak at the Barcelona on Rails Meetup on May 15th. Join him for a presentation on Doors open at 7 PM, and thanks to the fine folks at XING for hosting us! Switzerland United Kingdom United States Where to Find You Our Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1323}}<br>{"title":"Managing Elasticsearch Fields When Searching","seo_title":"","url":"\/blog\/found-managing-elasticsearch-fields-when-searching","author":{"name":"Njal Karevoll"},"date":"May 13, 2014","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. Controlling the number of fields returned for search requests is an important aspect of maximizing Elasticsearch's performance. In this article we'll look at how we can selectively return only the fields we're interested in for each search hit in order to optimize our usage pattern. \n"}<br>{"index": {"_id": 1324}}<br>{"title":"Marvel 1.1.1 released","seo_title":"","url":"\/blog\/marvel-1-1-1-released","author":{"name":"Boaz Leskes"},"date":"May 12, 2014","category":"","locales":"","content":" Today, we are happy to announce the release of . This is a bug fix release, fixing an issue with the correct interpretation of timeout settings by the Marvel agent. Although this bug is not critical, we felt it was important enough to justify a release. While this release is beneficial for all users, we especially recommend it if you are experiencing occasional timeout errors such as these: [2014-05-12 21:52:41,133][ERROR][marvel.agent.exporter ] [Robert da Costa] error connecting to [10.255.255.1:9200] java.net.SocketTimeoutException: connect timed out To upgrade, you must install the latest Marvel plugin on all your ES nodes. As with any other Java plugin, you will need to restart nodes (one by one) in order for the version to become active. You may follow a similar procedure to the rolling upgrade of Elasticsearch itself, described in more details . As always, we welcome all feedback so we can continue improving Elasticsearch Marvel. Please send questions, praise or pains to the . \n"}<br>{"index": {"_id": 1325}}<br>{"title":"Where in the World is Elasticsearch? - May 12, 2014","seo_title":"","url":"\/blog\/world-elasticsearch-4","author":{"name":"Leslie Hawthorn"},"date":"May 12, 2014","category":"","locales":"","content":" Welcome to the latest installment of Where in the world is Elasticsearch. We've got and speaking at conferences en France, plus plenty of awesome meetups featuring our core devs!DjangoCon EUIf you happen to find yourself on the beautiful \u00cele des Embiez in France, you're probably already at . Good for you, my friend! Join Honza for his talk and enjoy hacking from the beach!dotScaleThe folks have organized another fantastic program in Paris. David Pilato and will help kick off the festivities on dotScale Workshop Day! Join David and Adrien this Saturday, May 17th at from 2-6 PM for a hands on . David and Adrien will be on hand for whole dotScale conference, so make sure to say hello in the hallways.MeetupsWhere to get your tasty ELK stack tidbits, from Algeria to the Philippines.Tuesday, May 13th Wednesday, May 14thJoin David Pilato, Adrien Grand and at the . Doors open at 6:30 PM in Paris. Costin will talk Elasticsearch and Apache Hadoop, and our friends at Nuxeo will share the story of how Elasticsearch made their lives better. Many thanks to the folks at Nuxeo for having us, and for speaking!Thursday, May 15thThe Barcelona on Rails Meetup will welcome to speak on ! Door open at 7:00 PM. Many thanks to the Barcelona Rails folks and XING for hosting us!More to Come...We've got a packed event calendar next week. Stay tuned to this space for more news next Monday! \n"}<br>{"index": {"_id": 1326}}<br>{"title":"Elasticsearch for Apache Hadoop 2.0 RC1 released","seo_title":"","url":"\/blog\/es-hadoop-20-rc1","author":{"name":"Costin Leau"},"date":"May 08, 2014","category":"","locales":"","content":" I am glad to report that 2.0 RC1 has been . As the label implies, this release brings the current development iteration close to fruition. Since the , exactly one month ago, several improvements have been made: Index time\/date-based formatting If you are dealing with time-based data (such as logs), es-hadoop can determine and format the target index\/type based on the data being processed, entry by entry. This works transparently across libraries (Map\/Reduce, Cascading, Hive, Pig) or, if opted so, on the raw JSON: Support for update scripting The and has been extended to allow the use of scripts and to mirror the Elasticsearch update API. Furthermore, the script parameters can be extracted dynamically, at runtime, from the data being processed. As you would expect, this works consistently raw JSON and Hadoop libraries. Upgrade to the latest Apache Hive and Pig We are actively monitoring the releases in the Hadoop ecosystem. es-hadoop 2.0 RC1 is not just compatible with the latest Apache Pig (0.12.1) and Apache Hive (0.13.0), it also supports the newly introduced types (like ) while preserving backwards compatibility. Increase the version from 1.3 to 2.0 While reviewing the list of changes since the of Elasticsearch for Apache Hadoop started, we quickly realized the version needs to reflect the plethora of new features and functionality added. And thus 1.3 became 2.0. In addition to all these updates, es-hadoop has been extensively tested across various Hadoop distributions to ensure full compatibility: whatever your environment, we want to make sure es-hadoop works flawlessly. Besides bug-fixes, the new release contains improved error and logging messages (especially when it comes to connectivity and network issues) to speed up the recovery process. As always, we appreciate feedback - please take 2.0 RC1 and \n"}<br>{"index": {"_id": 1327}}<br>{"title":"Logstash 1.4.1 has been released!","seo_title":"","url":"\/blog\/logstash-1-4-1-released","author":{"name":"Kurt Hurtado"},"date":"May 07, 2014","category":"Engineering","locales":"","content":" The Elasticsearch Logstash team is pleased to announce the release of version 1.4.1. This is a minor version containing mostly bugfixes and minor feature enhancements. This version of Logstash now contains an embedded version of Elasticsearch 1.1.1, as well as Kibana 3.0.1. We strive to constantly improve all aspects of our software, both glorious and mundane. To that end, we have updated our documentation, which, as always, is driven by our community of users - both via feedback and actual user documentation submissions. Also, the project's testing infrastructure received some love in this cycle, as our team has been busy improving the specs and tests as well as our continuous integration system. Lastly, the packaging has been greatly improved, ensuring users on all of our supported platforms have great experiences when deploying Logstash! Inputs, Outputs and Filters Packaging improvements You can read the full , or jump right to the . \n"}<br>{"index": {"_id": 1328}}<br>{"title":"This week in elasticsearch - May 07, 2014","seo_title":"","url":"\/blog\/2014-05-07-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"May 07, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Slides & Videos Where to find Us We'd love to feature all the great Elasticsearch, Logstash and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Community Manager, , know! Austria The has scheduled their first meetup for Thursday, June 12th. Please join us at 7 PM to hear from on What's New in Elasticsearch. Brasil Elasticsearch is very excited to send our first speaker from the company to Brasil! Leslie Hawthorn, our Community Manager, will be returning to FISL once again to speak on . Leslie will speak on May 7th and runs from May 7-10th in Porto Alegre. Her talk will be in English but most of the talks on the program are given in BR-PT. Leslie will also be on hand to answer questions you may have about Elasticsearch, Logstash and Kibana. Bulgaria will discuss how to Explore Your Data using Elasticsearch at the . The conference takes place on May 31st in Sofia. Denmark The inaugural will convene on Tuesday, May 13th at 7 PM. Please join us to hear from , and our friends at Falcon Social. France Germany Norway will be speaking on at the conference. The show runs from June 2-6th. Romania will speak at on Big data real time search and analytics. Topconf Bucharest runs from June 10-13th and Costin will speak at 3:20 PM on June 12th. Russia will speak at . The schedule is still being finalized, but mark your calendars for June 2nd and 3rd. If you're heading to PyCon Ru, make sure to say hello to Honza! Spain has been invited to speak at the Barcelona on Rails Meetup on May 15th. Join him for a presentation on Doors open at 7 PM, and thanks to the fine folks at XING for hosting us! Switzerland Tunisia will speak at the Esprit JUG Days in Ariana. The conference runs from May 7th and 8th. You may want to visit the for more details on the group or just . United Kingdom United States \n"}<br>{"index": {"_id": 1329}}<br>{"title":"Logstash Puppet module 0.5.0 released","seo_title":"","url":"\/blog\/logstash-puppet-module-0-5-0-released","author":{"name":"Richard Pijnenburg"},"date":"May 06, 2014","category":"Engineering","locales":"","content":" Today, we are happy to announce the release of our . You can download it and read the full changes list here: What's New Like we did in the , we've made a number of improvements, including a better test suite, and switching to for easier configuration. We have worked hard to incorporate the package changes that were made in logstash 1.4.x, and now you can install the contrib package directly from the repository or other remote source. We have also made some minor improvements like fixing inline documentation and, with the help of the community, found and squashed some minor bugs. We're always working to improve the quality and support of our Puppet offerings, and we hope you enjoy these latest enhancements. As always, you can give us your feedback or report problems on our page. \n"}<br>{"index": {"_id": 1330}}<br>{"title":"A Little Elasticsearch Hometown Love for Rails Girls Amsterdam","seo_title":"","url":"\/blog\/railsgirls-amsterdam-free-ruby-rails-workshop-girls","author":{"name":"Livia Froelicher"},"date":"May 06, 2014","category":"News","locales":"","content":" We\u2019re very happy that Elasticsearch will be sponsoring RailsGirls Amsterdam! Rails Girls Amsterdam is a two days Ruby on Rails workshop, on June 6 and 7, for absolute beginners in the world of programming and web development. Rails Girls wants to empower girls to build capacity and acquire the tools they need to conquer the last online frontier. Our aim is to provide tools and a community where women come together to study technology and build their ideas. Come join us and learn sketching, prototyping, basic programming and get introduced to the world of technology! Rails Girls was born in Finland, but is nowadays a global, non-profit volunteer community. Thanks to Elasticsearch we can provide the girls some awesome refreshments! Are you or do you know a woman who wants to learn programming for free? Applications for Rails Girls Amsterdam are ! Don\u2019t miss out! Apply at ! \n"}<br>{"index": {"_id": 1331}}<br>{"title":"Where in the World is Elasticsearch? - May 05, 2014","seo_title":"","url":"\/blog\/world-elasticsearch-3","author":{"name":"Leslie Hawthorn"},"date":"May 05, 2014","category":"","locales":"","content":" Welcome to the merry month of May! As we start this month's adventures, we've got a full slate of awesome talks coming up this week. If you're attending any of these conferences, we hope that you'll stop by to meet our team members!DevOps Days Austin\u00a0Our very own Logstash core developer and creator of\u00a0,\u00a0, will be at\u00a0. The conference takes place on May 5th and 6th, and you can meet up with Aaron during the festivities at the Elasticsearch table. Even cooler, Aaron is hoping to schedule some time during the conference's open space hours to talk logging, the ELK stack and other topics near and dear to the heart of ops humans (and developers!). Make sure to say stop by our table and say hello to Aaron!MonitoramaThe North American edition of , an open source monitoring conference and hackathon, kicks off at 9 AM today in Portland, Oregon, US. In addition to all of the great talks on the agenda, , creator of Kibana, will host a workshop on Wednesday, May 7th just after the opening welcome at 9:45 AM. Check out the workshop, and make sure to say hi to Rashid and in the hallway track! Espirit JUG Day TunisiaThe will hold their annual conference on May 7th and 8th in Ariana. , Elasticsearch Developer Advocate and DJ extraordinaire, will host two sessions: Make sure to attend David's talks. If everyone is excited about it, perhaps you can convince him to spin some tunes like he did recently at Devoxx France! 15th F\u00f3rum Internacional de Software Livre and Brasil MeetupsElasticsearch is very excited to send our first speaker from the company to Brazil! Leslie Hawthorn, our Community Manager, will return to FISL once again to speak on . She will speak on May 7th and runs from May 7-10th in Porto Alegre.Leslie's talk will be in English but most of the talks on the program are given in BR-PT. Leslie will also be on hand to answer questions you may have about Elasticsearch, Logstash and Kibana. You can visit with Leslie after her talk or in the Elasticsearch booth in the exhibits area.During her visit for FISL 15, Leslie will also speak at the first ever on May 5th.If you are attending FISL 15 or make your home in or near Porto Alegre, please join us for the first on May 8th.Elasticsearch and MIT Sloan Data Analytics HackathonOn May 10th in Cambridge, Masschusetts, US, Elasticsearch will along with the MIT Sloan Data Analytics Club. In addition to the chance to hack on Elasticsearch, network with other cool folks and eat delicious noms, we'll feature something a little different: data science for the non-computer scientist. We know that there are many people who need to make sense of their data, not just those with experience as technologists. If that sounds like you, we'll have from the Elasticsearch engineering team on hand to help you get started using Kibana, the data visualization tool that makes extracting insights from your data simple and beautiful., Elasticsearch core developer, will also be on hand to mentor attendees coming up to speed on Elasticsearch. And to make awesome things. :)The hackathon is open to anyone, not just students. Space is limited, so !But Wait, There's More ... Got Meetups?We've got a number of meetups happening this week, and even more awesome Elasticsearch content on offer from the wider community: Phew. That's one busy week! We'll keep bringing you news of where we'll be each week, so stay tuned to this blog or for the latest news. \n"}<br>{"index": {"_id": 1332}}<br>{"title":"The Elasticsearch Deutschland Experience at NoSQL Matters Cologne","seo_title":"","url":"\/blog\/elasticsearch-deutschland-experience-nosql-matters-cologne","author":{"name":"Livia Froelicher"},"date":"May 05, 2014","category":"News","locales":"","content":" Last week, we attended the 5th edition of the . Hosted at the Mediapark in Cologne, more than 200 attendees were treated to both a great venue and a ton of mind blowing talks about new products, use cases and field reports of day-to-day operation of NoSQL infrastructures.Our own \u2013 Software Developer on the Elasticsearch Marvel team \u2013 gave an in-depth presentation on Elasticsearch: a Deep Dive into Analytics Using Aggregations.The organizers gave out happy and sad faces at the exit to each talk so folks could rate material during each session they attended with a quick +1\/-1.The \u201csmiley likes\" were all over during Boaz's talk. Folks were very keen to know more about our products. Boaz gave several impromptu demos tailored to specific audience after his talk. For those of you who couldn't make it join us for the presentation, you may enjoy Boaz's .Boaz was also selected to deliver at the conference wrap up lightning talks. He gave a short 5 minutes intro to Marvel, complete with another cool demo. If you're interested in learning more, you may want to .A BIG thank you to and the entire NoSQL Matters Cologne team for all their hard work to bring all of us together and to give us the opportunity to learn from each other. It was a pleasure to be part of it and discover a bunch of happy users of Elasticsearch and meet more folks who want to check it out! \n"}<br>{"index": {"_id": 1333}}<br>{"title":"This Week in Elasticsearch - April 30, 2014","seo_title":"","url":"\/blog\/2014-04-30-this-week-in-elasticsearch","author":{"name":"Luca Cavanna"},"date":"April 30, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Slides & Videos \n"}<br>{"index": {"_id": 1334}}<br>{"title":"Aliases for the Win","seo_title":"","url":"\/blog\/aliases-ftw","author":{"name":"Luca Cavanna"},"date":"April 29, 2014","category":"Engineering","locales":"","content":" Index aliases are supported in elasticsearch for some time now. Using aliases you can easily abstract your physical indices away, so that only logical indices are exposed to the users and a lot of interesting things become possible. For instance you can , or even scale out without reindexing your data when your index has reached its full capacity. Aliases can be created, modified and deleted through proper aliases api: elasticsearch makes it even easier to create them though. The idea is that aliases should be used in every situation, right from the beginning of every project, which is why we made it possible to specify them while creating an index, as well as when creating index templates. Aliases upon index creation As of , aliases can be provided as part of the create index api. Here is an example: curl -XPUT localhost:9200\/logs-2014-04-14 -d ' { \"aliases\" : { \"april_2014\" : {}, \"year_2014\" : {} }, \"settings\" : { \"number_of_shards\" : 3, \"number_of_replicas\" : 0 } } ' The above request creates a new index called and associates the aliases and with it. Aliases support in index templates From it is also possible to specify aliases when registering . This comes in very handy especially when dealing with time based data, for instance daily indices. You can just create a couple of index templates as follows: curl -XPUT localhost:9200\/_template\/template_2014 -d ' { \"template\" : \"logs-2014-*\", \"aliases\" : { \"logs-2014\" : {} } } ' curl -XPUT localhost:9200\/_template\/template_2014_04 -d ' { \"template\" : \"logs-2014-04-*\", \"aliases\" : { \"logs-2014-04\" : {} } } ' As a result, whenever you create an index for year 2014, it will get automatically added to the alias. Also, whenever an index for april 2014 is created, it will get added to the existing alias that holds all indices for april 2014. The above examples contain simple aliases but let\u2019s not forget that an alias can hold routing keys and a filter too. Also, because index templates allow you to associate an alias with an index whose name is not known yet, it is possible to use the placeholder as part of the alias name, which will get automatically replaced with the index the template is getting applied to at index creation time. curl -XPUT localhost:9200\/_template\/template_2014 -d ' { \"template\" : \"logs-2014-*\", \"aliases\" : { \"{index}-alias\" : {} } } ' Note that it is only possible to use the whole index name as part of the alias name. Although it would be nice to be able to use a portion of the index name and do much more complex things, we decided to keep it simple for now, but there\u2019s already a to address this. A big thank you to for his contribution on these improvements! We look forward to your feedback on the or ! \n"}<br>{"index": {"_id": 1335}}<br>{"title":"DRY - Keeping Search Requests Short","seo_title":"","url":"\/blog\/dry-keeping-your-queries-short","author":{"name":"Alexander Reelsen"},"date":"April 29, 2014","category":"Engineering","locales":"","content":" With the release of it is now possible to have query and search templates for all your requests. This blog post explains the how and why. Most of us know this principle from programming: Don\u2019t repeat yourself. Make sure, you only write code once and leave out repetitive code that does not change. The same applies for search requests. There should be no need to repeat parts of a query that do not change a lot. However, even for executing a query via HTTP, you are required to repeat a similar JSON data structure over and over again. Template Query The first DRY helper for you is the . This allows you to specify a specific query where one part is the template, which simply is a mustache template, and one part parameters, which are then compiled together, before the query is executed as a normal query. Take a look at this simple example: GET \/_search { \"query\": { \"template\": { \"query\": {\"match_{{template}}\": {}}, \"params\" : { \"template\" : \"all\" } } } } Now this does not save you a lot of code exactly, does it? Very true, let us make this example more usable. First, most queries are not a simple match_all query, but rather a longer query where usually a single search phrase (possibly consisting of several terms) is put into several fields like this: { \"query\": { \"template\": { \"query\": { \"bool\" : { \"must\" : [ { \"match\" : { \"name\": \"{{name}}\" } } ], \"should\" : [ { \"match\" : { \"firstname\": \"{{name}}\" } } ] } }, \"params\" : { \"name\" : \"alexander\" } } } } Again, this query did not become any shorter. So the next step is not to send the query with every request, but maybe have it already stored on the server side. This is exactly one of the features of the query template. You can put the query part into a file in directory, for example , as mustache is used for rendering. Then the query is suddenly short like this: GET \/_search { \"query\": { \"template\": { \"query\": \"my-script\", \"params\" : { \"name\" : \"alexander\" } } } } You can add the script file to elasticsearch while running and it will pick it up automatically without the need for a restart. So, now we are saving some bytes per request. But can we do better? There is still some redundancy above like the part. Also, it would be nice to maybe template the full request, and have script aggregations or highlighting fields for example. Search template GET \/_search\/template { \"template\": { \"query\": { \"term\": { \"{{field}}\" : \"{{value}}\" } }, \"aggs\" : { \"{{field}}\" : { \"terms\" : { \"field\": \"{{field}}\"} } } }, \"params\": { \"field\" : \"name\", \"value\" : \"alexander\" } } As you can see, you can template the whole request. And again you can refer to an already stored script and shorten it dramatically! GET \/_search\/template { \"template\": \"my-request\", \"params\": { \"field\" : \"username\", \"value\" : \"alexander\" } } In addition, you can use more complex features of the of the mustache templating engine, see the . There are several reasons for this feature. Saving some bytes on the wire might be one: only allowing to execute a couple of predefined search operations (like a functionality, or executing A\/B tests by easily specifying different queries, or adding some ACL driven filters to all queries) might be another. This could also become a point of sharing queries between applications, perhaps even written in different languages. Up next\u2026 Storing the script in the directory of elasticsearch still implies you have to copy it manually to each node. Another idea might be to store it in an index or the cluster state. We will work on that as well. Also, feel free to drop us some feedback, if you think mustache is a good fit here or if you think it makes sense to support other template languages. As mustache is a so-called logic less template language, some people might consider it too limited, so we are eager to know about your use-case. In addition, we\u2019re discussing if it is a good idea to allow for a pure parameter driven get request like this without a body: An advantage of this approach might be that it is easy to cache with a proxy, if needed. What do you think? \n"}<br>{"index": {"_id": 1336}}<br>{"title":"Where in the World is Elasticsearch? - April 29, 2014","seo_title":"","url":"\/blog\/world-elasticsearch-2","author":{"name":"Daniel Palay"},"date":"April 29, 2014","category":"","locales":"","content":" In this week's search for Elasticsearchers, we turn our attention to the town of Cologne as our very own and come to town for . There will be plenty of Elasticsearch and Logstash stickers and even a few stuffed ELKs there for you to get your hands on. But fancy schwag aside, if you are in Cologne, you are really going to want to catch Boaz and his talk happening at 13:45 Tuesday. Can't make it to NoSQL Matters? Don't worry, we've got you covered. We recently held a community meet-up at our office in Amsterdam \u2013 where we highlighted the new features in and Boaz (yea, he's a busy speaking and coding machine) demoed our cluster-monitoring product . Enjoy and we'll catch you next time on Where in the World is Elasticsearch \n"}<br>{"index": {"_id": 1337}}<br>{"title":"Resiliency and Elasticsearch","seo_title":"","url":"\/blog\/resiliency-elasticsearch","author":{"name":"Shay Banon"},"date":"April 26, 2014","category":"Engineering","locales":"","content":" This blog post tries to explain our thought processes around how we work in Elasticsearch and Apache Lucene to address resiliency. It ended up being much longer post than I intended, but I hope you will find it well worth the read. The first question is: why would we even care about resiliency in Elasticsearch? Is it not \"just\" a search system, one that simply mirrors a primary \"source of truth\" data source? Surely you can always reindex the data? Well, to a degree, this is a correct. Many systems out there have their \"single source of truth\" outside of Elasticsearch. If your SSoT is another datastore or flat files in S3 or HDFS, you can always reindex the data. But, the fact that you can reindex the data doesn't mean that we are happy with the fact that you *have to do this*. We have users of Elasticsearch storing petabytes of data - reindexing all of that data would take an unacceptably long time! For that reason, we strive to ensure that Elasticsearch doesn\u2019t lose data, ever. A major step towards keeping data safe was the addition of the snapshot\/restore API. While it was possible to do backups in Elasticsearch before, it was fiddly and inefficient. With the incremental backups available in snapshot\/restore, you can now recover your data even when your cluster suffers massive failure, be it hardware or user induced (think DELETE \/*). But restoring data still takes time. We also want to ensure that your live cluster is resilient and never loses data. How do we address the resiliency aspects of Elasticsearch? Our process is quite simple. We work through known issues based on how likely are they to occur, and how broad the scope of applying the fix. If we suspect there is a bug in Apache Lucene, we put all our resources on it to try to find and fix it. Quickly! Lucene is at the core of Elasticsearch. We feel deeply responsible for helping Lucene to move forward (see ), it\u2019s a very high priority for us. Lucene is a widely used library and, outside of the context of Elasticsearch, us helping to fix anything related to resiliency in Lucene means that we have a karma multiplier that goes beyond just Elasticsearch. We do not take this responsibility lightly. A lot also happens somewhat behind the scenes. For example, a few months ago we were getting reports of users losing data in Elasticsearch. Among them was GitHub, one of our customers. We had a few engineers fully dedicated to figuring out why it happened. It took us a few months to nail down the problem. We started by examining each step within Elasticsearch itself \u2013 when shards are allocated, when shards are deleted \u2013 hardening each step to add resiliency. In the end, it turned out to be a bug in Lucene, which could result in a whole index being deleted! We were super excited that we had managed to track down this bug and commit the fix. (). We\u2019re doing the same thing with the upcoming Lucene 4.8 release. So far there have been two bugs in Lucene 4.8 that we have managed to uncover and fix: (wipes index), (zero byte files). That\u2019s not to say that there aren't bugs in Elasticsearch itself. A few months ago, we found that using multiple data paths in Elasticsearch could result in Elasticsearch wrongly reporting a corrupted index. Again, this bug was one that took us quite some time to find, but it was a high priority for us. How do we make sure our system is resilient? There are two aspects to it. First is our test infrastructure. One of the amazing things that happened in Apache Lucene that helped to make it super resilient was the use of randomized testing (see for background). Think of randomized testing as a test infrastructure that is \"predictably irrational.\" Tests usually stagnate towards stability, and randomized testing allows you to make your test infrastructure a living organism that keeps on trying to be, effectively, \"predictably irrational\". Another part of the test infrastructure is what Simon has us all fondly referring to as \u201cevil tests.\u201d These are not Chaos Monkey tests, these are Rabid-Monkey-on-Acid tests! For example, Lucene now has a Directory (effectively a file system) that simulates faulty hardware when doing fsync calls. Anybody who follows Elasticsearch closely has probably noticed how much work Simon and others in our team have done to bring this amazing randomized testing infrastructure to Elasticsearch as well. Today, each test run in Elasticsearch is significantly different (in a good way) from the previous one, exposing our code to a huge range of conditions which us mere humans would not have considered. When a failure appears, we can replicate the exact conditions for that test run in order to find the problem. We have also added the ability to simulate many failure modes within our own system. A good example is the test case in Elasticsearch (another \u201cevil\u201d test). It introduces (predictably) random failures to try to break our system. If Elasticsearch doesn\u2019t cope with the failure, then we harden it. Testing network problems from outside is hard, so we have added the ability to simulate network partitions (or misbehaving nodes), to more easily strengthen our distributed model (more on that later). The second aspect is reviewing how Elasticsearch and Lucene behave today, analyzing the results, and making them more resilient wherever possible. For instance, it always bothered me that checksumming was not an integral aspect of Lucene (it was done on a higher, Elasticsearch, level for recovery purposes) which makes file corruption difficult to detect. Now, with the additional people we have dedicated to Lucene, we have the capacity to address it. (Add that to the more on that later list, too.) So, more concretely, what are our plans to address making Elasticsearch and Lucene more resilient? Here is our top priority list as of today. It tends to change based on feedback from users: (, , ) Today, we can\u2019t easily tell if a Lucene index is corrupted or not. Lucene 4.8 has added checksums to all files, with checksum validation on reads of small files and some large files, with an option for a more expensive merge process that also validates checksums on all files. We need to make sure we have more checksum verification, at the very least during merges on all files. In the same way as checksums are used in Lucene, we can improve how we do checksumming in our transaction log. Today we are too lenient. Snapshot\/Restore is a new feature in Elasticsearch 1.x. During a snapshot operation, we can actually validate the checksum while reading the data from disk, and reject the snapshot (and failover to a replica) if the checksum doesn't match. In the same way as for snapshotting, we can improve shard recovery on replicas by checksumming the Lucene segments as they are copied over from the primary. We plan on assigning a sequence number to operations that occur on primary shards.This is a really interesting feature that will lay the groundwork for many future features in Elasticsearch. The most obvious one is speeding up the replica recovery process when a node is restarted. Currently we have to copy every segment which is different which, over time, means every segment! Sequence numbers will allow us to copy over only the data that has really changed. There is a bug in Elasticsearch that can cause split brain when the cluster is faced with a partial partition, i.e. some nodes can see nodes that other nodes can\u2019t see (). This bug has been open for a while and has received a lot of attention recently. I would like to talk about how we are dealing with this problem in particular. First, network disconnections are actually a relatively rare problem with Elasticsearch deployments. A more common problem is an unresponsive node, due to very heavy load or prolonged garbage collections. A node which becomes unresponsive for a long period can appear to be dead. By improving node stability, we also improve cluster stability. In Elasticsearch, we actively promote the use of dedicated master nodes in critical clusters to make sure that there are 3 nodes whose only role is to be master, a lightweight operational responsibility. By reducing the amount of resource intensive work that these nodes do (no data ingestion or search), we greatly reduce the chance of cluster instability. Even with that, we found that under large clusters (our users keep on pushing us!), or large cluster states (many thousands of indices), those master nodes were still under an unacceptable load. We worked a lot into improving that: improving our shard allocation algorithm to be 100x faster and more lightweight, using our network stack more efficiently when publishing large cluster states, batching frequent updates to mappings in the cluster state, etc. All of this work has been backported all the way back to the latest 0.90.x releases, and recent 1.x releases. This reflects the approach that we take to improving resiliency in Elasticsearch. We focus on the problems that end up causing most of the failures we actually see in the field (and our project is quite popular, with more than 500,000 downloads a month, so we see a lot of those), and address those first. Other improvements such as reduced memory usage with compressed fielddata structures, better cache recycling and reducing garbage collection have all indirectly helped to improve node (and thus cluster) stability. Back to the issue. In order to properly fix it, and potential future issues, we first have to be able to replicate the problem reliably. With our improved testing infrastructure, we now have a \"mock transport\" which allows us to simulate the condition and reproduce the problem. With a lightweight test for the bug now in place, we can start to address it. We have a good idea of what is needed to fix this issue and have created a branch in Elasticsearch to implement and test the solution. Expect it to be pulled into master in the near future. The partial-partition split brain is a real problem that we need to fix. Having said that, in practice it is actually very rare. Personally, with all the deployments that I have assisted with, I have never seen this bug. Users often attribute their problem to this bug, but it almost always turns out to be something else. That\u2019s not to say that this bug is not important. It is. But the frequency with which it manifests, especially with the optimized resource usage of recent Elasticsearch versions and with dedicated master nodes, is very very low. By addressing resource usage first, we have helped many more users than we would have been able to if we had focussed just on the split-brain issue. Last, a frequent question is why don't we use an external system to solve the problem. For example, our discovery module is quite pluggable, why can't we just plug Zookeeper and use it instead of something we build. This, to me, is at the heart of our approach to resiliency. Zookeeper, an excellent product, is a separate external system, with its own communication layer. By having the discovery module in Elasticsearch using its own infrastructure, specifically the communication layer, it means that we can use the \u201cliveness\u201d of the cluster to assess its health. Operations happen on the cluster all the time, reads, writes, cluster state updates. By tying our assessment of health to the same infrastructure, we can actually build a more reliable more responsive system. We are not saying that we won\u2019t have a formal Zookeeper integration for those who already use Zookeeper elsewhere. But this will be next to a hardened, built in, discovery module. Btw, for a live Q&A session that touches on many of those aspects, please watch the Q&A I gave a few months ago at the NYC Elasticearch meetup, starting at minute 55 . If you look at the change log of the last Linux release, or the last Java release, it makes you wonder \u201chow the hell did my app ever work with those bugs?\u201d At the end though, our systems work and work well. Elasticsearch and Lucene are massively popular, and many people use them daily to build amazing products. We continuously invest in fixing ::allthethings::, we hope this blog post gave you some insight into our approach. \n"}<br>{"index": {"_id": 1338}}<br>{"title":"A Gentle Intro to Function Scoring","seo_title":"","url":"\/blog\/found-function-scoring","author":{"name":"Andrew Cholakian"},"date":"April 26, 2014","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. We'll cover the basics of scoring using functions while taking a look at some use cases where functional scoring techniques are highly useful and effective. \n"}<br>{"index": {"_id": 1339}}<br>{"title":"Enriching Your Searches With Open Geo Data","seo_title":"","url":"\/blog\/enriching-searches-open-geo-data","author":{"name":"Alexander Reelsen"},"date":"April 24, 2014","category":"Engineering","locales":"","content":" Have you ever found some neat public datasets where you thought it might make sense to include it in your application to optimize a specific feature, even a minor feature? Sure you have! This blog post shows you how to use Logstash to get an external dataset in the desired format, using Kibana to check if it is applicable, and then making sure the data gets indexed correctly into Elasticsearch so it can do the heavy lifting in production. Getting the data I will assume from now on that you have a current Elasticsearch and Logstash installation available. I will use and in these examples. is a German website, which includes German geo information in SQL and CSV formats. As we want to store data in Elasticsearch, SQL is not an option, neither is CSV out of the box, however we can use Logstash to preprocess and index data in Elasticsearch. The file we are going to parse is a list of German cities, including all of their zip codes. The dataset is available and these files are licensed as . Data format Taking a look at the data reveals it consists of a number of columns: Interesting fields to play around with might be , , , , and . More about that soon\u2026 Indexing the data into Elasticsearch Using the Logstash CSV filter The next step is to get the data into Elasticsearch. The first step is to create a Logstash configuration, so I\u2019ll copy this configuration into a file named . Note that we are using a filter called \u201ccsv\u201d, even though the field separator is a tab, and not a comma. input { stdin {} } filter { # Step 1, possible dropping if [message] =~ \/^#\/ { drop {} } # Step 2, splitting csv { # careful... there is a \"tab\" embedded in the next line: # if you cannot copy paste it, press ctrl+V and then the tab key to create the control sequence # or maybe just tab, depending on your editor separator => ' ' quote_char => '|' # arbitrary, default one is included in the data and does not work columns => [ 'id', 'ags', 'name_uc', 'name', 'lat', 'lon', 'official_description', 'zip', 'phone_area_code', 'population', 'area', 'plate', 'type', 'level', 'of', 'invalid' ] } # Step 3, possible dropping if [level] != '6' { drop {} } # Step 4, zip code splitting if [zip] =~ \/,\/ { mutate { split => [ \"zip\", \",\" ] } } # Step 5, lat\/lon love if [lat] and [lon] { # move into own location object for additional geo_point type in ES # copy field, then merge to create array for bettermap mutate { rename => [ \"lat\", \"[location][lat]\", \"lon\", \"[location][lon]\" ] add_field => { \"lonlat\" => [ \"%{[location][lon]}\", \"%{[location][lat]}\" ] } } } # Step 6, explicit conversion mutate { convert => [ \"population\", \"integer\" ] convert => [ \"area\", \"integer\" ] convert => [ \"[location][lat]\", \"float\" ] convert => [ \"[location][lon]\", \"float\" ] convert => [ \"[lonlat]\", \"float\" ] } } output { elasticsearch { host => 'localhost' index => 'opengeodb' index_type => \"locality\" flush_size => 1000 protocol => 'http' } } Before going on, this is how you would call Logstash in order to index the data. You should fire up Elasticsearch first. cat DE.tab | logstash-1.4.0\/bin\/logstash -f opengeodb.conf So, quite a lot of stuff going on here (might take a minute, depending highly on your hardware). The first thing you might notice: the Logstash configuration does not ingest events using a input. The reason for this is, that the file input behaves like a under UNIX systems and waits for new data to be appended to the file. The data file we have however has a defined end, so it is more appropriate to read of all its data using the input. The section consists of five steps. So, lets go through each and every step and explain what it does Step 1 \u2013 Exclude comments The first step drops comments, which are defined as lines starting with a hash. This is needed because the supplied tab-separated file\u2019s first line is such a comment, which contains the names of the columns, and there is no need to index that. Step 2 \u2013 CSV extraction The second step is doing all the hard CSV work. You have to define the as a tab, the is by default a single , which is used in our data and thus has to be changed to something else. The setting defines the names of the columns, which are used as field names from then on. : When you copy and paste the configuration file from above, the character might need to replaced, as it is copied and represented as a couple of spaces instead of tab. Please check that, in case it is not working as expected. Step 3 \u2013 Removing certain entries We only need the entries from the CSV file which represent a city (those have the set to ). We simply remove the rest by dropping all other events. Step 4 \u2013 Zip code handling The fourth step is for better zip code handling. If an entry has more than one zip code (like bigger cities), all the zip codes are contained in the field, but separated by commas. In order to store those as an array and not one big string, you can use the filter to split that field. Storing this data in an array (as number) would allow you do to numeric range queries for example. Step 5 \u2013 Geo data structures The fifth step is to cater a little bit better for geo data. When reading from the input file, and fields are created. However those fields only have a meaning when they are stored together. This logic stores both fields in two data structures. One looks like an Elasticsearch and results in a structure. The other is a simple array and contains the longitude and latitude (in that order!), so we can use a Kibana bettermap to draw it. Step 6 \u2013 Explicit field conversion The last filter step is to explicitly set the data types of some fields, allowing numeric operations on those in Elasticsearch later. The section uses features available only in the Logstash 1.4 release and later, so make sure you use at least that version. In the former version you had to specify the output explicitly. Going forward, there will only be one output, and you can specify to use HTTP over port 9200 to communicate with Elasticsearch. Using kibana & elasticsearch to gather insights After having indexed some data, we could use kibana to get some further insights. Using a bettermap widget and some small search queries like we could show every bigger city in Germany. You can use this for a couple of things: Even though this is nice, it does not help to improve existing applications. We need to go deeper. Adding suggestions So, lets step back for a moment and check what useful things one could possibly do with this data. We\u2019ve got cities, postal codes\u2026 and there are plenty of occasions in web applications, where one has to enter exactly these data points. A good example is during the checkout process of a purchase, as not every system has all their customer\u2019s data saved already: you may be the kind of shop that frequently processes one-time orders or simply allows to orders without user registration. In this case, it might make sense to help the customer to speed up the order process, with the bonus of preventing order loss or cancellation due to a difficult purchase flow. Elasticsearch has a very fast prefix suggester called the . This suggester has the disadvantage that you need to enrich the results a bit before indexing your data, but this is exactly what Logstash is for. In order to best understand this example, you may want to take a look at . The completion suggester So, let\u2019s decide that we want to help the user typing in the city he\/she lives in. And we also want to provide a list of zip codes, so it is easier to find the right one once the correct city has been selected. You could also do this vice versa and let the user type the zip code and then help by autofilling the city information. Time to add a couple of things to the Logstash configuration to make this work. Lets start with the easy part, the configuration inside of the filter. Add this snippet of configuration to your , right after step 5 and before step 6: # Step 5 and a half # create a prefix completion field data structure # input can be any of the zips or the name field # weight is the population, so big cities are preferred when the city name is entered mutate { add_field => [ \"[suggest][input]\", \"%{name}\" ] add_field => [ \"[suggest][output]\", \"%{name}\" ] add_field => [ \"[suggest][payload][name]\", \"%{name}\" ] add_field => [ \"[suggest][weight]\", \"%{population}\" ] } # add all the zips to the input as well mutate { merge => [ \"[suggest][input]\", zip ] convert => [ \"[suggest][weight]\", \"integer\" ] } # ruby filter to put an array into the event ruby { code => 'event[\"[suggest][payload][data]\"] = event[\"zip\"]' } Logstash will now write a suggest compatible data structure when indexing certain datasets. However we need to configure a template for the mapping to have the suggest feature configured in Elasticsearch as well. Therefore you also need to change the default template for Logstash in the output. # change the output to this in order to include an index template output { elasticsearch { host => 'localhost' index => 'opengeodb' index_type => \"locality\" flush_size => 1000 protocol => 'http' template_name => 'opengeodb' template => '\/path\/to\/opengeodb-template.json' } } The template is very similar to the default Logstash template, but adds the and the fields. { \"template\" : \"opengeodb\", \"settings\" : { \"index.refresh_interval\" : \"5s\" }, \"mappings\" : { \"_default_\" : { \"_all\" : {\"enabled\" : true}, \"dynamic_templates\" : [ { \"string_fields\" : { \"match\" : \"*\", \"match_mapping_type\" : \"string\", \"mapping\" : { \"type\" : \"string\", \"index\" : \"analyzed\", \"omit_norms\" : true, \"fields\" : { \"raw\" : {\"type\": \"string\", \"index\" : \"not_analyzed\", \"ignore_above\" : 256} } } } } ], \"properties\" : { \"@version\": { \"type\": \"string\", \"index\": \"not_analyzed\" }, \"location\" : { \"type\" : \"geo_point\" }, \"suggest\" : { \"type\": \"completion\", \"payloads\" : true, \"analyzer\" : \"whitespace\" } } } } } Now it is time to delete your old data (including the index) and reindex curl -X DELETE localhost:9200\/opengeodb cat DE.tab | logstash-1.4.0\/bin\/logstash -f opengeodb.conf Next step is to actually execute a suggestion curl -X GET 'localhost:9200\/opengeodb\/_suggest?pretty' -d '{ \"places\" : { \"text\" : \"B\", \"completion\" : { \"field\" : \"suggest\" } } }' And this is the result { \"_shards\" : { \"total\" : 5, \"successful\" : 5, \"failed\" : 0 }, \"places\" : [ { \"text\" : \"B\", \"offset\" : 0, \"length\" : 1, \"options\" : [ { \"text\" : \"Berlin\", \"score\" : 3431675.0, \"payload\" : {\"data\":[\"Berlin\",\"10115\",\"10117\",\"10119\",\"10178\",\"10179\",\"10243\",\"10245\",\"10247\",\"10249\",\"10315\",\"10317\",\"10318\",\"10319\",\"10365\",\"10367\",\"10369\",\"10405\",\"10407\",\"10409\",\"10435\",\"10437\",\"10439\",\"10551\",\"10553\",\"10555\",\"10557\",\"10559\",\"10585\",\"10587\",\"10589\",\"10623\",\"10625\",\"10627\",\"10629\",\"10707\",\"10709\",\"10711\",\"10713\",\"10715\",\"10717\",\"10719\",\"10777\",\"10779\",\"10781\",\"10783\",\"10785\",\"10787\",\"10789\",\"10823\",\"10825\",\"10827\",\"10829\",\"10961\",\"10963\",\"10965\",\"10967\",\"10969\",\"10997\",\"10999\",\"12043\",\"12045\",\"12047\",\"12049\",\"12051\",\"12053\",\"12055\",\"12057\",\"12059\",\"12099\",\"12101\",\"12103\",\"12105\",\"12107\",\"12109\",\"12157\",\"12159\",\"12161\",\"12163\",\"12165\",\"12167\",\"12169\",\"12203\",\"12205\",\"12207\",\"12209\",\"12247\",\"12249\",\"12277\",\"12279\",\"12305\",\"12307\",\"12309\",\"12347\",\"12349\",\"12351\",\"12353\",\"12355\",\"12357\",\"12359\",\"12435\",\"12437\",\"12439\",\"12459\",\"12487\",\"12489\",\"12524\",\"12526\",\"12527\",\"12529\",\"12555\",\"12557\",\"12559\",\"12587\",\"12589\",\"12619\",\"12621\",\"12623\",\"12627\",\"12629\",\"12679\",\"12681\",\"12683\",\"12685\",\"12687\",\"12689\",\"13051\",\"13053\",\"13055\",\"13057\",\"13059\",\"13086\",\"13088\",\"13089\",\"13125\",\"13127\",\"13129\",\"13156\",\"13158\",\"13159\",\"13187\",\"13189\",\"13347\",\"13349\",\"13351\",\"13353\",\"13355\",\"13357\",\"13359\",\"13403\",\"13405\",\"13407\",\"13409\",\"13435\",\"13437\",\"13439\",\"13442\",\"13465\",\"13467\",\"13469\",\"13503\",\"13505\",\"13507\",\"13509\",\"13581\",\"13583\",\"13585\",\"13587\",\"13589\",\"13591\",\"13593\",\"13595\",\"13597\",\"13599\",\"13627\",\"13629\",\"14050\",\"14052\",\"14053\",\"14055\",\"14057\",\"14059\",\"14089\",\"14109\",\"14129\",\"14163\",\"14165\",\"14167\",\"14169\",\"14193\",\"14195\",\"14197\",\"14199\"]} }, { \"text\" : \"Bremen\", \"score\" : 545932.0, \"payload\" : {\"data\":[\"Bremen\",\"28195\",\"28203\",\"28205\",\"28207\",\"28209\",\"28211\",\"28213\",\"28215\",\"28217\",\"28219\",\"28237\",\"28239\",\"28307\",\"28309\",\"28325\",\"28327\",\"28329\",\"28355\",\"28357\",\"28359\",\"28717\",\"28719\",\"28755\",\"28757\",\"28759\",\"28777\",\"28779\",\"28197\",\"28199\",\"28201\",\"28259\",\"28277\",\"28279\"]} }, { \"text\" : \"Bochum\", \"score\" : 388179.0, \"payload\" : {\"data\":[\"Bochum\",\"44787\",\"44789\",\"44791\",\"44793\",\"44795\",\"44797\",\"44799\",\"44801\",\"44803\",\"44805\",\"44807\",\"44809\",\"44866\",\"44867\",\"44869\",\"44879\",\"44892\",\"44894\"]} }, { \"text\" : \"Bielefeld\", \"score\" : 328012.0, \"payload\" : {\"data\":[\"Bielefeld\",\"33602\",\"33604\",\"33605\",\"33607\",\"33609\",\"33611\",\"33613\",\"33615\",\"33617\",\"33619\",\"33647\",\"33649\",\"33659\",\"33689\",\"33699\",\"33719\",\"33729\",\"33739\"]} }, { \"text\" : \"Bonn\", \"score\" : 311938.0, \"payload\" : {\"data\":[\"Bonn\",\"53111\",\"53113\",\"53115\",\"53117\",\"53119\",\"53121\",\"53123\",\"53125\",\"53127\",\"53129\",\"53173\",\"53175\",\"53177\",\"53179\",\"53225\",\"53227\",\"53229\"]} } ] } ] } As you can see now, it makes a lot of sense to use the population of a city as . Using this, the bigger cities are suggested before smaller ones. The returned payload contains the name of the city and all the different zip codes, which could be used to automatically fill a form (especially if it is only one zip code is returned). And that\u2019s it for today! However, keep in mind that this is not about public datasets. I am pretty sure that somewhere, deeply buried inside your company, someone has gathered some insightful data which only waits to get enriched and used to improve your applications. Ask your colleagues \u2013 you will find these kinds of data sets in every company! Also, if you find an interesting public (or internal datasets that you can talk about) let us know how you\u2019re using it with Elasticsearch. We are always interested how you\u2019re improved your applications with (open) data and would love to ! \n"}<br>{"index": {"_id": 1340}}<br>{"title":"This Week in Elasticsearch - April 23, 2014","seo_title":"","url":"\/blog\/2014-04-23-this-week-in-elasticsearch","author":{"name":"Luca Cavanna"},"date":"April 23, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Photo courtesy of Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Photo courtesy of Slides & Videos You may also be interested in our about all the talks and other awesome from Elasticsearch folks last week at DevNation, co-located with Red Hat Summit. Where to find Us We'd love to feature all the great Elasticsearch, Logstash and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Community Manager, , know! Austria The just formed! Join the group now to get updates on their first meeting. Brasil Elasticsearch is very excited to send our first speaker from the company to Brasil! Leslie Hawthorn, our Community Manager, will be returning to FISL once again to speak on . Leslie will speak on May 7th and runs from May 7-10th in Porto Alegre. Her talk will be in English but most of the talks on the program are given in BR-PT. Leslie will also be on hand to answer questions you may have about Elasticsearch, Logstash and Kibana. Bulgaria will discuss how to Explore Your Data using Elasticsearch at the . The conference takes place on May 31st in Sofia. France Germany Spain has been invited to speak at the Barcelona on Rails Meetup on May 15th. Join him for a presentation on Doors open at 7 PM, and thanks to the fine folks at XING for hosting us! Tunisia will speak at the Esprit JUG Days in Ariana. Further details of the conference schedule are forthcoming, but mark your calendar for May 7th and 8th. In the meantime, you may want to visit the . United Kingdom United States Where to Find You Our Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1341}}<br>{"title":"Multi-Field Search Just Got Better","seo_title":"","url":"\/blog\/multi-field-search-just-got-better","author":{"name":"Clinton Gormley"},"date":"April 23, 2014","category":"Engineering","locales":"","content":" The is the go-to query for matching on a single field. It understands the field mapping and uses the appropriate analyzer for the field, it can match any word or require all words (with set to or ), or it can match a minimum number or percentage of words with . It can do fuzzy matching and phrase or proximity matching. In short, it is very flexible and very powerful. Multi-field search, on the other hand, is hard. Elasticsearch provides the , which makes multi-field search look simple: But in reality, it is not as simple as it looks. Unless you understand how the query works, you will often use it incorrectly and get suboptimal results. Elasticsearch v1.1.0 added some new features to the query which make multi-field search much more powerful and easier to use. Types of multi-field search How you search across multiple fields depends on how your data is indexed and the type of search that you need. There are three main scenarios: Best matching field When searching across multiple fields for a single \u201cconcept\u201d, you want to look for as many words as possible within the same field. For instance, \u201cbrown fox\u201d in a single field is more meaningful than \u201cbrown\u201d in one field and \u201cfox\u201d in the other. In other words, you\u2019re looking for the single field. This type of query can be executed by running a query against each field, and choosing the relevance from the best matching field, using the : The query accepts a parameter which tells it how to execute the query. The default type is , which results in exactly the same query as we have above: This query, as written above, will choose the best matching field, but will ignore other lesser matches. We can still take these secondary matches into account by specifying the parameter: The above query will still use the from the best matching field, but will also add in the from any other matching fields, multiplied by . Most matching fields Often we index the same text with several different analyzers, perhaps as stemmed and unstemmed, with synonyms, with shingles for proximity matching, with edge-ngrams for autocomplete etc. In this case, we want to query all of the fields and add up the from each match to find the documents with the . We could write such a query by wrapping individual clauses with a : This is the same query that would be executed by the query when the parameter is set to : You can give extra \u201cweight\u201d to one or more fields by specifying a on that field, using the caret () syntax: In the above query, the field is twice as important as the other fields. Cross field matching Finally, we often need to search for entities whose data is spread across multiple fields, such as when we search for \"John Smith\" in the and fields of a object. In this case, we want to find as many individual words as possible in . The approach may appear to be the answer here, but there are several reasons why it will not give good results. Both and are queries\u2009\u2014\u2009they match each field separately. This means that: One solution to this problem is just to index the data from and into the single field , which we can do automatically with this mapping: Then we can just query the field with a simple query. That said, it is often useful to be able to achieve the same thing across multiple fields. Elasticsearch v1.1.0 added the new execution type which allows you to do just that: The approach first analyzes the query string into individual terms, then it looks for each term in any field, much like this: The and parameters would work as you expect, as each word is queried (and so can be counted) separately. But this still leaves the problem of term frequencies. In the above query, would still score higher than . In fact, the approach doesn\u2019t use queries. Instead it uses a special query which combines the term frequency of with the term frequency of and uses that value for both fields. In other words, it treats and as if they were . It has certain advantages over the approach: Note about analysis All fields used in a query should use the same so that they all produce the same list of query terms. If fields with different analyzers are queried, then they will be grouped together by analyzer. Each group will be queried with the approach, then the scores from all groups will be combined with a query. Alternatively, you can force the same analyzer across all fields by specifying an in the query: Conclusion The feature is a really important addition to Elasticsearch. It adds functionality that it was impossible to replicate client side. You can read more about this topic in the chapter in our upcoming book: . \n"}<br>{"index": {"_id": 1342}}<br>{"title":"Averages Can Be Misleading: Try a Percentile","seo_title":"","url":"\/blog\/averages-can-dangerous-use-percentile","author":{"name":"Zachary Tong"},"date":"April 22, 2014","category":"Engineering","locales":"","content":" With the release of Elasticsearch 1.1.0, there is a new metric aggregation available to users: the . Percentiles tell you the value at which a certain percentage of your data is included. So a 95th percentile tells you the value which is greater than or equal to 95% of your data. Ok\u2026but why is that useful? Imagine you are the administrator for a large website. One of your goals is to guarantee fast response times to all website visitors, no matter where in the world they live. How do you analyze your data to guarantee that the latency is small? Most people reach for basic statistics like mean, median or max. Each have their place, but for populations of data they often hide the truth. Mean and median tend to hide outliers, since the majority of your data is \u201cnormal\u201d. In contrast, the max is a hypercondriac and easily distorted by a single outlier. Let\u2019s look at a graph. If you rely on simple metrics like mean or median, you might see a graph that looks like this: That doesn\u2019t look so bad, does it? Average and median response time is around 50ms, and creeps up to 100ms for a little while. A different truth is apparent when you include the 99th percentile: Wow! That certainly doesn\u2019t look good at all! At 9:30am, the mean is telling you . In contrast, the 99th percentile says , which is a very different picture. One percent of all your customers are experiencing 800+ ms latencies, which could be very bad for business. Using the percentile The new percentile metric works just like the simpler stats metrics like and . It is a metric that can be applied to any aggregation bucket. The percentile metric will then calculate a set of percentiles based on the documents that fall within the bucket. Let\u2019s look at a simple example: curl -XGET localhost:9200\/website\/logs\/_search -d ' { \"aggs\" : { \"load_time_outlier\" : { \"percentiles\" : { \"field\" : \"load_time\" } } } }' By default, the metric will calculate a set of default percentiles () and return you the value for each one: { ... \"aggregations\": { \"load_time_outlier\": { \"1.0\": 15, \"5.0\": 20, \"25.0\": 33, \"50.0\": 38, \"75.0\": 45, \"95.0\": 60, \"99.0\": 867 } } } Often, only the extreme percentiles are important to you, such as the 95th and 99.9th percentile. In this case, you can specify just the percentile you are interested in: curl -XGET localhost:9200\/website\/logs\/_search -d ' { \"aggs\" : { \"load_time_outlier\" : { \"percentiles\" : { \"field\" : \"load_time\" , \"percents\" : [ 95, 99.9 ] } } } }' Being a metric, we can nest it inside of buckets to get more sophisticated analysis. Going back to our original goal \u2014 detecting high latency based on geographical location \u2014 we can build an aggregation that buckets users by their country and then computes a percentile on curl -XGET localhost:9200\/website\/logs\/_search -d ' { \"aggs\" : { \"countries\" : { \"terms\" : { \"field\" : \"country_code\" }, \"aggs\" : { \"load_time_outlier\" : { \"percentiles\" : { \"field\" : \"load_time\" , \"percents\" : [ 95 ] } } } } } }' And now we can see that Antarctica has a particularly slow 95th percentile (for some strange reason): { ... \"aggregations\": { \"country\" : { \"buckets\": [ { \"key\" : \"AY\", \"doc_count\" : 20391, \"load_time_outlier\": { \"95.0\": 1205 } }, ... percentiles are (usually) approximate All good things come at a price, and with percentiles it usually boils down to approximations. Fundamentally, percentiles are very expensive to calculate. If you want to calculate the 95th percentile, you need to sort all your values from least to greatest, then find the value at This works fine for small data that fits in memory, but simply fails when you have terrabytes of data spread over a cluster of servers (which is common for Elasticsearch users). The exact method just won't work for Elasticsearch. Instead, we use an algorithm called (). Without getting bogged down in technical details, it is sufficient to make the following claims about T-Digest: The following chart shows the relative error on a uniform distribution depending on the number of collected values and the requested percentile: The absolute error of a percentile is the actual value minus the approximate value. It is often useful to express that as a relative percentage rather than in absolute difference. In the chart, we can see that at 1000 values, the 50th percentile is 0.26% off the true 50th percentile. In absolute terms, if the true 50th was , T-Digest might have told us . Practically speaking, the error is often negligible, especially when you are looking at the more extreme percentiles The chart also shows how precision is as you add more data. The reason why error diminishes for large number of values is that the law of large numbers makes the distribution of values more and more uniform and the t-digest tree can do a better job at summarizing it. It would not be the case on more skewed distributions. The memory-vs-accuracy tradeoff is configurable via a parameter, which you can . Conclusion Now armed with some basic knowledge about percentiles, hopefully you are beginning to see applications all over your data. These approximate algorithms are exciting new territory for Elasticsearch. We look forward to your feedback on the or ! \n"}<br>{"index": {"_id": 1343}}<br>{"title":"The Week that Was at Red Hat Summit & DevNation","seo_title":"","url":"\/blog\/week-red-hat","author":{"name":"Daniel Palay"},"date":"April 19, 2014","category":"News","locales":"","content":" For those of you who couldn\u2019t join us in San Francisco this week, we had quite the busy week. \u2013 creator of Logstash \u2013 was part of a star-studded in San Francisco this past Tuesday night. Jordan \u2013 pictured left (via ) was joined by \u2013 author of , \u2013 Developer and Platform Evangelist for Red Hat Enterprise Linux, and \u2013 Principal Open Shift Architect at Red Hat. The quartet led a vibrant discussion on the best practices for system and application monitoring. Our own was on hand for the BoF and captured the essence of the discussion. \u2013 \"Everyone seems to have all these tools. That they hate.\" Problem is not fully solved. \u2014 Leslie Hawthorn (@lhawthorn) Jordan also joined the Elasticsearch team at our Red Hat Summit booth. Partnering up with fellow Logstash engineer , Jordan led 3 standing room only demos on the ELK Stack. If you couldn\u2019t make any of Jordan & Kurt\u2019s demos this week or just wanted more information, take a moment to watch this video from our recent and listen to how Bloomberg is utilizing the entire stack. \u00a0 As you can see by the pictures from the and the Bloomberg video, simple and beautiful data visualization is a key part of the ELK Stack. The creator of the K part of ELK \u2013 \u2013 just . If you have a few minutes this weekend and simple and beautiful data visualizations interest you, we recommend taking a moment to watch it. \n"}<br>{"index": {"_id": 1344}}<br>{"title":"Java 1.7u55 is Safe for Use With Elasticsearch","seo_title":"","url":"\/blog\/java-1-7u55-safe-use-elasticsearch-lucene","author":{"name":"Michael McCandless"},"date":"April 18, 2014","category":"Engineering","locales":"","content":" This post was co-authored with .Apache Lucene's \u00a0are so stressful that they also happily serve as\u00a0strong test cases for the JVM itself.Over time, Lucene's tests, running many times per day on multiple\u00a0Jenkins installations with random JVM options, different operating\u00a0systems and garbage collectors, have uncovered a number of exciting JVM\u00a0bugs. There's\u00a0a\u00a0.For example, the very first Java 1.7 release had a , which was fixed with the first update (1.7.0u1). Fortunately, Oracle's QA team has been working more closely with Lucene developers since then, helping to iterate on new issues, notifying us on new early-access Java releases, etc.One recent bug, ,\u00a0would cause SEGV or, worse, silent corruption in the index term vectors. Because of this bug, we've had to recommend Lucene users stick with Java 1.7u25, now almost a year old.At Oracle, Vladimir Kozlov has worked very hard and , as of . It's so hard to imagine how he could track down this bug, when debugging tricky Lucene test failures is hard enough, so we asked him how does that, and he explained that he steps through megabytes of assembly instructions, correlates them back to the particular Java sources, thinks about which parts of the Hotspot compiler may have resulted in each part of the assembly. \u00a0This all sounds exceptionally challenging, and we are happy Vladimir is able to do it so well!Finally, that fix has now been back-ported to Java's 1.7.x branch, and released as of . The Lucene developers have upgraded Lucene's continuous Jenkins builds to 1.7u55 and no tests are failing, so we are comfortable and can now recommend that 1.7u55 is safe for Elasticsearch and all other Lucene based applications. \n"}<br>{"index": {"_id": 1345}}<br>{"title":"Investing in Apache Lucene","seo_title":"","url":"\/blog\/investing-apache-lucene","author":{"name":"Shay Banon"},"date":"April 17, 2014","category":"","locales":"","content":" As you know, Apache Lucene is at the heart of Elasticsearch, and when we formed the company around Elasticsearch, we made a commitment to make sure we drive Apache Lucene forward. With , , , and , we already have a very strong group of Lucene committers that help to harden Lucene and keep adding enhancements to it. Other Elasticsearch employees invest a lot of time in Lucene as well, for example, with spending a considerable amount of time in Lucene a few months ago. In keeping with our commitments to improving core Lucene, I am happy to announce that and have joined Elasticsearch. We hope you already notice the extra work that has gone into improving Apache Lucene in the past few weeks since they joined us. It is humbling to have such a wonderful group of Apache Lucene committers at Elasticsearch, and to have the opportunity to help innovation in the Lucene world happen at an even faster pace. Welcome, Mike and Robert! \n"}<br>{"index": {"_id": 1346}}<br>{"title":"This Week in Elasticsearch - April 17, 2014","seo_title":"","url":"\/blog\/2014-04-17-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"April 17, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Slides & Videos Where to find Us We'd love to feature all the great Elasticsearch, Logstash and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Community Manager,, know! Austria The just formed! Join the group now to get updates on their first meeting. Brasil Elasticsearch is very excited to send our first speaker from the company to Brasil! Leslie Hawthorn, our Community Manager, will be returning to FISL once again to speak on . Leslie will speak on May 7th and runs from May 7-10th in Porto Alegre. Her talk will be in English but most of the talks on the program are given in BR-PT. Leslie will also be on hand to answer questions you may have about Elasticsearch, Logstash and Kibana. Canada will be attending and the accompanying Django sprints. Make sure to stop by and hear more from him during his poster session . France Germany Japan The has been scheduled by Jun Ohtani. Please plan to join the meeting at 7 PM on April 21st. Spain has been invited to speak at the Barcelona on Rails Meetup on May 15th. Join him for a presentation on Doors open at 7 PM, and thanks to the fine folks at XING for hosting us! Tunisia will speak at the Esprit JUG Days in Ariana. Further details of the conference schedule are forthcoming, but mark your calendar for May 7th and 8th. In the meantime, you may want to visit the . United Kingdom United States Where to Find You Our Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1347}}<br>{"title":"Why I joined elasticsearch - April 16, 2014","seo_title":"","url":"\/blog\/joined-elasticsearch","author":{"name":"Gaurav Gupta"},"date":"April 16, 2014","category":"","locales":"","content":" Hello Elasticsearchers! I\u2019m Gaurav Gupta, and I recently joined Elasticsearch as VP of Product Management. A little bit about me and why I\u2019m so excited to be part of the team! My love for all things data and search started in the late 90\u2019s when I first tried out Google. For the first time, the data on the web truly became useful to me. When I joined Splunk in 2008, I found a kind of corollary to Google. Splunk leveraged search, but explored an entirely different type of data. Machine data was a kind of metadata of the world \u2013 the logs, metrics and spew that come out of servers, applications, network devices, and sensors that run our world. It was possibly thousands of times larger than the entirety of human-generated data (the stuff that Google mostly searched) and its growth seemed limitless. In the world of Big Data, \u201chuman\u201d and \u201cmachine\u201d generated data have largely remained distinct in terms of both tools and technical approaches. Elasticsearch brings these two together for the first time. Its engine can tackle both document search and machine data analytics with an elegant simplicity and speed. The sheer number of use cases is a product guy\u2019s dream (or nightmare, depending on how you see it!) The Elasticsearch community really \u201cgets\u201d it. Hop onto twitter, read the blog posts, hang out in the IRC channel, or better yet talk to some customers of Elasticsearch. People LOVE our products, and they\u2019re excited to contribute back to make it even better. I can\u2019t wait to be a part of it. Elasticsearch is building one of the few truly geographically distributed startups I know of. As a result, we are able to hire the best and brightest technical and business minds regardless of where they live. I live in San Francisco, but I regularly communicate with people living in Amsterdam, Germany, the UK, and all over the US. We all get together 1-2x a year and with modern technology coupled with the right culture, it works. My recent experiences with other open source \u201cBig Data\u201d infrastructure companies (ie Hadoop, NoSQL etc) left me puzzled. Getting those solutions up and running, let alone getting something useful, took days and often weeks. Elasticsearch and the ELK stack is a dream in comparison. Beyond the surface, lies great power. Everything is designed with flexibility in mind: clean APIs, JSON everywhere, and a product built with scalability and reliability as a first class citizen. It can just as easily live on-premise as it can in the cloud. And being open source means that we are by nature open and transparent, quality conscious, and focused on serving our community. I look forward to meeting many of you! Feel free to reach out anytime via email at gaurav.gupta (at) elasticsearch.com or on twitter at . \n"}<br>{"index": {"_id": 1348}}<br>{"title":"Elasticsearch 1.1.1 and 1.0.3 Released","seo_title":"","url":"\/blog\/elasticsearch-1-1-1-1-0-3-released","author":{"name":"Clinton Gormley"},"date":"April 16, 2014","category":"Engineering","locales":"","content":" Today we are happy to announce the release of , based on Lucene 4.7.2 and , based on Lucene 4.6.1. You can download them and read the full changes list here: Both of these releases contain important bug fixes, but we recommend upgrading to version 1.1.1 unless you have a particular reason for staying with the 1.0 branch. \n"}<br>{"index": {"_id": 1349}}<br>{"title":"Significant Terms Aggregation","seo_title":"","url":"\/blog\/significant-terms-aggregation","author":{"name":"Mark Harwood"},"date":"April 15, 2014","category":"Engineering","locales":"","content":" Strap on your goggles... In the movie , the alien has a sophisticated thermal imaging system that allows him to single out his human prey by observing the heat differences between their bodies and the environment in which they are hiding. The new behaves like the Predator's vision, identifying interesting things that stand out from the background (not by observing heat differentials but by observing term frequency differentials). Terms of interest in a result set stand out clearly like the heat signal of a monosyllabic Austrian bodybuilder sweating behind a fern. Revealing the uncommonly common The trick behind the significant terms aggregation is in spotting terms that are significantly more common in a result set than they are in the general background of data from which they are drawn. These are what you might call uncommonly common terms and examples of the real insights these can give include: In the following sections we present worked examples of just some of the useful applications of this new feature: Use case: Geographic anomalies This XKCD cartoon neatly summarises the issue with the typical forms of mapping analysis: The significant terms aggregation can help overcome this problem. Let's first take all of the UK crime data for last year and break the reports down into geographic areas using the and with a simple like this: curl -XGET \"http:\/\/localhost:9200\/ukcrimes\/_search\" -d' { \"query\": { \"aggregations\" : { \"map\" : { \"geohash_grid\" : { \"field\":\"location\", \"precision\":5, }, \"aggregations\":{ \"most_popular_crime_type\":{\"terms\":{ \"field\" : \"crime_type\", \"size\" : 1}} } } } }' We end up with an XKCD-style map effectively showing us a population distribution and the less-than useful insight that anti-social behaviour is the most popular crime type : However, if we use the aggregation we can get a more interesting insight into the data and reveal the unusual occurrences of crime in each location: curl -XGET \"http:\/\/localhost:9200\/ukcrimes\/_search\" -d' { \"query\": { \"aggregations\" : { \"map\" : { \"geohash_grid\" : { \"field\":\"location\", \"precision\":5, }, \"aggregations\":{ \"weirdCrimes\":{\"significant_terms\":{\"field\" : \"crime_type\", \"size\":1}} } } } }' If we show only the top scoring areas, we move away from focusing purely on the most populated areas and the most common crime and begin to find the anomalies in our data: Here, we see a relatively remote area with a disproportionately large number of Possession of Weapon crimes. If we zoom in, we can see from the sky why this is the case - this is the location of Stansted airport where passengers are routinely searched as they transit through the airport. Other spots around the country have their own curiosities - the fields where drug-related crimes peak as part of annual music festivals, the year-round bicycle thefts from university towns like Cambridge, and the prisons where it would seem a crime conducted against a fellow criminal is not really a crime so is registered with the type Other. Use case: Root cause analysis The maintains a database of car fault reports and, like many systems for fault reports, there is a product ID and a free-text description with each report. Using the aggregation you can identify the common reasons for product failures by examining the free-text descriptions of each product. Example querycurl -XGET \"http:\/\/localhost:9200\/nhtsa\/_search\" -d' { \"aggregations\" : { \"car_model\":{ \"terms\":{\"field\" : \"car_model\", \"size\" : 20}, \"aggregations\":{ \"reasons_for_failure\" : { \"significant_terms\":{\"field\" : \"fault_description\", \"size\" : 20} } } } } }' Example results\"aggregations\": { \"car_model\": { \"buckets\": [ { \"key\": \"Taurus\", \"doc_count\": 3967, \"reasons_for_failure\": { \"doc_count\": 3967, \"buckets\": [ { \"key\": \"coil\", \"doc_count\": 250, \"score\": 0.544, \"bg_count\": 1115 }, { \"key\": \"mounts\", \"doc_count\": 178, \"score\": 0.3969, \"bg_count\": 777 }, { \"key\": \"spring\", \"doc_count\": 261, \"score\": 0.3668, \"bg_count\": 1706 }, ... To make these keywords a more readable explanation of failures, a useful technique is to display the keywords in context (a technique commonly known by the acronym KWIC). This involves taking the keywords from the results shown above and constructing a query with highlighting. Here is an example javascript function to do just this: Fetching \"keywords in context\" examplesfunction getKWIC(car_model,buckets){ var shouldClauses=[]: for(var i=0: i < buckets.length: i++) { \/\/Get at least the top 5 significant keywords if((shouldClauses.length > 5) || (buckets[i].score < 2)) { shouldClauses.push( {\"term\" : { \"fault_description\" : { \"value\" : buckets[i].key, \"boost\" : buckets[i].score } }}): } } var kwicQuery={ \"query\" : { \"bool\" : { \"should\":shouldClauses, \"must\":[{\"terms\":{\"car_model\":[car_model]}}] } }, \"size\":30, \"highlight\": { \"pre_tags\" : [\"<span style=\"background-color: #f7f7a7: \">\"], \"post_tags\" : [\"<\/span>\"], \"fields\": {\"fault_description\":{\"matched_fields\": [\"fault_description\"] }} } }: dataForServer=JSON.stringify(kwicQuery): var kwResultHtml=\"\": $.ajax({ type: \"POST\", url: '\/nhtsa\/_search', dataType: 'json', async: false, data: dataForServer, success: function (data) { var hits=data.hits.hits: for (h in hits){ \/\/format results as html table rows var snippets=hits[h].highlight.fault_description: kwResultHtml+=\"<tr><td>\": for(snippet in snippets){ kwResultHtml+=\"<span>\"+snippets[snippet]+\"...<\/span>\": } kwResultHtml+=\"<\/td><\/tr>\": } } }): return kwResultHtml: } The results of our root-cause analysis might then appear as follows: . AS A RESULT OF THE SITUATION, I INCURRED EXPENSE TO REPLACE THE , STRUTS AND UPPER : PLUS...AS I WAS BACKING UP THE FRONT DRIVERS SIDE BROKE, PUNCTURING THE TIRE. IT IS THE SAME... 2001 FORD TAURUS (48302 ODOMETER) REAR BROKE REPLACED WITH REAR STRUTS. *NM... WAS BROKE. FORD HAS HAD A HISTORY OF FAILURES AND SHOULD ISSUE A RECALL ON ALL . *TR...WHILE GETTING A SCHEDULED OIL CHANGE, THE DEALER NOTICED MY ON THE REAR PASSENGER SIDE... TRECALL CAMPAIGN 04V332000 CONCERNING . THE BROKE IN THREE PLACES. IT BLEW... Use case: Training a classifier Many systems classify documents by assigning tag or category fields. Classifying documents can be a tedious manual process and so in this example we will train a classifier to automatically spot keywords in new documents that suggest a suitable category. By using The Movie Database (TMDB) data we can search for movies that contain the term vampire in their description: Example querycurl -XGET \"http:\/\/localhost:9200\/tmdb\/_search\" -d' { \"query\" : { \"match\" : {\"overview\":\"vampire\" } }, \"aggregations\" : { \"keywords\" : {\"significant_terms\" : {\"field\" : \"overview\"}} } }' Example results \"aggregations\": { \"keywords\": { \"doc_count\": 437, \"buckets\": [ { \"key\": \"vampire\", \"doc_count\": 437, \"score\": 3790.9405, \"bg_count\": 437 }, { \"key\": \"helsing\", \"doc_count\": 17, \"score\": 113.9480, \"bg_count\": 22 }, { \"key\": \"dracula\", \"doc_count\": 33, \"score\": 98.3565, \"bg_count\": 96 }, { \"key\": \"harker\", \"doc_count\": 7, \"score\": 42.5023, \"bg_count\": 10 }, { \"key\": \"undead\", \"doc_count\": 15, \"score\": 31.9717, \"bg_count\": 61 }, { \"key\": \"buffy\", \"doc_count\": 4, \"score\": 23.130071721937412, \"bg_count\": 6 }, { \"key\": \"bloodsucking\", \"doc_count\": 4, \"score\": 19.8244, \"bg_count\": 7 }, { \"key\": \"fangs\", \"doc_count\": 5, \"score\": 19.7094, \"bg_count\": 11 } These keywords could then be cherry-picked and added to a new terms query that is registered using the Percolate API to help identify new movies that should potentially be tagged as vampire movies. Note that much of the guesswork in selecting useful keywords is avoided. Use case: Finding mis-categorized content using the Like this but not this pattern For systems that have a lot of pre-categorized content it can be useful to identify where the database maintainers have failed to categorize existing content properly. In this example we will start by looking at Reuters news articles tagged with the topic \"acquisitions\" and use aggregation to learn some relevant keywords e.g.: curl -XGET \"http:\/\/localhost:9200\/reuters\/_search\" -d' { \"query\" : { \"match\" : {\"topics\":\"acq\" } }, \"aggregations\" : { \"keywords\":{\"significant_terms\" : {\"field\" : \"body\", \"size\" : 20}}, } }' The keywords that are revealed as relevant to the \"acquisition\" news category are as follows: { \"aggregations\": { \"keywords\": { \"doc_count\": 2340, \"buckets\": [ { \"key\": \"acquisition\", \"doc_count\": 469, \"score\": 0.973, \"bg_count\": 704 }, { \"key\": \"acquire\", \"doc_count\": 395, \"score\": 0.927, \"bg_count\": 535 }, { \"key\": \"shares\", \"doc_count\": 842, \"score\": 0.820, \"bg_count\": 2258 }, { \"key\": \"stake\", \"doc_count\": 363, \"score\": 0.780, \"bg_count\": 529 }, { \"key\": \"inc\", \"doc_count\": 1220, \"score\": 0.752, \"bg_count\": 4390 }, { \"key\": \"merger\", \"doc_count\": 298, \"score\": 0.674, \"bg_count\": 416 }, { \"key\": \"acquired\", \"doc_count\": 327, \"score\": 0.643, \"bg_count\": 513 }, ... The next step is to construct a like this but not this query by: as follows: curl -XGET \"http:\/\/localhost:9200\/reuters\/_search\" -d' { \"query\" : { \"bool\": { \"mustNot\":[ {\"match\" : {\"topics\" : \"acq\" } }], \"should\":[ { \"terms\":{\"body\":[\"acquisition\", \"acquire\",\"shares\",\"stake\",\"inc\",\"merger\"...]}} ] } } }' The results of this query are a relevance-ranked list of news articles that should have been tagged as articles about acquisitions but have somehow slipped through the net. Below is an example match which failed to record the \"acq\" topic tag: Salomon Brothers said it has 21,978 convertible subordinated debentures of Harcourt... Brace Jovanovich Inc, which it says could be converted into 21,978,000 common . In a filing... them into stock. Salomon said it would have a 35.8 pct in Harcourt, based on 39.4 mln .... Harcourt has said that Salomon and Mutual Shares Corp, a New York investment firm, hold a combined... some or all of their current in the market or in negotiated deals, Use case: detecting credit card fraud When a bank's customers phone the bank and complain that they have noticed unusual transactions on their account, the bank undertakes a common point of compromise analysis. The unusual transactions that were spotted might be payment for a hotel in a country the customer has not visited but this payment is the of the root problem and not the . Somewhere in a customer's credit card history of payments a merchant has deliberately stolen their details (perhaps a card-skimmer installed in a petrol station) or accidentally lost their details (perhaps a website had its database hacked). Either way, this merchant represents a common point of compromise where potentially many card details were obtained and sold on the black market. For the bank, the objective is to identify the problem merchant (or merchants) and identify their customers who may be about to experience fraudulent payments. The starting query would be to take a selection of compromised cards and look at all of their transactions in the last few months and summarise who they've been paying: curl -XGET \"http:\/\/localhost:9200\/transactions\/_search\" -d' { \"query\": { \"terms\": {\"payer\" : [59492167, 203701197, 365610456,....]} }, \"aggregations\" : { \"payees\":{ \"significant_terms\":{\"field\":\"payee\"}, \"aggregations\":{ \"payers\":{\"terms\":{\"field\":\"payer\"}}} } } }' The set of payers in the query represent our unhappy customers and so the set of transactions that it matches will include a mix of happy payments but crucially the unhappy payments that led to their predicament. By using the aggregation on the payee field, we can focus in on the merchants that appear in this fishy set of transactions disproportionately more than they would in a random sampling of predominantly happy customers. This helps tune out the popular merchants that are likely to be common with any random sample of customers and focus in on the likely points of compromise. For the selected fishy merchants, we have a child aggregation of payers so we can see just how many of our unhappy customers traded with this merchant and can visualize this as a social network diagram. If we only use the simpler aggregation we tend to focus on the popular merchants in our set and the culprit is not clear as it is hidden among the commonly common payees: However when we use the aggregation our focus shifts to the uncommonly common connector and the extra stats in the results mean we can report on what percentage of that merchant's transactions lie in this fishy set of transactions: Now the culprit is much clearer. The fishiest merchant here has 13 of his total of 72 transactions in the problem set, making him our strongest suggestion. The merchant with 3 out of his 19 transactions present in this set may appear simply because the bad merchant's customers are also likely to shop at this neighbouring store. Overlaying geographic and temporal information helps these sorts of investigations and is easy to do by adding extra child aggregations into our queries. Use case: product recommendation Product recommendations are often driven by a \"people who liked this also like..\" type analysis of purchase data. The most powerful recommendation engines use complex algorithms and examine many features of the data but here we will use the aggregation to provide reasonable results quickly using a simple set of data. In this example, we will use the publicly available \"MovieLens\" data. The first task is to index the user ratings data so that there is a single JSON document for each user listing all of the movie IDs they have liked (ratings of 4 stars or over): { \"user\": 6785, \"movie\": [12, 3245, 4657, 7567, 55276, 56367...] } Now for any given movie we can query for all the people who liked that movie and summarise what other movies they like: { \"query\": { \"terms\": { \"movie\": [46970]} }, \"aggs\": { \"significantMovies\": { \"significant_terms\": { \"field\": \"movie\" }}, \"popularMovies\": { \"terms\": { \"field\": \"movie\" }} } } The above query first selects all fans of the movie with the ID 46970 (Talladega Nights) and then summarises their favourite movies using the aggregation to identify the most popular movies and the <code>significant_terms aggregation to find the more insightful \"uncommonly common\" movies. The results are as follows: The aggregation looks to focus on movies that are universally popular (and arguably irrelevant) while the <code>significant_terms aggregation has focused in on movies that are particularly more popular with the fans of \"Talladega Nights\". The top 3 suggestions shown here all feature the star of Talladega Nights, Will Ferrell. Conclusion This post illustrates a sample of what can be done with . I am excited to see what new insights people will gain from exploring their data using this new perspective. Let us know how you are using it and help us improve the analytic capabilities. Happy hunting! \n"}<br>{"index": {"_id": 1350}}<br>{"title":"Where in the World is Elasticsearch? - April 14, 2014","seo_title":"","url":"\/blog\/world-elasticsearch","author":{"name":"Daniel Palay"},"date":"April 14, 2014","category":"","locales":"","content":" Welcome to our new series, where we\u2019ll give you a sneak peak of what conferences we\u2019ll be attending and other places to find us. We know the series doesn\u2019t come with its , but it will come along with great insights on our future presentations. For our regular readers, we hope these posts give you another reason to visit us at an event near you. So, without further ado, where in the world is Elasticsearch going to be this week? Not only will we have a booth (#1113) on the exhibit hall floor - right next to the crowd favorite developer lounge - but we\u2019ll also have several Elasticsearch talks through out the conference. Here\u2019s who and what you can hear: Kevin Kluge, Vice President of Engineering When: Thursday, April 17th @ 9:45 am Where: Room 220 Jordan Sissel, Creator-Logstash When: Tuesday, April 15th @ 8:00 pm Where: Room 212 Now that you know where we\u2019ll be, come see what we have in store. But if you can't join us, follow us on for updates! \n"}<br>{"index": {"_id": 1351}}<br>{"title":"Introducing Elasticsearch.Net and NEST 1.0.0-beta1","seo_title":"","url":"\/blog\/introducing-elasticsearch-net-nest-1-0-0-beta1","author":{"name":"Martijn Laarman"},"date":"April 10, 2014","category":"Engineering","locales":"","content":" It\u2019s been 4 months since was released and a lot has happened since then. Elasticsearch released 1.0 and even version 1.1. With this release announcement, I\u2019m pleased to say NEST has finally caught up and brings (almost) all the awesome that Elasticsearch 1.0 and 1.1 bring to the .NET world. Even more exciting \u2013 as of today, Elasticsearch.Net and NEST are both officially supported .Net clients for Elasticsearch! (For those just learning about Elasticsearch.Net and NEST, Elasticsearch.Net is the low level client and NEST is the high level client for users of .Net and Elasticsearch.) Before diving in all the technical details of the NEST 1.0 beta release, I would first like to express a sincere thank you to all of you who\u2019ve reached out on Twitter, GitHub issues and via email. Your kind words made all the difference these past 4 months as I busily switched jobs, refactored the client and implemented 1.0\/1.1 features. I am happy to say that I have formally joined Elasticsearch Inc and will now be fully dedicated to making Elasticsearch in the .NET world awesome! So, what does \u2018beta\u2019 mean? All tests are passing, but we are still waiting for at least one new feature to land. Additionally, beta means that some new features may change before general release. Most importantly, this beta period is intended to solicit as much feedback as possible from everyone on breaking changes\/oversights\/bugs. Breaking Changes With this 1.0 release, we will have many breaking changes. The NEST releases have been around since 2010 and the internals were showing their age. This 1.0 release represents an almost complete refactoring of NEST. A separate section that lists the breaking changes . If you find any breaking changes that are not documented, we\u2019d love to hear about them in . Not one but two clients NEST 0.12.0 introduced a client interface called which allowed you to build your own requests and responses without having to worry about building endpoints. Much of the work for this 1.0 beta release has been around refactoring this functionality out of the NEST assembly and making NEST\u2019s strongly typed use internally. Elasticsearch.Net Elasticsearch.Net\u2019s client is now called and is almost completely generated , exposing all the Elasticsearch 1.1 endpoints. It brings a client that\u2019s well aligned in spirit and architecture with the other official Elasticsearch client libraries. Elasticsearch.Net leaves all the request and response mapping up to you although it comes with support for mapping responses into a dynamic container (a slightly modified DynamicDictionary from ) out of the box. Elasticsearch.Net is very much intended to be used by other high level clients. Another big new feature is built-in support. This allows the client to retry failed connections on different nodes and sniff the cluster for live nodes when a node fails or at certain configurable intervals. Elasticsearch is elastic, and the client should be, too. Elasticsearch 1.0.0-beta is a prerelease package so make sure you adjust your filter inside the package manager: or pass the flag to nuget from the console: Please read to find out more. NEST NEST\u2019s client classes have completely been rewritten and internally use and still expose the Elasticsearch.Net client. It benefits from it\u2019s cluster failover support and it no longer has complicated internal path builders. NEST is highly opinionated on how you should build and consume Elasticsearch responses, and comes with a strongly typed Query DSL. NEST has really high coverage of mapped endpoints, and the unmapped API\u2019s are all identified and documented on the . Changelog This release consists of 300+ commits over a 4 month timespan so I will just list the highlights: Aggregations All of Elasticsearch\u2019s (1.0 and 1.1!) aggregations have been mapped in NEST 1.0. Snapshot and Restore You can now script your create\/delete\/get repositories\/snapshotting\/restoring with NEST. New query\/filter types The and have all been mapped, along with other new query and filter types. Lots of new API\u2019s are mapped Count percolations, clearing scrolls, external versioning, suggests and more are now all mapped in NEST. The goal is to get as close to a 100% API coverage as possible before the final 1.0 release goes out. Just to reiterate: , the low level client, already has 100% API coverage but building and handling the responses is out of its scope. Conditionless() query construct NEST comes with a powerful feature called conditionless queries which greatly simplifies writing queries with optional parts. Consider this example: NEST will remove the term query and default to not sending a query at all in the body (equivalent to ) But what if you want a different query to be run in instead of ? This is where the construct comes into play: Now we\u2019ll fallback to a query on instead. Note that fallbacks themselves can be conditionless and constructs can be nested inside fallbacks as well. Also if you want to disable conditionless queries you can specify on individual parts in the query or globally on the search descriptor. The previous example will throw an exception because the term misses a value. To enable conditionless only for certain parts in your query, you can also do: The previous example will just send a query on the field , and NEST is smart enough to infer the bool is no longer needed. Finally, if you really intend to send a conditionless query to Elasticsearch you can use The and constructs are not new but worth repeating in this context. Community As with every release the level of community engagement never ceases to amaze me. Whoever proclaimed open source in .Net is dead? A thank you goes out to the folks who submitted the following pull requests. In addition a huge thank you goes out to all the folks who gave continuous feedback on the state of while it underwent major refactoring. A special shout out to and for opening and Seeing like is awesome, thank you & ! Moving forward The goal is to come to a final Elasticsearch.Net and NEST 1.0 release as soon as possible and with your help we can! Please don\u2019t forget to post your issues and feedback in ! \n"}<br>{"index": {"_id": 1352}}<br>{"title":"Elasticsearch & MapR Hadoop: The Best of Both Worlds","seo_title":"","url":"\/blog\/elasticsearch-mapr-hadoop-best-worlds","author":{"name":""},"date":"April 10, 2014","category":"","locales":"","content":" It\u2019s been a big week for Elasticsearch and Hadoop! On Tuesday, we announced the release of Elasticsearch for Apache Hadoop 1.3 M3, which includes a . And just last week, we in the Hadoop ecosystem, with MapR Technologies. We\u2019re beyond thrilled to partner with MapR and to help their customers - and ours - add real-time search and analytics capabilities to their MapR Hadoop Distribution clusters. With the combination of MapR and Elasticsearch, developers gain a scalable, distributed architecture to quickly perform search and discovery across tremendous amounts of information. The combined solution is already in use at leading enterprise companies including Solutionary, the leading pure-play managed security service provider, and several Fortune 100 financial services institutions. For example, we worked closely with MapR Technologies to help a large financial institute store all of their raw access logs - billions of documents - in Hadoop. The documents were indexed into Elasticsearch using the Elasticsearch for Apache Hadoop integration, then visualized using Kibana. This approach allowed the customer to have near real time visibility into their data through Kibana, yet also run batch oriented jobs over all their raw data when needed. Moreover, by using the Elasticsearch for Apache Hadoop, our data search and analytics capabilities were also available while executing the aforementioned Map\/Reduce, Hive, or Pig jobs. The distributed nature of the Map\/Reduce model fits really well on top of Elasticsearch because we correlate the number of Map\/Reduce tasks with the number of Elasticsearch shards for a particular query. So every time a query is run, the system dynamically generates a number of Hadoop splits proportional to the number of shards available so that the jobs are run in parallel \u2013 your Hadoop cluster scales easily alongside Elasticsearch and vice-versa. Best of all, Elasticsearch for Apache Hadoop provides a single jar that enables real time search and analytics across different Hadoop, Cascading, Hive and Pig versions and across multiple Hadoop distributions, whether it is vanilla Apache Hadoop, CDH, HDP, MapR or Pivotal. No dependencies, all the functionality. We look forward to hearing what you\u2019re building with Elasticsearch and MapR. Most of all, we want to hear how using this software together makes your life better, and how we can improve. any time! \n"}<br>{"index": {"_id": 1353}}<br>{"title":"This Week in Elasticsearch - April 09, 2014","seo_title":"","url":"\/blog\/2014-04-09-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"April 09, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch Core Photo courtesy of . Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Photo courtesy of . Slides & Videos \u00a0 Where to Find Us We'd love to feature all the great Elasticsearch, Logstash and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Community Manager, , know! Brasil Elasticsearch is very excited to send our first speaker from the company to Brasil! Leslie Hawthorn, our Community Manager, will be returning to FISL once again to speak on . Leslie will speak on May 7th and runs from May 7-10th in Porto Alegre. Her talk will be in English but most of the talks on the program are given in BR-PT. Leslie will also be on hand to answer questions you may have about Elasticsearch, Logstash and Kibana. Canada France Germany Italy David Pilato will present Make sense of your (BIG) data! at the The conference takes place in Rome on April 11-12th, and David will speak at 2:10 PM on the 12th. Japan The has been scheduled by Jun Ohtani. Please plan to join the meeting at 7 PM on April 21st. Romania will be speaking at the , covering an Introduction to Elasticsearch. Doors open at 6 PM. Spain has been invited to speak at the Barcelona on Rails Meetup on May 15th. Join him for a presentation on Doors open at 7 PM, and thanks to the fine folks at XING for hosting us! South Africa will take the stage at ScaleConf to talk . The conference runs April 10th and 11th in Cape Town. Tunisia will speak at the Esprit JUG Days in Ariana. Further details of the conference schedule are forthcoming, but mark your calendar for May 7th and 8th. In the meantime, you may want to visit the . United Kingdom United States Where to Find You Our Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1354}}<br>{"title":"Sizing Elasticsearch","seo_title":"","url":"\/blog\/found-sizing-elasticsearch","author":{"name":"Alex Brasetvik"},"date":"April 08, 2014","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. Scaling up and outWe're often asked \"How big a cluster do I need?\", and it's usually hard to be more specific than \"Well, it depends!\". There are so many variables, where knowledge about your application's specific workload and your performance expectations are just as important as the number of documents and their average size. In this article we won't offer a specific answer or a formula, instead we will equip you with a set of questions you'll want to ask yourself, and some tips on finding their answers. \n"}<br>{"index": {"_id": 1355}}<br>{"title":"Elasticsearch for Apache Hadoop 1.3 M3 is out","seo_title":"","url":"\/blog\/elasticsearch-apache-hadoop-1-3-m3","author":{"name":"Costin Leau"},"date":"April 08, 2014","category":"","locales":"","content":" I am happy to announce that 1.3 M3 has been . Elasticsearch for Apache Hadoop provides a single jar that enables real time search and analytics across different Hadoop, Cascading, Hive and Pig versions and across multiple Hadoop distributions, whether it is vanilla Apache Hadoop, CDH, HDP, MapR or Pivotal. No dependencies, all the functionality. Besides a healthy dose of bug fixes, the last (planned) milestone in 1.3 adds a series of improvements and features, such as: Multi-index Writes When indexing data, it is common to `split` it into different buckets based on its content. For example, log data is typically indexed per date (per-day, week or month), which makes it easy to both handle and manage the data and its life-cycle. es-hadoop 1.3 M3 brings this functionality to the table, allowing data in Hadoop to be indexed in real-time and based on its content, regardless of whether you are using Map\/Reduce, Cascading, Hive or Pig. If we want to index our media based on its type, we can simply define the following target resource: At runtime, the field is being extracted, the actual index\/type resolved and the data properly dispatched. The actual value extraction happens transparently whether you are using a Cascading tuple or a Hive table and also, no matter if you passing in native types or raw JSON. See of the user guide for more information. Support for automatic time-based formatting is for 1.3-RC1, so one could use logstash-like patterns: ( ) Metrics Getting insight into how your jobs are performing is crucial for maximizing performance, tracking behavior and diagnosing issues. That is why in M3, we have added that cover extensively the entire I\/O spectrum of es-hadoop. Simply upgrade and you will get the stats automatically logged into the console for each Map\/Reduce job: All the stats are exposed through the Hadoop infrastructure and are available through the standard APIs. There are extra steps or configurations that need to be setup - everything is already included. Mapping Typo Suggestions Typos happen to everyone (to some more often than to others), and it can be quite annoying discovering that your query is incorrect because there is no or in your data. es-hadoop tries to help out: This validation can be if you wish to prevent your potentially expensive job from running with typos. Proxy (HTTP and SOCKS) support If your network has access restrictions, with M3 you can use both HTTP and SOCKS proxies to transparently route connections from Hadoop to Elasticsearch (and back :)). Both open and authorized proxies are supported. Plus, the proxying is scoped, so es-hadoop connections do not interfere with the rest of the JVM. Same binary for both Hadoop 1.x and 2.x es-hadoop supports both Hadoop 1.x and 2.x environments. Since Hadoop 2.x is not binary compatible with Hadoop 1.x (for package) this resulted in two separate jars that had to be used, one for each environment. Needless to say, it was easy to mix the two, until now. In M3, we introduce a single jar that works across both Hadoop environments! Modular jars Speaking of binaries, in M3 we also introduced one jar per module. es-hadoop as a whole takes about ~300 KB which gives you integration with Map\/Reduce, Hive, Pig and Cascading. Yet we understand that some folks might want to use Elasticsearch just with Cascalog or only do real-time search with Hive. For this reason, one can now get a jar, for each integration, with a dedicated Maven POM, slimmer in size and that can run stand-alone, no other jars required. We have also expanded the configuration option for each integration, allowing a single job to read and write data to different Elasticsearch indices, extended Cascading integration with per- configuration and (run ANSI SQL in Hadoop against Elasticsearch) and improved exception reporting and handling. Feedback welcome We are quite excited about the upcoming 1.3 release and we hope you are too! So go ahead, for a spin and what you think! \n"}<br>{"index": {"_id": 1356}}<br>{"title":"Elasticsearch Puppet Modules 0.3.0 Released","seo_title":"","url":"\/blog\/elasticsearch-puppet-module-0-3-0-released","author":{"name":"Richard Pijnenburg"},"date":"April 07, 2014","category":"Engineering","locales":"","content":" Today we are happy to announce the release of our Elasticsearch Puppet modules version 0.3.0. You can download them and read the full changes list here: What's New We've improved support for different Linux distributions and added OpenSuse to our list of supported distros. Debian 6 support has also been improved. To improve the support for the defaults files we've implemented . Improved testing For the past few weeks, we've worked hard on improving the quality of these modules. With the implementation of System Tests, we now have several layers of testing: Puppet lint allows us to validate the code against the recommended Puppet style guidelines from the . This makes sharing code easier as everyone holds to the same guidelines as much as possible. The syntax validation step validates the code against the without having to run the actual code. Rspec tests are the first step in actual validation of the module. This step runs the code and validates different test scenarios and is the first step in catching errors. System testing is the final step in the testing process. These tests run the actual code on real systems to validate it all actually works. Conclusion We will continue to improve the quality and support of our Puppet modules. You can report any problems on our page. \n"}<br>{"index": {"_id": 1357}}<br>{"title":"Count on Elasticsearch!","seo_title":"","url":"\/blog\/count-elasticsearch","author":{"name":"Adrien Grand"},"date":"April 03, 2014","category":"","locales":"","content":" One feature that has been requested landed in Elasticsearch and is available in the 1.1.0 release: the ability to count unique values for a particular field. There are lots of interesting things that this feature allows to compute: Example This feature is exposed under the form of an aggregation called , so that you can benefit from all the goodness of aggregations, especially composability. So taking back the unique number of visitors on your website as an example, you could put this aggregation under a aggregation in order to see the trend over months: curl -XGET \"http:\/\/localhost:9200\/_search\" -d' { \"aggs\": { \"monthly\": { \"date_histogram\": { \"field\": \"timestamp\", \"interval\": \"month\" }, \"aggs\": { \"visitor_count\": { \"cardinality\": { \"field\": \"ip_address\" } } } } } }' Under the hood As long as a dataset is small and can fit on a single machine, computing the number of unique values is simple and is just a matter of adding elements into a and returning its size. However, memory usage of this solution is linear with the number of unique values, which makes it impractical to evaluate high cardinalities. Another issue is that if you want to compute the cardinality of a dataset that is stored on several machines, summing up the cardinalities returned on each machine is not good enough since there might be overlap. So you actually need to stream these sets to a single location where they can be merged in order to know the actual cardinality. Fortunately, there are other algorithms that address these challenges, in particular and . I won't explain how they work given that there are already some that do it. However, here are a few important things to know about these algorithms: Because of the different characteristics of these algorithms, there is something interesting that can be done: using on small cardinalities and on larger ones. This way, we would have the best of both worlds: excellent precision on small cardinalities and fixed memory usage whatever the cardinality to estimate is. But this also means that a needs to be slightly modified in such a way that it can be upgraded to an counter. This is exactly what the algorithm, that we use for the aggregation, does. Precision and memory usage As we just saw, precision degrades at some point in order to keep memory usage bounded. Elasticsearch makes this threshold configurable through the parameter. For example, if you configure a of , you could expect precision to be excellent if the return value is < 1000 and a bit more approximate otherwise. The memory usage of this aggregation also depends on this parameter: for a value of , you should expect a memory usage of about bytes per shard per aggregation bucket. For example, we built the following chart that computes the relative error for various sets of random values, depending on the precision threshold and the actual cardinality: For all 3 thresholds, counts have been accurate up to the configured threshold (although not guaranteed, this is likely to be the case). Please also note that even with a threshold as low as , the relative error remained way under under 5%, even when counting millions of items. Hopefully this post gives you insights about what the aggregation does and how it works. We look forward to your feedback on the or ! \n"}<br>{"index": {"_id": 1358}}<br>{"title":"This Week in Elasticsearch - April 02, 2014","seo_title":"","url":"\/blog\/2014-04-02-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"April 02, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Elasticsearch Core Elasticsearch EcosystemHere's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Slides & Videos \n"}<br>{"index": {"_id": 1359}}<br>{"title":"This Week in Elasticsearch - March 26, 2014","seo_title":"","url":"\/blog\/2014-03-2-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"March 26, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Elasticsearch Core Elasticsearch EcosystemHere's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Slides & Videos \n"}<br>{"index": {"_id": 1360}}<br>{"title":"Snapshot and Restore","seo_title":"","url":"\/blog\/found-elasticsearch-snapshot-and-restore","author":{"name":"Konrad Beiske"},"date":"March 26, 2014","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. Behind the Scenes Let's take a closer look at Elasticsearch's snapshot and restore module and the files used to store snapshots, exemplified with snapshots on S3. \n"}<br>{"index": {"_id": 1361}}<br>{"title":"Elasticsearch 1.1.0, 1.0.2 and 0.90.13 released","seo_title":"","url":"\/blog\/elasticsearch-1-1-0-released","author":{"name":"Clinton Gormley"},"date":"March 25, 2014","category":"Releases","locales":"","content":" #index #post_content p { margin: 0.5em }<br \/> Today we are happy to announce the release of , based on Lucene 4.7, along with bug fix releases and :You can download them and read the full changes list here: \n"}<br>{"index": {"_id": 1362}}<br>{"title":"Elasticsearch - The Definitive Guide","seo_title":"","url":"\/blog\/elasticsearch-definitive-guide","author":{"name":"Clinton Gormley"},"date":"March 20, 2014","category":"News","locales":"","content":" For a long time, new users have struggled to get started with our reference docs, and for a long time we have been promising \u201csomething better\u201d. Today, we are proud to announce the early release edition of , which will be published by O\u2019Reilly Media. It can be read online at and it will be available to purchase in printed form or as an eBook from O\u2019Reilly at . This book is suitable for novices and experienced users alike. We expect you to have some programming background and, although not required, it would help to have used SQL and have some database experience. We explain concepts from first principles, helping novices to gain a sure footing in the complex world of search. The reader with a search background will also benefit from this book. Elasticsearch is a new technology which has some familiar concepts. The more experienced user will gain an understanding of how those concepts have been implemented and how they interact in the context of Elasticsearch. It was very important to us to ensure that this book would be freely available to anybody who needs it. A lot of time and effort was invested in ensuring that it could be freely read online, while still making it available in eBook and printed format. We would like to thank O\u2019Reilly for their support, cooperation and flexibility. They are one of the few publishers who really understand open source and have already made a number of their works available online for free. It is an honour to join their stable of authors. The book is a long way from being finished\u2009\u2014\u2009there is a lot to write about! However, we felt that there was enough content to be useful to many users already. Release soon release often! We will be uploading new chapters as they are finished. If you spot any errors in the book, or have suggestions for improving a section, we would love to hear from you. Please open an issue or a pull request on the GitHub repo: . We will need you to sign our standard to ensure that your changes can be incorporated in the printed version of the book. Happy reading! \n"}<br>{"index": {"_id": 1363}}<br>{"title":"Logstash 1.4.0 GA Has Been Unleashed","seo_title":"","url":"\/blog\/logstash-1-4-0-ga-unleashed","author":{"name":"Jordan Sissel"},"date":"March 20, 2014","category":"News","locales":"","content":" Today, we are releasing Logstash 1.4.0 GA! \u00a0This release is the culmination of several months of adding features to and maturing Logstash.To recap, here are some of the key features and changes from 1.3 to 1.4: Also we wanted to give a big THANK YOU to the community for all their help with tests and the patches that went into this release! The Logstash user base does so much to move the project forward, and Logstash is so much better for it. \u00a0This release had some great features, but we are particularly excited about the quality and maturity improvements in it.You can read the\u00a0, or jump right\u00a0!As always, we welcome and encourage feedback. Check out the release and what you think. Happy Logstashing! \n"}<br>{"index": {"_id": 1364}}<br>{"title":"This Week in Elasticsearch - March 19, 2014","seo_title":"","url":"\/blog\/2014-03-19-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"March 19, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Elasticsearch Core Elasticsearch EcosystemHere's some more information about what is happening in the ecosystem we are maintaining around the ELK stack - that's Elasticsearch plus Logstash and Kibana - including plugin and driver releases. Slides & Videos Where to Find UsWe'd love to feature all the great Elasticsearch, Logstash and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Community Manager,, know!Canada will be attending and the accompanying Django sprints. Make sure to stop by and hear more from him during his poster session .France and will both be at Devoxx France 2014, where they will co-present the . Devoxx France runs April 16-18th in Paris.Germany Italy JapanThe has been scheduled by Jun Ohtani. Please plan to join the meeting at 7 PM on April 21st.The NetherlandsThe group will convene on Thursday, April 3rd at 6:30 PM at Elasticsearch's EU HQ in Amsterdam. Attendees will be treated to a deep dive on new features in Elasticsearch 1.0 by and a demo of Elasticsearch Marvel by . New ZealandThe will talk all things Elasticsearch on Tuesday, March 25th. Doors open at 6 PM.NorwayThe has been scheduled for April 3rd at 6 PM. Details on the presentations are forthcoming, but you can register to attend now.South Africa will take the stage at ScaleConf to talk . The conference runs April 10th and 11th in Cape Town.United Kingdom will share What's New in Elasticsearch 1.0 with the on March 21st. Doors open at 6:15 PM.United States Where to Find YouOur Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, .Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head.TrainingsIf you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1365}}<br>{"title":"Kibana 3.0.0 GA is now available!","seo_title":"","url":"\/blog\/kibana-3-0-0-ga-now-available","author":{"name":"Rashid Khan"},"date":"March 18, 2014","category":"","locales":"","content":" Today is a big day for Elasticsearch and the Kibana team. After 5 milestone releases and over 1000 commits, we\u2019re happy to announce the release of Kibana 3.0.0 GA. Over the last year, Kibana has moved from a simple interface to search logs to a fully featured, interactive analysis and dashboard system for any type of data. Everyday, we\u2019re incredibly inspired by the people who tell us they\u2019ve solved major problems, optimized their existing deployments and found insights in places they never imagined. . Changes since milestone 5 We\u2019re thrilled to say there have been many bugs fixed since milestone 5, but we\u2019ve introduced no breaking changes! One hundred percent of the focus has been on delivering a stable, consistent experience. What do I need to do to upgrade? If you\u2019re coming from milestone 5? Nothing! Simply install and go. If you\u2019re upgrading from milestone 4 your dashboards schema is compatible, but you should know that the has been deprecated (.) If you\u2019re coming from milestone 4, you may need to clear your browser cache upon upgrading. We have put in place a number of cache busting strategies to limit the need for this in the future. More information We\u2019ve written some great tutorials that you can find in the section. If you\u2019re using Kibana for the first time, make sure to read the . Additionally, these pieces of documentation will be useful to getting you up and running: Getting Started Videos We\u2019ve also created some getting-started videos to guide you through Kibana\u2019s many panel types. These two are the first in a series, so stay tuned to this blog to learn when more are on offer. For a deeper dive, you can attend our live Kibana webcast, hosted by yours truly, on April 9th. You can to attend the session, which will include live Q&A following the presentation. \u00a0 Introduction to the Kibana Terms Panel \u00a0 Using the Kibana Table Panel Let Us Know What You Think and check out all of the updates! As always, ! \n"}<br>{"index": {"_id": 1366}}<br>{"title":"Logstash 1.4.0 RC1 released","seo_title":"","url":"\/blog\/logstash-1-4-0-rc1-released","author":{"name":"Jordan Sissel"},"date":"March 14, 2014","category":"","locales":"","content":" We are pleased to announce that the first release candidate for Logstash 1.4.0 is available! There are no new 'big' features since 1.4.0 Beta 2, only a few bug fixes! You can read the , or jump right ! We'll be running some longer tests on this over the next few days, and with your help, will be releasing 1.4.0 GA shortly! Happy Logstashing! \n"}<br>{"index": {"_id": 1367}}<br>{"title":"Marvel 1.1.0 Released","seo_title":"","url":"\/blog\/marvel-1-1-0-released","author":{"name":"Boaz Leskes"},"date":"March 13, 2014","category":"","locales":"","content":" Today, we are happy to announce the release of . This is the first feature release since the introduction of Marvel, slightly more than a month ago. We've gotten great feedback from our users thus far, and Marvel 1.1.0 includes a couple of new features based on their requests. Here are the highlights: Elasticsearch 1.0 Support in Sense Sense's knowledge base has been extended to incorporate new features introduced in Elasticsearch 1.0. Most notably, autocomplete suggestions are now available for both the Aggregations and Snapshot and Restore APIs. All have also been incorporated. These updates will make it easier to both explore these new APIs via Sense and discover how your API calls need to change when moving to 1.0. Visual Improvements to the Nodes & Indices Overview Changes to the Nodes & Indices section provide new visual cues to help you understand the state of your cluster. The current master node is indicated with a little star. If a node drops off the cluster and stops sending data, the corresponding row will be greyed out to indicate that the data is stale and some action is needed. The same thing happens if an index was deleted, indicating the index no longer exists. Data Reduction One of the goals when building Marvel was to offer in-depth monitoring and insights into the heart of Elasticsearch. As such, Marvel's agent shipped statistics on the cluster and index levels, even all the way to shard level information - be it a primary shard or a replica. Since the release, we have learned that shard level statistics generate considerable amounts of data and some users find they do not provide sufficient value to be worth the extra resources. Shard level statistics are useful to pinpoint bad performance to the level of a specific shard misbehaving. However, in practically all cases the unintended behavior is caused by load on the Node hosting the shard. As Marvel already makes Node level information readily available, we have decided to disable shipping of shard level statistics by default. You can still enable them, in run-time, if needed. We expect this change to result in big resource savings, especially in deployments with many indices. To help even more, we have also increased the default sampling rate from 5 seconds to 10 seconds. Dynamically Updatable Settings Marvel now allows you to use the to change some of its settings. You can now temporarily disable data shipping and change the target to which the agent sends data without restarting the cluster. This will be very helpful during maintenance and upgrades. For a complete change list, see . As mentioned at the start of this post, we welcome all feedback so we can continue improving Elasticsearch Marvel. Please send questions, praise or pains to the . \n"}<br>{"index": {"_id": 1368}}<br>{"title":"Using Kibana for Business Intelligence","seo_title":"","url":"\/blog\/found-using-kibana-for-twitter-intelligence","author":{"name":"Morten Ingebrigtsen"},"date":"March 13, 2014","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. In this article we will set up a simple and easy to follow example on how to use Elasticsearch and Kibana for basic business intelligence. In our demo we will be using real world Twitter data which we'll feed into Elasticsearch and then inspect and analyze it by using the Kibana dashboard. \n"}<br>{"index": {"_id": 1369}}<br>{"title":"This Week in Elasticsearch - March 12, 2014","seo_title":"","url":"\/blog\/2014-03-12-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"March 12, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, and news about Logstash and Kibana. Slides & Videos Where to find Us We'd love to feature all the great Elasticsearch, Logstash and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Community Manager, , know! Australia and will head Down Under to teach training courses in Melbourne and Sydney. On March 13th you can join us for the , or come by the on March 17th. Austria will speak at the tonight, March 12th. Doors open at 7 PM. Canada France Germany Italy will present Make sense of your (BIG) data! at the The conference takes place in Torino on April 3rd, and David will speak at 10:30 AM. Japan The has been scheduled by Jun Ohtani. Please plan to join the meeting at 7 PM on April 21st. New Zealand The will talk all things Elasticsearch on Tuesday, March 25th. Doors open at 6 PM. Norway The has been scheduled for April 3rd at 6 PM. Details on the presentations are forthcoming, but you can register to attend now. South Africa will take the stage at ScaleConf to talk . The conference runs April 10th and 11th in Cape Town. United Kingdom will share What's New in Elasticsearch 1.0 with the on March 21st. Doors open at 6:15 PM. United States Where to Find You Our Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1370}}<br>{"title":"Tribe Node","seo_title":"","url":"\/blog\/tribe-node","author":{"name":"Shay Banon"},"date":"March 06, 2014","category":"Engineering","locales":"","content":" At Elasticsearch, we like to think different about data and how to manage it. We know that companies can innovate only if they truly understand all aspects of their business through their data. We see Elasticsearch being used for many different use cases within individual organizations: logging critical visitor data in one division, analyzing financial transactions in another, and driving insights from social data in yet another division. Often, these departments are spread out across the globe. What if, instead of each division having their own data silo, we could produce one coherent view of data from across the entire organization? What new insights could be gained if we were able to connect all of this data? To answer this question, we created the Tribe node. The Tribe node connects to multiple Elasticsearch clusters and allows you to view them as if they were one big cluster. You may remember that this functionality was partially the promise of Federated Search. What makes the Tribe node unique is that it doesn\u2019t impose any restrictions on cross-cluster search or, for that matter, on any other core APIs. Technically, the Tribe node is quite simple: it connects to multiple clusters and registers to receive their cluster events. Any time a cluster event occurs, the Tribe node acts on it by merging the different cluster events\/states into a single global cluster state that can be used by all the different APIs. This means that searching on 10 shards in a single cluster, or searching across 10 shards where 6 of them exist on 1 cluster and the other 4 exist on another, is exactly the same operation. The Tribe node supports almost all APIs, with the exception of meta-level APIs such as the Create Index API. Meta-level APIs must be processed by the elected master node, but the Tribe node effectively has no single elected master. Instead, operations like creating an index must be executed on the individual cluster. Another important point to note when using the Tribe node: index names must be unique across all clusters. Because the cluster states from multiple clusters are merged into a single global cluster state, if an index with the same name exists on two clusters then one of the two indices will simply be ignored. Using the Tribe node couldn\u2019t be simpler. Here is a demonstration of how to test it out by running two clusters on your local machine: # first, start a single node LDN cluster bin\/elasticsearch --cluster.name ldn # second, start another single node HK cluster bin\/elasticsearch --cluster.name hk Elasticsearch makes it easy to run multiple instances on the same machine for testing purposes. We have just started two nodes, each belonging to a different cluster: the first LDN cluster uses ports 9300\/9200 and the second HK cluster uses ports 9301\/9201. # now, let's start a Tribe node that connects to both clusters bin\/elasticsearch --tribe.ldn.cluster.name ldn --tribe.hk.cluster.name hk This Tribe node started with ports 9302\/9202. Now, let\u2019s see which nodes are part of the Tribe node cluster state: # see all the nodes that are part of the Tribe node (9202) state curl 'localhost:9202\/_cluster\/state\/nodes?pretty' # response { \"nodes\" : { \"lykJOKu2Shaa0v4jjt9d4g\" : { \"name\" : \"Man-Eater\/hk\", \"transport_address\" : \"inet[\/10.12.1.196:9303]\", \"attributes\" : { \"tribe.name\" : \"hk\", \"client\" : \"true\", \"data\" : \"false\" } }, \"fuFL42E1S_GSe_miEQKOvg\" : { \"name\" : \"Man-Eater\/ldn\", \"transport_address\" : \"inet[\/10.12.1.196:9304]\", \"attributes\" : { \"tribe.name\" : \"ldn\", \"client\" : \"true\", \"data\" : \"false\" } }, \"I8iGiHehQES9G-ZWbw2roQ\" : { \"name\" : \"Stygyro\", \"transport_address\" : \"inet[\/10.12.1.196:9300]\", \"attributes\" : { \"tribe.name\" : \"ldn\" } }, \"4rVSDX2vQNe4b6WGMqhH7A\" : { \"name\" : \"Sepulchre\", \"transport_address\" : \"inet[\/10.12.1.196:9301]\", \"attributes\" : { \"tribe.name\" : \"hk\" } }, \"s7QC7w2gTpyu_pDM14JitQ\" : { \"name\" : \"Man-Eater\", \"transport_address\" : \"inet[\/10.12.1.196:9302]\", \"attributes\" : { \"client\" : \"true\", \"data\" : \"false\" } } } } Let me explain the above output, as it helps understand how the Tribe node works: Now, let\u2019s see how we can interact with the nodes and the Tribe node. We\u2019ll start by creating 2 indices, one on each cluster. Remember, those indices need to be explicitly created on each cluster. # Create index ldn_index on ldn cluster (9200) directly curl -XPUT localhost:9200\/ldn_index # Create index hk_index on hk cluster (9201) directly curl -XPUT localhost:9201\/hk_index Once created, we can easily index data through the Tribe node (9202) to the respective indices: curl -XPUT localhost:9202\/ldn_index\/data\/1 -d '{ \"desc\" : \"heya from ldn\" }' curl -XPUT localhost:9202\/hk_index\/data\/1 -d '{ \"desc\" : \"heya from hk\" }' the Tribe node automatically redirected each indexing request to the correct cluster. Now, let\u2019s do a simple search that spans all the data across all clusters and all indices: # execute search curl 'localhost:9202\/_search?pretty' # response { \"took\" : 5, \"timed_out\" : false, \"_shards\" : { \"total\" : 10, \"successful\" : 10, \"failed\" : 0 }, \"hits\" : { \"total\" : 2, \"max_score\" : 1.0, \"hits\" : [ { \"_index\" : \"ldn_index\", \"_type\" : \"data\", \"_id\" : \"1\", \"_score\" : 1.0, \"_source\" : { \"desc\" : \"heya from ldn\" } }, { \"_index\" : \"hk_index\", \"_type\" : \"data\", \"_id\" : \"1\", \"_score\" : 1.0, \"_source\" : { \"desc\" : \"heya from hk\" } } ] } } You see how the Tribe node fanned out our search request across both clusters and merged the results from each cluster into a single global result set? Any other core operation (get, suggest, percolator, etc) is also fully supported by the Tribe node. I will end with one note on a feature in Kibana that was added in order to better support the Tribe node. Imagine having two different logging clusters, fed by Logstash. The cluster in Hong Kong creates index names with a pattern, and the cluster in London uses a pattern. Kibana now allows you to specify multiple index patterns when querying, which makes it easy to explore data that exists on either cluster or both of them, using the Tribe node to create a single coherent view. This single view allows you to put your data into context, making it easier to spot patterns that would otherwise be missed. Hopefully, this post gives you a glimpse of how the Tribe node can be used. We look forward to your feedback on the or ! \n"}<br>{"index": {"_id": 1371}}<br>{"title":"This Week in Elasticsearch - March 05, 2014","seo_title":"","url":"\/blog\/2014-03-05-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"March 05, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, and news about Logstash and Kibana. Slides & Videos Where to find Us We'd love to feature all the great Elasticsearch, Logstash and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Community Manager,, know! Australia and will head Down Under to teach training courses in Melbourne and Sydney. On March 13th you can join us for the , or come by the on March 17th. Austria will speak at the on March 12th. Canada Czech Republic will be speaking at the on March 5th. Doors open at 7 PM. France will be speaking on the ELK stack - that's Elasticsearch, Logstash and Kibana - and Elasticsearch Marvel on March 13th in Paris. The talks are free of charge but . Germany Italy will present Make sense of your (BIG) data! at the The conference takes place in Torino on April 3rd, and David will speak at 10:30 AM. Japan The has been scheduled by Jun Ohtani. Please plan to join the meeting at 7 PM on April 21st. The Netherlands and will be attending the this Friday in Rotterdam. Say hello to them in the hallways! South Africa will take the stage at ScaleConf to talk . The conference runs April 10th and 11th in Cape Town. United Kingdom United States Where to Find You Our Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1372}}<br>{"title":"Renaming the Perl client","seo_title":"","url":"\/blog\/renaming-perl-client","author":{"name":"Clinton Gormley"},"date":"March 03, 2014","category":"","locales":"","content":" \n"}<br>{"index": {"_id": 1373}}<br>{"title":"Logstash 1.4.0 beta 2","seo_title":"","url":"\/blog\/logstash-1-4-0-beta-2","author":{"name":"Aaron Mildenstein"},"date":"March 01, 2014","category":"","locales":"","content":" We are pleased to announce the second beta release of Logstash 1.4.0! The following major features are: Other points of note: Since the first beta we've had tremendous support from the community! \u00a0We have had numerous bugs filed and patches submitted. \u00a0We've been really pleased by your enthusiasm and support! Thank you! You can view the full changelog for this beta here:\u00a0 What\u2019s the \u2018beta\u2019 mean? All tests are passing, but we are leaving some time to allow the community to kick the tires and take it for a test drive. Additionally, beta means that some new features may change before general release. Get started and download the new tarball package: \u00a0 \n"}<br>{"index": {"_id": 1374}}<br>{"title":"This Week in Elasticsearch - February 26, 2014","seo_title":"","url":"\/blog\/2014-02-26-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"February 26, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, and news about Logstash and Kibana. Slides & Videos Where to find Us We'd love to feature all the great Elasticsearch, Logstash and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Community Manager,, know! Australia and will head Down Under to teach training courses in Melbourne and Sydney. On the 13th of March you can join us for the meetup, or come by the on March 17th. Austria will speak at the on March 12th. Canada Czech Republic will be speaking at the on March 5th. Doors open at 7 PM. Germany Italy will present Make sense of your (BIG) data! at the The conference takes place in Torino on April 3rd, and David will speak at 10:30 AM. Japan The has been scheduled by Jun Ohtani. Please plan to join the meeting at 7 PM on April 21st. Slovakia will speak at the on February 27th. The conference takes place in Bratislava. South Africa will take the stage at ScaleConf to talk . The conference runs April 10th and 11th in Cape Town. United Kingdom United States Where to Find You Our Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1375}}<br>{"title":"Elasticsearch 1.0.1 and 0.90.12 Released","seo_title":"","url":"\/blog\/elasticsearch-0-90-12-1-0-1-released","author":{"name":"Kevin Kluge"},"date":"February 25, 2014","category":"","locales":"","content":" Today we are happy to announce the release of\u00a0and\u00a0 elasticsearch 1.0.1 Thanks to everyone for the positive feedback on 1.0.0, including the bug reports! \u00a0We have responded to the quick feedback with the 1.0.1 release, which is now the current stable release in the 1.0 series. \u00a0Details of the changes are available in the\u00a0. Some of the notable changes are: We recommend that users of Elasticsearch from all versions upgrade to 1.0.1 and not 1.0.0. \u00a0This path will avoid the issue where reading Lucene memory usage could cause excessive CPU usage. You can\u00a0. elasticsearch 0.90.12 This is the current stable release in the 0.90 series and contains a number of \u00a0bug fixes and small enhancements that you can read about in the\u00a0. Please note that we are decreasing the rate of development of the 0.90.x series of releases so that we can focus our attention on 1.0.x and future releases. \u00a0Some of the notable changes are: We recommend that users of Elasticsearch from the 0.20.x series or earlier upgrade to 0.90.12 and not 0.90.11, or 1.0.1. \u00a0This path will avoid the issue where getting Lucene memory usage could cause excessive CPU usage. You can\u00a0. \u00a0 \n"}<br>{"index": {"_id": 1376}}<br>{"title":"This Week in Elasticsearch - February 19, 2014","seo_title":"","url":"\/blog\/2014-02-19-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"February 19, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Elasticsearch Core Elasticsearch EcosystemHere's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, and news about Logstash and Kibana. Slides & Videos Where to Find UsWe'd love to feature all the great Elasticsearch, Logstash and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Community Manager,, know!Australia Austrian will talk all about Elasticsearch at the on March 12th. Doors open at 7 PM.Canada Czech RepublicKarel Mina\u0159\u00edk will be speaking at the on March 5th. Doors open at 7 PM.Germany ItalyDavid Pilato will present Make sense of your (BIG) data! at the The conference takes place in Torino on April 3rd, and David will speak at 10:30 AM.bedJapanThe has been scheduled by Jun Ohtani. Please plan to join the meeting at 7 PM on April 21st.Slovakia will speak at the on February 27th. The conference takes place in Bratislava.South Africa will take the stage at ScaleConf to talk . The conference runs April 10th and 11th in Cape Town.United Kingdom United States Where to Find YouOur Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, .Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head.TrainingsIf you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1377}}<br>{"title":"Logstash 1.4.0 beta1","seo_title":"","url":"\/blog\/logstash-1-4-0-beta1","author":{"name":"Jordan Sissel"},"date":"February 19, 2014","category":"","locales":"","content":" We are pleased to announce the beta release of Logstash 1.4.0! This release series is primarily focused on improving quality, maturity, and ease of use. The following major features are included in this beta: Other points of note: You can view the full changelog for this beta here: What\u2019s the \u2018beta\u2019 mean? All tests are passing, but we are still waiting for at least one new feature to land. Additionally, beta means that some new features may change before general release. Get started and download the new tarball package: A tarball? What happened to the jar file? Read on, my inquisitive friend! Jar? Tarball! Past releases have been a single jar file which included all Ruby and Java library dependencies to eliminate deployment pains. The jar file served us well, but over time we found Java\u2019s default heap size, garbage collector, and other settings weren\u2019t well suited to Logstash. In order to provide better Java defaults, we\u2019ve changed to releasing a tarball (.tar.gz) that includes all the same dependencies (yay!). What does this mean to you? Instead of running you run (for Windows users, ) One pleasant side effect of using a tarball is that the Logstash code itself is much more accessible and able to satisfy any curiosity you may have. Contrib plugins package Logstash has grown brilliantly over the past few years with great contributions from the community. Now having 165 plugins, it became hard for us (the Logstash engineering team) to reliably support all the wonderful technologies in each contributed plugin. We combed through all the plugins and picked the ones we felt strongly we could support, and those now ship by default with Logstash. All the other plugins are now available in a package. All plugins continue to be and free, of course! Installing plugins from the package is very easy and documented on the package site. A bonus effect of this decision is that the default Logstash download size shrank by 19MB compared to the previous release because we were able to shed some lesser-used dependencies. You can learn more about the plugin package here: New release cycle This beta release is the first step in our new release process. Going forward, Logstash release cycles will more closely mirror Elasticsearch\u2019s model of releases. Each new major release will start as a beta, continuing to a release candidate once all features are complete, and finally, becoming a general release once we feel it is production-ready. Maintenance of major versions will include bug fixes only. New features will wait until the next major release (for example, until 1.5.0). A more formal release cycle lets us more effectively set expectations about changes going into Logstash and is intended to help make you happier when it comes to upgrades and bug fixes! Better documentation We\u2019ve got a brand new that aims to more effectively educate new users about how to use Logstash. Beyond that, we took a look at the most popular plugins and put lots of effort into improving them. Try out the new beta and what you think! \n"}<br>{"index": {"_id": 1378}}<br>{"title":"Restricting Users for Kibana with Filtered Aliases","seo_title":"","url":"\/blog\/restricting-users-kibana-filtered-aliases","author":{"name":"Chris Earle"},"date":"February 18, 2014","category":"Engineering","locales":"","content":" location ~ ^\/((,?)${remote_user}-d+.d+.d+)+\/_search$ { proxy_pass http:\/\/127.0.0.1:9200: proxy_read_timeout 90: } One question we often get with Kibana is, \u201cHow do you restrict the data for different users?\u201d Our go to answer has always been to proxy the requests through Nginx and use filtered aliases to segment the data. The typical response to this is, \u201cUh\u2026 Okay I will look into it.\u201d This blog post will take that advice one step further and give you a working example of exactly what\u2019s needed to accomplish this task. For our example, we are going to use web server logs that segment the users based on the host name. The incoming log will look something like this: { \"@timestamp\": \"2014-02-04T11:46:16.164Z\", \"ip\": \"106.115.144.245\", \"extension\": \"css\", \"response\": \"200\", \"country\": \"IN\", \"tags\": [ \"warning\", \"info\"], \"referrer\": \"http:\/\/twitter.com\/success\/pyotr-kolodin\", \"agent\": \"Mozilla\/5.0 (X11: Linux x86_64: rv:6.0a1) Gecko\/20110421 Firefox\/6.0a1\", \"clientip\": \"106.115.144.245\", \"bytes\": 6091.388051980175, \"request\": \"\/terry-hart.css\", \"host\": \"astronauts.com\", \"responseTime\": 303, \"message\": \"106.115.144.245 - - [2014-02-04T11:46:16.164Z] \\\"GET \/terry-hart.css HTTP\/1.1\\\" 200 6091.388051980175 \\\"-\\\" \\\"Mozilla\/5.0 (X11: Linux x86_64: rv:6.0a1) Gecko\/20110421 Firefox\/6.0a1\\\"\" } Assuming the log data is coming in via Logstash, we can setup the following translate filter to add a user field based on the host: filter { translate { field => \"host\" destination => \"user\" dictionary => [ \"astronauts.com\", \"buzz\", \"nasa.org\", \"gus\", \"space.com\", \"shakey\", \"rocketmen.org\", \"hotdog\" ] } } With the user field added to the data, we can now setup our first filtered alias for a user using the Sense interface in : POST _aliases { \"actions\": [ { \"add\": { \"index\": \"logstash-2014.02.03\", \"alias\": \"buzz-2014.02.03\", \"filter\": { \"term\": { \"user\": \"buzz\" } } } } ] } Any request that goes to will now include a term filter on the field for . The one gotcha for this system is that an alias will need to be setup for every user for each daily Logstash index. Elasticsearch currently does not have a feature for setting up dynamic aliases upon index creation, but the good news is that . For now, we will need to use a nightly cron to setup our user aliases. require 'elasticsearch' require 'hashie' # Connect to the ElasticSearch cluster client = Elasticsearch::Client.new # Get all the users and map them to an array resp = Hashie::Mash.new client.search index: \"logstash-*\", body: { size: 0, facets: { users: { terms: { field: 'user' } } } } users = resp.facets.users.terms.to_a.map { |f| f.term } # Get a list of all the indexes and aliases aliases = Hashie::Mash.new client.indices.get_aliases aliases.each_pair do |index,aliases| # Match the all the Logstash indexes and get the Logstash # date stamp from the index name. matches = \/logstash-(d{4}.d{2}.d{2})\/.match index if matches # Loop through each user and check to see if the index exists # if it doesn't then create the new alias and add a term filter. users.each do |user| aliasName = \"#{user}-#{matches[1]}\" unless aliases.aliases[aliasName] puts \"Creating alias #{aliasName} for #{index}\" client.indices.put_alias index: index, name: aliasName, body: { filter: { term: { user: user } } } end end end end The next piece of the puzzle is setting up Nginx to serve the Kibana interface with basic auth and to proxy the requests to the user\u2019s aliases. There is a in the Kibana Github repo that we will use as a starting point. We need to add basic auth to the top of configuration along with modifying some of the rewrite rules to use the filtered aliases and user specific indexes. You can view the . The trickiest part to setup is translating the requests to the user\u2019s aliases. Kibana will often send requests like , which will need to be translated to . Nginx doesn\u2019t have a simple find and replace feature, so we need to dust off our hacker skills and setup a recursive rewrite rule to make the translation for us. # Recursively change Logstash prefixed index names to user prefixed aliases. # This will process until the logstash-YYYY.MM.DD pattern disappears location ~ ^\/([^*]*)logstash-(?<date>d+.d+.d+)(,?[^*\/]+)*\/_search$ { set $part1 $1: set $part3 $3: rewrite ^.*$ \/${part1}${remote_user}-${date}${part3}\/_search last: } # All request to kibana-int also need to be proxied to an unique index per user. location ~ ^\/kibana-int\/(.*)$ { set $part1 $1: proxy_pass http:\/\/127.0.0.1:9200\/kibana-int-${remote_user}\/${part1}: proxy_read_timeout 90: } location ~ ^\/[^*\/]+\/_search$ { proxy_pass http:\/\/127.0.0.1:9200: proxy_read_timeout 90: } There we have it, Kibana locked down using basic authentication and the data segmented by the authenticated user. Before you go to production with this setup, we highly recommend serving the Kibana interface behind a SSL (or a SSL proxy) and . If you want to use the code from this example, you can find it in the on GitHub under . \n"}<br>{"index": {"_id": 1379}}<br>{"title":"All About Analyzers, Part Two","seo_title":"","url":"\/blog\/found-text-analysis-part-2","author":{"name":"Andrew Cholakian"},"date":"February 18, 2014","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. This is a follow up article where we'll continue to survey various analyzers, each of which showcases a very different approach to parsing text. This is the second of two articles about analyzers. If you haven't yet read the first article on this topic, , it is strongly recommended that you read that first. In this article we'll be diving a little deeper into the catalog of Elasticsearch analyzers. The intention of these articles is to take users on a guided tour of some of the most useful analyzers. There's no need to remember everything here, but if you know all these tools are available you'll be able to create much better queries using Elasticsearch. \n"}<br>{"index": {"_id": 1380}}<br>{"title":"1.0.0 Released","seo_title":"","url":"\/blog\/1-0-0-released","author":{"name":"Clinton Gormley"},"date":"February 12, 2014","category":"","locales":"","content":" Today we are proud to announce the release of GA, based on Lucene 4.6.1. This release is the culmination of 9 months of work with almost 8,000 commits by 183 contributors! A big thank you to everybody who has made this release possible. You can . The main features available in 1.0 are: Migrating to 1.0.0 We took advantage of a major version bump to remove cruft and to fix a number of inconsistencies. Our goal is that the user interface should be intuitive\u2009\u2014\u2009you shouldn\u2019t even need to consult the docs for common requests because the API should be obvious. The good news is that a number of APIs are much simpler. Unfortunately, this means that there were a few backwards incompatible changes. We have put together a guide to help you migrate to v1.0.0: . Please read this carefully, backup your data and test your application thoroughly before upgrading. You will need to do a when upgrading, but we hope to make these a thing of the past in the 1.x branch\u2009\u2014\u2009a number of features have been added to facilitate rolling upgrades going forward. The list all of the changes since v1.0.0.RC2, but you should also check the release notes for: If you are using the official Elasticsearch clients, please see the appropriate docs for instructions about how to use them with v1.0.0: Please and ! \n"}<br>{"index": {"_id": 1381}}<br>{"title":"This Week in Elasticsearch - February 12, 2014","seo_title":"","url":"\/blog\/2014-02-12-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"February 12, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Photo Credit: Igor Motov Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, and news about Logstash and Kibana. Slides & Videos Where to find Us We'd love to feature all the great Elasticsearch, Logstash and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Community Manager,, know! Australia and will headed Down Under to teach training courses in Melbourne and Sydney, and we're working to schedule meetups during their visit. We hope to have full details by next week's edition of , but for now you can save the date. We're targeting March 13th for the Melbourne Meetup and March 24th for Sydney. Canada France David will speak on at Microsoft Tech Days in Paris. David's presentation is scheduled for February 13th at 4:30 PM. Slovakia will speak at the on February 27th. The conference takes place in Bratislava. United Kingdom United States Where to Find You Our Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1382}}<br>{"title":"Troubleshooting Elasticsearch searches, for Beginners","seo_title":"","url":"\/blog\/found-beginner-troubleshooting","author":{"name":"Alex Brasetvik"},"date":"February 11, 2014","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. We'll look at common problems when getting started with Elasticsearch. \n"}<br>{"index": {"_id": 1383}}<br>{"title":"Data visualization with Elasticsearch aggregations and D3","seo_title":"","url":"\/blog\/data-visualization-elasticsearch-aggregations","author":{"name":"Shelby Sturgis"},"date":"February 10, 2014","category":"Engineering","locales":"ko-kr","content":" For those of you familiar with , you know that its an amazing modern, scalable, full-text search engine with and the at its core. Elasticsearch allows users to query their data and provides efficient and blazingly fast look up of documents that make it perfect for creating real-time analytics dashboards. Currently, Elasticsearch includes , a functionality that allows users to compute aggregations of their data. For example, a user with twitter data could create buckets for the number of tweets per year, quarter, month, day, week, hour, or minute using the , making it quite simple to create histograms. Faceted search is a powerful tool for data visualization. is a great example of a front-end interface that makes good use of facets. However, there are some major restrictions to faceting. Facets do not retain information about which documents fall into which buckets, making complex querying difficult. Which is why, Elasticsearch is pleased to introduce the framework with the 1.0 release. Aggregations rips apart its faceting restraints and provides developers the potential to do much more with visualizations. Aggregations (=Awesomeness!) Aggregations is \"faceting reborn\". Aggregations incorporate all of the faceting functionality while also providing much more powerful capabilities. Aggregations is a generic but extremely powerful framework for building any type of aggregation. There are several different types of aggregations, but they fall into two main categories: bucketing and metric. Bucketing aggregations produce a list of buckets, each one with a set of documents that belong to it (e.g., , , , , , ). Metric aggregations keep track and compute metrics over a set of documents (e.g., , , , , , ). Using Aggregations for Data Visualization (with D3) Lets dive right in and see the power that aggregations give us for data visualization. We will create a donut chart and a dendrogram using the Elasticsearch aggregations framework, the , and . If you are new to Elasticsearch, it is very easy to get started. Visit the Elasticsearch page to learn how to download, install, and run Elasticsearch version 1.0. Requirements: * a link to the index.html and main javascript file can be found . Alternatively, you can clone the on github. Uploading Data to our Elasticsearch Index We will need to create an index and add some data. Since the (American) football season just ended, let's send it off by exploring some NFL data. For this tutorial, we will only be concerned with . Download the dataset (nfl_2013.json) and its mappings (nfl_mapping.json) using the link above. Fire up Elasticsearch from your localhost. Now, let's add an index and some data. From the terminal: curl -XPOST localhost:9200\/nfl?pretty curl -XPUT localhost:9200\/nfl\/2013\/_mapping?pretty -d @nfl_mapping.json curl -XPOST localhost:9200\/nfl\/2013\/_bulk?pretty --data-binary @nfl_2013.json The NFL data file consists of play-by-play data with 18 fields. { def: \"HOU\", \/\/ defensive team defscore: \"13\", \/\/ score for defensive team description: \"(11:34) S.Ridley right guard for 8 yards TOUCHDOWN.\", \/\/ play description down: \"2\", \/\/ down for current play (up to 4) gameid: \"20130113_HOU@NE\", \/\/ game id with date and teams min: \"26\", \/\/ minutes remaining in game nextscore: \"7\", \/\/ ??? off: \"NE\", \/\/ offensive team offscore: \"17\", \/\/ score for offensive team qtr: \"3\", \/\/ quarter scorechange: \"0\", \/\/ amount offensive score changed scorediff: \"4\", \/\/ difference in score season: \"2012\", \/\/ nfl season (year) sec: \"34\", \/\/ seconds remaining within minute of play series1stdn: \"1\", \/\/ ??? teamwin: \"1\", \/\/ either 1 or 0, demarks the team winning togo: \"6\", \/\/ number of yards to go to reach a first down ydline: \"8\" \/\/ yard line ball is on to start play } Setting up our HTML and Javascript Files Lets begin by creating a directory for our project. Lets call it nfl. Now add index.html and a scripts subdirectory. Within scripts, place our downloaded elasticsearch.js, d3.js, and require.js files. We will also create our main.js file within scripts. Let's add some markup to index.html. <!DOCTYPE html> <html> <head> <title>Elastic Aggregations<\/title> <script src=\"scripts\/require.js\"><\/script> <script>require([\"scripts\/main\"], function () {})<\/script> <style><\/style> <\/head> <body> <div id=\"donut-chart\"><\/div> <\/body> <\/html> Now, let's add some javascript to main.js. define(['scripts\/d3.v3', 'scripts\/elasticsearch'], function (d3, elasticsearch) { \"use strict\": var client = new elasticsearch.Client(): }): Donut Chart with Terms Aggregation Let's start by making a donut chart of the number of touchdowns scored in each quarter. We will use the to accomplish this. The same thing can be done using the , but this will demonstrate how aggregations can accomplish the same things as facets. Since there are typically only 4 quarters in an NFL game, we should end up with a donut chart with 4 slices. To ensure that we only return 4 quarters we will filter out overtime quarters. We will also need to filter for touchdowns. So lets create our query using the Elasticsearch javascript client and add it to main.js. define(['scripts\/d3.v3', 'scripts\/elasticsearch'], function (d3, elasticsearch) { \"use strict\": var client = new elasticsearch.Client(): client.search({ index: 'nfl', size: 5, body: { \/\/ Begin query. query: { \/\/ Boolean query for matching and excluding items. bool: { must: { match: { \"description\": \"TOUCHDOWN\" }}, must_not: { match: { \"qtr\": 5 }} } }, \/\/ Aggregate on the results aggs: { touchdowns: { terms: { field: \"qtr\", \/\/ order by quarter, ascending order: { \"_term\" : \"asc\" } } } } \/\/ End query. } }).then(function (resp) { console.log(resp): \/\/ D3 code goes here. }): }): If we fire up a webserver, open up our browser, and navigate to the console under developer tools, you should see the output. Voila, data! Now, let's create a donut chart. Add your donut chart d3 code to main.js. ... }).then(function (resp) { console.log(resp): \/\/ D3 code goes here. var touchdowns = resp.aggregations.touchdowns.buckets: \/\/ d3 donut chart var width = 600, height = 300, radius = Math.min(width, height) \/ 2: var color = ['#ff7f0e', '#d62728', '#2ca02c', '#1f77b4']: var arc = d3.svg.arc() .outerRadius(radius - 60) .innerRadius(120): var pie = d3.layout.pie() .sort(null) .value(function (d) { return d.doc_count: }): var svg = d3.select(\"#donut-chart\").append(\"svg\") .attr(\"width\", width) .attr(\"height\", height) .append(\"g\") .attr(\"transform\", \"translate(\" + width\/1.4 + \",\" + height\/2 + \")\"): var g = svg.selectAll(\".arc\") .data(pie(touchdowns)) .enter() .append(\"g\") .attr(\"class\", \"arc\"): g.append(\"path\") .attr(\"d\", arc) .style(\"fill\", function (d, i) { return color[i]: }): g.append(\"text\") .attr(\"transform\", function (d) { return \"translate(\" + arc.centroid(d) + \")\": }) .attr(\"dy\", \".35em\") .style(\"text-anchor\", \"middle\") .style(\"fill\", \"white\") .text(function (d) { return d.data.key: }): }): }): Let's add some styling to index.html. <style> body { font: 14px sans-serif: } .arc path { stroke: #fff: stroke-width: 3px: } <\/style> Refresh your page in the browser, and you should see a nice donut chart. Of course, you can create the same donut chart using a terms facet, no surprises here. So, let's try something a bit more complex. Dendrogram with Nested Terms Aggregations Let's say we want to know for the 2013 season (through the 12th week), for each team, the name of the player(s) who scored touchdowns and the total number of touchdowns they scored in each quarter. For example, for the Denver Broncos (an NFL team), Peyton Manning (a player) was responsible for 36 touchdowns with: Let's write this query. We will need to filter out incomplete passes, interceptions, fumbles, and over-turned plays to get a more accurate number. define(['scripts\/d3.v3', 'scripts\/elasticsearch'], function (d3, elasticsearch) { \"use strict\": var client = new elasticsearch.Client(): client.search({ index: 'nfl', size: 5, body: { query: { bool: { must: { match: { \"description\": \"TOUCHDOWN\"}}, must_not: [ { match: { \"description\": \"intercepted\"}}, { match: { \"description\": \"incomplete\"}}, { match: { \"description\": \"FUMBLES\"}}, { match: { \"description\": \"NULLIFIED\"}} ] } }, aggs: { teams: { terms: { field: \"off\", exclude: \"\", \/\/ exclude empty strings. size: 5 \/\/ limit to top 5 teams (out of 32). }, aggs: { players: { terms: { field: \"description\", include: \"([a-z]?[.][a-z]+)\", \/\/ regex to pull out player names. size: 20 \/\/ limit to top 20 players per team. }, aggs: { qtrs: { terms: { field: \"qtr\" } } } } } } } } }).then(function (resp) { console.log(resp): \/\/ D3 code goes here. }): }): You can check the results in the console. * Note that the team nodes have a touchdown count that is less than the sum of its leaf nodes. This is because touchdowns that resulted from passes are counted twice, once for the player catching the pass and once for the\u00a0 \u00a0(e.g. Peyton Manning) throwing the pass. Let's create our dendrogram. We will modify index.html. ... <body> <div id=\"donut-chart\"><\/div> <div id=\"dendrogram\"><\/div> <\/body> ... Add your d3 code to main.js. ... }).then(function (resp) { console.log(resp): \/\/ D3 code goes here. var root = createChildNodes(resp): \/\/ d3 dendrogram var width = 600, height = 2000: var color = ['#ff7f0e', '#d62728', '#2ca02c', '#1f77b4']: var cluster = d3.layout.cluster() .size([height, width - 200]): var diagonal = d3.svg.diagonal() .projection(function(d) { return [d.y, d.x]: }): var svg = d3.select(\"#dendrogram\").append(\"svg\") .attr(\"width\", width) .attr(\"height\", height) .append(\"g\") .attr(\"transform\", \"translate(120,0)\"): var nodes = cluster.nodes(root), links = cluster.links(nodes): var link = svg.selectAll(\".link\") .data(links) .enter().append(\"path\") .attr(\"class\", \"link\") .attr(\"d\", diagonal): var node = svg.selectAll(\".node\") .data(nodes) .enter().append(\"g\") .attr(\"class\", \"node\") .attr(\"transform\", function(d) { return \"translate(\" + d.y + \",\" + d.x + \")\": }): node.append(\"circle\") .attr(\"r\", 4.5) .style(\"fill\", function (d) { return d.children ? \"#ffffff\" : color[d.key - 1]: }) .style(\"stroke\", function (d) { return d.children ? \"#4682B4\" : color[d.key - 1]: }): node.append(\"text\") .attr(\"dx\", function(d) { return d.children ? -8 : 8: }) .attr(\"dy\", 3) .style(\"text-anchor\", function(d) { return d.children ? \"end\" : \"start\": }) .text(function(d) { return d.children? d.key : d.key + \": \" + d.doc_count: }): d3.select(self.frameElement).style(\"height\", height + \"px\"): function createChildNodes(dataObj) { var root = {}: root.key = \"NFL\": root.children = dataObj.aggregations.teams.buckets: root.children.forEach(function (d) { d.children = d.players.buckets: }): root.children.forEach(function (d) { d.children.forEach(function (d) { d.children = d.qtrs.buckets: }): }): return root: } }): ... And finally, let's add the styling. <style> ... .node circle { fill: #fff: stroke: steelblue: stroke-width: 1.5px: } .node { font: 10px sans-serif: } .link { fill: none: stroke: #ccc: stroke-width: 1.5px: } <\/style> Refresh your browser and voila, dendrogram goodness! As you can see, aggregations are a powerful tool for creating visualizations. Of course, you can create much more rich and interactive visualizations than what we have created here, but hopefully this will get you started. Happy searching! \n"}<br>{"index": {"_id": 1384}}<br>{"title":"The Ladders and Elasticsearch Marvel","seo_title":"","url":"\/blog\/ladders-elasticsearch-marvel","author":{"name":"Livia Froelicher"},"date":"February 07, 2014","category":"User Stories","locales":"","content":" We've been seeing tremendous growth in attendance at Elasticsearch meetups, and I'm personally quite excited to see new groups springing up worldwide. Today, we're excited to share more from Monday's at . In this video, Peter Pathirana, Lead Engineer, Recommendations Infrastructure, Platform Team and co-author of , treats us to an in-depth view of how The Ladders uses Elasticsearch to power their job-matching service for career-driven professionals. Following the talk, Shay Banon, our CTO and creator of Elasticsearch, answers extensive audience Q&A on all things Elasticsearch, including our brand new management & monitoring product, . The whole meetup proceedings are chock full of juicy architectural bits and the Q&A quite wide ranging, but here are some of the highlights: #MonitoringLove Use Case High Points \u00a0 Thanks again to Peter and the whole team at The Ladders for hosting us and sharing their story! As always, if you're giving a talk on Elasticsearch, Elasticsearch Marvel, Logstash or Kibana, I would love to . We're proud and excited to support user group activities and I'm available to help you get the word out about your talk and help you get the pizza to go with it. Happy viewing! \n"}<br>{"index": {"_id": 1385}}<br>{"title":"Elasticsearch for Apache Hadoop 1.3 M2 released","seo_title":"","url":"\/blog\/elasticsearch-hadoop-1-3-m2","author":{"name":"Costin Leau"},"date":"February 06, 2014","category":"Engineering","locales":"","content":" I am happy to announce that the second milestone of 1.3 (also known as es-hadoop) has been released. M2 brings several new major features to the table, including: Support for Elasticsearch 1.0 (RC1+) es-hadoop supports Elasticsearch 1.0 RC1 or higher while preserving compatibility with the Elasticsearch 0.90.x line. The code base automatically detects the target Elasticsearch version and uses the appropriate . id awareness es-hadoop 1.3 M1 enabled new indexes to be created in Elasticsearch directly from Hadoop jobs. M2 takes this feature several steps forward, enabling both index creation and updating. Furthermore, one can specify all the meta-data options if needed: document , , and . Field aliasing Higher level abstractions on Map\/Reduce, like Cascading, Apache Hive and Apache Pig provide mapping and data types on top of raw data for easier manipulation. With es-hadoop, one can also define field aliasing, decoupling the Hadoop libraries structural declaration from the underlying document fields for cleaner syntax and improved readability. Field extraction Performance is a top priority for es-hadoop. As such, M2 only loads the data that it must from Elasticsearch: rather than loading the entire document, es-hadoop retrieves just the required fields, also known as . This implementation of projection results in less network, CPU and memory usage. JSON support Besides supporting the Map\/Reduce, Cascading, Hive and Pig data types, M2 also allows JSON data to be indexed. Don\u2019t forget that es-hadoop can now extract the document metadata (such as ) if instructed to do so. Parallel writes and ingest mitigation Users with high ingestion volumes will be happy to hear that M2 provides significant updates on the write front. Now, all writes to Elasticsearch are parallelized on the target shards: this implementation prevents network bottlenecks as the load is spread across multiple nodes. In case of excessive loads on Elasticsearch, regardless of the reason, 1.3 M2 automatically retrieves the rejected payload before ingesting further data. This temporary throttling prevents data spillage. Improved I\/O In a similar vein, es-hadoop 1.3 M2 provides automatic cluster discovery and, in case of network errors, automatic fall back to the rest of the available nodes. Snapshot\/Restore for HDFS Last but not least, 1.3 M2 introduces support for through a separate, umbrella project (). Once installed in the Elasticsearch cluster, this standalone plugin enables any storage (from the omnipresent HDFS to pluggable implementations such as or ) to be used for backing up and restoring data within running Elasticsearch clusters. Of course, this release also includes the usual bug fixes, compatibility improvements and refinements. As always, we welcome feedback so and what you think. P.S. If you are migrating from M1, you might want to read up on the . \n"}<br>{"index": {"_id": 1386}}<br>{"title":"This Week in Elasticsearch - February 05, 2014","seo_title":"","url":"\/blog\/2014-02-05-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"February 05, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the , as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, and news about Logstash and Kibana. Slides & Videos Where to find Us We'd love to feature all the great Elasticsearch, Logstash and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Community Manager,, know! Czech Republic Honza Kral will give two presentations at : and . Honza's presentations take place on Friday, February 7th, and the conference runs from the 7th through the 9th. France Germany Japan Thanks to Jun Ohtani, the 3rd Elasticsearch Meetup will be held in Tokyo on February 7th starting at 7 PM. Please remember to . Sweden The has just been scheduled for February 5th. will cover Elasticsearch and Chef, and will discuss What's New in 1.0 with Aggregations. United Kingdom United States Where to Find You Our Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1387}}<br>{"title":"0.90.11 and 1.0.0.RC2 released","seo_title":"","url":"\/blog\/0-90-11-1-0-0-rc2-released","author":{"name":"Clinton Gormley"},"date":"February 03, 2014","category":"","locales":"","content":" Today we are happy to announce the release of and , both of which are based on Lucene 4.6.1. Elasticsearch 0.90.11 This is the current stable release in the 0.90 series and contains a number of small bug fixes and enhancements which you can read about in the . Some of the notable changes are: We recommend that users of older versions upgrade to 0.90.11, but users of 0.90.10 don't need to upgrade unless they are being affected by one of the issues listed in the release notes. You can . Elasticsearch 1.0.0.RC2 This is the final release candidate in the 1.0 branch and contains a number of small bug fixes, consistency improvements and a few enhancements, including the ones listed above. You can see the details in the . We don't intend to make any more changes other than bug fixes to the 1.0 branch before the final release of 1.0. Please download this release candidate and be mean to it! If anything breaks, before 1.0. You can . \n"}<br>{"index": {"_id": 1388}}<br>{"title":"Azure Cloud Plugin for Elasticsearch","seo_title":"","url":"\/blog\/azure-cloud-plugin-for-elasticsearch","author":{"name":"David Pilato"},"date":"January 31, 2014","category":"Engineering","locales":"","content":" In cloud environments like Azure, multicast is often (always?) forbidden. So you need to provide a list of nodes to help Elasticsearch to discover the nodes of the cluster. Starting new instances could be then tricky as you have to maintain a minimal list of nodes. And what happens when a virtual machine goes down? When it comes back up, it could have a new IP address. So you need to edit unicast settings for each node, right? We are pleased to announce the first release of . This first release uses the Azure API for the unicast discovery mechanism and simplifies your cluster growth management a lot. Azure Virtual Machine DiscoveryAzure plugin uses to perform automatic discovery, which is similar to multicast discovery in multicast-friendly environments. You just have to: And\u2026 You're done! Want More Details?Suppose that you want to build an Ubuntu 13 virtual machine running Elasticsearch. Let's say that you already have an with your already defined and uploaded to Azure, that you have installed , that you have a ready to use. # You first need to generate a java keystore (azurekeystore.pkcs12) # from your existing ssh key (azure-private.key) and certificate (azure-certificate.pem) openssl x509 -outform der -in azure-certificate.pem -out azure-certificate.cer openssl pkcs8 -topk8 -nocrypt -in azure-private.key -inform PEM -out azure-pk.pem -outform PEM openssl x509 -inform der -in azure-certificate.cer -out azure-cert.pem cat azure-cert.pem azure-pk.pem > azure.pem.txt openssl pkcs12 -export -in azure.pem.txt -out azurekeystore.pkcs12 -name azure -noiter -nomaciter # Deploy an Ubuntu image on an extra small instance in West Europe: azure vm create azure-elasticsearch-cluster \\ b39f27a8b8c64d52b05eac6a62ebad85__Ubuntu-13_10-amd64-server-20130808-alpha3-en-us-30GB \\ --vm-name myesnode1 \\ --location \"West Europe\" \\ --vm-size extrasmall \\ --ssh 22 \\ --ssh-cert \/tmp\/azure-certificate.pem \\ elasticsearch password1234!! # \"elasticsearch\/password1234!!\" are the SSH login\/password for this instance. # Connect to your instance when started # SSH settings for convenience HOST=myescluster.cloudapp.net SSH_OPTIONS=\"-o User=elasticsearch -o IdentityFile=\/tmp\/azure-private.key -o StrictHostKeyChecking=no -o UserKnownHostsFile=\/dev\/null\" # Copy your keystore to the VM scp $SSH_OPTIONS \/tmp\/azurekeystore.pkcs12 $HOST:\/home\/elasticsearch # Connect to the VM ssh $SSH_OPTIONS $HOST Install either the latest OpenJDK using or and then install Elasticsearch and its Azure cloud plugin: curl -s https:\/\/download.elasticsearch.org\/elasticsearch\/elasticsearch\/elasticsearch-0.90.10.deb \\ -o elasticsearch-0.90.10.deb sudo dpkg -i elasticsearch-0.90.10.deb sudo \/usr\/share\/elasticsearch\/bin\/plugin -install \\ elasticsearch\/elasticsearch-cloud-azure\/1.0.0.alpha1 Edit and add: cloud.azure.management: subscription.id: your_azure_subscription_id cloud.service.name: your_azure_cloud_service_name keystore: path: \/home\/elasticsearch\/azurekeystore.pkcs12 password: your_password_for_keystore discovery: type: azure Restart Elasticsearch and you're done! Now this instance uses the Azure API to get a list of available nodes. sudo service elasticsearch restart Scaling Out!Hey! But we have started only one node! It's not really a cluster, right? Let's scale out and bring more nodes to the party! # From your local machine, shutdown azure node and create an image: azure vm shutdown myesnode1 azure vm capture myesnode1 esnode-image --delete # Start 10 instances: for x in $(seq 1 10) do echo \"Launching azure instance #$x...\" azure vm create azure-elasticsearch-cluster \\ esnode-image \\ --vm-name myesnode$x \\ --vm-size extrasmall \\ --ssh $((21 + $x)) \\ --ssh-cert \/tmp\/azure-certificate.pem \\ --connect \\ elasticsearch password1234!! done You should now have a cluster running with 10 nodes! What's Next?First, we love to hear feedback from our community! Feel free to ask questions on the and raise issues or ask for feature requests on . Pull requests are warmly welcomed too! We plan to add a blog post on how to use it with Microsoft Windows virtual machines. Also, Elasticsearch 1.0 comes with the great feature. This basically means that we will provide new capabilities to use for snapshots. Stay tuned! \n"}<br>{"index": {"_id": 1389}}<br>{"title":"This Week in Elasticsearch - January 29, 2014","seo_title":"","url":"\/blog\/2014-01-29-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"January 29, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to\u00a0. In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the GitHub repositories, as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, and news about Logstash and Kibana. Slides & Videos Where to find Us We'd love to feature all the great Elasticsearch, Logstash and Kibana presentations and meetups happening worldwide in this section. If you're speaking or hosting a meetup, let our Community Manager,, know! Belgium Czech Republic Honza Kral will give two presentations at : and . Honza's presentations take place on Friday, February 7th, and the conference runs from the 7th through the 9th. France Germany Japan Thanks to Jun Ohtani, the 3rd Elasticsearch Meetup will be held in Tokyo on February 7th starting at 7 PM. Please remember to . Sweden The has just been scheduled for February 5th. Further details are forthcoming, but you can look forward to presentations from and . United Kingdom United States Where to Find You Our Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1390}}<br>{"title":"Why We Built Marvel","seo_title":"","url":"\/blog\/building-marvel","author":{"name":"Boaz Leskes"},"date":"January 29, 2014","category":"","locales":"","content":" Yesterday, our latest product, . Judging by the twitter storm alone, people are just as excited about it as we are. Today, I would like to take the opportunity to tell more about how it works and how it came to be. Marvel is the result of all of our experiences helping users and providing support to customers. Most importantly, the product has come from our own needs for its capabilities and insights. What happened at 3 AM this morning? Since Elasticsearch , its adoption has been nothing short of impressive. As the number of users has grown, so have the number of questions and requests for help on the and in IRC (#elasticsearch on ). We also have numerous inquiries that come in from our customers on dedicated support contracts. The questions come, of course, in many flavors. Some would be about how to best use a feature, or help with a certain aspect of the Query DSL. Others would report a problem and ask for help figuring out what has happened, be it about an exception from the logs, garbage collection taking longer than ideal or an indication that memory has run out. Sometimes a quick API call would be enough to find out the cause of the problem and resolve it quickly. Other times, issues are a result of a more complex sequence of events. Take, for example, the following scenario: you are the proud owner of a cluster. You have an application which analyzes time-based data. Following best practices, you have your recent data on powerful SSD-equipped machines. As data gets older, you have a nightly cronjob that uses Elasticsearch's to indicate the data should be moved to cheaper & less capable machines. One morning, just as you walk into the office, you notice that one of the old-data machines is stressing out and run out of capacity. But why? And why now? There is no spike in search traffic, and indexing goes to the more powerful nodes. The only change you can think of is that nightly cronjob, but it runs at 3 AM, 6 hours before the node started having problems. As it happens, the cronjob started a chain of events that led to the current situation. In order not to impact performance, Elasticsearch throttles moving data around. Since the job issued the command at 3 AM, more and more data moved. Only a couple of hours later, the node's maximum capacity was reached. Once you've found out this information and spent some time digging into logs and thinking hard, the solution is easy: temporarily move some data back to the SSD machines, provision another cheap node and move the data to it. Upon reflection, you realize you need some way of seeing cluster behavior over time. This functionality would have allowed you to see the increasing usage trend and to easily trace back the problem to its start at 3 AM in the morning. It would also have allowed you to see that the same thing happened yesterday, and the day before, except then it was not a problem - yet. It would also be great if just at the beginning of that trend, you could see an indication that Elasticsearch had started to relocate data \u2026 but we'll get to that later. As you can imagine, such stories are not unique. In fact, things can get even more complex. Repeatedly, we ask customers to send us the logs from all their nodes. We also ask to call the stats API repeatedly while running heavy queries, what management commands were actually issued, when they were issued, etc. Once we get the information, we scan it carefully and try to correlate the different information streams and compare them to how we know Elasticsearch behaves. The process is manual, intensive and time consuming. Especially during those moments where time is not necessarily on your side. Being engineers, we kept thinking about how we could improve and automate this process. We wanted to build something that would make our own lives easier and help all of our users: tools to monitor clusters & to collect and analyze the vast number of statistics Elasticsearch exposes. To accomplish this, we needed a place to store all this data, an analytics engine to analyze it and a tool to visualize the results. As it turns out, we have an intimate knowledge of just the right tools for the job. Based on Elasticsearch and Kibana, we've set out to build a smart solution: Marvel. Cluster, this is Mission Control Marvel is a plugin for Elasticsearch that hooks into the heart of Elasticsearch clusters and immediately starts shipping statistics and change events. By default, these events are stored in the very same Elasticsearch cluster. However, you can send them to any other Elasticsearch cluster of your choice. Once data is extracted and stored, the second aspect of Marvel kicks in - a set of dedicated dashboards built specifically to give both a clear overview of cluster status and to supply the tools needed to deep dive into the darkest corners of Elasticsearch. Overview, Nodes & Indices The is the one offered by default when navigating to with your favorite browser. The dashboard displays the essentials metrics you need to know that your cluster is healthy. The dashboard also provides an overview of your nodes and indices, displayed in two clean tables along with the relevant key metrics. These tables serve as an entry point to more details on the Node Statistics and Index Statistics dashboards, where you can see more than 90 different metrics plotted over time. Simply click on a table cell or select multiple nodes\/indices to compare and you'll be transferred to the relevant place in the detailed dashboard. The dashboard displays metric charts from the perspective of one or more nodes. Metrics include hardware level metrics (like load and CPU usage), process and JVM metrics (memory usage, GC), and node level Elasticsearch metrics such as field data usage, search requests rate and thread pool rejection. The dashboard is very similar to the Node Statistics dashboard, but it shows you all the metrics from the perspective of one or more indices. The metrics are per index, with data aggregated from all of the nodes in the cluster. For example, the 'store size' chart shows the total size of the index data across the whole cluster. ] Cluster Events The dashboard allows you to see any event of interest in the cluster. Typical events include nodes joining or leaving, master election, index creation, shard (re)allocation and more. Think of the Cluster Pulse Dashboard as your window into the nerve system of Elasticsearch. Easy access to the REST API Marvel also comes with a lightweight developer console, based on the popular Chrome extension Sense. The console is handy when you want to make an extra API call to check something or perhaps tweak a setting. The developer console understands both JSON and the Elasticsearch API, offering suggestions and auto-completes. It\u2019s also quite handy to use to prototype queries, dive into your data or look at the current version of a specific document. Back to 3AM in the morning Let's go back to our example story, but this time with Marvel installed on the cluster. When you were first notified of a problem on a node, you would have gone to the dashboard and confirmed that it\u2019s in trouble. Let's assume the issue was a memory problem. You'd click on the JVM memory metric - which is red at the moment - opening up the dashboard to take a look at the history of the problematic node\u2019s memory. You'd see a clear, slow growth pattern starting around 3 AM. Wondering what had happened there - and probably not remembering your cronjob yet - you'd go to the dashboard and see that Elasticsearch was relocating shards from SSD machines from that time. From there, you'd move to Sense, undo the allocation setting for the relevant index and go provision another node. Ok, cool. So how do I get it? Marvel is a plugin and you install it just as you would any other Elasticsearch plugin. Give it a try: .\/bin\/plugin -i elasticsearch\/marvel\/latest followed by restarting the nodes and opening in your browser. Marvel is licensed free for development use and runs on Elasticsearch versions 0.90.9 and up. For detailed instructions please . Looking ahead We have great plans for Marvel but they also depend on the feedback we get from you. All we can say for now is that as the analytical and visualization powers of Elasticsearch & Kibana grow, the future looks \u2026 Marvelous! Please do let us know what think, either via our , or (#elasticsearch). \n"}<br>{"index": {"_id": 1391}}<br>{"title":"Introducing Elasticsearch Marvel","seo_title":"","url":"\/blog\/introducing-elasticsearch-marvel-native-monitoring-deployments","author":{"name":"Steven Schuurman"},"date":"January 28, 2014","category":"News","locales":"","content":" Native Management and Monitoring for DeploymentsToday, we're making an announcement that's probably the most important one Elasticsearch has made since we founded the company.With unbelievable pride and excitement we would like to introduce you to \u2013 our brand new management & monitoring product. Marvel is 100% native to Elasticsearch, built from scratch by the team that also develops Elasticsearch and is effectively the #1 requested ecosystem product requested for our product stack. We hope you will be as excited about it as we are!What does Marvel do Exactly?Marvel solves one of the most important challenges anyone who has deployed Elasticsearch has encountered: how to gain a complete view of the state of a deployment and how to manage clusters towards optimal health. Although Elasticsearch exposes a very rich set of system statistics through its Stats API, translating those outputs into actionable cluster health information is an entirely different issue. Marvel instantly provides much-needed visibility into a deployment, both in real-time and historically. Native Monitoring for DeploymentsMarvel is directly connected with every node in an Elasticsearch deployment and records and visualizes all metrics produced by each node in a cluster, allowing the operator to monitor the current, real-time state as well as the historical state of the cluster. This level of visibility into the Operating System, the JVM, and the various services that are running within Elasticsearch and Lucene, combined with low level system metrics like machine load, CPU, disk, network and memory usage, provide invaluable insights that weren't available before. Although deceivingly simple, being able to correlate core system metrics with Elasticsearch and Lucene specific metrics, is unbelievably valuable. No other off-the-shelf monitoring system is able to provide this level of transparency into your Elasticsearch deployment.How to get MarvelGetting Marvel is simple - you can install it via the command line or download it and install as you would any other Elasticsearch plugin. You can learn more at The Rules are SimpleWe decided to make Marvel completely free for development use and downloadable without any registration of any kind. Marvel is a commercial product though, so if you want to use it to for your live deployment you need to buy a license. If you're an Elasticsearch subscription customer, you get a full license to use Marvel included with your subscription package. If you're not already a subscription customer, you can find all our product information at .And no, $500 for the first five nodes isn't a typo. We've priced our offering to be affordable to any and all Elasticsearch users. We certainly hope you enjoy using Marvel as much as we enjoyed building it for you! \n"}<br>{"index": {"_id": 1392}}<br>{"title":"What's Cooking in Kibana","seo_title":"","url":"\/blog\/whats-cooking-kibana","author":{"name":"Rashid Khan"},"date":"January 27, 2014","category":"Engineering","locales":"","content":" Elasticsearch 1.0 is almost here, and the Kibana team is gearing up for release right alongside. Along with the usual bug fixes and small tweaks, we've got some great new features for you in our next release: Panel Groups Panels are now organized into groups that happily contain as many panels as you you\u2019d like. Rows collapse cleanly and panels consume no resources when hidden. Chart Markers Correlate deployments, logins and other critical events with changes in traffic, memory consumption or load. Chart markers let you input a custom query to be used to draw your important events inline with a time series chart. Ad hoc Filters Create your own query filters and save them for later. Filters are stored along with the dashboard and can be toggled on and off to compare the data subsets you define. Top-N Queries Click the colored dot next to a query to do more than set the query color. The new top-N query finds the most popular terms in a field and uses them to compute new queries. Stats Panel The Stats Panel distills a search down into a single, meaningful number. Terms_Stats mode Bytes served by country? Revenue per customer? Per-page memory usage? The terms_stats mode of the terms panel has everything you need. Coming Soon The next release of Kibana will occur in the coming weeks, but you can grab the current version . If you really want to get your hands dirty, pop on over to the . Feedback is welcome and encouraged, so keep those coming! \n"}<br>{"index": {"_id": 1393}}<br>{"title":"This Week in Elasticsearch - January 22, 2014","seo_title":"","url":"\/blog\/this-week-in-elasticsearch-2014-01-22","author":{"name":"Luca Cavanna"},"date":"January 22, 2014","category":"","locales":"","content":" Welcome to\u00a0 . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the GitHub repositories, as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, and news about Logstash and Kibana. Slides & Videos Where to find Us We'd love to feature all the great Elasticsearch presentations happening worldwide in this section. If you're speaking on Elasticsearch, ! Belgium will be speaking on What's New in Elasticsearch 1.0 with Aggregations at the in Brussels on Friday, January 31st. Doors open at 6 PM. and Honza Kral will be attending on February 1st and 2nd. Stop by the Elasticsearch table to say hello! We'll be in Building K on the 2nd Floor.Leslie Hawthorn will be speaking at the on DevOps: For Happier, More Productive People. Infrastructure.Next takes place on February 5th in Ghent, following .Czech Republic Honza Kral will give two presentations at : and . Honza's presentations take place on Friday, February 7th, and the conference runs from the 7th through the 9th. France Germany Japan Thanks to Jun Ohtani, the 3rd Elasticsearch Meetup will be held in Tokyo on February 7th starting at 7 PM. Please remember to . Sweden The has just been scheduled for February 5th. Further details are forthcoming, but you can look forward to presentations from and . United Kingdom Elasticsearch will have two sessions at , which takes place March 3-7th. You can join for a tutorial on plus see and Graham Tackley co-present on . Make sure to stop by our booth to say hello! United States Where to Find You Our Community Manager, , is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1394}}<br>{"title":"All About Analyzers, Part One","seo_title":"","url":"\/blog\/found-text-analysis-part-1","author":{"name":"Andrew Cholakian"},"date":"January 22, 2014","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. In this article we'll survey various analyzers, each of which showcases a very different approach to parsing text. \n"}<br>{"index": {"_id": 1395}}<br>{"title":"Introducing Snapshot & Restore","seo_title":"","url":"\/blog\/introducing-snapshot-restore","author":{"name":"Igor Motov"},"date":"January 21, 2014","category":"Engineering","locales":"","content":" In the last year, we saw a tremendous increase in adoption of Elasticsearch by many companies. As more and more companies are using Elasticsearch as an integral part of their business, high availability of Elasticsearch becomes increasingly important. With the help of automatic replication and failover, Elasticsearch provides a stable, highly available search and analytics platform. However, while replication can protect a cluster from hardware failures, it doesn\u2019t help when someone accidentally deletes an index. Anyone that relies on an Elasticsearch cluster needs to perform regular backups. It has always been possible to backup an Elasticsearch cluster. However, until version 1.0 the backup process involved turning off index flushing, identifying locations of primary shards on the file system, copying the data and then remembering to turn on flushing again. We believe that simple is best, and the previous backup process in Elasticsearch didn\u2019t quite fit the definition of simple. That\u2019s why in v1.0 we are introducing a new Snapshot & Restore API that should make backup process much easier. In v1.0, backup is a simple and straightforward process. First, Elasticsearch needs to know where to backup data, which is done by registering a backup repository: $ curl -XPUT 'http:\/\/localhost:9200\/_snapshot\/my_backup' -d '{ \"type\": \"fs\", \"settings\": { \"location\": \"\/mount\/backups\/my_backup\", \"compress\": true } }' Currently, we support and repositories. is coming soon. Once Elasticsearch knows about a repository, it\u2019s possible to make a backup of the entire cluster with a single command: $ curl -XPUT \"localhost:9200\/_snapshot\/my_backup\/snapshot_1?wait_for_completion=true\" Snapshots can be created on a live cluster that continues to perform indexing and search operations. A snapshot captures the point-in-time view of the index at the moment when a snapshot process has started. It makes the backup image of the index consistent. Restore is even simpler: $ curl -XPOST \"localhost:9200\/_snapshot\/my_backup\/snapshot_1\/_restore?wait_for_completion=true\" It\u2019s possible to restore indices within a live cluster as well. However, indices have to be closed prior to restore. We are planning to make it possible to restore open read-only indices in a future release. Both backup and restore operations are incremental, which means that only files that changed since the last snapshot will be copied into the repository or restored into an index. Incremental snapshots allow performing the snapshot operation as frequently as needed without too much disk space overhead. Users can now easily create a snapshot before upgrade or a risky change in the cluster and quickly rollback to the previous index state if things go wrong. The snapshot\/restore mechanism can be also used to synchronize data between a \u201chot\u201d cluster and a remote, \u201ccold\u201d backup cluster in a different geographic region for fast disaster recovery. We are very excited about this new feature. We like to think of incremental backup as a time machine for your data. We are confident that everyone who relies on Elasticsearch as a critical component in their system and cannot afford down time for re-indexing will find the new Snapshot and Restore mechanism really helpful. We welcome your feedback \u2013 the Snapshot & Restore API and what you think! \n"}<br>{"index": {"_id": 1396}}<br>{"title":"Curator: Tending your time-series indices","seo_title":"","url":"\/blog\/curator-tending-your-time-series-indices","author":{"name":"Aaron Mildenstein"},"date":"January 20, 2014","category":"Engineering","locales":"","content":" backgroundA few years ago, I was managing an Elasticsearch, Logstash and Kibana (ELK) stack and needed a way to automatically clean up indices older than 30 days. After reading the API documentation and getting some help from the community in the #logstash and #elasticsearch IRC channels, I realized that this was fairly easy to set up with simple scripting and cron. curl -XDELETE 'localhost:9200\/logstash-2014.01.01?pretty' Sure, this works, and it\u2019s not terribly hard to generate dates, but I wanted something a bit more elegant. In the beginning\u2026So, I started writing a script in python. It did the job with a cleaner command line and a single target number of days to keep, so I shared it with the larger community. Others polished it up and added new functionality. I wrote another script that also allowed me to optimize \u2014 which really just means \u201cmerge the segments in each shard until no more than n segments exist per shard \u2014 old indices. These scripts have now been merged and enhanced to become a single, helpful tool to help manage your older indices like the fine works of art they are! Introducing CuratorHere are a few of the index operations you can do with Curator: Installing CuratorAs of this writing, Curator is at release 0.5.1 and works with versions up through 0.90.10. Curator should also should be compatible with Elasticsearch version 1.0 (which is still only at RC1). We\u2019ll be testing to ensure compatibility with each release. It currently resides in a git repository. In the near future, it will be a pip installable package (it\u2019s python-based). Don\u2019t let that scare you away from using it, though! If you have python and pip installed on your machine, installation is as simple as: git clone https:\/\/github.com\/elasticsearch\/curator.git pip install -r requirements.txt After that, you should be able to run this: $ .\/curator.py -v curator.py 0.5.1 How-To and examplesBefore we get to the examples, in context. The list is long (and included at the end of this post), but illustrative of how much control you have. Please note where defaults have been listed. If you like them, you do not need to specify those flags. Now let\u2019s go through some simple examples to illustrate how Curator can make your ELK stack better, and even more responsive. DeleteLet\u2019s say you want to keep no more than 90 days of indices. The command is simple: $ curator.py --host my-elasticsearch -d 90 Here the -d specifies the number of days. Simple, right? Delete by spaceThis is a special case where you might want to delete indices in excess of some number of gigabytes (starting with the oldest): $ curator.py --host my-elasticsearch -C space -g 10024 Here you see that we specified curation (-C) by space, and a number of (-g) gigabytes (10024, or 10TB). The -g argument will accept a decimal value, e.g. 1.5, 0.5, etc. CloseClosing an index is handled by the : The open and close index APIs allow to you close an index, and later on open it. A closed index has almost no overhead on the cluster (except for maintaining its metadata), and is blocked for read\/write operations. A closed index can be opened which will then go through the normal recovery process.Closing an index means it\u2019s still there, but not searchable. Why is that useful? Imagine that you have an obligation to keep indices for 90 days, but rarely if ever do you search through an index over 30 days old. In this case, you can close the indices which will save valuable resources (heap space, in particular). This means your cluster will have more memory for searches and indexing! And if you ever need the data in those indices, you can open them again with an API call and they\u2019ll be there again. $ curator.py --host my-elasticsearch -c 30 -d 90 This builds on our previous example. This will close indices older than 30 days and delete indices older than 90 days. Still quite simple! Disable Bloom Filters Don\u2019t worry, the script checks to make sure your version is sufficient before attempting the operation. What is a bloom filter? Why would I want it disabled? The bloom filter is resources allocated to speed indexing operations. With time-series data this is still useful while indexing. Your index is probably not indexing new data 2 days after the date has rolled over. The bloom filter is then holding on to resources that the index no longer requires. With Curator we can free those resources! $ curator.py --host my-elasticsearch -b 2 -c 30 -d 90 Now we\u2019re freeing those bloom filter resources on indices older than 2 days (you could also do 1), closing indices older than 30 days and deleting indices older than 90 days. Optimize, or rather forceMergeIt\u2019s important to understand that when you see in the Elasticsearch API you\u2019re not seeing a command you need to run on a live index, or repeatedly on a \u201ccold\u201d index (meaning one that is no longer actively indexing). In fact, so people would not make an optimize call thinking it was improving their index. Merging segments in Elasticsearch can bring benefits, but understand the cost before you start optimizing all of your cold indices. A forceMerge operation will try to reduce the segment count in each shard in your indices. Since each segment has an overhead, more segments means more resources used. That\u2019s good, right? Less resources? It can be, but the amount of disk and network I\/O to perform a significant merge operation can take a toll on your disks and your cluster\u2019s normal write operations. My advice here is to consider carefully if you need this. It can help make searches faster (by a few percentage points), and reduce resources. It can also make cluster recover faster as there are fewer segments to manage. It can take a very long time to optimize a single index \u2014 perhaps an hour or more. As a result, increasing the timeout may be necessary, with a recommended value of no less than 3600 seconds (one hour). As with the warning labels on cleaning bottles, \u201ctest in an inconspicuous place before using,\u201d you should test this during a time of reduced disk I\/O and see if it improves operations and resources in a way that makes sense for your cluster and use-case. The default is to merge to 2 segments per shard, but you can override this default with the flag. Building on our previous example yet again, $ curator.py --host my-elasticsearch -b 2 -o 2 -c 30 -d 90 This will disable bloom filters for indices older than 2 days, \u201coptimize\u201d indices older than 2 days, close indices older than 30 days and delete indices older than 90 days. Order of operationsThe script enforces the following order to prevent operations from colliding. Why optimize an index that\u2019s closed? Why close an index that\u2019s slated for deletion? Usage considerationsIn the most recent example, we performed all three operations in one command, but you may not want them all run serially. $ curator.py --host my-elasticsearch -b 2 -o 2 -c 30 -d 90 \u2026is functionally equivalent to\u2026 $ curator.py --host my-elasticsearch -d 90 $ curator.py --host my-elasticsearch -c 30 $ curator.py --host my-elasticsearch -b 2 $ curator.py --host my-elasticsearch -o 2 You could easily run these commands at different times, or with extra flags (especially the optimize run, which should have something like ). You may also have indices with prefixes other than the default logstash- to crawl: $ curator.py --host my-elasticsearch --prefix logstash- -d 30 $ curator.py --host my-elasticsearch --prefix othername- -d 30 ConclusionCurator helps you manage your time-series indices retention policies. With an abundance of configuration options you can easily manage your indices\u2013whether you have 1 node, or a hundred or more in your cluster. Feedback and contributions are welcome at ! (all arguments and options displayed)$ curator.py -h usage: curator.py [-h] [-v] [--host HOST] [--port PORT] [-t TIMEOUT] [-p PREFIX] [-s SEPARATOR] [-C CURATION_STYLE] [-T TIME_UNIT] [-d DELETE_OLDER] [-c CLOSE_OLDER] [-b BLOOM_OLDER] [-g DISK_SPACE] [--max_num_segments MAX_NUM_SEGMENTS] [-o OPTIMIZE] [-n] [-D] [-l LOG_FILE] Curator for Elasticsearch indices. Can delete (by space or time), close, disable bloom filters and optimize (forceMerge) your indices. optional arguments: -h, --help show this help message and exit -v, --version show program version number and exit --host HOST Elasticsearch host. Default: localhost --port PORT Elasticsearch port. Default: 9200 -t TIMEOUT, --timeout TIMEOUT Elasticsearch timeout. Default: 30 -p PREFIX, --prefix PREFIX Prefix for the indices. Indices that do not have this prefix are skipped. Default: logstash- -s SEPARATOR, --separator SEPARATOR Time unit separator. Default: . -C CURATION_STYLE, --curation-style CURATION_STYLE Curate indices by [time, space] Default: time -T TIME_UNIT, --time-unit TIME_UNIT Unit of time to reckon by: [days, hours] Default: days -d DELETE_OLDER, --delete DELETE_OLDER Delete indices older than n TIME_UNITs. -c CLOSE_OLDER, --close CLOSE_OLDER Close indices older than n TIME_UNITs. -b BLOOM_OLDER, --bloom BLOOM_OLDER Disable bloom filter for indices older than n TIME_UNITs. -g DISK_SPACE, --disk-space DISK_SPACE Delete indices beyond n GIGABYTES. --max_num_segments MAX_NUM_SEGMENTS Maximum number of segments, post-optimize. Default: 2 -o OPTIMIZE, --optimize OPTIMIZE Optimize (Lucene forceMerge) indices older than n TIME_UNITs. Must increase timeout to stay connected throughout optimize operation, recommend no less than 3600. -n, --dry-run If true, does not perform any changes to the Elasticsearch indices. -D, --debug Debug mode -l LOG_FILE, --logfile LOG_FILE log file \n"}<br>{"index": {"_id": 1397}}<br>{"title":"Introducing: The cat API","seo_title":"","url":"\/blog\/introducing-cat-api","author":{"name":"Drew Raines"},"date":"January 17, 2014","category":"Engineering","locales":"","content":" Background Perhaps the biggest success of Elasticsearch is its APIs. Interacting with the system is so simple it still catches me off guard, four years after I first tried it out. The engine powering this simplicity is JSON, a straightforward form of structured text birthed out of the rise of JavaScript. JSON is easy to understand and parse, and because of that, supported by almost every programming language in existence. Humans, however, are not programming languages. JSON\u2019s strength is that it\u2019s plaintext, which makes it possible for our eyes to parse, but merely looking at human-readable characters isn\u2019t the same as actually understanding the information. With any more than the most trivial structure in a JSON doc, we typically reach for the nearest pretty-printer. Unfortunately, pretty-printing often still does not translate into actionable knowledge. In fact, the addition of whitespace often makes life even more difficult as it eats up precious space in a terminal window. \u201cNot a problem,\u201d you say. \u201cJSON is so simple all I need is $LANG and five minutes.\u201d Unfortunately, JSON and $LANG, along with speaking, walking, producing coherent sentences, and almost any other task in life, is a bit harder when you\u2019re woken up from deep sleep by your phone alerting you to a system outage. The 3 AM Page Imagine this has just happened to Teresa. The monitoring system noticed that her cluster is red. A common first step in this moment of life as an Elasticsearch cluster administrator is to take a look at the logs on the master node. Which node is master? Armed with the comprehensive output of the , she\u2019s off to the races. % curl 'es1:9200\/_cluster\/state?pretty' { ... \"master_node\" : \"Wjf_YVvySoK8TE41yORt3A\", ... OK, not quite. That\u2019s just the node ID. node is that? ... \"nodes\" : { \"56RhV2ecT3OIZFzUYVYwNQ\" : { \"name\" : \"Midnight Sun\", \"transport_address\" : \"inet[\/192.168.56.20:9300]\", \"attributes\" : { } }, \"pyqzjh_nRx6rapL-CBvsyA\" : { \"name\" : \"Urthona\", \"transport_address\" : \"inet[\/192.168.56.40:9300]\", \"attributes\" : { } }, \"Wjf_YVvySoK8TE41yORt3A\" : { \"name\" : \"Lasher\", \"transport_address\" : \"inet[\/192.168.56.10:9300]\", \"attributes\" : { } }, ... Her tired eyes move back and forth a few times and figure out that in order to get to she must connect to . She grumbles and pores over the logs. She notices that a node has failed some pings. She\u2019s no fool. She\u2019s seen this before and it wasn\u2019t the network. The JVM is likely in trouble on that node. First up, she checks on the cluster\u2019s health. % curl es1:9200\/_cluster\/health?pretty { \"cluster_name\" : \"foo\", \"status\" : \"red\", \"timed_out\" : false, \"number_of_nodes\" : 4, \"number_of_data_nodes\" : 4, \"active_primary_shards\" : 283, \"active_shards\" : 566, \"relocating_shards\" : 0, \"initializing_shards\" : 0, \"unassigned_shards\" : 1 } Uh oh! Red! Teresa is a bit paranoid, so she checks health across the whole cluster. % for i in 1 2 3 4 5: do curl es${i}:9200\/_cluster\/health: echo: done {\"cluster_name\":\"foo\",\"status\":\"red\",\"timed_out\":false,\"number_of_nodes\":4,\"number_of_data_nodes\":4,\"active_primary_shards\":283,\"active_shards\":566,\"relocating_shards\":0,\"initializing_shards\":0,\"unassigned_shards\":1} {\"cluster_name\":\"foo\",\"status\":\"red\",\"timed_out\":false,\"number_of_nodes\":4,\"number_of_data_nodes\":4,\"active_primary_shards\":283,\"active_shards\":566,\"relocating_shards\":0,\"initializing_shards\":0,\"unassigned_shards\":1} {\"cluster_name\":\"foo\",\"status\":\"red\",\"timed_out\":false,\"number_of_nodes\":4,\"number_of_data_nodes\":4,\"active_primary_shards\":283,\"active_shards\":566,\"relocating_shards\":0,\"initializing_shards\":0,\"unassigned_shards\":1} {\"cluster_name\":\"foo\",\"status\":\"red\",\"timed_out\":false,\"number_of_nodes\":4,\"number_of_data_nodes\":4,\"active_primary_shards\":283,\"active_shards\":566,\"relocating_shards\":0,\"initializing_shards\":0,\"unassigned_shards\":1} A bit verbose, but it got the job done. All the nodes agree: at least, the ones that are responding. A node definitely is missing, which confirms the ping failures, but that doesn\u2019t explain the red cluster. She sits back nods off for ten minutes. When she wakes up, by chance she notices in the JSON soup splattered all over her screen that there\u2019s an unassigned shard. \u201cHm, which one is that?\u201d she asks herself. Experienced with the APIs, she cleverly attaches the parameter to to dig deeper. % curl es1:9200\/_cluster\/health?level=shards&amp: pretty ... \"foo-20140116\" : { \"status\" : \"red\", \"number_of_shards\" : 2, \"number_of_replicas\" : 0, \"active_primary_shards\" : 1, \"active_shards\" : 1, \"relocating_shards\" : 0, \"initializing_shards\" : 0, \"unassigned_shards\" : 1, \"shards\" : { \"0\" : { \"status\" : \"red\", \"primary_active\" : false, \"active_shards\" : 0, \"relocating_shards\" : 0, \"initializing_shards\" : 0, \"unassigned_shards\" : 1 }, ... Now she\u2019s getting somewhere. The index was created today by Logstash. For some reason shard doesn\u2019t have an active primary, which must have been on the node that isn\u2019t up at the moment. \u201cWhat happened to the replicas?\u201d she thinks. Teresa starts the missing node, flips on a replica, and heads back to bed. She can figure that out in the morning. A new kind of API If it was as difficult to read that short tale as it was to write it, I apologize. Fortunately there is light at the end of the curly brace. Let\u2019s see what Teresa\u2019s night would have looked like if she was able to work with some slightly different APIs. The first thing she needed to do was find the master. It would have been nice if in one, single glorious line she got the node and host information. % curl es1:9200\/_cat\/master Wjf_YVvySoK8TE41yORt3A es1 192.168.56.10 Lasher Puurfect! Instead of messing with the logs, however, she really just needs to get a bird\u2019s-eye view of the current node situation. % curl es1:9200\/_cat\/nodes es1 192.168.56.10 35 79 0.00 d * Lasher es2 192.168.56.20 40 88 0.00 d m Midnight Sun es4 192.168.56.40 49 89 0.00 d m Urthona es5 192.168.56.50 40 75 0.00 d m Chimera She immediately can tell that she\u2019s missing a node, and which one! Next up is to figure out why the cluster is . Is it thirty indices or only one? % curl es1:9200\/_cat\/indices | grep ^red red foo-20140116 2 0 30620 1 78.6mb 78.6mb Looks like it\u2019s only one. How many shards are missing? % curl es1:9200\/_cat\/shards\/foo-20140116 foo-20140116 0 p UNASSIGNED foo-20140116 1 p STARTED 30620 78.6mb 192.168.56.50 Chimera It\u2019s easy to see now that half of the primaries are gone and there aren\u2019t replicas configured for . After starting up , a cluster-wide health check: % for i in 1 2 3 4 5: do ssh es${i} curl -s localhost:9200\/_cat\/health: done 1389940476 18:05:40 foo green 5 5 10 10 0 0 0 1389940477 18:05:40 foo green 5 5 10 10 0 0 0 1389940479 18:05:40 foo green 5 5 10 10 0 0 0 1389940480 18:05:40 foo green 5 5 10 10 0 0 0 1389940480 18:05:40 foo green 5 5 10 10 0 0 0 Nice and succinct, where anomalies can easily be caught before precious minutes are wasted in data that doesn\u2019t lead you to informed decisions. Numbers Everywhere This may not seem like an improvement to you. We\u2019ve gone from the explicit, labeled JSON to columns of random numbers. To alleviate the transition headache, every cat endpoint takes a parameter to turn on mode. It will output a header row labeling each column. % curl 'es1:9200\/_cat\/health?v' epoch timestamp cluster status nodeTotal nodeData shards pri relo init unassign 1389963537 18:06:03 foo green 5 5 10 10 0 0 0 Headers Now we can see that the numbers correspond directly to the key\/value pairs that appear in the cluster health API. We can also use these headers to selectively output columns relative to our context. Suppose we\u2019re tracking a long cluster recovery and we want to see our unassigned shards number precipitously drop. We could just output all the numbers. A cleaner approach would be to filter every thing except the number we care about. % while true: do curl 'es1:9200\/_cat\/health?h=epoch,timestamp,cluster,status,unassign': sleep 30: done 1389969492 06:38:12 foo yellow 262 1389969495 06:38:15 foo green 250 1389969498 06:38:18 foo green 237 ... Column management One of the major motivations behind cat is to speak Unix fluently. In this case, a simple would have sufficed, but some APIs have many more non-default columns that you can only get to with . Let\u2019s say Teresa experienced some high heap usage on her nodes and she does a lot of sorting and faceting, common users of fielddata cache. She would like to compare fielddata cache usage and heap across nodes, a task that\u2019s technically possible with the , but becomes impractical-to-impossible after two nodes. With the , it\u2019s simply a matter of knowing a few column names. % curl 'es1:9200\/_cat\/nodes?h=host,heapPercent,heapMax,fielddataMemory' | sort -rnk2 es4 61 29.9gb 14.4gb es3 58 29.9gb 16.5gb es5 40 29.9gb 5gb es2 33 29.9gb 8.2gb es1 20 29.9gb 3.4gb Sorting by percentage of heap used makes it very clear there is some rough correlation between heap and fielddata use. Byte and time resolution What if she wanted to sort by ? ES provides human-readable conversions from bytes but this actually makes it harder for . She can supply the flag to specify the unit of precision. % curl 'es1:9200\/_cat\/nodes?h=host,heapPercent,heapMax,fielddataMemory&bytes=b' | sort -rnk4 es3 58 29.9gb 17805705171 es4 61 29.9gb 15550755044 es2 33 29.9gb 8880273008 es5 40 29.9gb 5449302354 es1 20 29.9gb 3687354160 The same kind of resolution calculation for time works as well. If she has a column like that she wants in seconds, she can supply a parameter with . % curl 'es1:9200\/_cat\/nodes?h=host,mtt&time=s' | sort -rnk2 es4 910 es3 902 es2 278 es1 190 es5 99 Help! How did she know that would give her ? Each API supports a flag with all the possible column headers. % curl 'es1:9200\/_cat\/nodes?help' | fgrep merge merges.current | mc,mergesCurrent | number of current merges merges.current_docs | mcd,mergesCurrentDocs | number of current merging docs merges.current_size | mcs,mergesCurrentSize | size of current merges merges.total | mt,mergesTotal | number of completed merge ops merges.total_docs | mtd,mergesTotalDocs | docs merged merges.total_size | mts,mergesTotalSize | size merged merges.total_time | mtt,mergesTotalTime | time spent in merges Any of , , or would have worked. She picked since it\u2019s short and esoteric, like a good Unix admin prefers. Much more! , , , and are just a few. There are APIs for , , and more! Conclusion cat is an evolution of ad hoc tools produced in the field of large clusters running on early versions of Elasticsearch. It was clear that the APIs were a generation ahead. They were excellent for machines while they were merely usable for humans. cat aims to fit in those places where JSON doesn\u2019t \u2013 the Unix pipe, the chat window, the tweet. In an era of unprecedented bandwidth of communication, it\u2019s the low-bandwidth, the lightweight, that we reach for most often. It\u2019s fitting that they also happen to be the places cats seem to appear most. We would love to hear your feedback on the . what you think! \n"}<br>{"index": {"_id": 1398}}<br>{"title":"This Week in Elasticsearch - January 16, 2014","seo_title":"","url":"\/blog\/2014-01-16-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"January 16, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to\u00a0. In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the GitHub repositories, as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, as well as news about Logstash and Kibana. Slides & Videos Where to find UsBelgium will be speaking on What's New in Elasticsearch 1.0 with Aggregations at the in Brussels on Friday, January 31st. Doors open at 6 PM. and Honza Kral will be attending on February 1st and 2nd. Stop by the Elasticsearch table to say hello!Leslie Hawthorn will be speaking at the on DevOps: For Happier, More Productive People. Infrastructure.Next takes place on February 5th in Ghent.Czech Republic Honza Kral will give two presentations at : and . Honza's presentations take place on Friday, February 7th, and the conference runs from the 7th through the 9th. France Germany Japan Thanks to Jun Ohtani, the 3rd Elasticsearch Meetup will be held in Tokyo on February 7th starting at 7 PM. Please remember to . United Kingdom Elasticsearch will have two sessions at , which takes place March 3-7th. You can join for a tutorial on plus see and Graham Tackley co-present on . Make sure to stop by our booth to say hello! United States Where to Find You Our Community Manager, Leslie Hawthorn, is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1399}}<br>{"title":"1.0.0.RC1 released","seo_title":"","url":"\/blog\/1-0-0-rc1-released","author":{"name":"Clinton Gormley"},"date":"January 15, 2014","category":"","locales":"","content":" Today we are happy to announce the release of , which is based on Lucene 4.6. This is our first (and hopefully last) release candidate before version 1.0.0 stable. You can . In the four years that Elasticsearch has been in development, it has accumulated some cruft: there are some inconsistent APIs and parameters. We are using this release to try to fix that. Our goal is that the user interface should be intuitive\u2009\u2014\u2009you shouldn\u2019t even need to consult the docs for common requests because the API should be obvious. While we try very hard to maintain backwards compatibility, some of these changes require us to break with the past. To help you migrate your application to 1.0, we have put together a . The full list of all changes is available in the . New features and enhancements An Elasticsearch release wouldn\u2019t be complete without new toys, and this release is no different: Federated search The first new toy is the (experimental!) which joins multiple clusters and act as a federated client. Almost all operations are supported: distributed search, suggestions, percolation. You can even index into multiple clusters with the tribe node. Alternatively, you can set a tribe node to not allow any write operations, making it read-only. See the for more information. Scale and stability Several of our clients and users are using Elasticsearch at humongous scale, pushing the boundaries of what is possible. Their experiences have helped us to find the breaking points in Elasticsearch, and to improve them. The result is improved stability and scale for all of us. Cluster state processing (eg creating indices, mappings, nodes joining and leaving, shard allocation) has been streamlined and takes 5% of the time that it used to. Shard allocation and recovery has been improved and several bugs have been fixed. See , , , , , , , , , and . Memory usage and limits One of the biggest causes of instability in Elasticsearch is : field values have to be loaded into memory to make aggregations, sorting and scripting perform as fast as they do. Up until now, it was difficult to prevent this field data from using all available memory and throwing an OOM error. The new will throw an exception if you try to exceed the , which defaults to 80% of the heap size. You can read more about it in the . Other memory optimizations include the ability to We try to play nicely with the JVM to reduce garbage collection and to keep request latency low. This can be difficult to do when large temporary data structures are required to service requests. The new PageCacheRecycler provides us with pages of memory that can be reused for subsequent requests without interfering with the young generation heap. See and . Other new features What\u2019s next This is a big release\u2009\u2014\u2009it reflects just how many improvements we wanted to get into version 1.0 of Elasticsearch. Part of the changes include a greatly expanded test suite. But our test suite can never cover everything, so we need your help with verifying this release. Please download and test out and report any problems that you find. This will help us get to version 1.0 stable more quickly! \n"}<br>{"index": {"_id": 1400}}<br>{"title":"BM25 vs Lucene Default Similarity","seo_title":"","url":"\/blog\/found-bm-vs-lucene-default-similarity","author":{"name":"Konrad Beiske"},"date":"January 14, 2014","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. A follow up on the similarity article where we compare the precision and recall of the two models using Wikipedia articles. \n"}<br>{"index": {"_id": 1401}}<br>{"title":"Elasticsearch 0.90.10 Released","seo_title":"","url":"\/blog\/0-90-10-released","author":{"name":"Clinton Gormley"},"date":"January 10, 2014","category":"Engineering","locales":"","content":" Today, we are happy to announce the release of E, which is based on Lucene 4.6. This is the current stable release in the 0.90 series. You can download it .This release fixes an . If you have set to point to multiple directories, you should upgrade to 0.90.10. More details about this bug can be found below. You can read about other bug fixes and enhancements in the .To explain the problem, a shard requires a single file called which stores the latest generation number. If there is more than one file, the index may (incorrectly) appear to be corrupted. When using multiple data paths, the file could be written to any of the listed directories, so causing duplication and the appearance of corruption. This can prevent a shard from recovering, with error messages such as:Failed to start shard, message [IndexShardGatewayRecoveryException[[my_indexname][2] shard allocated for local recovery (post api), should exist, but doesn't, current files: [_66wz.fdx, ...]]: nested: FileNotFoundException[segments_4ws]: ]] Often users have resorted to deleting the shard and thus losing data. This by ensuring that the file is only ever written to one location. If you encounter this apparent index corruption in a running system, you can it by deleting all files called . It is advisory only, and Lucene can recover correctly without it.This release also includes a big speed up when calculating geo-distances. We have changed the distance calculation to use the and we use to calculate cosine and arcsin. Distance calculations are now 99.9% accurate and ! If you need absolutely accurate calculations, you can set the to instead of the new default .We hope you enjoy this new release. Please , and let us know what you think. \n"}<br>{"index": {"_id": 1402}}<br>{"title":"This Week in Elasticsearch - January 08, 2014","seo_title":"","url":"\/blog\/2014-01-08-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"January 08, 2014","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to\u00a0. In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the GitHub repositories, as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. We've been out for a bit due to the end of the year holidays, so we have even more great information to share with you this week.Elasticsearch Core Elasticsearch EcosystemHere's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, as well as news about Logstash and Kibana. Slides & Videos Where to Find UsBelgium and will be attending on February 1st and 2nd. Stop by the Elasticsearch table to say hello!Czech RepublicHonza Kral will give two presentations at : and . Honza's presentations take place on Friday, February 7th, and the conference runs from the 7th through the 9th.France Germany JapanThanks to Jun Ohtani, the 3rd Elasticsearch Meetup will be held in Tokyo on February 7th starting at 7 PM. Please remember to .Netherlands will present From A to JSON - an Overview of Elasticsearch at the in Rotterdam. Doors open tomorrow night, January 9th, at 6 PM. United Kingdom will talk about What's New in Elasticsearch 1.0 at in London on January 15th. Attendance is free of charge, though registration is required. Doors open at 5 PM.United States Where to Find YouOur Community Manager, Leslie Hawthorn, is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, .Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana and Logstash than where you rest your head.TrainingIf you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1403}}<br>{"title":"Ignore Filters: The Latest Feature in elmah.io, Courtesy of Elasticsearch","seo_title":"","url":"\/blog\/ignore-filters-latest-feature-elmah-io-courtesy-elasticsearch","author":{"name":"Leslie Hawthorn"},"date":"January 07, 2014","category":"","locales":"","content":" Today we\u2019re bringing you another story of Elasticsearch in the field: elmah.io and its latest feature, . Elmah.io is cloud based error logger for .NET web applications. Thomas Ardal, one of their backend developers, was kind enough to share his story of implementing the latest functionality for elmah.io in just 30 minutes, all based on Elasticsearch\u2019s . At , we\u2019ve set a course to create the best cloud based error logging framework for .NET web applications: simply add a NuGet package to your web project, and all of your website errors are logged to elmah.io. On the elmah.io site, you can search through all of your errors and logs using various search input. All of the errors we receive are indexed in a cluster of Elasticsearch instances, making it highly available and super-fast to search through all possible errors. Let\u2019s talk about how we\u2019ve used some of the nice features of Elasticsearch for some of our recently added functionality. Like any good company, we eat our own dog food and use elmah.io to perform all logging for our own website. One day, I noticed new errors in our logs with the user agent saying something like *bot*. You\u2019ve probably seen something similar yourself: Google or someone else is trying to request pages that don\u2019t exist on the server or somehow manipulate the URL in an unintended way. We could sit down and implement special code handling bot requests, but what we really want is a way to tell elmah.io not to index certain types of errors that don\u2019t yield useful, actionable information. That\u2019s why we decided to build . In this blog post, I will tell you how we did that using C#, NEST and Elasticsearch\u2019s Percolator API. In short, the Percolator API implements a sort of reverse query in Elasticsearch. Usually you index documents and query them. Using the Percolator, you index queries and then ask if Elasticsearch has queries which match documents \u2013 perfect use-case for implementing ignore queries! were something we had been thinking about for some time. We wanted a solution that was easy for our users to setup and possible for us to implement without using months of development time. After reading a blog post explaining the Percolator API in Elasticsearch, I got curious and, before I knew it, I had implemented a prototype of the feature. To get started, users need to input search queries telling elmah.io what errors to ignore. We built a new UI for this task: The user adds their own queries or chooses one of the templates defined at the bottom. Implementing this save in C# is easy using the wonderful client package for , written by Martijn Laarman: var connectionSettings = new ConnectionSettings(url): connectionSettings.SetDefaultIndex(indexName): var elasticClient = new ElasticClient(connectionSettings): var registerPercolator = elasticClient.RegisterPercolator(id, p => p.QueryString(qs => qs.Query(query))): We start by creating a new instance pointing to the index that we want to add the ignore filter to. Then, we call the method, which takes an ID that we generate from a random number, as well as a query. We\u2019ve decided to let the user input Lucene queries in the UI, which uses the in Elasticsearch. This solution is not optimal, because users may incidentally write slow queries this way. There\u2019s a new feature in recent versions of Elasticsearch called , which we plan to migrate to in the next version of elmah.io. And that\u2019s it! The user is now able to register ignore filters, based on Lucene queries and the Percolator API. Each time we receive an error, we ask the Percolator for queries (ignore filters) matching the new error using NEST: var percolateResponse = elasticClient.Percolate(errorDocument): if (percolateResponse.OK && percolateResponse.Matches.Any()) { return Request.CreateResponse(HttpStatusCode.OK): } In text: if the percolate request were OK and the request actually returned any queries, we simply return a response immediately. To be able to distinguish if errors are actually logged or ignored by an ignore filter, we use status code 200 for everything went well, but if the errors were ignored then status code 201 is created for the error. Looking at the code, the entire feature looks simple. With the Percolator API this complex feature was indeed simple to implement. Doing similar stuff with something like a relational databases really shows the strength of a NoSQL search engine like Elasticsearch. In conclusion, the Percolator API turned out to be the perfect companion for implementing elmah.io\u2019s . The Perclator\u2019s simplicity led us in the right direction, making the feature we built for our elmah.io users simple to use, as well. We just released this feature in the past few weeks, and we\u2019re looking forward to getting more . Many thanks to Thomas for sharing his experience with us. If you are interested in learning more about the redesigned percolator forthcoming in Elasticsearch 1.0 (and already available in our beta releases), check out this presentation from Elasticsearch core developer : \u00a0 Last but not least, if you\u2019d like to see your story featured here on the Elasticsearch Developer blog, ! \n"}<br>{"index": {"_id": 1404}}<br>{"title":"A Data Exploration Workflow for Mappings","seo_title":"","url":"\/blog\/found-mapping-workflow","author":{"name":"Njal Karevoll"},"date":"January 07, 2014","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. In this article we explore a workflow for exploring new data via mapping refinements. We index an example document, look at its default mapping and iteratively improve on it to get us one step closer to our goal. \n"}<br>{"index": {"_id": 1405}}<br>{"title":"Facebook & Elasticsearch: for Your Holiday Viewing Pleasure","seo_title":"","url":"\/blog\/holiday-viewing-pleasure-facebook-elasticsearch","author":{"name":"Livia Froelicher"},"date":"December 24, 2013","category":"","locales":"","content":" Our days are a bit quiet here at Elasticsearch this week, as we and many of our friends and colleagues spend time with our loved ones for the holidays. We won't be bringing you our usual update in , but didn't want to leave anyone hungry for Elasticsearch awesome. So, without further ado, we bring you this video from the , in which you'll learn more about Facebook's use of Elasticsearch, including: \u00a0 You'll also hear from me on Elasticsearch 1.0 and enjoy some lively audience Q&A. Many thanks to Facebook for hosting us and sharing their Elasticsearch use cases. We hope you enjoy the video. what you think. Happy holidays to all of you celebrating them this week and next, and happy hacking on Elasticsearch! \n"}<br>{"index": {"_id": 1406}}<br>{"title":"Logstash 1.3.2 Released!","seo_title":"","url":"\/blog\/logstash-1-3-2-released","author":{"name":"Aaron Mildenstein"},"date":"December 24, 2013","category":"","locales":"","content":" Hello again friends! is now available! We recently implemented a new feature to help make Logstash and Elasticsearch get along more usefully (the new indexing template, it is awesome!). However, 1.3.0 had a bug that prevented it from actually working, and 1.3.1 had a different bug that caused the data to be stored in a way that made searches work inconsistently with previous releases. The 1.3.2 release has a few bug fixes and a big performance improvement for date processing (json codec, date filter, etc will all benefit here). You can to see the whole list. Some highlights: That's it for now! Happy Logstashing! \n"}<br>{"index": {"_id": 1407}}<br>{"title":"Elasticsearch 0.90.9 released","seo_title":"","url":"\/blog\/0-90-9-released","author":{"name":"Clinton Gormley"},"date":"December 23, 2013","category":"Engineering","locales":"","content":" Today, just in time for the holidays, we are happy to announce the release of E, which is based on Lucene 4.6. This is the current stable release in the 0.90 series. You can download it .Unfortunately, 0.90.8 had a bug in the API which might report too few shards if one of your indices is status `red`. While this doesn't put your data at risk, it might cause sysadmins to suffer a moment of extreme panic.While we were about it, we found a bug in the which could, in rare cases, cause search requests to hang. And lastly, a bug was introduced in 0.90.8 which prevented index templates from being loaded when placed under the config directory.Apologies for the quick re-release, but we hope it makes your holiday more festive and relaxed. Thanks to those who reported these bugs so promptly. Please and let us know what you think. \n"}<br>{"index": {"_id": 1408}}<br>{"title":"Announcing DEB and RPM Repositories","seo_title":"","url":"\/blog\/apt-and-yum-repositories","author":{"name":"Richard Pijnenburg"},"date":"December 20, 2013","category":"Engineering","locales":"","content":" global wrapper \n"}<br>{"index": {"_id": 1409}}<br>{"title":"Elasticsearch's New Aggregations","seo_title":"","url":"\/blog\/found-elasticsearch-aggregations","author":{"name":"Alex Brasetvik"},"date":"December 20, 2013","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. Elasticsearch's faceting feature has made it extremely popular not just for realtime search, but also for analytics. With its new aggregations framework, it'll take you even further. - <p>We\u2019ve made <a href=\"https:\/\/www.found.no\/play\/gist\/cab4eaf924717c5d1c92\">a runnable example in Play<\/a>. (See <a href=\"\/blog\/found-presenting-play\/\">Presenting Play<\/a> for an introduction on how Play works). In the figure below is the resulting aggregation definition, a tree visualization, and parts of an example result: showing how things get nested. <\/p> <p> <img src=\"\/assets\/bltb4f98197e5aeb7cf\/stackoverflow-tree.svg?uid=bltb4f98197e5aeb7cf\" data-sys-asset-uid=\"blt651afbb922035410\" alt=\"A nested aggregation - the query, its tree and sample result\" style=\"max-width:100%: \" > <\/p><figcaption>A nested aggregation - the query, its tree and sample result<\/figcaption> <p>First, the <code>terms<\/code>-aggregation on the <code>tags<\/code>-field will produce one bucket per <code>tag<\/code>. The documents in each bucket are then fed to an <code>avg<\/code>-aggregator on the <code>comment_count<\/code> field for each document in the bucket. The documents are also sent to a <code>nested<\/code>-aggregator. The <code>nested<\/code>-aggregator pulls up the <code>comments<\/code> of each document in the bucket, and these inner comments are passed to a <code>terms<\/code>-aggregator. That <code>terms<\/code>-aggregator produces buckets of comments per author. Last, these are passed through a <code>max<\/code>-aggregator, to find the highest comment score. <\/p> <p>Many things are happening here, but if you think of how documents pass through a tree of aggregators step by step, complex problems can be broken down into a tree of simple operations. <\/p> <\/section> <section id=\"more-examples\" class=\"level2\"> <h2><a href=\"#more-examples\">More examples<\/a><\/h2> <p>We have made some <a href=\"\/blog\/found-presenting-play\">Plays<\/a> that contain various annotated examples. Check them out and have a play. You can adjust the documents and searches and press <code>Run<\/code> (or <code>Ctrl<\/code>+<code>Enter<\/code>) to experiment! When there are multiple searches in the example, they are delimited with <code>---<\/code> and show their results in different tabs (e.g. \u201cSearch #1\u201d, \u201cSearch #2\u201d, &hellip: ) <\/p> <p>The examples do not have lots of complex documents, but enough to demonstrate some concepts. (Note: As of this writing, there is <a href=\"https:\/\/github.com\/elasticsearch\/elasticsearch\/pull\/4472\">a bug related to sorting terms aggregations based on sub-aggregations<\/a>. Play should work, however. This will likely be fixed before 1.0.) <\/p> <ul> <li><a href=\"https:\/\/www.found.no\/play\/gist\/8053573\">Find servers that report the most variance in CPU-usage<\/a>. Logstash now makes it quite easy to report metrics to Elasticsearch.<\/li> <li><a href=\"https:\/\/www.found.no\/play\/gist\/8053633\">For ticket sales, find top-selling organizations, their most popular events and get a date histogram of revenue per event<\/a><\/li> <li><a href=\"https:\/\/www.found.no\/play\/gist\/8053769\">HTTP request logs: Find hosts with slow requests, and per host what\u2019s slow<\/a><\/li> <li><a href=\"https:\/\/www.found.no\/play\/gist\/8053943\">Hierarchically faceting products by category and store<\/a><\/li> <li><a href=\"https:\/\/www.found.no\/play\/gist\/cab4eaf924717c5d1c92\">The Stackoverflow example from above<\/a><\/li> <\/ul> <\/section> \n"}<br>{"index": {"_id": 1410}}<br>{"title":"Elasticsearch 0.90.8 Released","seo_title":"","url":"\/blog\/0-90-8-released","author":{"name":"Clinton Gormley"},"date":"December 18, 2013","category":"Engineering","locales":"","content":" global wrapper \n"}<br>{"index": {"_id": 1411}}<br>{"title":"This Week in Elasticsearch - December 18, 2013","seo_title":"","url":"\/blog\/2013-12-18-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"December 18, 2013","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to\u00a0. In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the GitHub repositories, as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, as well as news about Logstash and Kibana. Slides Where to find Us Israel The first ever will take place on December 30th, beginning at 7 PM. Join Elasticsearch core developer , who will present on what's new in Elasticsearch 1.0, and Itamar Syn-Hershko, who will discuss Monitoring online conversation at scale using Elasticsearch. France will talk about in Angers at the 14th of January. Netherlands will talk about Elasticsearch at in Rotterdam at the 9th of January. United Kingdom Mark Harwood will talk about Elasticsearch 1.0 at in London at the 15th of January. Where to Find You Our Community Manager, Leslie Hawthorn, is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana and Logstash than where you rest your head. Training If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1412}}<br>{"title":"Announcing Elasticsearch.js for Node.js and the Browser","seo_title":"","url":"\/blog\/client-for-node-js-and-the-browser","author":{"name":"Spencer Alger"},"date":"December 17, 2013","category":"Engineering","locales":"","content":" global wrapper \n"}<br>{"index": {"_id": 1413}}<br>{"title":"How to Use Fuzzy Searches in Elasticsearch","seo_title":"","url":"\/blog\/found-fuzzy-search","author":{"name":"Andrew Cholakian"},"date":"December 17, 2013","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. Elasticsearch's Fuzzy query is a powerful tool for a multitude of situations. Username searches, misspellings, and other funky problems can oftentimes be solved with this unconventional query. In this article we clarify the sometimes confusing options for fuzzy searches, as well as dive into the internals of Lucene's FuzzyQuery. \n"}<br>{"index": {"_id": 1414}}<br>{"title":"Logstash Collectd Input Plugin","seo_title":"","url":"\/blog\/logstash-collectd-input-plugin","author":{"name":"Aaron Mildenstein"},"date":"December 17, 2013","category":"Engineering","locales":"","content":" A few weeks ago I finished the initial release of the Logstash collectd input plugin. I'm really excited about this new feature! Some of you may be wondering why we would go to this effort, seeing how collectd data isn't exactly, well, . We consider any data that has a corresponding timestamp to be an event in Logstash. The data collectd sends is also timestamp + metric data. It will fit right alongside your other log data as a valuable companion. Now you can see if there's a corresponding change in disk I\/O or CPU load when you see certain log entries, or vice versa! The possibilities are vast! I can't wait to hear how you use this plugin to help visualize your data! collectd configuration The simplest way to get started is to configure collectd. You may or may not already have a collectd setup where you are, but your configuration file could be as simple as this: Hostname \"host.example.com\" LoadPlugin interface LoadPlugin load LoadPlugin memory LoadPlugin network <Plugin interface> Interface \"eth0\" IgnoreSelected false <\/Plugin> <Plugin network> <Server \"10.0.0.1\" \"25826\"> <\/Server> <\/Plugin> These options will send collectd information consisting of cpu load, memory stats, and network traffic information via UDP to the IP 10.0.0.1 on port 25826. For your own setup just replace 10.0.0.1 with the IP or hostname of your Logstash instance. The collectd plugin will populate the Logstash event host field with whatever is in the \u201cHostname\" directive rather than what reverse lookup finds. If otherwise unset, the default configuration will send values every 10 seconds. You can learn more about collectd configuration . This example is only a tiny sample of the kind of plugins and configurations collectd has to offer. A comprehensive list can be found . As with Logstash, you can write your own plugins for collectd so there are virtually endless possibilities! Logstash configuration Now that we have our collectd ready to send let's configure our Logstash instance input { collectd {} } Yep, that's it. Pretty crazy, right? We try to come up with sane defaults for everything. The full configuration explanations are . Let me explain some important ones. So, what is the result of this little example? I ran this test on my 2013 MacBook Air, with the data coming from a nearby computer with 2 Ethernet ports and 16G of memory. This is traffic from a single box over a 1 hour period. As you can see from this graph the memory is broken down into blocks: , , , . The CPU load histogram should be fairly self-explanatory, as are the network I\/O charts. You can clearly see peaks every 5 minutes in network traffic on EN1 with little other traffic usually. The version of Kibana I am using here (as of 16 Dec 2013) was downloaded straight from the master branch on GitHub and is not an officially released version. I needed this version as it enabled me to do derivative graphing, where each subsequent point is the difference between the current and previous values. This is necessary with network values as collectd measures them as it simply sends the counter values from the kernel store (similar to SNMP network data). If you need this feature now you too can use the most current development version. The release of Kibana coming in Jan 2014 (coinciding with ES 1.0 release) will have this feature. The stats themselves are unimpressive, seeing how they are from a personal server on home network with limited traffic. So I fired up , the collectd traffic generator. This was the result: Keeping in mind that this was tested on a MacBook Air I thought it was a pretty good show: 3000 events per second. If I had configured servers to send an average of 30 events every 10 seconds (3 events per second) that amounts to my laptop being able to process a continuous stream of events from 1000 servers! So, there's a brief introduction to the collectd plugin. Happy Logstashing! \n"}<br>{"index": {"_id": 1415}}<br>{"title":"New in Logstash 1.3: Elasticsearch Index Template Management","seo_title":"","url":"\/blog\/new-in-logstash-1-3-elasticsearch-index-template-management","author":{"name":"Aaron Mildenstein"},"date":"December 13, 2013","category":"","locales":"","content":" For a long time in the Logstash community we\u2019ve been advising users to apply an index mapping template. There are a number of compelling reasons to do this, including: Not having that last option set has resulted in a near-constant stream of similar questions, \u201cWhy do the terms break up on hyphens?\u201d and others of this sort. To answer these questions and prevent future questions like it from being asked, it became one of the first tasks I was assigned to work on as an employee at Elasticsearch. Important note The plugin uses Java API calls to manage the template, while the plugin uses REST API calls. With this comes an important caveat. In order to use template management with the plugin you must be using version 0.90.5 or newer. The Java API calls did not exist prior to that. If you attempt to use Logstash v1.3+ with a version of Elasticsearch older than 0.90.5 with the output plugin the template management features will not work and there will be a stack trace in the log files indicating the absence of those API calls. The REST API has no such constraints. If you are using the output with an older version of Elasticsearch it will still attempt to assign the template. Some new template options may not exist in very old versions of Elasticsearch, so be sure to upgrade. Upgrading is good. You want all of the performance benefits and new features that come with new releases, right? Configuration options. Common to both the and plugin are the following options : The option is boolean and is only used to disable the automatic template feature since it is on by default. Who would use this feature? Why wouldn\u2019t you want the awesomeness of automatic template management? One such reason might be that you have dynamically named indices. For example, if you want a different index name for production logs than staging, but in the same Elasticsearch cluster, you could configure that in Logstash: output { elasticsearch { cluster => \"mycluster\" manage_template => false index => \"%{segment_name}-logstash-%{+YYYY.MM.dd}\" } } In this example the index is determined in part by date, and in part by a variable, . When using complex index names we recommend setting the template manually. The option determines what name the template will be stored as in Elasticsearch. The default is . There is an important caveat to note with this setting. If you change the option in a fully configured and running system you\u2019ll still have a template stored under that name. In this case you may want to clean out the old template so it\u2019s not left around. curl -XDELETE http:\/\/localhost:9200\/_template\/OLD_template_name?pretty where is the previous template name. The configuration option is useful if you want to use the template engine but provide your own template instead of the included one. An example might be: output { elasticsearch { cluster => \"mycluster\" template => \"\/path\/to\/mytemplate.json\" } } Because the default is to manage templates, this configuration would read the JSON from the indicated file and attempt to upload the template if there isn\u2019t one already there. This brings me to\u2026 The option will always overwrite the indicated template in Elasticsearch with either the one indicated by or the included one. This option is set to by default. If you always want to stay up to date with the template provided by Logstash, this option could be very useful to you. Likewise, if you have your own template file managed by puppet, for example, and you wanted to be able to update it regularly, this option could help there as well. Conclusion Hopefully this helps make the configuration options more clear. Happy Logstashing! \n"}<br>{"index": {"_id": 1416}}<br>{"title":"Logstash 1.3.1 Released!","seo_title":"","url":"\/blog\/logstash-1-3-1-released","author":{"name":"Jordan Sissel"},"date":"December 12, 2013","category":"Engineering","locales":"","content":" Hello friends! We have released with lots of new fixes and features. You can , but I\u2019d like to highlight two of the new features, both of which were implemented by . First, in our mission to make it easy to integrate with lots of tools, we have a new input plugin, collectd. This plugin lets you receive metrics from agents with logstash and ship them anywhere you want. Want to know more? Check out the . Second, as a way to make logstash have the best possible default behavior for the most users, we now have logstash providing its own . This index template was built to try and solve some common problems for users by using better default analyzers and mappings specific to logging use cases. To demonstrate how this new feature works, let\u2019s look at some apache logs in Kibana. I\u2019ve parsed these apache logs with the following logstash config: filter { grok { match => { \"message\" => \"%{COMBINEDAPACHELOG}\" } } date { match => [ \"timestamp\", \"dd\/MMM\/yyyy:HH:mm:ss Z\" ] } } The filter configuration above uses grok with the built-in apache log pattern to parse apache logs into separate fields such as the request path, http response code, bytes sent, user agent, etc. The second filter takes the original timestamp field in the apache log and parses it to be used as the canonical timestamp of the event \u2013 this gives you more accurate search results over time and also lets you ingest old log data correctly. Now, a common search pattern is to ask for the top N of something. In Kibana, you can either use the \u2018top N\u2019 query or you can use a pie chart, depending on your goals. In this example, I\u2019ll just use a pie chart. Adding a pie chart with mode \u2018terms\u2019 on the \u2018request\u2019 field gets me this: Most folks, in this situation, sit and scratch their heads, right? I know I did the first time. I\u2019m pretty certain \u201cdocs\u201d and \u201ccentralized\u201d aren\u2019t valid paths on the logstash.net website! The problem here is that the pie chart is built from a . With the default text analyzer in elasticsearch, a path like \u201c\/docs\/1.3.1\/filters\/\u201d becomes 3 terms {docs, 1.3.1, filters}, so when we ask for a terms facet, we only get individual terms back! Index templates to the rescue! The we provide adds a \u201c.raw\u201d field to every field you index. These \u201c.raw\u201d fields are set by logstash as \u201cnot_analyzed\u201d so that no analysis or tokenization takes place \u2013 our original value is used as-is! If we update our pie chart above to instead use the \u201crequest.raw\u201d field, we get the following: Much better! And because we still index both the terms and the not-analyzed parts for each field, you can still do simple term queries like \u201crequest:docs\u201d to find all requests with \u2018docs\u2019 in the text. I hope this helps explain the new feature. Happy logstashing! \n"}<br>{"index": {"_id": 1417}}<br>{"title":"This Week in Elasticsearch - December 11, 2013","seo_title":"","url":"\/blog\/2013-12-11-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"December 11, 2013","category":"","locales":"","content":" Welcome to\u00a0. In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the GitHub repositories, as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Also, do not miss our webinar tomorrow! Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, as well as news about Logstash and Kibana. Slides Where to find UsFrance will speak at the . David's talk will cover all things Elasticsearch, including new features in 1.0. Doors open at 7:15 PM. Israel The first ever will take place on December 30th, beginning at 7 PM. Join Elasticsearch core developer , who will present on what's new in Elasticsearch 1.0, and Itamar Syn-Hershko, who will discuss Monitoring online conversation at scale using Elasticsearch. Netherlands will talk about Elasticsearch at in Rotterdam at the 9th of January. Where to Find You Our Community Manager, Leslie Hawthorn, is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1418}}<br>{"title":"Securing Your Elasticsearch Cluster","seo_title":"","url":"\/blog\/found-elasticsearch-security","author":{"name":"Alex Brasetvik"},"date":"December 09, 2013","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud.A Brief Overview of Running Elasticsearch SecurelyElasticsearch does not perform authentication or authorization, leaving that as an exercise for the developer. This article gives an overview of things to keep in mind when you configure the security settings for your Elasticsearch cluster, providing users with (limited) access to your cluster when you cannot necessarily (entirely) trust them. : Elastic has released , a product which provides comprehensive security for Elasticsearch, including encrypted communications, role-based access control, AD\/LDAP integration and Auditing. The following article was authored before Shield was available. \n"}<br>{"index": {"_id": 1419}}<br>{"title":"This Week in Elasticsearch - December 04, 2013","seo_title":"","url":"\/blog\/2013-12-04-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"December 04, 2013","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to\u00a0. In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the GitHub repositories, as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, as well as news about Logstash and Kibana. Slides Where to find UsFrance Israel The first ever will take place on December 30th, beginning at 7 PM. Join Elasticsearch core developer , who will present on what's new in Elasticsearch 1.0, and Itamar Syn-Hershko, who will discuss Monitoring online conversation at scale using Elasticsearch. Netherlands will present at the Open Source Conference in Amsterdam on December 6th. Shay's talk will start at 4:05 PM. United States Where to Find You Our Community Manager, Leslie Hawthorn, is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1420}}<br>{"title":"How the World is Using Elasticsearch","seo_title":"","url":"\/blog\/how-the-world-is-using-elasticsearch","author":{"name":"Steven Schuurman"},"date":"December 03, 2013","category":"News","locales":"","content":" It's been just over a year since Elasticsearch Inc was born, and about 3.5 years since our CTO, Shay Banon, first released Elasticsearch. From that time to now, we've brought almost 40 developers on board to grow and maintain the ecosystem around Elasticsearch, Logstash and Kibana, and we've seen our software downloaded almost half a million times per month. Just a week ago, we hit the memorable milestone of 5,000,000 downloads, an impressive number by anyone's standard. The fact that nearly 4,000,0000 of those were downloaded over the last 12 months, and that number is growing at a rate of nearly 500,000 a month makes it even more special. Elasticsearch, Logstash and Kibana are on fire, baby! Members of all startups will consistently tell you how proud they are of their world-changing technology, phenomenal growth and market traction, and we are - of course - no exception. However, we'd like you to hear these things from our customers and our users, not from us. To that end, we've had a robust case study program going for the past few months, leading to some pretty amazing stories of how Elasticsearch has helped companies create new revenue streams, improve their customer interaction, create stellar new application functionality and save money. Today, we'd like to share some of these case studies with you and, more importantly, to ask for you to let us know how you're using Elasticsearch. \u00a0 Elasticsearch Powers Social, ECommerce, Education and Much More\u2026 We've seen a number of compelling use cases for Elasticsearch across the full spectrum of social companies, including: Klout If you're one of the many household names using Klout to create campaigns that target social influencers, you're using Elasticsearch. at this case study to find out how Elasticsearch made it possible for Klout to provide their forthcoming self-service option to their customers, which Klout predicts will allow them to at least double their current revenues. XING XING is the leading business social network in Europe, with half its users located in Germany and the other half throughout the rest of Europe, Asia and Australia. XING has called their relationship with Elasticsearch a strategic partnership, far beyond a simple customer and service provider relationship. about how we've forged these deep ties with our customer by enabling XING to keep their users' updates flowing in real-time. GitHub Elasticsearch empowers GitHub's 4 million 'social coders' through providing search across GitHub's 8 million + code repositories. The GitHub team also makes use of Elasticsearch to monitor for abuse using some fairly clever logging hacks. You can get all the details in our . \u00a0 Focusmatic Focusmatic provides its customers with brand insights from across all aspects of the social web: blogs and micro-blogging sites, video content, news outlets and social networks. Thanks to Elasticsearch, Focusmatic was able to scale to meet the needs of their current customers and, more significantly, be prepared to meet the needs of many more new customers, all at 75% less cost. how Elasticsearch made it possible for Focusmatic to \u201ccontinue their business.\" Cogenta Cogenta provides retail market data to high-end brand retailers in Europe, with plans currently underway to expand into 20 countries worldwide. Their real-time pricing intelligence platform tracks and analyzes competitive data on more than 20 million products. at how Elasticsearch helped Cogenta prepare for this customer base expansion at a 40% lower total cost of ownership. Datadog Datadog is a SaaS monitoring service startup for IT, operations and development teams that enables these teams to better analyze metrics and events, ensuring their operations continue smoothly. By using Elasticsearch, Datadog was able to scale to take on larger customers who produce 500x more events than Datadog could originally handle. You can how Elasticsearch helped Datadog increase their event handling capacity by 11x. How Are You Using Elasticsearch? We are always excited to hear from anyone using Elasticsearch: we want to know why you chose Elasticsearch, plus how it has made life easier for you and better for your customers. anytime and share your story. \n"}<br>{"index": {"_id": 1421}}<br>{"title":"1.0.0.Beta2 Released","seo_title":"","url":"\/blog\/1-0-0-beta2-released","author":{"name":"Clinton Gormley"},"date":"December 02, 2013","category":"Engineering","locales":"","content":" Today we are delighted to announce the release of , the second beta release on the road to 1.0.0 GA. The new features we have planned for 1.0.0 have come together more quickly than we expected, and this beta release is chock full of shiny new toys. Christmas has come early! We have added: Please , try it out, break it, figure out what is missing and . Our next release will focus on cleaning up inconsistent APIs and usability, plus fixing any bugs that are reported in the new functionality, so your early bug reports are an important part of ensuring that 1.0.0 GA is solid. This is a beta release \u2013 it is not production ready, features are not set in stone and may well change in the next version, and once you have made any changes to your data with this release, it will no longer be readable by older versions! Snapshot \/ Restore While it has always been possible to backup a live index on Elasticsearch, the process was a bit finicky. The long awaited snapshot\/restore API makes it easy. First, define a \u2009\u2014\u2009the place where your backups will live: curl -XPUT 'http:\/\/localhost:9200\/_snapshot\/my_backup' -d '{ \"type\": \"fs\", \"settings\": { \"location\": \"\/mount\/backups\/my_backup\" } }' Currently we support the shared filesystem () repository, which needs to be writable by all nodes. In the future we will add support for S3, HDFS, GlusterFS, Google Compute Engine and Microsoft Azure. With the repository in place, you can tell Elasticsearch to create a snapshot named with: curl -XPUT localhost:9200\/_snapshot\/my_backup\/snapshot_1 You can snapshot the whole cluster or just specific indices. The best part is that \u2009\u2014\u2009it only copies the segments that have changed since the last snapshot was made. This makes the snapshotting process faster and lighter (you can snapshot every 5 minutes if you want to) and uses up less storage in the repository. You can restore the whole cluster, with or without persistent cluster settings, or just individual indices: curl -XPOST localhost:9200\/_snapshot\/my_backup\/snapshot_1\/_restore Later on we plan on making cross data-center replication possible by adding the ability to do incremental restores into a read-only index. You can . API JSON is a great\u2026 for computers. But at 3 AM when you\u2019re trying to figure out what is happening in your cluster, we humans prefer a simpler text format, easier to read and use with command line tools like and . The new API is the system administrator\u2019s friend: \u2009\u2014\u2009it formats the results in a columnar fashion for easy reading and parsing. For instance, to find out which indices are status : curl localhost:9200\/_cat\/indices | grep ^yell yellow foo 5 1 4 0 17kb 17kb Column headers are not returned by default, but you can request them by adding the parameter to the query string: curl localhost:9200\/_cat\/recovery?v index shard target recovered % ip node wiki1 2 68083830 7865837 11.6% 192.168.56.20 Adam II wiki2 1 2542400 444175 17.5% 192.168.56.20 Adam II Above we can see that two shards are recovering after a node failure, and that they are 12% and 18% complete, respectively. There are endpoints for many admin APIs, including allocation, indices, nodes, and shards. See the for details. Aggregations Aggregations are \u201cfacets reborn\u201d. Facets are amazingly powerful\u2009\u2014\u2009they allow you to summarise vast amounts of data in the context of a user\u2019s query on the fly, without the need for slow batch precalculations. However, the way they are implemented limits them in two important ways: Aggregations change all this. There are two types of aggregation (or ): aggregators which allow you to divide documents up into separate buckets eg , , , , , etc and aggregators which perform some calculation on the documents in each bucket, eg , , etc. Buckets can be sub-divided into smaller buckets, and metrics can be calculated for any bucket at any level. In the following example, we run a query looking for all tweets which mention , count the most popular hashtags overall, count the number of tweets per day calculate the most popular hashtags per day: GET \/tweets\/_search { \"query\": { \"match\": { \"tweet\": \"elasticsearch\" } }, \"aggs\": { \"popular_hashtags_overall\": { \"terms\": { \"field\": \"hashtags\" } }, \"per_day\": { \"date_histogram\": { \"field\": \"date\", \"interval\": \"day\" }, \"aggs\": { \"popular_hashtags\": { \"terms\": { \"field\": \"hashtags\" } } } } } } Doing this with facets would have been unthinkable\u2009\u2014\u2009it would have required a separate query for every day! Now that this framework is in place, it makes it much easier to add new aggregations. And as soon as a new aggregation has been implemented, it can used immediately in combination with any of the other aggregations. Facets are not going away just yet. We want to give you time to migrate from facets to aggregations so both implementations will be available for the foreseeable future. Also facets have had many micro-optimizations added over the years to make them perform as well as they do. Aggregations are not yet as fast for the simple case, but we are working hard to squeeze more performance out of them. You can . Still to come Before the next release, we are going to be looking at tidying up inconsistencies and warts that have crept into our API. We want to make it clean, consistent, and as Do-What-I-Mean as possible. You can take a look at the issues we are considering . We welcome further discussion. Please download , try it out, and . \n"}<br>{"index": {"_id": 1422}}<br>{"title":"Disk-Based Field Data a.k.a. Doc Values","seo_title":"","url":"\/blog\/disk-based-field-data-a-k-a-doc-values","author":{"name":"Adrien Grand"},"date":"November 28, 2013","category":"Engineering","locales":"","content":" Elasticsearch is not just about full-text search, and many users are actually not using Elasticsearch for full-text search at all but for analytics though facets. This approach works well, but, as you probably know, faceting or sorting on a field requires loading field values into in-memory data structures that we call . It is very common that takes several (tens of) gigabytes of memory. Memory is rather cheap, so it is usually not a problem to get boxes with enough memory. However, this can raise issues at the JVM level: major garbage collections on a heap of several tens of gigabytes can easily take several seconds during which your application will be unresponsive. Careful JVM tuning can help prevent this issue, but ideally field data should be stored .Doc Values to the Rescue is a feature that will be available in the forthcoming Elasticsearch 1.0 release. You can already check it out in our . are a Lucene 4.x feature which allow for storing field values on disk in a column stride fashion, which is filesystem cache friendly and suitable for custom scoring, sorting or faceting, exactly like field data. It was only natural to build a new field data backend based on , and this new implementation has several benefits compared to the traditional field data implementations that Elasticsearch builds by uninverting the inverted index: On the other hand, are going to make indices bigger \u2014 unless it allows for not indexing the field, eg. if the field is used solely for sorting \u2014 and intensive work loads such as faceting will be slightly slower.When Should I Use Doc Values? can be used as a drop-in replacement for uninverted in most cases, but there are a few cases where they can be particularly helpful: How to Enable Doc Values are an index time decision, so they need to be enabled in the mappings before indexing the first document. Here is an example of a string field definition that can be used for sorting and faceting, but not searching:\"my_field\": { \"type\": \"string\", \"index\": \"no\", \"fielddata\": { \"format\": \"doc_values\" } } For now, doc values are supported on non-analyzed string fields and numeric fields (byte, short, integer, long, float, double, date).As you can see, fields don't need to be indexed to enable . And once are enabled, all operations working on top of like sorting or faceting will transparently use under the hood.We would love to get your feedback on . Try out our latest beta release and ! \n"}<br>{"index": {"_id": 1423}}<br>{"title":"This week in elasticsearch - November 27, 2013","seo_title":"","url":"\/blog\/2013-11-27-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"November 27, 2013","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to\u00a0 . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the GitHub repositories, as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, as well as news about Logstash and Kibana. Slides Where to find Us France David Pilato will speak at Drupagora on December 5th, covering . David's talk will begin at 3 PM. Netherlands will present at the Open Source Conference in Amsterdam on December 6th. Shay's talk will start at 4:05 PM. Spain will speak at the NoSQL matters conference in Barcelona on . Clinton's talk takes place on Saturday, November 30th at 10:30 AM, and the conference runs November 29-30th. United Kingdom United States Where to Find You Our Community Manager, Leslie Hawthorn, is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1424}}<br>{"title":"Similarity in Elasticsearch","seo_title":"","url":"\/blog\/found-similarity-in-elasticsearch","author":{"name":"Konrad Beiske"},"date":"November 26, 2013","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud.A Brief Introduction to the Similarity Models AvailableElasticsearch now supports replacement of the default similarity model. In this article we will look into what a similarity model is with a special focus on tf-idf and bm25. \n"}<br>{"index": {"_id": 1425}}<br>{"title":"Redesigned Percolator","seo_title":"","url":"\/blog\/percolator-redesign-blog-post","author":{"name":""},"date":"November 25, 2013","category":"Engineering","locales":"","content":" The percolator is essentially search in reverse, which can by confusing initially for many people. This post will help to solve that problem and give more information on the redesigned percolator. We have added a lot more features to it to help users work with percolated documents\/queries more easily. In normal search systems, you store your data as documents and then send your questions as queries. The search results are a list of documents that matched your query. With the percolator, this is reversed. First, you store the queries and then you send your 'questions' as documents. The percolator results are a list of queries that matched the document. So what can do percolator do for you? The percolator can be used for a number of use cases, but the most common is for alerting and monitoring. By registering queries in Elasticsearch, your data can be monitored in real-time. If data with certain properties is being indexed, the percolator can tell you what queries this data matches. For example, imagine a user \"saving\" a search. As new documents are added to the index, documents are percolated against this saved query and the user is alerted when new documents match. The percolator can also be used for data classification and user query feedback. So how does it work in Elasticsearch? Data and queries are two separate things, but are both expressed in JSON. By using this common property, we can send queries to Elasticsearch and they will be stored as documents...but that alone isn't enough. Elasticsearch needs to treat it as a query, not a document. The current percolator system stores queries in a dedicated index. Whenever queries are registered with the percolator index, the query part is extracted and turned into a real query, which is kept around for later usage via the percolate api. The percolate api is the equivalent to the search api for percolating. Also the percolate api is one of the APIs that is fully real-time, meaning that as soon as a query is registered with the percolator it available for use. Let take a look at the percolator already available in many Elasticsearch releases: # Register a query for <= 0.90.x percolator. curl -XPUT 'localhost:9200\/_percolator\/my-index\/my-id' -d '{ \"query\" : { \"match\" : { \"body\" : \"coffee\" } } }' # <= 0.90.x percolate api curl -XPUT 'localhost:9200\/my-index\/my-type\/_percolate' -d '{ \"doc\" : { \"title\" : \"Coffee percolator\", \"body\" : \"A coffee percolator is a type of ...\" } }' The system index that is used to register a query as shown in the first request in the above sample is a single primary shard index that has replica shards on each data node and these settings are fixed. The last request in the above sample sends a percolate request to Elasticsearch and will yield the following result: { \"ok\" : true \"matches\" : [\"my-id\", ...] } This image below illustrates how a client executes a percolate request. It doesn't matter where the percolate request is executed, because each data node has a _percolate shard (p1 squares), that sits next to all the other shards (other squares) a data node may have. The current percolator has been around since ES version and since then more people have started using it with more and more queries. The percolator works fine until a certain amount of queries are store in it, but then the percolate execution time begins to increase to a level where people are less comfortable using it in production. It scales roughly linear to the number of registered queries. In order to get around this limitation, queries can be partitioned against multiple indices or the percolate query mechanism can be used in order to reduce the percolator execution time. Even with these workarounds, the current percolator has fundamental scaling limits, which becomes obvious when people are percolating massive amounts of queries. So we had to go back to the drawing board and come up with a different solution for how to scale the percolator. The good news is that we did and came up with an alternative solution which we already included in our first 1.0 beta release! So what has changed in the percolator? The core of the percolator didn't change that much. You still register percolator queries as in the old system, and percolate documents with the percolate api. What has changed is where we store the percolate queries. We dropped the reserved index and instead percolate queries are now be stored in any index under the type. This means that any index can be used as a percolate index, which allows for more flexibility when it comes to scaling. The single shard index restriction has been removed. Each percolator index can be configured with the number of shards necessary to hold your percolator queries. The percolate api has been changed to execute on any index and parallelize the execution between all the shards within that index. The percolate api can now percolate documents against multiple indices and aliases. The percolate API also now supports and support, just like the search API. This image illustrates how the redesigned percolator works. Here the index has a type and holds registered queries. It is just an ordinary index with 3 primary shards (green squares) and a replica shard for each primary shard (white squares). The registered queries are divided between shards and then the percolate request is executed in parallel on each node that holds these shards. Obviously, this large-scale redesign means breaking backwards compatibility with the currently released percolator. Breaking changes are a good time to make improvements to existing structures: for example, the percolator response has changed with some new usability improvements. If you're already using the percolator, you can just upgrade to 1.0 and re-import your queries from the index to an index of your choice. Here's some code to illustrate the new functionality: # Register a query with the redesigned percolator curl -XPUT 'localhost:9200\/my-index1\/.percolator\/my-id' -d '{ \"query\" : { \"match\" : { \"body\" : \"coffee\" } } }' # Execute a percolate request with the redesigned percolator curl -XGET 'localhost:9200\/my-index1\/my-type\/_percolate' -d '{ \"doc\" : { \"title\" : \"Coffee percolator\", \"body\" : \"A coffee percolator is a type of ...\" } }' The last request in the above sample to the percolate api will yield the following result: { \"took\" : 19, \"_shards\" : { \"total\" : 2, \"successful\" : 2, \"failed\" : 0 }, \"count\" : 4, \"matches\" : [ { \"_index\" : \"my-index1\", \"_id\" : \"my-id\" }, ... ] } The first major change to the percolate response is that we now include a response header. Just like with the search api, we show you how many shards the request should have gone to, how many shards were actually visited and how many shards failed. The biggest change in the response is how percolate query matches are represented. Instead of list all query ids that have matches in a string array, there is now a match object that encapsulates the query id and the concrete index the query resides in. The part is important now because the same query id can be used in multiple indices. We also include a total count in the response, which just tells how many queries matched the percolated document. By default all matching query ids are returned, but that is controllable. The new features are described in our . So, are you curious about the redesigned percolator? Try out our latest beta release and ! \n"}<br>{"index": {"_id": 1426}}<br>{"title":"This Week in Elasticsearch - November 21, 2013","seo_title":"","url":"\/blog\/2013-11-2-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"November 21, 2013","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to\u00a0 . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the GitHub repositories, as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, as well as news about Logstash and Kibana. Slides Where to find Us France David Pilato will speak at Drupagora on December 5th, covering . David's talk will begin at 3 PM. Netherlands Norway and will speak at the on November 26th. Full details on their talks and other presentations by community members in Oslo will be published next week. Spain will speak at the NoSQL matters conference in Barcelona on . Clinton's talk takes place on Saturday, November 30th at 10:30 AM, and the conference runs November 29-30th. United Kingdom Where to Find You Our Community Manager, Leslie Hawthorn, is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1427}}<br>{"title":"Keeping Elasticsearch in Sync","seo_title":"","url":"\/blog\/found-keeping-elasticsearch-in-sync","author":{"name":"Andrew Cholakian"},"date":"November 19, 2013","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. One of the trickiest parts of integrating Elasticsearch into an existing app is figuring out how to manage the flow of data from an authoritative data source, such as an SQL database, into Elasticsearch. In most cases this means utilizing Elasticsearch's bulk API. It also implies designing an application to effectively make data available in an efficient, robust, on-time manner. This usually requires modifying an application's workflow to replicate data in batches. This article is a survey of various patterns for accomplishing this task. \n"}<br>{"index": {"_id": 1428}}<br>{"title":"This Week in Elasticsearch - November 14, 2013","seo_title":"","url":"\/blog\/2013-11-14-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"November 14, 2013","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to\u00a0. In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the GitHub repositories, as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Elasticsearch Core Elasticsearch EcosystemHere's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, as well as news about Logstash and Kibana. SlidesCheck out presentations from Lucene revolutions, talking about and . Also at the ruby user group in San Francisco. Last, talked about using .Where to Find UsAustraliaClinton Gormley will be speaking at the inaugural on November 18th and the on November 21st. Clinton will cover new features forthcoming in 1.0 and will be joined by other speakers from the Melbourne and Sydney community. We'll have full details for you next week.BelgiumIf you're heading to Devoxx Belgium 2013, be sure to check out on Elastify Your App: From SQL to NoSQL in Less than One Hour. David will speak on Wednesday, November 13th at 3:10 PM in Room 6. David will also give a lightning talk, Make Sense of Your (BIG) Data on Thursday, November 14th at 1:10 PM in Room 9. Devoxx Belgium runs from November 11-15 at the Metropolis Business Center in Antwerp.France Germany organizes the , and will be hosting a meetup on November 20th. The meetup begins at 6:45 PM.NetherlandsElasticsearch will be at the on November 20-22nd in Amsterdam. Stop by our table to say hello, and make sure to catch and Gerard de Vos' workshop on Elasticsearch, taking place on Wednesday, November 20th. Also you can easily join the on the 20th as well in the evening. Even if you attend the Cloudstack Collaboration Conference, feel free to come over, as the event starts a bit later.Norway and will speak at the on November 26th. Full details on their talks and other presentations by community members in Oslo will be published next week.Spain will speak at the NoSQL matters conference in Barcelona on . Clinton's talk takes place on Saturday, November 30th at 10:30 AM, and the conference runs November 29-30th.United Kingdom United States Where to Find YouOur Community Manager, Leslie Hawthorn, is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, .Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head.TrainingsIf you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1429}}<br>{"title":"Sense - a Cool JSON Aware Interface to Elasticsearch","seo_title":"","url":"\/blog\/found-sense-a-cool-json-aware-interface-to-elasticsearch","author":{"name":"Florian Hopf"},"date":"November 13, 2013","category":"","locales":"","content":" \u00a0This article will introduce you to Sense, a Chrome plugin for Elasticsearch. It offers autocompletion, code highlighting and formatting and can help you with exploring Elasticsearch. \n"}<br>{"index": {"_id": 1430}}<br>{"title":"0.90.7 released","seo_title":"","url":"\/blog\/0-90-7-released","author":{"name":"Clinton Gormley"},"date":"November 13, 2013","category":"","locales":"","content":" Today we are happy to announce the release of , which is based on Lucene 4.5.1. This is the current stable release in the 0.90 series and we recommend upgrading. You can download it . This is largely a bug fix release. Most changes deal with edge cases (you can read about them in the ) but there are a few important fixes which are worth mentioning: Norms and memory use In an effort to make Elasticsearch as responsive as possible, 0.90.6 introduced a change which loaded all into memory whenever a new merged segment was created. For some users, this turned out to be an optimization too far. Field norms provide statistics about field length and are an important variable in TF\/IDF, Lucene\u2019s default similarity algorithm. However, they are only useful when you actually run a full-text query on a field. Many users, especially our Logstash users, store many text fields in Elasticsearch which they never search on, which means that we never need to load the norms for these fields. This \u201ceager\u201d loading of norms used up much more RAM than before. In 0.90.7 we reverted this change (see ) and in a later version we will add a per-field option which will allow you to opt in to eager norms loading, where it makes sense for you.\u00a0See . Lucene and memory use A was causing a delay in cleaning up old files which manifested itself in increased memory use, especially when using the store. This bug has been fixed in Lucene 4.6 and the fix has been backported to this release as well.\u00a0See . Postings highlighter The newly added Postings highlighter got off to a false start. Highlighting worked just fine... until there was more than one segment. (Note: you can never have too many tests). See . It also failed on fields whose index name and field name were different. See . And finally, an enhancement! The postings highlighter now also supports a separate . See . Other Details of other changes are available in the . Many thanks to everybody who submitted bug reports and pull requests. Your help is greatly appreciated. \n"}<br>{"index": {"_id": 1431}}<br>{"title":"Presenting Play: A Preview of an Elasticsearch Playground","seo_title":"","url":"\/blog\/found-presenting-play","author":{"name":"Alex Brasetvik"},"date":"November 13, 2013","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. \n"}<br>{"index": {"_id": 1432}}<br>{"title":"Building Enterprise Content Management Systems on Elasticsearch","seo_title":"","url":"\/blog\/building-enterprise-content-management-systems-on-elasticsearch","author":{"name":"Leslie Hawthorn"},"date":"November 12, 2013","category":"","locales":"","content":" Today we\u2019re bringing you another story of Elasticsearch\u2019s use in the field: Vodori and Pepper, their home grown enterprise content management system based on Alfresco and Elasticsearch. is a full service digital agency that blends Strategy, Design, Technology, and Product to deliver high-velocity digital global marketing solutions. They are based in Chicago, Illinois, US and they\u2019re the gracious hosts of the . Grant Gochnauer Vice President and Co-Founder of Vodori was kind enough to share their story with us. Two and a half years ago, Vodori set out to redesign its enterprise content management system, Pepper, to delivery high-velocity digital marketing to our customers. With a global scale and complex content management and distribution requirements, Pepper had to be flexible, scalable, and of course provide rich search capabilities. In 2010, we evaluated technologies that would enable us to meet our product goals and decided on two core technologies: Alfresco and Elasticsearch. Why Elasticsearch? Before diving into our decision to use Elasticsearch, it helps to understand a bit more about some of our requirements. Content management systems base their data storage on an allowing developers to specify how content types are defined and relate to one another in a system. For example, we might have an object called \u201cDocument\u201d that contains properties such as \u201ctitle\u201d and \u201cfilename\u201d. We can then extend \u201cDocument\u201d with a child object in our object model \u2013 a \u201cWebDocument\u201d. It has additional properties such as \u201cseoDescription\u201d and \u201curl\u201d. \u201cWebDocument\u201d inherits the properties defined on \u201cDocument\u201d. Pepper provides an object model as part of the core product but allows (and encourages) implementation teams to extend this model depending on the business requirements for the solution being delivered. Alfresco provides its own \u201cobject model\u201d out of box and we extend this concept significantly for Pepper in our searching paradigm. Because project implementations can contain widely varied content types and properties, we have to support the myriad ways our customers may want to search and filter content. While Alfresco implements CMIS, the industry standard for interacting with content data (creating, updating, searching), the performance did not meet Pepper\u2019s specific needs. Our challenge: how to get content out of Alfresco (and by extension Pepper) in such a way that: Enter Elasticsearch. After evaluating a number of technology options, we selected Elasticsearch because it met our requirements and also because of the trust we had in the people and product gained through the successful use of Shay Banon\u2019s previous technology, Compass. By introducing this facade layer on top of Alfresco, we not only introduced a high-performance and scalable way to interact with our data, it also gave us complete control of how we search content. Let\u2019s look at an example: Pepper Library One of the many ways users can find and interact with content is through the Pepper Library. We allow customers to toggle a number of parametric filters as the results appear through an endless scroll list. Elasticsearch provides everything we need to implement this user experience out of the box. When users toggle filters along the left panel, we simply construct the appropriate Elasticsearch query using the TermsFilter combined with a BoolFilter and Elasticsearch immediately provides the data we need. We also provide for free-text search by using the search box in the upper right corner of the Library. Thankfully this is also extremely easy to do with Elasticsearch \u2013 even when searching with the left panel filters applied. If a user types in a search query, we simply append a Match Query to the existing BoolFilter in our previous query. Elasticsearch happily returns what we asked for. We can further customize the way free-text search works by implementing custom Index and Search analyzers for each property. Modelling Content in Elasticsearch One of the challenges we faced when building our architecture was making it easy for product engineering to create content models without worrying about the details of Elasticsearch. Similarly, we wanted to provide a layer of abstraction so that our implementation teams could focus on the client solution and not on the intricacies of Elasticsearch mapping and index creation. We built a framework that allows us to annotate our Java content object model in such a way that generates Elasticsearch mappings that abstract the complexities from our engineers. Our framework provides the contract between our product API\u2019s and Elasticsearch. In this example, \u201clogicalName\u201d represents the filename of a document exposed to the end-user which is different than the system generated physical filename we store in Alfresco. With our @ElasticSearchProperty annotation, we can specify the following: When using a combination of \u201cfilterable\u201d and \u201cfreeTextSearchable\u201d we index the value in a \u201cmulti_field\u201d type in Elasticsearch so that we can use either the analyzed or non-analyzed value. Our framework is smart enough to know when to use each. Parent child relationships The other Elasticsearch modelling feature we use heavily is Parent\/Child relationships. We needed to support the ability to manage and distribute a single document in many different distribution channels (Website, iPad, social media, etc). By leveraging the Parent\/Child relationships, we can index a single source document which represents the canonical binary asset and an \u201cindex card\u201d that represents a pointer back to the source document with additional descriptor metadata. We can then create additional index card objects in each channel of distribution, all pointing back to the same source document. The Index card becomes the parent document with the source document becoming the child document. Our framework also extends this idea with another annotation on the child source document: So why would we want to use a parent\/child relationship in this way? Among other things, it allows us to write really interesting queries to fetch all content for a distribution channel while also filtering on values in the source document. Let\u2019s look at two examples. Our customers store product marketing and catalog data within Pepper. As we mentioned earlier, this content is leveraged across many different distribution channels. As a global marketing manager, I may need to search across the entire content ecosystem and find where a particular set of documents are being used. With Elasticsearch and our Parent\/Child relationships, we can execute queries that answer this question by leveraging the filter. We simply search for child documents with a specific attribute value (e.g. productCatalogId) and Elasticsearch will return all the parent documents. Parent documents represent our \u201cindex card\u201d which is specific to a distribution channel and contains specific usage metadata for that channel. { \"from\":0, \"size\":2, \"filter\":{ \"has_child\":{ \"type\":\"com.vodori.pepper.content.model.document.PepperWebpage\", \"query\":{ \"term\":{ \"productCatalogId\":\"CRX1234A\" } } } } } We also need to be able to serve and query content by distribution channel. For example, when our iPad application, Pepper Mobile, needs to fetch all the content approved for consumption from within the iOS application, we can perform this search using the filter. In this case, we want to find child \u201csource documents\u201d where the parent object has a specific attribute value such as a distributionChannelId value of 5. { \"from\":0, \"size\":2, \"filter\":{ \"has_parent\":{ \"type\":\"com.vodori.pepper.content.model.descriptor.PostDescriptor\", \"query\":{ \"term\":{ \"distributionChannel\":\"5\" } } } } } What\u2019s next for Pepper\u2019s usage in Elasticsearch? We have a number of new features on our roadmap that will be based on Elasticsearch. A few examples include: Wrapping up It has been really exciting to see the Elasticsearch product and team grow over the last two years. The Elasticsearch community has been fantastic and really reinforces the fact that we made the right decision on our choice to use Elasticsearch. We think that this technology will continue its growth into new industries and applications as more companies realize the power and flexibility of Elasticsearch. We are excited to be a part of that growth. \u00a0 \n"}<br>{"index": {"_id": 1433}}<br>{"title":"This Week in Elasticsearch - November 06, 2013","seo_title":"","url":"\/blog\/2013-11-06-this-week-in-elasticsearch","author":{"name":"Luca Cavanna"},"date":"November 06, 2013","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to\u00a0 . In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the GitHub repositories, as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, as well as news about Logstash and Kibana. Slides Check out presentation on and slides on . Both presentations were delivered at this week's . Where to find UsAustralia Clinton Gormley will be speaking at the inaugural on November 18th and the on November 21st. Clinton will cover new features forthcoming in 1.0 and will be joined by other speakers from the Melbourne and Sydney community. We'll have full details for you next week. Belgium If you're heading to Devoxx Belgium 2013, be sure to check out on . David will speak on Wednesday, November 13th at 3:10 PM in Room 6. David will also give a lightning talk, on Thursday, November 14th at 1:10 PM in Room 9. Devoxx Belgium runs from November 11-15 at the Metropolis Business Center in Antwerp. Estonia will explore at on Thursday, November 7th at 3:30 PM. Topconf runs November 6th and 7th in Tallinn. France Germany Ireland will present at on Thursday, November 7th at 2:45 PM. Lucene Revolution takes place November 4th - 7th in Dublin. Japan The Elasticsearch User Group in Japan will meet for a on November 12th in Tokyo. The meeting begins at 7 PM. Netherlands Elasticsearch will be at the on November 20-22nd in Amsterdam. Stop by our table to say hello, and make sure to catch and Gerard de Vos' workshop on Elasticsearch, taking place on Wednesday, November 20th. Norway and will speak at the on November 26th. Full details on their talks and other presentations by community members in Oslo will be published next week. Spain will speak at the NoSQL matters conference in Barcelona on . Clinton's talk takes place on Saturday, November 30th at 10:30 AM, and the conference runs November 29-30th. United Kingdom United States Where to Find You Our Community Manager, Leslie Hawthorn, is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Oh yeah, we're also\u00a0 . If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1434}}<br>{"title":"1.0.0.Beta1 released","seo_title":"","url":"\/blog\/1-0-0-beta1-released","author":{"name":"Clinton Gormley"},"date":"November 06, 2013","category":"","locales":"","content":" Today we are delighted to announce the release of , the first public release on the road to 1.0.0. The countdown has begun! You can . In each beta release we will add one major new feature, giving you the chance to try it out, to break it, to figure out what is missing and to tell us about it. Your use cases, ideas and feedback is essential to making Elasticsearch awesome. The main feature we are showcasing in this first beta is . This is a beta release - it is not production ready, features are not set in stone and may well change in the next version, and once you have made any changes to your data with this release, it will no longer be readable by older versions! Distributed percolation For those of you who aren\u2019t familiar with percolation, it is \u201csearch reversed\u201d. Instead of running a query to find matching docs, percolation allows you to find queries which match a doc. Think of people registering alerts like: . Percolation has been supported by Elasticsearch for a long time. In the current implementation, queries are stored in a special index which is replicated to all nodes, meaning that all queries exist on all nodes. The idea was to have the queries alongside the data. But users are using it at a scale that we never expected, with hundreds of thousands of registered queries and high indexing rates. Having all queries on every node just doesn\u2019t scale. Enter . In the new implementation, queries are registered under the special type within the same index as the data. This means that queries are distributed along with the data, and percolation can happen in a distributed manner across potentially all nodes in the cluster. It also means that an index can be made as big or small as required. The more nodes you have the more percolation you can do. We have removed the ability to percolate while indexing a document, as that didn\u2019t scale either. But we\u2019ve added a host of new features that makes percolation awesome. Check out the . Doc Values The most common problem that users have with Elasticsearch is with fielddata. In order to sort or facet on field values, those values need to be easily accessible. By far the fastest way of accessing field values is by loading them into memory, which is known as fielddata. Especially string fields can use large amounts of RAM and can cause slow garabage collection and even out of memory exceptions. The other big new feature in this release is the addition of doc values. With this new functionality, field values can be stored on disk at index time, instead of in memory. It\u2019s not as fast as holding fielddata in memory - facets take longer because they need to hit disk - but this is achieved with a fraction of the memory, meaning that you can now calculate facets, sort on fields or access field values in scripts for much larger datasets than was previously possible. Doc values need to be setup in the field mapping at index time, and work on numeric, geo and string values, both single and multi-valued. They cannot be enabled on analyzed string fields as that would require a second analysis phase. This may change in the future. Check out the . Stopwords disabled by default The analyzer, the default analyzer used by Elasticsearch, comes with stopwords enabled. Not only that, it uses English stopwords by default. It doesn't matter what language your text is in, or which full text field you're indexing, it'll have stopwords removed. This can produce unexpected confusion, like wondering why doesn't match anything, or why you can't find any plays called \"To be or not to be\". With modern hardware and queries like the , stopwords are less useful than they used to be. This release sets the default stopwords list for the analyzer to empty, meaning that no stopwords are removed by default. You can still enable stopwords where you want them, but you can do that where you choose to. For the sake of backwards compatibility, indices created with a previous version of Elasticsearch will continue to use the English stopwords list. Still to come There are three major new features still to come: Please , try it out, and let us know what you think. \n"}<br>{"index": {"_id": 1435}}<br>{"title":"Kibana 3: Milestone 4","seo_title":"","url":"\/blog\/kibana-3-milestone-4","author":{"name":"Rashid Khan"},"date":"November 05, 2013","category":"","locales":"","content":" Kibana 3: Milestone 4 has been released and brings with it a wealth of performance, usability and visualization enhancements. Let\u2019s take a look at a few of the significant changes. If you\u2019re still on Milestone 3, check out for even more new features. An all new look Kibana\u2019s panels have been overhauled to feature more prominent labeling, easier to use buttons and links, and an entirely new style. The changes result in improved usability, as well as a space efficient design that allows for great data density and a more consistent UI. Kibana\u2019s new look Consistent query and filter placement To improve UI harmony, the query and filter panels get their own collapsible, pull-down sections right under the navigation bar. There is no longer a need to place these essential panels yourself, as they\u2019re included in every dashboard by default. Like many of Kibana\u2019s features, they can be disabled entirely from the dashboard configuration dialog. 100% new time range selector If you\u2019re familiar with Kibana\u2019s 2 year history, you might know that there have been several time picker evolutions. The new time picker is a total rewrite that not only uses less space than the old one, but is simpler and easier to use. By moving this important component off the main dashboard, Kibana now has more room to devote to important data and charts. Plus, the new filter format implements Elasticsearch\u2019s so there\u2019s no need to reselect a time frame to move your time window: every search will update the window automatically. An all new time picker Filterable field list Find fields quickly and easily with the type-to-filter feature of the table. Filterable field lists Ad-hoc facets And, once you\u2019ve found those field,s analyze them quickly with ad-hoc terms facets. Simply click a field and select a visualization to see the top 10 term matches for that field. Exploration is even easier No need to add a panel. Pie chart on the fly! Dynamic dashboards and URL parameters Kibana 3: Milestone 4 can now take input via URL parameters! This much anticipated feature comes in two flavors: templated dashboards and scripted dashboards. Kibana 3: Milestone 4 ships with 2 examples designed to work flawlessly with Logstash and gives you a foundation to build your own dashboards with. Templated dashboards are easy to create by simply exporting your dashboard schema to a file, editing it and adding it to your app\/dashboards directory. For example, take this section from logstash.json () Templated dashboards use \u201chandlebar syntax\u201d to add dynamic section to the JSON based dashboard scheme. Here we\u2019ve replaced the contents of the query key with an expression that translates to: . Now we could access this dashboard with a URL such as More complex scripted dashboards Scripted dashboards are an even more powerful method of taking URL parameters, using all of the power of JavaScript to compose a complete dashboard object. An example, logstash.js () is included in app\/dashboards. Because scripted dashboards are entirely JavaScript, we can perform complex operations, like splitting URL parameters. For example, in this URL we are searching for , in the , and showing in the table. Note the important change from to in the URL: Go get it now Milestone 4 is a big step forward for both implementers and users. It is simultaneously more powerful and more simple. And, of course. Kibana continues to integrate seamlessly with Logstash, including the recently released . Kibana can be downloaded directly from elastic.co . Also, we\u2019re hiring Do you want to get paid to work on open source? Are you passionate about JavaScript, with a head full of data visualization ideas? We\u2019re way more interested in what you know and what you can do than where you live. . \n"}<br>{"index": {"_id": 1436}}<br>{"title":"Elasticsearch Internals: Networking Introduction","seo_title":"","url":"\/blog\/found-elasticsearch-networking","author":{"name":"Njal Karevoll"},"date":"November 05, 2013","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud.This article introduces the networking part of Elasticsearch. We look at the network topology of an Elasticsearch cluster, which connections are established between which nodes and how the different Java clients works. Finally, we look a bit closer on the communication channels between two nodes. \n"}<br>{"index": {"_id": 1437}}<br>{"title":"0.90.6 Released","seo_title":"","url":"\/blog\/0-90-6-released","author":{"name":"Clinton Gormley"},"date":"November 04, 2013","category":"Engineering","locales":"","content":" Today we are happy to announce the release of , which is based on Lucene 4.5.1. This is the current stable release in the 0.90 series and we recommend upgrading. You can download it . In this release there have been big improvements to highlighting including the new highlighter, automatic script reloading, better handling of edge cases associated with cluster-level changes, and many small bug fixes and enhancements which you can read about in the . Postings highlighter The new highlighter is faster, requires less disk space than the fast-vector-highlighter, and is \u201csentence aware\u201d which should result in more meaningful snippets. In order to use it, the field mapping must be configured with set to instead of the default . For instance: curl -XPUT localhost:9200\/my_index -d ' { \"mappings\": { \"my_type\": { \"properties\": { \"title\": { \"type\": \"string\", \"analyzer\": \"english\", \"index_options\": \"offsets\" } } } } } ' With the mapping setup correctly, we can index some documents: curl -XPOST localhost:9200\/my_index\/my_type\/_bulk -d ' {\"index\":{\"_id\": 1}} {\"title\": \"The quick brown fox jumped over the lazy dog\"} {\"index\":{\"_id\": 2}} {\"title\": \"Brown foxes do love jumping, especially over dogs\"} ' And search them: curl -XGET localhost:9200\/my_index\/my_type\/_search?pretty -d ' { \"query\": { \"match\": { \"title\": \"Jumping brown foxes\"} }, \"highlight\": { \"fields\": { \"title\": {} } } } ' Each result from the above request is accompanied by a nicely highlighted snippet: Other highlighting improvements Thanks go to Nik Everett, a frequent contributor to Elasticsearch, who has added the ability to specify a separate query just for highlighting (see ) and the ability to return a simple excerpt when there are no words that can be highlighted (see in ). More accurate terms facet Because terms facets are calculated by combining the results from multiple shards, it is possible that each shard has a different list, resulting in inaccurate global counts. This release introduces the parameter which allows you to fetch more results from each shard, while still returning only (default ) results to the user. Pulling more results from each shard reduces the inaccuracy in global counts. Reload scripts automatically Scripts are used in many APIs in Elasticsearch, eg for scoring, script fields, faceting etc. A script can either be specified in the request itself, or named scripts can be loaded from the directory on each node. Previously, changing configured scripts was a tiresome process which involved updating and restarting all nodes. Now, a new watcher will check for changes in the scripts directory every 60 seconds (configurable with ) and load new scripts, reload changed scripts or delete removed scripts automatically. See for more. Pretty is prettier This is a very simple change, but removes a common source of annoyance. Pretty-printed results now have a newline character appended to make console output easier to read. We hope you enjoy this new release. Please , and let us know what you think. \n"}<br>{"index": {"_id": 1438}}<br>{"title":"Elasticsearch and Hortonworks Partner","seo_title":"","url":"\/blog\/elasticsearch-and-hortonworks-partner-what-you-need-to-know","author":{"name":"Steven Schuurman"},"date":"October 31, 2013","category":"News","locales":"","content":" What You Need to KnowWe've got some exciting news to share around Elasticsearch and Hadoop. Elasticsearch and have strengthened their relationship by , which has resulted in Elasticsearch now being the first certified search vendor. With both Elasticsearch and Hortonworks being leaders in the open source space, this partnership will lead to a valuable integration between Elasticsearch and Hadoop that anyone using the open source products will benefit from. This is what Hortonworks said about our newly formed partnership:\u201cThe over 400,000 downloads a month is a testament to the level of trust put into Elasticsearch. Since Elasticsearch and Hadoop are such critical elements to the data analytics infrastructure for a huge number of users, we're excited by this opportunity to join together and reach beyond our users' expectations.\" Shaun Conolly, Vice President, Corporate Strategy at HortonworksElasticsearch's real-time data exploration, analytics, logging and search features combine really well with Hadoop and make for a powerful combination: very useful to anyone handling large volumes of data on a day to day basis. Why This MattersOur customers can now enhance their Hortonworks Hadoop based workflows with our rich query language, designed to help businesses ask better questions, get clearer answers and better analyze their business metrics, all in real-time. Elasticsearch plays well with all Hadoop distributions, including MapR, Cloudera, Pivotal HD and Amazon EMR, and we have plans to provide specific integration with Hortonworks' HDP platform. This is what Shay had to say about our partnership with Hortonworks:\u201cWe're moving quickly here at Elasticsearch. Just a few weeks ago, we announced , so it's exciting to announce Elasticsearch now works with Hortonworks' HDP Hadoop distribution. We're constantly working to improve our product so we can provide the most value to all of our users.\" Shay Banon, founder and CTO of ElasticsearchHow Your Hadoop Infrastructure Can Benefit by integrating with ElasticsearchOften, data stores integrated into Hadoop can become a bottleneck due to the number of requests generated by the tasks running in the cluster for each job. The distributed nature of the Map\/Reduce model fits really well on top of Elasticsearch because we correlate the number of Map\/Reduce tasks with the number of Elasticsearch shards for a particular query. So every time a query is run, the system dynamically generates a number of Hadoop splits proportional to the number of shards available so that the jobs are run in parallel - your Hadoop cluster scales easily alongside Elasticsearch and vice-versa.Finally, Elasticsearch provides near real-time responses (think milliseconds) that significantly improve a Hadoop job's execution and the cost associated with it, especially when running on 'rented resources' such as Amazon EMR. We've got even more news in the works about Elasticsearch's integration with all things Hadoop. Follow this blog for future details! And, how you're using Elasticsearch with Hadoop. We would love to hear about it. \n"}<br>{"index": {"_id": 1439}}<br>{"title":"This Week in Elasticsearch - October 30, 2013","seo_title":"","url":"\/blog\/2013-10-30-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"October 30, 2013","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to\u00a0. In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the GitHub repositories, as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, as well as news about Logstash and Kibana. Upcoming Webinar will be presenting on October 31st. You can watch live at 9 AM Pacific Time, 5 PM in the UK or 6 PM CET, followed by real-time Q&A with Honza and other members of the Elasticsearch core developer team. For those who are not able to join the broadcast, it will be archived for later playback. Registration is required. Slides Where to find Us Australia We're working on scheduling meetups in Sydney on November 18th and Melbourne on November 21st to coincide with our Elasticsearch training courses. We'll update everyone once all details are confirmed. Belgium If you're heading to Devoxx Belgium 2013, be sure to check out on . David will speak on Wednesday, November 13th at 3:10 PM in Room 6. David will also give a lightning talk, on Thursday, November 14th at 1:10 PM in Room 9. Devoxx Belgium runs from November 11-15 at the Metropolis Business Center in Antwerp. Brasil Elasticsearch community members in Brasil have created a Brasilian Portugese mailing list for folks to discuss Elasticsearch in their native tongue. You can now and we will have an update on their first meetup coming soon. Estonia will explore at on Thursday, November 7th at 3:30 PM. Topconf runs November 6th and 7th in Tallinn. France Germany Ireland will present at on Thursday, November 7th at 2:45 PM. Lucene Revolution takes place November 4th - 7th in Dublin. Japan The Elasticsearch User Group in Japan will meet for a on November 12th in Tokyo. The meeting begins at 7 PM. Netherlands Elasticsearch will be at the on November 20-22nd in Amsterdam. Stop by our table to say hello! United Kingdom United States Call for Speakers and Community Organizers Our Community Manager, Leslie Hawthorn, is hard at work to help folks create more Elasticsearch meetup groups and to help meetup organizers find more speakers. If you are interested in either effort, . Where to Find You Are you hosting an Elasticsearch meetup or giving a talk about Elasticsearch? We would love to know so we can feature that information in future editions of\u00a0. Just let our\u00a0\u00a0know what you're up to and we're happy to help promote your efforts. Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1440}}<br>{"title":"Indexing for Beginners, Part 3","seo_title":"","url":"\/blog\/found-indexing-for-beginners-part3","author":{"name":"Morten Ingebrigtsen"},"date":"October 29, 2013","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. What Does an Index Look Like? In the previous article we looked at how search engines parses, analyzes and tokenizes text. In this article we will explore in more detail what an index looks like. \n"}<br>{"index": {"_id": 1441}}<br>{"title":"Tiny Data: Rapid Development with Elasticsearch","seo_title":"","url":"\/blog\/tiny-data-rapid-development-with-elasticsearch","author":{"name":"Leslie Hawthorn"},"date":"October 24, 2013","category":"Engineering","locales":"","content":" Last weekend we participated in , a 48 hour hacking contest to build something fancy on top of Ruby (nowadays, Rails is not required). Beyond fancy, we wanted to build something that solves a real problem that we could continue developing after the hackathon concluded. It turns out that we found a common scratch to itch: our entire group was interested in . The Project Sadly, there are almost no good learning resources for sign language on the internet. If material is available, licensing is a hassle or both the licensing and the material is poorly documented. Documenting sign language yourself is also hard, because producing and collecting videos is difficult. You need third-party recording tools, video conversion and manual categorization. That's a sad state in a world where every notebook has a usable camera built in! Our idea was to leverage modern browser technologies to provide an easy recording function and a quick interface to categorize the recorded words. The result is . We Have a Hundred Problems... Handling UserMedia (video and audio) in the browser is still in its infancy. Especially with recording, which mostly works through elaborate hacks like that need to be set up very carefully. Given only about 24 hours of full work - our team valued sleep and rest - we expected recording and proper video conversion to take up most of our time. ... The Data Store Shouldn't Be One of Them Thus, we were looking for a data store that: The last point stems from the contest rules: all applications have to run on a Linode instance with 1GB of memory. Considering that we have to convert videos on the same machine, we cannot be wasteful. Our problem is language and searching, so Apache Lucene is an obvious pick. Three of our team members had already worked with Elasticsearch and the decision was made quickly: we used Elasticsearch and couldn't be happier with it. Elasticsearch for Tiny Data Elasticsearch supported the goals of our fast prototype very well: Setting up a reasonably configured elasticsearch instance as a developer is as easy as: With packages available for many platforms, Elasticsearch is quickly configured on the server as well. Also, contrary to popular belief, Elasticsearch can be run in a small memory space by setting to a small value. Given that we expected less than 5000 documents for our initial prototype, we were able to easily fit Elasticsearch in less around 256MB of memory. Setting up the new was also a breeze, it integrates well with the connection-less data models provided by . On the content side, we had 3 main problems: tagging, flagging and transcription. The transcriptions to a video should be searchable. At the same time, we want to flag videos by a fixed set of criteria (if a word is vulgar or an insult, we want to know). Tagging is free-form and allows users to categorize words. All this is possible using Elasticsearch's dynamic mapping. Our main datatype ended up looking roughly like this: { \"transcription\": \"hello from seemespeak\", \"tags\": [\"funny\"], \"flags\": [\"casual\"], \"reviewed\": false, \"language\": \"ASL\" } This is a very workable application-side data format that Elasticsearch's dynamic mapping indexes very well. More specifically, it gives you all you need to search it as expected: We found that the Elasticsearch's query language makes is very easy to build queries iteratively. We started with a plain query to give frontend developers enough content to start building and added filters and randomizations over the first day. By the end of the first day, we were done with all search scenarios. The current SeeMeSpeak is a prototype. We didn't venture into fine-tuning by implementing custom analyzers, e.g. for proper stemming and synonym searches. We were confident that we could do this on the second day, but wanted to invest our time in other things, like translating our German corpus to English for our English-speaking visitors and translating the whole site into two languages. All in all, Elasticsearch allowed us not to worry too much about data storage and push out a minimum viable version of our product with usable features over the course of a weekend. Wrapping Up Elasticsearch is not only a great database for \"big data,\" it is also a great fit for rapid application development in early stages. We were able to validate all our scenarios and use-cases very quickly. As always, investing time and effort into your data store will improve results in the long run, but we were impressed by the number of features we got out of Elasticsearch so quickly without starting with fine tuning. How You Can Help SeeMeSpeak is open source and solves a real issue: building an openly licenced and well tagged corpus for sign languages. You can contribute . Also, you can help us by voting or leaving feedback on the site. Feel free to try out our recording function. Just try to say . Thank you! , Elasticsearch Berlin User Group Co-Organizer, , , \n"}<br>{"index": {"_id": 1442}}<br>{"title":"This Week in Elasticsearch - October 23, 2013","seo_title":"","url":"\/blog\/2013-10-23-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"October 23, 2013","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to\u00a0. In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the GitHub repositories, as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, as well as news about Logstash and Kibana. Slides While not slides per se, you can check out the interactive coder oriented Elasticsearch tutorial used for his presentation at last week's GOTO Berlin conference. We also now have a for all presentations given by Elasticsearch's employees that may be a useful reference resource for you. Where to find UsBelgium If you're heading to Devoxx Belgium 2013, be sure to check out on . David will speak on Wednesday, November 13th at 3:10 PM in Room 6. David will also give a lightning talk, on Thursday, November 14th at 1:10 PM in Room 9. Devoxx Belgium runs from November 11-15 at the Metropolis Business Center in Antwerp. Estonia will explore at on Thursday, November 7th at 3:30 PM. Topconf runs November 6th and 7th in Tallinn. France Germany Ireland will present at on Thursday, November 7th at 2:45 PM. Lucene Revolution takes place November 4th - 7th in Dublin. Switzerland David Pilato will be in Geneva on October 24th and 25th for the . You can visit with David in the Elasticsearch booth, and make sure to check out his presentation on on Thursday at 4:30 PM. You may also want to join David for the NoSQL Fireside Chat, also taking place on Thursday, starting at 2:30 PM. United Kingdom United States Where to Find You Are you hosting an Elasticsearch meetup or giving a talk about Elasticsearch? We would love to know so we can feature that information in future editions of\u00a0. Just let our\u00a0\u00a0know what you're up to and we're happy to help promote your efforts. Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1443}}<br>{"title":"Managing Elasticsearch with Found","seo_title":"","url":"\/blog\/found-cluster-management","author":{"name":"Alex Brasetvik"},"date":"October 22, 2013","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. \n"}<br>{"index": {"_id": 1444}}<br>{"title":"This Week in Elasticsearch - October 16, 2013","seo_title":"","url":"\/blog\/2013-10-16-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"October 16, 2013","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to\u00a0. In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the GitHub repositories, as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, as well as news about Logstash and Kibana. Slides Last week, the Core Developer Team presented several lightning talks on Elasticsearch to more than 65 people at the Elasticsearch Netherlands User Group Meeting. You can check out on Speakerdeck and read excellent on the lightning talks. You might also want to check out the slides from , a presentation by at . Where to find UsEstonia will explore at on Thursday, November 7th at 3:30 PM. Topconf runs November 6th and 7th in Tallinn. France will present at the Nantes Java User Group meeting on November 4th. The meeting begins at 7:00 PM. Germany Ireland will present at on Thursday, November 7th at 2:45 PM. Lucene Revolution takes place November 4th - 7th in Dublin. Norway Alex Brasetvik from Found will present at the javaBin Trondheim User Group on October 22nd. Poland Honza Kral will present at PyCon Poland on Friday, October 18th. The conference runs Thursday, October 17th through Sunday, October 20th in Szczyrk. Switzerland David Pilato will be in Geneva on October 24th and 25th for the . You can visit with David in the Elasticsearch booth, and make sure to check out his presentation on on Thursday at 4:30 PM. United Kingdom \u00a0will give a talk at about how to on Wednesday, October 30th. United States Where to Find You Are you hosting an Elasticsearch meetup or giving a talk about Elasticsearch? We would love to know so we can feature that information in future editions of\u00a0. Just let our\u00a0\u00a0know what you're up to and we're happy to help promote your efforts. Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1445}}<br>{"title":"From Amsterdam with Love","seo_title":"","url":"\/blog\/from-amsterdam-with-love-elasticsearchs-second-company-all-hands","author":{"name":"Livia Froelicher"},"date":"October 16, 2013","category":"News","locales":"","content":" Elasticsearch's Second Company All Hands This post was co-authored with . Last week, the Elasticsearch crew all converged on our EU headquarters in Amsterdam, The Netherlands for five days of collaboration, hacking and community outreach. This meeting was the first time most of us had met in person, as the company has grown by more than 15 employees since our last All Hands in April 2013. We can't recount all the great stuff we did in one blog post, but we wanted to share some highlights of our meeting, particularly our development discussions. Development Discussions We spent several days with all the developers talking about progress we have made thus far and brainstorming about where we should go across all our different products, Elasticsearch, Logstash, Kibana, Elasticsearch-Hadoop, and the various language clients. Elasticsearch We checked status of features aimed at our 1.0 release planned for early next year. We chatted with about , talked about the , and discussed . We also brainstormed about some future work we would like to see in Elasticsearch, and we would love to share some of these initial thoughts with all of you: Field Data Heavy brainstorming on how to improve the experience of users when using features that require loading all field data and the potential memory problems they run into. The discussions ranged from talking about what use cases \u201cdoc values\" will help solve (which has implemented, watch out for a forthcoming blog post), improved memory usage, and potentially other storage means for the field data. Machine Learning Britta led a wonderful session about ML, asking all of us what we would like to see in ML, and to see what directions might be interesting for us to pursue in the future. We ended up breaking things into several buckets, amongst them classification, predictive functions, sentiment analysis, NLP, and more. The session was mainly exploratory in terms of understanding what we have out there and what might apply to Elasticsearch. Changes API One of the exciting features that we want to try and tackle post 1.0 release is registering for changes happening in an index. We mainly brainstormed about how something like this can be implemented - it is quite a complicated feature. We had a couple of different options for storing or virtually storing the change log, but the best choice isn't yet clear. Backwards Compatibility The plan is to have wire level backwards compatibility in 1.0, and we also discussed what it means to have backwards compatibility on the index level over multiple Elasticsearch versions (for example, in keeping backward comp. on the analysis chain level). Field Collapsing \/ Inner Hits We again fleshed out what is needed in order to properly support field collapsing in a distributed environment execution, as well as the ability to get inner hits (for nested \/ parent child cases). We have a good idea on the type of refactoring we need in our search execution infrastructure, and hope to tackle it post 1.0. Tests If you haven't noticed, and the rest of us have been hard at work at Elasticsearch to improve our testing, mainly around introducing randomized testing and improving our integration tests. We continued the discussion regarding how to move forward with our testing enhancements, including other places where we can benefit from creating an infrastructure for our tests. Test Infrastructure has been working on setting up an extensive test infrastructure for all our products, including running all our tests over multiple JDK versions, multiple operating systems, multiple machine types and other variants. We test all our products using it, and we plan to open it up relatively soon for people to see it. Performance Infrastructure We also discussed how to automate our benchmarking code and make it both consistent and applicable across different projects. We brainstormed on creating an infrastructure that all our projects can use, and creating performance reports streamed to Elasticsearch and visualized in Kibana, across different infrastructure variants (OS types, machines types, \u2026). Documentation discussed all the work that went into creating the infrastructure for all our documentation across all projects. If you haven't seen it, our reference guide has moved to live with the code, and we have a framework in place that slurps it up and builds it to be displayed on the web site. The same infrastructure can be used for docs across all our projects, and for example, elasticsearch-hadoop is already using it. The plan is to have the infrastructure also build our forthcoming book. Logstash (with participating remotely) gave a great introduction on how Logstash works to all the developers, and we bounced ideas around about how to make it even better. We have already, in the past couple of weeks, significantly improved the performance of the elasticsearch_http output, added multiple outputs to improve data throughput to elasticsearch (as an example output), and improved the performance of the grok filter. Kibana gave a demo on The State of Kibana, and we bounced several ideas around on how it should move forward. One of the exciting features that came out of this discussion is Annotations, with the ability to have annotations displayed on a histogram (for example) for important events during the (time) lifecycle of the data. Rashid didn't forget to mention how excited he is regarding Aggregations in Elasticsearch : ). Clients Clint, , and talked about the recently open sourced set of language clients to Elasticsearch (PHP, Perl, Python and Ruby). The output of the effort was creating a spec of Elasticsearch APIs, and we discussed how we can automate generating the spec out of the Elasticsearch codebase. The other nice side effect is the fact that the spec now includes a generic YAML based test infrastructure that all the clients run, allowing us to write tests in a single place, and have them execute by all the different clients (which we want to also execute as part of the Elasticsearch tests as well). We also spent time with around how to develop a javascript\/node.js client, and Chander for a future .NET client. Team Growth We are not a small development team anymore, and we are getting more distributed by the day. We discussed how to communicate better within our team, how to properly develop features (feature branches, on dev own repo and making pull requests, \u2026), and the review process that goes with it. We also spent time to see how we can better manage our time between all the tasks our developers do, be it helping out on the mailing list and IRC, coding & docs\/books, talking at conferences and helping out customers (yea, support from our company means talking to the developers, which we are very proud about). The Business of Our Business While the majority of our heavy lifting was on the code side of the house, the rest of our team spent the week figuring out how to bring Elasticsearch to even more users and customers. Our marketing team focused on making sure that our meetup program rocks, that we're seeing folks at the right conferences and that information about Elasticsearch's product offerings is most robust. Our operations and administrative teams had extensive discussions on how to best improve our company processes so we can maintain our laser focus on producing Elasticsearch and serving our customers. Our sales team, of course, ran through \u201cthe numbers,\" and things are looking great: lots of happy customers using our and great feedback from attendees of our . Community Outreach As with all times when someone from the Elasticsearch team visits a particular city, we were excited to host a community meetup in Amsterdam. We welcomed more than 65 people to the Elasticsearch office for a full evening of talks, beer and pizza. While we usually have two shorter presentations on Elasticsearch at meetups - one on features, one on a particular use case - this time around we had the whole dev team talk about what they're working towards for 1.0 in a series of lightning talks. You can read even more about the Meet-the-Devs Meetup in . Looking Forward That's a wrap for our October All Hands, but we're all looking forward to all getting together again sometime in the Spring, likely at our brand new Silicon Valley headquarters in Los Altos, California, US. In the coming weeks, we'll be talking even more about the future of Elasticsearch, Logstash and Kibana, sharing more in-depth insights into the discussions we had in Amsterdam. \n"}<br>{"index": {"_id": 1446}}<br>{"title":"Meet-the-Devs Meetup in Amsterdam","seo_title":"","url":"\/blog\/meet-the-devs-meetup-in-amsterdam","author":{"name":"Zachary Tong"},"date":"October 15, 2013","category":"","locales":"","content":" h2 {clear:left: } Last Thursday, the group held its eighth meetup. This meetup was a bit special, however, since it also coincided with the Elasticsearch company meeting. Rather than the traditional two presentation format, the Elasticsearch developers gave a number of lightning talks about what they have been working on. A big thanks to for hosting the meetup! Around 65 people showed up, with lots of great discussion before, during and after the event. Drew Raines - Life after EC2 Elasticsearch talks are often at a very high level: a new feature, a new type of query, how to implement XYZ functionality. talk went the other direction and discussed the ramifications of running on bare metal hardware. In particular, he discussed how he and debugged a performance quirk with their new cluster. Long story short, they discovered that the default Linux I\/O scheduler is atrocious when using SSDs, or RAID over fast disks. After switching their scheduler to Noop or Deadline, they saw a remarkable performance increase! Check out for more details (especially if you are using RAID or SSDs!) Costin Leau - Real-time data with Hadoop talked about his new integration. He highlighted what Hadoop is good at...and where it is lacking. Real-time processing, analytics, and geo operations are all difficult for Hadoop. Elasticsearch, on the other hand, excels at these problems. Costin explained how Elasticsearch can be integrated with an existing Hadoop installation to provide functionality that is difficult or slow in Hadoop. He then showed examples in several popular Hadoop frameworks and some benchmark data. Costin's slides are . Clinton Gormley, Karel Minarik, Honza Kral, Zachary Tong - Unleashing the Clients The client team gave a short overview of the . They talked about the motivations behind creating the clients, as well as the need for a unified interface, consistent testing framework and pluggable components. Britta Weber - Function Score Query talked about the new . Partially known for its outrageously awesome , the function score allows you to tweak scoring with complicated mathematical functions. Britta discussed how it is used and some example scenarios. Igor Motov - Snapshot and Restore presented the Snapshot and Restore functionality that he has been working on. Slated for version 1.0, Snapshot and Restore will allow users to snapshot their cluster to a shared repository (S3, shared FS, etc). Using another API, they can restore these incremental snapshots to the cluster. Snapshot and Restore will make backing up and delayed replication vastly easier in the future. You can get more detail from . Alexander Reelsen - Completion Suggester discussed the new . Using advanced Finite State Transducers, the completion suggester provides autocomplete-style suggestions in milliseconds. Importantly, it only requires one request, as opposed to approaches like ngrams which require multiple round-trips - users need suggestions they finish typing. You can learn more from . Uri Boness - Aggregations demoed his much-anticipated . Designed to replace facets, aggregations provide a framework where individual aggregations can be composed into nearly limitless combinations. He first built an example that mirrored a traditional facet, then proceeded to enhance it with more nested aggregations. Simon Willnauer - Lucene Pipeline wrapped up the meetup by talking about some low-level improvements that will be coming to Apache Lucene in the future. In particular, he discussed his frustrations with the standard Apache Lucene highlighters, as well as depreciating Span queries in favor of adding payloads to non-span queries. You'll enjoy , including the obligatory photo of his fellow Apache Lucene committer Uwe Schindler. Wrap up Big thanks to everyone who showed up for the meetup, and everyone who stayed around to chat after the presentations. The Elasticsearch team had a great time presenting and really enjoyed fielding questions about their respective projects. \n"}<br>{"index": {"_id": 1447}}<br>{"title":"City Bikes Part two","seo_title":"","url":"\/blog\/found-city-bikes-reindexing-for-filters","author":{"name":"Konrad Beiske"},"date":"October 15, 2013","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud.Reindexing and Query Optimization with FiltersIn this article we will look at basic memory optimization of our queries and while doing so, we will write a small script for reindexing our data. TODO: Terms query filter, siden stativene ikke flytter p\u00e5 seg kan vi bruke navn som er mere cachbart? \n"}<br>{"index": {"_id": 1448}}<br>{"title":"Hopper Hosts Hackathon with Elasticsearch","seo_title":"","url":"\/blog\/hopper-hosts-hackathon-with-elasticsearch","author":{"name":"Igor Motov"},"date":"October 10, 2013","category":"","locales":"","content":" Last week, I attended the first . This all day event was co-organized by , a Cambridge, Massachusetts, US based company that is using Elasticsearch to plow through a massive amount of travel data. Also organizing the hackathon were the fine folks from the , a diverse group of Elasticsearch users in the Greater Boston area. The hackathon gathered more than 40 software engineers, students and other search and open source software enthusiasts eager to learn more about Elasticsearch and share their knowledge with others. The goal of the Hackathon organizers was to create an inclusive event that would be interesting to both experts and novices alike, so we started with to bring all attendees up to speed before getting started coding. During a typical one-day hackathon, attendees have only 5-7 hours to write code, and getting stuck during these hours can derail otherwise interesting project. In order to improve participants\u2019 experiences and allow them to make as much progress as possible on their projects in just a few short hours, the Hackathon organizers convened a group of local Elasticsearch experts from Hopper, Traacker and Elasticsearch Inc as mentors. I was one of the six mentors during this hackathon, and it was an amazing experience. This event wasn\u2019t my first Elasticsearch-themed hackathon, but what made it very different for me was the number of new Elasticsearch users and the amount of progress that they made during a very short period of time. This Hackthon was the first where we introduced the and , and I think this two projects made all the difference. With the lightweight API, new users were able to very quickly translate concepts described in the elasticsearch.org user guide into working code. At the same time, Kibana made it simple to look at very complex data without requiring a lot of new code. In just seven hours by combining Twitter river with Kibana, one of the teams managed to create Twitter analytics solution for analyzing demographics of topics of interest (in their case tweets about Justin Bieber). Two winning teams analyzed Twitter to determine the popularity of TV shows and did sentiment analysis on political topics. But it wasn't all about Twitter: other hacks ranged from finding the shortest path between two Wikipedia articles to finding hidden relationships between Enron employees based on their email messages. Two teams won prizes in this hackathon, and it was wonderful to be a part of something where everyone was learning stuff, having fun and left with a sense of accomplishment. Many thanks to our sponsors: Elasticsearch Inc., SoftLayer and Traackr. You can read even more about the hackathon on the . \n"}<br>{"index": {"_id": 1449}}<br>{"title":"This Week in Elasticsearch - October 09, 2013","seo_title":"","url":"\/blog\/2013-10-09-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"October 09, 2013","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to\u00a0. In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the Github repositories, as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Elasticsearch Ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, as well as news about Logstash and Kibana. Slides Where to find UsGermany Hungary \u00a0will talk about Elasticsearch at\u00a0\u00a0in Budapest on October 12th. RuPy is a conference to bring together programmers and communities of different programming languages like Ruby, Python, Clojure or JavaScript. Netherlands You can meet almost all of the Elasticsearch, Kibana and Logstash developers tomorrow in Amsterdam at the and ask us whatever you want to know. In addition to our Q&A session, will talk about running Elasticsearch on bare metal and will talk about our Hadoop integration. United Kingdom \u00a0will give a talk at about how to on Wednesday, October 30th. United States Where to Find You Are you hosting an Elasticsearch meetup or giving a talk about Elasticsearch? We would love to know so we can feature that information in future editions of\u00a0. Just let our\u00a0\u00a0know what you're up to and we're happy to help promote your efforts. Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head. Trainings If you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1450}}<br>{"title":"Indexing for Beginners, Part 2","seo_title":"","url":"\/blog\/found-indexing-for-beginners-part2","author":{"name":"Morten Ingebrigtsen"},"date":"October 08, 2013","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud.Document Parsing and TokenizationWe continue the Indexing for beginners article with an introduction to the document parsing process and use some space to explain the concept of tokenization and tokens. \n"}<br>{"index": {"_id": 1451}}<br>{"title":"Docs! Docs! Docs","seo_title":"","url":"\/blog\/docs-docs-docs","author":{"name":"Clinton Gormley"},"date":"October 04, 2013","category":"","locales":"","content":" There's not much point in having an amazing piece of software, if users can't figure out how to use it. Over the years, we've had several complaints about our documentation: it's difficult to navigate, it's difficult to know where to start, etc. This is not unusual -- documentation is the bugbear of most software projects. But that doesn't mean we can't make it better! So let's tell you what we've done so far and what we've got planned. Docs and code, code and docs Documentation should be an accurate reflection of the code it describes. Up until now, we've had the code and the documentation in separate repositories. Now, the code lives with the docs in the . This is good news both for users and developers. Developers can include code and documentation in the same pull request and users can now access that they are using. We build a separate set of documentation for each major version, ie , , . Changes between point versions are marked up as in this example in the . So far, we have focussed on migrating the docs to the new build system. There are still a few niggles in the new docs. Please bear with us as we work on fixing them. Next we plan on improving them: making them more consistent, more complete, better explanations and more examples. This is a long-term project but you should notice a steady improvement in the documentation over time. We welcome feedback, suggestions and pull-requests! One build system to rule them all All of our projects will be using the same framework to provide their documentation. We have chosen to use as our markup language, because it is easy to read, very expressive and, via DocBook, gives us the assurance that we don't have any bad links. Also, because we build all docs from each project together, we can ensure that cross-document links work and continue to work when edits are made later on. Another good reason to use AsciiDoc and DocBook is that DocBook can produce output as HTML, PDF, EPUB and Mobi... and it is the preferred format for ! The Definitive Guide Yes! We are in the process of writing , to be published by O'Reilly Media. It was important for us to find the right partner for this book: we are an open-source company and we wanted the book to be open-source too. O'Reilly has a long track record of supporting the open-source world and we are thrilled to be working with them on this important project. While our reference documentation is intended to explain how to use a particular API and what parameters it accepts, the book will focus on how to approach and solve problems: how to improve search relevance, how to handle multiple languages, how to tune Elasticsearch for your workload. It will be suitable for beginners who know nothing about search, but will have enough meat in it to satisfy the more experienced as well. The book will be freely available online in HTML format both on our website and on O'Reilly's site and, when finished, will be available to purchase in hard copy from O'Reilly. The first part of the book is due to be published online in December this year. New chapters will be added as they are finished, and hardcopies will available for purchase in mid-2014. \n"}<br>{"index": {"_id": 1452}}<br>{"title":"Elasticsearch and Hadoop","seo_title":"","url":"\/blog\/elasticsearch-and-hadoop","author":{"name":"Costin Leau"},"date":"October 03, 2013","category":"Engineering","locales":"","content":" global wrapper \n"}<br>{"index": {"_id": 1453}}<br>{"title":"This Week in Elasticsearch - October 02, 2013","seo_title":"","url":"\/blog\/2013-10-02-this-week-in-elasticsearch","author":{"name":"Boaz Leskes"},"date":"October 02, 2013","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to\u00a0. In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the Github repositories, as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Elasticsearch core Elasticsearch EcosystemHere's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, as well as news about Logstash and Kibana. Slides Where to find Us will be speaking tonight at the Belux Elasticsearch meetup about the which will be part of the 1.0 version.David Pilato will treat attendees of m to a his presentation\u00a0, as well as lead an\u00a0. Open World Forum takes place October 3rd-5th in Paris.GermanyThe will convene for their regular monthly meeting on October 29th.\u00a0will talk about Elasticsearch at\u00a0\u00a0in Budapest on October 12th. RuPy is a conference to bring together programmers and communities of different programming languages like Ruby, Python, Clojure or JavaScript.United Kingdom\u00a0will give a talk at about how to on Wednesday, October 30th.United States Where to Find YouAre you hosting an Elasticsearch meetup or giving a talk about Elasticsearch? We would love to know so we can feature that information in future editions of\u00a0. Just let our\u00a0\u00a0know what you're up to and we're happy to help promote your efforts.Oh yeah, we're also\u00a0. If you'd like us to find you for employment purposes, just\u00a0. \u00a0We care more about your skill set and passion for Elasticsearch, Kibana and Logstash than where you rest your head.TrainingIf you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1454}}<br>{"title":"Elasticsearch Internals: an Overview","seo_title":"","url":"\/blog\/found-elasticsearch-internals","author":{"name":"Njal Karevoll"},"date":"October 02, 2013","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud.This article gives an overview of the Elasticsearch internals. I will present a 10,000 foot view of the different modules that Elasticsearch is composed of and how we can extend or replace built-in functionality using plugins. \n"}<br>{"index": {"_id": 1455}}<br>{"title":"Using ElasticSearch and Logstash to Serve Billions of Searchable Events for Customers","seo_title":"","url":"\/blog\/using-elasticsearch-and-logstash-to-serve-billions-of-searchable-events-for-customers","author":{"name":"Leslie Hawthorn"},"date":"October 01, 2013","category":"User Stories","locales":"","content":" sends and receives a lot of emails and we track and store every event that happens to every email. It adds up to billions of events per month that we need to make available to our customers, along with the ability easily parse through this data with full text search. Below is a detailed account of this challenge and how we solved it with the help of Elasticsearch and Logstash (note: we were delighted to hear about shortly after completing this project). \n"}<br>{"index": {"_id": 1456}}<br>{"title":"This Week in Elasticsearch - September 26, 2013","seo_title":"","url":"\/blog\/2013-09-26-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"September 26, 2013","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to\u00a0 . In this roundup, we try to inform you about the latest and greatest changes in elasticsearch. We cover what happened in the Github repositories, as well as many elasticsearch events happening worldwide, and give you a small peek into the future of the project. Elasticsearch core Elasticsearch ecosystem Here's some more information about what is happening in the ecosystem we are maintaining around elasticsearch, including plugin and driver releases, as well as news about logstash and kibana. Slides Where to find UsDenmark will be attending to with a few other folks from the Elasticsearch team on September 30th - October 2nd. You can pop by our booth to meet us, or just head to Alex's talk . France David will also give attendees of Open World Forum a taste of , as well as lead an . Open World Forum takes place October 3rd-5th in Paris. Norway The fine folks spearheading the will host their inaugural meetup on Thursday, September 26th. will join the festivities to talk about new features in the works for Elasticsearch. Hungary will talk about elasticsearch at in Budapest on 12th of October. RuPy is a conference to bring together programmers and communities of different programming languages like Ruby, Python, Clojure or JavaScript. Ukraine kicks off on Friday, September 27th in Kiev. Karel Minarik will be there, giving a presentation on the first day of the conference. United States Where to Find You Are you hosting an Elasticsearch meetup or giving a talk about Elasticsearch? We would love to know so we can feature that information in future editions of . Just let our know what you're up to and we're happy to help promote your efforts. Oh yeah, we're also . If you'd like us to find you for employment purposes, just . \u00a0We care more about your skill set and passion for elasticearch, kibana and logstash than where you rest your head. Trainings If you are interested in elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1457}}<br>{"title":"Release the clients! Ruby, Python, PHP, Perl","seo_title":"","url":"\/blog\/unleash-the-clients-ruby-python-php-perl","author":{"name":"Clinton Gormley"},"date":"September 24, 2013","category":"","locales":"","content":" Today, the Elasticsearch developer team is excited to announce the release of official Elasticsearch clients for Ruby, Python, PHP and Perl, with other languages to follow in the future. All of the clients are licensed under the Apache 2 open source license. Why are we providing official clients? The Elasticsearch community has done a great job over the years of providing clients for many languages. The feature set of these clients varies greatly: some are low level thin wrappers, some are high level with many abstractions. Some focus on the Elasticsearch API, while others focus on the networking layer. Some have extensive coverage of the Elasticsearch APIs and some just implement the few APIs that the developer needs. And they are all implemented in the preferred style of the developer. A number of our users have multiple languages in their codebase and want to use Elasticsearch from all of them. Differences between clients can make this more complicated than it need be. What do these clients provide? We have written these clients with the following goals in mind: No opinions! It should be as simple as possible to go from the directly to the client of your choice. All of the Elasticsearch APIs provided by these clients are direct translations of the native Elasticsearch REST interface. There should be no guessing required. Play nicely with the cluster While it is easy to make HTTP calls to Elasticsearch, handling dynamic node detection or failover when nodes disappear is tricky. These clients provide a solid networking base for playing nicely with the cluster. Full, consistent coverage of the APIs We have implemented the full REST interface. Nothing is missing. And the method calls and parameters are consistent between languages: you can make the same calls from any of the supported clients. That said, each client still feels like it belongs to the language it is written in. It won\u2019t feel like you are programming Java in Ruby, or C++ in PHP. Transport abstraction These clients are not tied to a particular networking module. Different HTTP backends can be plugged in for different environments, or to match the HTTP client that you are already using. But this abstraction also allows us to plugin different transport protocols in the future, which are more efficient than HTTP. Extend and conquer The API that these clients provide is a thin wrapper around the REST interface. Perhaps their style is different from your own, and you\u2019d prefer more abstractions. We hear you, so we have built these clients to be extensible. We have tried to do the hard stuff for you, to provide you with a solid foundation for building your own interface.This is the beauty of open source: our users will have great ideas that haven\u2019t even occurred to us. Now you also have the tools to implement them, without having to start from scratch. Supported by Elasticsearch Because we wrote these clients and they are tested by us, we can provide official support for them. When bugs are found, we can fix them quickly \u2013 it\u2019s our job. Downloading the clients Each client is available from GitHub and also from the standard distribution network for each language, where one exists. This is the first release of these clients. Please download them, try them out and give us feedback. What doesn\u2019t work? What is missing? What can we do better? Elasticsearch for Perl Installing cpanm Elasticsearch Example usage use Elasticsearch: # Connect to localhost:9200 my $es = Elasticsearch->new(): # Round-robin between two nodes my $es = Elasticsearch->new( nodes => [ 'search1:9200', 'search2:9200' ] ): # Connect to cluster at search1:9200, sniff all nodes # and round-robin between them my $es = Elasticsearch->new( nodes => 'search1:9200', cxn_pool => 'Sniff' ): # Index a document $es->index( index => 'my_app', type => 'blog_post', id => 1, body => { title => 'Elasticsearch clients', content => 'Interesting content...', date => '2013-09-24' } ): # Get the document my $doc = $es->get( index => 'my_app', type => 'blog_post', id => 1 ): # Search my $results = $es->search( index => 'my_app', body => { query => { match => { title => 'elasticsearch' } } } ): From the developer My name is Clinton Gormley and I\u2019ve been using Perl since 1999 and Elasticsearch from the first release back in early 2010. At the time I was working for the largest obituary and family announcement website in Europe and we desperately needed a solution for full text search. I kept putting it off because the options that existed back then made me want to cry. But eventually, I couldn\u2019t put it off any longer. Before starting, I searched Google again, just in case a different solution had become available, and discovered an interview with Shay Banon discussing version 0.4 of Elasticsearch. I clicked through to the website and it looked too good to be true: simple, scalable, easy to start using. I tried it out and found that it lived up to its promises! The first thing that I needed was a Perl API so I wrote and have been maintaining it ever since. ElasticSearch.pm is used by amongst others. The new client is a complete rewrite of the original codebase with a number of improvements, especially in extensibility, logging and handling node failover, that would have been difficult to add in the old version. I apologise in advance for the change in naming: ElasticSearch to Elasticsearch\u2026 Currently there is only support for using as a backend, but I will soon be releasing backends for HTTP::Lite, LWP, libcurl and AnyEvent too. Also, I will release an ElasticSearch::Compat module which will make it easy to migrate your existing code to the new Elasticsearch client. In the meantime, please try out the new client and let me know of anything that is missing via the GitHub issues list. Elasticsearch for PHP Installing Add `elasticsearch\/elasticsearch` to your `composer.json`: { \"require\": { \"elasticsearch\/elasticsearch\": \"~0.4\" } } Then install with composer curl -s http:\/\/getcomposer.org\/installer | php php composer.phar install Example usage require 'vendor\/autoload.php': use Elasticsearch: \/\/ Connect to localhost:9200: $es = new Elasticsearch\\Client(): \/\/ Round-robin between two nodes: $es = new Elasticsearch\\Client( array( 'hosts' => array( 'search1:9200', 'search2:9200' ) ) ): \/\/Connect to cluster at search1:9200, sniff all nodes and round-robin between them: $es = new Elasticsearch\\Client( array( 'hosts' => array('search1:9200'), 'connectionPoolClass' => '\\Elasticsearch\\ConnectionPool\\SniffingConnectionPool' ) ): \/\/ Index a document: $es->index( array( 'index' => 'my_app', 'type' => 'blog_post', 'id' => 1, 'body' => array( 'title' => 'Elasticsearch clients', 'content' => 'Interesting content...', 'date' => '2013-09-24' ) ) ): \/\/Get the document: $doc = $es->get( array( 'index' => 'my_app', 'type' => 'blog_post', 'id' => 1 ) ): \/\/ Search: $params = array( 'index' => 'my_app', 'type' => 'blog_post' ): $params['body']['query']['match']['title'] = 'elasticsearch': $results = $es->search($params): From the developer My name is Zachary Tong and I\u2019ve been working in PHP off and on for about 12 years. I had the pleasure of meeting Elasticsearch about two years ago around release 0.18.6.1. We\u2019ve been in a steady relationship ever since. At the time I was working as a molecular biologist and was desperately dissatisfied with available biomedical search engines. Always being an evening-hacker at heart, I obtained a lease to the NLM Medline database of biomedical abstracts and began trying to develop a better search solution. Wouldn\u2019t you know it\u2026search is a Hard Problem! I stumbled onto Elasticsearch at that point and was excited by the combination of features + performance (even on my modest laptop). Although that particular search project never left my laptop, I\u2019ve continued using Elasticsearch for a variety of personal and professional projects since. Coming from a non-information-retrieval background (and largely non-computer-science background), many of the concepts in Elasticsearch were foreign to me. Shards, indexes, TF-IDF, analyzers, ngrams, what? It can be overwhelming for newcomers to the search field. I find that I learn best by teaching, so over the last two years I\u2019ve written a number of articles on my personal blog. Although I\u2019ve been coding and writing about Elasticsearch for a long time, I have never really participated in the open source community until recently. My first big forray into OSS was with a PHP client for Elasticsearch. This caught the attention of developers at Elasticsearch and the rest is history. I\u2019m very excited about the clients being released today. My hope is to free developers from the drudgery of \u201cboring\u201d low-level interaction with an Elasticsearch cluster. Using this client as a base we can start to build more interesting components, like bundles for popular frameworks, or advanced ORMs that abstract away the cluster entirely. Elasticsearch for Python Installing pip install elasticsearch Example usage import elasticsearch # Connect to localhost:9200 by default: es = elasticsearch.Elasticsearch() # Round-robin between two nodes: es = elasticsearch.Elasticsearch([\"search1:9200\", \"search2:9200\"]) # Connect to cluster at search1:9200, sniff all nodes and round-robin between them es = elasticsearch.Elasticsearch([\"search1:9200\"], sniff_on_start=True) # Index a document: es.index( index=\"my_app\", doc_type=\"blog_post\", id=1, body={ \"title\": \"Elasticsearch clients\", \"content\": \"Interesting content...\", \"date\": date(2013, 9, 24), } ) # Get the document: es.get(index=\"my_app\", doc_type=\"blog_post\", id=1) # Search: es.search(index=\"my_app\", body={\"query\": {\"match\": {\"title\": \"elasticsearch\"}}}) From the developer My name is Honza Kr\u00e1l, I chose Python as my primary language in 2006 and haven\u2019t looked back. Before I joined Elasticsearch in April of 2013 my job was to develop and maintain backends for a few bigger content websites based on the web framework. Before that I spent my days as an ETL guy working in data warehousing I learned about Elasticsearch as part of my job when I was looking for a search engine to power our full-text search and was immediately captured by it\u2019s balance of ease-of-use and powerful feature set. It reminded me of my days as a data guy and dove right in. Ever since the beginning of my programming career I was drawn towards open-source and, whenever possible, would contribute back to the project I am using. It was no surprise then that once I learned that there is an opening for a Python guy on the team to work on the new client I couldn\u2019t let it pass by. Since the new clients we\u2019re releasing today are a very close mapping to the REST API it should be very easy for any elasticsearch user to learn and use, as well as flexible enough for any possible use-case. This should enable us to work well with existing clients and provide a clean migration path for people who would wish to migrate \u2013 we will try and work with the maintainers of existing clients to port their code to be a layer on top of this new client, thus enabling developers to keep their code while getting the benefit of using our new client underneath. Elasticsearch for Ruby Installing gem install elasticsearch Example usage require 'elasticsearch' # Connect to localhost:9200 by default: es = Elasticsearch::Client.new log: true # Round-robin between two nodes: es = Elasticsearch::Client.new hosts: ['search1:9200', 'search2:9200'] # Connect to cluster at search1:9200, sniff all nodes and round-robin between them es = Elasticsearch::Client.new hosts: ['search1:9200'], reload_connections: true # Index a document: es.index index: 'my_app', type: 'blog_post', id: 1, body: { title: \"Elasticsearch clients\", content: \"Interesting content...\", date: \"2013-09-24\" } # Get the document: es.get index: 'my_app', type: 'blog_post', id: 1 # Search: es.search index: 'my_app', body: { query: { match: { title: 'elasticsearch' } } } From the developer My name is Karel Mina\u0159\u00edk, and I discovered Elasticsearch in late 2010, when I was researching alternatives for CouchDB-Lucene, which I was using on a project at the time. As I\u2019m quite often quoted, I initially considered the project a hoax: there just can\u2019t exist such a magical project with so many buzzwords (HTTP, JSON, schema-free, distributed, \u2026), I was saying to myself. Nevertheless, I installed the project, glanced on the source, and it not only did what it said on the tin \u2014 it surpassed all expectations, up to the level where my colleagues didn\u2019t believed me when I was demoing it. Our application was written in Ruby, and we had a pretty good idea how we would like to \u201ctalk\u201d to Elasticsearch: we need a DSL for its DSL! One late evening, I have such Ruby DSL, and after some time, we had a brand new client as a Rubygem, called and later renamed to . Little did I know that will get nearly 1,500 watchers and 500 forks at Github, that I\u2019ll solve more then 700 issues, and the library will grow to be loved and hated by many users. managed to solve many issues for a nice Ruby and Rails integration, and it also managed to make some seriously bad decisions. Today marks a fresh start for me, and for Ruby users of Elasticsearch. Today, we\u2019re releasing a suite of clients with common design and semantics, which aims to provide a solid foundation for further extensions, integrations and experiments. If you liked , you can be sure that all the convenience for painless Rails integration will come soon. If you hated , I\u2019d like to invite you to kick the tires on the new Ruby client. I took great care to avoid all the bad decisions of Tire, and make the library \u2014 or, in fact a collection of three libraries \u2014 as modular, extensible and robust as much as I could. Your feedback, opinions and critique \u2014 either via Github issues, via IRC or via e-mail \u2014 is most welcome! \n"}<br>{"index": {"_id": 1458}}<br>{"title":"An Introduction to Elasticsearch Mapping","seo_title":"","url":"\/blog\/found-elasticsearch-mapping-introduction","author":{"name":"Njal Karevoll"},"date":"September 23, 2013","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. This article will give an introduction to the mapping feature of Elasticsearch. We'll define the key terms and take a closer look at what mapping is, when we specify it, how it is structured and how we can apply it to our data. \n"}<br>{"index": {"_id": 1459}}<br>{"title":"This Week in Kibana","seo_title":"","url":"\/blog\/this-week-in-kibana","author":{"name":"Rashid Khan"},"date":"September 19, 2013","category":"Kurrently in Kibana","locales":"","content":" Histogram zero filling The histogram panel received a makeover that brought proper light weight zero filling. This means that at intervals where a query should have 0 results, it will properly appear as such, instead of drawing a sloped line to the next point. The zero filling also means that histogram stacked bars will always appear in the same order top to bottom. In addition, the stacked tooltip now allows you to choose between cumulative and individual modes. Micro analysis of array fields Array fields can now be handled as singles or groups in the micro analysis panel. For example, if I have an array of tags I could see either the 10 most common tags, or the 10 most common ways that tags appear together _source as the default table field If you don't select any fields for your table, Kibana will now show you the json source of your even by default until you select some fields to show Configurable field trimming Noticed the '...' at the end of the _source in the above screenshot? Table fields can be trimmed by a configurable \"factor\". The factor is essentially the maximum length of a field, divided by the number of columns in the table, after which the field will be trimmed to nicely fit. For example, if my trim factor was 300, and I had 3 columns in the table, fields would be trimmed to a max of 100 character, after which '...' would be added. Of course the entirety of the field is still available in the expanded details view About that details view You may know that you can see a table of event fields by click on a table row. Now you have a choice of how you'd like to see the details of an event, including syntax highlighted JSON, as well as the raw unhighlighted JSON. Lighter, faster, smaller, better Kibana has an all new build system! This new system allows us to build an optimized, minified, awesomulated distribution of Kibana. It also has the benefit of cleanly clearing old caches when you upgrade. Regular builds of Kibana are being published at for your convenience. That zipball can be extracted right to your webserver. You can still run it right out of the if you want. However instead of copying the entire repo, you need only upload the src\/ directory to your webserver. We recommend grabbing the built version however as its much faster. \n"}<br>{"index": {"_id": 1460}}<br>{"title":"This Week in Elasticsearch - September 18, 2013","seo_title":"","url":"\/blog\/2013-09-18-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"September 18, 2013","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to\u00a0. In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the Github repositories, as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Elasticsearch core Elasticsearch ecosystemHere's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, as well as news about Logstash and Kibana. Slides Where to find UsAustraliaOn September 19th, the will have talk by RealEstate.com.au about their migration to Elasticsearch.Austria will be presenting at EJUG Austria on September 25th.Czech RepublicShould you find yourself in Prague for , stop in to see and co-present .Denmark will be attending to with a few other folks from the Elasticsearch team on September 30th - October 2nd. You can pop by our booth to meet us, or just head to Alex's talk .France Germany NorwayThe fine folks spearheading the will host their inaugural meetup on Thursday, September 26th. will join the festivities to talk about new features in the works for Elasticsearch.Ukraine kicks off on Friday, September 27th in Kiev. Karel Minarik will be there, giving a presentation on the first day of the conference.United States Where to Find YouAre you hosting an Elasticsearch meetup or giving a talk about Elasticsearch? We would love to know so we can feature that information in future editions of . Just let our know what you're up to and we're happy to help promote your efforts.Oh yeah, we're also . If you'd like us to find you for employment purposes, just . \u00a0We care more about your skill set and passion for elasticearch, kibana and logstash than where you rest your head.TrainingIf you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1461}}<br>{"title":"Elasticsearch in Production","seo_title":"","url":"\/blog\/found-elasticsearch-in-production","author":{"name":"Alex Brasetvik"},"date":"September 17, 2013","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. Elasticsearch easily lets you develop amazing things, and it has gone to great lengths to make Lucene's features readily available in a distributed setting. However, when it comes to running Elasticsearch in production, you still have a fairly complicated system on your hands: a system with high demands on network stability, a huge appetite for memory, and a system that assumes all users are trustworthy. These articles cover some of the lessons we've learned from securing and herding hundreds of Elasticsearch clusters. Elastic provides , a product which offers comprehensive security for Elasticsearch, including encrypted communications, role-based access control, AD\/LDAP integration and auditing. The following article was authored before Shield was available. This article is introductory. Its goal is to give an overview of important aspects of running and maintaining Elasticsearch clusters (or other distributed search engines), and to motivate learning more about them. It also aims to explain the importance of having enough memory and how to achieve high availability. Hopefully, this article will help you set reasonable expectations in terms of what Elasticsearch can (and cannot) do for you. In the future, we'll add more thorough articles about each of the covered topic. These are the topics we will cover in this article: It is no coincidence that is largely based on the amount of memory for your cluster. \n"}<br>{"index": {"_id": 1462}}<br>{"title":"Elasticsearch 0.90.5 Released","seo_title":"","url":"\/blog\/0-90-5-released","author":{"name":"Clinton Gormley"},"date":"September 17, 2013","category":"Engineering","locales":"","content":" The Elasticsearch dev team are pleased to announce the release of , which is based on Lucene 4.4. You can download it\u00a0.We released 0.90.4 yesterday with great expectations, and a few hours later had our expectations dashed by a silly bug in the plugin install script, which installed site plugins (e.g. head, bigdesk, paramedic) incorrectly. We apologize for that. That bug has been fixed and we've added the appropriate tests. However, that is not all. Things move fast in the Elasticsearch world, so we've taken advantage of this quick release to fix a few other bugs: Windows SupportAnd finally, an enhancement for those of you using Elasticsearch on Windows: we have added support for running Elasticsearch as a service on Windows , via the script. You can now do:> service.bat Usage: service.bat install|remove|start|stop|manager [SERVICE_ID] > service install Installing service : 'elasticsearch-service-x64' Using JAVA_HOME (64-bit): c:\\jvm\\jdk1.7 The service 'elasticsearch-service-x64' has been installed. > service start The service 'elasticsearch-service-x64' has been started > service stop The service 'elasticsearch-service-x64' has been stopped > service remove The service 'elasticsearch-service-x64' has been removed All the details are available in the . If you are not affected by any of the above issues then there is no need for you to upgrade from 0.90.4.Thank you for your feedback on the release of 0.90.4 yesterday - it allowed us to find and fix the plugin script error quickly. \n"}<br>{"index": {"_id": 1463}}<br>{"title":"Elasticsearch 0.90.4 released","seo_title":"","url":"\/blog\/0-90-4-released","author":{"name":"Clinton Gormley"},"date":"September 16, 2013","category":"Engineering","locales":"","content":" global wrapper \n"}<br>{"index": {"_id": 1464}}<br>{"title":"Elasticsearch from the Bottom Up, Part 1","seo_title":"","url":"\/blog\/found-elasticsearch-from-the-bottom-up","author":{"name":"Alex Brasetvik"},"date":"September 16, 2013","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. In this article series, we look at Elasticsearch from a new perspective. We'll start at the \"bottom\" (or close enough!) of the many abstraction levels, and gradually move upwards towards the user-visible layers, studying the various internal data structures and behaviours as we ascend. \n"}<br>{"index": {"_id": 1465}}<br>{"title":"Elasticsearch as a NoSQL Database","seo_title":"","url":"\/blog\/found-elasticsearch-as-nosql","author":{"name":"Alex Brasetvik"},"date":"September 15, 2013","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. .Can Elasticsearch be used as a \"NoSQL\"-database? NoSQL means different things in different contexts, and interestingly it's not really about SQL. We will start out with a \"Maybe!\", and look into the various properties of Elasticsearch as well as those it has sacrificed, in order to become one of the most flexible, scalable and performant search and analytics engines yet. \n"}<br>{"index": {"_id": 1466}}<br>{"title":"Leader Election, Why Should I Care?","seo_title":"","url":"\/blog\/found-leader-election-in-general","author":{"name":"Konrad Beiske"},"date":"September 14, 2013","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud.Leader election is one of the most tricky things to do in distributed systems. At same time, understanding how a leader is elected and the responsibilities of the leader is key to understanding a distributed system. \n"}<br>{"index": {"_id": 1467}}<br>{"title":"Indexing for Beginners, Part 1","seo_title":"","url":"\/blog\/found-indexing-for-beginners-part1","author":{"name":"Morten Ingebrigtsen"},"date":"September 13, 2013","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud.The Missing Document on Search Engine Indexing \n"}<br>{"index": {"_id": 1468}}<br>{"title":"This Week in Elasticsearch - September 11, 2013","seo_title":"","url":"\/blog\/2013-09-11-this-week-in-elasticsearch","author":{"name":"Luca Cavanna"},"date":"September 11, 2013","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to\u00a0. In this roundup, we try to inform you about the latest and greatest changes in Elasticsearch. We cover what happened in the Github repositories, as well as many Elasticsearch events happening worldwide, and give you a small peek into the future of the project.Elasticsearch core Elasticsearch ecosystemHere's some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, including plugin and driver releases, as well as news about Logstash and Kibana. Slides Where to find UsAustraliaOn September 19th, the will have talk by RealEstate.com.au about their migration to Elasticsearch.Czech RepublicShould you find yourself in Prague for , stop in to see and co-present .Denmark will be attending to with a few other folks from the Elasticsearch team on September 30th - October 2nd. You can pop by our booth to meet us, or just head to Alex's talk .France Germany and will be attending Monitorama on September 19-20th in Berlin. Ping either of them on Twitter if you want to talk all things Elasticsearch over a tasty beverage.NorwayThe fine folks spearheading the will host their inaugural meetup on Thursday, September 26th. will join the festivities to talk about new features in the works for Elasticsearch.Ukraine kicks off on Friday, September 27th in Kiev. Karel Minarik will be there, giving a presentation on the first day of the conference.United States Where to Find YouAre you hosting an Elasticsearch meetup or giving a talk about Elasticsearch? We would love to know so we can feature that information in future editions of . Just let our know what you're up to and we're happy to help promote your efforts.Oh yeah, we're also . If you'd like us to find you for employment purposes, just . \u00a0We care more about your skill set and passion for Elasticearch, Kibana and Logstash than where you rest your head.TrainingIf you are interested in Elasticsearch training we have courses taught by our core developers coming up in: \n"}<br>{"index": {"_id": 1469}}<br>{"title":"Writing an Elasticsearch Plugin: Getting Started","seo_title":"","url":"\/blog\/found-writing-a-plugin","author":{"name":"Njal Karevoll"},"date":"September 10, 2013","category":"Engineering","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud.WARNING: This article contains outdated information. We no longer recommend taking its advice.Using plugins, it's possible to add new functionality to Elasticsearch without having to create a fork of Elasticsearch itself. In this article, we will go through the steps required to create a new Elasticsearch plugin from the ground up. \n"}<br>{"index": {"_id": 1470}}<br>{"title":"Elasticsearch and the Discovery Plugin","seo_title":"","url":"\/blog\/found-elasticsearch-and-the-discovery-plugin","author":{"name":"Konrad Beiske"},"date":"September 10, 2013","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. The Zen discovery plugin might seem like magic, but replacing it is actually not that hard. Getting down and dirty with Zen might very well pay off in your particular setup. \n"}<br>{"index": {"_id": 1471}}<br>{"title":"City Bikes and Elasticsearch Facets","seo_title":"","url":"\/blog\/found-city-bikes-and-elasticsearch-facets","author":{"name":"Konrad Beiske"},"date":"September 06, 2013","category":"","locales":"","content":" This article refers to our hosted Elasticsearch offering by an older name, Found. Please note that Found is now known as Elastic Cloud. A small demo of using facets in Elasticsearch on time series. \n"}<br>{"index": {"_id": 1472}}<br>{"title":"This Week in Elasticsearch - September 04, 2013","seo_title":"","url":"\/blog\/2013-09-04-this-week-in-elasticsearch","author":{"name":"Boaz Leskes"},"date":"September 04, 2013","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to\u00a0. In this format we try to inform you about the latest and greatest changes in Elasticsearch. We try to cover what happened in the GitHub repositories, as well as all the events happening about Elasticsearch and give you a small peek in the future.Elasticsearch core Elasticsearch ecosystemWe try to give you some more information about what is happening in the ecosystem we are maintaining around Elasticsearch, be it plugin or driver releases or news about Kibana. Elasticsearch communityGot an interesting open source project, plugin, driver or anything else for Elasticsearch? Here is your time to shine! Just drop us a note and we will list it here (and on the .org website, of course!). Meetups Also, if you are interested in a core Elasticsearch training, the next locations are London at the 9th of September each (special discount ), Paris at the 16th of September (with a 10% rebate, if you sign up by Sep 6th) and San Francisco at September 23rd.\u00a0\u00a0For more locations, check the\u00a0If you are interested in all this, we are\u00a0. We are interested in your skills, not in your location. Just drop us a note. \n"}<br>{"index": {"_id": 1473}}<br>{"title":"This Week in Elasticsearch - August 28, 2013","seo_title":"","url":"\/blog\/2013-08-28-this-week-in-elasticsearch","author":{"name":"Boaz Leskes"},"date":"August 28, 2013","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to\u00a0. In this format we try to inform you about the latest and greatest changes in elasticsearch. We try to cover what happened in the github repositories, as well as all the events happening about elasticsearch and give you a small peek in the future. Elasticsearch core Elasticsearch ecosystem We try to give you some more information about what is happening in the ecosystem we are maintaining around elasticsearch, be it plugin or driver releases or news about kibana. Elasticsearch community Got an interesting open source project, plugin, driver or anything else for elasticsearch? Here is your time to shine! Just drop us a note and we will list it here (and on the .org website, of course!). Meetups Also, if you are interested in a core elasticsearch training, the next locations are Toronto at the 29th of August, \u00a0London and New York at the 9th of September each and Paris at the 16th of September. For more locations, check the\u00a0 If you are interested in all this, we are\u00a0. We are interested in your skills, not in your location. Just drop us a note. \n"}<br>{"index": {"_id": 1474}}<br>{"title":"Welcome Jordan & Logstash","seo_title":"","url":"\/blog\/welcome-jordan-logstash","author":{"name":""},"date":"August 27, 2013","category":"","locales":"","content":" Today is a defining day in the history of our company: We are proud to announce that Jordan Sissel, the creator of Logstash and a good friend, is joining Elasticsearch! This means that Elasticsearch, the company, now provides a fully open source product stack for logging and events management: for log processing, Elasticsearch as the real time analytics and search engine, and (created by Rashid Khan) as the visual front end. Neither Jordan nor Logstash really need an introduction, but I'd like to give you an idea about why this is amazing news for so many Elasticsearch and Logstash users. About Logstash Logstash, which just released version 1.2.0, is one of the most popular open source logs and events shipper\/processor out there. It consumes logs (eg by tailing log files), processes and enriches the data and stores it in Elasticsearch. This means that your logging data can now be analyzed in real time. Kibana is a visual web front end which allows you to explore and monitor the analytics that matter to you. The trio of Logstash, Kibana and Elasticsearch is already the most popular open source solution to logs management. The three products work together beautifully, which is not surprising, given that Jordan, Rashid and I have known each other for a long time and have worked closely on ensuring that our products work well together. Now with Jordan joining us full time, we will build a team dedicated to Logstash development as well, and will have more time to work together on developing the many new ideas we have for new features and smoother integration. Logstash \/ Kibana support Ever since the company started offering SLA based support subscriptions, we have received requests to offer commercial support for Logstash. We\u2019re happy to report that, as of today, our support customers will receive Logstash and Kibana support as part of their existing subscriptions \u2013 at no additional cost. The same applies to future customers: our company will support Logstash and Kibana in addition to Elasticsearch, as part of our standard support subscriptions without any change to the pricing. Our vision Even though Elasticsearch itself was not designed specifically to be a logging product, the logging use case has contributed heavily to its popularity. There are a few reasons for this: What is a log? Logs used to be an (often indecipherable) line of text intended for offline human analysis of what went wrong. Today, a log can be any piece of structured or unstructured data, usually associated with a timestamp, that may come from access logs, application logs, or even tweets, financial transactions, audit events, etc. Elasticsearch was built from the ground up to handle any type of data and, over the years, the time based data model has proved to be a very good fit for Elasticsearch. Moreover, the ability to slice, dice and aggregate data on the fly, based on any field in the logs has freed users from worrying about how to turn their raw logs into valuable insights. When Rashid joined our company, Kibana was tied to data generated by Logstash. Since then, Rashid and our team have been heavily at work building Kibana 3. The new version of Kibana today allows users to explore any time based data stored in Elasticsearch including, obviously, our vision of what constitutes a log. Logstash shares the same vision. Effectively, Logstash is a generic system to process events. It provides a pluggable pipeline to combine different ways of inputting data, enriching it, and outputting the results. The plethora of inputs, filters, and outputs, and the amazing community that have developed around them, makes Logstash a Swiss Army knife suitable for almost any type of data munging. This same thread runs through all of our products, and our vision for redefining the logging space is not just a happy coincidence. In the same way that we have redefined search with Elasticsearch, we want to redefine the log with Logstash. Single context Users have many different types of data in their applications or organizations, such as logs, documents and database records. Usually each dataset exists in a separate silo, but users want to understand all of this information within a single context. We see users today pushing all of these datasets into Elasticsearch, and using it to join the dots, often resulting in serendipitous discoveries. This is something that would not have been possible before. One of my favourite examples is that of a Fortune 100 company that stored all of their documents and their access logs recording views and modifications in Elasticsearch. They wanted to ask questions about how people were using the confidential documents. They used \u201cmore like this\u201d queries to find places where people had copied and pasted information across documents, which was against policy, and then used the access logs to find who had accessed those documents. This was only possible by correlating the documents and access logs, putting them into the same context. Another example is a company which uses Logstash and Elasticsearch not only for all their application logs, but also for all of their application metrics. The ability to tie metrics indicating high CPU usage to a log message of \u201cmmm, we shouldn\u2019t really get here\u201d has proven to be invaluable more than once. This ability to view information in a single context has lead to Elasticsearch becoming a favorite tool of many DevOps. Thousands of companies, Fortune 100 enterprises and hyper-growth startups alike, from all over the world now run Elasticsearch, Logstash and Kibana to analyze logging data. Open source Our company roots lie deep in open source soil and we believe that our user community will benefit most from our products if they are open source. Needless to say, Jordan will continue to head up Logstash development, and Elasticsearch, Kibana and Logstash will continue to be available under the Apache 2 open source license. Also the option to use either one of the three products without the others will continue to be possible. Final words I don\u2019t have a crystal ball to predict the future, but I suspect you don\u2019t need one to predict that today\u2019s news will bring a lot value to whoever uses our products. I\u2019m incredibly excited, as we just made a big step forwards in realizing our vision. Welcome! \n"}<br>{"index": {"_id": 1475}}<br>{"title":"Stop Stopping Stop Words: a Look at Common Terms Query","seo_title":"","url":"\/blog\/stop-stopping-stop-words-a-look-at-common-terms-query","author":{"name":"Zachary Tong"},"date":"August 26, 2013","category":"","locales":"","content":" Stop words are a fundamental part of Information Retrieval lore. Common wisdom dictates that you should identify and remove stop words from your index. This increases both performance (fewer terms in your dictionary) and more relevant search results. Elasticsearch supports stop word removal through the , but a new query was recently added which makes this filter unnecessary: . Background Before we go much farther, Why would you want to remove stop words anyway? In most cases, stop words add little semantic value to a sentence. They are filler words that help sentences flow better, but provide very little context on their own. Stop words are usually words like \u201cto\u201d, \u201cI\u201d, \u201chas\u201d, \u201cthe\u201d, \u201cbe\u201d, \u201cor\u201d, etc etc. Even worse than being void of useful information\u2026they are everywhere! Stop words are the most frequent words in the English language. Because of this, most sentences share a similar percentage of stop words. Stop words bloat your index without providing any extra value. If they are both common lacking in much useful information, why not remove them? Removing stop words helps decrease the size of your index as well as the size of your query. Fewer terms is always a win with regards to performance. And since stop words are semantically empty, relevance scores are unaffected. Stop words are useless\u2026 \u2026unless you actually need them. The classic example is a phrase from Shakespeare: This sentence is composed entirely of stop words, and would therefore not be represented in your index. That\u2019s a problem. At this point, people usually start maintaining multiple mappings of their data: one with stop words removed, and one that has stop words intact. They are boosted differently, to favor phrases with no stop words. This procedure, however, eliminates the benefits of stop word removal. Instead of decreasing the number of terms being searched (and indexed), we just doubled it by indexing the field in two different ways! Enter Common Terms The new Common Terms Query is designed to fix this situations, and it does so through a very clever mechanism. At a high level, Common Terms analyzes your query, identifies which words are \u201cimportant\u201d and performs a search using just those words. Only after documents are matched with important words are the \u201cunimportant\u201d words considered The motivation behind Common Terms is to leverage the power of stop word removal (faster searches) without eliminating stop words entirely (because they can contribute to score sometimes). You can have your cake and eat it too! How Common Terms works Let\u2019s first look at how you construct a Common query: { \"common\": { \"body\": { \"query\": \"this is bonsai cool\", \"cutoff_frequency\": 0.001 } } } Several things happen when you execute this query: Internally, the query is rewritten into roughly this representation: { \"bool\": { \"must\": [ { \"term\": { \"body\": \"bonsai\"}}, { \"term\": { \"body\": \"cool\"}} ], \"should\": [ { \"term\": { \"body\": \"this\"}} { \"term\": { \"body\": \"is\"}} ] } } It should be easy to see how this can greatly affect performance. The low frequency words act as a pre-filter, drastically reducing the number of terms that need to be evaluated\/scored against the full index. Adaptive Stop Word Evaluation With traditional stop word schemes, you must first create a list of stop words. Every domain is unique when it comes to stop words: there are no \u201cpre-made\u201d stop word lists on the internet. As an example, consider the word \u201c\u201c. For most businesses, \u201cvideo\u201d is an important word \u2013 it shouldn\u2019t be removed. But if you are Youtube, \u201cvideo\u201d is probably mentioned in thousands of places\u2026it is definitely a stop word in this context. Traditional stop word removal would need a human to sit down, compile a list of stop words, add it to Elasticsearch and then routinely maintain the list with additions\/deletions. In contrast, Common Terms adapts to your domain. Words with high frequency will automatically be recognized as stop words. Different companies, using the same query, will get different stop word behavior due to the unique set of documents in their index. Customizing Common Terms Common Terms allows considerable customization. Since it is effectively creating two Bool queries, there are a number of options you can twiddle. Let\u2019s look at an example that uses all the options: { \"common\": { \"body\": { \"query\": \"nelly the elephant not as a cartoon\", \"cutoff_frequency\": 0.001, \"low_freq_operator\": \"or\", \"high_freq_operator\": \"or\", \"minimum_should_match\": { \"low_freq\" : \"60%\", \"high_freq\" : \"20%\" } } } } In this query, we are specifying that both the high- and low-frequency term booleans should use an \u201cOr\u201d operator (e.g. go into a Should clause). Alternatively, we could make one or both of these options an \u201cAnd\u201d (go into a Must clause). We are also specifying how many of the terms we want to match, for both high- and low-frequencies. This can be either a percentage or an exact value. By fiddling with the cuttoff and minimum_should_match values, you can very easily hone in on the behavior that you want. Revisiting Shakespeare Let\u2019s revisit that Shakespearean phrase we saw earlier. What happens when we query for with Common Terms? { \"common\": { \"body\": { \"query\": \"To be or not to be\", \"cutoff_frequency\": 0.001 } } } In most corpuses, all those terms are going to be well over 1%, so they are all going to be categorized as highly frequent terms. What does Common Terms do in this situation? Since all terms are highly frequent and there are no low frequency terms, Elasticsearch converts the high-frequency list into a Must clause: { \"bool\": { \"must\": [ { \"term\": { \"body\": \"to\"}}, { \"term\": { \"body\": \"be\"}}, { \"term\": { \"body\": \"or\"}}, { \"term\": { \"body\": \"not\"}} ] } } The theory is that, individually, these terms carry very little semantic information and will match too many documents. But when they are all required, they become much more exclusive and match a limited subset of documents. Sometimes this approach can be too strict, so it may make sense to relax the requirements with a minimum_should_match: { \"common\": { \"body\": { \"query\": \"To be or not to be\", \"cutoff_frequency\": 0.001, \"high_freq_operator\": \"or\", \"minimum_should_match\": { \"high_freq\" : \"70%\" } } } } Which will convert the Must clause into a Should that must match 70% of the terms. This is more restrictive than a simple OR, but less restrictive than an AND. Conclusion The Common Terms Query is exciting, since it is truly a win-win. You gain the speed of stop word removal, but maintain the precision of leaving stop words in the index. Stop words will still have their uses, but we envision the majority of queries converting to a Common query. It is a powerful optimization that doesn\u2019t sacrifice relevance for speed. Give it a shot with your data and see if it helps boost performance! \n"}<br>{"index": {"_id": 1476}}<br>{"title":"You Complete Me","seo_title":"","url":"\/blog\/you-complete-me","author":{"name":"Alexander Reelsen"},"date":"August 22, 2013","category":"Engineering","locales":"","content":" Effective search is not just about returning relevant results when a user types in a search phrase, it's also about helping your user to choose the best search phrases. Elasticsearch already has functionality which can correct the user's spelling after they have searched. Now, we are adding the which can make suggestions . Giving the user the right search phrase before they have issued their first search makes for happier users and reduced load on your servers. Consider this feature experimental at the moment! Things might change\/break in future releases. Why Another Suggester? It was already possible to make suggestions using existing functionality in Elasticsearch, like prefix queries and ngrams, so why have we added a dedicated completion suggester? There are a few reasons: SPEED Remember, we're making suggestions while the user types, so results need to be shown to the user within a few milliseconds, even after taking network latency into account! A full-blown search has to examine too many terms (and their frequencies) to perform sufficiently fast for this purpose. Instead, we use an in-memory data structure called an FST which contains valid suggestions and is optimised for fast retrieval and memory usage. Essentially, it is just a graph. For instance, and FST containing the words , , , and would look like this: All we do is start on the left and follow the paths to the right. If the user types an , then we can see that there is only one possible completion: , so we can immediately complete that word. If the user types an , then we can provide a list of all the \"m\" words. As soon as they type , then we can autocomplete the word \"marriot\". Following this in-memory graph is blazingly fast, as you will see from the benchmarks later in this blogpost. Real Time Suggesters in Lucene are built in-memory by loading the completion values from the index, then building the FST. This can be a slow, resource intensive process. And, as soon as the index changes, the FST needs to be rebuilt. \"Real time search\" is a mantra of Elasticsearch. It is not acceptable to return out of date suggestions, nor to require a full rebuild whenever the index changes. Instead of building the FST at search time, we now build an FST per-segment at index time. Essentially, whenever a new segment is written to disk, we also write the FST to a file in a format which is fast to load into memory when required. Instead of consulting a single FST for the whole index, we query each per-segment FST to produce a unified list of results. Having an FST per segment also means that the completion suggester , in exactly the same way as for full text search: the more nodes you add, the more you can scale. Readability A user searching for may type in any number of search phrases: However, we want our suggestions to be explicit, leaving the user in no doubt about the page they will see if they click on our suggestion. All of the above inputs should return the single, nicely formatted suggestion of . Custom Ordering We want suggestions to be presented in a particular order, but this order is not the same as the ordering we need for full text search. Full text search uses TF\/IDF (term frequency\/inverse document frequency) to find the documents that are most relevant for the given search phrase. For suggestions, we may want common terms to appear at the top of the list. However common terms have high document frequencies, which their relevance. Alternatively, we may want a completely custom ordering applied to suggestions, which is independent of term frequency. For instance, we may want to promote hotels which have received good user ratings, or promote recent blogposts over older blogposts. The completion suggester gives us complete control over the order of suggestions but, by default, treats more common suggestions as more important. Use Case: Hotel Bookings To demonstrate the power of the , let's start with a simple function on a hotel bookings website. We'll build on this example below. First, create an index, and setup the completion suggester for the field: curl -X PUT localhost:9200\/hotels -d ' { \"mappings\": { \"hotel\" : { \"properties\" : { \"name\" : { \"type\" : \"string\" }, \"city\" : { \"type\" : \"string\" }, \"name_suggest\" : { \"type\" : \"completion\" } } } } }' Note the new suggester : . Then, index some hotels: curl -X PUT localhost:9200\/hotels\/hotel\/1 -d ' { \"name\" : \"Mercure Hotel Munich\", \"city\" : \"Munich\", \"name_suggest\" : \"Mercure Hotel Munich\" }' curl -X PUT localhost:9200\/hotels\/hotel\/2 -d ' { \"name\" : \"Hotel Monaco\", \"city\" : \"Munich\", \"name_suggest\" : \"Hotel Monaco\" }' curl -X PUT localhost:9200\/hotels\/hotel\/3 -d ' { \"name\" : \"Courtyard by Marriot Munich City\", \"city\" : \"Munich\", \"name_suggest\" : \"Courtyard by Marriot Munich City\" }' And now we can ask for suggestions: curl -X POST localhost:9200\/hotels\/_suggest -d ' { \"hotels\" : { \"text\" : \"m\", \"completion\" : { \"field\" : \"name_suggest\" } } }' The (partial) response, as shown below, contains a single suggestion: : ... \"hotels\" : [ { \"text\" : \"m\", \"offset\" : 0, \"length\" : 1, \"options\" : [ { \"text\" : \"Mercure Hotel Munich\", \"score\" : 1.0 } ] } ] Why has it returned just ? Why doesn't it include or ? The reason is that an FST query is not the same as a full text query. We can't find words anywhere within a phrase. Instead, we have to start at the left of the graph and move towards the right. The only suggestion that starts with an is the . The solution to this is to provide multiple inputs: several possible phrases that the user may type. Multiple Inputs We'll reindex all of our hotels, providing multiple search phrases for each suggestion: curl -X PUT localhost:9200\/hotels\/hotel\/1 -d ' { \"name\" : \"Mercure Hotel Munich\", \"city\" : \"Munich\", \"name_suggest\" : { \"input\" : [ \"Mercure Hotel Munich\", \"Mercure Munich\" ] } }' curl -X PUT localhost:9200\/hotels\/hotel\/2 -d ' { \"name\" : \"Hotel Monaco\", \"city\" : \"Munich\", \"name_suggest\" : { \"input\" : [ \"Monaco Munich\", \"Hotel Monaco\" ] } }' curl -X PUT localhost:9200\/hotels\/hotel\/3 -d ' { \"name\" : \"Courtyard by Marriot Munich City\", \"city\" : \"Munich\", \"name_suggest\" : { \"input\" : [ \"Courtyard by Marriot Munich City\", \"Marriot Munich City\" ] } }' If we rerun our completion suggester, we get more results: \"hotels\" : [ { \"text\" : \"m\", \"offset\" : 0, \"length\" : 1, \"options\" : [ { \"text\" : \"Marriot Munich City\", \"score\" : 1.0 }, { \"text\" : \"Mercure Hotel Munich\", \"score\" : 1.0 }, { \"text\" : \"Mercure Munich\", \"score\" : 1.0 }, { \"text\" : \"Monaco Munich\", \"score\" : 1.0 } ] } ] Great! We're now seeing all the hotels which start with . But it's not quite perfect: the has been returned twice: once as and once as . This is because both inputs matched the search text. We want to unify those results into a single, standardised output. Single Unified Output We'll reindex our documents, specifying the text of the suggestion that should be returned whenever one of the s is matched: curl -X PUT localhost:9200\/hotels\/hotel\/1 -d ' { \"name\" : \"Mercure Hotel Munich\", \"city\" : \"Munich\", \"name_suggest\" : { \"input\" : [ \"Mercure Hotel Munich\", \"Mercure Munich\" ], \"output\": \"Hotel Mercure\" } }' curl -X PUT localhost:9200\/hotels\/hotel\/2 -d ' { \"name\" : \"Hotel Monaco\", \"city\" : \"Munich\", \"name_suggest\" : { \"input\" : [ \"Monaco Munich\", \"Hotel Monaco\" ], \"output\": \"Hotel Monaco\" } }' curl -X PUT localhost:9200\/hotels\/hotel\/3 -d ' { \"name\" : \"Courtyard by Marriot Munich City\", \"city\" : \"Munich\", \"name_suggest\" : { \"input\" : [ \"Courtyard by Marriot Munich City\", \"Marriot Munich City\" ], \"output\": \"Hotel Marriot\" } }' Finally, the results from our suggester are correct: we have a single result for each matching document, and the suggestions are formatted as we want them: \"hotels\" : [ { \"text\" : \"m\", \"offset\" : 0, \"length\" : 1, \"options\" : [ { \"text\" : \"Hotel Marriot\", \"score\" : 1.0 }, { \"text\" : \"Hotel Mercure\", \"score\" : 1.0 }, { \"text\" : \"Hotel Monaco\", \"score\" : 1.0 } ] } ] Scoring - The End of Neutrality Not all suggestions have equal value. Perhaps our users have ranked some hotels higher than others. Or perhaps we earn more revenue from some hotels than from others. Either way, we want to be able to control the order in which suggestions are returned. We'll reindex our documents, this time specifying a for each hotel: curl -X PUT localhost:9200\/hotels\/hotel\/1 -d ' { \"name\" : \"Mercure Hotel Munich\", \"city\" : \"Munich\", \"name_suggest\" : { \"input\" : [ \"Mercure Hotel Munich\", \"Mercure Munich\" ], \"output\": \"Hotel Mercure\", \"weight\": 5 } }' curl -X PUT localhost:9200\/hotels\/hotel\/2 -d ' { \"name\" : \"Hotel Monaco\", \"city\" : \"Munich\", \"name_suggest\" : { \"input\" : [ \"Monaco Munich\", \"Hotel Monaco\" ], \"output\": \"Hotel Monaco\", \"weight\": 10 } }' curl -X PUT localhost:9200\/hotels\/hotel\/3 -d ' { \"name\" : \"Courtyard by Marriot Munich City\", \"city\" : \"Munich\", \"name_suggest\" : { \"input\" : [ \"Courtyard by Marriot Munich City\", \"Marriot Munich City\" ], \"output\": \"Hotel Marriot\", \"weight\": 15 } }' As you can imagine, the results are now sorted by , which is returned as the : \"hotels\" : [ { \"text\" : \"m\", \"offset\" : 0, \"length\" : 1, \"options\" : [ { \"text\" : \"Hotel Marriot\", \"score\" : 15.0 }, { \"text\" : \"Hotel Monaco\", \"score\" : 10.0 }, { \"text\" : \"Hotel Mercure\", \"score\" : 5.0 } ] } ] A weight must be an integer (not a float, as you are used from normal scoring) between 0 and 2^31. If you don't specify a then Elasticsearch will use the term frequency of the search phrase within its segment, usually . This is pretty much meaningless as far as suggestions go. It is better to control order using . Connecting Users With Results The question arises: what does the user do with our suggestions? We want to connect the user with the correct results as fast as possible. If we are returning explicit suggestions, eg , then why should we force the user to perform a search on those words? Why not take the user directly to the correct page? We can enrich the suggestions by including a , which can be an arbitrary JSON document. For our hotel suggestions, we can include a simple JSON document which includes the ID of the hotel. Payloads must be enabled in the mapping before we can use them, which means that we need to recreate the index: curl -X DELETE localhost:9200\/hotels curl -X PUT localhost:9200\/hotels -d ' { \"mappings\": { \"hotel\" : { \"properties\" : { \"name\" : { \"type\" : \"string\" }, \"city\" : { \"type\" : \"string\" }, \"name_suggest\" : { \"type\" : \"completion\", \"payloads\" : true } } } } }' And reindex the hotels with the appropriate payloads: curl -X PUT localhost:9200\/hotels\/hotel\/3 -d ' { \"name\" : \"Courtyard by Marriot Munich City\", \"city\" : \"Munich\", \"name_suggest\" : { \"input\" : [ \"Courtyard by Marriot Munich City\", \"Marriot Munich City\" ], \"output\": \"Hotel Marriot\", \"weight\": 15, \"payload\": { \"hotel_id\": 3} } }' The suggester responses will return whatever was associated with that suggestion: ... { \"text\" : \"Hotel Marriot\", \"score\" : 15.0, \"payload\" : { \"hotel_id\": \"3\" } }, ... When the user clicks on , we can transfer them directly to the correct page, without having to fire off another search request. Working With Synonyms The completion suggester can make use of synonyms, in the same way as normal searches. For example, let's make and synonoms of each other: curl -X DELETE localhost:9200\/hotels curl -X PUT localhost:9200\/hotels -d ' { \"settings\": { \"analysis\": { \"analyzer\": { \"suggest_synonyms\": { \"type\": \"custom\", \"tokenizer\": \"lowercase\", \"filter\": [ \"my_synonyms\" ] } }, \"filter\": { \"my_synonyms\": { \"type\": \"synonym\", \"synonyms\": [ \"courtyard, marriot\" ] } } } }, \"mappings\": { \"hotel\" : { \"properties\" : { \"name\" : { \"type\" : \"string\" }, \"city\" : { \"type\" : \"string\" }, \"name_suggest\" : { \"type\" : \"completion\", \"index_analyzer\" : \"suggest_synonyms\", \"search_analyzer\" : \"suggest_synonyms\" } } } } }' Now if we index the , it will be added to the FST as : curl -X PUT 'localhost:9200\/hotels\/hotel\/3?refresh=true' -d ' { \"name\" : \"Courtyard Hotel\", \"city\" : \"Munich\", \"name_suggest\" : \"Courtyard Hotel\" }' Suggestions for the letter will match on and return the as a suggestion. Be aware that this might confuse the user, so you should add enough context to the output label so that the user understands why a suggestion has been included. In version 0.90.3, and have to be specified separately. From version 0.90.4 onwards, you will be able to use the single parameter instead. By default, the is used at both index and search time. Ignoring Stopwords Stopwords also come into play for suggestions. A user searching for might well type in just . We should still be able to find the right hotel. Of course, you could just index it with two s: , but you could use stopwords to do it for you automatically. Unfortunately, there is a bit of a gotcha with stopwords. The stopwords token filter removes terms, but still leaves a blank in the token stream, where the term used to be. For instance, without stopwords, would generate a graph like the following, where represents the space between the two words: With stopwords, however, the suggestion now STARTS with a space: To get around this, we have to change the completion suggester mapping to set both and to : curl -X DELETE localhost:9200\/hotels curl -X PUT localhost:9200\/hotels -d ' { \"mappings\": { \"hotel\" : { \"properties\" : { \"name\" : { \"type\" : \"string\" }, \"city\" : { \"type\" : \"string\" }, \"name_suggest\" : { \"type\" : \"completion\", \"index_analyzer\" : \"standard\", \"search_analyzer\" : \"standard\", \"preserve_position_increments\": false, \"preserve_separators\": false } } } } }' Now, is added to the FST without stopwords or separators, ie as . This can have unintended consequences, as will now match . Similarly, searching for will not match as is not a stopword. While using stopwords can be a time saver, you will get better results by manually specifying all the \u00ecnput variations that you want to be able to match. The added complication that stopwords brings to the suggester is also the reason why the default analyzer is the analyzer (which doesn't use stopwords) instead of the analyzer. Easy Updates While Elasticsearch makes it easy to add suggestions to existing documents, it will often make more sense to maintain the suggestions in a separate index. Payloads allow you to link the suggestions back to the original resource. Improving Relevance Maintaining a good suggestions list requires forethought and regular maintenance. It takes mores effort than straightforward full text search, but that effort will be repaid by better user experience and increased conversion rates. Fine tuning suggestions requires to combine several signals: Further Plans After laying the foundations for this powerful completion framework, we will start adding new features gradually. Here are a few in the pipeline: Going Fuzzy In order to find suggestions even if the user misspells some words, the completion suggester will support fuzzy queries as of elasticsearch 0.90.4. All you have to do is to add the option to your suggest request: curl -X POST 'localhost:9200\/hotels\/_suggest?pretty' -d ' { \"hotels\" : { \"text\" : \"coutr\", \"completion\" : { \"field\" : \"name_suggest\", \"fuzzy\" : { \"edit_distance\" : 2 } } } }' Improved Stopwords Support Another issue when using stopwords with suggesters is that stopwords like can interfere with autocompletion of words like . The standard stopwords filter will remove so we are not able to provide suggestions until the user has typed a second letter. Version 0.90.4 will support the new which Mike McCandless built specifically for suggesters: if the stopword is the final word in the query and is not followed by a space or other word boundary, then it will not be treated as a stopword but rather as a prefix that can be queried. Statistics Having insight into how much RAM is consumed by the in-memory FST is important for capacity planning. Roughly similar to the fielddata statistics, you will be able to get total and per-field memory usage. This feature will also land in 0.90.4. curl 'http:\/\/localhost:9200\/_stats\/completion?pretty&human' { \"ok\" : true, \"_shards\" : { \"total\" : 10, \"successful\" : 5, \"failed\" : 0 }, \"_all\" : { \"primaries\" : { \"completion\" : { \"size_in_bytes\" : 163691700, \"size\": \"156.1mb\" } }, \"total\" : { \"completion\" : { \"size_in_bytes\" : 163691700, \"size\": \"156.1mb\" } } }, \"indices\" : { \"data\" : { \"primaries\" : { \"completion\" : { \"size_in_bytes\" : 163691700, \"size\": \"156.1mb\" } }, \"total\" : { \"completion\" : { \"size_in_bytes\" : 163691700, \"size\": \"156.1mb\" } } } } } Highlighting Many implementations highlight the portion of the term which has already been entered. We plan to add this to the response as we well. Reduce Payload Memory Usage As you will see from the benchmarks below, even small payloads can use a significant amount of memory. Version 0.90.4 will support payloads as simple values (ie integers, strings etc) rather than requiring a JSON body. Also, we will be looking at storing payloads on disk with block compression, to make their impact on memory usage negligible. Performance & Benchmarks In order to back the claims of incredible speed, I include these stats from a short benchmark on my developer notebook with an SSD and enough RAM to fit the whole index into the file system cache, which makes the regular and queries significantly faster than the typical case. Tests were performed over the loopback interface. The dataset consisted of the titles of 2.1 million pages in Wikipedia. Explanation As you can see from the results, even the request is blazingly fast. Adding the (which was small) doubled the amount of memory used by the FST. Try to keep the payload as small as possible. Round-up That's it for now. You have had an overview of the past, the present and the future of the completion suggester, and hopefully you are raring to start using it into your application. We will keep you posted, once we add some of the features planned. Also keep in mind, that this feature is still marked experimental. If you have an interesting use case for this suggester you would like to share, please do so, we are happy to get some feedback about it. \n"}<br>{"index": {"_id": 1477}}<br>{"title":"This Week in Elasticsearch - August 21, 2013","seo_title":"","url":"\/blog\/2013-08-21-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"August 21, 2013","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to . In this format we try to inform you about the latest and greatest changes in elasticsearch. We try to cover what happened in the github repositories, as well as all the events happening about elasticsearch and give you a small peek in the future. Elasticsearch core Elasticsearch ecosystem We try to give you some more information about what is happening in the ecosystem we are maintaining around elasticsearch, be it plugin or driver releases or news about kibana. Elasticsearch community Got an interesting open source project, plugin, driver or anything else for elasticsearch? Here is your time to shine! Just drop us a note and we will list it here (and on the .org website, of course!). Meetups Also, if you are interested in a core elasticsearch training, the next locations are Toronto at the 29th of August, and London and New York at the 9th of September each. For more locations, check the If you are interested in all this, we are . We are interested in your skills, not in your location. Just drop us a note. \n"}<br>{"index": {"_id": 1478}}<br>{"title":"Kibana: What's Cooking","seo_title":"","url":"\/blog\/kibana-whats-cooking","author":{"name":"Rashid Khan"},"date":"August 21, 2013","category":"","locales":"","content":" Haven't upgraded Kibana lately? You might be missing out on some neat stuff! A lot has changed in Kibana and new panels are only half the story. The entire system behind querying has been refactored to provide consistent colors and legends across the entire dashboard. Interfaces have been standardized and many functions have been modified to provide simpler, faster and more powerful functionality. Let's take a deeper look at some of the recent developments. Terms panel: Global colors, aliases and queries: Filters. New Query Input The new query panel replaces the 'stringquery' panel as your method for inputting queries. Gone are the individual query inputs for each panel. You can still specify specific queries for specific panels, but you enter them here first, optionally assigning an alias and color, then select them from within the panel editor. Queries can also be pinned to a collapsable section when not being actively modified. Assigning Queries to panels Assigning queries to panels has been greatly simplified. Queries can be toggled on\/off from the panel editor and even if the underlying query is updated or filtered, the alias will remain consistent. You may also notice that settings windows have been segmented into a tabs to provide a cleaner configuration interface. Custom colors and aliases When you assign a color to a query it is instantly reflected on every panel, and the same goes for aliases, which are used as legend values. This makes it easy to assign color variations in logical groups that make sense for your dashboard and data. Hello Terms! A new terms panel has been introduced that represents top field values in 3 unique fashions: pie charts, bar charts and tables. All have click-to-filter functionality that integrates with the new filtering panel. filtering panel? Caught that in the last section, did you? Sharp eye! Filters! Filters allow you to drill down into the dataset without modifying your queries. They can also be removed, toggled and edited at will. Filters have 3 modes. Fields list and micropanel The fields panel has been integrated with the table panel. Field lists are now populated by reading the Elasticsearch endpoint. Note that you may need to update your proxy to reflect this change. The field list is now collapsable to save space and new charts have been added to the micropanel. Hey, whats with the color scheme?! There you go, spotting changes before I can explain! Kibana now allows you to switch between light and dark color schemes to better fit your environment and preferences. That about sums it up! Of course Kibana is constantly evolving so be sure to watch this space, , and follow and on Twitter. Cheers! \n"}<br>{"index": {"_id": 1479}}<br>{"title":"welcome leslie","seo_title":"","url":"\/blog\/welcome-leslie","author":{"name":""},"date":"August 20, 2013","category":"","locales":"","content":" It's my pleasure to welcome Leslie Hawthorn () to our team\u00a0joining Elasticsearch as our new . \u00a0\u00a0\u00a0is well know across the open source world spending the last decade creating, cultivating and enabling open source communities.\u00a0She created the\u00a0to involve pre-university students in open source software development, launched, received an\u00a0\u00a0in 2010 and has given\u00a0on many things open source.\u00a0She\u2019s worked as Program Manager for, Community Manager for\u00a0\u00a0and Community Engineering Team Manager at. I can certainly state Leslie truly understands the spirit of open source.\u00a0I'm in the lucky position to have worked with Leslie in the past and I am even more happy to work with here again! Given the enormous responsibility that comes with an open source project like Elasticsearch I can't really think of better fit for the role of ensuring community happiness, helping on project culture, and \u00a0organising events for devs and geeks. Welcome Leslie! \u00a0 ps: ...wanna join this team too? We are ! \n"}<br>{"index": {"_id": 1480}}<br>{"title":"This Week in Elasticsearch - August 14, 2013","seo_title":"","url":"\/blog\/2013-08-14-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"August 14, 2013","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to the seventh issue of . In this format we try to inform you about the latest and greatest changes in elasticsearch. We try to cover what happened in the github repositories, as well as all the events happening about elasticsearch and give you a small peek in the future. Elasticsearch core Elasticsearch ecosystem We try to give you some more information about what is happening in the ecosystem we are maintaining around elasticsearch, be it plugin or driver releases or news about kibana. Elasticsearch community Got an interesting open source project, plugin, driver or anything else for elasticsearch? Here is your time to shine! Just drop us a note and we will list it here (and on the .org website, of course!). Meetups Talks\/Slides Also, if you are interested in a core elasticsearch training, the next locations are Amsterdam at 20th, Austin at the 26th and Toronto at the 29th of August. For more locations, check the If you are interested in all this, we are . We are interested in your skills, not in your location. Just drop us a note. \n"}<br>{"index": {"_id": 1481}}<br>{"title":"welcome lee","seo_title":"","url":"\/blog\/welcome-lee","author":{"name":""},"date":"August 12, 2013","category":"","locales":"","content":" I'd like to welcome Lee Hinman (\"\") to our team. Lee has been a long time elasticsearch user, running and using large elasticsearch clusters. He wrote quite a few plugins to Elasticsearch, such as . Last, Lee is the author of the upcoming Elasticsearch Manning . welcome! p.s. we are . \n"}<br>{"index": {"_id": 1482}}<br>{"title":"This Week in Elasticsearch - August 07, 2013","seo_title":"","url":"\/blog\/2013-08-07-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"August 07, 2013","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to the sixth issue of . In this format we try to inform you about the latest and greatest changes in elasticsearch. We try to cover what happened in the github repositories, as well as all the events happening about elasticsearch and give you a small peek in the future. Elasticsearch core Elasticsearch ecosystem We try to give you some more information about what is happening in the ecosystem we are maintaining around elasticsearch, be it plugin or driver releases or news about kibana. Elasticsearch community Got an interesting open source project, plugin, driver or anything else for elasticsearch? Here is your time to shine! Just drop us a note and we will list it here (and on the .org website, of course!). Meetups Also, if you are interested in a core elasticsearch training, the next locations are Boston next week, Amsterdam (sold out!) at the 20th and Austin at the 24th og August. For more locations, check the If you are interested in all this, we are . We are interested in your skills, not in your location. Just drop us a note. \n"}<br>{"index": {"_id": 1483}}<br>{"title":"0.90.3 Released","seo_title":"","url":"\/blog\/0-90-3-released","author":{"name":"Alexander Reelsen"},"date":"August 06, 2013","category":"Engineering","locales":"","content":" The Elasticsearch dev team is pleased to announce the release of\u00a0, which is based on Lucene 4.4. You can download it\u00a0.Noticeable changes in 0.90.3 include performance improvements to the has_child query, and improved cluster stability and handling of large cluster states (many indices\/shards\/aliases). A full list of changes can be found .An exciting new experimental feature that we back ported to 0.90.3 is a new type of suggester called . This is a real-time, prefix oriented suggestion that supports updates in real time while also maintaining an efficient (speed and resource) data structure to provide extreme low latency suggestions cases, specifically as-you-type ones. A blog post describing this exciting new features with actual use cases will be posted shortly.Please , and let us know what you think.: If you use the analysis, mapper attachments or cloud plugins, you'll need to update to the newest version of the plugin to be compatible with the new 0.90.3 release. \n"}<br>{"index": {"_id": 1484}}<br>{"title":"welcome adrien","seo_title":"","url":"\/blog\/welcome-adrien","author":{"name":""},"date":"August 02, 2013","category":"","locales":"","content":" I'd like to welcome Adrien Grand (\"\") to our team (long overdue...). Adrien is an Apache Lucene committer, and some of his contributions include , (and many more). He also maintains the compression codec in Java (the fastest Java compression out ).\u00a0Adrien has been heavily\u00a0\u00a0with Elasticsearch for some time. With someone of Adrien's scale, amazing things will happen for both Apache Lucene and Elasticsearch now that he is fully dedicated to both projects. welcome! p.s. we are . \n"}<br>{"index": {"_id": 1485}}<br>{"title":"welcome britta","seo_title":"","url":"\/blog\/welcome-britta","author":{"name":""},"date":"July 31, 2013","category":"","locales":"","content":" I'd like to welcome Britta Weber (\"\") to our team (long overdue...). Britta is almost done with her PhD in computer science, developing Machine Learning algorithms to process electron microscopy image data. She has already contributed to elasticsearch the new \u00a0implementation, and a wonderful new query (including support for built in decaying functions).\u00a0With someone as smart as Britta, I'm excited about what she can contribute to our company and product. welcome! p.s. we are . \n"}<br>{"index": {"_id": 1486}}<br>{"title":"This Week in Elasticsearch - July 31, 2013","seo_title":"","url":"\/blog\/2013-07-31-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"July 31, 2013","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to the fifth issue of . In this format we try to inform you about the latest and greatest changes in elasticsearch. We try to cover what happened in the github repositories, as well as all the events happening about elasticsearch and give you a small peek in the future. Elasticsearch core Elasticsearch ecosystem We try to give you some more information about what is happening in the ecosystem we are maintaining around elasticsearch, be it plugin or driver releases or news about kibana. Elasticsearch community Got an interesting open source project, plugin, driver or anything else for elasticsearch? Here is your time to shine! Just drop us a note and we will list it here (and on the .org website, of course!). Meetups Also, if you are interested in a core elasticsearch training, the next locations are San Francisco (limited offer: get three seats for the price of two!) and Boston at the beginning of August. For more locations, check the If you are interested in all this, we are . We are interested in your skills, not in your location. Just drop us a note. \n"}<br>{"index": {"_id": 1487}}<br>{"title":"welcome zach","seo_title":"","url":"\/blog\/welcome-zach","author":{"name":""},"date":"July 29, 2013","category":"","locales":"","content":" I'd like to welcome Zachary Tong (\"\") to our team (long overdue...). I am sure you've seen Zach around, he has been active about Elasticsearch (on his own blog, and our own), wrote a , , and many . Zach has an amazing gift distilling complex concepts into simple explanations, and he will help us improve our documentation and online resources around Elasticsearch. He will also help push forward Elasticsearch in PHP land. welcome! p.s. we are . \n"}<br>{"index": {"_id": 1488}}<br>{"title":"This Week in Elasticsearch - July 24, 2013","seo_title":"","url":"\/blog\/2013-07-24-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"July 24, 2013","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to the fourth issue of . In this format we try to inform you about the latest and greatest changes in elasticsearch. We try to cover what happened in the github repositories, as well as all the events happening about elasticsearch and give you a small peek in the future. Elasticsearch core Elasticsearch ecosystem We try to give you some more information about what is happening in the ecosystem we are maintaining around elasticsearch, be it plugin or driver releases or news about kibana. Elasticsearch community Got an interesting open source project, plugin, driver or anything else for elasticsearch? Here is your time to shine! Just drop us a note and we will list it here (and on the .org website, of course!). Meetups Also, if you are interested in a core elasticsearch training, the next locations are San Francisco (limited offer: get three seats for the price of two!) and Boston at the beginning of August. For more locations, check the . If you are interested in all this, we are . We are interested in your skills, not in your location. Just drop us a note. \n"}<br>{"index": {"_id": 1489}}<br>{"title":"welcome boaz","seo_title":"","url":"\/blog\/welcome-boaz","author":{"name":""},"date":"July 23, 2013","category":"","locales":"","content":" I'd like to welcome Boaz Leskes (\"\") to our team (long overdue...). Boaz has been an active user of Elasticsearch for a few years now, is an active developer within the Elasticsearch ecosystem (), started the work on multi value memory optimizations in elasticsearch field data, and quite a few contributions to . Last but not least, Boaz is the organizer of the . welcome! p.s. we are . \n"}<br>{"index": {"_id": 1490}}<br>{"title":"This Week in Elasticsearch - July 17, 2013","seo_title":"","url":"\/blog\/2013-07-17-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"July 17, 2013","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to the third issue of . In this format we try to inform you about the latest and greatest changes in elasticsearch. We try to cover what happened in the github repositories, as well as all the events happening about elasticsearch and give you a small peek in the future. Elasticsearch core Elasticsearch community Got an interesting open source project, plugin, driver or anything else for elasticsearch? Here is your time to shine! Just drop us a note and we will list it here (and on the .org website, of course!). Meetups Also, if you are interested in a core elasticsearch training, the next locations are San Francisco and Boston in August. For more locations, check the If you are interested in all this, we are . We are interested in your skills, not in your location. Just drop us a note. \n"}<br>{"index": {"_id": 1491}}<br>{"title":"This Week in Elasticsearch - July 11, 2013","seo_title":"","url":"\/blog\/2013-07-11-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"July 11, 2013","category":"This week in Elasticsearch and Apache Lucene","locales":"","content":" Welcome to the second issue of . In this format we try to inform you about the latest and greatest changes in elasticsearch. We try to cover what happened in the github repositories, as well as all the events happening about elasticsearch and give you a small peek in the future. Elasticsearch core Elasticsearch ecosystem We try to give you some more information about what is happening in the ecosystem we are maintaining around elasticsearch, be it plugin or driver releases or news about kibana. Elasticsearch community Got an interesting open source project, plugin, driver or anything else for elasticsearch? Here is your time to shine! Just drop us a note and we will list it here (and on the .org website, of course!). Meetups Talks\/Slides Also, if you are interested in a core elasticsearch training, the next dates are San Francisco and New York the next week. For more dates, check the If you are interested in all this, we are . We are interested in your skills, not in your location. Just drop us a note. \n"}<br>{"index": {"_id": 1492}}<br>{"title":"Explosive Growth Fuels Demand For Talent","seo_title":"","url":"\/blog\/explosive-growth-fuels-demand-for-talent","author":{"name":"Steven Schuurman"},"date":"July 03, 2013","category":"","locales":"","content":" I believe Elasticsearch is destined for greatness, and here\u2019s why: since 2010 we have been constantly innovating Elasticsearch based on our vision for the future for one of the biggest holes in the IT landscape today, and that solution is now being downloaded thousands and thousands of times \u2026 per day! But the innovation doesn\u2019t stop there: we have a talented team hard at work to bring further revolutionary ideas into the market, which you can expect hear more about in the future. We believe this is how software innovation should work: think ahead and create wonderful products that don\u2019t just solve problems, but also create new possibilities. Elasticsearch fits this description very nicely. The product isn\u2019t merely a solution to problem: we find our customers actually creating new products based on Elasticsearch, that they wouldn\u2019t have been able to drive to market without it. If you look at what we\u2019re currently working on, you\u2019ll undoubtedly agree that Elasticsearch is only the beginning of an exciting journey. The main reason being, that even though there are many other solutions out there that also solve part of the \u201cbig data challenge\u201d, no other product was designed from the ground up to provide a single holistic end-to-end experience. Combine that with our team\u2019s near obsession with user friendliness, and you end up with a product that is really easy to use, and that\u2019s getting noticed. Now this is where we are today. However, we have some truly incredibly advanced ideas for releases that we believe will be as groundbreaking as Elasticsearch is today. We are unbelievably passionate about creating Elasticsearch, and know there are more people like us out there. We are driven by our shared passion for making a difference. Creating products that allow others to have new insights into their business, or innovate by driving new products to market, is about as rewarding as it gets. With us progressing Elasticsearch faster than ever before, we have to grow our tech team as well as the group of people that make up the commercial and operational side of our company. We are therefore looking passionate team-players in Sales, Marketing, Technology and Operations that love driving change. We are not interested in merely being ready for the future, we\u2019re creating it. We\u2019re not exactly big believers in tight hierarchical layers and skills set requirements in job descriptions. That\u2019s why you won\u2019t find things like \u201c5 years of experience with X\u201d or \u201cMasters degree in ABC\u201d on our job postings. We need you to excel at what you do, or have the ambition to learn how to excel. Here\u2019s a quick overview of what kind of expertise we\u2019re seeking to expand our team with here at Elasticsearch. We\u2019re looking for Elasticsearch developers that wish to help us progress our product. Whether it\u2019s contributing to the core (in Java) or to the clients (in many other languages) we would love to talk to you. You have the possibility to have a broad and exciting role, where your responsibilities go way beyond writing code. If you want to, you have the possibility to be involved in teaching training courses, creating marketing materials, talking to customers in commercial processes, and speaking at conferences around the world. If you love working with happy customers that are about as excited about a product as you are, you should consider working at Elasticsearch to provide tech support to our customer base. It\u2019s growing fast, and they have questions that need answering. We are as passionate about our business execution as we are about creating new technology. When you speak with us, you will find that our demand generation engine is designed and operated by the very best people in the industry. Our marketing team and our sales teams consist of true industry professionals that are experts in their field. Whenever I talk with anybody on the marketing or sales teams, it\u2019s very rewarding to see how proud they are to represent Elasticsearch. Here you have the opportunity to harness the great momentum of our open source technology to deliver outstanding products to our customers. We\u2019re a global company. Elasticsearch has its main European presence in The Netherlands, and its main US presence in the Bay Area just south of San Francisco, but we hiring into many other places. We have hubs of people in Paris, London, Berlin and Prague, but also have talented individuals working either from their homes across Europe and the US. To us, your location is less important than your qualities, so don\u2019t hesitate to contact us even if you\u2019re living 10,000 miles from our nearest office location. Our developers love to talk about Elasticsearch and what it\u2019s like to work here. You can meet them yourself on the What this comes down to, is that if you want to help us revolutionize an industry by actually delivering a solution that works, please reach out to us. We\u2019d love to connect. \n"}<br>{"index": {"_id": 1493}}<br>{"title":"This Week in Elasticsearch - July 02, 2013","seo_title":"","url":"\/blog\/2013-07-02-this-week-in-elasticsearch","author":{"name":"Alexander Reelsen"},"date":"July 02, 2013","category":"","locales":"","content":" Welcome to the first issue of . In this format we try to inform you about the latest and greatest changes in elasticsearch. We try to cover what happened in the github repositories, as well as all the events in the elasticsearch community and give you a small peek into the future. Elasticsearch core Elasticsearch ecosystem Elasticsearch maintains a number of projects outside the core server code. In this section, we will try to give you some more information about what is happening in the ecosystem around elasticsearch, be it plugin or driver releases or news about kibana. Elasticsearch community Got an interesting open source project, plugin, driver or anything else for elasticsearch? Here is your time to shine! Just drop us a note and we will list it here (and on the .org website, of course!). Meetups There are plenty of meetup groups about elasticsearch on , so maybe a meetup for your city already exists. In case you could not find your favorite city for a meetup in the list, contact us and let us try to create an elasticsearch user group! Talks Also, if you are interested in a core elasticsearch training, the next dates are Munich next week, or San Francisco and New York the week after. For more dates, check the Want to work at Elasticsearch? We are ! We are interested in your skills, not in your location. Drop us a note if you are interested. \n"}<br>{"index": {"_id": 1494}}<br>{"title":"Elasticsearch 0.90.2 Released","seo_title":"","url":"\/blog\/0-90-2-released","author":{"name":"Clinton Gormley"},"date":"June 26, 2013","category":"Engineering","locales":"","content":" global wrapper \n"}<br>{"index": {"_id": 1495}}<br>{"title":"Elasticsearch Versioning Support","seo_title":"","url":"\/blog\/elasticsearch-versioning-support","author":{"name":"Boaz Leskes"},"date":"June 24, 2013","category":"Engineering","locales":"","content":" Elasticsearch Versioning Support One of the key principles behind Elasticsearch is to allow you to make the most out of your data. Historically, search was a read-only enterprise where a search engine was loaded with data from a single source. As the usage grows and Elasticsearch becomes more central to your application, it happens that data needs to be updated by multiple components. Multiple components lead to concurrency and concurrency leads to conflicts. Elasticsearch's versioning system is there to help cope with those conflicts. The need for versioning - an example To illustrate the situation, let's assume we have a website which people use to rate t-shirt design. The website is simple. It lists all designs and allows users to either give a design a thumbs up or vote them down using a thumbs down icon. For every t-shirt, the website shows the current balance of up votes vs down votes. A record for each search engine looks like this: curl -XPOST 'http:\/\/localhost:9200\/designs\/shirt\/1' -d' { \"name\": \"elasticsearch\", \"votes\": 999 }' As you can see, each t-shirt design has a name and a votes counter to keep track of it's current balance. To keeps things simple and scalable, the website is completely stateless. When someone looks at a page and clicks the up vote button, it sends an AJAX request to the server which should indicate to elasticsearch to update the counter. To do so, a naive implementation will take the current votes value, increment it by one and send that to elasticsearch: curl -XPOST 'http:\/\/localhost:9200\/designs\/shirt\/1' -d' { \"name\": \"elasticsearch\", \"votes\": 1000 }' This approach has a serious flaw - it may lose votes. Say both Adam and Eve are looking at the same page at the same time. At the moment the page shows 999 votes. Since both are fans, they both click the up vote button. Now Elasticsearch gets two identical copies of the above request to update the document, which it happily does. That means that instead of having a total vote count of 1001, the\u00a0vote count is now 1000. Oops. Of course, the allows you to be smarter and communicate the fact that the vote can be incremented rather than set to specific value: curl -XPOST 'http:\/\/localhost:9200\/designs\/shirt\/1\/_update' -d' { \"script\" : \"ctx._source.votes += 1\" }' Doing it this way, means that Elasticsearch first retrieves the document internally, performs the update and indexes it again. While this makes things much more likely to succeed, it still carries the same potential problem as before. During the small window between retrieving and indexing the documents again, things can go wrong. To deal with the above scenario and help with more complex ones, Elasticsearch comes with a built-in versioning system. Elasticsearch's versioning system Every document you store in Elasticsearch has an associated version number. That version number is a positive number between 1 and 2 -1 (inclusive). When you index a document for the very first time, it gets the version 1 and you can see that in the response Elasticsearch returns. This is, for example, the result of the first cURL command in this blog post: { \"ok\": true, \"_index\": \"designs\", \"_type\": \"shirt\", \"_id\": \"1\", \"_version\": 1 } With every write-operation to this document, whether it is an , or , Elasticsearch will increment the version by 1. This increment is atomic and is guaranteed to happen if the operation returned successfully. Elasticsearch will also return the current version of documents with the response of get operations (remember those are real time) and it can also be to return it with every search result. Optimistic locking So back in our toy example, we needed a solution to a scenario where potentially two users try to update the same document at the same time. Traditionally this will be solved with locking: before updating a document, one will acquire a lock on it, do the update and release the lock. When you have a lock on a document, you are guaranteed that no one will be able to change the document. In many applications this also means that if someone is modifying a document no one else is able to read from it until the modification is done. This type of locking works but it comes with a price. In the context of high throughput systems, it has two main downsides: Elasticsearch's versioning system allows you easily to use another pattern called optimistic locking. Instead of acquiring a lock every time, you tell Elasticsearch what version of the document you expect to find. If the document didn't change in the meantime, your operation succeeds, lock free. If something did change in the document and it has a newer version, Elasticsearch will signal it to you so you can deal with it appropriately. Going back to the search engine voting example above, this is how it plays out. When we render a page about a shirt design, we note down the current version of the document. This is returned with the response of the request we do for the page: curl -XGET 'http:\/\/localhost:9200\/designs\/shirt\/1' { \"_index\": \"designs\", \"_type\": \"shirt\", \"_id\": \"1\", \"_version\": 4, \"exists\": true, \"_source\": { \"name\": \"elasticsearch\", \"votes\": 1002 } } After the user has cast her vote, we can instruct Elasticsearch to only index the new value (1003) if nothing has changed in the meantime: (note the extra query string parameter) curl -XPOST 'http:\/\/localhost:9200\/designs\/shirt\/1?version=4' -d' { \"name\": \"elasticsearch\", \"votes\": 1003 }' Internally, all Elasticsearch has to do is compare the two version numbers. This is much lighter than acquiring and releasing a lock. If no one changed the document, the operation will succeed with a status code of . However, if someone did change the document (thus increasing its internal version number), the operation will fail with a status code of . Our website can now respond correctly. It will retrieve the new document, increase the vote count and try again using the new version value. Chances are this will succeed. If it doesn't we simply repeat the procedure. This pattern is so common that Elasticsearch's endpoint can do it for you. You can set the parameter to tell it to retry the operation in the case of version conflicts. It is especially handy in combination with a scripted update. For example, this cURL will tell Elasticsearch to try to update the document up to 5 times before failing: curl -XPOST 'http:\/\/localhost:9200\/designs\/shirt\/1\/_update?retry_on_conflict=5' -d' { \"script\" : \"ctx._source.votes += 1\" }' Note that the versioning check is completely optional. You can choose to enforce it while updating certain fields (like ) and ignore it when you update others (typically text fields, like ). It all depends on the requirements of your application and your tradeoffs. Already have a versioning system in place? Next to its internal support, Elasticsearch plays well with document versions maintained by other systems. For example, you may have your data stored in another database which maintains versioning for you or may have some application specific logic that dictates how you want versioning to behave. In this situations you can still use Elasticsearch's versioning support, instructing it to use an version type. Elasticsearch will work with any numerical versioning system (in the 1:2-1 range) as long as it is guaranteed to go up with every change to the document. To tell Elasticssearch to use external versioning, add a parameter along with the parameter in request that changes data. For example: curl -XPOST 'http:\/\/localhost:9200\/designs\/shirt\/1?version=526&version_type=external' -d' { \"name\": \"elasticsearch\", \"votes\": 1003 }' Maintaing versioning somewhere else means Elasticsearch doesn't necessarily know about every change in it. That has subtle implications to how versioning is implemented. Consider the indexing command above. With versioning, it means \"only index this document update if its current version is equal to 526\". If the version matches, Elasticsearch will increase it by one and store the document. However, with an external versioning system this will be a requirement we can't enforce. Maybe that versioning system doesn't increment by one every time. Maybe it jumps with arbitrary numbers (think time based versioning). Or maybe it is hard to communicate every single version change to Elasticsearch. For all of those reasons, the versioning support behaves slightly differently. With set to , Elasticsearch will store the version number as given and will not increment it. Also, instead of checking for an exact match, Elasticsearch will only return a version collision error if the version currently stored is greater or equal to the one in the indexing command. This effectively means \"only store this information if no one else has supplied the same or a more recent version in the meantime\". Concretely, the above request will succeed if the stored version number is smaller than 526. 526 and above will cause the request to fail. when using versioning, make sure you always add the current (and ) to any index, update or delete calls. If you forget, Elasticsearch will use it's internal system to process that request, which will cause the version to be incremented erroneously. Some final words about deletes. Deleting data is problematic for a versioning system. Once the data is gone, there is no way for the system to correctly know whether new requests are dated or actually contain new information. For example, say we run the following to delete a record: curl -XDELETE 'http:\/\/localhost:9200\/designs\/shirt\/1?version=1000&version_type=external' That delete operation was version 1000 of the document. If we just throw away everything we know about that, a following request that comes out of sync will do the wrong thing: curl -XPOST 'http:\/\/localhost:9200\/designs\/shirt\/1\/?version=999&version_type=external' -d' { \"name\": \"elasticsearch\", \"votes\": 3001 }' If we were to forget that the document ever existed, we would just accept this call and create a new document. However, the version of the operation (999) actually tells us that this is old news and the document should stay deleted. Easy, you may say, do not really delete everything but keep remembering the delete operations, the doc ids they referred to and their version. While that indeed does solve this problem it comes with a price. We will soon run out resources if people repeatedly index documents and then delete them. Elasticsearch search strikes a balance between the two. It does keep records of deletes, but forgets about them after a minute. This is called deletes garbage collection. For most practical use cases, 60 second is enough for the system to catch up and for delayed requests to arrive. If this doesn't work for you, you can change it by setting on your index to some other time span. \n"}<br>{"index": {"_id": 1496}}<br>{"title":"Changing Mapping with Zero Downtime","seo_title":"","url":"\/blog\/changing-mapping-with-zero-downtime","author":{"name":"Clinton Gormley"},"date":"June 17, 2013","category":"Engineering","locales":"de-de,fr-fr,ko-kr","content":" global wrapper \n"}<br>{"index": {"_id": 1497}}<br>{"title":"Webinar: Log Analysis with Elasticsearch","seo_title":"","url":"\/blog\/log-analysis-with-elasticsearch","author":{"name":"Rashid Khan"},"date":"June 14, 2013","category":"","locales":"","content":" \u00a0 With growing infrastructure, expanded automation and increasing server:staff ratios, lean operations teams are leading the charge to extract intelligence\u00a0from logging data. Join us to learn how Elasticsearch fits into an easy to deploy log analysis architecture. We'll talk about: Rashid Khan will be your host for this\u00a0live webinar on on Wednesday, June 19th at 9:00am PDT (6pm CET). Rashid is a logging nerd and the author of Kibana, a browser based log and data analysis interface for Elasticsearch \n"}<br>{"index": {"_id": 1498}}<br>{"title":"Terms Filter Lookup","seo_title":"","url":"\/blog\/terms-filter-lookup","author":{"name":"Zachary Tong"},"date":"June 11, 2013","category":"Engineering","locales":"","content":" There is a new feature in the 0.90 branch that is pretty awesome: the now supports document lookups. In a normal Terms Filter, you provide a list of Terms that you want to filter against. This is fine for small lists, but what if you have 100 terms? A thousand terms? That is a lot of data to pass over the wire. If that list of terms is stored in your index somewhere, you also have to retrieve it first\u2026just so you can pass it back to Elasticsearch. The new lookup feature tells Elasticsearch to use another document as your terms array. Instead of passing 1000 terms, you simply tell the Terms Filter . Elasticsearch will fetch that document internally, extract the terms and perform your query. Let\u2019s work our way through a concrete example of how it all works. A concrete exampleThe I encourage you to read over it. But I come from a biology background and you can only read so many Twitter examples\u2026so let\u2019s try something a bit different and bioinformatics-y. Imagine you run a bioinformatics search engine and database. You have two indices holding two different types of data. First, you have an index that stores academic research articles. This document represents a single scientific paper. It has two fields, the title of the paper and a list of all proteins relevant to the topic: curl -XPUT localhost:9200\/papers\/paper\/paper789 -d '{ \"title\" : \"Ahi1, whose human ortholog is mutated in Joubert syndrome, is required for Rab8a localization, ciliogenesis and vesicle trafficking.\" \"proteins\" : [ \"Ahi1\", \"Rab8a\" ] }' Next, you have an index which holds data from a . Microarrays are a method to determine whether a gene\u2019s activity is more (\u201cup-regulated\u201d) or less (\u201cdown-regulated\u201d) than its normal rate. Microarrays are about the size of a postage stamp and test thousands of genes at once. The resulting \u201cup-regulated\u201d field could potentially be thousands long: curl -XPUT localhost:9200\/microarrays\/experiment\/experiment1234 -d '{ \"upregulated_proteins\" : [ \"Ahi1\", \"Wnt\", \"SHH\", \"CDC42\", \"GSK-3B\", [.......] ] }' Given this data, a very common question might be: . Filtering the papersBefore lookups, the way to accomplish this is a GET plus a Filtered Search. First you have to GET the microarray experiment and extract the array of terms: curl -XGET localhost:9200\/microarrays\/experiment\/experiment1234 # ...Extract array in your app... # Then perform a search query using the filter you need: curl -XGET localhost:9200\/papers\/paper\/_search -d '{ \"query\":{ \"filtered\":{ \"filter\":{ \"terms\" : { \"proteins\":[ \"Ahi1\", \"Wnt\", \"SHH\", \"CDC42\", \"GSK-3B\", [.......] ] } } } } } This works, but you can see why it isn\u2019t ideal. Not only do we need to perform two requests \u2013 a GET and a Search \u2013 but we have to shuffle a potentially large term array across the wire twice. The lookup feature allows you to bypass this inefficiency. Filtering, this time with LookupsLookups use documents themselves as the list of Terms, which means you can avoid unnecessary requests. Let\u2019s try again, but this time with lookups. The data is organized the same as before, but when we search we skip the extraneous GET phase and go straight to the Terms Filter with the new Lookup syntax: curl -XGET localhost:9200\/papers\/paper\/_search -d '{ \"query\" : { \"filtered\" : { \"filter\" : { \"terms\" : { \"proteins\" : { \"index\" : \"microarrays\", \"type\" : \"experiment\", \"id\" : \"experiment1234\", \"path\" : \"upregulated_proteins\" }, \"_cache_key\" : \"experiment_1234\" } } } } }' Neat! How does it work? Let\u2019s just look at the new Terms Filter syntax line by line: Filter terms in the field\u2026. \u2026matching the array of terms located in the field, inside the document located at \u2026 \u2026and save (cache) the result of this filter under the name \u201cexperiment_1234\u2033 so we can use it again later without loading the document. More than just convenienceThe new Lookup feature is certainly useful. But it offers more than just convenience: there are tangible performance benefits. Performance can be boosted even more if the Lookup index ( in this example) is fully replicated to each node. The Lookup will prefer shards that are local, removing the need to query other shards to get the lookup document. While inter-node latency is usually pretty low, zero latency is always faster. ConclusionThis is just one example of using the new Lookup feature. Lookups are predominantly used to boost performance when filtering large Term lists. Check out the for more details about settings (adjusting cache memory, etc) as well as the standard Twitter example. \n"}<br>{"index": {"_id": 1499}}<br>{"title":"Customizing Your Document Routing","seo_title":"","url":"\/blog\/customizing-your-document-routing","author":{"name":"Zachary Tong"},"date":"June 03, 2013","category":"Engineering","locales":"","content":" global wrapper \n"}<br>{"index": {"_id": 1500}}<br>{"title":"Elasticsearch 0.90.1 Released","seo_title":"","url":"\/blog\/0-90-1-released","author":{"name":"Clinton Gormley"},"date":"May 30, 2013","category":"Engineering","locales":"","content":" The Elasticsearch dev team are pleased to announce the release of E, which is based on Lucene 4.3. You can download it\u00a0.We highly recommend upgrading to 0.90.1 from 0.90.0 as this release includes some key bug fixes, notably a fix to the bool filter which could produce incorrect results () and a fix to the DFS search types ().Besides the bug fixes, 0.90.1 also has some nice new features and enhancements, especially: There are many more changes which you can read about on the . Please download and use 0.90.1, and let us know what you think. \n"}<br>{"index": {"_id": 1501}}<br>{"title":"All About Elasticsearch Filter BitSets","seo_title":"","url":"\/blog\/all-about-elasticsearch-filter-bitsets","author":{"name":"Zachary Tong"},"date":"May 06, 2013","category":"Engineering","locales":"","content":" global wrapper \n"}<br>{"index": {"_id": 1502}}<br>{"title":"0.90.0 Released","seo_title":"","url":"\/blog\/0-90-0-released","author":{"name":"Clinton Gormley"},"date":"April 29, 2013","category":"News","locales":"","content":" The Elasticsearch dev team are pleased to announce the release of - the first stable release of Elasticsearch based on Lucene 4. You can download it .Besides all of the performance and memory improvements made by Lucene, version 0.90.0 comes with a host of improvements and new features specific to Elasticsearch itself. \u00a0Probably the biggest improvement that our users will notice is much better memory usage when loading for or on a field. Fielddata uses less memory and makes it easier for the garbage collector to do its work, resulting in more stable clusters. \u00a0This change alone makes it worth upgrading.Other user-visible features include: On Thursday 2nd May at 9am PST (6pm CET) we will be holding a free (reg. required) live webinar explaining more about the new features in 0.90 and how you can use them. \u00a0Come along and ask questions. You can .The next major release will be 1.00, which we have just finished planning at our dev week in Amsterdam. We will post about the new features we intend to include in 1.00 soon, but suffice to say, there are some very cool things planned. \u00a0In the meantime, please download and use 0.90, and let us know what you think. \n"}<br>{"index": {"_id": 1503}}<br>{"title":"Webinar: What's new in Elasticsearch 0.90?","seo_title":"","url":"\/blog\/webinar-whats-new-in-elasticsearch-0-90","author":{"name":"Clinton Gormley"},"date":"April 25, 2013","category":"","locales":"","content":" (Thursday 2 May @ 9:00am PT, 6pm CET) We're getting ready to release Elasticsearch 0.90, the first version to use Apache Lucene 4. But this release is not just about Lucene 4 - there are a whole lot of goodies that are going to make your life easier, such as: We will be talking about these updates live on Thursday, May 2nd at 9:00am PDT (6pm CET). The webinar will be hosted by Clinton Gormley, the first user of Elasticsearch and author of ElasticSearch.pm, the official Perl API and other Perl modules for Elasticsearch. \u00a0 \n"}<br>{"index": {"_id": 1504}}<br>{"title":"0.90.0.RC2 Released","seo_title":"","url":"\/blog\/0-90-0-rc2-released","author":{"name":"Shay Banon"},"date":"April 08, 2013","category":"","locales":"","content":" version is out, the last release candidate before the 0.90 release. You can download it . This version contains a number of bug fixes and enhancements which bring us closer to a stable release of 0.90. It is also our first release to make an RPM available, which should work for RedHat, Fedora and openSUSE. Some of the changes are: Upgrading to it from previous 0.90.* releases is highly recommended. \n"}<br>{"index": {"_id": 1505}}<br>{"title":"0.20.6 Released","seo_title":"","url":"\/blog\/0-20-6-released","author":{"name":"Shay Banon"},"date":"March 25, 2013","category":"","locales":"","content":" version is out. You can download it . This release includes several critical bug fixes, and it is a recommended upgrade for and users. The main critical bug fixed () relates to a problem that has been haunting us for some time now, which can cause full shard deletion when running out of OS system resources. We finally managed to nail it down (you can track the ), and backported a fix to 0.20. \n"}<br>{"index": {"_id": 1506}}<br>{"title":"0.90.0.RC1 Released","seo_title":"","url":"\/blog\/0-90-0-rc1-released-2","author":{"name":"Shay Banon"},"date":"March 20, 2013","category":"","locales":"","content":" version is out, the first release candiate for the 0.90 release. You can download it . This release includes an upgrade to Lucene 4.2, many improvements to the suggester feature (including its own dedicated API), another round of memory improvements to field data (long type will now automatically \u201cnarrow\u201d to the smallest type when loaded to memory) and several bug fixes. Upgrading to it from previous beta releases is highly recommended. \n"}<br>{"index": {"_id": 1507}}<br>{"title":"welcome alexander!","seo_title":"","url":"\/blog\/welcome-alexander","author":{"name":""},"date":"March 20, 2013","category":"","locales":"","content":" I'd like to welcome Alexander Reelsen () to our team. Alexander has been involved with elasticsarch for quite some time now, with work ranging from building the FST suggester plugin, to the opennlp plugin, to different visualization components (see more of Alexander's work ) and we are very privileged to have him join us. welcome! \n"}<br>{"index": {"_id": 1508}}<br>{"title":"0.90.0.Beta1 Released","seo_title":"","url":"\/blog\/0-90-0-rc1-released","author":{"name":"Shay Banon"},"date":"March 20, 2013","category":"","locales":"","content":" version is out. You can download it . Why 0.90? More than anything else, it shows where we are heading. The next stable release after 0.90 will be the 1.0 release of elasticsearch. Elasticsearch is being used in production, in mission critical applications, daily, and we feel its time for us to move to that blessed 1.0 release. It is also an indication of the breadth of changes that accompany this release. Down the Road Our aim now is to get 0.90.0 GA out the door. We are working hard on finalizing the last bits to get it done, and hope for a quick cycle to get to the GA. Once its out, we will blog about what we hope to get to in our 1.0 release. Features This release includes many new features, an evidence of the speed of development we have achieved with a team of extremely talented people working daily on the codebase. We are also actively working on documenting all the new features in the guide. Here are some of the highlighted features in this release: New Routing Algorithm () Up to 0.90.0, elasticsearch used a relatively naive algorithm of balancing shards across the cluster, by trying to maintaining an even number of shards across (data) nodes. This created problems with clusters holding many indices, specifically with varied sizes. The new algorithm takes the fact that shards belong to an index into account, trying to balance an index out across all nodes. The new algorithm is based on a weight function, and we will slowly add additional weight options (such as shard size) down the road. Suggst () The suggest feature (part of a search request) allows Elasticsearch to provide suggestions for the given text based on the corpus that is part of the index. The current implemented suggest type uses the Levenshtein distance on a per term basis to potentially provide spelling suggestions. This feature is considered experimental, mainly in the request and response format. We are actively working on additional suggest implementation (such as phrase based suggestion), and this work will be finalized towards the 0.90.0 GA release. Lucene 4 Codecs () Elasticsearch exposes the new codecs infrastructure added by Lucene 4. Codecs allow complete control over how the index is actually stored and read. Though implementing a custom Codec can be considered adventurous (but quite doable as a plugin), elasticsearch exposes several options to control codecs using the mappings. For example, here is an example of mappings that will load the index for the field into memory, and use a bloom filter for the relatively unique field: { \"my_type\" : { \"properties\" : { \"tag\" : {\"type\" : \"string\", \"postings_format\" : \"memory\"}, \"external_id\" : {\"type\" : \"string\", \"postings_format\" : \"bloom_default\"} } } } A nice feature is the ability to change on the fly for existing mapping, which will start to be used for new data as it is indexed, or applied to old data as merging \/ optimization happens. Field Data Refactoring Field Data in elasticsearch is the data structure used to load field values into memory for sorting and faceting. The data structure has been completely reimplemented, requiring considerably less memory than before, and has been abstracted away to allow for additional future implementations. Multi Value Sorting (, ) Sorting on fields with multiple numeric values now work as expected, properly choosing how to sort based on the sort direction. Sorting on nested documents is now supported as well (with an option filter). On top of it, sorting on multiple values now support the ability to sort based on the , , , and values. Lucene 4 Similarity () Similarity in Lucene allows us to control how relevancy or scoring is done. The new Lucene 4 adds exciting new similarity implementations, such as on top of the current TF\/ based one. It also allows us to set similarities per field, which is exposed in elasticsearch through mappings. Compression In 0.19, elasticsearch added compression to stored fields (the ), which had to be enabled by using a specific setting. Now, compression is turned on by default, and it uses the new compression support in Lucene 4.1. The old compression settings are no longer relevant. Rescore () The rescore feature enables us to \u201crescore\u201d a document returned by a query based on a secondary algorithm. Rescoring is commonly used if a scoring algorithm is too costly to be executed across the entire document set but efficient enough to be executed on the Top-K documents scored by a faster retrieval method. Lookup Terms Filter () This allows the filter to lookup the list of terms to filter by using another document in the cluster. It includes a highly optimized caching mechanism that works well with the existing filter caching. Here is an example: # index the information for user with id 2, specifically, its friends curl -XPUT localhost:9200\/users\/user\/2 -d '{ \"friends\" : [\"1\", \"3\"] }' # index a tweet, from user with id 2 curl -XPUT localhost:9200\/tweets\/tweet\/1 -d '{ \"user\" : \"2\" }' # search on all the tweets that match the friends of user 2 curl -XGET localhost:9200\/tweets\/_search -d '{ \"query\" : { \"filtered\" : { \"filter\" : { \"terms\" : { \"user\" : { \"index\" : \"users\", \"type\" : \"user\", \"id\" : \"2\", \"path\" : \"friends\" }, \"_cache_key\" : \"user_2_friends\" } } } } }' \n"}<br>{"index": {"_id": 1509}}<br>{"title":"welcome costin","seo_title":"","url":"\/blog\/welcome-costin","author":{"name":""},"date":"March 05, 2013","category":"","locales":"","content":" I'd like to welcome Costin Leau () to our team. Costin has spent his last 7+ years mainly in open source around the Java Spring ecosystem with anything and everything from the core container and data access to NoSQL and Hadoop. I personally have known Costin for quite some time now and am really excited about having such a great engineer on-board. welcome! \n"}<br>{"index": {"_id": 1510}}<br>{"title":"What is an Elasticsearch Index?","seo_title":"","url":"\/blog\/what-is-an-elasticsearch-index","author":{"name":"Zachary Tong"},"date":"February 24, 2013","category":"","locales":"","content":" What exactly is an index in Elasticsearch? Despite being a very basic question, the answer is surprisingly nuanced. <strong>$ curl -XGET localhost:9200\/SubaruFactory\/Cars\/SubaruImprezza <\/strong> <strong>$ curl -XGET localhost:9200\/logs-2013-02-22,logs-2013-02-21\/Errors\/_search?query=\"q:Error Message\" <\/strong> \n"}<br>{"index": {"_id": 1511}}<br>{"title":"Managing Relations Inside Elasticsearch","seo_title":"","url":"\/blog\/managing-relations-inside-elasticsearch","author":{"name":"Zachary Tong"},"date":"February 20, 2013","category":"Engineering","locales":"","content":" Data in the real world is rarely simple - often times it is a jumble of interlocking relations. How do you represent relational data in Elasticsearch? There are a few mechanisms that can be used to provide relation support. Each has their pros and cons, making them useful for different situations. Inner Objects The simplest mechanism are named \"inner objects\". These are JSON objects embedded inside your parent document: { \"name\":\"Zach\", \"car\":{ \"make\":\"Saturn\", \"model\":\"SL\" } } Simple, right? The \"car\" field is just another JSON object, with the inner object having two properties (\"make\" and \"model\"). This inner object mapping will work as long as you have a one-to-one relationship between the root object and the inner object. E.g. every person has at most one \"car\". But what if Zach owns two cars, and we add another person (Bob) who owns just one car? { \"name\" : \"Zach\", \"car\" : [ { \"make\" : \"Saturn\", \"model\" : \"SL\" }, { \"make\" : \"Subaru\", \"model\" : \"Imprezza\" } ] } { \"name\" : \"Bob\", \"car\" : [ { \"make\" : \"Saturn\", \"model\" : \"Imprezza\" } ] } Ignoring the fact that Saturn never made an Imprezza car, what happens when we try to search for it? Logically, only Bob has a \"Saturn Imprezza\", so we should be able to do a query like: `query: car.make=Saturn AND car.model=Imprezza` Right? . If you perform that query, you'll receive both documents as the result. What happens is that Elasticsearch internally flattens inner objects into a single object. So Zach's entry looks like this: { \"name\" : \"Zach\", \"car.make\" : [\"Saturn\", \"Subaru\"] \"car.model\" : [\"SL\", \"Imprezza\"] } Which explains why it was returned as a result. Elasticsearch is fundamentally flat, so internally the documents are represented as flattened fields. Hmm. Nested As an alternative to inner objects, Elasticsearch provides the concept of \" \". Nested documents look identical to inner objects at the document level, but provide the functionality we were missing above (as well as some limitations). Example nested document: { \"name\" : \"Zach\", \"car\" : [ { \"make\" : \"Saturn\", \"model\" : \"SL\" }, { \"make\" : \"Subaru\", \"model\" : \"Imprezza\" } ] } At the mapping level, nested types must be explicitly declared (unlike inner objects, which are automatically detected): { \"person\":{ \"properties\":{ \"name\" : { \"type\" : \"string\" }, \"car\":{ \"type\" : \"nested\" } } } } The problem with inner objects was that each nested JSON object is not treated as an individual component of the document. Instead they were merged with other inner objects sharing the same property names. This is not the case with nested documents. Each nested doc remains independent, and you can perform a query like `car.make=Saturn AND car.model=Imprezza` without a problem. Elasticsearch is still fundamentally flat, but it manages the nested relation internally to give the appearance of nested hierarchy. When you create a nested document, Elasticsearch actually indexes two separate documents (root object and nested object), then relates the two internally. Both docs are stored in the same Lucene block on the same Shard, so read performance is still very fast. This arrangement does come with some disadvantages. Most obvious, you can only access these nested documents using a special ` `. Another big disadvantage comes when you need to update the document, either the root or any of the objects. Since the docs are all stored in the same Lucene block, and Lucene never allows random write access to it's segments, updating one field in the nested doc will force a reindex of the document. This includes the root and any other nested objects, even if they were not modified. Internally, ES will mark the old document as deleted, update the field and then reindex everything into a new Lucene block. If your data changes often, nested documents can have a non-negligible overhead associated with reindexing. Lastly, it is not possible to \"cross reference\" between nested documents. One nested doc cannot \"see\" another nested doc's properties. For example, you are not able to filter on \"A.name\" but facet on \"B.age\". You can get around this by using `include_in_root`, which effectively copies the nested docs into the root, but this get's you back to the problems of inner objects. Parent\/Child The last method that Elasticsearch provides are . This scheme is a looser coupling than nested, and gives you a set of slightly more powerful queries. Let's look at an example where a single person has multiple homes (in different states). Your parent has a mapping as usual, perhaps: { \"mappings\":{ \"person\":{ \"name\":{ \"type\":\"string\" } } } } While your children have their own mapping outside the parent, with a special `_parent` property set: { \"homes\":{ \"_parent\":{ \"type\" : \"person\" }, \"state\" : { \"type\" : \"string\" } } } The `_parent` field tells Elasticsearch that the \"Employers\" type is a child of the \"Person\" type. Adding documents to this scheme is very easy. The parent doc is indexed as normal: $ curl -XPUT localhost:9200\/test\/person\/zach\/ -d' { \"name\" : \"Zach\" } And indexing children documents is like normal, except you need to specify which parent this child belongs to in the query parameter ('zach' in this case, which is the ID that we used in the above document): $ curl -XPOST localhost:9200\/homes?parent=zach -d' { \"state\" : \"Ohio\" } $ curl -XPOST localhost:9200\/test\/homes?parent=zach -d' { \"state\" : \"South Carolina\" } Both of these documents are now associated with the 'zach' parent document, which allows you to use special queries such as: You can also query the parents or children types individually, since they are first-class types and will respond to normal queries as usual (you just can't use the relationship values). The big problem with Nested was their storage: everything is stored in the same Lucene block. Parent\/Child removes this limitation by separating the two documents and only loosely coupling them. There are some pros and cons to this. The loose coupling means you are more free to update\/delete children docs, since they have no effect on the parent or other children. The downside is that Parent\/Child are slightly less performant than Nested. The children docs are routed to the same shard as the parent, so they will still benefit from shard-level caches and memory filtering. But they aren't quite as fast as nested since they are not colocated in the same Lucene block. There is also a bit more memory overhead, since ElasticSearch needs to keep an in-memory \"join table\", which manages the relations. Lastly, you'll run into situations where sorting or scoring are, frankly, very difficult. For example, it is impossible to tell child documents matched your `Has_Child` filter, just that one of the docs of the returned parent matched the criteria. This can be frustrating depending on your use-case. Denormalization Sometimes the best option is to simply denormalize your data where appropriate. The relational facilities that Elasticsearch provides are great for certain scenarios...but were never meant to provide the robust relational features that you expect from an RDBM. At it's heart, Elasticsearch is a flat hierarchy and trying to force relational data into it can be very challenging. Sometimes the best solution is to judiciously choose which data to denormalize, and where a second query to retrieve children is acceptable. Denormalization gives you arguably the most power and flexibility. Of course, this comes with the burden of administrative overhead. get to manage relations, and get to perform the required queries\/filters to associate the various types. Yay! Conclusion and Recap This turned into a long, wordy article, so here is a bulletted recap: \n"}<br>{"index": {"_id": 1512}}<br>{"title":"Way Beyond Search","seo_title":"","url":"\/blog\/way-beyond-search","author":{"name":"Steven Schuurman"},"date":"February 19, 2013","category":"News","locales":"","content":" I am thrilled to announce that we just secured a $24M Series B round of funding from Index Ventures.I know what you're thinking ... \u201cdidn't you just close a $10M Series A in November?\" Yes we did, but this was very much the right thing to do for Elasticsearch as an open source project and as a company. Peter Fenton from Benchmark Capital led our A round, and Mike Volpi from Index's San Francisco office took the lead on our B Round - not a bad starting point for a company that's working hard to take Search way beyond merely querying data.In the light of our investment announcement, there are 3 topics we would like to share our thoughts on: Raising Series BWe did not wake up one day with the brilliant idea to set out and raise Series B. In fact, when the plan came together, we were still recovering from our previous fund raising adventure. We did have a great experience talking to some of the greatest minds in venture capital, and received great advice and feedback on how to build our company. Besides that, we learned that the investment community's interest in Elasticsearch was tremendous. This got the ball rolling, and sparked a series of brainstorm-style discussions that got us to start pondering what we would do if we raised an early B round. The answer came to us as quickly as the decision to look for Series B did. Raising a Series B allows us to execute faster on our growth plans for the company and thereby do a better job at serving our rapidly growing customer base on both sides of the Atlantic, in the US and Europe. The driver of this growth is the rapid evolution of search itself.Beyond Just SearchSearch today is so much more than it was even 5 years ago. The technology evolved into a data exploration mechanism and is now used in ways that go way beyond your basic \u201cfree text search\" search box on the upper right corner of a website. Search has become top-of-mind for so many people and the world is quickly getting a handle on what search is actually capable of. We feel there are actually a number of reasons why search has made an amazing jump in popularity over the last 12 months: Search solutions like Elasticsearch have a very promising relationship with rapidly expanding data volumes. Whereas search technology and large data volumes fell in love many years ago, we like to believe they recently got engaged and they're currently planning their wedding. It wouldn't surprise us if this celebrity wedding actually lasted.What Elasticsearch made possible with its first release in 2009 (search beyond free text search), is now being adopted by some of the most data intensive organizations in the world. Next generation social network Path very recently announced advanced search functionality in their platform, and as recently as mid-January, Facebook launched its much-discussed Graph Search functionality.Also, with the search technology now capable of powering advanced real time analytics, we see an increase in users depending heavily on search technology to power their dashboards. We know of various companies that use Elasticsearch to drive Google Analytics-like features and can't afford for its service to be disrupted. Even trend analysis is something we see more and more often. For example, a user can query massive data sets though unstructured searches, sprinkle structure on top of the result sets to break down the result over time, and analyze results through a date histogram graph. Let's say that you're applying this formula to Twitter data, you would instantaneously see a trend in time: very powerful, yet extremely easy to realize these days with Elasticsearch.The Future of ElasticsearchIt is our mission to make real-time data exploration available to anyone, and we feel Elasticsearch is very well positioned to achieve just that. Even though Elasticsearch is off to a good start, we feel there are still many places where we can add value into the future. As a company, one of our objectives is to accelerate the Elasticsearch learning curve and hereby shorten our users' \u201ctime-to-epiphany\". The latter might sound a little odd, so allow us to explain. We find that many people still come to Elasticsearch for purely for classic search. Of course we are perfectly fine with that, but for those that are up for it, we want to be their main source for data analysis. Read: drive real time analytics through Elasticsearch, and truly benefit from what the product is capable of. We will work hard to help people go from their first download of Elasticsearch to their \u201cAhaaa moment\" with Elasticsearch as soon as possible. This is going to be an important focus area for us.But there is more. We also want to make the overall Elasticsearch experience better. One area in which we will increase our investment is our documentation. Our current documentation is excellent for reference purposes, but requires work when it comes to hands-on tips and tricks for day-to-day usage. We know this, and expect to be making a significant leap forwards here during the course of 2013. The product itself will also continue to involve, and we expect that evolution to accelerate towards an even more feature complete release in the near future.Reliability is an important theme in the context of robustness. As Elasticsearch is playing a more and more mission critical part in the stacks of many organizations worldwide, we feel very responsible for the reliability of our product. That means we are engineering Elasticsearch in such a way and are adding new features that make it more dependable even in distressed situations, so that anyone using the product can sleep well at night, knowing that Elasticsearch takes care of your data.Steven & Shay \n"}<br>{"index": {"_id": 1513}}<br>{"title":"Logging Elasticsearch Events with Logstash (and Elasticsearch)","seo_title":"","url":"\/blog\/logging-elasticsearch-events-with-logstash-and-elasticsearch","author":{"name":"Zachary Tong"},"date":"February 16, 2013","category":"Engineering","locales":"","content":" global wrapper \n"}<br>{"index": {"_id": 1514}}<br>{"title":"0.20.5 Released","seo_title":"","url":"\/blog\/0-20-5-released","author":{"name":"Shay Banon"},"date":"February 14, 2013","category":"","locales":"","content":" version is out. You can download it . This release includes several critical bug fixes, and it is a recommended upgrade for and users. \n"}<br>{"index": {"_id": 1515}}<br>{"title":"Understanding \"Query Then Fetch\" vs \"DFS Query Then Fetch\"","seo_title":"","url":"\/blog\/understanding-query-then-fetch-vs-dfs-query-then-fetch","author":{"name":"Zachary Tong"},"date":"February 10, 2013","category":"Engineering","locales":"","content":" In our , we ran into a situation where the returned scores were suspicious. As a refresher, here is the query in question:$ curl -XGET localhost:9200\/startswith\/test\/_search?pretty -d '{ \"query\": { \"match_phrase_prefix\": { \"title\": { \"query\": \"d\", \"max_expansions\": 5 } } } }' | grep title \"_score\" : 1.0, \"_source\" : {\"title\":\"drunk\"} \"_score\" : 0.30685282, \"_source\" : {\"title\":\"dzone\"} \"_score\" : 0.30685282, \"_source\" : {\"title\":\"data\"} \"_score\" : 0.30685282, \"_source\" : {\"title\":\"drive\"} See how the document \u201cdrunk\u201d receives a score of 1.0, while the rest have a score of 0.3? Shouldn\u2019t these docs all have the same score, since they match the query for \u201cd\u201d equally the same? The answer is yes, but there is a very good reason for this scoring discrepancy.Relevancy ScoringPart of the scoring algorithm used by Elasticsearch (and Lucene underneath) includes \u201c\u201d statistics to help calculate relevancy of documents in the index.A lot has been written on the subject of TF-IDF, but it basically says \u201cthe more a term appears in a document, the more relevant this document is. But the relevancy is dampened by how often the term appears in the entire index\u201d. Rare terms are only present in a few documents, which means any query matching a rare term becomes highly relevant. Conversely, common terms are found everywhere, so their relevancy to the query is low.Elasticsearch faces an interesting dilemma when you execute a search. Your query needs to find all the relevant documents\u2026but these documents are scattered around any number of shards in your cluster. Each shard is basically a Lucene index, which maintains its own TF and DF statistics. A shard only knows how many times \u201cpineapple\u201d appears within the shard, not the entire cluster.But the relevancy algorithm uses TF-IDF\u2026doesn\u2019t it need to know how the TF and DF for the , not for each shard?Default search type: Query Then FetchThe answer is yes and no. By default, Elasticsearch will use a search type called \u201c\u201c. The way it works is as follows: This system works fine. In most cases, your index has \u201cenough\u201d documents to smooth out the Term\/Document frequency statistics. So while each shard may not have complete knowledge of frequencies across the cluster, results are \u201cgood enough\u201d because the frequencies are fairly similar everywhere.But in the case of our query mentioned at the beginning of this article, the default search type sometimes fails. DFS Query Then FetchIn the last article, we built an index without specifying shard count \u2013 ElasticSearch used the default of 5 shards. We then inserted a measly five documents into the index and demanded ES return relevant results and accurate scores. Not quite fair, is it?The scoring discrepancies were caused by the Query Then Fetch search type. Each shard only contained 1 or 2 documents (the hashing algorithm used by ES ensures a relatively random distribution). When we asked Elastic to compute scores, each shard only had a tiny view of the five-doc index\u2026so scores were inaccurate.Luckily, Elasticsearch doesn\u2019t leave you out to dry. If you have a situation where this scoring discrepancy is problematic, ES provides a search type called \u201cDFS Query Then Fetch\u201d. The procedures is almost identical to Query then Fetch, except it performs a pre-query to calculate global document frequencies. If we apply this new search type to our previous query, we get scoring results that make sense (e.g. they are all identical):$ curl -XGET 'localhost:9200\/startswith\/test\/_search?pretty=true&search_type=dfs_query_then_fetch' -d '{ \"query\": { \"match_phrase_prefix\": { \"title\": { \"query\": \"d\", \"max_expansions\": 5 } } } }' | grep title \"_score\" : 1.9162908, \"_source\" : {\"title\":\"dzone\"} \"_score\" : 1.9162908, \"_source\" : {\"title\":\"data\"} \"_score\" : 1.9162908, \"_source\" : {\"title\":\"drunk\"} \"_score\" : 1.9162908, \"_source\" : {\"title\":\"drive\"} ConclusionOf course, better accuracy doesn\u2019t come for free. The prequery causes an extra round-trip between the shards, which could cause a performance hit depending on size of the index, number of shards, query rate, etc etc. And in most cases, it is totally unnecessary\u2026having \u201cenough\u201d data solves the problem for you.But sometimes you\u2019ll run into strange scoring situations, and in those cases, it\u2019s useful to know how to tweak the search execution plan with DFS Query then Fetch. \n"}<br>{"index": {"_id": 1516}}<br>{"title":"Starts-With Phrase Matching","seo_title":"","url":"\/blog\/starts-with-phrase-matching","author":{"name":"Zachary Tong"},"date":"February 04, 2013","category":"Engineering","locales":"","content":" \u201cStarts-with\u201d functionality is common in search applications. Either you want to return results as the user types (ala Google Instant) or you simply want to search partial phrases and return any matches. This can be accomplished in Elasticsearch several ways. In this article, we are going to explore phrase matching at query time, instead of building the functionality directly into the index using shingles or nGrams. In particular, we are going to focus on `` query to do the heavy lifting. This query take the normal `match` query and adds phrase support + fuzzy prefix capability. The phrase matching comes from the ability to look at token offsets, allowing the query to know when tokens follow each other in a phrase. The prefix capability will take the last portion of your query and expand it into new query tokens. For example, if your query is \u201cdog f\u201d then will expand this into new queries: Handy, right? Getting Started Let\u2019s go ahead and insert some data into a newly created index. . Our data looks like this: $ curl -XGET localhost:9200\/startswith\/test\/_search?pretty -d '{ \"query\": { \"match_all\" : {} } }' | grep title {\"title\":\"data\"} {\"title\":\"drive\"} {\"title\":\"drunk\"} {\"title\":\"river dog\"} {\"title\":\"dzone\"} Our goal is to do a do a phrase match on the single character \u201cd\u201d. Ideally, we would retrieve all the titles that start with \u201cd\u201d, but not return the [river dog] entry because it starts with an \u201cr\u201d. Let\u2019s go ahead and try the query and see what happens: $ curl -XGET localhost:9200\/startswith\/test\/_search?pretty -d '{ \"query\": { \"match_phrase_prefix\": { \"title\": { \"query\": \"d\", \"max_expansions\": 5 } } } }' | grep title \"_score\" : 0.70710677, \"_source\" : {\"title\":\"data\"} \"_score\" : 0.70710677, \"_source\" : {\"title\":\"drive\"} \"_score\" : 0.70710677, \"_source\" : {\"title\":\"dzone\"} \"_score\" : 0.44194174, \"_source\" : {\"title\":\"river dog\"} \"_score\" : 0.30685282, \"_source\" : {\"title\":\"drunk\"} Hmm\u2026well that didn\u2019t work. Why not? Because we didn\u2019t specify a mapping for this new index, Elasticsearch simply used the default Standard Analyzer. And if you use Standard on [river dog], you\u2019ll end up with this curl -XGET 'localhost:9200\/startswith\/_analyze?analyzer=standard&pretty' -d 'river dog' | grep token \"token\" : \"river\", \"token\" : \"dog\", And that\u2019s where the problem comes from. Standard tokenizes on whitespace, so [river dog] becomes [river] and [dog]. The query doesn\u2019t match [river], but does match [dog]. You can see this reflected in the score of \u201criver dog\u201d, about half as much as all the other entries because only one token matched. The solution, as is so often the case, comes in the form of a mapping. We want Elasticsearch to look at the entire field as a single token, not parse it into individual tokens. We could simply set the field to not_analyzed, but that will make it case sensitive. Instead, we are going to use the plus the . The tokenizer is simple, and difficult to appreciate until you run into a situation like this one. It simply takes the entire field and emits it as a single token. It doesn\u2019t really tokenize at all in fact, just returns what you give it. `Lowercase` filter is pretty obvious, I should think Go ahead and delete the old index, recreate it with the following mapping and re-insert all the data. { \"settings\":{ \"index\":{ \"analysis\":{ \"analyzer\":{ \"analyzer_startswith\":{ \"tokenizer\":\"keyword\", \"filter\":\"lowercase\" } } } } }, \"mappings\":{ \"test\":{ \"properties\":{ \"title\":{ \"search_analyzer\":\"analyzer_startswith\", \"index_analyzer\":\"analyzer_startswith\", \"type\":\"string\" } } } } } Now, when we execute the same query from above, we get much better results: $ curl -XGET localhost:9200\/startswith\/test\/_search?pretty -d '{ \"query\": { \"match_phrase_prefix\": { \"title\": { \"query\": \"d\", \"max_expansions\": 5 } } } }' | grep title \"_score\" : 1.0, \"_source\" : {\"title\":\"drunk\"} \"_score\" : 0.30685282, \"_source\" : {\"title\":\"dzone\"} \"_score\" : 0.30685282, \"_source\" : {\"title\":\"data\"} \"_score\" : 0.30685282, \"_source\" : {\"title\":\"drive\"} Huzzah! The incorrect [river dog] entry is no longer present in our search results. Let\u2019s add another character to our query, making the search for \u201cdr\u201d instead of just \u201cd\u201d. Does it still work? curl -XGET localhost:9200\/startswith\/test\/_search?pretty -d '{ \"query\": { \"match_phrase_prefix\": { \"title\": { \"query\": \"dr\", \"max_expansions\": 5 } } } }' | grep title \"_score\" : 1.0, \"_source\" : {\"title\":\"drunk\"} \"_score\" : 0.30685282, \"_source\" : {\"title\":\"drive\"} Yep! Works perfectly, only returning the two documents that start with \u201cdr\u201d. You may notice that one document (\u201cdrunk\u201d) receives a score of 1 while the rest have scores of 0.306\u2026there is a good reason for this, but it is outside the scope of this article. Suffice to say that it is an artifact of having a low document count in the index. You can ignore this peculiarity for now. Conclusion So, what have we learned? If you want to build a \u201cstarts with\u201d functionality at query time, you still need to have appropriate mapping at index time. In this article, we looked at how a simple tokenizer (plus filter) can ensure that the query returns the right results, by keeping our fields from being broken into multiple terms. \n"}<br>{"index": {"_id": 1517}}<br>{"title":"0.20.4 Released","seo_title":"","url":"\/blog\/0-20-4-released","author":{"name":"Shay Banon"},"date":"January 29, 2013","category":"","locales":"","content":" version is out. This release includes important bug fixes over the previous release and an upgrade is highly recommended. ( was also released a couple of days ago, but had a problematic deb package). \n"}<br>{"index": {"_id": 1518}}<br>{"title":"Welcome David","seo_title":"","url":"\/blog\/welcome-david","author":{"name":""},"date":"January 16, 2013","category":"","locales":"","content":" I'd like to warmly welcome David Pilato () to elasticsearch. David is a prominent elasticsearch user and advocate, and has been doing an amazing work spreading Elasticsearch in France. I just came back from Paris giving our elasticsearch training with and talking at the first France elasticsearch meetup. You can easily see David influence, resulting in 100 people attending the meetup!.David will continue his amazing work promoting elasticsearch, as well as contribute to the development of elasticsearch. You can also check on joining our Elasticsearch. \n"}<br>{"index": {"_id": 1519}}<br>{"title":"Searching with Shingles","seo_title":"","url":"\/blog\/searching-with-shingles","author":{"name":"Zachary Tong"},"date":"January 15, 2013","category":"Engineering","locales":"","content":" global wrapper \n"}<br>{"index": {"_id": 1520}}<br>{"title":"Some 2012 Elasticsearch Highlights","seo_title":"","url":"\/blog\/some-2012-elasticsearch-highlights","author":{"name":"Steven Schuurman"},"date":"January 14, 2013","category":"News","locales":"","content":" Have you ever had that feeling when - due to sheer excitement - it's hard to decide what to talk about first because there's just too much to tell? Well, that's where I'm at right now\u2026 Please allow me to jump right in.Adoption and Series-A Investment with BenchmarkOne of the most illustrative news items of last year was around our download numbers: 2012 was without any doubt the year Elasticsearch took off like a rocket ship. Within a year, our download numbers went from around 50k\/month to more than 200k\/month and we surpassed the 1.5 million downloads mark. In all my years in open source, including my years at SpringSource, I have never witnessed anything as spectacular as the speed at which the world is adopting Elasticsearch. Personally, I believe the popularity of the product isn't that hard to explain. I remember our investor Peter Fenton tweeting the following last November when we announced our Series-A with Benchmark:\u201cJaw-dropping momentum, Big Data's killer app has arrived:@elasticsearch Benchmark thrilled to back the team\u2026\"I believe this statement to be spot on as Elasticsearch is groundbreaking in two very relevant aspects:1) Its power to drive information out of extremely large volumes of data 2) Its user friendlinessThese two design characteristics combined with Elasticsearch being fast, real-time and highly scalable make that it lives up to Peter's aforementioned claim.\u00a0\u00a0what I wrote about our Series-A investment from Benchmark, Rod Johnson and Data Collective last November.Elasticsearch in the WildAnother set of important highlights (which get us really fired up, and provide for very rewarding reading material) are the use cases we encounter in the wild. We now know Elasticsearch is literally used everywhere there's data \u2013 and as we all know - companies are accumulating more data every day. To put it in perspective, Wired recently described Elasticsearch at \u201cYour Own Private Google.\"\u00a0\u00a0provides for an interesting read, so I recommend checking it out.However, there are many more use cases for Elasticsearch, and though out 2012 many people have been kind enough to share their experiences with us. To pick a few, here are some publications that are interesting to everyone considering making a move on Elasticsearch as their search & analytics runtime of choice. If you're interested in sharing some of your Elasticsearch war-stories, we'd love to\u00a0. Or, you can of course just\u00a0\u00a0on Twitter and tweet about your findings.At Elasticsearch we're grateful for all those wonderful stories that are being shared online by so many people. It's great inspiration for the entire Elasticsearch team and undoubtedly also for people considering test-driving Elasticsearch for a bit.So thank you very much for sharing \u2013 and we look forward to hearing more from you in 2013. \n"}<br>{"index": {"_id": 1521}}<br>{"title":"Welcome Drew & Rashid","seo_title":"","url":"\/blog\/welcome-drew-rashid","author":{"name":""},"date":"January 10, 2013","category":"","locales":"","content":" I'd like to warmly welcome both Drew Raines () and Rashid Khan () to elasticsearch.Drew has been a long time elasticsearch user, and helped develop, manage and operate very large elasticsearch installations. Drew joined us to help sprinkle a bit more devops qualities to our team, as well as help improve our story in the devops land. His passion for clojure will also have an impact (or already is!).Rashid needs no introduction if you are using logstash. He is the guy behind\u00a0, the beautiful interface built for logstash (or logstash \u201cstructured\" log data). We love the work Rashid has done on Kibana, and obviously are excited about his knowledge of elasticsearch. Rashid will continue and develop Kibana full time with us, as well as dabbling more into our operational and management infrastructure. \n"}<br>{"index": {"_id": 1522}}<br>{"title":"0.20.2 Released","seo_title":"","url":"\/blog\/0-20-2-released","author":{"name":"Shay Banon"},"date":"December 27, 2012","category":"","locales":"","content":" version is out. This release includes both important bug fixes as well as upgrades to Lucene (from 3.6.1 to 3.6.2), and other internal libraries. Another change includes how plugins are downloaded. Now, \u201celasticsearch\u201d plugins are downloaded automatically from our new service, but it can also download plugins from maven directly. Site plugins can stil be downloaded from github as \u201crepositories\u201d. In the future, we will also allow users to upload their own plugins to if they wish to. Enjoy! \n"}<br>{"index": {"_id": 1523}}<br>{"title":"New Download Service","seo_title":"","url":"\/blog\/new-download-service","author":{"name":"Drew Raines"},"date":"December 17, 2012","category":"","locales":"","content":" Elasticsearch has been using Github\u2019s static downloads feature as a means of distributing releases for both the core and its plugins for a few years now. Unfortunately, last week, . We\u2019ve been working the past few days to replace this functionality internally. All of the links to elasticsearch core have been updated to the new site through . We\u2019re still migrating our plugins, so you\u2019ll see those change in the next day or two. We are still working on a solution for third-party plugins. The old assets will be removed tomorrow, so if you\u2019re using any links in your provisioning system please update them to the commensurate . \n"}<br>{"index": {"_id": 1524}}<br>{"title":"0.20.0 Released","seo_title":"","url":"\/blog\/0-20-0-released","author":{"name":"Shay Banon"},"date":"December 07, 2012","category":"","locales":"","content":" version is out. This is the GA release of the 0.20.x branch. You can download it . The release mainly include bug fixes over the previous release. Update: released to fix a bug when downloading plugins, please make sure to use it when using plugins. This version also deprecates the snappy compression option (see more ), and the Shared Gateway (more info ). \n"}<br>{"index": {"_id": 1525}}<br>{"title":"0.19.12 Released","seo_title":"","url":"\/blog\/0-19-12-released","author":{"name":"Shay Banon"},"date":"December 04, 2012","category":"","locales":"","content":" version is out. You can download it . It contains several bug fixes (upgrade when possible\u2026) and a new feature for indexing slow log (similar to search slow log feature). This version also deprecates the snappy compression option (see more ), and the Shared Gateway (more info ). \n"}<br>{"index": {"_id": 1526}}<br>{"title":"Welcome Clinton!","seo_title":"","url":"\/blog\/welcome-clinton","author":{"name":""},"date":"November 14, 2012","category":"","locales":"","content":" I am extremely happy to announce that Clinton Gormley (\"\") has joined elasticsearch. I still remember those early days in elasticsearch, when we had 3 people on IRC and \"that Perl dude\" kept asking questions on how it works, and gave instrumental insights on the elasticsearch API design and usability. When I created elasticsearch, the goal was always to make it usable and easy to use from any language, and Clinton, with his \"Perlishness\", helped keep elasticsearch honest. As time passed Clint has also become an invaluable source of information and help to the rest of the elasticsearch community, on the mailing list, IRC, and at conferences.Joining our company, Clint will continue to do his thing, but now full time on elasticsearch. He will continue to develop the Perl libraries, help the community around elasticsearch, and sprinkle his high standards when it comes to keeping and making elasticsearch usable and easy to use.Welcome Clint! \n"}<br>{"index": {"_id": 1527}}<br>{"title":"Elasticsearch: Easy, Complete and Robust \u2013 Just like Our Product","seo_title":"","url":"\/blog\/elasticsearch-easy-complete-and-robust-just-like-our-product","author":{"name":"Steven Schuurman"},"date":"November 08, 2012","category":"News","locales":"","content":" With unbelievable excitement we just announced Elasticsearch secured $10M in Series A venture funding from , led by Peter Fenton. Other investors in the round include my SpringSource co-founder Rod Johnson and . Being able to work with Peter Fenton and Rod Johnson again after SpringSource is nothing short of a privilege. Both are established open source visionaries and have already brought a lot of value to the company in terms of insights, network and general advice over the last few weeks.Three reasons stand out why Benchmark, Rod, and Data Collective believe in Elasticsearch: the product and the company: When Shay and I joined forces about 6 months ago, we set out to build a company based on our shared belief that we would be able to create a beacon of light in our industry. Our industry, mostly referred to as the big data market, is undeniably complex and extraordinary technology heavy. Many companies provide a solution that solves one of the many technical challenges companies are facing when aiming to gain competitive advantage from the massive volumes of data it's gathering on a daily basis. I believe that up until Shay created Elasticsearch, very few \u2013 if any \u2013of the solutions available were able to make achieving this objective as easy as operating an Apple device.So in a way Elasticsearch already achieved its objective, which makes my life as the CEO of Elasticsearch a lot easier of course. However, we're not done. In fact, we're only getting started\u2026Since we launched the company, I have received many questions on where we want to take the company and what we plan on doing moving forward. The key element to the answer to that question has always been, that our way forward is merely a continuation of the path we're currently on. Please allow me to elaborate.The more we talk to people who use Elasticsearch, the more we are able to distill 3 main reasons why Elasticsearch is so popular. In a nutshell, people love our product because it is: To us, this is an extremely important finding. Predominantly because this confirms that Shay and his team are achieving their objective: to make an extremely easy to use product that reliably delivers on its promise. The mere fact that a product achieve it's objective is actually not as common as it might seem. As products mature, markets mature and as product's established user base grows, it's not uncommon for product roadmaps to deviate from its original path due to heavy pressure from many outside forces. I believe that Elasticsearch was created after a solid vision, rather than based on feature requests from individual users. This has had a massive positive impact on Shay's ability to create a product that is usable for an immensely large audience, instead of just a handful of power users. Shay has not given in to temptations, but rather worked closely together with many users to create a user-friendly product that meets all critical requirements in a large number of use cases.The challenge for our company is to be as focused on being as easy to work with, robust and complete as our product is. Now that doesn't mean that there's nothing left to be desired. Au contraire, we are currently working hard on bullet proofing our support organization by scaling it out fast and fine-tuning our systems to ensure the quality of our support increases while our client base rapidly grows. We are also working on a public training course schedule that covers more cities across the globe, to ensure attendees never have to travel unacceptably far to attend a course. And as is to be expected, we are growing our executive team with talented professional that have the required skills to help grow our reach.With Elasticsearch now having a company behind it to propel it forward, it seems safe to conclude that the Big Data Dark Ages are now finally behind us.Steven & Shay \n"}<br>{"index": {"_id": 1528}}<br>{"title":"Welcome Igor","seo_title":"","url":"\/blog\/welcome-igor","author":{"name":""},"date":"October 26, 2012","category":"","locales":"","content":" I am very happy to announce that Igor Motov () is joining Elasticsearch. Igor has extensive knowledge on Elasticsearch, and has written several plugins for it, including a zookeeper discovery module and the jetty plugin. He is also the co-organizer of the . Igor will join our team focusing on continuing and improving Elasticsearch as his full time job.Personally, I am very excited about having Igor join us. We just got a big boost on our ability to execute on our vision that is Elasticsearch. Welcome Igor! \n"}<br>{"index": {"_id": 1529}}<br>{"title":"0.19.11 & 0.20.0.RC1 Released","seo_title":"","url":"\/blog\/0-19-11-0-20-0-rc1-released","author":{"name":"Shay Banon"},"date":"October 23, 2012","category":"","locales":"","content":" version and are out. You can download it . contains important bug fixes and is a recommended upgrade, is the first release candidate for 0.20 release, major features include: Update Improved update , including the ability to provide a partial document to merge into the existing one, and the ability to \u201cupsert\u201d a document if the document doesn\u2019t exists. geo_shape Support for a type allowing to index complex geo shape (using geo json as the format), and for a query\/filter allowing to provide a geo shape and check if it intersects, contains, or disjoint with the indexed shape. It also allows to fetch the \u201cquery\u201d shape from the index itself (without needing to provide it as part of the query, just the name of the index\/type\/id to use). Warmers Provides the ability to register search requests that will be executed before new data becomes available for search, allowing to preload for example data that is needed for sorting, faceting, or parent\/child support. This removes the load time from the \u201cuser\u201d execution path, allowing to provide consistent search performance. Warmers have full control for registering them, as well as deleting and getting them. They can also be provided as part of the index creation , or as part of index templates. Other A lot of work has going into building the basis for cross major version cluster compatibility, we are not there yet, but we are on our way. Bugs have been fixed (though most major ones have been backported to 0.19), and many other smaller features and enhancements have been implemented. Moving forward, the plan is to have the next version be 0.20.0 final. 0.21 will focus on upgrading to Lucene 4.0 (and exposing its new features), as well as internal refactoring to support future features such as grouping (specifically, optimized for distributed execution). \n"}<br>{"index": {"_id": 1530}}<br>{"title":"0.19.10 Released","seo_title":"","url":"\/blog\/0-19-10-released","author":{"name":"Shay Banon"},"date":"October 01, 2012","category":"","locales":"","content":" version is out. You can download it . It contains several bug fixes but also new features, including: has_parent filter\/query filter allows to execute a query on parent documents and result in matching children documents (the inverse of ). More info . Also, the performance of filter\/query has been greatly improved. Less overhead of filter cache The filter cache cleanup process is now more optimized, specially when large number of shards exists on a node. Cluster Reroute The allows to explicitly send commands that would move, cancel, and allocate shards. Note, this is an experimental and feedback is welcomed. Bulk The interface allows to have elasticsearch listen using for bulk formatted requests. While comes with its own downsides, it can come in handy, specially when indexing non critical data (ala statsd). This interface is also experimental. \n"}<br>{"index": {"_id": 1531}}<br>{"title":"Welcome Karmi","seo_title":"","url":"\/blog\/welcome-karmi","author":{"name":""},"date":"September 04, 2012","category":"","locales":"","content":" I very happy to announce that Karel Minarik () is joining Elasticsearch. Karel is well known in the Elasticsearch community, specifically the ruby community as the author of the popular library, though he is quite the polyglot that dabbles in chef, emberjs and many more.Go ahead and read , I would simply add that we feel lucky that we have Karel on our team, as it greatly helps us realize our vision around Elasticsearch, and our commitment to our community, specifically, the ruby one. \n"}<br>{"index": {"_id": 1532}}<br>{"title":"the future is elastic","seo_title":"","url":"\/blog\/the-future-is-elastic","author":{"name":"Karel Mina\u0159\u00edk"},"date":"September 04, 2012","category":"","locales":"","content":" When I first discovered Elasticsearch, in late 2010, I immediately considered it an elaborate hoax.What else can you think when you discover a software project which comes sprinkled with so many buzzwords: a RESTful HTTP interface, working with schema-free documents, talking in JSON through a rich DSL, horizontally scalable and distributed by design, cloud-ready and cloud-friendly? And that software project is a search engine? A hoax, clearly.But then I downloaded the source code, had a look a it... and it seemed quite legit. I became suspicious - it seemed like a little bit too much work for a prank. So I installed said project, and, to my astonishment, it did seem to work the way it was advertised on the tin.At that time, I was working as a lead developer for a social media monitoring application, which was using CouchDB and CouchDB-Lucene as core technologies, so, as you can easily imagine, my neural paths had just exploded like fireworks. Working with schema-free JSON-based documents over HTTP and using full text queries and facets was something I was used to, only this time, it looked way, way better.Being a Ruby shop, we naturally needed a Ruby library for talking to Elasticsearch, and not being satisfied with the offering, I set out to write a . In spite of working hard to make it usable outside of our pretty specific use case, I never imagined it will get nearly nine hundreds of GitHub watchers and be in the process. Or that I will get to solve more then three hundred issues and pull requests, curating other people's code and making sure the library does not crumble under the weight of different styles, approaches and opinions.In no time, I was writing articles for the Elasticsearch site about , , , and in the process got to write a , Elasticsearch data for Ember.js, a monitoring to check for health problems of the cluster. I about Elasticsearch at three conferences. In short, my life became fully immersed in this crazy project. During all that time, Shay was an immensely helpful source of information, advice, and inspiration for cranking out features with incredible speed.Today marks a special day on this journey. As a member of the Elasticsearch.com team, I will be able to put more of my time and energy into Elasticsearch and the surrounding ecosystem \u2014 the Ruby library, provisioning and monitoring tools, research and documentation. My specific goal is to make it even more easy for Rubyists to work with full text search in their applications, to understand it better, and to make most of it.After all, search is the primary means for keeping up with the vast amounts of data: every day, from Google to Mac OS X Spotlight, we rely on search to find information. In fact, the future of our civilization depends on how well we understand the data about ourselves, be it the global Twitter chatter, air pollution metrics, DNA sequences or evidence gathered by the Curiosity rover on Mars. I believe that full text search, and Elasticsearch in particular, will be an important part of this future. \n"}<br>{"index": {"_id": 1533}}<br>{"title":"0.19.9 Released","seo_title":"","url":"\/blog\/0-19-9-released","author":{"name":"Shay Banon"},"date":"August 23, 2012","category":"","locales":"","content":" version is out. You can download it . It contains several bug fixes but also new features, including: Snappy Compression New experimental support for compression on top of the current . Changing to use it is as simple as setting to . Note, anything already compressed with will still work correctly. renamed to The query name gave it great injustice, as it nicely also handles dates and numeric types as well for example. It was renamed to in order to better reflect what it actually does, with backward support for the name as well. On top of that there is now support for query, allowing to more easily run queries on several fields without the verbosity of using query to wrap it. Explain New called , allowing to easily check how and why a specific document matches a query, or even understand why a specific document does not match a specific query. Networking Enhacements Several networking enhancements geared towards reducing further the amount of buffer copies while doing network operations, and better defaults for network buffer sizes. \n"}<br>{"index": {"_id": 1534}}<br>{"title":"Exciting Times Ahead","seo_title":"","url":"\/blog\/exciting-times-ahead","author":{"name":"Uri Boness"},"date":"July 13, 2012","category":"","locales":"","content":" About 7 years ago, I met with Shay in a small coffee place in Tel Aviv. We talked about Compass and search in general. I only wished I had recorded that conversation. We talked about the future of information retrieval, about big data (although we didn't use this label yet) and the role that search technology, specifically open source search technology, will have in the future. Fast forward a few years and there I was, with years of Lucene and Solr experience behind me, about to set up a company around open source search. I sat down with Steven and together we laid out the blueprints for the next generation search engine. We had a pretty good idea on the direction the information and data management world is heading. And we also knew what it was missing - A simple yet powerful distributed search engine, built to scale from ground up. Sounds pretty simple, doesn't it :). Few months later, Shay released the first version of Elasticsearch. And as time passed, it became clearer to us all that our visions are too much aligned to be ignored. It took some time and effort, but we finally made it happen - today the Elasticsearch company was born. It is the beginning of a new era. And not in the traditional definition of search, but in the modern definition of information retrieval. The definition by which data becomes accessible in the form of insightful knowledge, or simply put: Making Sense of Your (Big) Data Shay did an amazing job with Elasticsearch. It's simply mind blowing to realize that he, single handedly, managed to build, support, consult and promote such as amazing piece of software and get it to where it is today. But even kimchyman has his limits. The community is immense. The install base is growing by the day (just the other day Elasticsearch reached the 1 million downloads mark on GitHub). The mailing lists and IRC channels are busier than ever. Companies are running their most critical runtime systems on top of Elasticsearch and demand continuous support. Elasticsearch, the company, no longer the missing piece in the success story of this product. It is here to support the continuation and development of the project, provide the much needed security for the ever growing install-base, and help expand the community through training and education. There's a long journey ahead of us, but an exciting one. And we invite you to join us in this journey and share the excitement. \n"}<br>{"index": {"_id": 1535}}<br>{"title":"The Rise of Open-source Search","seo_title":"","url":"\/blog\/the-rise-of-open-source-search","author":{"name":"Simon Willnauer"},"date":"July 13, 2012","category":"","locales":"","content":" Wow! I'm excited to write this blog today being the day that Open-Source Search moved a huge step forward. I have been working with Lucene for over 8 years now spending an enormous amount of time on adding features, fixing bugs, writing documentation and eventually bringing the project forward together with an awesome gang of committers. I think I can state that Lucene has become one of the most successful Open-Source libraries serving million of users worldwide. Yet, there was always something missing in the picture when you need to go out and build a search system especially when it gets to reliability, fail-over and distributed search. You know those things are hard and have always been out of scope for the Lucene library. A couple of years ago Elasticsearch came into the picture offering an extremely promising idea by an extremely passionate engineer. What can I say, \u201cit's grown up\", here comes Elasticsearch the company!With the rise of NoSQL, Hadoop and being Big-Data everywhere Lucene's star didn't shine that bright without offering all these features out of the box and related projects like Solr are slowly catching up with scaling capabilities. But going from an idea to a mature and stable software is a pretty rocky path and it takes time and effort to go. Elasticsearch has gone down that path with all the hard problems in mind from day one. Hey, this is awesome - you know, for search! However, it's not just Buzz! 4 weeks ago at the Berlin Buzzwords conference you could literally feel how much momentum Elasticsearch gained in the last couple of years. Rooms were packed, engineers talking about success stories, limitations, features and improvements all over the place. This is healthy in a lot of ways and a good indicator that it's time to take Elasticsearch to the next level. When Shay, Steven, Uri and myself first talked about the idea to join forces and to establish Elasticsearch as a company it was already obvious to me that this is an enormous chance for Open-Source Search in general as well as Lucene being the underlying technology. As a company we heavily rely on the features, maturity and stability of the software we incorporate into Elasticsearch and in turn on the health of the Open Source community. It's our job and responsibility to maintain it and push it forward. I'm looking forward to a great time working together with great engineers on hard problems making the Elasticsearch user experience as smooth as possible and making Lucene the only choice when you need Search - and trust me you need it! \n"}<br>{"index": {"_id": 1536}}<br>{"title":"You Know, for Search! (inc)","seo_title":"","url":"\/blog\/you-know-for-search-inc","author":{"name":"Shay Banon"},"date":"July 13, 2012","category":"","locales":"","content":" When I set down to write the first lines of code for Elasticsearch, about 3 years ago, I looked at my wife and my 2 months old daughter and knew perfectly what I was getting into. Well, as Miracle Max would say, I mostly did. I knew that its going to be a commitment that will take a big chunk of my life to follow through, I knew that I was building something useful that will make developers life simple, and I knew that there is a need for something like Elasticsearch out there.Obviously, I knew all those things, but not many others did. Its funny, as Tim Robbins found out in the classic Cohen brothers movie, \u201cThe Hudsucker Proxy\", getting people to see a circle and state \u201cYou Know, for Kids!\", and making the leap to understand what it can actually be is not simple.Thomas Jefferson said: \u201cI am a great believer in Luck, and I find that the harder I work, the more I have of it\". Elasticsearch was and is certainly not a walk in the park. Building a distributed system, that can handle massive amounts of data, and still be usable is no simple task. I do feel lucky though, we live in an age where anyone can open a laptop and set out to change the world (a bit), with extra luck points for having an understanding spouse.More than that, I feel lucky with the community that evolved around Elasticsearch. It caught me by surprise the speed at which Elasticsearch got adopted. I knew that something was missing, I just couldn't believe how quickly people will realize it as well. I am very proud of what happened around Elasticsearch, the ecosystem that developed around it, and the users actually taking and using it in real systems and in production.But, dodging buses like crazy for the past couple of years has left me exhausted, and the user's request for having something formal around Elasticsearch, the need to feel safe, has been increasing exponentially. You see, I have seen it happen for 10 years now, it usually starts with \u201clets just have a search box so people can search some content\", and quickly evolves to using it in many other parts of the stack \/ system, quickly increasing its importance in the application.Luckily (do you notice a trend?), a few months ago, my good friend from the Compass days Uri Boness mentioned that he was doing something around search, and I got to know Steven, who was leading it. Steven and myself immediately hit it off. You see, Steven and myself think very much alike, yet still differently. It's a rare combination that doesn't happen frequently, but when it does, exciting things happen. And to top it all, Steven comes with an extensive track record when it comes to Open Source projects. When I learned that Simon Willnauer, one of Lucene rock stars is part of the team as well, the inevitable conclusion was not that hard to make. It Just Felt Right.So, I am extremely happy to announce that we now have an Elasticsearch company, your basic one stop shop for anything to do with Elasticsearch. What does it mean? It means that we can basically move Elasticsearch harder, faster, better, and stronger, while providing all the services you might expect from an Open Source company.On top of that, the Elasticsearch team also includes Nick White (the finance wizard), as the CFO. Chris Male, and Martijn van Groningen, both amazingly talented developers and Lucene committers, and the valuable Elissa Nancarrow to handle, well, basically everything else. With the future holding additional talented people joining the company (and if you are up to it, we are hiring!), it really feels like we are on our way to build something really special.I still vividly remember 10 years ago sitting in a one room apartment in London, with no job, first getting into the search space by writing \u201ciCook\" for my wife while she was studying to be a Chef at the Cordon Bleu. Its been a long journey to get to this point, yet it feels like it has just begun... \n"}<br>{"index": {"_id": 1537}}<br>{"title":"Introducing: Elasticsearch \u2013 the Company!","seo_title":"","url":"\/blog\/introducing-elasticsearch-the-company","author":{"name":"Steven Schuurman"},"date":"July 13, 2012","category":"News","locales":"","content":" Hi everyone,Today is a great day for the Elasticsearch project, all Elasticsearch users, open source in general and not in the least for my colleague, fellow company founder and originator of Elasticsearch - Shay Banon. Today is the day we launch the company behind Elasticsearch! In practice, this means that as of today, users and potential users of Elasticsearch have a definitive source for support, education and guidance with respect to developing, deploying and running Elasticsearch in production environments.Shay and I connected though a mutual acquaintance (company co-founder Uri Boness) and started to share ideas about setting up a company around Elasticsearch. As it turned out, Shay and I shared a vision of creating an innovative company that will really make a difference in the Big Data space, and is focused 100% at creating products that truly meet the needs of users. With my background as co-founder of SpringSource, the company behind the popular Spring Framework, open source was an obvious ingredient of course. It didn't take us long come to the conclusion that cooperating on serving customers and helping companies make successful use of Elasticsearch made a lot of sense. Only months later we setup a company that is committed to the success of Elasticsearch users and that is committed to open source. We take these commitments very seriously. I am therefore very pleased to state that Elasticsearch will also make contributions to the Apache Lucene project, which is for obvious reasons an open source project that's very close to our hearts. All the more reason for me to also be extremely excited of having one of the leaders of the Apache Lucene project, Simon Willnauer, as a co-founder of the company and technology leader on my team.Moving forward, Shay will continue to develop Elasticsearch, and will continue to develop a solution that's exactly what users want and what users need. As of right now, he has a whole team to back him up. During the next few months we will be adding talented Elasticsearch colleagues to the team, so if you're interested in being part of a great team of technologists in the big data search and analytics space, feel free to drop us a line!I truly look forward to working together with my wonderful team towards the continued success of Elasticsearch. It's going to be great.Cheers, Steven Schuurman, CEO \n"}<br>{"index": {"_id": 1538}}<br>{"title":"0.19.8 Released","seo_title":"","url":"\/blog\/0-19-8-released","author":{"name":"Shay Banon"},"date":"July 02, 2012","category":"","locales":"","content":" version is out. You can download it . The release includes bug fixes including integer overflow when reading the new compressed stored format, and a fix for failure to of recovery of peer shards due to failure to detected comrpessor (not common). Dangling Indices It also includes better handling of dangling indices. Dangling indices happen when a node that has several indices stored locally, joins a cluster and those local indices do not exists in the cluster metadata. This usually does not happen, especially not with proper gateway.recover_after_nodes flag, but still, users can by mistake get into this state. A new setting setting, with possible values of (never import dangling indices, but also delay the delation of them), (import dangling indices), and (import dangling indices, but in closed state). The default value is . This also allows to recover \u201cother\u201d indices into a cluster, by mv\u2019ing it into an existing node or a new node, where they will be detected as dangling and be recovered (or imported) into the cluster automatically. Actually, it also has a nice trick of possibly using a \u201cnew\u201d index name based on the name of the index on the file system. Wildcard Multi Index Syntax Multi index syntax has just become considerably simpler. Current multi index sytax allows to specify several indices to search on using , now, it also support wildcards, for example: . It also support the ability to \u201cadd\u201d () and \u201cremove\u201d (), for example: . \n"}<br>{"index": {"_id": 1539}}<br>{"title":"0.19.7 Released","seo_title":"","url":"\/blog\/0-19-7-released","author":{"name":"Shay Banon"},"date":"June 26, 2012","category":"","locales":"","content":" version is out. You can download it . The release includes mainly bug fixes, fixing the broken debian package, and a bug in the new store compression option (on reads). \n"}<br>{"index": {"_id": 1540}}<br>{"title":"0.19.5 Released","seo_title":"","url":"\/blog\/0-19-5-released","author":{"name":"Shay Banon"},"date":"June 25, 2012","category":"","locales":"","content":" version is out. You can download it . The release includes critical bug fixes in elasticsearch cluster management and peer recovery process, and it is highly recommended for all users. [Update]: Some users reported a problem when starting elasticsearch with due to verification error. This problem has been fixed in . p. [Update 2]: The package seems to be broken in and , a fix will be issued later. p. [Update 3]: has been released fixing the debian packaging problem and a bug in the new compression support (on reads). The release also includes several features, including: Store Compression elasticsearch has had the ability to compress the document for a long time. The problem with it is the fact that small documents don\u2019t end up compressing well, as several documents compressed in a single compression \u201cblock\u201d (we use , but Snappy, whihc will be supported also in the future, works the same) will provide a considerable better compression ratio. This version introduces the ability to compress stored fieds using the setting, as well as term vector using the setting. The settings can be set on the index level, and are dynamic, allowing to change them using the index update settings . elasticsearch can handle mixed stored \/ non stored cases. This allows, for example, to enable compression at a later stage in the index lifecycle, and optimize the index to make use of it (generating new segmetns that use compression). Best compression, comprared to _source level compression, will mainly happen when indexing smaller documents (less than 64k). The price on the other hand is the fact that for each doc returned, a block will need to be decompressed (its fast though) in order to extract the document data. Store Throttling The way Lucene, the IR library elasticsearh uses under the covers, works is by creating immutable segments (up to deletes) and constantly merging them (the merge policy settings allow to control how those merges happen). The merge proces happen in an asyncronous manner without affecting the indexing \/ search speed. The problem though, especially on systems with low IO, is that the merge process can be expensive and affect search \/ index operation simply by the fact that the box is now taxed with more IO happening. The store module now allows to have throttling configured for merges (or all) either on the node level, or on the index level. The node level throttling will make sure that out of all the shards allocated on that node, the merge process won\u2019t pass the specific setting bytes per second. It can be set by setting to , and setting to something like . The node level settings can be changed dynamically using the cluster update settings . If specific index level configuration is needed, regardless of the node level settings, it can be set as well using the , and . The default value for the type is , meaning it will throttle based on the node level settings and participate in the global throttling happening. Both settings can be set using the index udpate settings dynamically. \n"}<br>{"index": {"_id": 1541}}<br>{"title":"0.19.4 Released","seo_title":"","url":"\/blog\/0-19-4-released","author":{"name":"Shay Banon"},"date":"May 21, 2012","category":"","locales":"","content":" version is out. You can download it . The release includes serveral bug fixes, mainly around percolator, mapping type, and file based config index templates. It also includes an enahcement allowing to configure the query to be , not failing when wrong format of a value is provided (for example, a text to a numeric field), as well as the ability to search \u201cwithin\u201d objects using wildcards in the syntax (it was already provided if it was used in the section), for example: . \n"}<br>{"index": {"_id": 1542}}<br>{"title":"0.19.3 Released","seo_title":"","url":"\/blog\/0-19-3-released","author":{"name":"Shay Banon"},"date":"April 30, 2012","category":"","locales":"","content":" version is out. You can download it . The release includes an upgraded Lucene 3.6 version, and several bug fixes, including better handling of network splits with node client nodes and with minimum master nodes. \n"}<br>{"index": {"_id": 1543}}<br>{"title":"0.19.2 Released","seo_title":"","url":"\/blog\/0-19-2-released","author":{"name":"Shay Banon"},"date":"April 04, 2012","category":"","locales":"","content":" version is out. You can download it . It is a bug fix release fixing several bugs including a bug not being able to update index level settings on a live index using the index update settings . \n"}<br>{"index": {"_id": 1544}}<br>{"title":"0.19.1 Released","seo_title":"","url":"\/blog\/0-19-1-released","author":{"name":"Shay Banon"},"date":"March 20, 2012","category":"","locales":"","content":" version is out. You can download it . It is a bug fix release fixing several bugs including a major bug where a thread can get into spin when its relocated and a search\/stats operation is executed against it. The release also includes an update to the `read_only` option on an index. The option caused both write and metadata operations to be disabled for the relevant index. Now, in 0.19.1, specific read, write and metadata blocks can be set. See more . \n"}<br>{"index": {"_id": 1545}}<br>{"title":"0.19.0 Released","seo_title":"","url":"\/blog\/0-19-0-released","author":{"name":"Shay Banon"},"date":"March 01, 2012","category":"","locales":"","content":" version is out. You can download it . It is the final 0.19.0 release (after 3 release candidates). 0.19 major features have been outlined in the previous blog posts for each release candidate release, but, it also marks an important bug fix and stability release over 0.18, upgrade is highly encouraged to all elasticsearch users. \n"}<br>{"index": {"_id": 1546}}<br>{"title":"0.19.0.RC3 Released","seo_title":"","url":"\/blog\/0-19-0-rc3-released","author":{"name":"Shay Banon"},"date":"February 21, 2012","category":"","locales":"","content":" version is out. You can download it . Its another bug fix released and (hopefully) the final release of 0.19.0 release candidates. It also includes two nice features. The first is the ability to use \u201cdate math\u201d on types (especially useful in queries\/filters). See more info in the (and documented under the mapping date type). The second feature is a new called \u201cMulti Search\u201d (or ). It allows to construct a single request holding several search requests, executing them in the cluster (in parallel) and returning the results. More info on the format and how to use it can be found in the (and documented under the guide section). \n"}<br>{"index": {"_id": 1547}}<br>{"title":"0.19.0.RC2 Released","seo_title":"","url":"\/blog\/0-19-0-rc2-released","author":{"name":"Shay Banon"},"date":"February 08, 2012","category":"","locales":"","content":" version is out. You can download it . Its a bug fix release mainly fixing a major bug in how buffers are read and reused over the network (the optimization done in 0.19.0.RC1 was not complete). It also include two nice features, the first is the ability to disallow a shard and its replica to be allocated on the same machine when running more than one instance on said machine. It can be enabled by setting to . The second is an effort to better log GC pause times (without needing to turn on GC logging), with GC type thresholds and logging thresholds (comes with built in default values). \n"}<br>{"index": {"_id": 1548}}<br>{"title":"0.19.0.RC1 Released","seo_title":"","url":"\/blog\/0-19-0-rc1-released","author":{"name":"Shay Banon"},"date":"February 07, 2012","category":"","locales":"","content":" version is out. You can download it . It is a major release candidate release of elasticsearch. This is the first time we release a \u201crelease candidate\u201d for elasticsearch. The aim is to get users to try it out, fix any problems found with it, and release a final release as soon as possible. Major features include improved indexing performance, more control over shard allocation, more statistics and simpler for stats, an update that accepts a script to perform an update on a document, better state storage when using local gateway, and many bug fixes. Upgrading This release requires a full cluster restart in order to upgrade to the new version (including issuing a flush across all indices before the restart). If you are using the (default) local gateway, it will automatically be upgraded to a new and improved state format (with backups of the original state). The structure of the project has also changed, moving all the plugins to their own repos under . Installing a plugin now requires specifying the location and version to install it from. \n"}<br>{"index": {"_id": 1549}}<br>{"title":"0.18.7 Released","seo_title":"","url":"\/blog\/0-18-7-released","author":{"name":"Shay Banon"},"date":"January 10, 2012","category":"","locales":"","content":" version is out. You can download it . It includes bug fixes including major bug fix in state storage with shared gateways (s3 for example), and support for nested documents in delete by query. \n"}<br>{"index": {"_id": 1550}}<br>{"title":"0.18.6 Released","seo_title":"","url":"\/blog\/0-18-6-released","author":{"name":"Shay Banon"},"date":"December 19, 2011","category":"","locales":"","content":" version is out. You can download it . It includes minor features and important bug fixes. Changes can be found . \n"}<br>{"index": {"_id": 1551}}<br>{"title":"0.18.5 Released","seo_title":"","url":"\/blog\/0-18-5-released","author":{"name":"Shay Banon"},"date":"November 29, 2011","category":"","locales":"","content":" version is out. You can download it . It includes an upgraded Lucene version (3.5), featuring bug fixes and memory improvements, as well as more bug fixes in elasticsearch itself. Changes can be found . \n"}<br>{"index": {"_id": 1552}}<br>{"title":"0.18.3 Released","seo_title":"","url":"\/blog\/0-18-3-released","author":{"name":"Shay Banon"},"date":"November 16, 2011","category":"","locales":"","content":" version has just been released. You can download it . Its an important bug fix release, including a fix for a and upgrade is highly recommended. An version with the bug fixed has also been released. The release also includes additional bug fixes, and some features including , and improved handling for dates. [Update]: Heads up that this release includes a broken plugin script, more info . [Update 2]: has been released fixing the plugin script. -shay.banon \n"}<br>{"index": {"_id": 1553}}<br>{"title":"0.18.0 Released","seo_title":"","url":"\/blog\/0-18-0-released","author":{"name":"Shay Banon"},"date":"October 26, 2011","category":"","locales":"","content":" version has just been released. You can download it . This is a major release, and includes the following major features: : was quickly released to fix a bug with custom location configuration and fetching inner fields from a source doc. Shard Allocation Awareness and Filtering Shard allocation within a cluster can now be \u201caware\u201d of which node replicas are allocated on (similar to rack awareness). It allows to make sure that a shard and a replica will be allocated across logical grouping of nodes. The awareness can also be forced, by not over allocating replicas within the same logical node group. Search and Get operations will automatically prefer shards that are allocated within the same logical node group the search is executing on. Filtering allows to explicitly control which nodes indices are allowed, or not allowed, to be allocated on, again, based on custom logical grouping of nodes (called node attributes). Both settings can be updated in realtime using either the cluster wide or index level update settings . More info can be found . Cluster Update Settings The cluster update settings allow to update node level settings (and not index level settings) in realtime on a live cluster. The settings allowed and more docs on the are provided . Timestamp and A document can now automatically be indexed with a timestamp associated with it, and have a (time to live), which, when expired, will cause the document to be deleted. More info can be found and . Improved Geo Execution Geo distance filter and facet good a considerable performance boost by doing bounding box optimization. Also, an option to use indexed lat lon for the checks (must be enabled in the mapping) is provided which can provide even faster executing under certain conditions (compared to in memory checks). More Statistics More statistics are now provided out of the box, including a new index stats (the status should not be used for stats anymore). Statistics for APIs such as index, get, and search are also being aggregated, with search allowing to specific specific stats grouping aggregation (to further distinguish search \u201ctypes\u201d). Multi Data locations A node can now work with multiple data locations, spreading the index files across those locations in a 0 like behavior. Smaller improvements and bug fixes Many more bug fixes and smaller improvement have went into this release. Full release notes can be found . -shay.banon \n"}<br>{"index": {"_id": 1554}}<br>{"title":"0.17.8 Released","seo_title":"","url":"\/blog\/0-17-8-released","author":{"name":"Shay Banon"},"date":"October 06, 2011","category":"","locales":"","content":" version has just been released. You can download it . The release includes major bug fixes listed . \n"}<br>{"index": {"_id": 1555}}<br>{"title":"0.17.7 Released","seo_title":"","url":"\/blog\/0-17-7-released","author":{"name":"Shay Banon"},"date":"September 19, 2011","category":"","locales":"","content":" version has just been released. You can download it . This release include the usual list of bug fixes, and also include an upgrade to Lucene 3.4.0 (fixes critical bugs, so make sure you upgrade), as well as improvements to the couchdb river (memory usage wise). \n"}<br>{"index": {"_id": 1556}}<br>{"title":"0.17.6 Released","seo_title":"","url":"\/blog\/0-17-6-released","author":{"name":"Shay Banon"},"date":"August 13, 2011","category":"","locales":"","content":" version has just been released. You can download it . This is is a quick release to fix a bug in automatic date detection when provided as or . \n"}<br>{"index": {"_id": 1557}}<br>{"title":"0.17.5 Released","seo_title":"","url":"\/blog\/0-17-5-released","author":{"name":"Shay Banon"},"date":"August 12, 2011","category":"","locales":"","content":" version has just been released. You can download it . This is a bug fix release and minor feature enhancements. Upgrade is highly recommended. \n"}<br>{"index": {"_id": 1558}}<br>{"title":"0.17.4 Released","seo_title":"","url":"\/blog\/0-17-4-released","author":{"name":"Shay Banon"},"date":"August 05, 2011","category":"","locales":"","content":" version has just been released. You can download it . This is a quick release post to fix a reported bug which probably doesn\u2019t affect most users, but its still an important one to get out there (for new users) as its a difficult one to track down\u2026 . The upgrade is only really needed when using explicit stored fields that have multi values, which can result in not all the values being returned when asked. \n"}<br>{"index": {"_id": 1559}}<br>{"title":"0.17.3 Released","seo_title":"","url":"\/blog\/0-17-3-released","author":{"name":"Shay Banon"},"date":"August 04, 2011","category":"","locales":"","content":" version has just been released. You can download it . This is another bug fix release with minor enhancements (listed ). This upgrade is highly recommended to all users. Note, when upgrading to this release, due to a bug in previous 0.17.x versions, it is recommended to run flush against all indices before shutting down the cluster (or doing a rolling restart) if \u201cdelete_by_query\u201d is used against specific types. \n"}<br>{"index": {"_id": 1560}}<br>{"title":"Mailing List Migration","seo_title":"","url":"\/blog\/mailing-list-migration","author":{"name":"Shay Banon"},"date":"July 27, 2011","category":"","locales":"","content":" I created the mailing list on a google apps account (paying one\u2026) with the hopes of not running into spam problems down the road. The problem with that is the fact that I did not know about the host of problems I will have with google account one\u2026 . The latest one is a major problem, where google apps restrict the size of members to 1000 members, and we just hit that. So, I am going to migrate the group to a new group in the \u201cpublic\u201d google groups, called . Sadly, I don\u2019t think migrating content is possible, but at least I will be able to subscribe all of you. I will automatically subscribe all under a \u201cSend email for each message and update\u201d option, so you will have to change that to your preference (sorry about that\u2026). : Google Groups seems to have spam limits on the number of users that can be added, will add them in batches over time, I guess\u2026 . Make sure to now if you can. Luckily, the group has been mirrored on nabble, and it will remain as a mirror to the new group as well. This group will be closed (but not deleted) and old content will be searchable from both nabble and this interface, posting will not be allowed though. And posts should only go to the new group mailing address. I will post details on the new group shortly, but you should get it as well via direct mail once I invite you. I apologize for that. If someone knows of a better way to migrate the mails, it would be great. -shay.banon \n"}<br>{"index": {"_id": 1561}}<br>{"title":"0.17.2 \/ 0.16.5 Released","seo_title":"","url":"\/blog\/0-17-2-0-16-5-released","author":{"name":"Shay Banon"},"date":"July 27, 2011","category":"","locales":"","content":" version and have just been released. You can download it . A major concurrency bug has been fixed when executing search requests, which is the reason for the 0.16.5 release and also included in the release. The release includes mainly bug fixes, and its highly recommended to upgrade to it if is used. \n"}<br>{"index": {"_id": 1562}}<br>{"title":"0.17.1 Released","seo_title":"","url":"\/blog\/0-17-1-released","author":{"name":"Shay Banon"},"date":"July 21, 2011","category":"","locales":"","content":" version has just been released. You can download it . This is a quick bug fix release fixing major bugs (listed ). \n"}<br>{"index": {"_id": 1563}}<br>{"title":"0.17.0 Released","seo_title":"","url":"\/blog\/0-17-0-released","author":{"name":"Shay Banon"},"date":"July 19, 2011","category":"Engineering","locales":"","content":" \n"}<br>{"index": {"_id": 1564}}<br>{"title":"0.16.2 Released","seo_title":"","url":"\/blog\/0-16-2-released","author":{"name":"Shay Banon"},"date":"June 01, 2011","category":"","locales":"","content":" version has just been released. You can download it . The bulk of the work on this release (backported from master) revolves around improved memory usage, especially with the filter cache (there is a new default filter cache, which takes the size in bytes as a limit on works on the level). As usual, bug fixes and other minor improvements. Upgrade is highly recommended. \n"}<br>{"index": {"_id": 1565}}<br>{"title":"Data Visualization with ElasticSearch and Protovis","seo_title":"","url":"\/blog\/data-visualization-with-elasticsearch-and-protovis","author":{"name":"Karel Mina\u0159\u00edk"},"date":"May 13, 2011","category":"Engineering","locales":"","content":" The primary purpose of a search engine is, quite unsurprisingly: . You pass it a query, and it returns bunch of matching documents, in the order of relevance. We can get creative with query construction, experimenting with different analyzers for our documents, and the search engine tries hard to provide best results. Nevertheless, a modern full-text search engine can do much more than that. At its core lies the , a highly optimized data structure for efficient lookup of documents matching the query. But it also allows to compute complex of our data, called . The usual purpose of facets is to offer the user a , or . When you search for \u201ccamera\u201d at an online store, you can refine your search by choosing different manufacturers, price ranges, or features, usually by clicking on a link, not by fiddling with the query syntax. A canonical example of a is pictured below. Faceted search is one of the few ways to make powerful queries accessible to your users: see Moritz Stefaner\u2019s experiments with for inspiration. But, we can do much more with facets then just displaying these links and checkboxes. We can use the data for makings , which is exactly what we\u2019ll do in this article. Live Dashboards In almost any analytical, monitoring or data-mining service you\u2019ll hit the requirement sooner or later. Because everybody loves dashboards, whether they\u2019re useful or just pretty. As it happens, we can use facets as a pretty powerful analytical engine for our data, without writing any implementations. The screenshot below is from a which uses not only to search and mine the data, but also to provide data aggregation for the interactive dashboard. When the user drills down into the data, adds a keyword, uses a custom query, all the charts change in real-time, thanks to the way how facet aggregation works. The dashboard is not a static snapshot of the data, pre-calculated periodically, but a truly interactive tool for data exploration. In this article, we\u2019ll learn how to retrieve data for charts like these from , and how to create the charts themselves. Pie charts with a facet For the first chart, we\u2019ll use a simple facet in . This facet returns the most frequent terms for a field, together with occurence counts. Let\u2019s index some example data first. curl -X DELETE \"http:\/\/localhost:9200\/dashboard\" curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d ' { \"title\" : \"One\", \"tags\" : [\"ruby\", \"java\", \"search\"]} ' curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d ' { \"title\" : \"Two\", \"tags\" : [\"java\", \"search\"] } ' curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d ' { \"title\" : \"Three\", \"tags\" : [\"erlang\", \"search\"] } ' curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d ' { \"title\" : \"Four\", \"tags\" : [\"search\"] } ' curl -X POST \"http:\/\/localhost:9200\/dashboard\/_refresh\" As you see, we are storing four articles, each with a couple of tags: an article can have multiple tags, which is trivial to express in \u2019s document format, JSON. Now, to retrieve \u201cTop Ten Tags\u201d across the documents, we can simply do: curl -X POST \"http:\/\/localhost:9200\/dashboard\/_search?pretty=true\" -d ' { \"query\" : { \"match_all\" : {} }, \"facets\" : { \"tags\" : { \"terms\" : {\"field\" : \"tags\", \"size\" : 10} } } } ' You can see that we are retrieving all documents, and we have defined a terms facet called \u201ctags\u201d. This query will return something like this: { \"took\" : 2, \/\/ ... snip ... \"hits\" : { \"total\" : 4, \/\/ ... snip ... }, \"facets\" : { \"tags\" : { \"_type\" : \"terms\", \"missing\" : 1, \"terms\" : [ { \"term\" : \"search\", \"count\" : 4 }, { \"term\" : \"java\", \"count\" : 2 }, { \"term\" : \"ruby\", \"count\" : 1 }, { \"term\" : \"erlang\", \"count\" : 1 } ] } } } We are interested in the section of the JSON, notably in the array. It tells us that we have four articles tagged , two tagged , and so on. (Of course, we could add a parameter to the query, to skip the results altogether.) Suitable visualization for this type of ratio distribution is a pie chart, or its variation: a donut chart. The end result is displayed below (you may want to check out the ). We will use , a JavaScript data visualization toolkit. is 100% open source, and you could think of it as for data visualization: in stark contrast to similar tools, it does not ship with a limited set of chart types to \u201cchoose\u201d from, but it defines a set of primitives and a flexible domain-specific language so you can easily build your own custom visualizations. Creating is pretty easy in . Since returns JSON data, we can load it with a simple Ajax call. Don\u2019t forget that you can clone or download the for this example. First, we need a HTML file to contain our chart and to load the data from : &lt: !DOCTYPE html&gt: &lt: html&gt: &lt: head&gt: &lt: title&gt: ElasticSearch Terms Facet Donut Chart&lt: \/title&gt: &lt: meta http-equiv=&quot: Content-Type&quot: content=&quot: text\/html: charset=utf-8&quot: \/&gt: &lt: !-- Load JS libraries --&gt: &lt: script src=&quot: jquery-1.5.1.min.js&quot: &gt: &lt: \/script&gt: &lt: script src=&quot: protovis-r3.2.js&quot: &gt: &lt: \/script&gt: &lt: script src=&quot: donut.js&quot: &gt: &lt: \/script&gt: &lt: script&gt: $( function() { load_data(): }): var load_data = function() { $.ajax({ url: &#x27: http:\/\/localhost:9200\/dashboard\/article\/_search?pretty=true&#x27: , type: &#x27: POST&#x27: , data : JSON.stringify({ &quot: query&quot: : { &quot: match_all&quot: : {} }, &quot: facets&quot: : { &quot: tags&quot: : { &quot: terms&quot: : { &quot: field&quot: : &quot: tags&quot: , &quot: size&quot: : &quot: 10&quot: } } } }) , dataType : &#x27: json&#x27: , processData: false , success: function(json, statusText, xhr) { return display_chart(json): } , error: function(xhr, message, error) { console.error(&quot: Error while loading data from ElasticSearch&quot: , message): throw(error): } }): var display_chart = function(json) { Donut().data(json.facets.tags.terms).draw(): }: }: &lt: \/script&gt: &lt: \/head&gt: &lt: body&gt: &lt: !-- Placeholder for the chart --&gt: &lt: div id=&quot: chart&quot: &gt: &lt: \/div&gt: &lt: \/body&gt: &lt: \/html&gt: On document load, we retrieve exactly the same facet, via Ajax, as we did earlier with . In the jQuery Ajax , we pass the returned JSON to the function via the wrapper. The function itself is displayed, with annotations, below: \/\/ ===================================================================================================== \/\/ A donut chart with Protovis - See http:\/\/vis.stanford.edu\/protovis\/ex\/pie.html \/\/ ===================================================================================================== var Donut = function(dom_id) { if (&#x27: undefined&#x27: == typeof dom_id) { \/\/ Set the default DOM element ID to bind dom_id = &#x27: chart&#x27: : } var data = function(json) { \/\/ Set the data for the chart this.data = json: return this: }: var draw = function() { var entries = this.data.sort( function(a, b) { \/\/ Sort the data by term names, so the return a.term &lt: b.term ? -1 : 1: \/\/ color scheme for wedges is preserved }), \/\/ with any order values = pv.map(entries, function(e) { \/\/ Create an array holding just the counts return e.count: }): \/\/ console.log(&#x27: Drawing&#x27: , entries, values): var w = 200, \/\/ Dimensions and color scheme for the chart h = 200, colors = pv.Colors.category10().range(): var vis = new pv.Panel() \/\/ Create the basis panel .width(w) .height(h) .margin(0, 0, 0, 0): vis.add(pv.Wedge) \/\/ Create the &quot: wedges&quot: of the chart .def(&quot: active&quot: , -1) \/\/ Auxiliary variable to hold mouse over state .data( pv.normalize(values) ) \/\/ Pass the normalized data to Protovis .left(w\/3) \/\/ Set-up chart position and dimension .top(w\/3) .outerRadius(w\/3) .innerRadius(15) \/\/ Create a &quot: donut hole&quot: in the center .angle( function(d) { \/\/ Compute the &quot: width&quot: of the wedge return d * 2 * Math.PI: }) .strokeStyle(&quot: #fff&quot: ) \/\/ Add white stroke .event(&quot: mouseover&quot: , function() { \/\/ On &quot: mouse over&quot: , set the &quot: wedge&quot: as active this.active(this.index): this.cursor(&#x27: pointer&#x27: ): return this.root.render(): }) .event(&quot: mouseout&quot: , function() { \/\/ On &quot: mouse out&quot: , clear the active state this.active(-1): return this.root.render(): }) .event(&quot: mousedown&quot: , function(d) { \/\/ On &quot: mouse down&quot: , perform action, var term = entries[this.index].term: \/\/ such as filtering the results... return (alert(&quot: Filter the results by &#x27: &quot: +term+&quot: &#x27: &quot: )): }) .anchor(&quot: right&quot: ).add(pv.Dot) \/\/ Add the left part of he &quot: inline&quot: label, \/\/ displayed inside the donut &quot: hole&quot: .visible( function() { \/\/ The label is visible when its wedge is active return this.parent.children[0] .active() == this.index: }) .fillStyle(&quot: #222&quot: ) .lineWidth(0) .radius(14) .anchor(&quot: center&quot: ).add(pv.Bar) \/\/ Add the middle part of the label .fillStyle(&quot: #222&quot: ) .width(function(d) { \/\/ Compute width: return (d*100).toFixed(1) \/\/ add pixels for percents .toString().length*4 + 10 + \/\/ add pixels for glyphs (%, etc) entries[this.index] \/\/ add pixels for letters (very rough) .term.length*9: }) .height(28) .top((w\/3)-14) .anchor(&quot: right&quot: ).add(pv.Dot) \/\/ Add the right part of the label .fillStyle(&quot: #222&quot: ) .lineWidth(0) .radius(14) .parent.children[2].anchor(&quot: left&quot: ) \/\/ Add the text to label .add(pv.Label) .left((w\/3)-7) .text(function(d) { \/\/ Combine the text for label return (d*100).toFixed(1) + &quot: %&quot: + &#x27: &#x27: + entries[this.index].term + &#x27: (&#x27: + values[this.index] + &#x27: )&#x27: : }) .textStyle(&quot: #fff&quot: ) .root.canvas(dom_id) \/\/ Bind the chart to DOM element .render(): \/\/ And render it. }: return { \/\/ Create the public API data : data, draw : draw }: }: As you can see, with a simple transformation of JSON data returned from , we\u2019re able to create rich, attractive visualization of tag distribution among our articles. It\u2019s worth repeating that the visualization will work in when we use a different query, such as displaying only articles written by a certain author or published in certain date range. Timelines with a facets makes it very easy to create another common form of visualization: the . Any type of data, tied to a certain date, such as an article being published, an event taking place, a purchase being completed can be visualized on a timeline. The end result should look like this: So, let's store handful of articles with a date in the index. curl -X DELETE \"http:\/\/localhost:9200\/dashboard\" curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d '{ \"t\" : \"1\", \"published\" : \"2011-01-01\" }' curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d '{ \"t\" : \"2\", \"published\" : \"2011-01-02\" }' curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d '{ \"t\" : \"3\", \"published\" : \"2011-01-02\" }' curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d '{ \"t\" : \"4\", \"published\" : \"2011-01-03\" }' curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d '{ \"t\" : \"5\", \"published\" : \"2011-01-04\" }' curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d '{ \"t\" : \"6\", \"published\" : \"2011-01-04\" }' curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d '{ \"t\" : \"7\", \"published\" : \"2011-01-04\" }' curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d '{ \"t\" : \"8\", \"published\" : \"2011-01-04\" }' curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d '{ \"t\" : \"9\", \"published\" : \"2011-01-10\" }' curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d '{ \"t\" : \"10\", \"published\" : \"2011-01-12\" }' curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d '{ \"t\" : \"11\", \"published\" : \"2011-01-13\" }' curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d '{ \"t\" : \"12\", \"published\" : \"2011-01-14\" }' curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d '{ \"t\" : \"13\", \"published\" : \"2011-01-14\" }' curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d '{ \"t\" : \"14\", \"published\" : \"2011-01-15\" }' curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d '{ \"t\" : \"15\", \"published\" : \"2011-01-20\" }' curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d '{ \"t\" : \"16\", \"published\" : \"2011-01-20\" }' curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d '{ \"t\" : \"17\", \"published\" : \"2011-01-21\" }' curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d '{ \"t\" : \"18\", \"published\" : \"2011-01-22\" }' curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d '{ \"t\" : \"19\", \"published\" : \"2011-01-23\" }' curl -X POST \"http:\/\/localhost:9200\/dashboard\/article\" -d '{ \"t\" : \"20\", \"published\" : \"2011-01-24\" }' curl -X POST \"http:\/\/localhost:9200\/dashboard\/_refresh\" To retrieve the frequency of articles being published, we\u2019ll use a in . curl -X POST \"http:\/\/localhost:9200\/dashboard\/_search?pretty=true\" -d ' { \"query\" : { \"match_all\" : {} }, \"facets\" : { \"published_on\" : { \"date_histogram\" : { \"field\" : \"published\", \"interval\" : \"day\" } } } } ' Notice how we set the interval to : we could easily change the granularity of the histogram to , , or . This query will return JSON looking like this: { \"took\" : 2, \/\/ ... snip ... \"hits\" : { \"total\" : 4, \/\/ ... snip ... }, \"facets\" : { \"published\" : { \"_type\" : \"histogram\", \"entries\" : [ { \"time\" : 1293840000000, \"count\" : 1 }, { \"time\" : 1293926400000, \"count\" : 2 } \/\/ ... snip ... ] } } } We are interested in the array, as in the previous example. And again, we will need some HTML to hold our chart and load the data. Since the mechanics are very similar, please refer to the for this example. With the JSON data, it\u2019s very easy to create rich, interactive timeline in , by using a customized . The full, annotated code of the JavaScript function is displayed below. \/\/ ===================================================================================================== \/\/ A timeline chart with Protovis - See http:\/\/vis.stanford.edu\/protovis\/ex\/area.html \/\/ ===================================================================================================== var Timeline = function(dom_id) { if ('undefined' == typeof dom_id) { \/\/ Set the default DOM element ID to bind dom_id = 'chart': } var data = function(json) { \/\/ Set the data for the chart this.data = json: return this: }: var draw = function() { var entries = this.data: \/\/ Set-up the data entries.push({ \/\/ Add the last \"blank\" entry for proper count : entries[entries.length-1].count \/\/ timeline ending }): \/\/ console.log('Drawing, ', entries): var w = 600, \/\/ Set-up dimensions and scales for the chart h = 100, max = pv.max(entries, function(d) {return d.count: }), x = pv.Scale.linear(0, entries.length-1).range(0, w), y = pv.Scale.linear(0, max).range(0, h): var vis = new pv.Panel() \/\/ Create the basis panel .width(w) .height(h) .bottom(20) .left(20) .right(40) .top(40): vis.add(pv.Label) \/\/ Add the chart legend at top left .top(-20) .text(function() { var first = new Date(entries[0].time): var last = new Date(entries[entries.length-2].time): return \"Articles published between \" + [ first.getDate(), first.getMonth() + 1, first.getFullYear() ].join(\"\/\") + \" and \" + [ last.getDate(), last.getMonth() + 1, last.getFullYear() ].join(\"\/\"): }) .textStyle(\"#B1B1B1\") vis.add(pv.Rule) \/\/ Add the X-ticks .data(entries) .visible(function(d) {return d.time: }) .left(function() { return x(this.index): }) .bottom(-15) .height(15) .strokeStyle(\"#33A3E1\") .anchor(\"right\").add(pv.Label) \/\/ Add the tick label (DD\/MM) .text(function(d) { var date = new Date(d.time): return [ date.getDate(), date.getMonth() + 1 ].join('\/'): }) .textStyle(\"#2C90C8\") .textMargin(\"5\") vis.add(pv.Rule) \/\/ Add the Y-ticks .data(y.ticks(max)) \/\/ Compute tick levels based on the \"max\" value .bottom(y) .strokeStyle(\"#eee\") .anchor(\"left\").add(pv.Label) .text(y.tickFormat) .textStyle(\"#c0c0c0\") vis.add(pv.Panel) \/\/ Add container panel for the chart .add(pv.Area) \/\/ Add the area segments for each entry .def(\"active\", -1) \/\/ Auxiliary variable to hold mouse state .data(entries) \/\/ Pass the data to Protovis .bottom(0) .left(function(d) {return x(this.index): }) \/\/ Compute x-axis based on scale .height(function(d) {return y(d.count): }) \/\/ Compute y-axis based on scale .interpolate('cardinal') \/\/ Make the chart curve smooth .segmented(true) \/\/ Divide into \"segments\" (for interactivity) .fillStyle(\"#79D0F3\") .event(\"mouseover\", function() { \/\/ On \"mouse over\", set segment as active this.active(this.index): return this.root.render(): }) .event(\"mouseout\", function() { \/\/ On \"mouse out\", clear the active state this.active(-1): return this.root.render(): }) .event(\"mousedown\", function(d) { \/\/ On \"mouse down\", perform action, var time = entries[this.index].time: \/\/ eg filtering the results... return (alert(\"Timestamp: '\"+time+\"'\")): }) .anchor(\"top\").add(pv.Line) \/\/ Add thick stroke to the chart .lineWidth(3) .strokeStyle('#33A3E1') .anchor(\"top\").add(pv.Dot) \/\/ Add the circle \"label\" displaying \/\/ the count for this day .visible( function() { \/\/ The label is only visible when return this.parent.children[0] \/\/ its segment is active .active() == this.index: }) .left(function(d) { return x(this.index): }) .bottom(function(d) { return y(d.count): }) .fillStyle(\"#33A3E1\") .lineWidth(0) .radius(14) .anchor(\"center\").add(pv.Label) \/\/ Add text to the label .text(function(d) {return d.count: }) .textStyle(\"#E7EFF4\") .root.canvas(dom_id) \/\/ Bind the chart to DOM element .render(): \/\/ And render it. }: return { \/\/ Create the public API data : data, draw : draw }: }: Be sure to check out the documentation on the primitive in , and watch what happens when you change to . You should have no problems to draw a from multiple facets, add more interactivity, and completely customize the visualization. The important thing to notice here is that the chart fully responds to any queries we pass to , making it possible to simply and instantly visualize metrics such as , with a query such as: author:John AND topic:Search AND published:[2011-03-01 TO 2011-05-31] tl: dr When you need to make rich, interactive data visualization for complex, ad-hoc queries, using data returned by from may well be one of the easiest ways to do it, since you can just pass the JSON response to a toolkit like . By adapting the approach and code from this article, you should have a working example for your data in couple of hours. \n"}<br>{"index": {"_id": 1566}}<br>{"title":"0.16.1 Released","seo_title":"","url":"\/blog\/0-16-1-released","author":{"name":"Shay Banon"},"date":"May 12, 2011","category":"","locales":"","content":" version has just been released. You can download it . This is a minor release but it includes some really cool features and enhancements: Text Query Family A new family of queries called . The aim with those is to simplify querying elasticsearch with regards to the analysis process (and should hopefully remove some confusion when using query). More Analysis Options All the analyzers (mainly around language analyzers) part of Lucene are now exposed. On top of that, several token filters were backported from Lucene 4.0 (synonym and word_delimiter). Other Minor additional enhancements (better global facets execution, custom boost per value for type, and more) and important bug fixes are part of this release. Upgrade is highly recommended. \n"}<br>{"index": {"_id": 1567}}<br>{"title":"0.16.0 Released","seo_title":"","url":"\/blog\/0-16-0-released","author":{"name":"Shay Banon"},"date":"April 23, 2011","category":"","locales":"","content":" version has just been released. You can download it . This release is quite a big and important one, adding many new features, and fixes several major\/critical bugs. Features\/enhancements include the ability to update many more index level settings at runtime, several new search types, new facet called term_stats, faster facets execution all around, upgrade to Lucene 3.1, improved support for many indices (memory wise), faster recover post full restart, much improved shard allocation logic to reduce load, and many more. Many bugs have also been fix, with several critical ones revolving around possible data loss. Its highly recommended to upgrade. All changes are listed in the . Upgrade Notes The field is no longer indexed by default. No functionality is lost by it, but, if the field was used in term\/terms query\/filters, it should be replaced with the new ids query\/filter. The issue explaining it is . \n"}<br>{"index": {"_id": 1568}}<br>{"title":"New Search Types","seo_title":"","url":"\/blog\/new-search-types","author":{"name":"Shay Banon"},"date":"March 24, 2011","category":"","locales":"","content":" has had the ability to control the since its inception. It includes the ability to control how to execute the \u201cquery\u201d and \u201cfetch\u201d phases of a distributed search execution, as well as the ability to compute distributed frequencies across shards (the \u201cdfs\u201d phase). Two things that many users have been asking for is the ability to easily iterate over a very large result set as fast as possible, and the ability to just count results (possibly with facets) without actually fetching any hits back. Both features are now supported as new search types. count The first is the search type. It allows to get back the total number of hits matching a query, with the ability to have facets configured in an optimized (implementation wise and performance wise) manner. For example: curl -XGET 'http:\/\/localhost:9200\/twitter\/tweet\/_search?search_type=count' -d '{ \"query\": { \"filtered\" : { \"query\" : { \"query_string\" : { \"query\" : \"some query string here\" } }, \"filter\" : { \"term\" : { \"user\" : \"kimchy\" } } } } } ' The result will not include any hits, just the and optional facets results. scan The new type allows to scroll a very large result set in an optimized manner. When scrolling large result set using one of the other search types, there is an overhead (that increases the more we scroll \u201cinto\u201d the result set) that comes from the fact that sorting needs to be computed (either by score, or custom). The type does no sorting, allowing it to optimize the scrolling process. It uses the same scroll mechanism when using other search types. The initial search execution bootstraps the scanning process: curl -XGET 'localhost:9200\/_search?search_type=scan&scroll=10m&size=50' -d ' { \"query\" : { \"match_all\" : {} } } ' The parameter indicates two things, the fact that we wish to scroll further into the result set, and the timeout value for maintaing the scroll \u201copen\u201d (the timeout value applies per request, not globally across the scroll process). The parameter controls how many hits we want to get back. Note, the actual number of hits will be the the size provided times the number of shards, which is done in order to further optimize the scrolling process. The result of the search request is a . The should then be used as a parameter to the next search request: curl -XGET 'localhost:9200\/_search\/scroll?scroll=10m' -d 'c2NhbjsxOjBLMzdpWEtqU2IyZHlmVURPeFJOZnc7MzowSzM3aVhLalNiMmR5ZlVET3hSTmZ3OzU6MEszN2lYS2pTYjJkeWZVRE94Uk5mdzsyOjBLMzdpWEtqU2IyZHlmVURPeFJOZnc7NDowSzM3aVhLalNiMmR5ZlVET3hSTmZ3Ow==' The results now will include hits, and another , which should then be used as the parameter to the next scroll request. Also, the parameter needs to be provided again in order to indicate we wish to continue the scrolling process. The \u201cexit\u201d point from the scrolling process is when no hits are returned back. -shay.banon \n"}<br>{"index": {"_id": 1569}}<br>{"title":"Update Settings","seo_title":"","url":"\/blog\/update-settings","author":{"name":"Shay Banon"},"date":"March 23, 2011","category":"","locales":"","content":" When using , many times the initial usage of an index in the cluster is bulk indexing data into it, and then moving into a more \u201cstreamlined\u201d operations that are applied in realtime against it. When doing something like bulk indexing, changing the default settings of the index can improve the speed at which documents are indexed, but, those settings then do not really apply for the case where we want to do real time indexing of data. Some of those settings include , which defaults to . Setting this value to be higher can improve indexing speed. Other settings include low level Lucene settings such as . In the upcoming 0.16 version (and already in master), there has been a lot of work going into being able to update a subset of index level settings in real time to improve that. It uses the same update settings already exposed that allowed to change only the . For example, lets say we are going to do some bulk indexing into an index, we can simply change the relevant index settings to the following: curl -XPUT localhost:9200\/test\/_settings -d '{ \"index\" : { \"refresh_interval\" : \"-1\", \"merge.policy.merge_factor\" : 30 } }' The above will disable refreshing of the index completely, and change the merge factor to be 30. Once the bulk loading is done, we can get back to the default settings: curl -XPUT localhost:9200\/test\/_settings -d '{ \"index\" : { \"refresh_interval\" : \"1s\", \"merge.policy.merge_factor\" : 10 } }' This makes even more elastic, allowing to munge it to adapt to what is currently required from it. The following are a list of issues listing the currently updateable settings: If you are missing some settings, ping the mailing list and we can see if they can also be updated dynamically. \n"}<br>{"index": {"_id": 1570}}<br>{"title":"0.15.0 Released","seo_title":"","url":"\/blog\/0-15-0-released","author":{"name":"Shay Banon"},"date":"February 18, 2011","category":"","locales":"","content":" version has just been released. You can download it . This is another major release that includes several major features and of course, the typical set of bug fixes and enhancements. Some of the major features include: Versioning Versioning got its own detailing how to use the feature. It now allows for a more interesting interaction model where we can use optimistic concurrency control when creating and updating documents. Percolator is an interesting feature, basically turning search upside down: Instead of indexing docs and searching for them, during the indexing process docs are \u201cpercolated\u201d to find out which queries match them. I can\u2019t wait to see all of the cool things that will be built on top of utilizing this feature!. Date Histogram One of the more powerful features of elasticsearch are , and one of my favorite facets is the facet (think \"number of comments per month). When using it on a field though, it lacks some important features. The facet comes to solve and enhance the regular histogram by allowing you to \u201cbucket\u201d results by uneven intervals, like months and years. On top of that, you can provide a time zone to control exactly how the \u201cbuckets\u201d of hits are defined \u2013 something you can\u2019t really do on the client side. Search Filter The new element to the search will now allow you to do facet based navigation in a much simpler way. The new element filters out returned hits, but will be applied to facet calculations. (although each facet can still have its own filters as well using the element). This allows things like navigation-by-facets to be done in a much simpler manner, while controlling which facets are affected by it and which ones still apply only to the original user-supplied query. Many More There are many more performance improvements, enhancements, features, and bug fixes, all listed in the . -shay.banon \n"}<br>{"index": {"_id": 1571}}<br>{"title":"Versioning","seo_title":"","url":"\/blog\/versioning","author":{"name":"Shay Banon"},"date":"February 08, 2011","category":"Engineering","locales":"","content":" \n"}<br>{"index": {"_id": 1572}}<br>{"title":"Percolator","seo_title":"","url":"\/blog\/percolator","author":{"name":"Shay Banon"},"date":"February 08, 2011","category":"Engineering","locales":"","content":" \n"}<br>{"index": {"_id": 1573}}<br>{"title":"0.14.0 Released","seo_title":"","url":"\/blog\/0-14-0-released","author":{"name":"Shay Banon"},"date":"December 27, 2010","category":"Engineering","locales":"","content":" \n"}<br>{"index": {"_id": 1574}}<br>{"title":"0.13.0 Released","seo_title":"","url":"\/blog\/0-13-0-released","author":{"name":"Shay Banon"},"date":"November 18, 2010","category":"Engineering","locales":"","content":" ElasticSearch version has just been released. You can download it . This release includes important bug fixes (most important one is a possible corruption in the index data) and some new features, including:More Mapping FeaturesSupport for a new IP (ipv4) type (that is automatically detected) allowing to do range queries (for example) on IP ranges. More enhancements to dynamic templates matching, a compression threshold on the source field, and an analyzer mapping field.Explicit Shard Routing ControlUp until 0.13, documents were routed to the relevant shard based on their respective type and id values. In this version, they are not routed only by the id value by default (check the upgrade notes below), and they can be routed based on a custom value. This means that doing searches can be much faster when knowing in advance the list of routing values the search should executed on.For example, when indexing a blog post as a single document, and a blog comment as another document, the comment document can be routed to the same shard as the blog post using the blog post id. This means that when wanting to search only on things relating to a specific blog post, only a single shard needs to be searched on and not all shards of that index.This is very similar to the multi indices feature (and the ability to search on several of them), but provides a much higher control of routing within an index.Improved Support for Large Number of IndicesLarge number of indices now consume much less resources on the cluster as a whole, and a new allowing to close and open an index has been added.Many More Smaller FeaturesThere are many more smaller features, with the list available under the 0.13 tag.Upgrade NotesTwo important nodes when upgrading to 0.13:The first, due to the change in the default routing mechanism of routing only based on the id and not the type, existing systems upgrading to the new version must set the to in order to maintain the same hashing mechanism as in previous releases.The second, the location of the index files have changed. It used to be stored under the \u201cwork\u201d directory, but it has been moved to a new \u201cdata\u201d directory. This means two things, if you are using the default, then rename the work directory under the installation to data. If was being explicitly set, change the setting to .This was done in order to simplify the management of files elasticsearch created. Now, there are three places where data is created: for index related data information, for the location of the logs, and for temporal data.-shay.banon \n"}<br>{"index": {"_id": 1575}}<br>{"title":"0.12.0 Released","seo_title":"","url":"\/blog\/0-12-0-released","author":{"name":"Shay Banon"},"date":"October 18, 2010","category":"","locales":"","content":" ElasticSearch version has just been released. You can download it . This release is a bit early due to a major bug found with full cluster recovery when using more than one index and the local gateway. Along the way, some features were added as well, those include: More Script Language Support On top of mvel, there is now support for JavaScript, Python, and Groovy for executing scripts. Scripts can be used in different components within elasticsearch, including custom scoring, facets, and others. This support is going to be utilized in future features as well. Dynamic Templates Dynamic schema introduction is already a part of elasticsearch, but sometimes, the defaults are just not good enough. Dynamic templates allow to control different mappings aspects while still retaining the dynamic nature of a document. A dynamic template, for example, can turn a single field automatically into a `multi_field` or have fields matching a template be stored. Geo Overhaul The geo support aim was to support multiple location per document. The current design was problematic in supporting that, so a new design was implemented. This sadly requires a full reindexing if using geo features, as well as requiring to explicitly define `geo_point` mapping type. Facets Improvements Both the `term` and the `statistical` facets now can be executed on more than one field and aggregating the results across all fields values. Query Filters Improvements Fine grained control over which filter results are cached or not, with sensible defaults per filter (as filters behave differently). Other Several small bug fixes and improvements. Note, if you use the thrift client, the thrift protocol has changed not to include some keywords in certain langs. Make sure to regenerate the client code. -shay.banon \n"}<br>{"index": {"_id": 1576}}<br>{"title":"0.11.0 Released","seo_title":"","url":"\/blog\/0-11-0-released","author":{"name":"Shay Banon"},"date":"September 29, 2010","category":"","locales":"","content":" ElasticSearch version has just been released. You can download it . This is a major release for elasticsearch, both in terms of feature set as well as stability. Major list of features include: Zero Conf Persistency Out of the box long term persistency using a \u201clocal\u201d gateway dubbed . River Generic support for which are services running within the elasticsearch cluster indexing streams of data. Rivers exists for , , and . Bulk A new to do bulk indexing of data, greatly increasing the throughput of the indexing process. Details . Thrift Transport A Thrift based transport (mimicking ) for faster execution compared with plain . Minor Features Minor features include and the ability to use them in plain fields, , improved geo support, faster query_string and field queries execution, and of course, bug fixes. -shay.banon \n"}<br>{"index": {"_id": 1577}}<br>{"title":"Searchable CouchDB","seo_title":"","url":"\/blog\/the-river-searchable-couchdb","author":{"name":"Shay Banon"},"date":"September 28, 2010","category":"","locales":"","content":" allows to easily define data sources and have elasticsearch index them. The example provided in the post is twitter, but a river is an open and can have different implementations. One of those coming out at 0.11 is . The allows to automatically index couchdb and make it searchable using the excellent stream couchdb provides. Setting it up is as simple as executing the following against elasticsearch: curl -XPUT 'localhost:9200\/_river\/my_db\/_meta' -d '{ \"type\" : \"couchdb\", \"couchdb\" : { \"host\" : \"localhost\", \"port\" : 5984, \"db\" : \"my_db\", \"filter\" : null } }' This call will create a river that uses the stream to index all data within couchdb. Moreover, any \u201cfuture\u201d changes will automatically be indexed as well, making your search index and couchdb synchronized at all times. On top of that, in case of a failover, the couchdb river will automatically be started on another elasticsearch node, and continue indexing from the last indexed seq. As you can see, elasticsearch can easily have several couchdb rivers (and other types of rivers) running at the same time, all pointing to different databases and indexing them into different indices (or the same index, you choose) using the same elasticsearch cluster. This means that being able to search couchdb has just become really really simple. The couchdb river is provided as a plugin (in upcoming 0.11) and can be installed using . -shay.banon \n"}<br>{"index": {"_id": 1578}}<br>{"title":"RabbitMQ River","seo_title":"","url":"\/blog\/the-river-rabbitmq","author":{"name":"Shay Banon"},"date":"September 28, 2010","category":"Engineering","locales":"","content":" \n"}<br>{"index": {"_id": 1579}}<br>{"title":"The River","seo_title":"","url":"\/blog\/the-river","author":{"name":"Shay Banon"},"date":"September 28, 2010","category":"Engineering","locales":"","content":" One of the problems elasticsearch aims at solving is \u201cthe river\u201d problem. The River is the stream of constant data and somehow finding a way to waddle through it and make something meaningful out of it. That constant data stream can come in different forms and from different sources. It can come directly from a user in an application that uses elasticsearch directly. For example, publishing a new status message, a new blog comment, or a review of a restaurant on apps that automatically apply that change to elasticsearch. Another option is for the data to be pushed to elasticsearch. For example, , cloudera log aggregator, can use an to push log changes to elasticsearch. The last option, and the one discussed here is where data is pulled from one source and applied to elasticsearch. As an example, someone can write a twitter component that listens on twitter stream updates, and apply them to elasticsearch. Those type of components, aside from writing the core code that does it, require additional services to be provided for them. For example, the twitter component will require failover support (if it fails, start it on another node), and possibly state storage (what was the last tweet indexed). in elasticsearch provides just that. A river is a service running within elasticsearch cluster and tries and solve the third type of integration point mentioned above. Rivers are allocated to nodes within the cluster. Are provided with automatic failover in case of node failure, and allow to store state associated with them. The River implementation is a bit of a cheat , rivers are simply represented as different types within an index called . Creating them is as simple as creating a document named within the river (type). Deleting them is just a matter of deleting the river (type). And last, they can easily store state as addition document(s) within the index type. ElasticSearch has a framework support for rivers, and upcoming 0.11 version will come with several different implementations of rivers. The one covered here is the . Here is how it can be created: curl -XPUT localhost:9200\/_river\/my_twitter_river\/_meta -d ' { \"type\" : \"twitter\", \"twitter\" : { \"user\" : \"twitter_user\", \"password\" : \"twitter_passowrd\" } } ' Once created, the will start to be indexed into elasticsearch (including all the relevant metadata, like geo location, places, replies, and so on). Think about the power and capabilities you get with all that data indexed in elasticsearch . Deleting the twitter river is as simple as: curl -XDELETE localhost:9200\/_river\/my_twitter_river The twitter river will be provided as a plugin in 0.11, and can be easily installed using . \n"}<br>{"index": {"_id": 1580}}<br>{"title":"Zero Conf Persistency","seo_title":"","url":"\/blog\/zero-conf-persistency","author":{"name":"Shay Banon"},"date":"September 27, 2010","category":"","locales":"","content":" With the new \u201clocal gateway\u201d, upcoming elasticsearch version 0.11 will provide zero conf long term persistency out of the box. In the post, elasticsearch support for long term persistency is explained. The idea is built around providing long term persistency using a shared storage solution. A common storage option between all nodes (shared file system, S3, ) is used to asynchronously write changes in both the cluster meta data (indices created, mappings) and the actual indices to it. The shared storage option has several benefits. One obvious one is the ability to store (parts) the index in memory, and still maintain long term persistency in case of full cluster shutdown. It also provides a native solution if backup is required of the indices (to s3 for example). It does come with an overhead though, the first is the actual need for a shared storage solution for long term persistency, which does complicate things for simpler and get it started scenarios. The other is the fact that potentially very large data set will be stored, where simply using a shared storage is an overhead that is unacceptable (mainly due to cost). In upcoming 0.11 version, another gateway option is provided, called local gateway. The local gateway option allows the cluster to restore both its state and the indices from each node local storage (local file system). And, in order to provide the best out of the box experience, this gateway is now the default one set. The cluster state, which includes the indices created, mappings, and other meta information is versioned and stored on the nodes. In order to recover it, the (or ) should be set to high enough value out of the total expected cluster size in order to ensure latest state recovery. Shards are recovered once a quorum (by default) of the shard with its replicas is found. For this reason (and others) it is recommended to have at least 2 replicas per shard set. Indices (and the transaction log) must be file system based, to provide recoverability in case of full shutdown. The local gateway allows for simple to use long term persistency with elasticsearch and should simplify greatly using elasticsearch with full persistency support. -shay.banon \n"}<br>{"index": {"_id": 1581}}<br>{"title":"0.10.0 Released","seo_title":"","url":"\/blog\/0-10-0-released","author":{"name":"Shay Banon"},"date":"August 27, 2010","category":"","locales":"","content":" ElasticSearch version has just been released. You can download it . This is a major release for elasticsearch, both in terms of feature set as well as stability. Major partial list of features include: Geo Support Geo location support has been added, allowing to have geo query based capabilities (distance, bounding box, polygon) as well as facet support (distance based). More info can be found . Update Number of Replicas Dynamically Allow to change the number of replicas an index has using a simple . More Facets Range, filter, and more term facet options. More Mapping Options Ability to compress the field with extensive optimization at decompression only when needed (for example, decompressing directly down into the stream). New Gateway Structure A new gateway structure reducing the chances of gateway corruption as well as building the basis for future options such as saving versions of the gateway and allowing to recover from them. Here is the . Transport Compression The ability to configure the communication between nodes to work in a compressed mode, as well as different components using it by default (for example, peer recovery fetches the index in compressed mode). Minor Enhancements, Bugs Squashing A lot of work has going into improved stability of elasticsearch, better memory management, and major bugs squashing. ElasticSearch is being used by several companies to index very large amount of data with large cluster size successfully with snapshot versions of 0.10. -shay.banon \n"}<br>{"index": {"_id": 1582}}<br>{"title":"Geo Location and Search","seo_title":"","url":"\/blog\/geo-location-and-search","author":{"name":"Shay Banon"},"date":"August 16, 2010","category":"","locales":"","content":" One of the coolest search technology combinations out there are the ability to combine geo and search. Queries such as give me all the restaurants that serves meat ([insert your query here]) within 20 miles from me, or create a distance heat map of them, is slowly becoming a must have for any content website. This is becoming even more relevant with new browsers supporting . Already in (and in the upcoming release), elasticsearch comes with rich support for geo location. Lets take a drive down the geo support path: Indexing Location Aware Documents In general, documents indexed are not required to define any predefined mapping in order to use geo location features, but they should conform to a convention if none is defined. For example, lets take an example of a \u201cpin\u201d that we want to index its location and maybe some tags its associated with: { \"pin\" : { \"location\" : { \"lat\" : 40.12, \"lon\" : -71.34 }, \"tag\" : [\"food\", \"family\"], \"text\" : \"my favorite family restaurant\" } } The element is a \u201cgeo enabled\u201d location since it has and properties. Once one follows the above conventions, all geo location features are enabled for . If explicit setting is still required, then its easy to define a mapping that defines a certain property as a . Here is an example: { \"pin\" : { \"properties\" : { \"location\" : { \"type\" : \"geo_point\" } } } } By defining the property as , this means that now we can index location data in many different formats, starting from the lat\/lon example above, up to . For information on all the available formats, check out . The automatic mapping of \u201cgeo enabled\u201d properties has been disabled since publishing this article. You have to provide the correct mapping for geo properties. Please see the . Find By Location The first thing after indexing location aware documents, is being able to query them. There are several ways to be able to query such information, the simplest one is by . Here is an example: { \"filtered\" : { \"query\" : { \"field\" : { \"text\" : \"restaurant\" } }, \"filter\" : { \"geo_distance\" : { \"distance\" : \"12km\", \"pin.location\" : { \"lat\" : 40, \"lon\" : -70 } } } } } The above will search for all documents with of that exists within of the provided location. The location point can accept several different formats as well, detailed at . The next query supported is a , allowing to restrict the results into a geo box defined by the top left, and bottom right coordinates. Here is an example: { \"filtered\" : { \"query\" : { \"field\" : { \"text\" : \"restaurant\" } }, \"filter\" : { \"geo_bounding_box\" : { \"pin.location\" : { \"top_left\" : { \"lat\" : 40.73, \"lon\" : -74.1 }, \"bottom_right\" : { \"lat\" : 40.717, \"lon\" : -73.99 } } } } } } The last, and the most advance form of geo query is a , here is an example: { \"filtered\" : { \"query\" : { \"field\" : { \"text\" : \"restaurant\" } }, \"filter\" : { \"geo_polygon\" : { \"pin.location\" : { \"points\" : [ {\"lat\" : 40, \"lon\" : -70}, {\"lat\" : 30, \"lon\" : -80}, {\"lat\" : 20, \"lon\" : -90} ] } } } } } Sorting The ability to sort results not just by ranking (how relevant is the document to the query), but also by distance allows for much greater geo usability. There is now a new allowing to sort based on a distance from a specific location: { \"sort\" : [ { \"_geo_distance\" : { \"pin.location\" : [-40, 70], \"order\" : \"asc\", \"unit\" : \"km\" } } ], \"query\" : { \"field\" : { \"text\" : \"restaurant\" } } } On top of that, elasticsearch will now return all the values per hit of fields sorted on, allowing to easily display this important information. Faceting Faceting, the ability to show an aggregated views on top of the search results go hand in hand with geo. For example, one would like to get the number of hits matching the search query within 10 miles, 20 miles, and above from his location. The facet provides just that: { \"query\" : { \"field\" : { \"text\" : \"restaurant\" } }, \"facets\" : { \"geo1\" : { \"geo_distance\" : { \"pin.location\" : { \"lat\" : 40, \"lon\" : -70 }, \"ranges\" : [ { \"to\" : 10 }, { \"from\" : 10, \"to\" : 20 }, { \"from\" : 20, \"to\" : 100 }, { \"from\" : 100 } ] } } } } Summary The combination of search with geo is a natural one, and slowly becoming critical to any (web) application, especially with 5 and mobile devices becoming more and more widespread. elasticsearch upcoming geo support brings this integration into a whole new level, and enables application to provide rich geo and search functionality easily (ohh, and scale ). -shay.banon \n"}<br>{"index": {"_id": 1583}}<br>{"title":"0.9.0 Released","seo_title":"","url":"\/blog\/0-9-0-released","author":{"name":"Shay Banon"},"date":"July 26, 2010","category":"","locales":"","content":" ElasticSearch version has just been released. You can download it . This is a major release for elasticsearch, both in terms of feature set as well as stability. Major partial list of features include: Facets Support allow to provide aggregated data view correlating to the search query executed. ElasticSearch now comes with several facets implementations, including the typical \u201cterms\u201d facets (allowing to get the most popular terms, and how often they occur), statistical facets providing statistical information on numeric fields including count, total, mean, min, max, variance, sum of squares, and standard deviation. And, the coolest facet type, histogram facets, which based on a field, break it into buckets and provide data on the relevant buckets derived from the same field, another field, or a script. Scripting Support Added as a general feature within elasticsearch, allows to define scripts that are evaluated at runtime and can be used in different elasticsearch features, such as facets, script search fields, script filter, and so on. More Queries and Filters Additional queries and filters have been added. Thanks to the Query of elasticsearch, adding queries is a snap. Queries include fuzzy query, custom score query (based on scripts), script filter, and\/or\/not filters, and more. Improved Gateway Recovery A major feature in elasticsearch, allowing to reuse existing index files when recovering from the gateway after a full cluster restart significantly reducing the time it takes to recover from the gateway. This include additions to the gateway behavior including the ability to control when the initial recovery will happen as a factor of the number of nodes in the cluster and time. Also, the shutdown has been enhanced to better handle full cluster shutdown. Script Search Fields The ability to load custom data (based on non stored fields) as part of the search request. Improves Fluent Java \/ Groovy The Java \/ Groovy has been greatly enhanced to provide more fluent execution. Cloud Specific Plugin The cloud has been rewritten to use directly the amazon , providing better stability and features when using . The cloud plugin now only works with Amazon . Stability, Bug Squashing, and Memory Usage Improvements A lot of work has going into improved stability of elasticsearch, better memory management, and major bugs squashing. ElasticSearch is being used by several companies to index very large amount of data with large cluster size successfully with snapshot versions of 0.9. -shay.banon \n"}<br>{"index": {"_id": 1584}}<br>{"title":"0.8.0 Released","seo_title":"","url":"\/blog\/0-8-0-released","author":{"name":"Shay Banon"},"date":"May 27, 2010","category":"Engineering","locales":"","content":" ElasticSearch version has just been released. You can download it . This release includes several bug fixes and memory footprint improvements, and one major feature, Hadoop integration. This allows to use Hadoop as elasticsearch gateway storage, and enabling it is as simple as:Installing the hadoop plugin using .Changing the configuration to include:gateway: type: hdfs hdfs: uri: hdfs:\/\/host:port path: path\/to\/folder -shay.banon \n"}<br>{"index": {"_id": 1585}}<br>{"title":"0.7.1 Released","seo_title":"","url":"\/blog\/0-7-1-released","author":{"name":"Shay Banon"},"date":"May 17, 2010","category":"","locales":"","content":" ElasticSearch version has just been released. You can download it . This release fixed a major bug when indexing large documents resulting in storing additional null bytes (and returning them). Version also brings a major feature to elasticsearch, recovery throttling. In elasticsearch, there are two types of recovery. The first, is recovery from the gateway. This happens only when the first shard is allocated in the cluster. The second recovery happens when nodes move or allocate shards around. The recovery process in both cases include recovering both each shard index files, and the transaction log. Up until version , elasticsearch would basically go full force in performing the recovery. If a new node would join the cluster, all the possible shards would be allocated to it, and all will perform recovery in parallel. More over, each single shard index file recovery will happen in parallel as well. This can lead to a heavy load on the nodes, making them less responsive for on going operations performed on them. From version , recovery throttling is enabled, basically allowing only for a controlled number of concurrent recovery operations, and concurrent stream (single shard index file) recovery operation. Both counts are maintained on the node level, regardless of the number of indices or shards. The setting controls the number of concurrent recoveries allowed (shard recoveries). It defaults to the number of cores. The control the concurrent shard index file recoveries, and defaults to the number of cores as well. -shay.banon \n"}<br>{"index": {"_id": 1586}}<br>{"title":"0.7.0 Released","seo_title":"","url":"\/blog\/0-7-0-released","author":{"name":"Shay Banon"},"date":"May 14, 2010","category":"Engineering","locales":"","content":" ElasticSearch version has just been released. You can download it . This release brings much improved stability, and several features:Zen DiscoveryA discovery module called built from the ground up to work well, and fast with elasticsearch. This is now the default discovery module, with the jgroups discovery module moving to be provided as a plugin.Groovy ClientA native groovy client providing a Groovyfied build on top of the native Java . More details provided in the blog post. As a side note, anybody up for building a Scala\/JRbuy client?CloudFirst and foremost, native cloud support, providing zero conf cloud discovery ( No Special Node\u2122 ) and the ability to persist long term index storage on different cloud providers blob stores. More information can be found in the blog post.Memcached TransportFor that extra oomph when is not fast enough (mainly from other languages), elasticsearch supports a subset of the memcached protocol. Basically, the implementation implements on top of memcached (as much as possible). More info can be found .Simpler Plugin ManagementMany things in elasticsearch are implemented as a plugin. For example, the cloud support or memcached support are implemented as plugins. Now, installing a plugin is as simple as issuing the following command:bin\/plugin -install cloud bin\/plugin -install transport-memcached Analysis Better support when working with unicode through the analysis plugin. More info .More APIsMore information on nodes using the new Node stats , as well as the ability to restart a node. ClientsSimpler dependency management, requiring only lucene as a dependency.XContentThough currently mainly for internal use, an abstraction on top of has been created, inspired by called . There is support a implementation for it, but also support for , which is a binary format for faster and smaller (message footprint) messages. The Java already uses it automatically (not for indexed documents), and both the and the indexed documents can be either in or format. format will be documented in the near future to allow for non based clients to use it.-shay.banon \n"}<br>{"index": {"_id": 1587}}<br>{"title":"Here Comes the Cloud","seo_title":"","url":"\/blog\/here-comes-the-cloud","author":{"name":"Shay Banon"},"date":"May 11, 2010","category":"Engineering","locales":"","content":" From the get go, elasticsearch has been designed and built for the cloud. From its internal architecture, to how it works in its distributed nature. In the upcoming 0.7 version, the cloud vision has been fully realized. The Cloud integration revolves around two major components in ElasticSearch: and . Cloud Discovery One of the main problems with running distributed systems on the cloud is discovery. Products that can do \u201czero conf\u201d discovery use multicast for it (elasticsearch among them), and in most cloud providers (Amazon or Rackspace) multicast is disabled. The typical way to work around it is to use unicast discovery, which requires setting up a specific list of IPs\/Hosts (routers or gossip servers). Unicast discovery is problematic when used on the cloud. Machines can come and go, and their IP is not static. Cloud providers work around that by providing the ability to have a set of \u201celastic IPs\u201d. But, at the end, the management of the cloud installation becomes a pain. At least two servers must be associated with an elastic IP and become a special exception case which needs to be managed. This goes completely against \u201czero conf\u201d discovery and heavily complicates the cloud installation. ElasticSearch has a new discovery module called \u201cZen\u201d which was built from the ground up to work well in cloud environments (and integrate well with other elasticsearch modules). The cloud extension to it provides \u201czero conf\u201d discovery in cloud environments. In a nutshell, when running on the cloud, the list of machines that are already running on the cloud is available through cloud APIs. This information can be used to perform \u201czero conf\u201d discovery. This follows the motto that the should be embraced by any system running on the cloud: . So, how do you enabled cloud discovery on the cloud? With a few lines of configuration: cloud: account: &lt: Your Amazon AWS Account Here&gt: key: &lt: Your Amazon AWS Secret Key Here&gt: compute: type: amazon discovery: type: cloud The above configuration enables auto discovery in Amazon . Simply replace with to work on the Rackspace cloud. There is a long list of compute cloud providers supported, including GoGrid, and Terremark. Gateway ElasticSearch has been designed to do reliable asynchronous long term persistency. This enables several features including the ability for fast local \u201cruntime\u201d storage (including in-memory) while having a long term storage that can be slower. The Gateway concept is described in the post. But first, a step back. When designing a system that would be deployed on the cloud, lets take a search engine for example , things come and go. One of those things that come and go are disks. So, local storage, in cloud environments, is considered transient. In Amazon for example, (Elastic Block Store) was introduced to provide a mountable disk that survives restarts. So, we could configure our search engine to store the index on . But, requires periodic snapshotting to S3 (amazon blob store) for \u201csafe\u201d persistency, since can certainly suffer from failures as well. Of course, this means more money spent on your cloud deployment since now one pays for both and S3. One way to work around this is to persist directly from the local store to S3 by writing some sort of synchronization script \/ code. But, if the machines fails we will loose all the data up to the point when the script last ran. The next step is to add replication (and sharding for performance) and so on. All of this is provided by elasticsearch out of the box. Here is how elasticsearch can be configured to store both its cluster metadata (to survive full cluster failure) and indices in the cloud: cloud: account: &lt: Your Amazon AWS Account Here&gt: key: &lt: Your Amazon AWS Secret Key Here&gt: blobstore: type: amazon gateway: type: cloud cloud: container: mycontainerhere The above simple configuration will store things in Amazon S3. Simply change to to use Rackspace CloudFiles. There is a long list of blobstore providers supported, including Azureblob. Final Words As you can see, elasticsearch is now a first class citizen when running on the cloud. I believe that it has actually created a new level of intimate integration of products with the cloud. Both the and means that managing an elasticsearch deployment on the cloud is a breeze. As a side note, I would like to note that cross cloud support is done using . Highly recommended. -shay.banon \n"}<br>{"index": {"_id": 1588}}<br>{"title":"ElasticSearch Just Got Groovy","seo_title":"","url":"\/blog\/elasticseach-just-got-groovy","author":{"name":"Shay Banon"},"date":"April 19, 2010","category":"Engineering","locales":"","content":" \n"}<br>{"index": {"_id": 1589}}<br>{"title":"0.6.0 Released","seo_title":"","url":"\/blog\/0-6-0-released","author":{"name":"Shay Banon"},"date":"April 09, 2010","category":"","locales":"","content":" ElasticSearch version has just been released. You can download it . This release brings much improved stability, and several features: First, a big rename has occurred. All the now uses \u201cunderscore casing\u201d instead of \u201cCamelCase casing\u201d. This makes elasticsearch more streamlined with other based APIs out there. The is much more flexible now, supporting numbers provided as strings, and boolean values provided as either numbers or strings. This makes using elasticsearch from dynamic languages more easy. field support has been added, automatically creating a field that includes all the different fields in the document for simpler searching (no need to explicitly specify the field name to search on). One of the nice things about the field is that it takes boost level setting of different fields into account. More information on the field can be found . Highlighting is now supported as part of the search request. Simpler Query including support for queries and on queries. allows to create aliases associated with a single index or more and executing other APIs using it instead of the actual index names. A new plugin system has been develop allowing to easily extend elasticsearch with the first plugin being the plugin allowing to index \u201cattachments\u201d such as documents, images, mails, and so on. Internal changes to how communication is handled between nodes resulting in much smaller messages passing around over the low level transport layer and a lower latency\/overhead for each . Many bug fixes and performance enhancements slowly making elasticsearch as rock solid as it should be! Last but not least, elasticsearch is now on Maven repository, with a and a . -shay.banon \n"}<br>{"index": {"_id": 1590}}<br>{"title":"0.5.0 Released","seo_title":"","url":"\/blog\/0-5-0-released","author":{"name":"Shay Banon"},"date":"March 05, 2010","category":"","locales":"","content":" ElasticSearch version has just been released. You can download it . This release brings much improved stability, better handling of mapping definitions, and several features: Several new queries have been added, including , , , with multiple fields. allowing to get terms (from one or more indices) of one or more fields and their respective document frequencies (how often they exists in documents). This can be very handy to implement things like tag clouds or simple auto suggest. for simple indication on the health of the cluster, as well as the ability to wait for the cluster to reach a health status. to search for documents that are like a certain document. exposing all of elasticsearch operations\/actions using simple, transport based, async to use with any based language. There are many more minor features and bug fixes, all listed under the tag. -shay.banon \n"}<br>{"index": {"_id": 1591}}<br>{"title":"NoSQL, Yes Search","seo_title":"","url":"\/blog\/no-sql-yes-search","author":{"name":"Shay Banon"},"date":"February 25, 2010","category":"Engineering","locales":"","content":" \n"}<br>{"index": {"_id": 1592}}<br>{"title":"Search Engine Time Machine","seo_title":"","url":"\/blog\/searchengine-time-machine","author":{"name":"Shay Banon"},"date":"February 16, 2010","category":"Engineering","locales":"","content":" \n"}<br>{"index": {"_id": 1593}}<br>{"title":"Your Data, Your Search","seo_title":"","url":"\/blog\/your-data-your-search","author":{"name":"Shay Banon"},"date":"February 12, 2010","category":"Engineering","locales":"","content":" \n"}<br>{"index": {"_id": 1594}}<br>{"title":"You Know, for Search","seo_title":"","url":"\/blog\/you-know-for-search","author":{"name":"Shay Banon"},"date":"February 08, 2010","category":"","locales":"","content":" ElasticSearch is an open source, distributed, RESTful, search engine which is built on top of internally and enjoys all the features it provides. All the features it has are listed in the , so no need to list them here again (with the extra splash, if I might add). ElasticSearch itself was born out of my frustration with the fact that there isn\u2019t really a good, open source, solution for distributed search engine out there, which also combines what I expect of search engines after building (and on that, I will blog later\u2026). I have been working on this for the past several months, pouring my search and distributed knowledge into this (and portions of my heart and time : ) ), Enjoy!. \n"}<br>